<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Net - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Net", url: "#net", children: [
              {title: "Load Analytics Zoo Model", url: "#load-analytics-zoo-model" },
              {title: "Load BigDL Model", url: "#load-bigdl-model" },
              {title: "Load Torch Model", url: "#load-torch-model" },
              {title: "Load Caffe Model", url: "#load-caffe-model" },
              {title: "Load TensorFlow model", url: "#load-tensorflow-model" },
          ]},
          {title: "TFNet", url: "#tfnet", children: [
              {title: "Export TensorFlow model to frozen inference graph", url: "#export-tensorflow-model-to-frozen-inference-graph" },
              {title: "Creating a TFNet", url: "#creating-a-tfnet" },
          ]},
          {title: "TFDataset", url: "#tfdataset", children: [
          ]},
          {title: "TFOptimizer", url: "#tfoptimizer", children: [
          ]},
          {title: "TFPredictor", url: "#tfpredictor", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Net</strong></h1>
    <hr>
    <h2 id="net">Net</h2>
<h3 id="load-analytics-zoo-model">Load Analytics Zoo Model</h3>
<p>Use <code>Net.load</code>(in Scala) or <code>Net.load</code> (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.  <code>Net</code> (Scala) or <code>Net</code>(Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.</p>
<p><strong>Scala example</strong></p>
<pre><code class="scala">val model = Net.load(&quot;/tmp/model.def&quot;, &quot;/tmp/model.weights&quot;) //load from local fs
val model = Net.load(&quot;hdfs://...&quot;) //load from hdfs
val model = Net.load(&quot;s3://...&quot;) //load from s3
</code></pre>

<p><strong>Python example</strong></p>
<pre><code class="python">model = Net.load(&quot;/tmp/model.def&quot;, &quot;/tmp/model.weights&quot;) //load from local fs
model = Net.load(&quot;hdfs://...&quot;) //load from hdfs
model = Net.load(&quot;s3://...&quot;) //load from s3
</code></pre>

<h3 id="load-bigdl-model">Load BigDL Model</h3>
<p><strong>Scala example</strong></p>
<pre><code class="scala">val model = Net.loadBigDL(&quot;/tmp/model.def&quot;, &quot;/tmp/model.weights&quot;) //load from local fs
val model = Net.loadBigDL(&quot;hdfs://...&quot;) //load from hdfs
val model = Net.loadBigDL(&quot;s3://...&quot;) //load from s3
</code></pre>

<p><strong>Python example</strong></p>
<pre><code class="python">model = Net.loadBigDL(&quot;/tmp/model.def&quot;, &quot;/tmp/model.weights&quot;) //load from local fs
model = Net.loadBigDL(&quot;hdfs://...&quot;) //load from hdfs
model = Net.loadBigDL(&quot;s3://...&quot;) //load from s3
</code></pre>

<h3 id="load-torch-model">Load Torch Model</h3>
<p><strong>Scala example</strong></p>
<pre><code class="scala">val model = Net.loadTorch(&quot;/tmp/torch_model&quot;) //load from local fs
val model = Net.loadTorch(&quot;hdfs://...&quot;) //load from hdfs
val model = Net.loadTorch(&quot;s3://...&quot;) //load from s3
</code></pre>

<p><strong>Python example</strong></p>
<pre><code class="python">model = Net.loadTorch(&quot;/tmp/torch_model&quot;) //load from local fs
model = Net.loadTorch(&quot;hdfs://...&quot;) //load from hdfs
model = Net.loadTorch(&quot;s3://...&quot;) //load from s3
</code></pre>

<h3 id="load-caffe-model">Load Caffe Model</h3>
<p><strong>Scala example</strong></p>
<pre><code class="scala">val model = Net.loadCaffe(&quot;/tmp/def/path&quot;, &quot;/tmp/model/path&quot;) //load from local fs
val model = Net.loadCaffe(&quot;hdfs://def/path&quot;, &quot;hdfs://model/path&quot;) //load from hdfs
val model = Net.loadCaffe(&quot;s3://def/path&quot;, &quot;s3://model/path&quot;) //load from s3
</code></pre>

<p><strong>Python example</strong></p>
<pre><code class="python">model = Net.loadCaffe(&quot;/tmp/def/path&quot;, &quot;/tmp/model/path&quot;) //load from local fs
model = Net.loadCaffe(&quot;hdfs://def/path&quot;, &quot;hdfs://model/path&quot;) //load from hdfs
model = Net.loadCaffe(&quot;s3://def/path&quot;, &quot;s3://model/path&quot;) //load from s3
</code></pre>

<h3 id="load-tensorflow-model">Load TensorFlow model</h3>
<p>We also provides utilities to load tensorflow model.</p>
<p>If we already have a frozen graph protobuf file, we can use the <code>loadTF</code> api directly to
load the tensorflow model. </p>
<p>Otherwise, we should first use the <code>export_tf_checkpoint.py</code> script provided by BigDL's distribution
package, or the <code>dump_model</code> function defined in <a href="https://github.com/intel-analytics/BigDL/blob/master/pyspark/bigdl/util/tf_utils.py">here</a> to
generate the model definition file (<code>model.pb</code>) and variable binary file (<code>model.bin</code>). </p>
<p><strong>Use Script</strong></p>
<pre><code class="shell">GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta
CKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt
SAVE_PATH=/tmp/model/
python export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH
</code></pre>

<p><strong>Use python function</strong></p>
<pre><code class="python">import tensorflow as tf

# This is your model definition.
xs = tf.placeholder(tf.float32, [None, 1])

W1 = tf.Variable(tf.zeros([1,10])+0.2)
b1 = tf.Variable(tf.zeros([10])+0.1)
Wx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)
output = tf.nn.tanh(Wx_plus_b1, name=&quot;output&quot;)

# Adding the following lines right after your model definition 
from bigdl.util.tf_utils import dump_model
dump_model_path = &quot;/tmp/model&quot;
# This line of code will create a Session and initialized all the Variable and
# save the model definition and variable to dump_model_path as BigDL readable format.
dump_model(path=dump_model_path)
</code></pre>

<p>Then we can use the <code>loadTF</code> api to load the tensorflow model into BigDL.</p>
<p><strong>Scala example</strong></p>
<pre><code class="scala">val modelPath = &quot;/tmp/model/model.pb&quot;
val binPath = &quot;/tmp/model/model.bin&quot;
val inputs = Seq(&quot;Placeholder&quot;)
val outputs = Seq(&quot;output&quot;)

// For tensorflow frozen graph or graph without Variables
val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)

// For tensorflow graph with Variables
val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))
</code></pre>

<p><strong>Python example</strong></p>
<pre><code class="python">model_def = &quot;/tmp/model/model.pb&quot;
model_variable = &quot;/tmp/model/model.bin&quot;
inputs = [&quot;Placeholder&quot;]
outputs = [&quot;output&quot;]
# For tensorflow frozen graph or graph without Variables
model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = &quot;little_endian&quot;, bigdl_type=&quot;float&quot;)

# For tensorflow graph with Variables
model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = &quot;little_endian&quot;, bigdl_type=&quot;float&quot;, bin_file=model_variable)
</code></pre>

<h2 id="tfnet">TFNet</h2>
<p>TFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel.</p>
<p>The difference between Net.loadTF() is that TFNet will call tensorflow's java api to do the computation.</p>
<p>TFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model.
When used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient
from TFNet is set to zero.</p>
<p><strong>Note</strong>: This feature currently supports <strong>tensorflow 1.10</strong> and requires the OS to be one of the following 64-bit systems.
<strong>Ubuntu 16.04 or later</strong>, <strong>macOS 10.12.6 or later</strong> and <strong>Windows 7 or later</strong>.</p>
<p>To run on other system may require you to manually compile the TensorFlow source code. Instructions can
be found <a href="https://github.com/tensorflow/tensorflow/tree/v1.10.0/tensorflow/java">here</a>.</p>
<h3 id="export-tensorflow-model-to-frozen-inference-graph">Export TensorFlow model to frozen inference graph</h3>
<p>Analytics-zoo provides a useful utility function, <code>export_tf</code>, to export a TensorFlow model
to frozen inference graph.</p>
<p>For example:</p>
<p><strong>Python:</strong></p>
<pre><code class="python">import tensorflow as tf
from nets import inception
slim = tf.contrib.slim

images = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3))

with slim.arg_scope(inception.inception_v1_arg_scope()):
    logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False)

sess = tf.Session()
saver = tf.train.Saver()
saver.restore(sess, &quot;/tmp/models/inception_v1.ckpt&quot;)

from zoo.util.tf import export_tf
export_tf(sess, &quot;/tmp/models/tfnet&quot;, inputs=[images], outputs=[logits])
</code></pre>

<p>In the above code, the <code>export_tf</code> utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names. </p>
<h3 id="creating-a-tfnet">Creating a TFNet</h3>
<p>After we have export the TensorFlow model, we can easily create a TFNet.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val m = TFNet(&quot;/tmp/models/tfnet&quot;)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">m = TFNet.from_export_folder(&quot;/tmp/models/tfnet&quot;)
</code></pre>

<p>Please refer to <a href="https://github.com/intel-analytics/analytics-zoo/tree/master/zoo/src/main/scala/com/intel/analytics/zoo/examples/tfnet">TFNet Object Detection Example (Scala)</a>
or <a href="https://github.com/intel-analytics/analytics-zoo/tree/master/pyzoo/zoo/examples/tensorflow/tfnet">TFNet Object Detection Example (Python)</a> and
the <a href="https://github.com/intel-analytics/analytics-zoo/tree/master/apps/tfnet">Image Classification Using TFNet Notebook</a> for more information.</p>
<h2 id="tfdataset">TFDataset</h2>
<p>TFDatset represents a distributed collection of elements to be feed into TensorFlow graph.
TFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing
the tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the
TFOptimizer or TFPredictor.</p>
<p><strong>Note</strong>: This feature currently requires <strong>tensorflow 1.10</strong> and OS is one of the following 64-bit systems.
<strong>Ubuntu 16.04 or later</strong>, <strong>macOS 10.12.6 or later</strong> and <strong>Windows 7 or later</strong>.</p>
<p>To run on other system may require you to manually compile the TensorFlow source code. Instructions can
be found <a href="https://github.com/tensorflow/tensorflow/tree/v1.10.0/tensorflow/java">here</a>.</p>
<p><strong>Python</strong></p>
<pre><code class="python">   dataset = TFDataset.from_rdd(train_rdd,
                                 names=[&quot;features&quot;, &quot;labels&quot;],
                                 shapes=[[28, 28, 1], [1]],
                                 types=[tf.float32, tf.int32],
                                 batch_size=BATCH_SIZE)
</code></pre>

<h2 id="tfoptimizer">TFOptimizer</h2>
<p>TFOptimizer is the class that does all the hard work in distributed training, such as model
distribution and parameter synchronization. There are two ways to create a TFOptimizer.</p>
<p>The <code>from_loss</code> API takes the <strong>loss</strong> (a scalar tensor) as input and runs
stochastic gradient descent using the given <strong>optimMethod</strong> on all the <strong>Variables</strong> that contributing
to this loss.</p>
<p>The <code>from_keras</code> API takes a compiled <strong>Keras Model</strong> and a <strong>TFDataset</strong> and runs stochastic gradient
descent using the loss function, optimizer and metrics specified by the Keras model.</p>
<p><strong>Note</strong>: This feature currently requires <strong>tensorflow 1.10</strong> and OS is one of the following 64-bit systems.
<strong>Ubuntu 16.04 or later</strong>, <strong>macOS 10.12.6 or later</strong> and <strong>Windows 7 or later</strong>.</p>
<p>To run on other system may require you to manually compile the TensorFlow source code. Instructions can
be found <a href="https://github.com/tensorflow/tensorflow/tree/v1.10.0/tensorflow/java">here</a>.</p>
<p><strong>Python</strong></p>
<pre><code class="python">loss = ...
optimizer = TFOptimizer.from_loss(loss, Adam(1e-3))
optimizer.optimize(end_trigger=MaxEpoch(5))
</code></pre>

<p>For Keras model:</p>
<pre><code class="python">

model = Model(inputs=..., outputs=...)

model.compile(optimizer='rmsprop',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])

optimizer = TFOptimizer.from_keras(model, dataset)
optimizer.optimize(end_trigger=MaxEpoch(5))
</code></pre>

<h2 id="tfpredictor">TFPredictor</h2>
<p>TFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in
 TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the
 model prediction for the corresponding input elements.</p>
<p><strong>Note</strong>: This feature currently requires <strong>tensorflow 1.10</strong> and OS is one of the following 64-bit systems.
 <strong>Ubuntu 16.04 or later</strong>, <strong>macOS 10.12.6 or later</strong> and <strong>Windows 7 or later</strong>.</p>
<p>To run on other system may require you to manually compile the TensorFlow source code. Instructions can
 be found <a href="https://github.com/tensorflow/tensorflow/tree/v1.10.0/tensorflow/java">here</a>.</p>
<p><strong>Python</strong></p>
<pre><code class="python">logist = ...
predictor = TFPredictor.from_outputs(sess, [logits])
predictions_rdd = predictor.predict()
</code></pre>

<p>For Keras model:</p>
<pre><code class="python">model = Model(inputs=..., outputs=...)
model.load_weights(&quot;/tmp/mnist_keras.h5&quot;)
predictor = TFPredictor.from_keras(model, dataset)
predictions_rdd = predictor.predict()
</code></pre>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>