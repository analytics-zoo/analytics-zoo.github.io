{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Analytics Zoo A unified analytics + AI platform for distributed TensorFlow, Keras and BigDL on Apache Spark What is Analytics Zoo? Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline; the entire pipeline can then transparently scale out to a large Hadoop/Spark cluster for distributed training or inference. Data wrangling and analysis using PySpark Deep learning model development using TensorFlow or Keras Distributed training/inference on Spark and BigDL All within a single unified pipeline and in a user-transparent fashion! In addition, Analytics Zoo also provides a rich set of analytics and AI support for the end-to-end pipeline, including: Easy-to-use abstractions and APIs (e.g., transfer learning support, autograd operations, Spark DataFrame and ML pipeline support, online model serving API, etc.) Common feature engineering operations (for image, text, 3D image, etc.) Built-in deep learning models (e.g., object detection, image classification, text classification, recommendation, anomaly detection, text matching, sequence to sequence etc.) Reference use cases (e.g., anomaly detection, sentiment analysis, fraud detection, image similarity, etc.) How to use Analytics Zoo? To get started, please refer to the Python install guide or Scala install guide . For running distributed TensorFlow on Spark and BigDL, please refer to the quick start here and the details here . For more information, You may refer to the Analytics Zoo document website . For additional questions and discussions, you can join the Google User Group (or subscribe to the Mail List ). Overview Distributed TensorFlow and Keras on Spark/BigDL Data wrangling and analysis using PySpark Deep learning model development using TensorFlow or Keras Distributed training/inference on Spark and BigDL All within a single unified pipeline and in a user-transparent fashion! High level abstractions and APIs Transfer learning : customize pretrained model for feature extraction or fine-tuning autograd : build custom layer/loss using auto differentiation operations nnframes : native deep learning support in Spark DataFrames and ML Pipelines Model serving : productionize model serving and inference using POJO APIs Built-in deep learning models Object detection API : high-level API and pretrained models (e.g., SSD and Faster-RCNN) for object detection Image classification API : high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for image classification Text classification API : high-level API and pre-defined models (using CNN, LSTM, etc.) for text classification Recommendation API : high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendation Anomaly detection API : high-level API and pre-defined models based on LSTM for anomaly detection Text matching API : high-level API and pre-defined KNRM model for text matching Sequence to sequence API : high-level API and pre-defined models for sequence to sequence Reference use cases : a collection of end-to-end reference use cases (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.) Docker images and builders Analytics-Zoo in Docker How to build it How to use the image Notice Distributed TensorFlow and Keras on Spark/BigDL To make it easy to build and productionize the deep learning applications for Big Data, Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline (as illustrated below), which can then transparently run on a large-scale Hadoop/Spark clusters for distributed training and inference. (Please see more details here ). 1.Data wrangling and analysis using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset sc = init_nncontext() #Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) #TFDataset represents a distributed set of elements, #in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, names=[ features , labels ], shapes=[[28, 28, 1], [1]], types=[tf.float32, tf.int32], batch_size=BATCH_SIZE) 2.Deep learning model development using TensorFlow import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors labels = tf.squeeze(labels) with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=True) loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)) 3.Distributed training on Spark and BigDL from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) 4.Alternatively, using Keras APIs for model development and distributed training from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * model = Sequential() model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation= tanh , name= fc1 )) model.add(Dense(class_num, activation= softmax , name= fc2 )) model.compile(loss='sparse_categorical_crossentropy', optimizer='adam') model.fit(train_rdd, batch_size=BATCH_SIZE, nb_epoch=5) High level abstractions and APIs Analytics Zoo provides a set of easy-to-use, high level abstractions and APIs that natively transfer learning, autograd and custom layer/loss, Spark DataFrames and ML Pipelines, online model serving, etc. etc. Transfer learning Using the high level transfer learning APIs, you can easily customize pretrained models for feature extraction or fine-tuning . (See more details here ) 1.Load an existing model (pretrained in Caffe) from zoo.pipeline.api.net import * full_model = Net.load_caffe(def_path, model_path) 2.Remove the last few layers # create a new model by removing layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) 3.Freeze the first few layers # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) 4.Add a few new layers from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * inputs = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputs) flatten = Flatten()(inception) logits = Dense(2)(flatten) newModel = Model(inputs, logits) autograd autograd provides automatic differentiation for math operations, so that you can easily build your own custom loss and layer (in both Python and Scala), as illustrated below. (See more details here ) 1.Define model using Keras-style API and autograd import zoo.pipeline.api.autograd as A from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * input = Input(shape=[2, 20]) features = TimeDistributed(layer=Dense(30))(input) f1 = features.index_select(1, 0) f2 = features.index_select(1, 1) diff = A.abs(f1 - f2) model = Model(input, diff) 2.Optionally define custom loss function using autograd def mean_absolute_error(y_true, y_pred): return mean(abs(y_true - y_pred), axis=1) 3.Train model with custom loss function model.compile(optimizer=SGD(), loss=mean_absolute_error) model.fit(x=..., y=...) nnframes nnframes provides native deep learning support in Spark DataFrames and ML Pipelines , so that you can easily build complex deep learning pipelines in just a few lines, as illustrated below. (See more details here ) 1.Initialize NNContext and load images into DataFrames using NNImageReader from zoo.common.nncontext import * from zoo.pipeline.nnframes import * from zoo.feature.image import * sc = init_nncontext() imageDF = NNImageReader.readImages(image_path, sc) 2.Process loaded data using DataFrames transformations getName = udf(lambda row: ...) getLabel = udf(lambda name: ...) df = imageDF.withColumn( name , getName(col( image ))).withColumn( label , getLabel(col('name'))) 3.Processing image using built-in feature engineering operations transformer = RowToImageFeature() - ImageResize(64, 64) - ImageChannelNormalize(123.0, 117.0, 104.0) \\ - ImageMatToTensor() - ImageFeatureToTensor()) 4.Define model using Keras-style APIs from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\ .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax'))) 5.Train model using Spark ML Pipelines classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\ .setBatchSize(40).setMaxEpoch(1).setFeaturesCol( image ).setCachingSample(False) nnModel = classifier.fit(df) Model Serving Using the POJO model serving API, you can productionize model serving and inference in any Java based frameworks (e.g., Spring Framework , Apache Storm , Kafka or Flink , etc.), as illustrated below: import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel; import com.intel.analytics.zoo.pipeline.inference.JTensor; public class TextClassificationModel extends AbstractInferenceModel { public TextClassificationModel() { super(); } } TextClassificationModel model = new TextClassificationModel(); model.load(modelPath, weightPath); List JTensor inputs = preprocess(...); List List JTensor result = model.predict(inputs); ... Built-in deep learning models Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as object detection , image classification , text classification , recommendation , anomaly detection , text matching , sequence to sequence , etc. Object detection API Using Analytics Zoo Object Detection API (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details here ) 1.Download object detection models in Analytics Zoo You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from detection model zoo . 2.Use Object Detection API for off-the-shell inference from zoo.models.image.objectdetection import * model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set) Image classification API Using Analytics Zoo Image Classification API (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet, etc.), you can easily build your image classification applications, as illustrated below. (See more details here ) 1.Download image classification models in Analytics Zoo You can download a collection of image classification models (pretrained on the ImageNet dataset) from image classification model zoo . 2.Use Image classification API for off-the-shell inference from zoo.models.image.imageclassification import * model = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set) Text classification API Analytics Zoo Text Classification API provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details here ) Recommendation API Analytics Zoo Recommendation API provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details here ) Anomaly detection API Analytics Zoo Anomaly Detection API provides a set of pre-defined models based on LSTM to detect anomalies for time series data. (See more details here ) Text matching API Analytics Zoo Text Matching API provides pre-defined KNRM model for ranking or classification. (See more details here ) Sequence to sequence API Analytics Zoo Sequence to Sequence API provides a set of pre-defined models based on Recurrent neural network for sequence to sequence problems. (See more details here ) Reference use cases Analytics Zoo provides a collection of end-to-end reference use cases, including time series anomaly detection , sentiment analysis , fraud detection , image similarity , etc. (See more details here ) Docker images and builders Analytics-Zoo in Docker By default, the Analytics-Zoo image has installed below packages: - git - maven - Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152) - python 2.7.6 - pip - numpy - scipy - pandas - scikit-learn - matplotlib - seaborn - jupyter - wordcloud - moviepy - requests - tensorflow_ - spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION}) - Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION}) - Analytics-Zoo source code (in /opt/work/analytics-zoo) The work dir for Analytics-Zoo is /opt/work. - download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions. - start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a specified jupyter notebook. - analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution. - analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution. - spark-${SPARK_VERSION} is the Spark home. - analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo. How to build it By default, you can build a Analytics-Zoo:default image with latest nightly-build Analytics-Zoo distributions: sudo docker build --rm -t intelanalytics/analytics-zoo:default . If you need http and https proxy to build the image: sudo docker build \\ --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\ --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\ --rm -t intelanalytics/analytics-zoo:default . You can also specify the ANALYTICS_ZOO_VERSION and SPARK_VERSION to build a specific Analytics-Zoo image: sudo docker build \\ --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\ --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\ --build-arg ANALYTICS_ZOO_VERSION=0.3.0 \\ --build-arg BIGDL_VERSION=0.6.0 \\ --build-arg SPARK_VERSION=2.3.1 \\ --rm -t intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 . How to use the image To start a notebook directly with a specified port(e.g. 12345). You can view the notebook on http://[host-ip]:12345 sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 If you need http and https proxy in your environment: sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 You can also start the container first sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default bash In the container, after setting proxy and ports, you can start the Notebook by: /opt/work/start-notebook.sh Notice If you need nightly build version of Analytics-Zoo, please pull the image form Dockerhub with: sudo docker pull intelanalytics/analytics-zoo:latest Please follow the readme in each app folder to test the jupyter notebooks !!! With 0.3+ version of Anaytics-Zoo Docker image, you can specify the runtime conf of spark sudo docker run -itd --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= 1234qwer \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ -e RUNTIME_DRIVER_CORES=4 \\ -e RUNTIME_DRIVER_MEMORY=20g \\ -e RUNTIME_EXECUTOR_CORES=4 \\ -e RUNTIME_EXECUTOR_MEMORY=20g \\ -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\ intelanalytics/analytics-zoo:latest","title":"Overview"},{"location":"#analytics-zoo","text":"A unified analytics + AI platform for distributed TensorFlow, Keras and BigDL on Apache Spark","title":"Analytics Zoo"},{"location":"#what-is-analytics-zoo","text":"Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline; the entire pipeline can then transparently scale out to a large Hadoop/Spark cluster for distributed training or inference. Data wrangling and analysis using PySpark Deep learning model development using TensorFlow or Keras Distributed training/inference on Spark and BigDL All within a single unified pipeline and in a user-transparent fashion! In addition, Analytics Zoo also provides a rich set of analytics and AI support for the end-to-end pipeline, including: Easy-to-use abstractions and APIs (e.g., transfer learning support, autograd operations, Spark DataFrame and ML pipeline support, online model serving API, etc.) Common feature engineering operations (for image, text, 3D image, etc.) Built-in deep learning models (e.g., object detection, image classification, text classification, recommendation, anomaly detection, text matching, sequence to sequence etc.) Reference use cases (e.g., anomaly detection, sentiment analysis, fraud detection, image similarity, etc.)","title":"What is Analytics Zoo?"},{"location":"#how-to-use-analytics-zoo","text":"To get started, please refer to the Python install guide or Scala install guide . For running distributed TensorFlow on Spark and BigDL, please refer to the quick start here and the details here . For more information, You may refer to the Analytics Zoo document website . For additional questions and discussions, you can join the Google User Group (or subscribe to the Mail List ).","title":"How to use Analytics Zoo?"},{"location":"#overview","text":"Distributed TensorFlow and Keras on Spark/BigDL Data wrangling and analysis using PySpark Deep learning model development using TensorFlow or Keras Distributed training/inference on Spark and BigDL All within a single unified pipeline and in a user-transparent fashion! High level abstractions and APIs Transfer learning : customize pretrained model for feature extraction or fine-tuning autograd : build custom layer/loss using auto differentiation operations nnframes : native deep learning support in Spark DataFrames and ML Pipelines Model serving : productionize model serving and inference using POJO APIs Built-in deep learning models Object detection API : high-level API and pretrained models (e.g., SSD and Faster-RCNN) for object detection Image classification API : high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for image classification Text classification API : high-level API and pre-defined models (using CNN, LSTM, etc.) for text classification Recommendation API : high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendation Anomaly detection API : high-level API and pre-defined models based on LSTM for anomaly detection Text matching API : high-level API and pre-defined KNRM model for text matching Sequence to sequence API : high-level API and pre-defined models for sequence to sequence Reference use cases : a collection of end-to-end reference use cases (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.) Docker images and builders Analytics-Zoo in Docker How to build it How to use the image Notice","title":"Overview"},{"location":"#distributed-tensorflow-and-keras-on-sparkbigdl","text":"To make it easy to build and productionize the deep learning applications for Big Data, Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline (as illustrated below), which can then transparently run on a large-scale Hadoop/Spark clusters for distributed training and inference. (Please see more details here ). 1.Data wrangling and analysis using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset sc = init_nncontext() #Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) #TFDataset represents a distributed set of elements, #in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, names=[ features , labels ], shapes=[[28, 28, 1], [1]], types=[tf.float32, tf.int32], batch_size=BATCH_SIZE) 2.Deep learning model development using TensorFlow import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors labels = tf.squeeze(labels) with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=True) loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)) 3.Distributed training on Spark and BigDL from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) 4.Alternatively, using Keras APIs for model development and distributed training from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * model = Sequential() model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation= tanh , name= fc1 )) model.add(Dense(class_num, activation= softmax , name= fc2 )) model.compile(loss='sparse_categorical_crossentropy', optimizer='adam') model.fit(train_rdd, batch_size=BATCH_SIZE, nb_epoch=5)","title":"Distributed TensorFlow and Keras on Spark/BigDL"},{"location":"#high-level-abstractions-and-apis","text":"Analytics Zoo provides a set of easy-to-use, high level abstractions and APIs that natively transfer learning, autograd and custom layer/loss, Spark DataFrames and ML Pipelines, online model serving, etc. etc.","title":"High level abstractions and APIs"},{"location":"#transfer-learning","text":"Using the high level transfer learning APIs, you can easily customize pretrained models for feature extraction or fine-tuning . (See more details here ) 1.Load an existing model (pretrained in Caffe) from zoo.pipeline.api.net import * full_model = Net.load_caffe(def_path, model_path) 2.Remove the last few layers # create a new model by removing layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) 3.Freeze the first few layers # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) 4.Add a few new layers from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * inputs = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputs) flatten = Flatten()(inception) logits = Dense(2)(flatten) newModel = Model(inputs, logits)","title":"Transfer learning"},{"location":"#autograd","text":"autograd provides automatic differentiation for math operations, so that you can easily build your own custom loss and layer (in both Python and Scala), as illustrated below. (See more details here ) 1.Define model using Keras-style API and autograd import zoo.pipeline.api.autograd as A from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * input = Input(shape=[2, 20]) features = TimeDistributed(layer=Dense(30))(input) f1 = features.index_select(1, 0) f2 = features.index_select(1, 1) diff = A.abs(f1 - f2) model = Model(input, diff) 2.Optionally define custom loss function using autograd def mean_absolute_error(y_true, y_pred): return mean(abs(y_true - y_pred), axis=1) 3.Train model with custom loss function model.compile(optimizer=SGD(), loss=mean_absolute_error) model.fit(x=..., y=...)","title":"autograd"},{"location":"#nnframes","text":"nnframes provides native deep learning support in Spark DataFrames and ML Pipelines , so that you can easily build complex deep learning pipelines in just a few lines, as illustrated below. (See more details here ) 1.Initialize NNContext and load images into DataFrames using NNImageReader from zoo.common.nncontext import * from zoo.pipeline.nnframes import * from zoo.feature.image import * sc = init_nncontext() imageDF = NNImageReader.readImages(image_path, sc) 2.Process loaded data using DataFrames transformations getName = udf(lambda row: ...) getLabel = udf(lambda name: ...) df = imageDF.withColumn( name , getName(col( image ))).withColumn( label , getLabel(col('name'))) 3.Processing image using built-in feature engineering operations transformer = RowToImageFeature() - ImageResize(64, 64) - ImageChannelNormalize(123.0, 117.0, 104.0) \\ - ImageMatToTensor() - ImageFeatureToTensor()) 4.Define model using Keras-style APIs from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\ .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax'))) 5.Train model using Spark ML Pipelines classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\ .setBatchSize(40).setMaxEpoch(1).setFeaturesCol( image ).setCachingSample(False) nnModel = classifier.fit(df)","title":"nnframes"},{"location":"#model-serving","text":"Using the POJO model serving API, you can productionize model serving and inference in any Java based frameworks (e.g., Spring Framework , Apache Storm , Kafka or Flink , etc.), as illustrated below: import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel; import com.intel.analytics.zoo.pipeline.inference.JTensor; public class TextClassificationModel extends AbstractInferenceModel { public TextClassificationModel() { super(); } } TextClassificationModel model = new TextClassificationModel(); model.load(modelPath, weightPath); List JTensor inputs = preprocess(...); List List JTensor result = model.predict(inputs); ...","title":"Model Serving"},{"location":"#built-in-deep-learning-models","text":"Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as object detection , image classification , text classification , recommendation , anomaly detection , text matching , sequence to sequence , etc.","title":"Built-in deep learning models"},{"location":"#object-detection-api","text":"Using Analytics Zoo Object Detection API (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details here ) 1.Download object detection models in Analytics Zoo You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from detection model zoo . 2.Use Object Detection API for off-the-shell inference from zoo.models.image.objectdetection import * model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Object detection API"},{"location":"#image-classification-api","text":"Using Analytics Zoo Image Classification API (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet, etc.), you can easily build your image classification applications, as illustrated below. (See more details here ) 1.Download image classification models in Analytics Zoo You can download a collection of image classification models (pretrained on the ImageNet dataset) from image classification model zoo . 2.Use Image classification API for off-the-shell inference from zoo.models.image.imageclassification import * model = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Image classification API"},{"location":"#text-classification-api","text":"Analytics Zoo Text Classification API provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details here )","title":"Text classification API"},{"location":"#recommendation-api","text":"Analytics Zoo Recommendation API provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details here )","title":"Recommendation API"},{"location":"#anomaly-detection-api","text":"Analytics Zoo Anomaly Detection API provides a set of pre-defined models based on LSTM to detect anomalies for time series data. (See more details here )","title":"Anomaly detection API"},{"location":"#text-matching-api","text":"Analytics Zoo Text Matching API provides pre-defined KNRM model for ranking or classification. (See more details here )","title":"Text matching API"},{"location":"#sequence-to-sequence-api","text":"Analytics Zoo Sequence to Sequence API provides a set of pre-defined models based on Recurrent neural network for sequence to sequence problems. (See more details here )","title":"Sequence to sequence API"},{"location":"#reference-use-cases","text":"Analytics Zoo provides a collection of end-to-end reference use cases, including time series anomaly detection , sentiment analysis , fraud detection , image similarity , etc. (See more details here )","title":"Reference use cases"},{"location":"#docker-images-and-builders","text":"","title":"Docker images and builders"},{"location":"#analytics-zoo-in-docker","text":"By default, the Analytics-Zoo image has installed below packages: - git - maven - Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152) - python 2.7.6 - pip - numpy - scipy - pandas - scikit-learn - matplotlib - seaborn - jupyter - wordcloud - moviepy - requests - tensorflow_ - spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION}) - Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION}) - Analytics-Zoo source code (in /opt/work/analytics-zoo) The work dir for Analytics-Zoo is /opt/work. - download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions. - start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a specified jupyter notebook. - analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution. - analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution. - spark-${SPARK_VERSION} is the Spark home. - analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.","title":"Analytics-Zoo in Docker"},{"location":"#how-to-build-it","text":"By default, you can build a Analytics-Zoo:default image with latest nightly-build Analytics-Zoo distributions: sudo docker build --rm -t intelanalytics/analytics-zoo:default . If you need http and https proxy to build the image: sudo docker build \\ --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\ --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\ --rm -t intelanalytics/analytics-zoo:default . You can also specify the ANALYTICS_ZOO_VERSION and SPARK_VERSION to build a specific Analytics-Zoo image: sudo docker build \\ --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\ --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\ --build-arg ANALYTICS_ZOO_VERSION=0.3.0 \\ --build-arg BIGDL_VERSION=0.6.0 \\ --build-arg SPARK_VERSION=2.3.1 \\ --rm -t intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 .","title":"How to build it"},{"location":"#how-to-use-the-image","text":"To start a notebook directly with a specified port(e.g. 12345). You can view the notebook on http://[host-ip]:12345 sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 If you need http and https proxy in your environment: sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:default sudo docker run -it --rm -p 12345:12345 \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 You can also start the container first sudo docker run -it --rm --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= your-token \\ intelanalytics/analytics-zoo:default bash In the container, after setting proxy and ports, you can start the Notebook by: /opt/work/start-notebook.sh","title":"How to use the image"},{"location":"#notice","text":"If you need nightly build version of Analytics-Zoo, please pull the image form Dockerhub with: sudo docker pull intelanalytics/analytics-zoo:latest Please follow the readme in each app folder to test the jupyter notebooks !!! With 0.3+ version of Anaytics-Zoo Docker image, you can specify the runtime conf of spark sudo docker run -itd --net=host \\ -e NotebookPort=12345 \\ -e NotebookToken= 1234qwer \\ -e http_proxy=http://your-proxy-host:your-proxy-port \\ -e https_proxy=https://your-proxy-host:your-proxy-port \\ -e RUNTIME_DRIVER_CORES=4 \\ -e RUNTIME_DRIVER_MEMORY=20g \\ -e RUNTIME_EXECUTOR_CORES=4 \\ -e RUNTIME_EXECUTOR_MEMORY=20g \\ -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\ intelanalytics/analytics-zoo:latest","title":"Notice"},{"location":"known-issues/","text":"If you encounter the following exception when calling the Python API of Analytics Zoo when you are using Python 3.5 or 3.6: Py4JJavaError: An error occurred while calling z:org.apache.spark.bigdl.api.python.BigDLSerDe.loads. : net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype) you may need to check whether your input argument involves Numpy types (such as numpy.int64 ). See here for the related issue. For example, invoking np.min , np.max , np.unique , etc. will return type numpy.int64 . One way to solve this is to use int() to convert a number of type numpy.int64 to a Python int.","title":"FAQ and Known Issues"},{"location":"powered-by/","text":"Powered By Dell EMC : AI-assisted Radiology Using Distributed Deep Learning on Apache Spark and Analytics Zoo MasterCard : Learning with Analytic Zoo Optimizes Mastercard* Recommender AI Service Talroo : Talroo Uses Analytics Zoo and AWS to Leverage Deep Learning for Job Recommendations Tencent : Enhance Tencent's TUSI Identity Practice with Intel Analytics Zoo Yunda : Intelligent transformation brings \"quality change\" to the express delivery industry Microsoft Azure : Use Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 1 Alibaba : Deploy Analytics Zoo in Aliyun EMR Baosight : LSTM-Based Time Series Anomaly Detection Using Analytics Zoo for Apache Spark* and BigDL at Baosight Midea : Industrial Inspection Platform in Midea and KUKA : Using Distributed TensorFlow* on Analytics Zoo","title":"Powered by"},{"location":"powered-by/#powered-by","text":"Dell EMC : AI-assisted Radiology Using Distributed Deep Learning on Apache Spark and Analytics Zoo MasterCard : Learning with Analytic Zoo Optimizes Mastercard* Recommender AI Service Talroo : Talroo Uses Analytics Zoo and AWS to Leverage Deep Learning for Job Recommendations Tencent : Enhance Tencent's TUSI Identity Practice with Intel Analytics Zoo Yunda : Intelligent transformation brings \"quality change\" to the express delivery industry Microsoft Azure : Use Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 1 Alibaba : Deploy Analytics Zoo in Aliyun EMR Baosight : LSTM-Based Time Series Anomaly Detection Using Analytics Zoo for Apache Spark* and BigDL at Baosight Midea : Industrial Inspection Platform in Midea and KUKA : Using Distributed TensorFlow* on Analytics Zoo","title":"Powered By"},{"location":"presentations/","text":"Talks: LSTM-based time series anomaly detection using Analytics Zoo for Spark and BigDL, Strata Data conference , May 2019, London ( slides ) Game Playing Using AI on Apache Spark, Spark+AI Summit , April 2019, San Francisco ( slides ) Using Deep Learning on Apache Spark to Diagnose Thoracic Pathology from Chest X-rays in DELL EMC, Spark+AI Summit , April 2019, San Francisco ( slides ) Leveraging NLP and Deep Learning for Document Recommendation in the Cloud, Spark+AI Summit , April 2019, San Francisco ( slides ) Analytics Zoo: Distributed Tensorflow, Keras and BigDL in production on Apache Spark, Strata Data conference , March 2019, San Francisco ( slides ) User-based real-time product recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Office Depot, Strata Data conference , March 2019, San Francisco ( slides ) Analytics Zoo: Unifying Big Data Analytics and AI for Apache Spark, Shanghai Apache Spark + AI meetup , Nov 2018, Shanghai ( slides ) Use Intel Analytics Zoo to build an intelligent QA Bot for Microsoft Azure, Shanghai Apache Spark + AI meetup , Nov 2018, Shanghai ( slides ) A deep learning approach for precipitation nowcasting with RNN using Analytics Zoo in Cray, Strata Data conference , Sep 2018, New York ( slides ) Job recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Talroo, Strata Data conference , Sep 2018, New York ( slides ) Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark, Spark + AI Summit , June 2018, San Francisco ( slides ) Using Crowdsourced Images to Create Image Recognition Models with Analytics Zoo in World Bank, Spark + AI Summit , June 2018, San Francisco ( slides ) Building Deep Reinforcement Learning Applications on Apache Spark with Analytics Zoo using BigDL, Spark + AI Summit , June 2018, San Francisco ( slides ) Using BigDL on Apache Spark to Improve the MLS Real Estate Search Experience at Scale, Spark + AI Summit , June 2018, San Francisco Analytics Zoo: Building Analytics and AI Pipeline for Apache Spark and BigDL, Spark + AI Summit , June 2018, San Francisco Using Siamese CNNs for removing duplicate entries from real estate listing databases, Strata Data conference , May 2018, London ( slides ) Classifying images on Spark in World Bank, AI conference , May 2018, New York ( slides ) Improving user-merchant propensity modeling using neural collaborative filtering and wide and deep models on Spark BigDL in Mastercard, Strata Data conference , March 2018, San Jose ( slides ) Accelerating deep learning on Apache Spark using BigDL with coarse-grained scheduling, Strata Data conference , March 2018, San Jose ( slides ) Automatic 3D MRI knee damage classification with 3D CNN using BigDL on Spark in UCSF, Strata Data conference , March 2018, San Jose ( slides )","title":"Presentations"},{"location":"release-docs/","text":"Release 0.4.0 Analytics-Zoo 0.4.0 Docs Release 0.3.0 Analytics-Zoo 0.3.0 Docs Release 0.2.0 Analytics-Zoo 0.2.0 Docs Release 0.1.0 Analytics-Zoo 0.1.0 Docs","title":"Documentation"},{"location":"release-docs/#release-040","text":"Analytics-Zoo 0.4.0 Docs","title":"Release 0.4.0"},{"location":"release-docs/#release-030","text":"Analytics-Zoo 0.3.0 Docs","title":"Release 0.3.0"},{"location":"release-docs/#release-020","text":"Analytics-Zoo 0.2.0 Docs","title":"Release 0.2.0"},{"location":"release-docs/#release-010","text":"Analytics-Zoo 0.1.0 Docs","title":"Release 0.1.0"},{"location":"release-download/","text":"Release 0.5.0 nightly build BigDL 0.7.2 Spark 1.6.2 download Spark 2.1.1 download Spark 2.2.0 download Spark 2.3.1 download Spark 2.4.0 download Release 0.4.0 BigDL 0.7.2 Spark 1.6.2 download Spark 2.1.1 download Spark 2.2.0 download Spark 2.3.1 download Spark 2.4.0 download Release 0.3.0 BigDL 0.6.0 BigDL 0.7.1 Spark 1.6.2 download download Spark 2.1.1 download download Spark 2.2.0 download download Spark 2.3.1 download download Release 0.2.0 BigDL 0.6.0 BigDL 0.5.0 Spark 1.6.2 download download Spark 2.1.1 download download Spark 2.2.0 download download Release 0.1.0 Download Links Spark 1.6.0 download Spark 2.1.0 download Spark 2.2.0 download","title":"Download"},{"location":"release-download/#release-050-nightly-build","text":"BigDL 0.7.2 Spark 1.6.2 download Spark 2.1.1 download Spark 2.2.0 download Spark 2.3.1 download Spark 2.4.0 download","title":"Release 0.5.0 nightly build"},{"location":"release-download/#release-040","text":"BigDL 0.7.2 Spark 1.6.2 download Spark 2.1.1 download Spark 2.2.0 download Spark 2.3.1 download Spark 2.4.0 download","title":"Release 0.4.0"},{"location":"release-download/#release-030","text":"BigDL 0.6.0 BigDL 0.7.1 Spark 1.6.2 download download Spark 2.1.1 download download Spark 2.2.0 download download Spark 2.3.1 download download","title":"Release 0.3.0"},{"location":"release-download/#release-020","text":"BigDL 0.6.0 BigDL 0.5.0 Spark 1.6.2 download download Spark 2.1.1 download download Spark 2.2.0 download download","title":"Release 0.2.0"},{"location":"release-download/#release-010","text":"Download Links Spark 1.6.0 download Spark 2.1.0 download Spark 2.2.0 download","title":"Release 0.1.0"},{"location":"wp-analyticszoo/","text":"","title":"Wp analyticszoo"},{"location":"wp-bigdl/","text":"BigDL: A Distributed Deep Learning Framework for Big Data Jason (Jinquan) Dai 1 , Yiheng Wang 1 , Xin Qiu 1 , Ding Ding 1 , Yao Zhang 2 \u01c2 , Yanzhang Wang 1 , Xianyan Jia 2 \u01c2 , Cherry (Li) Zhang 1 , Yan Wan 3 \u01c2 , Zhichao Li 1 , Jiao Wang 1 , Shengsheng Huang 1 , Zhongyuan Wu 1 , Yang Wang 1 , Yuhao Yang 1 , Bowen She 1 , Dongjie Shi 1 , Qi Lu 1 , Kai Huang 1 , Guoqiong Song 1 1 Intel Corporation, 2 Tencent Inc., 3 Alibaba Group \u01c2 Work was done when the author worked at Intel Abstract In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an AllReduce like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark. 1. Introduction Recent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends: Data scale drives deep learning process. Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure). Real-world deep learning applications are complex big data pipelines, which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10]. Deep learning is increasingly adopted by the big data and data science community. Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications. We have developed BigDL [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion. BigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms. 2. Programming Model BigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1. 1 spark = SparkContext(appName= text_classifier , \u2026) 2 //load input data: (text, label) pairs 3 texts_rdd = spark.textFile( hdfs://... ) 4 //convert text to list of words 5 words_rdd = texts_rdd.map(lambda text, label: 6 ([w for w in to_words(text)], label)) 7 //load GloVe embedding 8 w2v = news20.get_glove_w2v(dim=\u2026) 9 //convert word list to list of vertors using GloVe embeddings 10 vector_rdd = words_rdd.map(lambda word_list, label: 11 ([to_vec(w, w2v) for w in word_list], label)) 12 //convert (list of vertors, label) pair to Sample 13 sample_rdd = vector_rdd.map(lambda vector_list, label: 14 to_sample(vector_list, label)) 15 //construct neural network model 16 model = Sequential().add(Recurrent().add(LSTM(\u2026))) 17 .add(Linear(\u2026)) 18 .add(LogSoftMax()) 19 //train the model 20 loss = ClassNLLCriterion() 21 optim_method = Adagrad() 22 optimizer = Optimizer(model=model, training_rdd=sample_rdd, 23 criterion=loss, optim_method= optim_method, \u2026) 24 optimizer.set_train_summary(summary = TrainSummary(\u2026)) 25 trained_model =optimizer.optimize() 26 //model prediction 27 test_rdd = \u2026 28 prediction_rdd = trained_model.predict(test_rdd) Figure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL. 2.1. Spark Spark provides the Resilient Distributed Dataset (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like map, filter and reduce. Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words. 2.2. Data transformation Spark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector. N-dimensional array: In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by numpy.ndarry [22] and BigDL.Tensor (similar to Torch.Tensor [23]) for BigDL Python and Scala/Java APIs respectively. Sample: Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more N-dimensional arrays. For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of Samples, which will later be used by BigDL model training. 2.3. Model Construction Similar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as ReLu, Spatial Convolution and LSTM ). BigDL then uses the semantics of the layers for model evaluation ( forward ) and gradient computation ( backward ). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example. 2.4. Model training The transformed input data (RDD of Samples) and the constructed model can then be passed over to the Optimizer in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in Figure 1. Optimizer: In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as SGD, AdaGrad [24], Adam [25], etc. ). Visualization: To make it easy for users to understand the behaviors of model training, the optimizer in BigDL can be configured to produce a TrainSummary that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27]. 2.5. Model Inference BigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1. ModelBroadcast: BigDL provides the ModelBroadcast abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation ( predict ) in BigDL uses ModelBroadcast to cache a single copy of the model on each machine (by leveraging the broadcast [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine. 2.6. Spark DataFrame and ML Pipeline Besides RDD, Spark provides a high level DataFrame abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like filter and join for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML (machine learning) pipeline [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its DLModel and DLEstimator abstractions). 3. Execution Model Similar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2. The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items). Figure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks. On the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference). 3.1. Data-parallel training To train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model. for (i - 1 to N) { // model forward-backward job for each task in the Spark job: read the latest weights get a random batch of data from local Sample partition compute errors (forward on local model replica) compute gradients (backward on local model replica) // parameter synchronization job aggregate (sum) all the gradients update the weights per specified optimization method } Figure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d. As described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional zip operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4. Figure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel. 3.2. Parameter synchronization Parameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the parameter server [33][34][35] architecture or AllReduce [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems. In BigDL, we have adapted the primitives available in Spark (e.g., shuffle, broadcast, in-memory cache , etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5). Figure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition. A Spark job has N tasks, each of which is assigned a unique Id ranging from 1 to N in BigDL. After each task in the \u201c model forward-backward \u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into N partitions, as shown in Figure 5. Next, another \u201c parameter synchronization \u201d job is launched; each task n in the \u201c parameter synchronization \u201d job is responsible for managing the n th partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n th partition of the gradients (from all the tasks of the previous \u201c model forward-backward \u201d job) are first shuffled to task n , which then aggregates (sums) these gradients, and applies the updates to the n th partition of the weights (using the specific optimization method ), as illustrated in Figure 5. Figure 6. The \u201cparameter synchronization\u201d Spark job, manages the n th partition of the parameters (similar to a parameter server). After that, each task n in the \u201c parameter synchronization \u201d job broadcasts the n th partition of the updated weights; consequently, tasks in the \u201c model forward-backward \u201d job of the next iteration can read the latest value of all the weights before the next training step begins. The shuffle and task-side broadcast operations described above are implemented on top of the distributed in-memory storage in Spark: both the shuffled gradients and broadcasted weights are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency. By implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7. Figure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes). 3.3. Task scheduling While BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization. In contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above). To scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by Drizzle [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8. Figure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39]. 3.4. Model quantization Quantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference. BigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time. Math.round(1.0 * value / Math.max(Math.abs(max), Math.abs(min)) * Byte.MaxValue).toByte Figure 9. Equation for quantizing 32-bit floating point to 8-bit integer. Unlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10. Figure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40]. 3.5. Local execution In addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based. 4. Applications Since its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL. 4.1. Model Inference: image feature extraction JD.com [41] is one of the largest online retailers in the world. It has built an end-to-end object detection and image feature extraction pipeline on top of Spark and BigDL[42], as illustrated in Figure 11. Figure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42]. The pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including resizing , normalization , and batching ) in a distributed fashion using Spark. After that, it uses BigDL to load a SSD [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures. It then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including resizing and batching ). Finally it uses BigDL to load a DeepBit [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS). The entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12. Figure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores). 4.2. Distributed training: precipitation nowcasting Cray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting ( predicting short-term precipitation ) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13). Figure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL. The application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of NumPy ndarrays . It then trains a sequence-to-sequence model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output. After the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14. Figure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37] 4.3. Transfer learning: image-similarity based house recommendations MLSListings Inc. is a large Multiple Listing Service (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15. Figure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47] To compute the semantic similarity for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo. To compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage. At model serving time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the \u201cSimilar Houses\u201d section of the webpage in Figure 16. Figure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47] 5.Related Work Existing big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model. Existing deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark. Recently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark). 6. Summary We have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training. BigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters. 7. Acknowledgement We gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project. 8. Reference [1] Caffe. http://caffe.berkeleyvision.org [2] Torch. http://torch.ch [3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016. [4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015. [5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015. [6] Apache Hadoop. http://hadoop.apache.org [7] Apache Spark. https://spark.apache.org [8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012. [9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV] [10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV] [11] BigDL. https://github.com/intel-analytics/BigDL/ [12] Keras. https://keras.io [13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015. [14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013. [15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016. [16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014. [17] Apache Storm. http://storm.apache.org [18] Apache Flink. https://flink.apache.org [19] Apache Kafka. https://kafka.apache.org [20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010. [21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014. [22] Numpy. http://www.numpy.org [23] Torch7. https://github.com/torch/torch7 [24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011. [25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015. [26] M. Abadi, et al. \u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems. , 2016. [27] Project Jupyter. http://jupyter.org [28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013. [29] SciKit-Learn. http://scikit-learn.org/stable/ [30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014. [31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016. [32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016. [33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012. [34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014. [35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014. [36] Andrew Gibiansky. Bringing HPC Techniques to Deep Learning [37] Alex Heye, et al. Scalable Deep Learning with BigDL on the Urika-XC Software Suite [38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017. [39] Shivaram Venkataraman, et al. Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark [40] Jason (Jinquan) Dai, et al. Leveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL [41] JD. https://en.wikipedia.org/wiki/JD.com [42] Jason (Jinquan) Dai, et al. Building Large-Scale Image Feature Extraction with BigDL at JD.com [43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016. [44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016. [45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014. [46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015. [47] Jason (Jinquan) Dai, et al. \u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d [48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015. [49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017. [50] Karen Simonyan, at al. \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d , 2014. [51] Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017. [52] DJ4J. https://deeplearning4j.org/ [53] TensorFrames. https://github.com/databricks/tensorframes [54] Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning [55] CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark [56] TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark [57] Philipp Moritz, et al. \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.","title":"BigDL"},{"location":"wp-bigdl/#bigdl-a-distributed-deep-learning-framework-for-big-data","text":"Jason (Jinquan) Dai 1 , Yiheng Wang 1 , Xin Qiu 1 , Ding Ding 1 , Yao Zhang 2 \u01c2 , Yanzhang Wang 1 , Xianyan Jia 2 \u01c2 , Cherry (Li) Zhang 1 , Yan Wan 3 \u01c2 , Zhichao Li 1 , Jiao Wang 1 , Shengsheng Huang 1 , Zhongyuan Wu 1 , Yang Wang 1 , Yuhao Yang 1 , Bowen She 1 , Dongjie Shi 1 , Qi Lu 1 , Kai Huang 1 , Guoqiong Song 1 1 Intel Corporation, 2 Tencent Inc., 3 Alibaba Group \u01c2 Work was done when the author worked at Intel","title":"BigDL: A Distributed Deep Learning Framework for Big Data"},{"location":"wp-bigdl/#abstract","text":"In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an AllReduce like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.","title":"Abstract"},{"location":"wp-bigdl/#1-introduction","text":"Recent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends: Data scale drives deep learning process. Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure). Real-world deep learning applications are complex big data pipelines, which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10]. Deep learning is increasingly adopted by the big data and data science community. Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications. We have developed BigDL [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion. BigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms.","title":"1. Introduction"},{"location":"wp-bigdl/#2-programming-model","text":"BigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1. 1 spark = SparkContext(appName= text_classifier , \u2026) 2 //load input data: (text, label) pairs 3 texts_rdd = spark.textFile( hdfs://... ) 4 //convert text to list of words 5 words_rdd = texts_rdd.map(lambda text, label: 6 ([w for w in to_words(text)], label)) 7 //load GloVe embedding 8 w2v = news20.get_glove_w2v(dim=\u2026) 9 //convert word list to list of vertors using GloVe embeddings 10 vector_rdd = words_rdd.map(lambda word_list, label: 11 ([to_vec(w, w2v) for w in word_list], label)) 12 //convert (list of vertors, label) pair to Sample 13 sample_rdd = vector_rdd.map(lambda vector_list, label: 14 to_sample(vector_list, label)) 15 //construct neural network model 16 model = Sequential().add(Recurrent().add(LSTM(\u2026))) 17 .add(Linear(\u2026)) 18 .add(LogSoftMax()) 19 //train the model 20 loss = ClassNLLCriterion() 21 optim_method = Adagrad() 22 optimizer = Optimizer(model=model, training_rdd=sample_rdd, 23 criterion=loss, optim_method= optim_method, \u2026) 24 optimizer.set_train_summary(summary = TrainSummary(\u2026)) 25 trained_model =optimizer.optimize() 26 //model prediction 27 test_rdd = \u2026 28 prediction_rdd = trained_model.predict(test_rdd) Figure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.","title":"2. Programming Model"},{"location":"wp-bigdl/#21-spark","text":"Spark provides the Resilient Distributed Dataset (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like map, filter and reduce. Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.","title":"2.1. Spark"},{"location":"wp-bigdl/#22-data-transformation","text":"Spark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector. N-dimensional array: In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by numpy.ndarry [22] and BigDL.Tensor (similar to Torch.Tensor [23]) for BigDL Python and Scala/Java APIs respectively. Sample: Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more N-dimensional arrays. For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of Samples, which will later be used by BigDL model training.","title":"2.2. Data transformation"},{"location":"wp-bigdl/#23-model-construction","text":"Similar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as ReLu, Spatial Convolution and LSTM ). BigDL then uses the semantics of the layers for model evaluation ( forward ) and gradient computation ( backward ). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.","title":"2.3. Model Construction"},{"location":"wp-bigdl/#24-model-training","text":"The transformed input data (RDD of Samples) and the constructed model can then be passed over to the Optimizer in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in Figure 1. Optimizer: In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as SGD, AdaGrad [24], Adam [25], etc. ). Visualization: To make it easy for users to understand the behaviors of model training, the optimizer in BigDL can be configured to produce a TrainSummary that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27].","title":"2.4. Model training"},{"location":"wp-bigdl/#25-model-inference","text":"BigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1. ModelBroadcast: BigDL provides the ModelBroadcast abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation ( predict ) in BigDL uses ModelBroadcast to cache a single copy of the model on each machine (by leveraging the broadcast [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.","title":"2.5. Model Inference"},{"location":"wp-bigdl/#26-spark-dataframe-and-ml-pipeline","text":"Besides RDD, Spark provides a high level DataFrame abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like filter and join for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML (machine learning) pipeline [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its DLModel and DLEstimator abstractions).","title":"2.6. Spark DataFrame and ML Pipeline"},{"location":"wp-bigdl/#3-execution-model","text":"Similar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2. The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items). Figure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks. On the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).","title":"3. Execution Model"},{"location":"wp-bigdl/#31-data-parallel-training","text":"To train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model. for (i - 1 to N) { // model forward-backward job for each task in the Spark job: read the latest weights get a random batch of data from local Sample partition compute errors (forward on local model replica) compute gradients (backward on local model replica) // parameter synchronization job aggregate (sum) all the gradients update the weights per specified optimization method } Figure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d. As described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional zip operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4. Figure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.","title":"3.1. Data-parallel training"},{"location":"wp-bigdl/#32-parameter-synchronization","text":"Parameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the parameter server [33][34][35] architecture or AllReduce [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems. In BigDL, we have adapted the primitives available in Spark (e.g., shuffle, broadcast, in-memory cache , etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5). Figure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition. A Spark job has N tasks, each of which is assigned a unique Id ranging from 1 to N in BigDL. After each task in the \u201c model forward-backward \u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into N partitions, as shown in Figure 5. Next, another \u201c parameter synchronization \u201d job is launched; each task n in the \u201c parameter synchronization \u201d job is responsible for managing the n th partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n th partition of the gradients (from all the tasks of the previous \u201c model forward-backward \u201d job) are first shuffled to task n , which then aggregates (sums) these gradients, and applies the updates to the n th partition of the weights (using the specific optimization method ), as illustrated in Figure 5. Figure 6. The \u201cparameter synchronization\u201d Spark job, manages the n th partition of the parameters (similar to a parameter server). After that, each task n in the \u201c parameter synchronization \u201d job broadcasts the n th partition of the updated weights; consequently, tasks in the \u201c model forward-backward \u201d job of the next iteration can read the latest value of all the weights before the next training step begins. The shuffle and task-side broadcast operations described above are implemented on top of the distributed in-memory storage in Spark: both the shuffled gradients and broadcasted weights are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency. By implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7. Figure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).","title":"3.2. Parameter synchronization"},{"location":"wp-bigdl/#33-task-scheduling","text":"While BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization. In contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above). To scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by Drizzle [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8. Figure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39].","title":"3.3. Task scheduling"},{"location":"wp-bigdl/#34-model-quantization","text":"Quantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference. BigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time. Math.round(1.0 * value / Math.max(Math.abs(max), Math.abs(min)) * Byte.MaxValue).toByte Figure 9. Equation for quantizing 32-bit floating point to 8-bit integer. Unlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10. Figure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40].","title":"3.4. Model quantization"},{"location":"wp-bigdl/#35-local-execution","text":"In addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.","title":"3.5. Local execution"},{"location":"wp-bigdl/#4-applications","text":"Since its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL.","title":"4. Applications"},{"location":"wp-bigdl/#41-model-inference-image-feature-extraction","text":"JD.com [41] is one of the largest online retailers in the world. It has built an end-to-end object detection and image feature extraction pipeline on top of Spark and BigDL[42], as illustrated in Figure 11. Figure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42]. The pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including resizing , normalization , and batching ) in a distributed fashion using Spark. After that, it uses BigDL to load a SSD [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures. It then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including resizing and batching ). Finally it uses BigDL to load a DeepBit [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS). The entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12. Figure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).","title":"4.1. Model Inference: image feature extraction"},{"location":"wp-bigdl/#42-distributed-training-precipitation-nowcasting","text":"Cray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting ( predicting short-term precipitation ) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13). Figure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL. The application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of NumPy ndarrays . It then trains a sequence-to-sequence model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output. After the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14. Figure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37]","title":"4.2. Distributed training: precipitation nowcasting"},{"location":"wp-bigdl/#43-transfer-learning-image-similarity-based-house-recommendations","text":"MLSListings Inc. is a large Multiple Listing Service (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15. Figure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47] To compute the semantic similarity for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo. To compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage. At model serving time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the \u201cSimilar Houses\u201d section of the webpage in Figure 16. Figure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47]","title":"4.3. Transfer learning: image-similarity based house recommendations"},{"location":"wp-bigdl/#5related-work","text":"Existing big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model. Existing deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark. Recently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark).","title":"5.Related Work"},{"location":"wp-bigdl/#6-summary","text":"We have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training. BigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.","title":"6. Summary"},{"location":"wp-bigdl/#7-acknowledgement","text":"We gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project.","title":"7. Acknowledgement"},{"location":"wp-bigdl/#8-reference","text":"[1] Caffe. http://caffe.berkeleyvision.org [2] Torch. http://torch.ch [3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016. [4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015. [5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015. [6] Apache Hadoop. http://hadoop.apache.org [7] Apache Spark. https://spark.apache.org [8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012. [9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV] [10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV] [11] BigDL. https://github.com/intel-analytics/BigDL/ [12] Keras. https://keras.io [13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015. [14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013. [15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016. [16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014. [17] Apache Storm. http://storm.apache.org [18] Apache Flink. https://flink.apache.org [19] Apache Kafka. https://kafka.apache.org [20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010. [21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014. [22] Numpy. http://www.numpy.org [23] Torch7. https://github.com/torch/torch7 [24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011. [25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015. [26] M. Abadi, et al. \u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems. , 2016. [27] Project Jupyter. http://jupyter.org [28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013. [29] SciKit-Learn. http://scikit-learn.org/stable/ [30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014. [31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016. [32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016. [33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012. [34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014. [35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014. [36] Andrew Gibiansky. Bringing HPC Techniques to Deep Learning [37] Alex Heye, et al. Scalable Deep Learning with BigDL on the Urika-XC Software Suite [38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017. [39] Shivaram Venkataraman, et al. Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark [40] Jason (Jinquan) Dai, et al. Leveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL [41] JD. https://en.wikipedia.org/wiki/JD.com [42] Jason (Jinquan) Dai, et al. Building Large-Scale Image Feature Extraction with BigDL at JD.com [43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016. [44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016. [45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014. [46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015. [47] Jason (Jinquan) Dai, et al. \u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d [48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015. [49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017. [50] Karen Simonyan, at al. \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d , 2014. [51] Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017. [52] DJ4J. https://deeplearning4j.org/ [53] TensorFrames. https://github.com/databricks/tensorframes [54] Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning [55] CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark [56] TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark [57] Philipp Moritz, et al. \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.","title":"8. Reference"},{"location":"APIGuide/FeatureEngineering/featureset/","text":"A FeatureSet can be used to represent an input pipeline as a collection of elements which is used in the model optimization process. You can use FeatureSet to switch the memory type between DRAM and PMEM in consideration of the hardware optimization. DRAM is the default mode which would cached the training data in main memory. PMEM mode would try to cache the training data in AEP rather than main memory. You should install the AEP hardware and memkind library before switching to this option. The FeatureSet can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the data() method to get the data sequence. You can use FeatureSet.rdd() function to create a FeatureSet. Scala example: import com.intel.analytics.zoo.feature.FeatureSet val featureSet = FeatureSet.rdd(rawRDD, memoryType = DRAM) // featureSet - feature transformer - batch and sample transformer model.fit(featureSet) Take a look at InceptionV1 example for more details.","title":"FeatureSet"},{"location":"APIGuide/FeatureEngineering/image/","text":"Analytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats. Load Image Analytics Zoo provides APIs to read image to different formats: Load to Data Frame Scala: package com.intel.analytics.zoo.pipeline.nnframes object NNImageReader { def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame } Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images. path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path). sc: SparkContext to be used. minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead resizeH: height after resize, by default is -1 which will not resize the image resizeW: width after resize, by default is -1 which will not resize the image Python: class zoo.pipeline.nnframes.NNImageReader static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type= float ) ImageSet ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read image data as ImageSet from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala APIs: object com.intel.analytics.zoo.feature.image.ImageSet def array(data: Array[ImageFeature]): LocalImageSet Create LocalImageSet from array of ImeageFeature data: array of ImageFeature def rdd(data: RDD[ImageFeature]): DistributedImageSet Create DistributedImageSet from rdd of ImageFeature data: array of ImageFeature def read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet Read images as Image Set. If sc is defined, read image as DistributedImageSet from local file system or HDFS. If sc is null, Read image as LocalImageSet from local file system path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character sc: SparkContext minPartitions: A suggestion value of the minimal splitting number for input data. resizeH: height after resize, by default is -1 which will not resize the image resizeW: width after resize, by default is -1 which will not resize the image Example: // create LocalImageSet from an image folder val localImageSet = ImageSet.read( /tmp/image/ ) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) Python APIs: class zoo.feature.image.ImageSet read(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type= float ) Read images as Image Set. If sc is defined, read image as DistributedImageSet from local file system or HDFS. If sc is null, Read image as LocalImageSet from local file system path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character sc: SparkContext min_partitions: A suggestion value of the minimal splitting number for input data. resize_height height after resize, by default is -1 which will not resize the image resize_width width after resize, by default is -1 which will not resize the image Python example: # create LocalImageSet from an image folder local_image_set2 = ImageSet.read( /tmp/image/ ) # create DistributedImageSet from an image folder distributed_image_set = ImageSet.read( /tmp/image/ , sc, 2) Image Transformer Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call transform with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. Scala APIs: package com.intel.analytics.zoo.feature.image object ImageBrightness def apply(deltaLow: Double, deltaHigh: Double): ImageBrightness Adjust the image brightness. deltaLow: low bound of brightness parameter deltaHigh: high bound of brightness parameter Example: val transformer = ImageBrightness(0.0, 32.0) val transformed = imageSet.transform(transformer) Python APIs: class zoo.feature.image.imagePreprocessing.ImageBrightness def __init__(delta_low, delta_high, bigdl_type= float ) Adjust the image brightness. delta_low: low bound of brightness parameter delta_high: high bound of brightness parameter Example: transformer = ImageBrightness(0.0, 32.0) transformed = imageSet.transform(transformer) Scala APIs: package com.intel.analytics.zoo.feature.image object ImageBytesToMat def apply(byteKey: String = ImageFeature.bytes, imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat Transform byte array(original image file in byte) to OpenCVMat byteKey: key that maps byte array. Default value is ImageFeature.bytes imageCodec: specifying the color type of a loaded image, same as in OpenCV.imread. 1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit. 2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one 3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one 4. 0 Return a 3-channel color image. Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel. 5. =0 Return a grayscale image. 6. 0 Return the loaded image as is (with alpha channel). Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED. Example: val imageSet = ImageSet.read(path, sc) imageSet - ImageBytesToMat() 3D Image Support Create ImageSet for 3D Images For 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python). Scala example: val image = ImageFeature3D(tensor) // create local imageset for 3D images val arr = Array[ImageFeature](image) val localImageSet = ImageSet.array(arr) // create distributed imageset for 3D images val rdd = sc.parallelize(Seq[ImageFeature](image)) val imageSet = ImageSet.rdd(rdd) Python example: # get image numpy array img_np = # create local imageset for 3D images local_imageset = LocalImageSet(image_list=[img_np]) # create distributed imageset for 3D images rdd = sc.parallelize([img_np]) dist_imageSet = DistributedImageSet(image_rdd=rdd) 3D Image Transformers Analytics zoo also provides several image transformers for 3D Images. The usage is similar as 2D image transformers. After create these transformers, call transform with ImageSet to get transformed ImageSet. Currently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation. Crop transformers Crop3D Scala: import com.intel.analytics.zoo.feature.image3d.Crop3D // create Crop3D transformer val cropper = Crop3D(start, patchSize) val outputImageSet = imageset.transform(cropper) Crop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size. * start: start point array(depth, height, width) for cropping * patchSize: patch size array(depth, height, width) Python: from zoo.feature.image3d.transformation import Crop3D crop = Crop3D(start, patch_size) transformed_image = crop(image_set) start: start point list[]depth, height, width] for cropping patch_size: patch size list[]depth, height, width] RandomCrop3D Scala: import com.intel.analytics.zoo.feature.image3d.RandomCrop3D // create Crop3D transformer val cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth) val outputImageSet = imageset.transform(cropper) Crop a random patch from an 3D image with specified patch size. The patch size should be less than the image size. cropDepth: depth after crop cropHeight: height after crop * cropWidth: width after crop Python: from zoo.feature.image3d.transformation import RandomCrop3D crop = RandomCrop3D(crop_depth, crop_height, crop_width) transformed_image = crop(image_set) crop_depth: depth after crop crop_height: height after crop crop_width: width after crop CenterCrop3D Scala: import com.intel.analytics.zoo.feature.image3d.CenterCrop3D // create Crop3D transformer val cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth) val outputImageSet = imageset.transform(cropper) Crop a cropDepth x cropWidth x cropHeight patch from center of image. The patch size should be less than the image size. cropDepth: depth after crop cropHeight: height after crop * cropWidth: width after crop Python: from zoo.feature.image3d.transformation import CenterCrop3D crop = CenterCrop3D(crop_depth, crop_height, crop_width) transformed_image = crop(image_set) crop_depth: depth after crop crop_height: height after crop crop_width: width after crop Rotation Scala: import com.intel.analytics.zoo.feature.image3d.Rotate3D // create Crop3D transformer val rotAngles = Array[Double](yaw, pitch, roll) val rot = Rotate3D(rotAngles) val outputImageSet = imageset.transform(rot) Rotate a 3D image with specified angles. * rotationAngles: the angles for rotation. Which are the yaw(a counterclockwise rotation angle about the z-axis), pitch(a counterclockwise rotation angle about the y-axis), and roll(a counterclockwise rotation angle about the x-axis). Python: from zoo.feature.image3d.transformation import Rotate3D rot = Rotate3D(rotation_angles) transformed_image = rot(image_set) Affine Transformation Scala: import com.intel.analytics.zoo.feature.image3d.AffineTransform3D import com.intel.analytics.bigdl.tensor.Tensor // create Crop3D transformer val matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4) val matTensor = Tensor[Double](matArray, Array[Int](3, 3)) val trans = Tensor[Double](3) trans(1) = 0 trans(2) = 1.8 trans(3) = 1.1 val aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode = clamp , padVal = 0) val outputImageSet = imageset.transform(aff) Affine transformer implements affine transformation on a given tensor. To avoid defects in resampling, the mapping is from destination to source. dst(z,y,x) = src(f(z),f(y),f(x)) where f: dst - src mat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src. translation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis. clampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image. padVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error. Python: from zoo.feature.image3d.transformation import AffineTransform3D affine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val) transformed_image = affine(image_set) affine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src. translation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis. clamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image. pad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.","title":"Image"},{"location":"APIGuide/FeatureEngineering/image/#load-image","text":"Analytics Zoo provides APIs to read image to different formats:","title":"Load Image"},{"location":"APIGuide/FeatureEngineering/image/#load-to-data-frame","text":"Scala: package com.intel.analytics.zoo.pipeline.nnframes object NNImageReader { def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame } Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images. path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path). sc: SparkContext to be used. minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead resizeH: height after resize, by default is -1 which will not resize the image resizeW: width after resize, by default is -1 which will not resize the image Python: class zoo.pipeline.nnframes.NNImageReader static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type= float )","title":"Load to Data Frame"},{"location":"APIGuide/FeatureEngineering/image/#imageset","text":"ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read image data as ImageSet from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala APIs: object com.intel.analytics.zoo.feature.image.ImageSet def array(data: Array[ImageFeature]): LocalImageSet Create LocalImageSet from array of ImeageFeature data: array of ImageFeature def rdd(data: RDD[ImageFeature]): DistributedImageSet Create DistributedImageSet from rdd of ImageFeature data: array of ImageFeature def read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet Read images as Image Set. If sc is defined, read image as DistributedImageSet from local file system or HDFS. If sc is null, Read image as LocalImageSet from local file system path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character sc: SparkContext minPartitions: A suggestion value of the minimal splitting number for input data. resizeH: height after resize, by default is -1 which will not resize the image resizeW: width after resize, by default is -1 which will not resize the image Example: // create LocalImageSet from an image folder val localImageSet = ImageSet.read( /tmp/image/ ) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) Python APIs: class zoo.feature.image.ImageSet read(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type= float ) Read images as Image Set. If sc is defined, read image as DistributedImageSet from local file system or HDFS. If sc is null, Read image as LocalImageSet from local file system path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character sc: SparkContext min_partitions: A suggestion value of the minimal splitting number for input data. resize_height height after resize, by default is -1 which will not resize the image resize_width width after resize, by default is -1 which will not resize the image Python example: # create LocalImageSet from an image folder local_image_set2 = ImageSet.read( /tmp/image/ ) # create DistributedImageSet from an image folder distributed_image_set = ImageSet.read( /tmp/image/ , sc, 2)","title":"ImageSet"},{"location":"APIGuide/FeatureEngineering/image/#image-transformer","text":"Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call transform with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. Scala APIs: package com.intel.analytics.zoo.feature.image object ImageBrightness def apply(deltaLow: Double, deltaHigh: Double): ImageBrightness Adjust the image brightness. deltaLow: low bound of brightness parameter deltaHigh: high bound of brightness parameter Example: val transformer = ImageBrightness(0.0, 32.0) val transformed = imageSet.transform(transformer) Python APIs: class zoo.feature.image.imagePreprocessing.ImageBrightness def __init__(delta_low, delta_high, bigdl_type= float ) Adjust the image brightness. delta_low: low bound of brightness parameter delta_high: high bound of brightness parameter Example: transformer = ImageBrightness(0.0, 32.0) transformed = imageSet.transform(transformer) Scala APIs: package com.intel.analytics.zoo.feature.image object ImageBytesToMat def apply(byteKey: String = ImageFeature.bytes, imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat Transform byte array(original image file in byte) to OpenCVMat byteKey: key that maps byte array. Default value is ImageFeature.bytes imageCodec: specifying the color type of a loaded image, same as in OpenCV.imread. 1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit. 2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one 3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one 4. 0 Return a 3-channel color image. Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel. 5. =0 Return a grayscale image. 6. 0 Return the loaded image as is (with alpha channel). Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED. Example: val imageSet = ImageSet.read(path, sc) imageSet - ImageBytesToMat()","title":"Image Transformer"},{"location":"APIGuide/FeatureEngineering/image/#3d-image-support","text":"","title":"3D Image Support"},{"location":"APIGuide/FeatureEngineering/image/#create-imageset-for-3d-images","text":"For 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python). Scala example: val image = ImageFeature3D(tensor) // create local imageset for 3D images val arr = Array[ImageFeature](image) val localImageSet = ImageSet.array(arr) // create distributed imageset for 3D images val rdd = sc.parallelize(Seq[ImageFeature](image)) val imageSet = ImageSet.rdd(rdd) Python example: # get image numpy array img_np = # create local imageset for 3D images local_imageset = LocalImageSet(image_list=[img_np]) # create distributed imageset for 3D images rdd = sc.parallelize([img_np]) dist_imageSet = DistributedImageSet(image_rdd=rdd)","title":"Create ImageSet for 3D Images"},{"location":"APIGuide/FeatureEngineering/image/#3d-image-transformers","text":"Analytics zoo also provides several image transformers for 3D Images. The usage is similar as 2D image transformers. After create these transformers, call transform with ImageSet to get transformed ImageSet. Currently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation.","title":"3D Image Transformers"},{"location":"APIGuide/FeatureEngineering/image/#crop-transformers","text":"","title":"Crop transformers"},{"location":"APIGuide/FeatureEngineering/image/#crop3d","text":"Scala: import com.intel.analytics.zoo.feature.image3d.Crop3D // create Crop3D transformer val cropper = Crop3D(start, patchSize) val outputImageSet = imageset.transform(cropper) Crop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size. * start: start point array(depth, height, width) for cropping * patchSize: patch size array(depth, height, width) Python: from zoo.feature.image3d.transformation import Crop3D crop = Crop3D(start, patch_size) transformed_image = crop(image_set) start: start point list[]depth, height, width] for cropping patch_size: patch size list[]depth, height, width]","title":"Crop3D"},{"location":"APIGuide/FeatureEngineering/image/#randomcrop3d","text":"Scala: import com.intel.analytics.zoo.feature.image3d.RandomCrop3D // create Crop3D transformer val cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth) val outputImageSet = imageset.transform(cropper) Crop a random patch from an 3D image with specified patch size. The patch size should be less than the image size. cropDepth: depth after crop cropHeight: height after crop * cropWidth: width after crop Python: from zoo.feature.image3d.transformation import RandomCrop3D crop = RandomCrop3D(crop_depth, crop_height, crop_width) transformed_image = crop(image_set) crop_depth: depth after crop crop_height: height after crop crop_width: width after crop","title":"RandomCrop3D"},{"location":"APIGuide/FeatureEngineering/image/#centercrop3d","text":"Scala: import com.intel.analytics.zoo.feature.image3d.CenterCrop3D // create Crop3D transformer val cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth) val outputImageSet = imageset.transform(cropper) Crop a cropDepth x cropWidth x cropHeight patch from center of image. The patch size should be less than the image size. cropDepth: depth after crop cropHeight: height after crop * cropWidth: width after crop Python: from zoo.feature.image3d.transformation import CenterCrop3D crop = CenterCrop3D(crop_depth, crop_height, crop_width) transformed_image = crop(image_set) crop_depth: depth after crop crop_height: height after crop crop_width: width after crop","title":"CenterCrop3D"},{"location":"APIGuide/FeatureEngineering/image/#rotation","text":"Scala: import com.intel.analytics.zoo.feature.image3d.Rotate3D // create Crop3D transformer val rotAngles = Array[Double](yaw, pitch, roll) val rot = Rotate3D(rotAngles) val outputImageSet = imageset.transform(rot) Rotate a 3D image with specified angles. * rotationAngles: the angles for rotation. Which are the yaw(a counterclockwise rotation angle about the z-axis), pitch(a counterclockwise rotation angle about the y-axis), and roll(a counterclockwise rotation angle about the x-axis). Python: from zoo.feature.image3d.transformation import Rotate3D rot = Rotate3D(rotation_angles) transformed_image = rot(image_set)","title":"Rotation"},{"location":"APIGuide/FeatureEngineering/image/#affine-transformation","text":"Scala: import com.intel.analytics.zoo.feature.image3d.AffineTransform3D import com.intel.analytics.bigdl.tensor.Tensor // create Crop3D transformer val matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4) val matTensor = Tensor[Double](matArray, Array[Int](3, 3)) val trans = Tensor[Double](3) trans(1) = 0 trans(2) = 1.8 trans(3) = 1.1 val aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode = clamp , padVal = 0) val outputImageSet = imageset.transform(aff) Affine transformer implements affine transformation on a given tensor. To avoid defects in resampling, the mapping is from destination to source. dst(z,y,x) = src(f(z),f(y),f(x)) where f: dst - src mat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src. translation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis. clampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image. padVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error. Python: from zoo.feature.image3d.transformation import AffineTransform3D affine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val) transformed_image = affine(image_set) affine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src. translation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis. clamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image. pad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.","title":"Affine Transformation"},{"location":"APIGuide/FeatureEngineering/relation/","text":"A Relation represents the relationship between two items. Scala/Python relation = Relation(id1, id2, label) id1 : String. The id of one item. id2 : String. The id of the other item. label : Integer. The label between the two items. By convention you can use 0 if they are unrelated and a positive integer if they are related. A RelationPair is made up of two relations of the same id1, namely: Relation(id1, id2Positive, label 0) (A positive Relation) Relation(id1, id2Negative, label=0) (A negative Relation) Read Relations From csv or txt file Each record is supposed to contain id1, id2 and label described above in the exact order. For csv file, it should be without header. For txt file, each line should contain one record with fields separated by comma. Scala relationsRDD = Relations.read(path, sc, minPartitions = 1) relationsArray = Relations.read(path) path : The path to the relations file, which can either be a local or distributed file system (such as HDFS) path (in this case sc needs to be specified). sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only takes effect when sc is specified. Default is 1. Python relations_rdd = Relations.read(path, sc, min_partitions = 1) relations_list = Relations.read(path) path : The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified). sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation. min_partitions : Integer. A suggestion value of the minimal partition number for input texts. Only takes effect when sc is specified. Default is 1. From parquet file Read relations from parquet file exactly with the schema in Relation. Return RDD of Relation. Scala relationsRDD = Relations.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python relations_rdd = Relations.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext.","title":"Relation"},{"location":"APIGuide/FeatureEngineering/relation/#read-relations","text":"From csv or txt file Each record is supposed to contain id1, id2 and label described above in the exact order. For csv file, it should be without header. For txt file, each line should contain one record with fields separated by comma. Scala relationsRDD = Relations.read(path, sc, minPartitions = 1) relationsArray = Relations.read(path) path : The path to the relations file, which can either be a local or distributed file system (such as HDFS) path (in this case sc needs to be specified). sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only takes effect when sc is specified. Default is 1. Python relations_rdd = Relations.read(path, sc, min_partitions = 1) relations_list = Relations.read(path) path : The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified). sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation. min_partitions : Integer. A suggestion value of the minimal partition number for input texts. Only takes effect when sc is specified. Default is 1. From parquet file Read relations from parquet file exactly with the schema in Relation. Return RDD of Relation. Scala relationsRDD = Relations.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python relations_rdd = Relations.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext.","title":"Read Relations"},{"location":"APIGuide/FeatureEngineering/text/","text":"Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline, including text loading, pre-processing, training and inference, etc. TextSet TextSet is a collection of TextFeatures where each TextFeature keeps information of a single text record. TextSet can either be a DistributedTextSet consisting of text RDD or a LocalTextSet consisting of text array. Read texts as TextSet Read texts from a directory Read texts with labels from a directory. Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. Each category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. Each text will be a given a label according to the directory where it is located. Scala textSet = TextSet.read(path, sc = null, minPartitions = 1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read(path, sc=None, min_partitions=1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1. Read texts from csv file Read texts with id from csv file. Each record is supposed to contain id(String) and text(String) in order. Note that the csv file should be without header. Scala textSet = TextSet.readCSV(path, sc = null, minPartitions = 1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read_csv(path, sc=None, min_partitions=1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1. Read texts from parquet file Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet. Scala textSet = TextSet.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python text_set = TextSet.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext. TextSet Transformations Analytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference: Tokenization Do tokenization on original text. Scala transformedTextSet = textSet.tokenize() Python transformed_text_set = text_set.tokenize() Normalization Removes all dirty (non English alphabet) characters from tokens and converts words to lower case. Need to tokenize first. Scala transformedTextSet = textSet.normalize() Python transformed_text_set = text_set.normalize() Word To Index Map word tokens to indices. Important: Take care that this method behaves a bit differently for training and inference. Training During the training, you need to generate a new word index correspondence according to the texts you are dealing with. Thus this method will first do the vocabulary generation and then convert words to indices based on the generated vocabulary. The following arguments pose some constraints when generating the vocabulary. In the result vocabulary, index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order. Here we adopt the convention that index 0 will be reserved for unknown words. Need to tokenize first. After word2idx, you can get the generated word index vocabulary by calling getWordIndex (Scala) or get_word_index() (Python) of the transformed TextSet. Also, you can call saveWordIndex(path) (Scala) save_word_index(path) (Python) to save this word index vocabulary to be used in future training. Inference During the inference, you are supposed to use exactly the same word index correspondence as in the training stage instead of generating a new one. Need to tokenize first. Thus please be aware that you do not need to specify any of the below arguments. You need to call loadWordIndex(path) (Scala) or load_word_index(path) (Python) beforehand for word index loading . Scala transformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null) removeTopN : Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing. maxWordsNum : Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer. minFreq : Positive integer. Only those words with frequency = minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered. existingMap : Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. If not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words. Python transformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None) remove_topN : Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing. max_words_num : Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int. min_freq : Positive int. Only those words with frequency = min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered. existing_map : Existing dictionary of word index if any. Default is None and in this case a new dictionary with index starting from 1 will be generated. If not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words. Sequence Shaping Shape the sequence of indices to a fixed length. Need to word2idx first. Scala transformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0) len : Positive integer. The target length. truncMode : Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. If 'TruncMode.pre', the sequence will be truncated from the beginning. If 'TruncMode.post', the sequence will be truncated from the end. Default is 'TruncMode.post'. padElement : Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length. Default is 0 with the convention that we reserve index 0 for unknown words. Python transformed_text_set = text_set.shape_sequence(len, trunc_mode= pre , pad_element=0) len : Positive int. The target length. trunc_mode : String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. If 'pre', the sequence will be truncated from the beginning. If 'post', the sequence will be truncated from the end. Default is 'post'. pad_element : Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length. Default is 0 with the convention that we reserve index 0 for unknown words. BigDL Sample Generation Transform indices and label (if any) to a BigDL Sample . Need to word2idx first. Scala transformedTextSet = textSet.generateSample() Python transformed_text_set = text_set.generate_sample() WordEmbedding This is a special Embedding layer that directly loads pre-trained word vectors as weights, which turns non-negative integers (indices) into dense vectors of fixed size. Currently only GloVe embedding is supported for this layer. The input of this layer should be 2D. Scala embedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1) embeddingFile : The path to the word embedding file. Currently glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now. inputLength : Positive integer. The sequence length of each input. Python embedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None) embedding_file The path to the word embedding file. Currently glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. trainable : To configure whether the weights of this layer will be updated or not. Only False is supported for now. inputLength : Positive int. The sequence length of each input.","title":"Text"},{"location":"APIGuide/FeatureEngineering/text/#textset","text":"TextSet is a collection of TextFeatures where each TextFeature keeps information of a single text record. TextSet can either be a DistributedTextSet consisting of text RDD or a LocalTextSet consisting of text array.","title":"TextSet"},{"location":"APIGuide/FeatureEngineering/text/#read-texts-as-textset","text":"","title":"Read texts as TextSet"},{"location":"APIGuide/FeatureEngineering/text/#read-texts-from-a-directory","text":"Read texts with labels from a directory. Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. Each category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. Each text will be a given a label according to the directory where it is located. Scala textSet = TextSet.read(path, sc = null, minPartitions = 1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read(path, sc=None, min_partitions=1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1.","title":"Read texts from a directory"},{"location":"APIGuide/FeatureEngineering/text/#read-texts-from-csv-file","text":"Read texts with id from csv file. Each record is supposed to contain id(String) and text(String) in order. Note that the csv file should be without header. Scala textSet = TextSet.readCSV(path, sc = null, minPartitions = 1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read_csv(path, sc=None, min_partitions=1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1.","title":"Read texts from csv file"},{"location":"APIGuide/FeatureEngineering/text/#read-texts-from-parquet-file","text":"Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet. Scala textSet = TextSet.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python text_set = TextSet.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext.","title":"Read texts from parquet file"},{"location":"APIGuide/FeatureEngineering/text/#textset-transformations","text":"Analytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference:","title":"TextSet Transformations"},{"location":"APIGuide/FeatureEngineering/text/#tokenization","text":"Do tokenization on original text. Scala transformedTextSet = textSet.tokenize() Python transformed_text_set = text_set.tokenize()","title":"Tokenization"},{"location":"APIGuide/FeatureEngineering/text/#normalization","text":"Removes all dirty (non English alphabet) characters from tokens and converts words to lower case. Need to tokenize first. Scala transformedTextSet = textSet.normalize() Python transformed_text_set = text_set.normalize()","title":"Normalization"},{"location":"APIGuide/FeatureEngineering/text/#word-to-index","text":"Map word tokens to indices. Important: Take care that this method behaves a bit differently for training and inference. Training During the training, you need to generate a new word index correspondence according to the texts you are dealing with. Thus this method will first do the vocabulary generation and then convert words to indices based on the generated vocabulary. The following arguments pose some constraints when generating the vocabulary. In the result vocabulary, index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order. Here we adopt the convention that index 0 will be reserved for unknown words. Need to tokenize first. After word2idx, you can get the generated word index vocabulary by calling getWordIndex (Scala) or get_word_index() (Python) of the transformed TextSet. Also, you can call saveWordIndex(path) (Scala) save_word_index(path) (Python) to save this word index vocabulary to be used in future training. Inference During the inference, you are supposed to use exactly the same word index correspondence as in the training stage instead of generating a new one. Need to tokenize first. Thus please be aware that you do not need to specify any of the below arguments. You need to call loadWordIndex(path) (Scala) or load_word_index(path) (Python) beforehand for word index loading . Scala transformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null) removeTopN : Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing. maxWordsNum : Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer. minFreq : Positive integer. Only those words with frequency = minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered. existingMap : Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. If not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words. Python transformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None) remove_topN : Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing. max_words_num : Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int. min_freq : Positive int. Only those words with frequency = min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered. existing_map : Existing dictionary of word index if any. Default is None and in this case a new dictionary with index starting from 1 will be generated. If not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words.","title":"Word To Index"},{"location":"APIGuide/FeatureEngineering/text/#sequence-shaping","text":"Shape the sequence of indices to a fixed length. Need to word2idx first. Scala transformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0) len : Positive integer. The target length. truncMode : Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. If 'TruncMode.pre', the sequence will be truncated from the beginning. If 'TruncMode.post', the sequence will be truncated from the end. Default is 'TruncMode.post'. padElement : Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length. Default is 0 with the convention that we reserve index 0 for unknown words. Python transformed_text_set = text_set.shape_sequence(len, trunc_mode= pre , pad_element=0) len : Positive int. The target length. trunc_mode : String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. If 'pre', the sequence will be truncated from the beginning. If 'post', the sequence will be truncated from the end. Default is 'post'. pad_element : Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length. Default is 0 with the convention that we reserve index 0 for unknown words.","title":"Sequence Shaping"},{"location":"APIGuide/FeatureEngineering/text/#bigdl-sample-generation","text":"Transform indices and label (if any) to a BigDL Sample . Need to word2idx first. Scala transformedTextSet = textSet.generateSample() Python transformed_text_set = text_set.generate_sample()","title":"BigDL Sample Generation"},{"location":"APIGuide/FeatureEngineering/text/#wordembedding","text":"This is a special Embedding layer that directly loads pre-trained word vectors as weights, which turns non-negative integers (indices) into dense vectors of fixed size. Currently only GloVe embedding is supported for this layer. The input of this layer should be 2D. Scala embedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1) embeddingFile : The path to the word embedding file. Currently glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now. inputLength : Positive integer. The sequence length of each input. Python embedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None) embedding_file The path to the word embedding file. Currently glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. trainable : To configure whether the weights of this layer will be updated or not. Only False is supported for now. inputLength : Positive int. The sequence length of each input.","title":"WordEmbedding"},{"location":"APIGuide/Models/anomaly-detection/","text":"Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. A sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions. Hightlights Keras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training. Models are defined base on LSTM. Build an AnomalyDetction model You can call the following API in Scala and Python respectively to create an AnomalyDetrctor model Scala import com.intel.analytics.zoo.models.anomalydetection._ val model = AnomalyDetector(featureShape, hiddenLayers, dropouts) featureShape The input shape of features, fist dimension is unroll length, second dimension is feature size. hiddenLayers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Python from zoo.models.anomalydetection import AnomalyDetector model = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2]) feature_shape The input shape of features, fist dimension is unroll length, second dimension is feature size. hidden_layers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Unroll features To prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length. Scala val unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep) dataRdd RDD[Array]. data to be unrolled, it holds original time series features unrollLength Int. the length of precious values to predict future value. predictStep Int. How many time steps to predict future value, default is 1. Python unrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step) data_rdd RDD[Array]. data to be unrolled, it holds original time series features unroll_length Int. The length of precious values to predict future value. predict_step Int. How many time steps to predict future value, default is 1. Detect anomalies After training the model, it can be used to predict values using previous data, then to detect anomalies. Anomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top anomalySize data points are anomalies). Scala val anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize) yTruth RDD of float or double values. Truth to be compared. yPredict RDD of float or double values. Predictions. anomalySize Int. The size to be considered as anomalies. Python `` anomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size) y_truth RDD of float or double values. Truth to be compared. y_predict RDD of float or double values. Predictions. anomaly_size Int. The size to be considered as anomalies. Save Model After building and training an AnomalyDetector model, you can save it for future use. Scala model.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python model.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False. Load Model To load an AnomalyDetector model (with weights) saved above : Scala AnomalyDetector.loadModel[Float](path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python AnomalyDetector.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Anomaly Detection"},{"location":"APIGuide/Models/anomaly-detection/#build-an-anomalydetction-model","text":"You can call the following API in Scala and Python respectively to create an AnomalyDetrctor model Scala import com.intel.analytics.zoo.models.anomalydetection._ val model = AnomalyDetector(featureShape, hiddenLayers, dropouts) featureShape The input shape of features, fist dimension is unroll length, second dimension is feature size. hiddenLayers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Python from zoo.models.anomalydetection import AnomalyDetector model = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2]) feature_shape The input shape of features, fist dimension is unroll length, second dimension is feature size. hidden_layers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1.","title":"Build an AnomalyDetction model"},{"location":"APIGuide/Models/anomaly-detection/#unroll-features","text":"To prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length. Scala val unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep) dataRdd RDD[Array]. data to be unrolled, it holds original time series features unrollLength Int. the length of precious values to predict future value. predictStep Int. How many time steps to predict future value, default is 1. Python unrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step) data_rdd RDD[Array]. data to be unrolled, it holds original time series features unroll_length Int. The length of precious values to predict future value. predict_step Int. How many time steps to predict future value, default is 1.","title":"Unroll features"},{"location":"APIGuide/Models/anomaly-detection/#detect-anomalies","text":"After training the model, it can be used to predict values using previous data, then to detect anomalies. Anomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top anomalySize data points are anomalies). Scala val anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize) yTruth RDD of float or double values. Truth to be compared. yPredict RDD of float or double values. Predictions. anomalySize Int. The size to be considered as anomalies. Python `` anomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size) y_truth RDD of float or double values. Truth to be compared. y_predict RDD of float or double values. Predictions. anomaly_size Int. The size to be considered as anomalies.","title":"Detect anomalies"},{"location":"APIGuide/Models/anomaly-detection/#save-model","text":"After building and training an AnomalyDetector model, you can save it for future use. Scala model.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python model.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False.","title":"Save Model"},{"location":"APIGuide/Models/anomaly-detection/#load-model","text":"To load an AnomalyDetector model (with weights) saved above : Scala AnomalyDetector.loadModel[Float](path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python AnomalyDetector.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Load Model"},{"location":"APIGuide/Models/image-classification/","text":"Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink. Model Load Use ImageClassifier.loadModel (in Scala) or ImageClassifier.load_model (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model. Module (Scala) or Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model. Scala example import com.intel.analytics.zoo.models.image.imageclassification._ val model = ImageClassifier.loadModel[Float]( /tmp/model.zoo , /tmp/model.bin ) //load from local fs val model = ImageClassifier.loadModel( hdfs://... ) //load from hdfs val model = ImageClassifier.loadModel( s3://... ) //load from s3 Python example from zoo.models.image.imageclassification import * model = ImageClassifier.load_model( /tmp/...model , /tmp/model.bin ) //load from local fs model = ImageClassifier.load_model( hdfs://... ) //load from hdfs model = ImageClassifier.load_model( s3://... ) //load from s3 Creat image configuration If the loaded model is a published Analytics Zoo model, when you call ImageClassifier.loadModel (in Scala) or ImageClassifier.load_model (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. Scala API ImageConfigure[T: ClassTag]( preProcessor: Preprocessing[ImageFeature, ImageFeature] = null, postProcessor: Preprocessing[ImageFeature, ImageFeature] = null, batchPerPartition: Int = 4, labelMap: Map[Int, String] = null, featurePaddingParam: Option[PaddingParam[T]] = None) preProcessor: preprocessor of ImageFrame before model inference postProcessor: postprocessor of ImageFrame after model inference batchPerPartition: batch size per partition labelMap: label mapping featurePaddingParam: featurePaddingParam if the inputs have variant size Scala example import com.intel.analytics.zoo.models.image.common._ import com.intel.analytics.zoo.feature.image._ val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preProcessor=preprocessing) Python API class ImageConfigure() def __init__(self, pre_processor=None, post_processor=None, batch_per_partition=4, label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float ) pre_processor: preprocessor of ImageSet before model inference post_processor: postprocessor of ImageSet after model inference batch_per_partition: batch size per partition label_map mapping: from prediction result indexes to real dataset labels feature_padding_param: featurePaddingParam if the inputs have variant size Python example from zoo.models.image.common.image_config import * from zoo.feature.image.imagePreprocessing import * preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(pre_processor=preprocessing) Predict with loaded image classification model Scala API predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this predcition Scala example import com.intel.analytics.zoo.models.image.imageclassification._ import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.feature.image._ val imagePath= /tmp/image val sc = NNContext.initNNContext() val model = ImageClassifier.loadModel( /tmp/analytics-zoo_inception-v1_imagenet_0.1.0 ) val data = ImageSet.read(image_path, sc) val output = model.predictImageSet(data) Python API predict_image_set(image, configure=None) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this predcition Python example from zoo.common.nncontext import * from zoo.models.image.imageclassification import * sc = init_nncontext() model = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Image Classification"},{"location":"APIGuide/Models/image-classification/#model-load","text":"Use ImageClassifier.loadModel (in Scala) or ImageClassifier.load_model (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model. Module (Scala) or Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model. Scala example import com.intel.analytics.zoo.models.image.imageclassification._ val model = ImageClassifier.loadModel[Float]( /tmp/model.zoo , /tmp/model.bin ) //load from local fs val model = ImageClassifier.loadModel( hdfs://... ) //load from hdfs val model = ImageClassifier.loadModel( s3://... ) //load from s3 Python example from zoo.models.image.imageclassification import * model = ImageClassifier.load_model( /tmp/...model , /tmp/model.bin ) //load from local fs model = ImageClassifier.load_model( hdfs://... ) //load from hdfs model = ImageClassifier.load_model( s3://... ) //load from s3","title":"Model Load"},{"location":"APIGuide/Models/image-classification/#creat-image-configuration","text":"If the loaded model is a published Analytics Zoo model, when you call ImageClassifier.loadModel (in Scala) or ImageClassifier.load_model (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. Scala API ImageConfigure[T: ClassTag]( preProcessor: Preprocessing[ImageFeature, ImageFeature] = null, postProcessor: Preprocessing[ImageFeature, ImageFeature] = null, batchPerPartition: Int = 4, labelMap: Map[Int, String] = null, featurePaddingParam: Option[PaddingParam[T]] = None) preProcessor: preprocessor of ImageFrame before model inference postProcessor: postprocessor of ImageFrame after model inference batchPerPartition: batch size per partition labelMap: label mapping featurePaddingParam: featurePaddingParam if the inputs have variant size Scala example import com.intel.analytics.zoo.models.image.common._ import com.intel.analytics.zoo.feature.image._ val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preProcessor=preprocessing) Python API class ImageConfigure() def __init__(self, pre_processor=None, post_processor=None, batch_per_partition=4, label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float ) pre_processor: preprocessor of ImageSet before model inference post_processor: postprocessor of ImageSet after model inference batch_per_partition: batch size per partition label_map mapping: from prediction result indexes to real dataset labels feature_padding_param: featurePaddingParam if the inputs have variant size Python example from zoo.models.image.common.image_config import * from zoo.feature.image.imagePreprocessing import * preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(pre_processor=preprocessing)","title":"Creat image configuration"},{"location":"APIGuide/Models/image-classification/#predict-with-loaded-image-classification-model","text":"Scala API predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this predcition Scala example import com.intel.analytics.zoo.models.image.imageclassification._ import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.feature.image._ val imagePath= /tmp/image val sc = NNContext.initNNContext() val model = ImageClassifier.loadModel( /tmp/analytics-zoo_inception-v1_imagenet_0.1.0 ) val data = ImageSet.read(image_path, sc) val output = model.predictImageSet(data) Python API predict_image_set(image, configure=None) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this predcition Python example from zoo.common.nncontext import * from zoo.models.image.imageclassification import * sc = init_nncontext() model = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Predict with loaded image classification model"},{"location":"APIGuide/Models/object-detection/","text":"Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink. Model Load Use ObjectDetector.loadModel (in Scala) or ObjectDetector.load_model (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model. Scala example import com.intel.analytics.zoo.models.image.objectdetection._ val model = ObjectDetector.loadModel[Float]( /tmp/zoo.model ) //load from local fs val model = ObjectDetector.loadModel( hdfs://... ) //load from hdfs val model = ObjectDetector.loadModel( s3://... ) //load from s3 Python example from zoo.models.image.objectdetection import * model = ObjectDetector.load_model( /tmp/zoo.model ) //load from local fs model = ObjectDetector.load_model( hdfs://... ) //load from hdfs model = ObjectDetector.load_model( s3://... ) //load from s3 Creat image configuration If the loaded model is a published Analytics Zoo model, when you call ObjectDetector.loadModel (in Scala) or ObjectDetector.load_model (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. Scala API ImageConfigure[T: ClassTag]( preProcessor: Preprocessing[ImageFeature, ImageFeature] = null, postProcessor: Preprocessing[ImageFeature, ImageFeature] = null, batchPerPartition: Int = 4, labelMap: Map[Int, String] = null, featurePaddingParam: Option[PaddingParam[T]] = None) preProcessor: preprocessor of ImageSet before model inference postProcessor: postprocessor of ImageSet after model inference batchPerPartition: batch size per partition labelMap: label mapping featurePaddingParam: featurePaddingParam if the inputs have variant size Scala example import com.intel.analytics.zoo.models.image.common._ import com.intel.analytics.zoo.feature.image._ val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preProcessor=preprocessing) Python API class ImageConfigure() def __init__(self, pre_processor=None, post_processor=None, batch_per_partition=4, label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float ) pre_processor: preprocessor of ImageSet before model inference post_processor: postprocessor of ImageSet after model inference batch_per_partition: batch size per partition label_map mapping: from prediction result indexes to real dataset labels feature_padding_param: featurePaddingParam if the inputs have variant size Python example from zoo.models.image.common.image_config import * from zoo.feature.image.imagePreprocessing import * preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(pre_processor=preprocessing) Predict with loaded object detection model Scala API predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this prediction Scala example import com.intel.analytics.zoo.models.image.objectdetection._ import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.feature.image._ val imagePath= /tmp/image val sc = NNContext.initNNContext() val model = ObjectDetector.loadModel( /tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model ) val data = ImageSet.read(image_path, sc) val output = model.predictImageSet(data) Python API predict_image_set(image, configure=None) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this prediction Python example from zoo.common.nncontext import * from zoo.models.image.objectdetection import * sc = init_nncontext() model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Object Detection"},{"location":"APIGuide/Models/object-detection/#model-load","text":"Use ObjectDetector.loadModel (in Scala) or ObjectDetector.load_model (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model. Scala example import com.intel.analytics.zoo.models.image.objectdetection._ val model = ObjectDetector.loadModel[Float]( /tmp/zoo.model ) //load from local fs val model = ObjectDetector.loadModel( hdfs://... ) //load from hdfs val model = ObjectDetector.loadModel( s3://... ) //load from s3 Python example from zoo.models.image.objectdetection import * model = ObjectDetector.load_model( /tmp/zoo.model ) //load from local fs model = ObjectDetector.load_model( hdfs://... ) //load from hdfs model = ObjectDetector.load_model( s3://... ) //load from s3","title":"Model Load"},{"location":"APIGuide/Models/object-detection/#creat-image-configuration","text":"If the loaded model is a published Analytics Zoo model, when you call ObjectDetector.loadModel (in Scala) or ObjectDetector.load_model (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. Scala API ImageConfigure[T: ClassTag]( preProcessor: Preprocessing[ImageFeature, ImageFeature] = null, postProcessor: Preprocessing[ImageFeature, ImageFeature] = null, batchPerPartition: Int = 4, labelMap: Map[Int, String] = null, featurePaddingParam: Option[PaddingParam[T]] = None) preProcessor: preprocessor of ImageSet before model inference postProcessor: postprocessor of ImageSet after model inference batchPerPartition: batch size per partition labelMap: label mapping featurePaddingParam: featurePaddingParam if the inputs have variant size Scala example import com.intel.analytics.zoo.models.image.common._ import com.intel.analytics.zoo.feature.image._ val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preProcessor=preprocessing) Python API class ImageConfigure() def __init__(self, pre_processor=None, post_processor=None, batch_per_partition=4, label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float ) pre_processor: preprocessor of ImageSet before model inference post_processor: postprocessor of ImageSet after model inference batch_per_partition: batch size per partition label_map mapping: from prediction result indexes to real dataset labels feature_padding_param: featurePaddingParam if the inputs have variant size Python example from zoo.models.image.common.image_config import * from zoo.feature.image.imagePreprocessing import * preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(pre_processor=preprocessing)","title":"Creat image configuration"},{"location":"APIGuide/Models/object-detection/#predict-with-loaded-object-detection-model","text":"Scala API predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this prediction Scala example import com.intel.analytics.zoo.models.image.objectdetection._ import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.feature.image._ val imagePath= /tmp/image val sc = NNContext.initNNContext() val model = ObjectDetector.loadModel( /tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model ) val data = ImageSet.read(image_path, sc) val output = model.predictImageSet(data) Python API predict_image_set(image, configure=None) image: Analytics Zoo ImageSet to be predicted configure: Image Configure for this prediction Python example from zoo.common.nncontext import * from zoo.models.image.objectdetection import * sc = init_nncontext() model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set)","title":"Predict with loaded object detection model"},{"location":"APIGuide/Models/recommendation/","text":"Analytics Zoo provides two Recommenders, including Wide and Deep (WND) model and Neural network-based Collaborative Filtering (NCF) model. Easy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer. Recommenders can handle models with either explict or implicit feedback, given corresponding features. We also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See here for more details. Wide and Deep Wide and Deep Learning Model, proposed by Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation. After training the model, users can use the model to do prediction and recommendation . Scala val wideAndDeep = WideAndDeep(modelType = wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10)) modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\". numClasses : The number of classes. Positive integer. columnInfo An instance of ColumnFeatureInfo . hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10). See here for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Python wide_and_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10)) class_num : The number of classes. Positive int. column_info : An instance of ColumnFeatureInfo . model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'. hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10). See here for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Neural network-based Collaborative Filtering NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. includeMF (Boolean) is provided for users to build a NeuralCF model with or without matrix factorization. After training the model, users can use the model to do prediction and recommendation . Scala val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20) userCount : The number of users. Positive integer. itemCount : The number of items. Positive integer. numClasses : The number of classes. Positive integer. userEmbed : Units of user embedding. Positive integer. Default is 20. itemEmbed : Units of item embedding. Positive integer. Default is 20. hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10). includeMF : Whether to include Matrix Factorization. Boolean. Default is true. mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20. See here for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Python ncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20) user_count : The number of users. Positive int. item_count : The number of classes. Positive int. class_num: The number of classes. Positive int. user_embed : Units of user embedding. Positive int. Default is 20. item_embed : itemEmbed Units of item embedding. Positive int. Default is 20. hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10). include_mf : Whether to include Matrix Factorization. Boolean. Default is True. mf_embed : Units of matrix factorization embedding. Positive int. Default is 20. See here for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Prediction and Recommendation Predict for user-item pairs Give prediction for each pair of user and item. Return RDD of UserItemPrediction . Scala predictUserItemPair(featureRdd) Python predict_user_item_pair(feature_rdd) Parameters: featureRdd : RDD of UserItemFeature . Recommend for users Recommend a number of items for each user. Return RDD of UserItemPrediction . Scala recommendForUser(featureRdd, maxItems) Python recommend_for_user(feature_rdd, max_items) Parameters: featureRdd : RDD of UserItemFeature . maxItems : The number of items to be recommended to each user. Positive integer. Recommend for items Recommend a number of users for each item. Return RDD of UserItemPrediction . Scala recommendForItem(featureRdd, maxUsers) Python recommend_for_item(feature_rdd, max_users) Parameters: featureRdd : RDD of UserItemFeature . maxUsers : The number of users to be recommended to each item. Positive integer. Model Save After building and training a WideAndDeep or NeuralCF model, you can save it for future use. Scala wideAndDeep.saveModel(path, weightPath = null, overWrite = false) ncf.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python wide_and_deep.save_model(path, weight_path=None, over_write=False) ncf.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False. Model Load To load a WideAndDeep or NeuralCF model (with weights) saved above : Scala WideAndDeep.loadModel[Float](path, weightPath = null) NeuralCF.loadModel[Float](path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python WideAndDeep.load_model(path, weight_path=None) NeuralCF.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None. UserItemFeature Represent records of user-item with features. Each record should contain the following fields: userId : Positive integer. item_id : Positive integer. sample : Sample which consists of feature(s) and label(s). Scala UserItemFeature(userId, itemId, sample) Python UserItemFeature(user_id, item_id, sample) UserItemPrediction Represent the prediction results of user-item pairs. Each prediction record will contain the following information: userId : Positive integer. itemId : Positive integer. prediction : The prediction (rating) for the user on the item. probability : The probability for the prediction. Scala UserItemPrediction(userId, itemId, prediction, probability) Python UserItemPrediction(user_id, item_id, prediction, probability) ColumnFeatureInfo An instance of ColumnFeatureInfo contains the same data information shared by the WideAndDeep model and its feature generation part. You can choose to include the following information for feature engineering and the WideAndDeep model: wideBaseCols : Data of wideBaseCols together with wideCrossCols will be fed into the wide model. wideBaseDims : Dimensions of wideBaseCols . The dimensions of the data in wideBaseCols should be within the range of wideBaseDims . wideCrossCols : Data of wideCrossCols will be fed into the wide model. wideCrossDims : Dimensions of wideCrossCols . The dimensions of the data in wideCrossCols should be within the range of wideCrossDims . indicatorCols : Data of indicatorCols will be fed into the deep model as multi-hot vectors. indicatorDims : Dimensions of indicatorCols . The dimensions of the data in indicatorCols should be within the range of indicatorDims . embedCols : Data of embedCols will be fed into the deep model as embeddings. embedInDims : Input dimension of the data in embedCols . The dimensions of the data in embedCols should be within the range of embedInDims . embedOutDims : The dimensions of embeddings for embedCols . continuousCols : Data of continuousCols will be treated as continuous values for the deep model. label : The name of the 'label' column. String. Default is \"label\". Remark: Fields that involve Cols should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data. Fields that involve Dims should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns. If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python). Scala ColumnFeatureInfo( wideBaseCols = Array[String](), wideBaseDims = Array[Int](), wideCrossCols = Array[String](), wideCrossDims = Array[Int](), indicatorCols = Array[String](), indicatorDims = Array[Int](), embedCols = Array[String](), embedInDims = Array[Int](), embedOutDims = Array[Int](), continuousCols = Array[String](), label = label ) Python ColumnFeatureInfo( wide_base_cols=None, wide_base_dims=None, wide_cross_cols=None, wide_cross_dims=None, indicator_cols=None, indicator_dims=None, embed_cols=None, embed_in_dims=None, embed_out_dims=None, continuous_cols=None, label= label )","title":"Recommendation"},{"location":"APIGuide/Models/recommendation/#wide-and-deep","text":"Wide and Deep Learning Model, proposed by Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation. After training the model, users can use the model to do prediction and recommendation . Scala val wideAndDeep = WideAndDeep(modelType = wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10)) modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\". numClasses : The number of classes. Positive integer. columnInfo An instance of ColumnFeatureInfo . hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10). See here for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Python wide_and_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10)) class_num : The number of classes. Positive int. column_info : An instance of ColumnFeatureInfo . model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'. hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10). See here for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.","title":"Wide and Deep"},{"location":"APIGuide/Models/recommendation/#neural-network-based-collaborative-filtering","text":"NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. includeMF (Boolean) is provided for users to build a NeuralCF model with or without matrix factorization. After training the model, users can use the model to do prediction and recommendation . Scala val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20) userCount : The number of users. Positive integer. itemCount : The number of items. Positive integer. numClasses : The number of classes. Positive integer. userEmbed : Units of user embedding. Positive integer. Default is 20. itemEmbed : Units of item embedding. Positive integer. Default is 20. hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10). includeMF : Whether to include Matrix Factorization. Boolean. Default is true. mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20. See here for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation. Python ncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20) user_count : The number of users. Positive int. item_count : The number of classes. Positive int. class_num: The number of classes. Positive int. user_embed : Units of user embedding. Positive int. Default is 20. item_embed : itemEmbed Units of item embedding. Positive int. Default is 20. hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10). include_mf : Whether to include Matrix Factorization. Boolean. Default is True. mf_embed : Units of matrix factorization embedding. Positive int. Default is 20. See here for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.","title":"Neural network-based Collaborative Filtering"},{"location":"APIGuide/Models/recommendation/#prediction-and-recommendation","text":"Predict for user-item pairs Give prediction for each pair of user and item. Return RDD of UserItemPrediction . Scala predictUserItemPair(featureRdd) Python predict_user_item_pair(feature_rdd) Parameters: featureRdd : RDD of UserItemFeature . Recommend for users Recommend a number of items for each user. Return RDD of UserItemPrediction . Scala recommendForUser(featureRdd, maxItems) Python recommend_for_user(feature_rdd, max_items) Parameters: featureRdd : RDD of UserItemFeature . maxItems : The number of items to be recommended to each user. Positive integer. Recommend for items Recommend a number of users for each item. Return RDD of UserItemPrediction . Scala recommendForItem(featureRdd, maxUsers) Python recommend_for_item(feature_rdd, max_users) Parameters: featureRdd : RDD of UserItemFeature . maxUsers : The number of users to be recommended to each item. Positive integer.","title":"Prediction and Recommendation"},{"location":"APIGuide/Models/recommendation/#model-save","text":"After building and training a WideAndDeep or NeuralCF model, you can save it for future use. Scala wideAndDeep.saveModel(path, weightPath = null, overWrite = false) ncf.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python wide_and_deep.save_model(path, weight_path=None, over_write=False) ncf.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False.","title":"Model Save"},{"location":"APIGuide/Models/recommendation/#model-load","text":"To load a WideAndDeep or NeuralCF model (with weights) saved above : Scala WideAndDeep.loadModel[Float](path, weightPath = null) NeuralCF.loadModel[Float](path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python WideAndDeep.load_model(path, weight_path=None) NeuralCF.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Model Load"},{"location":"APIGuide/Models/recommendation/#useritemfeature","text":"Represent records of user-item with features. Each record should contain the following fields: userId : Positive integer. item_id : Positive integer. sample : Sample which consists of feature(s) and label(s). Scala UserItemFeature(userId, itemId, sample) Python UserItemFeature(user_id, item_id, sample)","title":"UserItemFeature"},{"location":"APIGuide/Models/recommendation/#useritemprediction","text":"Represent the prediction results of user-item pairs. Each prediction record will contain the following information: userId : Positive integer. itemId : Positive integer. prediction : The prediction (rating) for the user on the item. probability : The probability for the prediction. Scala UserItemPrediction(userId, itemId, prediction, probability) Python UserItemPrediction(user_id, item_id, prediction, probability)","title":"UserItemPrediction"},{"location":"APIGuide/Models/recommendation/#columnfeatureinfo","text":"An instance of ColumnFeatureInfo contains the same data information shared by the WideAndDeep model and its feature generation part. You can choose to include the following information for feature engineering and the WideAndDeep model: wideBaseCols : Data of wideBaseCols together with wideCrossCols will be fed into the wide model. wideBaseDims : Dimensions of wideBaseCols . The dimensions of the data in wideBaseCols should be within the range of wideBaseDims . wideCrossCols : Data of wideCrossCols will be fed into the wide model. wideCrossDims : Dimensions of wideCrossCols . The dimensions of the data in wideCrossCols should be within the range of wideCrossDims . indicatorCols : Data of indicatorCols will be fed into the deep model as multi-hot vectors. indicatorDims : Dimensions of indicatorCols . The dimensions of the data in indicatorCols should be within the range of indicatorDims . embedCols : Data of embedCols will be fed into the deep model as embeddings. embedInDims : Input dimension of the data in embedCols . The dimensions of the data in embedCols should be within the range of embedInDims . embedOutDims : The dimensions of embeddings for embedCols . continuousCols : Data of continuousCols will be treated as continuous values for the deep model. label : The name of the 'label' column. String. Default is \"label\". Remark: Fields that involve Cols should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data. Fields that involve Dims should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns. If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python). Scala ColumnFeatureInfo( wideBaseCols = Array[String](), wideBaseDims = Array[Int](), wideCrossCols = Array[String](), wideCrossDims = Array[Int](), indicatorCols = Array[String](), indicatorDims = Array[Int](), embedCols = Array[String](), embedInDims = Array[Int](), embedOutDims = Array[Int](), continuousCols = Array[String](), label = label ) Python ColumnFeatureInfo( wide_base_cols=None, wide_base_dims=None, wide_cross_cols=None, wide_cross_dims=None, indicator_cols=None, indicator_dims=None, embed_cols=None, embed_in_dims=None, embed_out_dims=None, continuous_cols=None, label= label )","title":"ColumnFeatureInfo"},{"location":"APIGuide/Models/seq2seq/","text":"Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more. The model could be fed into NNFrames or BigDL Optimizer directly for training. Build a Seq2seq Model Before build Seq2seq Model, you need build Encoder , Decoder . And Bridge if you want to do some transformation before passing encoder states to decoder. Build an Encoder Currently we only support RNNEncoder which enables you to put RNN layers into encoder. You can call the following API in Scala and Python respectively to create a RNNEncoder . Scala val encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding) rnnType style of recurrent unit, one of [SimpleRNN, LSTM, GRU] numLayers number of layers used in encoder hiddenSize hidden size of encoder embedding embedding layer in encoder, default is null You can also define RNN layers yourself val encoder = RNNEncoder(rnns, embedding, inputShape) rnns rnn layers used for encoder, support stacked rnn layers embedding embedding layer in encoder, default is null Python encoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding) rnn_type style of recurrent unit, one of [SimpleRNN, LSTM, GRU] nlayers number of layers used in encoder hidden_size hidden size of encoder embedding embedding layer in encoder, default is None Or encoder = RNNEncoder(rnns, embedding, input_shape) rnns rnn layers used for encoder, support stacked rnn layers embedding embedding layer in encoder, default is None Build a Decoder Similar to Encoder, we only support RNNDecoder and API is pretty much the same with RNNEncoder Scala val decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding) rnnType style of recurrent unit, one of [SimpleRNN, LSTM, GRU] numLayers number of layers used in decoder hiddenSize hidden size of decoder embedding embedding layer in decoder, default is null You can also define RNN layers yourself val decoder = RNNDecoder(rnns, embedding, inputShape) rnns rnn layers used for decoder, support stacked rnn layers embedding embedding layer in decoder, default is null Python encoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding): rnn_type style of recurrent unit, one of [SimpleRNN, LSTM, GRU] nlayers number of layers used in decoder hidden_size hidden size of decoder embedding embedding layer in decoder, default is None Or decoder = RNNDecoder(rnns, embedding, input_shape) rnns rnn layers used for decoder, support stacked rnn layers embedding embedding layer in decoder, default is None Build a Bridge By default, encoder states are directly fed into decoder. In this case, you don't need build a Bridge . But if you want to do some transformation before feed encoder states to decoder, please use following API to create a Bridge . Scala val bridge = Bridge(bridgeType, decoderHiddenSize) bridgeType currently only support \"dense | densenonlinear\" decoderHiddenSize hidden size of decoder You can also specify various keras layers as a Bridge val bridge = Bridge(bridge) bridge keras layers used to do the transformation Python bridge = Bridge.initialize(bridge_type, decoder_hidden_size) bridge_type : currently only support \"dense | densenonlinear\" decoder_hidden_size : hidden size of decoder Or bridge = Bridge.initialize_from_keras_layer(bridge) bridge keras layers used to do the transformation Build a Seq2seq Scala val seq2seq = Seq2seq(encoder, decoder, inputShape, outputShape, bridge, generator) encoder an encoder object decoder a decoder object inputShape shape of encoder input, for variable length, please input -1 outputShape shape of decoder input, for variable length, please input -1 bridge connect encoder and decoder, you can input null generator Feeding decoder output to generator to generate final result, null is supported See here for the Scala example that trains the Seq2seq model and uses the model to do prediction. Python seq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge, generator) encoder an encoder object decoder a decoder object input_shape shape of encoder input, for variable length, please input -1 output_shape shape of decoder input, for variable length, please input -1 bridge connect encoder and decoder, you can input null generator Feeding decoder output to generator to generate final result, None is supported","title":"Sequence to Sequence"},{"location":"APIGuide/Models/seq2seq/#build-a-seq2seq-model","text":"Before build Seq2seq Model, you need build Encoder , Decoder . And Bridge if you want to do some transformation before passing encoder states to decoder.","title":"Build a Seq2seq Model"},{"location":"APIGuide/Models/seq2seq/#build-an-encoder","text":"Currently we only support RNNEncoder which enables you to put RNN layers into encoder. You can call the following API in Scala and Python respectively to create a RNNEncoder . Scala val encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding) rnnType style of recurrent unit, one of [SimpleRNN, LSTM, GRU] numLayers number of layers used in encoder hiddenSize hidden size of encoder embedding embedding layer in encoder, default is null You can also define RNN layers yourself val encoder = RNNEncoder(rnns, embedding, inputShape) rnns rnn layers used for encoder, support stacked rnn layers embedding embedding layer in encoder, default is null Python encoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding) rnn_type style of recurrent unit, one of [SimpleRNN, LSTM, GRU] nlayers number of layers used in encoder hidden_size hidden size of encoder embedding embedding layer in encoder, default is None Or encoder = RNNEncoder(rnns, embedding, input_shape) rnns rnn layers used for encoder, support stacked rnn layers embedding embedding layer in encoder, default is None","title":"Build an Encoder"},{"location":"APIGuide/Models/seq2seq/#build-a-decoder","text":"Similar to Encoder, we only support RNNDecoder and API is pretty much the same with RNNEncoder Scala val decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding) rnnType style of recurrent unit, one of [SimpleRNN, LSTM, GRU] numLayers number of layers used in decoder hiddenSize hidden size of decoder embedding embedding layer in decoder, default is null You can also define RNN layers yourself val decoder = RNNDecoder(rnns, embedding, inputShape) rnns rnn layers used for decoder, support stacked rnn layers embedding embedding layer in decoder, default is null Python encoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding): rnn_type style of recurrent unit, one of [SimpleRNN, LSTM, GRU] nlayers number of layers used in decoder hidden_size hidden size of decoder embedding embedding layer in decoder, default is None Or decoder = RNNDecoder(rnns, embedding, input_shape) rnns rnn layers used for decoder, support stacked rnn layers embedding embedding layer in decoder, default is None","title":"Build a Decoder"},{"location":"APIGuide/Models/seq2seq/#build-a-bridge","text":"By default, encoder states are directly fed into decoder. In this case, you don't need build a Bridge . But if you want to do some transformation before feed encoder states to decoder, please use following API to create a Bridge . Scala val bridge = Bridge(bridgeType, decoderHiddenSize) bridgeType currently only support \"dense | densenonlinear\" decoderHiddenSize hidden size of decoder You can also specify various keras layers as a Bridge val bridge = Bridge(bridge) bridge keras layers used to do the transformation Python bridge = Bridge.initialize(bridge_type, decoder_hidden_size) bridge_type : currently only support \"dense | densenonlinear\" decoder_hidden_size : hidden size of decoder Or bridge = Bridge.initialize_from_keras_layer(bridge) bridge keras layers used to do the transformation","title":"Build a Bridge"},{"location":"APIGuide/Models/seq2seq/#build-a-seq2seq","text":"Scala val seq2seq = Seq2seq(encoder, decoder, inputShape, outputShape, bridge, generator) encoder an encoder object decoder a decoder object inputShape shape of encoder input, for variable length, please input -1 outputShape shape of decoder input, for variable length, please input -1 bridge connect encoder and decoder, you can input null generator Feeding decoder output to generator to generate final result, null is supported See here for the Scala example that trains the Seq2seq model and uses the model to do prediction. Python seq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge, generator) encoder an encoder object decoder a decoder object input_shape shape of encoder input, for variable length, please input -1 output_shape shape of decoder input, for variable length, please input -1 bridge connect encoder and decoder, you can input null generator Feeding decoder output to generator to generate final result, None is supported","title":"Build a Seq2seq"},{"location":"APIGuide/Models/text-classification/","text":"Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts. The model could be fed into NNFrames or BigDL Optimizer directly for training. Build a TextClassifier Model You can call the following API in Scala and Python respectively to create a TextClassifier with pre-trained GloVe word embeddings as the first layer . Scala val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = cnn , encoderOutputDim = 256) classNum : The number of text categories to be classified. Positive integer. embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. sequenceLength : The length of a sequence. Positive integer. Default is 500. encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\". encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256. See here for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction. Python text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256) class_num : The number of text categories to be classified. Positive int. embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. sequence_length : The length of a sequence. Positive int. Default is 500. encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'. encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256. See here for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction. Save Model After building and training a TextClassifier model, you can save it for future use. Scala textClassifier.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python text_classifier.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False. Load Model To load a TextClassifier model (with weights) saved above : Scala TextClassifier.loadModel(path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python TextClassifier.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Text Classification"},{"location":"APIGuide/Models/text-classification/#build-a-textclassifier-model","text":"You can call the following API in Scala and Python respectively to create a TextClassifier with pre-trained GloVe word embeddings as the first layer . Scala val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = cnn , encoderOutputDim = 256) classNum : The number of text categories to be classified. Positive integer. embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. sequenceLength : The length of a sequence. Positive integer. Default is 500. encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\". encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256. See here for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction. Python text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256) class_num : The number of text categories to be classified. Positive int. embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. sequence_length : The length of a sequence. Positive int. Default is 500. encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'. encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256. See here for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.","title":"Build a TextClassifier Model"},{"location":"APIGuide/Models/text-classification/#save-model","text":"After building and training a TextClassifier model, you can save it for future use. Scala textClassifier.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python text_classifier.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False.","title":"Save Model"},{"location":"APIGuide/Models/text-classification/#load-model","text":"To load a TextClassifier model (with weights) saved above : Scala TextClassifier.loadModel(path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python TextClassifier.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Load Model"},{"location":"APIGuide/Models/text-matching/","text":"Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering). For training, you can use Keras-Style API methods or alternatively feed the model into NNFrames and BigDL Optimizer. More text matching models will be supported in the future. Build a KNRM Model Kernel-pooling Neural Ranking Model with RBF kernel. See here for more details. You can call the following API in Scala and Python respectively to create a KNRM with pre-trained GloVe word embeddings . Scala val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = ranking ) text1Length : Sequence length of text1 (query). text2Length : Sequence length of text2 (doc). embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true. kernelNum : Integer 1. The number of kernels to use. Default is 21. sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1. exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. See here for the Scala example that trains a KNRM model on WikiQA dataset. Python knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking ) text1_length : Sequence length of text1 (query). text2_length : Sequence length of text2 (doc). embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. train_embed : Boolean. Whether to train the embedding layer or not. Default is True. kernel_num : Int 1. The number of kernels to use. Default is 21. sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1. exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. See here for the Python example that trains a KNRM model on WikiQA dataset. Save Model After building and training a KNRM model, you can save it for future use. Scala knrm.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python knrm.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False. Load Model To load a KNRM model (with weights) saved above : Scala KNRM.loadModel(path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python KNRM.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Text Matching"},{"location":"APIGuide/Models/text-matching/#build-a-knrm-model","text":"Kernel-pooling Neural Ranking Model with RBF kernel. See here for more details. You can call the following API in Scala and Python respectively to create a KNRM with pre-trained GloVe word embeddings . Scala val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = ranking ) text1Length : Sequence length of text1 (query). text2Length : Sequence length of text2 (doc). embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true. kernelNum : Integer 1. The number of kernels to use. Default is 21. sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1. exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. See here for the Scala example that trains a KNRM model on WikiQA dataset. Python knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking ) text1_length : Sequence length of text1 (query). text2_length : Sequence length of text2 (doc). embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. train_embed : Boolean. Whether to train the embedding layer or not. Default is True. kernel_num : Int 1. The number of kernels to use. Default is 21. sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1. exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. See here for the Python example that trains a KNRM model on WikiQA dataset.","title":"Build a KNRM Model"},{"location":"APIGuide/Models/text-matching/#save-model","text":"After building and training a KNRM model, you can save it for future use. Scala knrm.saveModel(path, weightPath = null, overWrite = false) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path to save weights. Default is null. overWrite : Whether to overwrite the file if it already exists. Default is false. Python knrm.save_model(path, weight_path=None, over_write=False) path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path to save weights. Default is None. over_write : Whether to overwrite the file if it already exists. Default is False.","title":"Save Model"},{"location":"APIGuide/Models/text-matching/#load-model","text":"To load a KNRM model (with weights) saved above : Scala KNRM.loadModel(path, weightPath = null) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any. Default is null. Python KNRM.load_model(path, weight_path=None) path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'. weight_path : The path for pre-trained weights if any. Default is None.","title":"Load Model"},{"location":"APIGuide/PipelineAPI/inference/","text":"Inference Model is a package in Analytics Zoo aiming to provide high-level APIs to speed-up development. It allows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Inference Model provides Java, Scala and Python interfaces. Highlights Easy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Support transformation of various input data type, thus supporting future prediction tasks. Transparently support the OpenVINO toolkit, which deliver a significant boost for inference speed ( up to 19.9x ). Basic usage of Inference Model: Directly use InferenceModel or write a subclass extends InferenceModel ( AbstractInferenceModel in Java). Load pre-trained models with corresponding load methods, e.g, doLoad for Analytics Zoo, and doLoadTF for TensorFlow. Do prediction with predict method. OpenVINO requirements: System requirements : Ubuntu 16.04.3 LTS (64 bit) Windows 10 (64 bit) CentOS 7.4 (64 bit) macOS 10.13, 10.14 (64 bit) Python requirements: tensorflow =1.2.0 networkx =1.11 numpy =1.12.0 protobuf==3.6.1 Supported models: Analytics Zoo Models Caffe Models TensorFlow Models OpenVINO models Load pre-trained model Load pre-trained Analytics Zoo model Load Analytics Zoo model with corresponding load methods ( load for Java and Python, doLoad for Scala). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.load(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoad(modelPath, weightPath) Python model = InferenceModel() model.load(modelPath, weightPath) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight. Default is null . Load pre-trained Caffe model Load Caffe model with loadCaffe methods ( loadCaffe for Java, doLoadCaffe for Scala and load_caffe Python). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadCaffe(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoadCaffe(modelPath, weightPath) Python model = InferenceModel() model.load_caffe(modelPath, weightPath) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight. Load TensorFlow model There are two backends to load a tensorflow model: TensorFlow and OpenVINO. When using TensorFlow as backend, tensorflow model will be loaded into FloatModel . Otherwise, it will be coverted into OpenVINO model, and loaded into OpenVINOModel . 1. Load with TensorFlow backend Load model into FloatModel with TensorFlow backend, with corresponding loadTF methods ( loadTF for Java, doLoadTF for Scala and load_tf Python) Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadTF(modelPath); Scala val model = new InferenceModel() model.doLoadTF(modelPath) Python model = InferenceModel() model.load_tf(modelPath) modelPath : String. Path of pre-trained model. 2. Load with OpenVINO backend Load model into OpenVINOModel with OpenVINO backend, with corresponding loadTF methods ( loadTF for Java, doLoadTF for Scala and load_tf Python). Note that OpenVINO cannot directly load TensorFlow models. We need to covert TensorFlow models into OpenVINO models , then load models into OpenVINO. Herein Analytics Zoo, we merge these two steps into one, and provide loadOpenVINOModelForTF with the following parameters: modelPath : String. Path of pre-trained tensorflow model. modelType : String. Type the type of the tensorflow model. checkpointPath : String. Path of the tensorflow checkpoint file inputShape : Array[Int]. Input shape that should be fed to an input node(s) of the model ifReverseInputChannels : Boolean. If need reverse input channels. switch the input channels order from RGB to BGR (or vice versa). meanValues : Array[Int]. All input values coming from original network inputs will be divided by this value. scale : Float. Scale value, to be used for the input image per channel. outputDir : String. Path of pre-trained tensorflow model. Note that we prepare several implementations with less parameters based on this method, e.g., loadTF(modelPath, modelType) . Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadTF(modelPath, modelType); Scala val model = new InferenceModel() model.doLoadTF(modelPath, modelType) Python model = InferenceModel() model.load_tf(modelPath, modelType) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight. Load OpenVINO model Load OpenVINO model with loadOpenVINO methods ( loadOpenVINO for Java, doLoadOpenVINO for Scala and load_openvino Python). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadOpenVINO(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoadOpenVINO(modelPath, weightPath) Python model = InferenceModel() model.load_openvino(modelPath, weightPath) modelPath : String. Path of pre-trained OpenVINO model. weightPath : String. Path of pre-trained OpenVINO model weight. Predict with loaded model After loading pre-trained models with load methods, we can make prediction with unified predict method. predictInput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Input data for prediction. JTensor is a 1D List, with Array[Int] shape. predictOutput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Prediction result. predict Do prediction with predict methods ( predict for Java and Python, doPredict for Scala). Java List List JTensor predictOutput = model.predict(predictInput); Scala val predictOutput = model.doPredict(predictInput) Python predict_output = model.predict(predict_input) predictInt8 and loadTFAsCalibratedOpenVINO Do prediction with int8 optimized model. Powered by VNNI and Intel Deep Learning Boost . Currently, this API is only for OpenVINO. For Analytics Zoo model, int8 optimized model can directly make prediction with predict method. To load an OpenVINO int8 optimized model from TensorFlow, we build loadTFAsCalibratedOpenVINO methods with 4 more parameters than loadOpenVINOModelForTF . networkType : String. Type of an inferred network, \"C\" to calibrate Classification, \"OD\" to calibrate Object Detection, \"RawC\" to collect only statistics for Classification, \"RawOD\" to collect only statistics for Object Detection. validationFilePath : String. Path to a file with validation images path and target labels. subset : Int. Number of pictures from the whole validation set to create the calibration dataset. opencvLibPath : String. lib path where libopencv_imgcodecs.so.4.0, libopencv_core.so.4.0 and libopencv_imgproc.so.4.0 can be found. Java List List JTensor predictOutput = model.predictInt8(predictInput); Scala val predictOutput = model.doPredictInt8(predictInput) Supportive classes InferenceModel doOptimizeTF method in Scala is designed for coverting TensorFlow model into OpenVINO model. doCalibrateTF method in Scala is designed for optimizing OpenVINO model into OpenVINO int8 optimized model. Pipline of these API: TensorFlow model - doOptimizeTF - OpenVINO model - doCalibrateTF - OpenVINO int8 optimized model InferenceSupportive InferenceSupportive is a trait containing several methods for type transformation, which transfer a model input to a valid data type, thus supporting future inference model prediction tasks. For example, method transferTensorToJTensor convert a model input of data type Tensor to JTensor , which will be the input for a FloatInferenceModel. AbstractModel AbstractModel is an abstract class to provide APIs for basic functions - predict interface for prediction, copy interface for coping the model into the queue of AbstractModels, release interface for releasing the model and isReleased interface for checking the state of model release. FloatModel FloatModel is an extending class of AbstractModel and achieves all AbstractModel interfaces. OpenVINOModel OpenVINOModel is an extending class of AbstractModel . It achieves all AbstractModel functions. InferenceModelFactory InferenceModelFactory is an object with APIs for loading pre-trained Analytics Zoo models, Caffe models, Tensorflow models and OpenVINO Intermediate Representations(IR). Analytics Zoo models, Caffe models, Tensorflow models can be loaded as FloatModels. The load result of it is a FloatModel Tensorflow models and OpenVINO Intermediate Representations(IR) can be loaded as OpenVINOModels. The load result of it is an OpenVINOModel . The load result of it is a FloatModel or an OpenVINOModel . OpenVinoInferenceSupportive OpenVinoInferenceSupportive is an extending object of InferenceSupportive and focuses on the implementation of loading pre-trained models, including tensorflow models and OpenVINO Intermediate Representations(IR).","title":"Inference"},{"location":"APIGuide/PipelineAPI/inference/#load-pre-trained-model","text":"","title":"Load pre-trained model"},{"location":"APIGuide/PipelineAPI/inference/#load-pre-trained-analytics-zoo-model","text":"Load Analytics Zoo model with corresponding load methods ( load for Java and Python, doLoad for Scala). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.load(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoad(modelPath, weightPath) Python model = InferenceModel() model.load(modelPath, weightPath) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight. Default is null .","title":"Load pre-trained Analytics Zoo model"},{"location":"APIGuide/PipelineAPI/inference/#load-pre-trained-caffe-model","text":"Load Caffe model with loadCaffe methods ( loadCaffe for Java, doLoadCaffe for Scala and load_caffe Python). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadCaffe(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoadCaffe(modelPath, weightPath) Python model = InferenceModel() model.load_caffe(modelPath, weightPath) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight.","title":"Load pre-trained Caffe model"},{"location":"APIGuide/PipelineAPI/inference/#load-tensorflow-model","text":"There are two backends to load a tensorflow model: TensorFlow and OpenVINO. When using TensorFlow as backend, tensorflow model will be loaded into FloatModel . Otherwise, it will be coverted into OpenVINO model, and loaded into OpenVINOModel . 1. Load with TensorFlow backend Load model into FloatModel with TensorFlow backend, with corresponding loadTF methods ( loadTF for Java, doLoadTF for Scala and load_tf Python) Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadTF(modelPath); Scala val model = new InferenceModel() model.doLoadTF(modelPath) Python model = InferenceModel() model.load_tf(modelPath) modelPath : String. Path of pre-trained model. 2. Load with OpenVINO backend Load model into OpenVINOModel with OpenVINO backend, with corresponding loadTF methods ( loadTF for Java, doLoadTF for Scala and load_tf Python). Note that OpenVINO cannot directly load TensorFlow models. We need to covert TensorFlow models into OpenVINO models , then load models into OpenVINO. Herein Analytics Zoo, we merge these two steps into one, and provide loadOpenVINOModelForTF with the following parameters: modelPath : String. Path of pre-trained tensorflow model. modelType : String. Type the type of the tensorflow model. checkpointPath : String. Path of the tensorflow checkpoint file inputShape : Array[Int]. Input shape that should be fed to an input node(s) of the model ifReverseInputChannels : Boolean. If need reverse input channels. switch the input channels order from RGB to BGR (or vice versa). meanValues : Array[Int]. All input values coming from original network inputs will be divided by this value. scale : Float. Scale value, to be used for the input image per channel. outputDir : String. Path of pre-trained tensorflow model. Note that we prepare several implementations with less parameters based on this method, e.g., loadTF(modelPath, modelType) . Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadTF(modelPath, modelType); Scala val model = new InferenceModel() model.doLoadTF(modelPath, modelType) Python model = InferenceModel() model.load_tf(modelPath, modelType) modelPath : String. Path of pre-trained model. weightPath : String. Path of pre-trained model weight.","title":"Load TensorFlow model"},{"location":"APIGuide/PipelineAPI/inference/#load-openvino-model","text":"Load OpenVINO model with loadOpenVINO methods ( loadOpenVINO for Java, doLoadOpenVINO for Scala and load_openvino Python). Java public class ExtendedInferenceModel extends AbstractInferenceModel { } ExtendedInferenceModel model = new ExtendedInferenceModel(); model.loadOpenVINO(modelPath, weightPath); Scala val model = new InferenceModel() model.doLoadOpenVINO(modelPath, weightPath) Python model = InferenceModel() model.load_openvino(modelPath, weightPath) modelPath : String. Path of pre-trained OpenVINO model. weightPath : String. Path of pre-trained OpenVINO model weight.","title":"Load OpenVINO model"},{"location":"APIGuide/PipelineAPI/inference/#predict-with-loaded-model","text":"After loading pre-trained models with load methods, we can make prediction with unified predict method. predictInput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Input data for prediction. JTensor is a 1D List, with Array[Int] shape. predictOutput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Prediction result.","title":"Predict with loaded model"},{"location":"APIGuide/PipelineAPI/inference/#predict","text":"Do prediction with predict methods ( predict for Java and Python, doPredict for Scala). Java List List JTensor predictOutput = model.predict(predictInput); Scala val predictOutput = model.doPredict(predictInput) Python predict_output = model.predict(predict_input)","title":"predict"},{"location":"APIGuide/PipelineAPI/inference/#predictint8-and-loadtfascalibratedopenvino","text":"Do prediction with int8 optimized model. Powered by VNNI and Intel Deep Learning Boost . Currently, this API is only for OpenVINO. For Analytics Zoo model, int8 optimized model can directly make prediction with predict method. To load an OpenVINO int8 optimized model from TensorFlow, we build loadTFAsCalibratedOpenVINO methods with 4 more parameters than loadOpenVINOModelForTF . networkType : String. Type of an inferred network, \"C\" to calibrate Classification, \"OD\" to calibrate Object Detection, \"RawC\" to collect only statistics for Classification, \"RawOD\" to collect only statistics for Object Detection. validationFilePath : String. Path to a file with validation images path and target labels. subset : Int. Number of pictures from the whole validation set to create the calibration dataset. opencvLibPath : String. lib path where libopencv_imgcodecs.so.4.0, libopencv_core.so.4.0 and libopencv_imgproc.so.4.0 can be found. Java List List JTensor predictOutput = model.predictInt8(predictInput); Scala val predictOutput = model.doPredictInt8(predictInput)","title":"predictInt8 and loadTFAsCalibratedOpenVINO"},{"location":"APIGuide/PipelineAPI/inference/#supportive-classes","text":"InferenceModel doOptimizeTF method in Scala is designed for coverting TensorFlow model into OpenVINO model. doCalibrateTF method in Scala is designed for optimizing OpenVINO model into OpenVINO int8 optimized model. Pipline of these API: TensorFlow model - doOptimizeTF - OpenVINO model - doCalibrateTF - OpenVINO int8 optimized model InferenceSupportive InferenceSupportive is a trait containing several methods for type transformation, which transfer a model input to a valid data type, thus supporting future inference model prediction tasks. For example, method transferTensorToJTensor convert a model input of data type Tensor to JTensor , which will be the input for a FloatInferenceModel. AbstractModel AbstractModel is an abstract class to provide APIs for basic functions - predict interface for prediction, copy interface for coping the model into the queue of AbstractModels, release interface for releasing the model and isReleased interface for checking the state of model release. FloatModel FloatModel is an extending class of AbstractModel and achieves all AbstractModel interfaces. OpenVINOModel OpenVINOModel is an extending class of AbstractModel . It achieves all AbstractModel functions. InferenceModelFactory InferenceModelFactory is an object with APIs for loading pre-trained Analytics Zoo models, Caffe models, Tensorflow models and OpenVINO Intermediate Representations(IR). Analytics Zoo models, Caffe models, Tensorflow models can be loaded as FloatModels. The load result of it is a FloatModel Tensorflow models and OpenVINO Intermediate Representations(IR) can be loaded as OpenVINOModels. The load result of it is an OpenVINOModel . The load result of it is a FloatModel or an OpenVINOModel . OpenVinoInferenceSupportive OpenVinoInferenceSupportive is an extending object of InferenceSupportive and focuses on the implementation of loading pre-trained models, including tensorflow models and OpenVINO Intermediate Representations(IR).","title":"Supportive classes"},{"location":"APIGuide/PipelineAPI/math/","text":"mean Mean of a Variable , alongside the specified axis. - axis axis to compute the mean. 0-based indexed. - keepDims A boolean, whether to keep the dimensions or not. If keepDims is False , the rank of the Variable is reduced by 1. If keepDims is True , the reduced dimensions are retained with length 1. Scala example mean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false) Python example mean(x, axis=0, keepDims=False): abs Element-wise absolute value. - x A Variable . Scala example abs(x: Variable[T]) Python example abs(x): sum Sum of the values in a Variable , alongside the specified axis. - axis axis to compute the mean. 0-based indexed. - keepDims A boolean, whether to keep the dimensions or not. If keepDims is False , the rank of the Variable is reduced by 1. If keepDims is True , the reduced dimensions are retained with length 1. Scala example sum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false) Python example sum(x, axis=0, keepDims=False): clip Element-wise value clipping. - x A Variable . - min Double - max Double Scala example clip(x: Variable[T], min: Double, max: Double) Python example clip(x, min, max) square Element-wise square. - x A Variable . Scala example square(x: Variable[T]) Python example square(x): sqrt Element-wise square root. - x A Variable . Scala example sqrt(x: Variable[T]) Python example sqrt(x): maximum Element-wise maximum of two Variables . - x A Variable . - y A Variable or Double. Scala example maximum(x: Variable[T], y: Variable[T]) Python example maximum(x, y): log Element-wise log. - x A Variable . Scala example log(x: Variable[T]) Python example log(x): exp Element-wise exponential. - x A Variable . Scala example exp(x: Variable[T]) Python example exp(x): pow Element-wise exponentiation. - x A Variable . - a Double. Scala example pow(x: Variable[T]) Python example pow(x): softsign Softsign of a Variable . Scala example softsign(x: Variable[T]) Python example softsign(x): softplus Softplus of a Variable . Scala example softplus(x: Variable[T]) Python example softplus(x): stack Stacks a list of rank R tensors into a rank R+1 tensor. You should start from 1 as dim 0 is for batch. - inputs: List of variables (tensors) - axis: xis along which to perform stacking. Scala example def stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1) Python example def stack(inputs, axis=1) expand_dims Adds a 1-sized dimension at index \"axis\". Scala example def expandDims[T: ClassTag](x: Variable[T], axis: Int) Python example expand_dims(x, axis) contiguous Turn the output and grad to be contiguous for the input Variable Scala example def contiguous[T: ClassTag](input: Variable[T]) Python example def contiguous(x) mm Module to perform matrix multiplication on two mini-batch inputs, producing a mini-batch. - x A variable. - y A variable. - axes Axes along which to perform multiplication. Scala example def mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int]) Python example def mm(x, y, axes) batch_dot Operator that computes a dot product between samples in two tensors. - x Shape should only be [batch, xx] - y Shape should only be [batch, xx] - axes Integer or tuple of integers, axis or axes along which to take the dot product. - normalize Whether to L2-normalize samples along the dot product axis before taking the dot product. If set to True, then the output of the dot product is the cosine proximity between the two samples. Scala example def batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false) Python example def batch_dot(x, y, axes=1, normalize=False) l2_normalize Normalizes a tensor wrt the L2 norm alongside the specified axis. - x A variable. - axis Axis along which to perform normalization. Scala example def l2Normalize[T: ClassTag](x: Variable[T], axis: Int) Python example def l2_normalize(x, axis)","title":"Autograd-Math"},{"location":"APIGuide/PipelineAPI/math/#mean","text":"Mean of a Variable , alongside the specified axis. - axis axis to compute the mean. 0-based indexed. - keepDims A boolean, whether to keep the dimensions or not. If keepDims is False , the rank of the Variable is reduced by 1. If keepDims is True , the reduced dimensions are retained with length 1. Scala example mean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false) Python example mean(x, axis=0, keepDims=False):","title":"mean"},{"location":"APIGuide/PipelineAPI/math/#abs","text":"Element-wise absolute value. - x A Variable . Scala example abs(x: Variable[T]) Python example abs(x):","title":"abs"},{"location":"APIGuide/PipelineAPI/math/#sum","text":"Sum of the values in a Variable , alongside the specified axis. - axis axis to compute the mean. 0-based indexed. - keepDims A boolean, whether to keep the dimensions or not. If keepDims is False , the rank of the Variable is reduced by 1. If keepDims is True , the reduced dimensions are retained with length 1. Scala example sum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false) Python example sum(x, axis=0, keepDims=False):","title":"sum"},{"location":"APIGuide/PipelineAPI/math/#clip","text":"Element-wise value clipping. - x A Variable . - min Double - max Double Scala example clip(x: Variable[T], min: Double, max: Double) Python example clip(x, min, max)","title":"clip"},{"location":"APIGuide/PipelineAPI/math/#square","text":"Element-wise square. - x A Variable . Scala example square(x: Variable[T]) Python example square(x):","title":"square"},{"location":"APIGuide/PipelineAPI/math/#sqrt","text":"Element-wise square root. - x A Variable . Scala example sqrt(x: Variable[T]) Python example sqrt(x):","title":"sqrt"},{"location":"APIGuide/PipelineAPI/math/#maximum","text":"Element-wise maximum of two Variables . - x A Variable . - y A Variable or Double. Scala example maximum(x: Variable[T], y: Variable[T]) Python example maximum(x, y):","title":"maximum"},{"location":"APIGuide/PipelineAPI/math/#log","text":"Element-wise log. - x A Variable . Scala example log(x: Variable[T]) Python example log(x):","title":"log"},{"location":"APIGuide/PipelineAPI/math/#exp","text":"Element-wise exponential. - x A Variable . Scala example exp(x: Variable[T]) Python example exp(x):","title":"exp"},{"location":"APIGuide/PipelineAPI/math/#pow","text":"Element-wise exponentiation. - x A Variable . - a Double. Scala example pow(x: Variable[T]) Python example pow(x):","title":"pow"},{"location":"APIGuide/PipelineAPI/math/#softsign","text":"Softsign of a Variable . Scala example softsign(x: Variable[T]) Python example softsign(x):","title":"softsign"},{"location":"APIGuide/PipelineAPI/math/#softplus","text":"Softplus of a Variable . Scala example softplus(x: Variable[T]) Python example softplus(x):","title":"softplus"},{"location":"APIGuide/PipelineAPI/math/#stack","text":"Stacks a list of rank R tensors into a rank R+1 tensor. You should start from 1 as dim 0 is for batch. - inputs: List of variables (tensors) - axis: xis along which to perform stacking. Scala example def stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1) Python example def stack(inputs, axis=1)","title":"stack"},{"location":"APIGuide/PipelineAPI/math/#expand_dims","text":"Adds a 1-sized dimension at index \"axis\". Scala example def expandDims[T: ClassTag](x: Variable[T], axis: Int) Python example expand_dims(x, axis)","title":"expand_dims"},{"location":"APIGuide/PipelineAPI/math/#contiguous","text":"Turn the output and grad to be contiguous for the input Variable Scala example def contiguous[T: ClassTag](input: Variable[T]) Python example def contiguous(x)","title":"contiguous"},{"location":"APIGuide/PipelineAPI/math/#mm","text":"Module to perform matrix multiplication on two mini-batch inputs, producing a mini-batch. - x A variable. - y A variable. - axes Axes along which to perform multiplication. Scala example def mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int]) Python example def mm(x, y, axes)","title":"mm"},{"location":"APIGuide/PipelineAPI/math/#batch_dot","text":"Operator that computes a dot product between samples in two tensors. - x Shape should only be [batch, xx] - y Shape should only be [batch, xx] - axes Integer or tuple of integers, axis or axes along which to take the dot product. - normalize Whether to L2-normalize samples along the dot product axis before taking the dot product. If set to True, then the output of the dot product is the cosine proximity between the two samples. Scala example def batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false) Python example def batch_dot(x, y, axes=1, normalize=False)","title":"batch_dot"},{"location":"APIGuide/PipelineAPI/math/#l2_normalize","text":"Normalizes a tensor wrt the L2 norm alongside the specified axis. - x A variable. - axis Axis along which to perform normalization. Scala example def l2Normalize[T: ClassTag](x: Variable[T], axis: Int) Python example def l2_normalize(x, axis)","title":"l2_normalize"},{"location":"APIGuide/PipelineAPI/net/","text":"Net Load Analytics Zoo Model Use Net.load (in Scala) or Net.load (in Python) to load an existing model defined using the Analytics Zoo Keras-style API. Net (Scala) or Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose. Scala example val model = Net.load( /tmp/model.def , /tmp/model.weights ) //load from local fs val model = Net.load( hdfs://... ) //load from hdfs val model = Net.load( s3://... ) //load from s3 Python example model = Net.load( /tmp/model.def , /tmp/model.weights ) //load from local fs model = Net.load( hdfs://... ) //load from hdfs model = Net.load( s3://... ) //load from s3 Load BigDL Model Scala example val model = Net.loadBigDL( /tmp/model.def , /tmp/model.weights ) //load from local fs val model = Net.loadBigDL( hdfs://... ) //load from hdfs val model = Net.loadBigDL( s3://... ) //load from s3 Python example model = Net.loadBigDL( /tmp/model.def , /tmp/model.weights ) //load from local fs model = Net.loadBigDL( hdfs://... ) //load from hdfs model = Net.loadBigDL( s3://... ) //load from s3 Load Torch Model Scala example val model = Net.loadTorch( /tmp/torch_model ) //load from local fs val model = Net.loadTorch( hdfs://... ) //load from hdfs val model = Net.loadTorch( s3://... ) //load from s3 Python example model = Net.loadTorch( /tmp/torch_model ) //load from local fs model = Net.loadTorch( hdfs://... ) //load from hdfs model = Net.loadTorch( s3://... ) //load from s3 Load Caffe Model Scala example val model = Net.loadCaffe( /tmp/def/path , /tmp/model/path ) //load from local fs val model = Net.loadCaffe( hdfs://def/path , hdfs://model/path ) //load from hdfs val model = Net.loadCaffe( s3://def/path , s3://model/path ) //load from s3 Python example model = Net.loadCaffe( /tmp/def/path , /tmp/model/path ) //load from local fs model = Net.loadCaffe( hdfs://def/path , hdfs://model/path ) //load from hdfs model = Net.loadCaffe( s3://def/path , s3://model/path ) //load from s3 Load TensorFlow model We also provides utilities to load tensorflow model. If we already have a frozen graph protobuf file, we can use the loadTF api directly to load the tensorflow model. Otherwise, we should first use the export_tf_checkpoint.py script provided by BigDL's distribution package, or the dump_model function defined in here to generate the model definition file ( model.pb ) and variable binary file ( model.bin ). Use Script GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta CKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt SAVE_PATH=/tmp/model/ python export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH Use python function import tensorflow as tf # This is your model definition. xs = tf.placeholder(tf.float32, [None, 1]) W1 = tf.Variable(tf.zeros([1,10])+0.2) b1 = tf.Variable(tf.zeros([10])+0.1) Wx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1) output = tf.nn.tanh(Wx_plus_b1, name= output ) # Adding the following lines right after your model definition from bigdl.util.tf_utils import dump_model dump_model_path = /tmp/model # This line of code will create a Session and initialized all the Variable and # save the model definition and variable to dump_model_path as BigDL readable format. dump_model(path=dump_model_path) Then we can use the loadTF api to load the tensorflow model into BigDL. Scala example val modelPath = /tmp/model/model.pb val binPath = /tmp/model/model.bin val inputs = Seq( Placeholder ) val outputs = Seq( output ) // For tensorflow frozen graph or graph without Variables val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN) // For tensorflow graph with Variables val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath)) Python example model_def = /tmp/model/model.pb model_variable = /tmp/model/model.bin inputs = [ Placeholder ] outputs = [ output ] # For tensorflow frozen graph or graph without Variables model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = little_endian , bigdl_type= float ) # For tensorflow graph with Variables model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = little_endian , bigdl_type= float , bin_file=model_variable) TFNet TFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel. The difference between Net.loadTF() is that TFNet will call tensorflow's java api to do the computation. TFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model. When used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient from TFNet is set to zero. Note : This feature currently supports tensorflow 1.10 and requires the OS to be one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Export TensorFlow model to frozen inference graph Analytics-zoo provides a useful utility function, export_tf , to export a TensorFlow model to frozen inference graph. For example: Python: import tensorflow as tf from nets import inception slim = tf.contrib.slim images = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3)) with slim.arg_scope(inception.inception_v1_arg_scope()): logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False) sess = tf.Session() saver = tf.train.Saver() saver.restore(sess, /tmp/models/inception_v1.ckpt ) from zoo.util.tf import export_tf export_tf(sess, /tmp/models/tfnet , inputs=[images], outputs=[logits]) In the above code, the export_tf utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names. Creating a TFNet After we have export the TensorFlow model, we can easily create a TFNet. Scala: val m = TFNet( /tmp/models/tfnet ) Python: m = TFNet.from_export_folder( /tmp/models/tfnet ) Please refer to TFNet Object Detection Example (Scala) or TFNet Object Detection Example (Python) and the Image Classification Using TFNet Notebook for more information. TFDataset TFDatset represents a distributed collection of elements to be feed into TensorFlow graph. TFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing the tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the TFOptimizer or TFPredictor. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Methods from_rdd Create a TFDataset from a rdd, each element of the rdd must be a list of numpy.ndarray. Python from_rdd(rdd, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_rdd=None) Arguments rdd : a rdd of list of numpy.ndarray each representing a tensor to feed into tensorflow graph on each iteration features : the structure of input features, should one the following: a tuple (dtype, shape), e.g. (tf.float32, [28, 28, 1]) a list of such tuple [(dtype1, shape1), (dtype2, shape2)], e.g. [(tf.float32, [10]), (tf.float32, [20])], a dict of such tuple, mapping string names to tuple {\"name\": (dtype, shape}, e.g. {\"input1\":(tf.float32, [10]), \"input2\": (tf.float32, [20])} labels : the structure of input labels, format is the same as features batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. val_rdd : validation data with the same structure of rdd from_ndarrays Create a TFDataset from a nested structure of numpy ndarrays. Each element in the resulting TFDataset has the same structure of the argument tensors and is created by indexing on the first dimension of each ndarray in the tensors argument. This method is equivalent to sc.parallize the tensors and call TFDataset.from_rdd Python from_ndarrays(tensors, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_tensors=None) Arguments tensors : the numpy ndarrays batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. val_tensors : the numpy ndarrays used for validation during training from_image_set Create a TFDataset from a ImagetSet. Each ImageFeature in the ImageSet should already has the \"sample\" field, i.e. the result of ImageSetToSample transformer Python from_image_set(image_set, image, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None) Arguments image_set : the ImageSet used to create this TFDataset image : a tuple of two, the first element is the type of image, the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])) label : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])) batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_image_set : the ImageSet used for validation during training from_text_set Create a TFDataset from a TextSet. The TextSet must be transformed to Sample, i.e. the result of TextFeatureToSample transformer. Python from_text_set(text_set, text, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None) Arguments text_set : the TextSet used to create this TFDataset text : a tuple of two, the first element is the type of this input feature, the second element is the shape of this element, i.e. (tf.float32, [10, 100, 4])). text can also be nested structure of this tuple of two. label : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of this tuple of two. batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_image_set : The TextSet used for validation during training from_feature_set Create a TFDataset from a FeatureSet. Currently, the element in this Feature set must be a ImageFeature that has a sample field, i.e. the result of ImageSetToSample transformer Python from_feature_set(dataset, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None) Arguments dataset : the feature set used to create this TFDataset features : a tuple of two, the first element is the type of this input feature, the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])). text can also be nested structure of this tuple of two. labels : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of this tuple of two. batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_dataset : The FeatureSet used for validation during training TFOptimizer TFOptimizer is the class that does all the hard work in distributed training, such as model distribution and parameter synchronization. There are two ways to create a TFOptimizer. The from_loss API takes the loss (a scalar tensor) as input and runs stochastic gradient descent using the given optimMethod on all the Variables that contributing to this loss. The from_keras API takes a compiled Keras Model and a TFDataset and runs stochastic gradient descent using the loss function, optimizer and metrics specified by the Keras model. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Python loss = ... optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.optimize(end_trigger=MaxEpoch(5)) For Keras model: model = Model(inputs=..., outputs=...) model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy']) optimizer = TFOptimizer.from_keras(model, dataset) optimizer.optimize(end_trigger=MaxEpoch(5)) TFPredictor TFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the model prediction for the corresponding input elements. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Python logist = ... predictor = TFPredictor.from_outputs(sess, [logits]) predictions_rdd = predictor.predict() For Keras model: model = Model(inputs=..., outputs=...) model.load_weights( /tmp/mnist_keras.h5 ) predictor = TFPredictor.from_keras(model, dataset) predictions_rdd = predictor.predict()","title":"Net"},{"location":"APIGuide/PipelineAPI/net/#net","text":"","title":"Net"},{"location":"APIGuide/PipelineAPI/net/#load-analytics-zoo-model","text":"Use Net.load (in Scala) or Net.load (in Python) to load an existing model defined using the Analytics Zoo Keras-style API. Net (Scala) or Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose. Scala example val model = Net.load( /tmp/model.def , /tmp/model.weights ) //load from local fs val model = Net.load( hdfs://... ) //load from hdfs val model = Net.load( s3://... ) //load from s3 Python example model = Net.load( /tmp/model.def , /tmp/model.weights ) //load from local fs model = Net.load( hdfs://... ) //load from hdfs model = Net.load( s3://... ) //load from s3","title":"Load Analytics Zoo Model"},{"location":"APIGuide/PipelineAPI/net/#load-bigdl-model","text":"Scala example val model = Net.loadBigDL( /tmp/model.def , /tmp/model.weights ) //load from local fs val model = Net.loadBigDL( hdfs://... ) //load from hdfs val model = Net.loadBigDL( s3://... ) //load from s3 Python example model = Net.loadBigDL( /tmp/model.def , /tmp/model.weights ) //load from local fs model = Net.loadBigDL( hdfs://... ) //load from hdfs model = Net.loadBigDL( s3://... ) //load from s3","title":"Load BigDL Model"},{"location":"APIGuide/PipelineAPI/net/#load-torch-model","text":"Scala example val model = Net.loadTorch( /tmp/torch_model ) //load from local fs val model = Net.loadTorch( hdfs://... ) //load from hdfs val model = Net.loadTorch( s3://... ) //load from s3 Python example model = Net.loadTorch( /tmp/torch_model ) //load from local fs model = Net.loadTorch( hdfs://... ) //load from hdfs model = Net.loadTorch( s3://... ) //load from s3","title":"Load Torch Model"},{"location":"APIGuide/PipelineAPI/net/#load-caffe-model","text":"Scala example val model = Net.loadCaffe( /tmp/def/path , /tmp/model/path ) //load from local fs val model = Net.loadCaffe( hdfs://def/path , hdfs://model/path ) //load from hdfs val model = Net.loadCaffe( s3://def/path , s3://model/path ) //load from s3 Python example model = Net.loadCaffe( /tmp/def/path , /tmp/model/path ) //load from local fs model = Net.loadCaffe( hdfs://def/path , hdfs://model/path ) //load from hdfs model = Net.loadCaffe( s3://def/path , s3://model/path ) //load from s3","title":"Load Caffe Model"},{"location":"APIGuide/PipelineAPI/net/#load-tensorflow-model","text":"We also provides utilities to load tensorflow model. If we already have a frozen graph protobuf file, we can use the loadTF api directly to load the tensorflow model. Otherwise, we should first use the export_tf_checkpoint.py script provided by BigDL's distribution package, or the dump_model function defined in here to generate the model definition file ( model.pb ) and variable binary file ( model.bin ). Use Script GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta CKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt SAVE_PATH=/tmp/model/ python export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH Use python function import tensorflow as tf # This is your model definition. xs = tf.placeholder(tf.float32, [None, 1]) W1 = tf.Variable(tf.zeros([1,10])+0.2) b1 = tf.Variable(tf.zeros([10])+0.1) Wx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1) output = tf.nn.tanh(Wx_plus_b1, name= output ) # Adding the following lines right after your model definition from bigdl.util.tf_utils import dump_model dump_model_path = /tmp/model # This line of code will create a Session and initialized all the Variable and # save the model definition and variable to dump_model_path as BigDL readable format. dump_model(path=dump_model_path) Then we can use the loadTF api to load the tensorflow model into BigDL. Scala example val modelPath = /tmp/model/model.pb val binPath = /tmp/model/model.bin val inputs = Seq( Placeholder ) val outputs = Seq( output ) // For tensorflow frozen graph or graph without Variables val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN) // For tensorflow graph with Variables val model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath)) Python example model_def = /tmp/model/model.pb model_variable = /tmp/model/model.bin inputs = [ Placeholder ] outputs = [ output ] # For tensorflow frozen graph or graph without Variables model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = little_endian , bigdl_type= float ) # For tensorflow graph with Variables model = Net.load_tensorflow(model_def, inputs, outputs, byte_order = little_endian , bigdl_type= float , bin_file=model_variable)","title":"Load TensorFlow model"},{"location":"APIGuide/PipelineAPI/net/#tfnet","text":"TFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel. The difference between Net.loadTF() is that TFNet will call tensorflow's java api to do the computation. TFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model. When used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient from TFNet is set to zero. Note : This feature currently supports tensorflow 1.10 and requires the OS to be one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here .","title":"TFNet"},{"location":"APIGuide/PipelineAPI/net/#export-tensorflow-model-to-frozen-inference-graph","text":"Analytics-zoo provides a useful utility function, export_tf , to export a TensorFlow model to frozen inference graph. For example: Python: import tensorflow as tf from nets import inception slim = tf.contrib.slim images = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3)) with slim.arg_scope(inception.inception_v1_arg_scope()): logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False) sess = tf.Session() saver = tf.train.Saver() saver.restore(sess, /tmp/models/inception_v1.ckpt ) from zoo.util.tf import export_tf export_tf(sess, /tmp/models/tfnet , inputs=[images], outputs=[logits]) In the above code, the export_tf utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names.","title":"Export TensorFlow model to frozen inference graph"},{"location":"APIGuide/PipelineAPI/net/#creating-a-tfnet","text":"After we have export the TensorFlow model, we can easily create a TFNet. Scala: val m = TFNet( /tmp/models/tfnet ) Python: m = TFNet.from_export_folder( /tmp/models/tfnet ) Please refer to TFNet Object Detection Example (Scala) or TFNet Object Detection Example (Python) and the Image Classification Using TFNet Notebook for more information.","title":"Creating a TFNet"},{"location":"APIGuide/PipelineAPI/net/#tfdataset","text":"TFDatset represents a distributed collection of elements to be feed into TensorFlow graph. TFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing the tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the TFOptimizer or TFPredictor. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here .","title":"TFDataset"},{"location":"APIGuide/PipelineAPI/net/#methods","text":"","title":"Methods"},{"location":"APIGuide/PipelineAPI/net/#from_rdd","text":"Create a TFDataset from a rdd, each element of the rdd must be a list of numpy.ndarray. Python from_rdd(rdd, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_rdd=None) Arguments rdd : a rdd of list of numpy.ndarray each representing a tensor to feed into tensorflow graph on each iteration features : the structure of input features, should one the following: a tuple (dtype, shape), e.g. (tf.float32, [28, 28, 1]) a list of such tuple [(dtype1, shape1), (dtype2, shape2)], e.g. [(tf.float32, [10]), (tf.float32, [20])], a dict of such tuple, mapping string names to tuple {\"name\": (dtype, shape}, e.g. {\"input1\":(tf.float32, [10]), \"input2\": (tf.float32, [20])} labels : the structure of input labels, format is the same as features batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. val_rdd : validation data with the same structure of rdd","title":"from_rdd"},{"location":"APIGuide/PipelineAPI/net/#from_ndarrays","text":"Create a TFDataset from a nested structure of numpy ndarrays. Each element in the resulting TFDataset has the same structure of the argument tensors and is created by indexing on the first dimension of each ndarray in the tensors argument. This method is equivalent to sc.parallize the tensors and call TFDataset.from_rdd Python from_ndarrays(tensors, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_tensors=None) Arguments tensors : the numpy ndarrays batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. val_tensors : the numpy ndarrays used for validation during training","title":"from_ndarrays"},{"location":"APIGuide/PipelineAPI/net/#from_image_set","text":"Create a TFDataset from a ImagetSet. Each ImageFeature in the ImageSet should already has the \"sample\" field, i.e. the result of ImageSetToSample transformer Python from_image_set(image_set, image, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None) Arguments image_set : the ImageSet used to create this TFDataset image : a tuple of two, the first element is the type of image, the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])) label : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])) batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_image_set : the ImageSet used for validation during training","title":"from_image_set"},{"location":"APIGuide/PipelineAPI/net/#from_text_set","text":"Create a TFDataset from a TextSet. The TextSet must be transformed to Sample, i.e. the result of TextFeatureToSample transformer. Python from_text_set(text_set, text, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None) Arguments text_set : the TextSet used to create this TFDataset text : a tuple of two, the first element is the type of this input feature, the second element is the shape of this element, i.e. (tf.float32, [10, 100, 4])). text can also be nested structure of this tuple of two. label : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of this tuple of two. batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_image_set : The TextSet used for validation during training","title":"from_text_set"},{"location":"APIGuide/PipelineAPI/net/#from_feature_set","text":"Create a TFDataset from a FeatureSet. Currently, the element in this Feature set must be a ImageFeature that has a sample field, i.e. the result of ImageSetToSample transformer Python from_feature_set(dataset, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None) Arguments dataset : the feature set used to create this TFDataset features : a tuple of two, the first element is the type of this input feature, the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])). text can also be nested structure of this tuple of two. labels : a tuple of two, the first element is the type of label, the second element is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of this tuple of two. batch_size : the batch size, used for training, should be a multiple of total core num batch_per_thread : the batch size for each thread, used for inference or evaluation hard_code_batch_size : whether to hard code the batch_size into tensorflow graph, if True, the static size of the first dimension of the resulting tensors is batch_size/total_core_num (training) or batch_per_thread for inference; if False, it is None. validation_dataset : The FeatureSet used for validation during training","title":"from_feature_set"},{"location":"APIGuide/PipelineAPI/net/#tfoptimizer","text":"TFOptimizer is the class that does all the hard work in distributed training, such as model distribution and parameter synchronization. There are two ways to create a TFOptimizer. The from_loss API takes the loss (a scalar tensor) as input and runs stochastic gradient descent using the given optimMethod on all the Variables that contributing to this loss. The from_keras API takes a compiled Keras Model and a TFDataset and runs stochastic gradient descent using the loss function, optimizer and metrics specified by the Keras model. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Python loss = ... optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.optimize(end_trigger=MaxEpoch(5)) For Keras model: model = Model(inputs=..., outputs=...) model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy']) optimizer = TFOptimizer.from_keras(model, dataset) optimizer.optimize(end_trigger=MaxEpoch(5))","title":"TFOptimizer"},{"location":"APIGuide/PipelineAPI/net/#tfpredictor","text":"TFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the model prediction for the corresponding input elements. Note : This feature currently requires tensorflow 1.10 and OS is one of the following 64-bit systems. Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . Python logist = ... predictor = TFPredictor.from_outputs(sess, [logits]) predictions_rdd = predictor.predict() For Keras model: model = Model(inputs=..., outputs=...) model.load_weights( /tmp/mnist_keras.h5 ) predictor = TFPredictor.from_keras(model, dataset) predictions_rdd = predictor.predict()","title":"TFPredictor"},{"location":"APIGuide/PipelineAPI/nnframes/","text":"NNEstimator Scala: val estimator = NNEstimator(model, criterion) Python: estimator = NNEstimator(model, criterion) NNEstimator extends org.apache.spark.ml.Estimator and supports training a BigDL model with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline to allow users to combine the components of BigDL and Spark MLlib. NNEstimator supports different feature and label data types through Preprocessing . During fit (training), NNEstimator will extract feature and label data from input DataFrame and use the Preprocessing to convert data for the model, typically converts the feature and label to Tensors or converts the (feature, option[Label]) tuple to a BigDL Sample . Each Preprocessing conducts a data conversion step in the preprocessing phase, multiple Preprocessing can be combined into a ChainedPreprocessing . Some pre-defined Preprocessing for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized Preprocessing . By default, SeqToTensor is used to convert an array or Vector to a 1-dimension Tensor. Using the Preprocessing allows NNEstimator to cache only the raw data and decrease the memory consumption during feature conversion and training, it also enables the model to digest extra data types that DataFrame does not support currently. More concrete examples are available in package com.intel.analytics.zoo.examples.nnframes NNEstimator can be created with various parameters for different scenarios. 1. NNEstimator(model, criterion) Takes only model and criterion and use SeqToTensor as feature and label Preprocessing . NNEstimator will extract the data from feature and label columns ( only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to 1-dimension Tensor. The tensors will be combined into BigDL Sample and send to model for training. 2. NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int]) Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). NNEstimator will extract the data from feature and label columns (only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to Tensor according to the specified Tensor size. 3. NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]], labelPreprocessing: Preprocessing[F, Tensor[T]]) Takes model, criterion, featurePreprocessing and labelPreprocessing. NNEstimator will extract the data from feature and label columns and convert each feature/label to Tensor with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNEstimator supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]]) to directly compose Sample according to user-specified Preprocessing. Scala Example: import com.intel.analytics.bigdl.nn._ import com.intel.analytics.zoo.pipeline.nnframes.NNEstimator import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat val model = Sequential().add(Linear(2, 2)) val criterion = MSECriterion() val estimator = NNEstimator(model, criterion) .setLearningRate(0.2) .setMaxEpoch(40) val data = sc.parallelize(Seq( (Array(2.0, 1.0), Array(1.0, 2.0)), (Array(1.0, 2.0), Array(2.0, 1.0)), (Array(2.0, 1.0), Array(1.0, 2.0)), (Array(1.0, 2.0), Array(2.0, 1.0)))) val df = sqlContext.createDataFrame(data).toDF( features , label ) val nnModel = estimator.fit(df) nnModel.transform(df).show(false) Python Example: from bigdl.nn.layer import * from bigdl.nn.criterion import * from bigdl.util.common import * from zoo.pipeline.nnframes.nn_classifier import * from zoo.feature.common import * data = self.sc.parallelize([ ((2.0, 1.0), (1.0, 2.0)), ((1.0, 2.0), (2.0, 1.0)), ((2.0, 1.0), (1.0, 2.0)), ((1.0, 2.0), (2.0, 1.0))]) schema = StructType([ StructField( features , ArrayType(DoubleType(), False), False), StructField( label , ArrayType(DoubleType(), False), False)]) df = self.sqlContext.createDataFrame(data, schema) model = Sequential().add(Linear(2, 2)) criterion = MSECriterion() estimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\ .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40) nnModel = estimator.fit(df) res = nnModel.transform(df) NNModel Scala: val nnModel = NNModel(bigDLModel) Python: nn_model = NNModel(bigDLModel) NNModel extends Spark's ML Transformer . User can invoke fit in NNEstimator to get a NNModel , or directly compose a NNModel from BigDLModel. It enables users to wrap a pre-trained BigDL Model into a NNModel, and use it as a transformer in your Spark ML pipeline to predict the results for DataFrame (DataSet) . NNModel can be created with various parameters for different scenarios. 1. NNModel(model) Takes only model and use SeqToTensor as feature Preprocessing. NNModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference. 2. NNModel(model, featureSize: Array[Int]) Takes model and featureSize(Array of Int). NNModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to Tensor according to the specified Tensor size. 3. NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model and featurePreprocessing. NNModel will extract the data from feature column and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNModel supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose Sample according to user-specified Preprocessing. NNClassifier Scala: val classifer = NNClassifer(model, criterion) Python: classifier = NNClassifer(model, criterion) NNClassifier is a specialized NNEstimator that simplifies the data format for classification tasks where the label space is discrete. It only supports label column of DoubleType, and the fitted NNClassifierModel will have the prediction column of DoubleType. model BigDL module to be optimized in the fit() method criterion the criterion used to compute the loss and the gradient NNClassifier can be created with various parameters for different scenarios. 1. NNClassifier(model, criterion) Takes only model and criterion and use SeqToTensor as feature and label Preprocessing. NNClassifier will extract the data from feature and label columns ( only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to 1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for training. 2. NNClassifier(model, criterion, featureSize: Array[Int]) Takes model, criterion, featureSize(Array of Int). NNClassifier will extract the data from feature and label columns and convert each feature to Tensor according to the specified Tensor size. ScalarToTensor is used to convert the label column. 3. NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model, criterion and featurePreprocessing. NNClassifier will extract the data from feature and label columns and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNClassifier supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]]) to directly compose Sample with user-specified Preprocessing. Scala example: import com.intel.analytics.bigdl.nn._ import com.intel.analytics.zoo.pipeline.nnframes.NNClassifier import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat val model = Sequential().add(Linear(2, 2)) val criterion = MSECriterion() val estimator = NNClassifier(model, criterion) .setLearningRate(0.2) .setMaxEpoch(40) val data = sc.parallelize(Seq( (Array(0.0, 1.0), 1.0), (Array(1.0, 0.0), 2.0), (Array(0.0, 1.0), 1.0), (Array(1.0, 0.0), 2.0))) val df = sqlContext.createDataFrame(data).toDF( features , label ) val dlModel = estimator.fit(df) dlModel.transform(df).show(false) Python Example: from bigdl.nn.layer import * from bigdl.nn.criterion import * from bigdl.util.common import * from bigdl.dlframes.dl_classifier import * from pyspark.sql.types import * #Logistic Regression with BigDL layers and Analytics zoo NNClassifier model = Sequential().add(Linear(2, 2)).add(LogSoftMax()) criterion = ClassNLLCriterion() estimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10) data = sc.parallelize([ ((0.0, 1.0), [1.0]), ((1.0, 0.0), [2.0]), ((0.0, 1.0), [1.0]), ((1.0, 0.0), [2.0])]) schema = StructType([ StructField( features , ArrayType(DoubleType(), False), False), StructField( label , ArrayType(DoubleType(), False), False)]) df = sqlContext.createDataFrame(data, schema) dlModel = estimator.fit(df) dlModel.transform(df).show(False) NNClassifierModel Scala: val nnClassifierModel = NNClassifierModel(model, featureSize) Python: nn_classifier_model = NNClassifierModel(model) NNClassifierModel is a specialized NNModel for classification tasks. Both label and prediction column will have the datatype of Double. NNClassifierModel can be created with various parameters for different scenarios. 1. NNClassifierModel(model) Takes only model and use SeqToTensor as feature Preprocessing. NNClassifierModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference. 2. NNClassifierModel(model, featureSize: Array[Int]) Takes model and featureSize(Array of Int). NNClassifierModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to Tensor according to the specified Tensor size. 3. NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model and featurePreprocessing. NNClassifierModel will extract the data from feature column and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNClassifierModel supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose Sample according to user-specified Preprocessing. Hyperparameter setting Prior to the commencement of the training process, you can modify the optimization algorithm, batch size, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier will use the default value. Continue the codes above, NNEstimator and NNClassifier can be set in the same way. Scala: //for esitmator estimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam()) //for classifier classifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam()) Python: # for esitmator estimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam()) # for classifier classifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam()) Prepare the data and start the training process NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet Suppose df is the training data, simple call fit method and let Analytics Zoo train the model for you. Scala: //get a NNClassifierModel val nnClassifierModel = classifier.fit(df) Python: # get a NNClassifierModel nnClassifierModel = classifier.fit(df) User may also set validation DataFrame and validation frequency through setValidation method. Train summay and validation summary can also be configured to log the training process for visualization in Tensorboard. Make prediction on chosen data Since NNModel / NNClassifierModel inherits from Spark's Transformer abstract class, simply call transform method on NNModel / NNClassifierModel to make prediction. Scala: nnModel.transform(df).show(false) Python: nnModel.transform(df).show(false) For the complete examples of NNFrames, please refer to: Scala examples Python examples NNImageReader NNImageReader is the primary DataFrame-based image loading interface, defining API to read images into DataFrame. Scala: val imageDF = NNImageReader.readImages(imageDirectory, sc) Python: image_frame = NNImageReader.readImages(image_path, self.sc) The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be accessed from com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema . Each record in \"image\" column represents one image record, in the format of Row(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file, and data holds the original file bytes for the image file. mode represents the OpenCV-compatible type: CV_8UC3, CV_8UC1 in most cases. val byteSchema = StructType( StructField( origin , StringType, true) :: StructField( height , IntegerType, false) :: StructField( width , IntegerType, false) :: StructField( nChannels , IntegerType, false) :: // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases StructField( mode , IntegerType, false) :: // Bytes in OpenCV-compatible order: row-wise BGR in most cases StructField( data , BinaryType, false) :: Nil) After loading the image, user can compose the preprocess steps with the Preprocessing defined in com.intel.analytics.zoo.feature.image .","title":"NNFrames"},{"location":"APIGuide/PipelineAPI/nnframes/#nnestimator","text":"Scala: val estimator = NNEstimator(model, criterion) Python: estimator = NNEstimator(model, criterion) NNEstimator extends org.apache.spark.ml.Estimator and supports training a BigDL model with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline to allow users to combine the components of BigDL and Spark MLlib. NNEstimator supports different feature and label data types through Preprocessing . During fit (training), NNEstimator will extract feature and label data from input DataFrame and use the Preprocessing to convert data for the model, typically converts the feature and label to Tensors or converts the (feature, option[Label]) tuple to a BigDL Sample . Each Preprocessing conducts a data conversion step in the preprocessing phase, multiple Preprocessing can be combined into a ChainedPreprocessing . Some pre-defined Preprocessing for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized Preprocessing . By default, SeqToTensor is used to convert an array or Vector to a 1-dimension Tensor. Using the Preprocessing allows NNEstimator to cache only the raw data and decrease the memory consumption during feature conversion and training, it also enables the model to digest extra data types that DataFrame does not support currently. More concrete examples are available in package com.intel.analytics.zoo.examples.nnframes NNEstimator can be created with various parameters for different scenarios. 1. NNEstimator(model, criterion) Takes only model and criterion and use SeqToTensor as feature and label Preprocessing . NNEstimator will extract the data from feature and label columns ( only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to 1-dimension Tensor. The tensors will be combined into BigDL Sample and send to model for training. 2. NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int]) Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). NNEstimator will extract the data from feature and label columns (only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to Tensor according to the specified Tensor size. 3. NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]], labelPreprocessing: Preprocessing[F, Tensor[T]]) Takes model, criterion, featurePreprocessing and labelPreprocessing. NNEstimator will extract the data from feature and label columns and convert each feature/label to Tensor with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNEstimator supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]]) to directly compose Sample according to user-specified Preprocessing. Scala Example: import com.intel.analytics.bigdl.nn._ import com.intel.analytics.zoo.pipeline.nnframes.NNEstimator import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat val model = Sequential().add(Linear(2, 2)) val criterion = MSECriterion() val estimator = NNEstimator(model, criterion) .setLearningRate(0.2) .setMaxEpoch(40) val data = sc.parallelize(Seq( (Array(2.0, 1.0), Array(1.0, 2.0)), (Array(1.0, 2.0), Array(2.0, 1.0)), (Array(2.0, 1.0), Array(1.0, 2.0)), (Array(1.0, 2.0), Array(2.0, 1.0)))) val df = sqlContext.createDataFrame(data).toDF( features , label ) val nnModel = estimator.fit(df) nnModel.transform(df).show(false) Python Example: from bigdl.nn.layer import * from bigdl.nn.criterion import * from bigdl.util.common import * from zoo.pipeline.nnframes.nn_classifier import * from zoo.feature.common import * data = self.sc.parallelize([ ((2.0, 1.0), (1.0, 2.0)), ((1.0, 2.0), (2.0, 1.0)), ((2.0, 1.0), (1.0, 2.0)), ((1.0, 2.0), (2.0, 1.0))]) schema = StructType([ StructField( features , ArrayType(DoubleType(), False), False), StructField( label , ArrayType(DoubleType(), False), False)]) df = self.sqlContext.createDataFrame(data, schema) model = Sequential().add(Linear(2, 2)) criterion = MSECriterion() estimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\ .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40) nnModel = estimator.fit(df) res = nnModel.transform(df)","title":"NNEstimator"},{"location":"APIGuide/PipelineAPI/nnframes/#nnmodel","text":"Scala: val nnModel = NNModel(bigDLModel) Python: nn_model = NNModel(bigDLModel) NNModel extends Spark's ML Transformer . User can invoke fit in NNEstimator to get a NNModel , or directly compose a NNModel from BigDLModel. It enables users to wrap a pre-trained BigDL Model into a NNModel, and use it as a transformer in your Spark ML pipeline to predict the results for DataFrame (DataSet) . NNModel can be created with various parameters for different scenarios. 1. NNModel(model) Takes only model and use SeqToTensor as feature Preprocessing. NNModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference. 2. NNModel(model, featureSize: Array[Int]) Takes model and featureSize(Array of Int). NNModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to Tensor according to the specified Tensor size. 3. NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model and featurePreprocessing. NNModel will extract the data from feature column and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNModel supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose Sample according to user-specified Preprocessing.","title":"NNModel"},{"location":"APIGuide/PipelineAPI/nnframes/#nnclassifier","text":"Scala: val classifer = NNClassifer(model, criterion) Python: classifier = NNClassifer(model, criterion) NNClassifier is a specialized NNEstimator that simplifies the data format for classification tasks where the label space is discrete. It only supports label column of DoubleType, and the fitted NNClassifierModel will have the prediction column of DoubleType. model BigDL module to be optimized in the fit() method criterion the criterion used to compute the loss and the gradient NNClassifier can be created with various parameters for different scenarios. 1. NNClassifier(model, criterion) Takes only model and criterion and use SeqToTensor as feature and label Preprocessing. NNClassifier will extract the data from feature and label columns ( only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to 1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for training. 2. NNClassifier(model, criterion, featureSize: Array[Int]) Takes model, criterion, featureSize(Array of Int). NNClassifier will extract the data from feature and label columns and convert each feature to Tensor according to the specified Tensor size. ScalarToTensor is used to convert the label column. 3. NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model, criterion and featurePreprocessing. NNClassifier will extract the data from feature and label columns and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNClassifier supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]]) to directly compose Sample with user-specified Preprocessing. Scala example: import com.intel.analytics.bigdl.nn._ import com.intel.analytics.zoo.pipeline.nnframes.NNClassifier import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat val model = Sequential().add(Linear(2, 2)) val criterion = MSECriterion() val estimator = NNClassifier(model, criterion) .setLearningRate(0.2) .setMaxEpoch(40) val data = sc.parallelize(Seq( (Array(0.0, 1.0), 1.0), (Array(1.0, 0.0), 2.0), (Array(0.0, 1.0), 1.0), (Array(1.0, 0.0), 2.0))) val df = sqlContext.createDataFrame(data).toDF( features , label ) val dlModel = estimator.fit(df) dlModel.transform(df).show(false) Python Example: from bigdl.nn.layer import * from bigdl.nn.criterion import * from bigdl.util.common import * from bigdl.dlframes.dl_classifier import * from pyspark.sql.types import * #Logistic Regression with BigDL layers and Analytics zoo NNClassifier model = Sequential().add(Linear(2, 2)).add(LogSoftMax()) criterion = ClassNLLCriterion() estimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10) data = sc.parallelize([ ((0.0, 1.0), [1.0]), ((1.0, 0.0), [2.0]), ((0.0, 1.0), [1.0]), ((1.0, 0.0), [2.0])]) schema = StructType([ StructField( features , ArrayType(DoubleType(), False), False), StructField( label , ArrayType(DoubleType(), False), False)]) df = sqlContext.createDataFrame(data, schema) dlModel = estimator.fit(df) dlModel.transform(df).show(False)","title":"NNClassifier"},{"location":"APIGuide/PipelineAPI/nnframes/#nnclassifiermodel","text":"Scala: val nnClassifierModel = NNClassifierModel(model, featureSize) Python: nn_classifier_model = NNClassifierModel(model) NNClassifierModel is a specialized NNModel for classification tasks. Both label and prediction column will have the datatype of Double. NNClassifierModel can be created with various parameters for different scenarios. 1. NNClassifierModel(model) Takes only model and use SeqToTensor as feature Preprocessing. NNClassifierModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference. 2. NNClassifierModel(model, featureSize: Array[Int]) Takes model and featureSize(Array of Int). NNClassifierModel will extract the data from feature column (only Scalar, Array[_] or Vector data type are supported) and convert each feature to Tensor according to the specified Tensor size. 3. NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]]) Takes model and featurePreprocessing. NNClassifierModel will extract the data from feature column and convert each feature to Tensor with the featurePreprocessing. This constructor provides more flexibility in supporting extra data types. Meanwhile, for advanced use cases (e.g. model with multiple input tensor), NNClassifierModel supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose Sample according to user-specified Preprocessing.","title":"NNClassifierModel"},{"location":"APIGuide/PipelineAPI/nnframes/#hyperparameter-setting","text":"Prior to the commencement of the training process, you can modify the optimization algorithm, batch size, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier will use the default value. Continue the codes above, NNEstimator and NNClassifier can be set in the same way. Scala: //for esitmator estimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam()) //for classifier classifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam()) Python: # for esitmator estimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam()) # for classifier classifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())","title":"Hyperparameter setting"},{"location":"APIGuide/PipelineAPI/nnframes/#prepare-the-data-and-start-the-training-process","text":"NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet Suppose df is the training data, simple call fit method and let Analytics Zoo train the model for you. Scala: //get a NNClassifierModel val nnClassifierModel = classifier.fit(df) Python: # get a NNClassifierModel nnClassifierModel = classifier.fit(df) User may also set validation DataFrame and validation frequency through setValidation method. Train summay and validation summary can also be configured to log the training process for visualization in Tensorboard.","title":"Prepare the data and start the training process"},{"location":"APIGuide/PipelineAPI/nnframes/#make-prediction-on-chosen-data","text":"Since NNModel / NNClassifierModel inherits from Spark's Transformer abstract class, simply call transform method on NNModel / NNClassifierModel to make prediction. Scala: nnModel.transform(df).show(false) Python: nnModel.transform(df).show(false) For the complete examples of NNFrames, please refer to: Scala examples Python examples","title":"Make prediction on chosen data"},{"location":"APIGuide/PipelineAPI/nnframes/#nnimagereader","text":"NNImageReader is the primary DataFrame-based image loading interface, defining API to read images into DataFrame. Scala: val imageDF = NNImageReader.readImages(imageDirectory, sc) Python: image_frame = NNImageReader.readImages(image_path, self.sc) The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be accessed from com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema . Each record in \"image\" column represents one image record, in the format of Row(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file, and data holds the original file bytes for the image file. mode represents the OpenCV-compatible type: CV_8UC3, CV_8UC1 in most cases. val byteSchema = StructType( StructField( origin , StringType, true) :: StructField( height , IntegerType, false) :: StructField( width , IntegerType, false) :: StructField( nChannels , IntegerType, false) :: // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases StructField( mode , IntegerType, false) :: // Bytes in OpenCV-compatible order: row-wise BGR in most cases StructField( data , BinaryType, false) :: Nil) After loading the image, user can compose the preprocess steps with the Preprocessing defined in com.intel.analytics.zoo.feature.image .","title":"NNImageReader"},{"location":"APIGuide/PipelineAPI/variable/","text":"Basic operators: + - * / Those are supported as element-wise operation. Scala example x + 1.0 x + y Python example x + 1.0 x + y squeeze Delete the singleton dimension(s). The batch dimension needs to be unchanged. For example, if input has size (2, 1, 3, 4, 1): - squeeze(dim = 1) will give output size (2, 3, 4, 1) - squeeze(dims = null) will give output size (2, 3, 4) Scala example x.squeeze(1) Python example x.squeeze(1) slice Slice the input with the number of dimensions not being reduced. The batch dimension needs to be unchanged. - dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension. -1 means the last dimension of the input. - startIndex Non-negative integer. The start index on the given dimension. 0-based index. - length The length to be sliced. Default is 1. For example, if input is: 1 2 3 4 5 6 - slice(1, 1, 2) will give output 2 3 5 6 - slice(1, 2, -1) will give output 3 6 Scala example x.slice(1, 1, 2) Python example x.slice(1, 1, 2) index_select Select an index of the input in the given dim and return the subset part. The batch dimension needs to be unchanged. The selected dim would be remove after this operation. - dim: The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input. - index: The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input. For example, if input is: 1 2 3 4 5 6 - Select(1, 1) will give output [2 5] - Select(1, -1) will give output [3 6] Scala example x.select(1, 1) Python example x.select(1, 1)","title":"Autograd-Variable"},{"location":"APIGuide/PipelineAPI/variable/#basic-operators-","text":"Those are supported as element-wise operation. Scala example x + 1.0 x + y Python example x + 1.0 x + y","title":"Basic operators: + - * /"},{"location":"APIGuide/PipelineAPI/variable/#squeeze","text":"Delete the singleton dimension(s). The batch dimension needs to be unchanged. For example, if input has size (2, 1, 3, 4, 1): - squeeze(dim = 1) will give output size (2, 3, 4, 1) - squeeze(dims = null) will give output size (2, 3, 4) Scala example x.squeeze(1) Python example x.squeeze(1)","title":"squeeze"},{"location":"APIGuide/PipelineAPI/variable/#slice","text":"Slice the input with the number of dimensions not being reduced. The batch dimension needs to be unchanged. - dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension. -1 means the last dimension of the input. - startIndex Non-negative integer. The start index on the given dimension. 0-based index. - length The length to be sliced. Default is 1. For example, if input is: 1 2 3 4 5 6 - slice(1, 1, 2) will give output 2 3 5 6 - slice(1, 2, -1) will give output 3 6 Scala example x.slice(1, 1, 2) Python example x.slice(1, 1, 2)","title":"slice"},{"location":"APIGuide/PipelineAPI/variable/#index_select","text":"Select an index of the input in the given dim and return the subset part. The batch dimension needs to be unchanged. The selected dim would be remove after this operation. - dim: The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input. - index: The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input. For example, if input is: 1 2 3 4 5 6 - Select(1, 1) will give output [2 5] - Select(1, -1) will give output [3 6] Scala example x.select(1, 1) Python example x.select(1, 1)","title":"index_select"},{"location":"APIGuide/TFPark/bert-classifier/","text":"Analytics Zoo provides a built-in BERTClassifier in TFPark for Natural Language Processing (NLP) classification tasks based on TFEstimator and BERT. Bidirectional Encoder Representations from Transformers (BERT) is Google's state-of-the-art pre-trained NLP model. You may refer to here for more details. BERTClassifier is a pre-built TFEstimator that takes the hidden state of the first token to do classification. Remarks : You need to install tensorflow==1.10 on your driver node. Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other systems, you need to manually compile the TensorFlow source code. Instructions can be found here . After constructing a BERTClassifier, you can directly call train , evaluate or predict in a distributed fashion. See here for more instructions. from zoo.tfpark.text.estimator import BERTClassifier estimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint=None, use_one_hot_embeddings=False, optimizer=None, model_dir=None) num_classes : Positive int. The number of classes to be classified. bert_config_file : The path to the json file for BERT configurations. init_checkpoint : The path to the initial checkpoint of the pre-trained BERT model if any. Default is None. use_one_hot_embeddings : Boolean. Whether to use one-hot for word embeddings. Default is False. optimizer : The optimizer used to train the estimator. It can either be an instance of tf.train.Optimizer or the corresponding string representation. Default is None if no training is involved. model_dir : The output directory for model checkpoints to be written if any. Default is None.","title":"BERT Classifier"},{"location":"APIGuide/TFPark/estimator/","text":"TFEstimator wraps a model defined by model_fn . The model_fn is almost identical to TensorFlow's model_fn except users are required to return a TFEstimator object. Users do not need to construct backward graph (calling optimizer.minimize(...) ) but set a loss tensor in TFEstimator . Create a TFEstimator : import tensorflow as tf from zoo.tfpark.estimator import TFEstimator, TFEstimatorSpec def model_fn(features, labels, mode): hidden = tf.layers.dense(features, 32, activation=tf.nn.relu) logits = tf.layers.dense(hidden, 10) if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN: loss = tf.reduce_mean( tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)) return TFEstimatorSpec(mode, predictions=logits, loss=loss) else: return TFEstimatorSpec(mode, predictions=logits) estimator = TFEstimator(model_fn, tf.train.AdamOptimizer(), model_dir= /tmp/estimator ) Methods __init__ TFEstimator(model_fn, optimizer=None, model_dir=None, config=None, params=None, warm_start_from=None) Arguments model_fn : Model function. Follows the signature: * Args: * `features`: This is the first item returned from the `input_fn` passed to `train`, `evaluate`, and `predict`. This should be a single `tf.Tensor` or `dict` of same. * `labels`: This is the second item returned from the `input_fn` passed to `train`, `evaluate`, and `predict`. This should be a single `tf.Tensor` or `dict` of same (for multi-head models). If mode is `tf.estimator.ModeKeys.PREDICT`, `labels=None` will be passed. If the `model_fn`'s signature does not accept `mode`, the `model_fn` must still be able to handle `labels=None`. * `mode`: Optional. Specifies if this training, evaluation or prediction. See `tf.estimator.ModeKeys`. * `params`: Optional `dict` of hyperparameters. Will receive what is passed to Estimator in `params` parameter. This allows to configure Estimators from hyper parameter tuning. * `config`: Optional `estimator.RunConfig` object. Will receive what is passed to Estimator as its `config` parameter, or a default value. Allows setting up things in your `model_fn` based on configuration such as `num_ps_replicas`, or `model_dir`. * Returns: `zoo.tfpark.estimator.TFEstimatorSpec` optimizer : the tf.train.Optimizer to be used in training, e.g. tf.train.AdamOptimizer() model_dir : Directory to save model parameters, graph and etc. This can also be used to load checkpoints from the directory into an estimator to continue training a previously saved model. If PathLike object, the path will be resolved. If None , the model_dir in config will be used if set. If both are set, they must be same. If both are None , a temporary directory will be used. config : estimator.RunConfig configuration object. params : dict of hyper parameters that will be passed into model_fn . Keys are names of parameters, values are basic python types. warm_start_from : Optional string filepath to a checkpoint or SavedModel to warm-start from, or a tf.estimator.WarmStartSettings object to fully configure warm-starting. If the string filepath is provided instead of a tf.estimator.WarmStartSettings , then all variables are warm-started, and it is assumed that vocabularies and tf.Tensor names are unchanged. train train(input_fn, steps=None) Arguments input_fn : A function that constructs the input data for evaluation. The function should construct and return one of the following: * A `TFDataset` object, each elements of which is a tuple `(features, labels)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple `(features, labels)` with same constraints as below. * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary of string feature name to `Tensor` and `labels` is a `Tensor` or a dictionary of string label name to `Tensor`. Both `features` and `labels` are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. steps : Number of steps for which to train the model. evaluate evaluate(input_fn, eval_methods, steps=None, checkpoint_path=None) Arguments input_fn : A function that constructs the input data for evaluation. The function should construct and return one of the following: * A `TFDataset` object, each elements of which is a tuple `(features, labels)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple `(features, labels)` with same constraints as below. * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary of string feature name to `Tensor` and `labels` is a `Tensor` or a dictionary of string label name to `Tensor`. Both `features` and `labels` are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. eval_methods : a list of strings to specify the evaluation metrics to be used in this model steps : Number of steps for which to evaluate model. checkpoint_path : Path of a specific checkpoint to evaluate. If None , the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir , evaluation is run with newly initialized Variables instead of ones restored from checkpoint. predict predict(input_fn, checkpoint_path=None) Arguments input_fn : A function that constructs the features. * A `TFDataset` object, each elements of which is a tuple `(features, None)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must have same constraints as below. * features: A `tf.Tensor` or a dictionary of string feature name to `Tensor`. features are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. * A tuple, in which case the first item is extracted as features. checkpoint_path : Path of a specific checkpoint to predict. If None , the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir , prediction is run with newly initialized Variables instead of ones restored from checkpoint.","title":"TFEstimator"},{"location":"APIGuide/TFPark/estimator/#methods","text":"","title":"Methods"},{"location":"APIGuide/TFPark/estimator/#9595init9595","text":"TFEstimator(model_fn, optimizer=None, model_dir=None, config=None, params=None, warm_start_from=None)","title":"__init__"},{"location":"APIGuide/TFPark/estimator/#arguments","text":"model_fn : Model function. Follows the signature: * Args: * `features`: This is the first item returned from the `input_fn` passed to `train`, `evaluate`, and `predict`. This should be a single `tf.Tensor` or `dict` of same. * `labels`: This is the second item returned from the `input_fn` passed to `train`, `evaluate`, and `predict`. This should be a single `tf.Tensor` or `dict` of same (for multi-head models). If mode is `tf.estimator.ModeKeys.PREDICT`, `labels=None` will be passed. If the `model_fn`'s signature does not accept `mode`, the `model_fn` must still be able to handle `labels=None`. * `mode`: Optional. Specifies if this training, evaluation or prediction. See `tf.estimator.ModeKeys`. * `params`: Optional `dict` of hyperparameters. Will receive what is passed to Estimator in `params` parameter. This allows to configure Estimators from hyper parameter tuning. * `config`: Optional `estimator.RunConfig` object. Will receive what is passed to Estimator as its `config` parameter, or a default value. Allows setting up things in your `model_fn` based on configuration such as `num_ps_replicas`, or `model_dir`. * Returns: `zoo.tfpark.estimator.TFEstimatorSpec` optimizer : the tf.train.Optimizer to be used in training, e.g. tf.train.AdamOptimizer() model_dir : Directory to save model parameters, graph and etc. This can also be used to load checkpoints from the directory into an estimator to continue training a previously saved model. If PathLike object, the path will be resolved. If None , the model_dir in config will be used if set. If both are set, they must be same. If both are None , a temporary directory will be used. config : estimator.RunConfig configuration object. params : dict of hyper parameters that will be passed into model_fn . Keys are names of parameters, values are basic python types. warm_start_from : Optional string filepath to a checkpoint or SavedModel to warm-start from, or a tf.estimator.WarmStartSettings object to fully configure warm-starting. If the string filepath is provided instead of a tf.estimator.WarmStartSettings , then all variables are warm-started, and it is assumed that vocabularies and tf.Tensor names are unchanged.","title":"Arguments"},{"location":"APIGuide/TFPark/estimator/#train","text":"train(input_fn, steps=None)","title":"train"},{"location":"APIGuide/TFPark/estimator/#arguments_1","text":"input_fn : A function that constructs the input data for evaluation. The function should construct and return one of the following: * A `TFDataset` object, each elements of which is a tuple `(features, labels)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple `(features, labels)` with same constraints as below. * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary of string feature name to `Tensor` and `labels` is a `Tensor` or a dictionary of string label name to `Tensor`. Both `features` and `labels` are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. steps : Number of steps for which to train the model.","title":"Arguments"},{"location":"APIGuide/TFPark/estimator/#evaluate","text":"evaluate(input_fn, eval_methods, steps=None, checkpoint_path=None)","title":"evaluate"},{"location":"APIGuide/TFPark/estimator/#arguments_2","text":"input_fn : A function that constructs the input data for evaluation. The function should construct and return one of the following: * A `TFDataset` object, each elements of which is a tuple `(features, labels)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple `(features, labels)` with same constraints as below. * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary of string feature name to `Tensor` and `labels` is a `Tensor` or a dictionary of string label name to `Tensor`. Both `features` and `labels` are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. eval_methods : a list of strings to specify the evaluation metrics to be used in this model steps : Number of steps for which to evaluate model. checkpoint_path : Path of a specific checkpoint to evaluate. If None , the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir , evaluation is run with newly initialized Variables instead of ones restored from checkpoint.","title":"Arguments"},{"location":"APIGuide/TFPark/estimator/#predict","text":"predict(input_fn, checkpoint_path=None)","title":"predict"},{"location":"APIGuide/TFPark/estimator/#arguments_3","text":"input_fn : A function that constructs the features. * A `TFDataset` object, each elements of which is a tuple `(features, None)`. * A `tf.data.Dataset` object: Outputs of `Dataset` object must have same constraints as below. * features: A `tf.Tensor` or a dictionary of string feature name to `Tensor`. features are consumed by `model_fn`. They should satisfy the expectation of `model_fn` from inputs. * A tuple, in which case the first item is extracted as features. checkpoint_path : Path of a specific checkpoint to predict. If None , the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir , prediction is run with newly initialized Variables instead of ones restored from checkpoint.","title":"Arguments"},{"location":"APIGuide/TFPark/model/","text":"KerasModel enables user to use tf.keras API to define TensorFlow models and perform training or evaluation on top of Spark and BigDL in a distributed fashion. from zoo.tfpark import KerasModel, TFDataset import tensorflow as tf model = tf.keras.Sequential( [tf.keras.layers.Flatten(input_shape=(28, 28, 1)), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(10, activation='softmax'), ] ) model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy']) keras_model = KerasModel(model) Methods __init__ KerasModel(model) Arguments model : a compiled keras model defined using tf.keras fit fit(x=None, y = None, batch_size=None, epochs=1, validation_split=0., validation_data=None, distributed=False) Arguments x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, if the model has named inputs. y : Target data. Like the input data x , It should be consistent with x (you cannot have Numpy inputs and tensor targets, or inversely). If x is a TFDataset, y should not be specified (since targets will be obtained from x ). batch_size : Integer or None . Number of samples per gradient update. If x is a TFDataset, you do not need to specify batch_size. epochs : Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. validation_split : Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. validation_data : validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split . validation_data could be: - tuple `(x_val, y_val)` of Numpy arrays or tensors - `TFDataset` distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array. evaluate evaluate(x=None, y=None, bath_per_thread=None, distributed=False) Arguments x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, if the model has named inputs. y : Target data. Like the input data x , It should be consistent with x (you cannot have Numpy inputs and tensor targets, or inversely). If x is a TFDataset, y should not be specified (since targets will be obtained from x ). batch_per_thread : The default value is 1. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array. predict predict(x, batch_per_thread=None, distributed=False): Arguments x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, batch_per_thread : The default value is 1. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array.","title":"KerasModel"},{"location":"APIGuide/TFPark/model/#methods","text":"","title":"Methods"},{"location":"APIGuide/TFPark/model/#9595init9595","text":"KerasModel(model)","title":"__init__"},{"location":"APIGuide/TFPark/model/#arguments","text":"model : a compiled keras model defined using tf.keras","title":"Arguments"},{"location":"APIGuide/TFPark/model/#fit","text":"fit(x=None, y = None, batch_size=None, epochs=1, validation_split=0., validation_data=None, distributed=False)","title":"fit"},{"location":"APIGuide/TFPark/model/#arguments_1","text":"x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, if the model has named inputs. y : Target data. Like the input data x , It should be consistent with x (you cannot have Numpy inputs and tensor targets, or inversely). If x is a TFDataset, y should not be specified (since targets will be obtained from x ). batch_size : Integer or None . Number of samples per gradient update. If x is a TFDataset, you do not need to specify batch_size. epochs : Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. validation_split : Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. validation_data : validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split . validation_data could be: - tuple `(x_val, y_val)` of Numpy arrays or tensors - `TFDataset` distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array.","title":"Arguments"},{"location":"APIGuide/TFPark/model/#evaluate","text":"evaluate(x=None, y=None, bath_per_thread=None, distributed=False)","title":"evaluate"},{"location":"APIGuide/TFPark/model/#arguments_2","text":"x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, if the model has named inputs. y : Target data. Like the input data x , It should be consistent with x (you cannot have Numpy inputs and tensor targets, or inversely). If x is a TFDataset, y should not be specified (since targets will be obtained from x ). batch_per_thread : The default value is 1. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array.","title":"Arguments"},{"location":"APIGuide/TFPark/model/#predict","text":"predict(x, batch_per_thread=None, distributed=False):","title":"predict"},{"location":"APIGuide/TFPark/model/#arguments_3","text":"x : Input data. It could be: - a TFDataset object - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs). - A dict mapping input names to the corresponding array/tensors, batch_per_thread : The default value is 1. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array.","title":"Arguments"},{"location":"APIGuide/TFPark/text-models/","text":"There are a number of built-in compiled text models in Analytics Zoo TFPark for Natural Language Processing (NLP) tasks based on KerasModel . After constructing a text model, you can directly call fit , evaluate or predict in a distributed fashion. See here for more instructions. Remarks : You need to install tensorflow==1.10 on your driver node. Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other systems, you need to manually compile the TensorFlow source code. Instructions can be found here . Intent Extraction This is a multi-task model used for joint intent extraction and slot filling. This model has two inputs: word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) This model has two outputs: intent labels of shape (batch, num_intents) entity tags of shape (batch, sequence_length, num_entities) from zoo.tfpark.text.keras import IntentEntity model = IntentEntity(num_intents, num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, char_lstm_dim=30, tagger_lstm_dim=100, dropout=0.2, optimizer=None) num_intents : Positive int. The number of intent classes to be classified. num_entities : Positive int. The number of slot labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. word_length : Positive int. The max word length in characters. Default is 12. word_emb_dim : Positive int. The dimension of word embeddings. Default is 100. char_emb_dim : Positive int. The dimension of character embeddings. Default is 30. char_lstm_dim : Positive int. The hidden size of character feature Bi-LSTM layer. Default is 30. tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.2. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer(). Model Save and Load Save the IntentEntity model to a single HDF5 file. model.save_model(path) Load an existing IntentEntity model (with weights) from HDF5 file. from zoo.tfpark.text.keras import IntentEntity model = IntentEntity.load_model(path) Named Entity Recognition This model is used for named entity recognition using Bidirectional LSTM with Conditional Random Field (CRF) sequence classifier. This model has two inputs: word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) This model outputs entity tags of shape (batch, sequence_length, num_entities). from zoo.tfpark.text.keras import NER model = NER(num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, tagger_lstm_dim=100, dropout=0.5, crf_mode='reg', optimizer=None) num_entities : Positive int. The number of entity labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. word_length : Positive int. The max word length in characters. Default is 12. word_emb_dim : Positive int. The dimension of word embeddings. Default is 100. char_emb_dim : Positive int. The dimension of character embeddings. Default is 30. tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.5. crf_mode : String. CRF operation mode. Either 'reg' or 'pad'. Default is 'reg'. 'reg' for regular full sequence learning (all sequences have equal length). 'pad' for supplied sequence lengths (useful for padded sequences). For 'pad' mode, a third input for sequence_length (batch, 1) is needed. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.keras.optimizers.Adam(0.001, clipnorm=5.). Model Save and Load Save the NER model to a single HDF5 file. model.save_model(path) Load an existing NER model (with weights) from HDF5 file. from zoo.tfpark.text.keras import NER model = NER.load_model(path) POS Tagging This model is used as Part-Of-Speech(POS)-tagger and chunker for sentence tagging, which contains three Bidirectional LSTM layers. This model can have one or two input(s): word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) (if char_vocab_size is not None) This model has two outputs: pos tags of shape (batch, sequence_length, num_pos_labels) chunk tags of shape (batch, sequence_length, num_chunk_labels) from zoo.tfpark.text.keras import SequenceTagger model = NER(num_pos_labels, num_chunk_labels, word_vocab_size, char_vocab_size=None, word_length=12, feature_size=100, dropout=0.2, classifier='softmax', optimizer=None) num_pos_labels : Positive int. The number of pos labels to be classified. num_chunk_labels : Positive int. The number of chunk labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. Default is None and in this case only one input, namely word indices is expected. word_length : Positive int. The max word length in characters. Default is 12. feature_size : Positive int. The size of Embedding and Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.5. classifier : String. The classification layer used for tagging chunks. Either 'softmax' or 'crf' (Conditional Random Field). Default is 'softmax'. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer(). Model Save and Load Save the SequenceTagger model to a single HDF5 file. model.save_model(path) Load an existing SequenceTagger model (with weights) from HDF5 file. from zoo.tfpark.text.keras import SequenceTagger model = SequenceTagger.load_model(path)","title":"Text Models"},{"location":"APIGuide/TFPark/text-models/#intent-extraction","text":"This is a multi-task model used for joint intent extraction and slot filling. This model has two inputs: word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) This model has two outputs: intent labels of shape (batch, num_intents) entity tags of shape (batch, sequence_length, num_entities) from zoo.tfpark.text.keras import IntentEntity model = IntentEntity(num_intents, num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, char_lstm_dim=30, tagger_lstm_dim=100, dropout=0.2, optimizer=None) num_intents : Positive int. The number of intent classes to be classified. num_entities : Positive int. The number of slot labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. word_length : Positive int. The max word length in characters. Default is 12. word_emb_dim : Positive int. The dimension of word embeddings. Default is 100. char_emb_dim : Positive int. The dimension of character embeddings. Default is 30. char_lstm_dim : Positive int. The hidden size of character feature Bi-LSTM layer. Default is 30. tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.2. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer(). Model Save and Load Save the IntentEntity model to a single HDF5 file. model.save_model(path) Load an existing IntentEntity model (with weights) from HDF5 file. from zoo.tfpark.text.keras import IntentEntity model = IntentEntity.load_model(path)","title":"Intent Extraction"},{"location":"APIGuide/TFPark/text-models/#named-entity-recognition","text":"This model is used for named entity recognition using Bidirectional LSTM with Conditional Random Field (CRF) sequence classifier. This model has two inputs: word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) This model outputs entity tags of shape (batch, sequence_length, num_entities). from zoo.tfpark.text.keras import NER model = NER(num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, tagger_lstm_dim=100, dropout=0.5, crf_mode='reg', optimizer=None) num_entities : Positive int. The number of entity labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. word_length : Positive int. The max word length in characters. Default is 12. word_emb_dim : Positive int. The dimension of word embeddings. Default is 100. char_emb_dim : Positive int. The dimension of character embeddings. Default is 30. tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.5. crf_mode : String. CRF operation mode. Either 'reg' or 'pad'. Default is 'reg'. 'reg' for regular full sequence learning (all sequences have equal length). 'pad' for supplied sequence lengths (useful for padded sequences). For 'pad' mode, a third input for sequence_length (batch, 1) is needed. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.keras.optimizers.Adam(0.001, clipnorm=5.). Model Save and Load Save the NER model to a single HDF5 file. model.save_model(path) Load an existing NER model (with weights) from HDF5 file. from zoo.tfpark.text.keras import NER model = NER.load_model(path)","title":"Named Entity Recognition"},{"location":"APIGuide/TFPark/text-models/#pos-tagging","text":"This model is used as Part-Of-Speech(POS)-tagger and chunker for sentence tagging, which contains three Bidirectional LSTM layers. This model can have one or two input(s): word indices of shape (batch, sequence_length) character indices of shape (batch, sequence_length, word_length) (if char_vocab_size is not None) This model has two outputs: pos tags of shape (batch, sequence_length, num_pos_labels) chunk tags of shape (batch, sequence_length, num_chunk_labels) from zoo.tfpark.text.keras import SequenceTagger model = NER(num_pos_labels, num_chunk_labels, word_vocab_size, char_vocab_size=None, word_length=12, feature_size=100, dropout=0.2, classifier='softmax', optimizer=None) num_pos_labels : Positive int. The number of pos labels to be classified. num_chunk_labels : Positive int. The number of chunk labels to be classified. word_vocab_size : Positive int. The size of the word dictionary. char_vocab_size : Positive int. The size of the character dictionary. Default is None and in this case only one input, namely word indices is expected. word_length : Positive int. The max word length in characters. Default is 12. feature_size : Positive int. The size of Embedding and Bi-LSTM layers. Default is 100. dropout : Dropout rate. Default is 0.5. classifier : String. The classification layer used for tagging chunks. Either 'softmax' or 'crf' (Conditional Random Field). Default is 'softmax'. optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer(). Model Save and Load Save the SequenceTagger model to a single HDF5 file. model.save_model(path) Load an existing SequenceTagger model (with weights) from HDF5 file. from zoo.tfpark.text.keras import SequenceTagger model = SequenceTagger.load_model(path)","title":"POS Tagging"},{"location":"Keras2StyleAPIGuide/keras-api-python/","text":"","title":"Keras api python"},{"location":"Keras2StyleAPIGuide/keras-api-scala/","text":"","title":"Keras api scala"},{"location":"Keras2StyleAPIGuide/Layers/activation/","text":"","title":"Activation"},{"location":"Keras2StyleAPIGuide/Layers/advanced-activation/","text":"","title":"Advanced activation"},{"location":"Keras2StyleAPIGuide/Layers/convolutional/","text":"Conv1D 1D convolution layer (e.g. temporal convolution). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide an input_shape argument (tuple of integers or None , e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors, or (None, 128) for variable-length sequences of 128-dimensional vectors. Input shape: 3D tensor with shape: (batch_size, steps, input_dim) Output shape: 3D tensor with shape: (batch_size, new_steps, filters) steps value might have changed due to padding or strides. Scala: Conv1D(filters, kernelSize, strides=1, padding = valid , activation = null, useBias = True, kernelInitializer = glorot_uniform , biasInitializer = zero , kernelRegularizer = null, biasRegularizer = null, inputShape = null) Python: Conv1D(filters, kernel_size, strides=1, padding= valid , activation=None, use_bias=True, kernel_initializer= glorot_uniform , bias_initializer = zero , kernel_regularizer=None, bias_regularizer=None, input_shape=None, name=None) Parameters: filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of a single integer, specifying the length of the 1D convolution window. strides : An integer or tuple/list of a single integer, specifying the stride length of the convolution. padding : One of \"valid\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. activation : Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x ). use_bias : Boolean, whether the layer uses a bias vector. kernel_initializer : Initializer for the kernel weights matrix. Default is 'glorot_uniform'. bias_initializer : Initializer for the bias vector. kernel_regularizer : Regularizer function applied to the kernel weights matrix. Default is null. bias_regularizer : Regularizer function applied to the bias vector. Default is null. input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.Conv1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Conv1D[Float](8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.3490186 0.9116212 1.0265731 -1.1517781 -1.3408363 0.068315335 2.330641 0.15831113 -0.3477347 -0.31537533 -0.004820011 0.19639632 (2,.,.) = -2.5452073 -0.07062272 0.07531657 0.7308297 -0.5541283 -0.672619 0.4120175 -0.63392377 -1.7937882 1.178323 -0.9584365 0.35273483 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: (1,.,.) = 1.9344429 -0.67874485 -2.8546433 -0.6660415 2.754292 0.91595435 -0.32557443 0.25574505 (2,.,.) = -0.15532638 -1.7119135 -0.53497326 -1.4706889 0.4749836 2.0963004 -0.32759145 -2.57343 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import Conv1D model = Sequential() model.add(Conv1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.26717132 0.71646316 0.46861815 0.15532447] [0.43466464 0.48129897 0.31993028 0.17653698] [0.49705025 0.36898188 0.17595273 0.13695961]] [[0.05537173 0.62180016 0.36560319 0.95572837] [0.98196495 0.20136646 0.0423306 0.02030028] [0.65687877 0.91620089 0.37612963 0.52101501]]] Output is [[[ 0.14253668 0.4923424 0.08080368 -0.5239319 -0.26981926 0.57145274 0.48187608 1.4999257 ]] [[-0.10191379 0.51799184 -0.20100947 -0.7895199 -0.23697199 0.4781017 0.5892592 2.1963782 ]]] Conv2D 2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\" . Input shape: 4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last'. Output shape: 4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or 4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. rows and cols values might have changed due to padding. Scala: Conv2D(filters, kernelSize, strides, padding = valid , dataFormat = channels_first , activation = null, useBias = true, kernelInitializer = glorot_uniform , biasInitializer = zero , kernelRegularizer = null, biasRegularizer = null, inputShape = null) Python: Conv2D(filters, kernel_size, strides=(1, 1), padding= valid , data_format= channels_first , activation=None, use_bias=True, kernel_initializer= glorot_uniform , bias_initializer= zero , kernel_regularizer=None, bias_regularizer=None, input_shape=None, name=None) Parameters: filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions. strides : A string, one of channels_last (default) or channels_first . The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\". padding : one of \"valid\" or \"same\" (case-insensitive). data_format : Number of columns in the convolution kernel. activation : Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x ). use_bias : Boolean, whether the layer uses a bias vector. Default is true. kernel_initializer : Initializer for the kernel weights matrix. Default is 'glorot_uniform'. bias_initializer : Initializer for the bias vector. kernel_regularizer : Regularizer function applied to the kernel weights matrix. Default is null. bias_regularizer : Regularizer function applied to the bias vector. Default is null. input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.Conv2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Conv2D[Float](4, Array(2, 2), activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.7008811 0.12288668 1.0145894 0.34869674 0.1495685 -0.84290063 -0.13881613 0.22891551 -0.065949395 0.7776933 0.3898055 0.8187307 (1,2,.,.) = -0.6645274 0.44756833 -0.8268243 -0.13796453 -1.2200167 -0.89445364 -0.16754562 -0.7029418 -0.032706447 -1.2504591 0.24031237 0.8331628 (2,1,.,.) = 0.025527362 -1.456607 1.4085853 2.115896 0.28405094 2.473169 -2.1256483 -0.37065008 1.1322745 2.3098936 0.40274113 -0.009792422 (2,2,.,.) = 0.38416716 0.42884415 0.48050597 -0.32054836 -0.18368138 -0.83845645 0.69398314 0.81973153 0.30809402 1.1508962 0.8602869 -0.27299604 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: (1,1,.,.) = 0.0 0.0 0.51253283 0.09132275 0.0 0.0 (1,2,.,.) = 0.96514046 0.32586247 0.0 0.0 0.7704669 0.0 (1,3,.,.) = 0.41404063 0.35680038 0.15091634 0.0 0.0 0.0 (1,4,.,.) = 0.0 0.5466105 0.0 0.0 0.0 0.45137247 (2,1,.,.) = 0.0 0.88202 0.0 0.0 2.1273396 0.0 (2,2,.,.) = 0.0 0.90696275 0.0 0.0 0.0 0.28731248 (2,3,.,.) = 0.0 0.0 0.5000323 0.0 0.0 0.0 (2,4,.,.) = 0.3865677 0.0 0.8942361 1.1031605 0.0 1.0433162 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import Conv2D model = Sequential() model.add(Conv2D(4, (2, 2), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.80687428 0.17910722 0.42103319 0.62854611] [0.15771997 0.63882001 0.47435052 0.74072266] [0.75874837 0.89953139 0.98486427 0.78619311]] [[0.17276155 0.6644038 0.06076521 0.93869801] [0.12812916 0.47968789 0.87123 0.15238281] [0.54624731 0.48725399 0.65683408 0.40533143]]] [[[0.67267837 0.08983171 0.77597291 0.64776813] [0.23830409 0.80719787 0.50198151 0.87555294] [0.83633492 0.84309489 0.54959086 0.09094626]] [[0.37056036 0.61459394 0.79002544 0.74196783] [0.33012708 0.90385893 0.45793861 0.89058154] [0.72228852 0.71115986 0.1502346 0.85841747]]]] Output is [[[[ 0.18198788 -0.07777633 -0.06771126] [ 0.11002313 0.09865391 0.13217448]] [[-0.41738698 0.0429197 -0.53935146] [-0.3684827 -0.61656874 -0.40491766]] [[ 0.15622243 0.31875694 0.4548544 ] [ 0.46874833 0.3621596 0.73849726]] [[ 0.21264602 0.73464984 0.38783965] [ 0.44780225 0.69555914 0.7172658 ]]] [[[-0.02473125 -0.26770562 0.06244571] [-0.04517556 0.03924857 0.12935217]] [[-0.21954477 -0.37033984 -0.44978783] [-0.45664912 -0.5516143 -0.34895533]] [[ 0.16499116 0.45316857 0.51688266] [ 0.4307469 0.5550571 0.06971958]] [[ 0.54072773 0.8459399 0.7282518 ] [ 0.71461993 0.6869658 0.5307025 ]]]]","title":"Convolutional"},{"location":"Keras2StyleAPIGuide/Layers/convolutional/#conv1d","text":"1D convolution layer (e.g. temporal convolution). This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide an input_shape argument (tuple of integers or None , e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors, or (None, 128) for variable-length sequences of 128-dimensional vectors. Input shape: 3D tensor with shape: (batch_size, steps, input_dim) Output shape: 3D tensor with shape: (batch_size, new_steps, filters) steps value might have changed due to padding or strides. Scala: Conv1D(filters, kernelSize, strides=1, padding = valid , activation = null, useBias = True, kernelInitializer = glorot_uniform , biasInitializer = zero , kernelRegularizer = null, biasRegularizer = null, inputShape = null) Python: Conv1D(filters, kernel_size, strides=1, padding= valid , activation=None, use_bias=True, kernel_initializer= glorot_uniform , bias_initializer = zero , kernel_regularizer=None, bias_regularizer=None, input_shape=None, name=None) Parameters: filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of a single integer, specifying the length of the 1D convolution window. strides : An integer or tuple/list of a single integer, specifying the stride length of the convolution. padding : One of \"valid\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. activation : Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x ). use_bias : Boolean, whether the layer uses a bias vector. kernel_initializer : Initializer for the kernel weights matrix. Default is 'glorot_uniform'. bias_initializer : Initializer for the bias vector. kernel_regularizer : Regularizer function applied to the kernel weights matrix. Default is null. bias_regularizer : Regularizer function applied to the bias vector. Default is null. input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.Conv1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Conv1D[Float](8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.3490186 0.9116212 1.0265731 -1.1517781 -1.3408363 0.068315335 2.330641 0.15831113 -0.3477347 -0.31537533 -0.004820011 0.19639632 (2,.,.) = -2.5452073 -0.07062272 0.07531657 0.7308297 -0.5541283 -0.672619 0.4120175 -0.63392377 -1.7937882 1.178323 -0.9584365 0.35273483 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: (1,.,.) = 1.9344429 -0.67874485 -2.8546433 -0.6660415 2.754292 0.91595435 -0.32557443 0.25574505 (2,.,.) = -0.15532638 -1.7119135 -0.53497326 -1.4706889 0.4749836 2.0963004 -0.32759145 -2.57343 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import Conv1D model = Sequential() model.add(Conv1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.26717132 0.71646316 0.46861815 0.15532447] [0.43466464 0.48129897 0.31993028 0.17653698] [0.49705025 0.36898188 0.17595273 0.13695961]] [[0.05537173 0.62180016 0.36560319 0.95572837] [0.98196495 0.20136646 0.0423306 0.02030028] [0.65687877 0.91620089 0.37612963 0.52101501]]] Output is [[[ 0.14253668 0.4923424 0.08080368 -0.5239319 -0.26981926 0.57145274 0.48187608 1.4999257 ]] [[-0.10191379 0.51799184 -0.20100947 -0.7895199 -0.23697199 0.4781017 0.5892592 2.1963782 ]]]","title":"Conv1D"},{"location":"Keras2StyleAPIGuide/Layers/convolutional/#conv2d","text":"2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None , it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\" . Input shape: 4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last'. Output shape: 4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or 4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. rows and cols values might have changed due to padding. Scala: Conv2D(filters, kernelSize, strides, padding = valid , dataFormat = channels_first , activation = null, useBias = true, kernelInitializer = glorot_uniform , biasInitializer = zero , kernelRegularizer = null, biasRegularizer = null, inputShape = null) Python: Conv2D(filters, kernel_size, strides=(1, 1), padding= valid , data_format= channels_first , activation=None, use_bias=True, kernel_initializer= glorot_uniform , bias_initializer= zero , kernel_regularizer=None, bias_regularizer=None, input_shape=None, name=None) Parameters: filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). kernel_size : An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions. strides : A string, one of channels_last (default) or channels_first . The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\". padding : one of \"valid\" or \"same\" (case-insensitive). data_format : Number of columns in the convolution kernel. activation : Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x ). use_bias : Boolean, whether the layer uses a bias vector. Default is true. kernel_initializer : Initializer for the kernel weights matrix. Default is 'glorot_uniform'. bias_initializer : Initializer for the bias vector. kernel_regularizer : Regularizer function applied to the kernel weights matrix. Default is null. bias_regularizer : Regularizer function applied to the bias vector. Default is null. input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.Conv2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Conv2D[Float](4, Array(2, 2), activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.7008811 0.12288668 1.0145894 0.34869674 0.1495685 -0.84290063 -0.13881613 0.22891551 -0.065949395 0.7776933 0.3898055 0.8187307 (1,2,.,.) = -0.6645274 0.44756833 -0.8268243 -0.13796453 -1.2200167 -0.89445364 -0.16754562 -0.7029418 -0.032706447 -1.2504591 0.24031237 0.8331628 (2,1,.,.) = 0.025527362 -1.456607 1.4085853 2.115896 0.28405094 2.473169 -2.1256483 -0.37065008 1.1322745 2.3098936 0.40274113 -0.009792422 (2,2,.,.) = 0.38416716 0.42884415 0.48050597 -0.32054836 -0.18368138 -0.83845645 0.69398314 0.81973153 0.30809402 1.1508962 0.8602869 -0.27299604 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: (1,1,.,.) = 0.0 0.0 0.51253283 0.09132275 0.0 0.0 (1,2,.,.) = 0.96514046 0.32586247 0.0 0.0 0.7704669 0.0 (1,3,.,.) = 0.41404063 0.35680038 0.15091634 0.0 0.0 0.0 (1,4,.,.) = 0.0 0.5466105 0.0 0.0 0.0 0.45137247 (2,1,.,.) = 0.0 0.88202 0.0 0.0 2.1273396 0.0 (2,2,.,.) = 0.0 0.90696275 0.0 0.0 0.0 0.28731248 (2,3,.,.) = 0.0 0.0 0.5000323 0.0 0.0 0.0 (2,4,.,.) = 0.3865677 0.0 0.8942361 1.1031605 0.0 1.0433162 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import Conv2D model = Sequential() model.add(Conv2D(4, (2, 2), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.80687428 0.17910722 0.42103319 0.62854611] [0.15771997 0.63882001 0.47435052 0.74072266] [0.75874837 0.89953139 0.98486427 0.78619311]] [[0.17276155 0.6644038 0.06076521 0.93869801] [0.12812916 0.47968789 0.87123 0.15238281] [0.54624731 0.48725399 0.65683408 0.40533143]]] [[[0.67267837 0.08983171 0.77597291 0.64776813] [0.23830409 0.80719787 0.50198151 0.87555294] [0.83633492 0.84309489 0.54959086 0.09094626]] [[0.37056036 0.61459394 0.79002544 0.74196783] [0.33012708 0.90385893 0.45793861 0.89058154] [0.72228852 0.71115986 0.1502346 0.85841747]]]] Output is [[[[ 0.18198788 -0.07777633 -0.06771126] [ 0.11002313 0.09865391 0.13217448]] [[-0.41738698 0.0429197 -0.53935146] [-0.3684827 -0.61656874 -0.40491766]] [[ 0.15622243 0.31875694 0.4548544 ] [ 0.46874833 0.3621596 0.73849726]] [[ 0.21264602 0.73464984 0.38783965] [ 0.44780225 0.69555914 0.7172658 ]]] [[[-0.02473125 -0.26770562 0.06244571] [-0.04517556 0.03924857 0.12935217]] [[-0.21954477 -0.37033984 -0.44978783] [-0.45664912 -0.5516143 -0.34895533]] [[ 0.16499116 0.45316857 0.51688266] [ 0.4307469 0.5550571 0.06971958]] [[ 0.54072773 0.8459399 0.7282518 ] [ 0.71461993 0.6869658 0.5307025 ]]]]","title":"Conv2D"},{"location":"Keras2StyleAPIGuide/Layers/core/","text":"","title":"Core"},{"location":"Keras2StyleAPIGuide/Layers/dropout/","text":"","title":"Dropout"},{"location":"Keras2StyleAPIGuide/Layers/embedding/","text":"","title":"Embedding"},{"location":"Keras2StyleAPIGuide/Layers/initialization/","text":"","title":"Initialization"},{"location":"Keras2StyleAPIGuide/Layers/merge/","text":"Maximum Layer that computes the maximum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape). Scala: Maximum() Python: Maximum() Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Maximum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = Maximum[Float]().inputs(Array(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.0085953 1.1095089 1.7487661 1.576811 1.3192933 1.173145 1.7567515 1.750411 1.0303572 1.0285444 1.4724362 1.0070276 1.6837391 1.2812499 1.7207997 1.9301186 1.6642286 1.300531 1.2989123 1.0117699 1.5870146 1.2845709 1.9443712 1.1186409 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.6898564 0.98180896 0.22475463 0.44690642 0.22631128 0.8658154 0.96297216 0.038640756 0.33791444 0.35920507 0.2056811 0.97009206 0.891668 0.73843783 0.49456882 0.92106706 0.54771185 0.52310455 0.49114317 0.93534994 0.82244986 0.080847055 0.56450963 0.73846775 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 1.0085953 1.1095089 1.7487661 1.576811 1.3192933 1.173145 1.7567515 1.750411 1.0303572 1.0285444 1.4724362 1.0070276 1.6837391 1.2812499 1.7207997 1.9301186 1.6642286 1.300531 1.2989123 1.0117699 1.5870146 1.2845709 1.9443712 1.1186409 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import Maximum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = Maximum()([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.85046637 0.76454759 0.92092265 0.18948392 0.96141892 0.75558563 0.16956892 0.49839472] [0.36737777 0.25567011 0.36751645 0.49982497 0.62344662 0.10207675 0.14432582 0.09316922] [0.34775348 0.56521665 0.01922694 0.97405856 0.96318355 0.48008106 0.09525403 0.64539933]] input2: [[0.23219699 4.58298671 4.08334902 3.35729794 3.28995515 3.88572392 0.13552906 2.20767025] [4.41043478 0.74315223 1.57928439 4.06317265 4.35646267 4.43969778 0.64163024 0.14681471] [1.60829488 3.75488617 4.69265858 1.38504037 3.2210222 3.4321568 4.00735856 2.6106414 ]] Output is [[0.8504664 4.582987 4.083349 3.357298 3.2899551 3.8857238 0.16956893 2.2076702 ] [4.4104347 0.74315226 1.5792844 4.063173 4.3564625 4.4396977 0.64163023 0.1468147 ] [1.6082948 3.7548862 4.6926584 1.3850404 3.2210221 3.4321568 4.0073586 2.6106415 ]] maximum Functional interface to the Maximum layer. Scala: maximum(inputs) Python: maximum(inputs) Parameters: inputs : A list of input tensors (at least 2). **kwargs : Standard layer keyword arguments. Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Maximum.maximum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = maximum(inputs = List(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.5386189 1.67534 1.3651735 1.0366004 1.2869223 1.6384993 1.5557045 1.5723307 1.2382979 1.0155076 1.1055984 1.1010389 1.6874355 1.3107576 1.2041453 1.9931196 1.4011493 1.0774659 1.3888124 1.7762307 1.8265619 1.7934192 1.7732148 1.2978737 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.14446749 0.7428541 0.9886685 0.5107685 0.85201174 0.40988243 0.12447342 0.8556565 0.91737056 0.35073906 0.07863916 0.89909834 0.8177192 0.09691833 0.1997524 0.4406145 0.4190805 0.6956053 0.9765333 0.6748145 0.87814146 0.5421859 0.31012502 0.25200275 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 1.5386189 1.67534 1.3651735 1.0366004 1.2869223 1.6384993 1.5557045 1.5723307 1.2382979 1.0155076 1.1055984 1.1010389 1.6874355 1.3107576 1.2041453 1.9931196 1.4011493 1.0774659 1.3888124 1.7762307 1.8265619 1.7934192 1.7732148 1.2978737 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import maximum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = maximum([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.32837152 0.66842081 0.5893283 0.71063029 0.53254716 0.98882168 0.53400631 0.93659819] [0.6198554 0.51117444 0.74729989 0.65475831 0.70510429 0.87443468 0.5629698 0.285089 ] [0.43159809 0.84360242 0.8493521 0.78723246 0.35496674 0.00144353 0.07231955 0.76153367]] input2: [[4.00763759 0.37730923 3.88563172 2.22099527 3.38980926 2.84321074 0.29846632 4.07808143] [0.36804983 2.34995472 2.24190514 1.63816757 2.22642342 1.45099988 0.55931613 0.42101343] [0.30218586 2.75409562 0.24024987 3.89805855 4.57479762 2.6592906 2.38562566 1.46560388]] Output is [[4.0076375 0.6684208 3.8856318 2.2209952 3.3898094 2.8432107 0.5340063 4.0780816 ] [0.6198554 2.3499546 2.2419052 1.6381676 2.2264235 1.4509999 0.5629698 0.42101344] [0.4315981 2.7540956 0.8493521 3.8980587 4.5747976 2.6592906 2.3856256 1.4656038 ]] Minimum Layer that computes the minimum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape). Scala: Minimum() Python: Minimum() Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Minimum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = Minimum[Float]().inputs(Array(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.9953886 1.0161483 1.844671 1.1757553 1.7548938 1.4735664 1.981268 1.354598 1.786057 1.4920603 1.538079 1.6601591 1.5213481 1.9032607 1.5938802 1.9769413 1.428338 1.5083437 1.1141979 1.4320385 1.9785057 1.845624 1.0637122 1.8684102 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.6624951 0.71156764 0.004659928 0.8797748 0.8676378 0.5605965 0.03135305 0.3550916 0.86810714 0.26216865 0.8639284 0.3357767 0.22505952 0.8216017 0.74407136 0.73391193 0.74810994 0.11495259 0.89162785 0.93693215 0.5673804 0.20798753 0.022446347 0.36790285 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 0.6624951 0.71156764 0.004659928 0.8797748 0.8676378 0.5605965 0.03135305 0.3550916 0.86810714 0.26216865 0.8639284 0.3357767 0.22505952 0.8216017 0.74407136 0.73391193 0.74810994 0.11495259 0.89162785 0.93693215 0.5673804 0.20798753 0.022446347 0.36790285 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import Minimum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = Minimum()([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.15979525 0.48601263 0.10587506 0.61769843 0.26736246 0.64769634 0.01616307 0.93659085] [0.3412241 0.02449786 0.64638927 0.32875475 0.77737532 0.94151168 0.95571165 0.1285685 ] [0.9758039 0.89746475 0.84606271 0.87471803 0.80568297 0.85872464 0.77484317 0.73048055]] input2: [[0.99780609 1.48670819 0.08911578 2.68460415 1.21065202 1.82819649 2.91991375 1.07241835] [3.18491884 3.72856744 3.82128444 1.53010301 1.20795887 3.20653343 3.07794378 1.59084261] [4.39776482 3.37465746 0.23752302 3.47325532 2.38110537 4.64806043 3.99013359 0.56055062]] Output is [[0.15979525 0.48601264 0.08911578 0.61769843 0.26736248 0.6476963 0.01616307 0.93659085] [0.3412241 0.02449786 0.64638925 0.32875475 0.77737534 0.9415117 0.95571166 0.1285685 ] [0.9758039 0.89746475 0.23752302 0.874718 0.80568296 0.85872465 0.77484316 0.56055063]] minimum Functional interface to the Minimum layer. Scala: minimum(inputs) Python: minimum(inputs) Parameters: inputs : A list of input tensors (at least 2). **kwargs : Standard layer keyword arguments. Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Minimum.minimum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = minimum(inputs = List(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.0131017 1.7637167 1.3681185 1.6208028 1.2059574 1.967363 1.5065156 1.5110291 1.1055611 1.4148856 1.5531528 1.3481603 1.3744175 1.5192658 1.7290237 1.629003 1.5601189 1.4540797 1.0981613 1.2463317 1.9510872 1.0527081 1.0487831 1.4148198 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.96061057 0.41263154 0.5029265 0.28855637 0.8030459 0.5923882 0.93190056 0.15111573 0.54223496 0.37586558 0.63049513 0.32910138 0.029513072 0.017590795 0.1943584 0.77225924 0.21727595 0.6552713 0.899118 0.07937545 0.016797619 0.5491529 0.7383374 0.8877089 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 0.96061057 0.41263154 0.5029265 0.28855637 0.8030459 0.5923882 0.93190056 0.15111573 0.54223496 0.37586558 0.63049513 0.32910138 0.029513072 0.017590795 0.1943584 0.77225924 0.21727595 0.6552713 0.899118 0.07937545 0.016797619 0.5491529 0.7383374 0.8877089 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import minimum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = minimum([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.82114595 0.19940446 0.57764964 0.49092517 0.67671559 0.72676631 0.85955214 0.80265871] [0.05640074 0.17010821 0.4896911 0.14905843 0.33233282 0.82684842 0.58635163 0.10010479] [0.83053659 0.83788089 0.6177536 0.71670009 0.54454425 0.19431431 0.49180683 0.25640596]] input2: [[0.47446558 3.8752243 4.9299194 3.35971335 0.85980843 2.37388383 4.38802943 4.3253041 ] [2.65459389 2.93173369 3.6176582 0.75475853 0.62484204 4.16820336 3.24864692 1.42238813] [0.439386 2.43623362 0.20248675 1.60213208 1.08081789 0.59718494 0.29896311 0.73010527]] Output is [[0.47446558 0.19940446 0.57764965 0.49092516 0.6767156 0.7267663 0.85955215 0.80265874] [0.05640074 0.17010821 0.4896911 0.14905843 0.33233282 0.82684845 0.58635163 0.10010479] [0.439386 0.8378809 0.20248675 0.7167001 0.5445443 0.1943143 0.2989631 0.25640595]]","title":"Merge"},{"location":"Keras2StyleAPIGuide/Layers/merge/#maximum","text":"Layer that computes the maximum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape). Scala: Maximum() Python: Maximum() Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Maximum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = Maximum[Float]().inputs(Array(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.0085953 1.1095089 1.7487661 1.576811 1.3192933 1.173145 1.7567515 1.750411 1.0303572 1.0285444 1.4724362 1.0070276 1.6837391 1.2812499 1.7207997 1.9301186 1.6642286 1.300531 1.2989123 1.0117699 1.5870146 1.2845709 1.9443712 1.1186409 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.6898564 0.98180896 0.22475463 0.44690642 0.22631128 0.8658154 0.96297216 0.038640756 0.33791444 0.35920507 0.2056811 0.97009206 0.891668 0.73843783 0.49456882 0.92106706 0.54771185 0.52310455 0.49114317 0.93534994 0.82244986 0.080847055 0.56450963 0.73846775 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 1.0085953 1.1095089 1.7487661 1.576811 1.3192933 1.173145 1.7567515 1.750411 1.0303572 1.0285444 1.4724362 1.0070276 1.6837391 1.2812499 1.7207997 1.9301186 1.6642286 1.300531 1.2989123 1.0117699 1.5870146 1.2845709 1.9443712 1.1186409 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import Maximum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = Maximum()([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.85046637 0.76454759 0.92092265 0.18948392 0.96141892 0.75558563 0.16956892 0.49839472] [0.36737777 0.25567011 0.36751645 0.49982497 0.62344662 0.10207675 0.14432582 0.09316922] [0.34775348 0.56521665 0.01922694 0.97405856 0.96318355 0.48008106 0.09525403 0.64539933]] input2: [[0.23219699 4.58298671 4.08334902 3.35729794 3.28995515 3.88572392 0.13552906 2.20767025] [4.41043478 0.74315223 1.57928439 4.06317265 4.35646267 4.43969778 0.64163024 0.14681471] [1.60829488 3.75488617 4.69265858 1.38504037 3.2210222 3.4321568 4.00735856 2.6106414 ]] Output is [[0.8504664 4.582987 4.083349 3.357298 3.2899551 3.8857238 0.16956893 2.2076702 ] [4.4104347 0.74315226 1.5792844 4.063173 4.3564625 4.4396977 0.64163023 0.1468147 ] [1.6082948 3.7548862 4.6926584 1.3850404 3.2210221 3.4321568 4.0073586 2.6106415 ]]","title":"Maximum"},{"location":"Keras2StyleAPIGuide/Layers/merge/#maximum_1","text":"Functional interface to the Maximum layer. Scala: maximum(inputs) Python: maximum(inputs) Parameters: inputs : A list of input tensors (at least 2). **kwargs : Standard layer keyword arguments. Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Maximum.maximum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = maximum(inputs = List(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.5386189 1.67534 1.3651735 1.0366004 1.2869223 1.6384993 1.5557045 1.5723307 1.2382979 1.0155076 1.1055984 1.1010389 1.6874355 1.3107576 1.2041453 1.9931196 1.4011493 1.0774659 1.3888124 1.7762307 1.8265619 1.7934192 1.7732148 1.2978737 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.14446749 0.7428541 0.9886685 0.5107685 0.85201174 0.40988243 0.12447342 0.8556565 0.91737056 0.35073906 0.07863916 0.89909834 0.8177192 0.09691833 0.1997524 0.4406145 0.4190805 0.6956053 0.9765333 0.6748145 0.87814146 0.5421859 0.31012502 0.25200275 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 1.5386189 1.67534 1.3651735 1.0366004 1.2869223 1.6384993 1.5557045 1.5723307 1.2382979 1.0155076 1.1055984 1.1010389 1.6874355 1.3107576 1.2041453 1.9931196 1.4011493 1.0774659 1.3888124 1.7762307 1.8265619 1.7934192 1.7732148 1.2978737 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import maximum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = maximum([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.32837152 0.66842081 0.5893283 0.71063029 0.53254716 0.98882168 0.53400631 0.93659819] [0.6198554 0.51117444 0.74729989 0.65475831 0.70510429 0.87443468 0.5629698 0.285089 ] [0.43159809 0.84360242 0.8493521 0.78723246 0.35496674 0.00144353 0.07231955 0.76153367]] input2: [[4.00763759 0.37730923 3.88563172 2.22099527 3.38980926 2.84321074 0.29846632 4.07808143] [0.36804983 2.34995472 2.24190514 1.63816757 2.22642342 1.45099988 0.55931613 0.42101343] [0.30218586 2.75409562 0.24024987 3.89805855 4.57479762 2.6592906 2.38562566 1.46560388]] Output is [[4.0076375 0.6684208 3.8856318 2.2209952 3.3898094 2.8432107 0.5340063 4.0780816 ] [0.6198554 2.3499546 2.2419052 1.6381676 2.2264235 1.4509999 0.5629698 0.42101344] [0.4315981 2.7540956 0.8493521 3.8980587 4.5747976 2.6592906 2.3856256 1.4656038 ]]","title":"maximum"},{"location":"Keras2StyleAPIGuide/Layers/merge/#minimum","text":"Layer that computes the minimum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape). Scala: Minimum() Python: Minimum() Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Minimum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = Minimum[Float]().inputs(Array(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.9953886 1.0161483 1.844671 1.1757553 1.7548938 1.4735664 1.981268 1.354598 1.786057 1.4920603 1.538079 1.6601591 1.5213481 1.9032607 1.5938802 1.9769413 1.428338 1.5083437 1.1141979 1.4320385 1.9785057 1.845624 1.0637122 1.8684102 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.6624951 0.71156764 0.004659928 0.8797748 0.8676378 0.5605965 0.03135305 0.3550916 0.86810714 0.26216865 0.8639284 0.3357767 0.22505952 0.8216017 0.74407136 0.73391193 0.74810994 0.11495259 0.89162785 0.93693215 0.5673804 0.20798753 0.022446347 0.36790285 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 0.6624951 0.71156764 0.004659928 0.8797748 0.8676378 0.5605965 0.03135305 0.3550916 0.86810714 0.26216865 0.8639284 0.3357767 0.22505952 0.8216017 0.74407136 0.73391193 0.74810994 0.11495259 0.89162785 0.93693215 0.5673804 0.20798753 0.022446347 0.36790285 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import Minimum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = Minimum()([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.15979525 0.48601263 0.10587506 0.61769843 0.26736246 0.64769634 0.01616307 0.93659085] [0.3412241 0.02449786 0.64638927 0.32875475 0.77737532 0.94151168 0.95571165 0.1285685 ] [0.9758039 0.89746475 0.84606271 0.87471803 0.80568297 0.85872464 0.77484317 0.73048055]] input2: [[0.99780609 1.48670819 0.08911578 2.68460415 1.21065202 1.82819649 2.91991375 1.07241835] [3.18491884 3.72856744 3.82128444 1.53010301 1.20795887 3.20653343 3.07794378 1.59084261] [4.39776482 3.37465746 0.23752302 3.47325532 2.38110537 4.64806043 3.99013359 0.56055062]] Output is [[0.15979525 0.48601264 0.08911578 0.61769843 0.26736248 0.6476963 0.01616307 0.93659085] [0.3412241 0.02449786 0.64638925 0.32875475 0.77737534 0.9415117 0.95571166 0.1285685 ] [0.9758039 0.89746475 0.23752302 0.874718 0.80568296 0.85872465 0.77484316 0.56055063]]","title":"Minimum"},{"location":"Keras2StyleAPIGuide/Layers/merge/#minimum_1","text":"Functional interface to the Minimum layer. Scala: minimum(inputs) Python: minimum(inputs) Parameters: inputs : A list of input tensors (at least 2). **kwargs : Standard layer keyword arguments. Scala example: import com.intel.analytics.zoo.pipeline.api.keras2.layers.Minimum.minimum import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.zoo.pipeline.api.keras.layers.Input import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input1 = Tensor[Float](3, 8).rand(0, 1) val input2 = Tensor[Float](3, 8).rand(1, 2) val input = T(1 - input1, 2 - input2) val l1 = Input[Float](inputShape = Shape(8)) val l2 = Input[Float](inputShape = Shape(8)) val layer = minimum(inputs = List(l1, l2)) val model = Model[Float](Array(l1, l2), layer) val output = model.forward(input) Input is: input: { 2: 1.0131017 1.7637167 1.3681185 1.6208028 1.2059574 1.967363 1.5065156 1.5110291 1.1055611 1.4148856 1.5531528 1.3481603 1.3744175 1.5192658 1.7290237 1.629003 1.5601189 1.4540797 1.0981613 1.2463317 1.9510872 1.0527081 1.0487831 1.4148198 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] 1: 0.96061057 0.41263154 0.5029265 0.28855637 0.8030459 0.5923882 0.93190056 0.15111573 0.54223496 0.37586558 0.63049513 0.32910138 0.029513072 0.017590795 0.1943584 0.77225924 0.21727595 0.6552713 0.899118 0.07937545 0.016797619 0.5491529 0.7383374 0.8877089 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] } Output is: output: 0.96061057 0.41263154 0.5029265 0.28855637 0.8030459 0.5923882 0.93190056 0.15111573 0.54223496 0.37586558 0.63049513 0.32910138 0.029513072 0.017590795 0.1943584 0.77225924 0.21727595 0.6552713 0.899118 0.07937545 0.016797619 0.5491529 0.7383374 0.8877089 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras2.layers import minimum from zoo.pipeline.api.keras.layers import Input l1 = Input(shape=[8]) l2 =Input(shape=[8]) layer = minimum([l1, l2]) input1 = np.random.random([3, 8]) input2 = 5 * np.random.random([3, 8]) model = Model([l1, l2], layer) output = model.forward([input1, input2]) Input is: input1: [[0.82114595 0.19940446 0.57764964 0.49092517 0.67671559 0.72676631 0.85955214 0.80265871] [0.05640074 0.17010821 0.4896911 0.14905843 0.33233282 0.82684842 0.58635163 0.10010479] [0.83053659 0.83788089 0.6177536 0.71670009 0.54454425 0.19431431 0.49180683 0.25640596]] input2: [[0.47446558 3.8752243 4.9299194 3.35971335 0.85980843 2.37388383 4.38802943 4.3253041 ] [2.65459389 2.93173369 3.6176582 0.75475853 0.62484204 4.16820336 3.24864692 1.42238813] [0.439386 2.43623362 0.20248675 1.60213208 1.08081789 0.59718494 0.29896311 0.73010527]] Output is [[0.47446558 0.19940446 0.57764965 0.49092516 0.6767156 0.7267663 0.85955215 0.80265874] [0.05640074 0.17010821 0.4896911 0.14905843 0.33233282 0.82684845 0.58635163 0.10010479] [0.439386 0.8378809 0.20248675 0.7167001 0.5445443 0.1943143 0.2989631 0.25640595]]","title":"minimum"},{"location":"Keras2StyleAPIGuide/Layers/normalization/","text":"","title":"Normalization"},{"location":"Keras2StyleAPIGuide/Layers/pooling/","text":"MaxPooling1D Max pooling operation for temporal data. Input shape: 3D tensor with shape: (batch_size, steps, features) . Output shape: 3D tensor with shape: (batch_size, downsampled_steps, features) . Scala: MaxPooling1D(poolSize = 2, strides = -1, padding = valid , inputShape = null) Python: MaxPooling1D(pool_size=2, strides=None, padding= valid , input_shape=None, name=None) Parameters: pool_size : Integer, size of the max pooling windows. Default is 2. strides : Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will be set to -1, which will be default to pool_size. padding : One of \"valid\" or \"same\" (case-insensitive). input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.MaxPooling1D val seq = Sequential[Float]() val layer = MaxPooling1D[Float](poolSize = 3, inputShape = Shape(4, 5)) seq.add(layer) val input = Tensor[Float](3, 4, 5).randn() val output = seq.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8663151 -0.23868443 -0.00667114 0.57754266 -1.1602311 1.453712 0.1588971 0.71542656 1.6594391 0.04762305 2.6128695 -0.4991936 0.37722582 0.07411593 1.8921419 0.85887206 0.99118704 0.717694 0.5889265 1.4998609 (2,.,.) = -2.3484302 -0.40476575 0.29646426 0.6123499 -2.3566647 -0.27840275 -0.0931928 -1.0732254 -0.28036273 -0.19488569 0.4438278 -0.13150546 -0.8513687 0.5319984 1.4565476 -1.8620179 -0.19861892 -0.14878958 1.4498321 0.016972434 (3,.,.) = -1.6097814 1.1128851 -1.7357148 -0.3583554 -0.6089424 2.1183956 0.6400526 0.26053894 -2.5416205 -0.9832211 0.2170545 0.28168106 -0.009057811 1.7110301 1.0579157 -0.46720266 -0.87794846 0.2708433 -1.6016585 0.23714945 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: (1,.,.) = 2.6128695 0.1588971 0.71542656 1.6594391 1.8921419 (2,.,.) = 0.4438278 -0.0931928 0.29646426 0.6123499 1.4565476 (3,.,.) = 2.1183956 1.1128851 0.26053894 1.7110301 1.0579157 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import MaxPooling1D model = Sequential() model.add(MaxPooling1D(pool_size=3, input_shape=(4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.65224256 0.20913976 0.37685946 0.57730155 0.66970161] [0.26367096 0.94933166 0.09015655 0.15487805 0.74161953] [0.55753943 0.6805039 0.42343199 0.25051912 0.59142363] [0.77773199 0.57204293 0.22107977 0.54485067 0.00167209]] [[0.12947324 0.13329145 0.95614414 0.85027407 0.5055782 ] [0.40469384 0.46683239 0.57578244 0.67001174 0.53348182] [0.2170539 0.51992802 0.31005515 0.67494018 0.74330305] [0.48408556 0.26271 0.32412418 0.08973007 0.01880989]] [[0.80010078 0.54220073 0.653223 0.29034995 0.11341325] [0.66065103 0.49484952 0.83346121 0.47914374 0.81174956] [0.29151878 0.61798409 0.74534208 0.92317947 0.54144718] [0.26080681 0.41200147 0.79630472 0.6739419 0.435016 ]]] Output is: [[[0.65224254 0.94933164 0.423432 0.57730156 0.7416195 ]] [[0.40469384 0.51992804 0.95614415 0.8502741 0.74330306]] [[0.8001008 0.6179841 0.8334612 0.92317945 0.8117496 ]]] AveragePooling1D Average pooling for temporal data. Input shape: 3D tensor with shape: (batch_size, steps, features) . Output shape: 3D tensor with shape: (batch_size, downsampled_steps, features) . Scala: AveragePooling1D(poolSize = 2, strides = -1, padding = valid , inputShape = null) Python: AveragePooling1D(pool_size=2, strides=None, padding= valid , input_shape=None, name=None) Parameters: pool_size : Integer, size of the average pooling windows. Default is 2. strides : Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will be set to -1, which will be default to pool_size. padding : One of \"valid\" or \"same\" (case-insensitive). input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.AveragePooling1D val seq = Sequential[Float]() val layer = AveragePooling1D[Float](poolSize = 3, inputShape = Shape(4, 5)) seq.add(layer) val input = Tensor[Float](3, 4, 5).randn() val output = seq.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.7240005 -0.06335294 0.6269808 0.24385877 0.014416845 -0.7663384 0.58187956 0.35314906 0.60641724 -0.2761965 1.0691774 -0.671351 0.7121989 0.7686876 0.14512675 -0.83099926 -0.31942126 -0.8608722 1.3061627 0.67469263 (2,.,.) = 0.32662675 -0.8206316 -2.312093 -1.2558469 0.0048087407 -0.46804208 -0.008146223 -1.3610557 -0.29545167 -0.9627323 -0.04214055 0.073838815 0.018005485 0.22931503 -0.6118381 0.23300731 0.059008796 -0.58128744 -0.49869594 0.6242729 (3,.,.) = 0.60912937 0.6315228 -0.23742959 -1.1818335 0.11456228 -0.4489492 0.2996443 -0.9002065 -0.53337836 -0.019300539 0.2350515 -1.0584278 -0.051998064 -1.2586755 0.17742781 1.3912749 -0.97213763 1.573626 0.36101308 0.11868247 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: (1,.,.) = 0.67561316 -0.050941467 0.56410956 0.53965455 -0.03888431 (2,.,.) = -0.06118529 -0.25164634 -1.218381 -0.44066116 -0.5232539 (3,.,.) = 0.1317439 -0.04242025 -0.3965447 -0.9912958 0.09089652 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import AveragePooling1D model = Sequential() model.add(AveragePooling1D(pool_size=3, input_shape=(4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.52804108 0.69499686 0.42818504 0.2107447 0.39879583] [0.01134639 0.74244503 0.71352988 0.4656967 0.56990969] [0.60781477 0.34275853 0.09997229 0.15758047 0.38226729] [0.8884477 0.57125125 0.19161781 0.70570558 0.38504297]] [[0.68505125 0.10344407 0.26294358 0.84476828 0.37145984] [0.5073895 0.17534648 0.88501456 0.12600059 0.43856957] [0.74562707 0.25003322 0.34860707 0.16645732 0.04184937] [0.5352171 0.85188837 0.64421649 0.51544795 0.7619103 ]] [[0.08110649 0.84742271 0.08083711 0.43689189 0.21256946] [0.24837393 0.53503375 0.41418659 0.34652157 0.00923598] [0.89420575 0.60971584 0.7718259 0.06192155 0.09029334] [0.72170843 0.0589505 0.78960517 0.9543299 0.2462495 ]]] Output is: [[[0.38240075 0.5934002 0.41389573 0.2780073 0.4503243 ]] [[0.6460226 0.17627458 0.49885502 0.3790754 0.2839596 ]] [[0.40789542 0.66405743 0.4222832 0.2817783 0.10403293]]]","title":"Pooling"},{"location":"Keras2StyleAPIGuide/Layers/pooling/#maxpooling1d","text":"Max pooling operation for temporal data. Input shape: 3D tensor with shape: (batch_size, steps, features) . Output shape: 3D tensor with shape: (batch_size, downsampled_steps, features) . Scala: MaxPooling1D(poolSize = 2, strides = -1, padding = valid , inputShape = null) Python: MaxPooling1D(pool_size=2, strides=None, padding= valid , input_shape=None, name=None) Parameters: pool_size : Integer, size of the max pooling windows. Default is 2. strides : Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will be set to -1, which will be default to pool_size. padding : One of \"valid\" or \"same\" (case-insensitive). input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.MaxPooling1D val seq = Sequential[Float]() val layer = MaxPooling1D[Float](poolSize = 3, inputShape = Shape(4, 5)) seq.add(layer) val input = Tensor[Float](3, 4, 5).randn() val output = seq.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8663151 -0.23868443 -0.00667114 0.57754266 -1.1602311 1.453712 0.1588971 0.71542656 1.6594391 0.04762305 2.6128695 -0.4991936 0.37722582 0.07411593 1.8921419 0.85887206 0.99118704 0.717694 0.5889265 1.4998609 (2,.,.) = -2.3484302 -0.40476575 0.29646426 0.6123499 -2.3566647 -0.27840275 -0.0931928 -1.0732254 -0.28036273 -0.19488569 0.4438278 -0.13150546 -0.8513687 0.5319984 1.4565476 -1.8620179 -0.19861892 -0.14878958 1.4498321 0.016972434 (3,.,.) = -1.6097814 1.1128851 -1.7357148 -0.3583554 -0.6089424 2.1183956 0.6400526 0.26053894 -2.5416205 -0.9832211 0.2170545 0.28168106 -0.009057811 1.7110301 1.0579157 -0.46720266 -0.87794846 0.2708433 -1.6016585 0.23714945 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: (1,.,.) = 2.6128695 0.1588971 0.71542656 1.6594391 1.8921419 (2,.,.) = 0.4438278 -0.0931928 0.29646426 0.6123499 1.4565476 (3,.,.) = 2.1183956 1.1128851 0.26053894 1.7110301 1.0579157 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import MaxPooling1D model = Sequential() model.add(MaxPooling1D(pool_size=3, input_shape=(4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.65224256 0.20913976 0.37685946 0.57730155 0.66970161] [0.26367096 0.94933166 0.09015655 0.15487805 0.74161953] [0.55753943 0.6805039 0.42343199 0.25051912 0.59142363] [0.77773199 0.57204293 0.22107977 0.54485067 0.00167209]] [[0.12947324 0.13329145 0.95614414 0.85027407 0.5055782 ] [0.40469384 0.46683239 0.57578244 0.67001174 0.53348182] [0.2170539 0.51992802 0.31005515 0.67494018 0.74330305] [0.48408556 0.26271 0.32412418 0.08973007 0.01880989]] [[0.80010078 0.54220073 0.653223 0.29034995 0.11341325] [0.66065103 0.49484952 0.83346121 0.47914374 0.81174956] [0.29151878 0.61798409 0.74534208 0.92317947 0.54144718] [0.26080681 0.41200147 0.79630472 0.6739419 0.435016 ]]] Output is: [[[0.65224254 0.94933164 0.423432 0.57730156 0.7416195 ]] [[0.40469384 0.51992804 0.95614415 0.8502741 0.74330306]] [[0.8001008 0.6179841 0.8334612 0.92317945 0.8117496 ]]]","title":"MaxPooling1D"},{"location":"Keras2StyleAPIGuide/Layers/pooling/#averagepooling1d","text":"Average pooling for temporal data. Input shape: 3D tensor with shape: (batch_size, steps, features) . Output shape: 3D tensor with shape: (batch_size, downsampled_steps, features) . Scala: AveragePooling1D(poolSize = 2, strides = -1, padding = valid , inputShape = null) Python: AveragePooling1D(pool_size=2, strides=None, padding= valid , input_shape=None, name=None) Parameters: pool_size : Integer, size of the average pooling windows. Default is 2. strides : Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will be set to -1, which will be default to pool_size. padding : One of \"valid\" or \"same\" (case-insensitive). input_shape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras2.layers.AveragePooling1D val seq = Sequential[Float]() val layer = AveragePooling1D[Float](poolSize = 3, inputShape = Shape(4, 5)) seq.add(layer) val input = Tensor[Float](3, 4, 5).randn() val output = seq.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.7240005 -0.06335294 0.6269808 0.24385877 0.014416845 -0.7663384 0.58187956 0.35314906 0.60641724 -0.2761965 1.0691774 -0.671351 0.7121989 0.7686876 0.14512675 -0.83099926 -0.31942126 -0.8608722 1.3061627 0.67469263 (2,.,.) = 0.32662675 -0.8206316 -2.312093 -1.2558469 0.0048087407 -0.46804208 -0.008146223 -1.3610557 -0.29545167 -0.9627323 -0.04214055 0.073838815 0.018005485 0.22931503 -0.6118381 0.23300731 0.059008796 -0.58128744 -0.49869594 0.6242729 (3,.,.) = 0.60912937 0.6315228 -0.23742959 -1.1818335 0.11456228 -0.4489492 0.2996443 -0.9002065 -0.53337836 -0.019300539 0.2350515 -1.0584278 -0.051998064 -1.2586755 0.17742781 1.3912749 -0.97213763 1.573626 0.36101308 0.11868247 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: (1,.,.) = 0.67561316 -0.050941467 0.56410956 0.53965455 -0.03888431 (2,.,.) = -0.06118529 -0.25164634 -1.218381 -0.44066116 -0.5232539 (3,.,.) = 0.1317439 -0.04242025 -0.3965447 -0.9912958 0.09089652 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras2.layers import AveragePooling1D model = Sequential() model.add(AveragePooling1D(pool_size=3, input_shape=(4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.52804108 0.69499686 0.42818504 0.2107447 0.39879583] [0.01134639 0.74244503 0.71352988 0.4656967 0.56990969] [0.60781477 0.34275853 0.09997229 0.15758047 0.38226729] [0.8884477 0.57125125 0.19161781 0.70570558 0.38504297]] [[0.68505125 0.10344407 0.26294358 0.84476828 0.37145984] [0.5073895 0.17534648 0.88501456 0.12600059 0.43856957] [0.74562707 0.25003322 0.34860707 0.16645732 0.04184937] [0.5352171 0.85188837 0.64421649 0.51544795 0.7619103 ]] [[0.08110649 0.84742271 0.08083711 0.43689189 0.21256946] [0.24837393 0.53503375 0.41418659 0.34652157 0.00923598] [0.89420575 0.60971584 0.7718259 0.06192155 0.09029334] [0.72170843 0.0589505 0.78960517 0.9543299 0.2462495 ]]] Output is: [[[0.38240075 0.5934002 0.41389573 0.2780073 0.4503243 ]] [[0.6460226 0.17627458 0.49885502 0.3790754 0.2839596 ]] [[0.40789542 0.66405743 0.4222832 0.2817783 0.10403293]]]","title":"AveragePooling1D"},{"location":"Keras2StyleAPIGuide/Layers/recurrent/","text":"","title":"Recurrent"},{"location":"Keras2StyleAPIGuide/Layers/wrappers/","text":"","title":"Wrappers"},{"location":"Keras2StyleAPIGuide/Optimization/loss/","text":"","title":"Loss"},{"location":"Keras2StyleAPIGuide/Optimization/optimizer/","text":"","title":"Optimizer"},{"location":"Keras2StyleAPIGuide/Optimization/training/","text":"","title":"Training"},{"location":"KerasStyleAPIGuide/keras-api-python/","text":"Introduction We provide Keras-Style API based on Keras 1.2.2 in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion. To define a model in Python using the Keras-Style API, now one just need to import the following packages: from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * One of the highlighted features with regard to the Keras-Style API is shape inference . Users only need to specify the input shape (a shape tuple excluding batch dimension, for example, input_shape=(3, 4) for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred. Define a model You can define a model either using Sequential API or Functional API . Remember to specify the input shape for the first layer. After creating a model, you can call the following methods : get_input_shape() get_output_shape() Return the input or output shape of a model, which is a shape tuple. The first entry is None representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned. set_name(name) Set the name of the model. Can alternatively specify the argument name in the constructor when creating a model. Sequential API The model is described as a linear stack of layers in the Sequential API. Layers can be added into the Sequential container one by one and the order of the layers in the model will be the same as the insertion order. To create a sequential container: Sequential() Example code to create a sequential model: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Dense, Activation model = Sequential() model.add(Dense(32, input_shape=(128, ))) model.add(Activation( relu )) Functional API The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs). To create an input node: Input(shape=None, name=None) Parameters: shape : A shape tuple indicating the shape of the input node, not including batch. name : String to set the name of the input node. If not specified, its name will by default to be a generated string. To create a graph container: Model(input, output) Parameters: input : An input node or a list of input nodes. output : An output node or a list of output nodes. To merge a list of input nodes ( NOT layers), following some merge mode in the Functional API: merge(inputs, mode= sum , concat_axis=-1) # This will return an output NODE. Parameters: inputs : A list of node instances. Must be more than one node. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concat_axis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. Example code to create a graph model: from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras.layers import Input, Dense, merge # instantiate input nodes input1 = Input(shape=(8, )) input2 = Input(shape=(6, )) # pass an input node into a layer and get an output node dense1 = Dense(10)(input1) dense2 = Dense(10)(input2) # merge two nodes following some merge mode output = merge([dense1, dense2], mode= sum ) # create a graph container model = Model([input1, input2], output) Layers See here for all the available layers for the Keras-Style API. To set the name of a layer, you can either call set_name(name) or alternatively specify the argument name in the constructor when creating a layer. LeNet Example Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import * model = Sequential() model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation= tanh , name= fc1 )) model.add(Dense(10, activation= softmax , name= fc2 )) model.get_input_shape() # (None, 28, 28, 1) model.get_output_shape() # (None, 10) Keras Code Support If you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with: from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * and making modifications subject to the following limitations: The Keras version we support and test is Keras 1.2.2 with TensorFlow backend. There exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See here for the full list of unsupported layer arguments. The default dim_ordering in Analytics Zoo is th (Channel First, channel_axis=1). Keras backend related code needs to be deleted or refactored appropriately. Code involving Keras utility functions or loading weights from HDF5 files should be removed. Remark: We have tested for migrating Keras code definition of VGG16 , VGG19 , ResNet50 and InceptionV3 into Analytics Zoo.","title":"Python Guide"},{"location":"KerasStyleAPIGuide/keras-api-python/#introduction","text":"We provide Keras-Style API based on Keras 1.2.2 in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion. To define a model in Python using the Keras-Style API, now one just need to import the following packages: from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * One of the highlighted features with regard to the Keras-Style API is shape inference . Users only need to specify the input shape (a shape tuple excluding batch dimension, for example, input_shape=(3, 4) for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.","title":"Introduction"},{"location":"KerasStyleAPIGuide/keras-api-python/#define-a-model","text":"You can define a model either using Sequential API or Functional API . Remember to specify the input shape for the first layer. After creating a model, you can call the following methods : get_input_shape() get_output_shape() Return the input or output shape of a model, which is a shape tuple. The first entry is None representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned. set_name(name) Set the name of the model. Can alternatively specify the argument name in the constructor when creating a model.","title":"Define a model"},{"location":"KerasStyleAPIGuide/keras-api-python/#sequential-api","text":"The model is described as a linear stack of layers in the Sequential API. Layers can be added into the Sequential container one by one and the order of the layers in the model will be the same as the insertion order. To create a sequential container: Sequential() Example code to create a sequential model: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Dense, Activation model = Sequential() model.add(Dense(32, input_shape=(128, ))) model.add(Activation( relu ))","title":"Sequential API"},{"location":"KerasStyleAPIGuide/keras-api-python/#functional-api","text":"The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs). To create an input node: Input(shape=None, name=None) Parameters: shape : A shape tuple indicating the shape of the input node, not including batch. name : String to set the name of the input node. If not specified, its name will by default to be a generated string. To create a graph container: Model(input, output) Parameters: input : An input node or a list of input nodes. output : An output node or a list of output nodes. To merge a list of input nodes ( NOT layers), following some merge mode in the Functional API: merge(inputs, mode= sum , concat_axis=-1) # This will return an output NODE. Parameters: inputs : A list of node instances. Must be more than one node. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concat_axis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. Example code to create a graph model: from zoo.pipeline.api.keras.models import Model from zoo.pipeline.api.keras.layers import Input, Dense, merge # instantiate input nodes input1 = Input(shape=(8, )) input2 = Input(shape=(6, )) # pass an input node into a layer and get an output node dense1 = Dense(10)(input1) dense2 = Dense(10)(input2) # merge two nodes following some merge mode output = merge([dense1, dense2], mode= sum ) # create a graph container model = Model([input1, input2], output)","title":"Functional API"},{"location":"KerasStyleAPIGuide/keras-api-python/#layers","text":"See here for all the available layers for the Keras-Style API. To set the name of a layer, you can either call set_name(name) or alternatively specify the argument name in the constructor when creating a layer.","title":"Layers"},{"location":"KerasStyleAPIGuide/keras-api-python/#lenet-example","text":"Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import * model = Sequential() model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation= tanh , name= fc1 )) model.add(Dense(10, activation= softmax , name= fc2 )) model.get_input_shape() # (None, 28, 28, 1) model.get_output_shape() # (None, 10)","title":"LeNet Example"},{"location":"KerasStyleAPIGuide/keras-api-python/#keras-code-support","text":"If you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with: from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * and making modifications subject to the following limitations: The Keras version we support and test is Keras 1.2.2 with TensorFlow backend. There exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See here for the full list of unsupported layer arguments. The default dim_ordering in Analytics Zoo is th (Channel First, channel_axis=1). Keras backend related code needs to be deleted or refactored appropriately. Code involving Keras utility functions or loading weights from HDF5 files should be removed. Remark: We have tested for migrating Keras code definition of VGG16 , VGG19 , ResNet50 and InceptionV3 into Analytics Zoo.","title":"Keras Code Support"},{"location":"KerasStyleAPIGuide/keras-api-scala/","text":"Introduction We provide Keras-Style API based on Keras 1.2.2 in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion. To define a model in Scala using the Keras-Style API, now one just need to import the following packages: import com.intel.analytics.zoo.pipeline.api.keras.layers._ import com.intel.analytics.zoo.pipeline.api.keras.models._ import com.intel.analytics.bigdl.utils.Shape One of the highlighted features with regard to the new API is shape inference . Users only need to specify the input shape (a Shape object excluding batch dimension, for example, inputShape=Shape(3, 4) for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred. Shape Input and output shapes of a model in the Keras-Style API are described by the Shape object in Scala, which can be classified into SingleShape and MultiShape . SingleShape is just a list of Int indicating shape dimensions while MultiShape is essentially a list of Shape . Example code to create a shape: // create a SingleShape val shape1 = Shape(3, 4) // create a MultiShape consisting of two SingleShape val shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6))) You can use method toSingle() to cast a Shape to a SingleShape . Similarly, use toMulti() to cast a Shape to a MultiShape . Define a model You can define a model either using Sequential API or Functional API . Remember to specify the input shape for the first layer. After creating a model, you can call the following methods : getInputShape() getOutputShape() Return the input or output shape of a model, which is a Shape object. For SingleShape , the first entry is -1 representing the batch dimension. For a model with multiple inputs or outputs, it will return a MultiShape . setName(name) Set the name of the model. Sequential API The model is described as a linear stack of layers in the Sequential API. Layers can be added into the Sequential container one by one and the order of the layers in the model will be the same as the insertion order. To create a sequential container: Sequential() Example code to create a sequential model: import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation} import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape val model = Sequential[Float]() model.add(Dense[Float](32, inputShape = Shape(128))) model.add(Activation[Float]( relu )) Functional API The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs). To create an input node: Input(inputShape = null, name = null) Parameters: inputShape : A Shape object indicating the shape of the input node, not including batch. name : String to set the name of the input node. If not specified, its name will by default to be a generated string. To create a graph container: Model(input, output) Parameters: input : An input node or an array of input nodes. output : An output node or an array of output nodes. To merge a list of input nodes ( NOT layers), following some merge mode in the Functional API: import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge merge(inputs, mode = sum , concatAxis = -1) // This will return an output NODE. Parameters: inputs : A list of node instances. Must be more than one node. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concatAxis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. Example code to create a graph model: import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input} import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge import com.intel.analytics.zoo.pipeline.api.keras.models.Model import com.intel.analytics.bigdl.utils.Shape // instantiate input nodes val input1 = Input[Float](inputShape = Shape(8)) val input2 = Input[Float](inputShape = Shape(6)) // call inputs() with an input node and get an output node val dense1 = Dense[Float](10).inputs(input1) val dense2 = Dense[Float](10).inputs(input2) // merge two nodes following some merge mode val output = merge(inputs = List(dense1, dense2), mode = sum ) // create a graph container val model = Model[Float](Array(input1, input2), output) Layers See here for all the available layers for the Keras-Style API. To set the name of a layer, call the method setName(name) of the layer. LeNet Example Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset: import com.intel.analytics.bigdl.numeric.NumericFloat import com.intel.analytics.zoo.pipeline.api.keras.layers._ import com.intel.analytics.zoo.pipeline.api.keras.models._ import com.intel.analytics.bigdl.utils.Shape val model = Sequential() model.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation = tanh ).setName( conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation = tanh ).setName( conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation = tanh ).setName( fc1 )) model.add(Dense(10, activation = softmax ).setName( fc2 )) model.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1) model.getOutputShape().toSingle().toArray // Array(-1, 10)","title":"Scala Guide"},{"location":"KerasStyleAPIGuide/keras-api-scala/#introduction","text":"We provide Keras-Style API based on Keras 1.2.2 in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion. To define a model in Scala using the Keras-Style API, now one just need to import the following packages: import com.intel.analytics.zoo.pipeline.api.keras.layers._ import com.intel.analytics.zoo.pipeline.api.keras.models._ import com.intel.analytics.bigdl.utils.Shape One of the highlighted features with regard to the new API is shape inference . Users only need to specify the input shape (a Shape object excluding batch dimension, for example, inputShape=Shape(3, 4) for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.","title":"Introduction"},{"location":"KerasStyleAPIGuide/keras-api-scala/#shape","text":"Input and output shapes of a model in the Keras-Style API are described by the Shape object in Scala, which can be classified into SingleShape and MultiShape . SingleShape is just a list of Int indicating shape dimensions while MultiShape is essentially a list of Shape . Example code to create a shape: // create a SingleShape val shape1 = Shape(3, 4) // create a MultiShape consisting of two SingleShape val shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6))) You can use method toSingle() to cast a Shape to a SingleShape . Similarly, use toMulti() to cast a Shape to a MultiShape .","title":"Shape"},{"location":"KerasStyleAPIGuide/keras-api-scala/#define-a-model","text":"You can define a model either using Sequential API or Functional API . Remember to specify the input shape for the first layer. After creating a model, you can call the following methods : getInputShape() getOutputShape() Return the input or output shape of a model, which is a Shape object. For SingleShape , the first entry is -1 representing the batch dimension. For a model with multiple inputs or outputs, it will return a MultiShape . setName(name) Set the name of the model.","title":"Define a model"},{"location":"KerasStyleAPIGuide/keras-api-scala/#sequential-api","text":"The model is described as a linear stack of layers in the Sequential API. Layers can be added into the Sequential container one by one and the order of the layers in the model will be the same as the insertion order. To create a sequential container: Sequential() Example code to create a sequential model: import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation} import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape val model = Sequential[Float]() model.add(Dense[Float](32, inputShape = Shape(128))) model.add(Activation[Float]( relu ))","title":"Sequential API"},{"location":"KerasStyleAPIGuide/keras-api-scala/#functional-api","text":"The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs). To create an input node: Input(inputShape = null, name = null) Parameters: inputShape : A Shape object indicating the shape of the input node, not including batch. name : String to set the name of the input node. If not specified, its name will by default to be a generated string. To create a graph container: Model(input, output) Parameters: input : An input node or an array of input nodes. output : An output node or an array of output nodes. To merge a list of input nodes ( NOT layers), following some merge mode in the Functional API: import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge merge(inputs, mode = sum , concatAxis = -1) // This will return an output NODE. Parameters: inputs : A list of node instances. Must be more than one node. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concatAxis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. Example code to create a graph model: import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input} import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge import com.intel.analytics.zoo.pipeline.api.keras.models.Model import com.intel.analytics.bigdl.utils.Shape // instantiate input nodes val input1 = Input[Float](inputShape = Shape(8)) val input2 = Input[Float](inputShape = Shape(6)) // call inputs() with an input node and get an output node val dense1 = Dense[Float](10).inputs(input1) val dense2 = Dense[Float](10).inputs(input2) // merge two nodes following some merge mode val output = merge(inputs = List(dense1, dense2), mode = sum ) // create a graph container val model = Model[Float](Array(input1, input2), output)","title":"Functional API"},{"location":"KerasStyleAPIGuide/keras-api-scala/#layers","text":"See here for all the available layers for the Keras-Style API. To set the name of a layer, call the method setName(name) of the layer.","title":"Layers"},{"location":"KerasStyleAPIGuide/keras-api-scala/#lenet-example","text":"Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset: import com.intel.analytics.bigdl.numeric.NumericFloat import com.intel.analytics.zoo.pipeline.api.keras.layers._ import com.intel.analytics.zoo.pipeline.api.keras.models._ import com.intel.analytics.bigdl.utils.Shape val model = Sequential() model.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1))) model.add(Convolution2D(6, 5, 5, activation = tanh ).setName( conv1_5x5 )) model.add(MaxPooling2D()) model.add(Convolution2D(12, 5, 5, activation = tanh ).setName( conv2_5x5 )) model.add(MaxPooling2D()) model.add(Flatten()) model.add(Dense(100, activation = tanh ).setName( fc1 )) model.add(Dense(10, activation = softmax ).setName( fc2 )) model.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1) model.getOutputShape().toSingle().toArray // Array(-1, 10)","title":"LeNet Example"},{"location":"KerasStyleAPIGuide/Layers/activation/","text":"Activation Simple activation function to be applied to the output. Scala: Activation(activation, inputShape = null) Python: Activation(activation, input_shape=None, name=None) Parameters: activation : Name of the activation function as string. See here for available activation strings. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Activation import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Activation[Float]( tanh , inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 2.1659365 0.28006053 -0.20148286 0.9146865 3.4301455 1.0930616 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.9740552 0.2729611 -0.1988 0.723374 0.99790496 0.7979928 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Activation from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Activation( tanh , input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[ 0.26202468 0.15868397 0.27812652] [ 0.45931689 0.32100054 0.51839282]] Output is [[ 0.2561883 0.15736534 0.27117023] [ 0.42952728 0.31041133 0.47645861]] Note that the following two pieces of code will be equivalent: model.add(Dense(32)) model.add(Activation('relu')) model.add(Dense(32, activation= relu )) Available Activations elu rrelu relu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input. selu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information). tanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension. hardtanh sigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension. hard_sigmoid softmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1. Softmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift) where shift = max_i(x_i) . softplus : Apply the SoftPlus function to an n-dimensional input tensor. softsign : SoftSign applies SoftSign function to the input tensor exponential : Exponential (base e) activation function. linear : Linear (i.e. identity) activation function. ELU Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero: ELU is defined as: f(x) = max(0, x) + min(0, alpha * (exp(x) - 1)) The output dimension is always equal to input dimension. For reference see Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) . Scala: ELU(alpha = 1.0, inputShape = null) Python: m = ELU(alpha=1.0, input_shape=None, name=None) Parameters: alpha : Double, scale for the negative factor. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ELU[Float](1.2, inputShape = Shape(4, 5))) val input = Tensor[Float](2, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.3208098 -0.3994111 1.5678865 -0.5417255 -0.72367394 -0.16772668 -0.28669843 1.0305564 0.15613572 0.29151332 -1.1018531 -0.32264477 -1.4345981 -0.4781121 -2.1548445 0.29493016 1.147811 0.8544963 0.15185815 0.6745268 (2,.,.) = 1.0066849 0.5372675 -0.4647158 -0.64999336 0.97413754 1.0128744 -0.3654132 0.15322192 1.048261 0.9095614 -0.6602698 0.2848114 -0.35451657 -1.3011501 0.7933063 -1.5871915 -0.9177772 0.4741297 0.34224162 -2.7270272 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.8796972 -0.3951421 1.5678865 -0.5019077 -0.61803937 -0.18529809 -0.29911432 1.0305564 0.15613572 0.29151332 -0.8012943 -0.33092272 -0.9141467 -0.4560568 -1.0608946 0.29493016 1.147811 0.8544963 0.15185815 0.6745268 (2,.,.) = 1.0066849 0.5372675 -0.4460236 -0.5735409 0.97413754 1.0128744 -0.36730814 0.15322192 1.048261 0.9095614 -0.57994574 0.2848114 -0.358185 -0.8733378 0.7933063 -0.9546011 -0.720713 0.4741297 0.34224162 -1.1215038 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ELU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ELU(1.2, input_shape=(4, 5))) input = np.random.random([2, 4, 5]) output = model.forward(input) Input is: array([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075], [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956], [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748], [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]], [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108], [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063], [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432 ], [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]]) Output is array([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076], [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957], [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748], [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]], [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ], [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066], [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432 ], [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]], dtype=float32) RReLU Applies the randomized leaky rectified linear unit element-wise to the input. f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u). In the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u). In the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2. If l == u, a RReLU essentially becomes a LeakyReLU. Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs. For reference, see Empirical Evaluation of Rectified Activations in Convolutional Network . Scala: RReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null) Python: RReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None) Parameters: lower : Lower boundary of the uniform random distribution. Default is 1.0/8. upper : Upper boundary of the uniform random distribution. Default is 1.0/3. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(RReLU[Float](inputShape = Shape(1, 4))) val input = Tensor[Float](1, 1, 4).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.1308445 0.001281989 0.13936701 0.21237929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.1308445 0.001281989 0.13936701 0.21237929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import RReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(RReLU(input_shape = (1, 4))) input = np.random.random([1, 1, 4]) output = model.forward(input) Input is: array([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]]) Ouput is: array([[[0.421039 , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32) HardTanh Applies the hard tanh function element-wise to the input. f(x) = maxValue, if x maxValue f(x) = minValue, if x minValue f(x) = x, otherwise Scala: HardTanh(minValue = -1, maxValue = 1, inputShape = null) Python: HardTanh(min_value=-1, max_value=1, input_shape=None, name=None) Parameters: minValue : The minimum threshold value. Default is -1. maxValue : The maximum threshold value. Default is 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8396661 -2.096241 -0.36010137 -1.97987 -0.20326108 1.5972694 -1.4166505 -0.3369559 -0.22637285 -1.1021988 1.0707928 -1.5014135 (2,.,.) = -0.24511681 -1.1103313 -0.7901563 -1.0394055 -0.033373486 0.22657289 -0.7928737 1.5241393 0.49224186 -0.21418595 -0.32379007 -0.941034 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5 -1.0 -0.36010137 -1.0 -0.20326108 0.5 -1.0 -0.3369559 -0.22637285 -1.0 0.5 -1.0 (2,.,.) = -0.24511681 -1.0 -0.7901563 -1.0 -0.033373486 0.22657289 -0.7928737 0.5 0.49224186 -0.21418595 -0.32379007 -0.941034 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import HardTanh from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(HardTanh(-1, 0.5, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.38707977, 0.94085094, 0.50552125, 0.42818523], [0.5544486 , 0.36521357, 0.42551631, 0.93228245], [0.29155494, 0.61710319, 0.93137551, 0.05688166]], [[0.75222706, 0.36454257, 0.83076327, 0.82004643], [0.29213453, 0.71532663, 0.99556398, 0.57001469], [0.58088671, 0.32646428, 0.60736 , 0.14861018]]] Output is [[[0.38707978, 0.5 , 0.5 , 0.42818522], [0.5 , 0.36521357, 0.4255163 , 0.5 ], [0.29155496, 0.5 , 0.5 , 0.05688166]], [[0.5 , 0.36454257, 0.5 , 0.5 ], [0.29213452, 0.5 , 0.5 , 0.5 ], [0.5 , 0.3264643 , 0.5 , 0.14861017]]]","title":"Activation"},{"location":"KerasStyleAPIGuide/Layers/activation/#activation","text":"Simple activation function to be applied to the output. Scala: Activation(activation, inputShape = null) Python: Activation(activation, input_shape=None, name=None) Parameters: activation : Name of the activation function as string. See here for available activation strings. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Activation import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Activation[Float]( tanh , inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 2.1659365 0.28006053 -0.20148286 0.9146865 3.4301455 1.0930616 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.9740552 0.2729611 -0.1988 0.723374 0.99790496 0.7979928 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Activation from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Activation( tanh , input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[ 0.26202468 0.15868397 0.27812652] [ 0.45931689 0.32100054 0.51839282]] Output is [[ 0.2561883 0.15736534 0.27117023] [ 0.42952728 0.31041133 0.47645861]] Note that the following two pieces of code will be equivalent: model.add(Dense(32)) model.add(Activation('relu')) model.add(Dense(32, activation= relu ))","title":"Activation"},{"location":"KerasStyleAPIGuide/Layers/activation/#available-activations","text":"elu rrelu relu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input. selu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information). tanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension. hardtanh sigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension. hard_sigmoid softmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1. Softmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift) where shift = max_i(x_i) . softplus : Apply the SoftPlus function to an n-dimensional input tensor. softsign : SoftSign applies SoftSign function to the input tensor exponential : Exponential (base e) activation function. linear : Linear (i.e. identity) activation function.","title":"Available Activations"},{"location":"KerasStyleAPIGuide/Layers/activation/#elu","text":"Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero: ELU is defined as: f(x) = max(0, x) + min(0, alpha * (exp(x) - 1)) The output dimension is always equal to input dimension. For reference see Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) . Scala: ELU(alpha = 1.0, inputShape = null) Python: m = ELU(alpha=1.0, input_shape=None, name=None) Parameters: alpha : Double, scale for the negative factor. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ELU[Float](1.2, inputShape = Shape(4, 5))) val input = Tensor[Float](2, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.3208098 -0.3994111 1.5678865 -0.5417255 -0.72367394 -0.16772668 -0.28669843 1.0305564 0.15613572 0.29151332 -1.1018531 -0.32264477 -1.4345981 -0.4781121 -2.1548445 0.29493016 1.147811 0.8544963 0.15185815 0.6745268 (2,.,.) = 1.0066849 0.5372675 -0.4647158 -0.64999336 0.97413754 1.0128744 -0.3654132 0.15322192 1.048261 0.9095614 -0.6602698 0.2848114 -0.35451657 -1.3011501 0.7933063 -1.5871915 -0.9177772 0.4741297 0.34224162 -2.7270272 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.8796972 -0.3951421 1.5678865 -0.5019077 -0.61803937 -0.18529809 -0.29911432 1.0305564 0.15613572 0.29151332 -0.8012943 -0.33092272 -0.9141467 -0.4560568 -1.0608946 0.29493016 1.147811 0.8544963 0.15185815 0.6745268 (2,.,.) = 1.0066849 0.5372675 -0.4460236 -0.5735409 0.97413754 1.0128744 -0.36730814 0.15322192 1.048261 0.9095614 -0.57994574 0.2848114 -0.358185 -0.8733378 0.7933063 -0.9546011 -0.720713 0.4741297 0.34224162 -1.1215038 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ELU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ELU(1.2, input_shape=(4, 5))) input = np.random.random([2, 4, 5]) output = model.forward(input) Input is: array([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075], [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956], [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748], [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]], [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108], [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063], [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432 ], [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]]) Output is array([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076], [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957], [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748], [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]], [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ], [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066], [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432 ], [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]], dtype=float32)","title":"ELU"},{"location":"KerasStyleAPIGuide/Layers/activation/#rrelu","text":"Applies the randomized leaky rectified linear unit element-wise to the input. f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u). In the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u). In the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2. If l == u, a RReLU essentially becomes a LeakyReLU. Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs. For reference, see Empirical Evaluation of Rectified Activations in Convolutional Network . Scala: RReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null) Python: RReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None) Parameters: lower : Lower boundary of the uniform random distribution. Default is 1.0/8. upper : Upper boundary of the uniform random distribution. Default is 1.0/3. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(RReLU[Float](inputShape = Shape(1, 4))) val input = Tensor[Float](1, 1, 4).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.1308445 0.001281989 0.13936701 0.21237929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.1308445 0.001281989 0.13936701 0.21237929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import RReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(RReLU(input_shape = (1, 4))) input = np.random.random([1, 1, 4]) output = model.forward(input) Input is: array([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]]) Ouput is: array([[[0.421039 , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32)","title":"RReLU"},{"location":"KerasStyleAPIGuide/Layers/activation/#hardtanh","text":"Applies the hard tanh function element-wise to the input. f(x) = maxValue, if x maxValue f(x) = minValue, if x minValue f(x) = x, otherwise Scala: HardTanh(minValue = -1, maxValue = 1, inputShape = null) Python: HardTanh(min_value=-1, max_value=1, input_shape=None, name=None) Parameters: minValue : The minimum threshold value. Default is -1. maxValue : The maximum threshold value. Default is 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8396661 -2.096241 -0.36010137 -1.97987 -0.20326108 1.5972694 -1.4166505 -0.3369559 -0.22637285 -1.1021988 1.0707928 -1.5014135 (2,.,.) = -0.24511681 -1.1103313 -0.7901563 -1.0394055 -0.033373486 0.22657289 -0.7928737 1.5241393 0.49224186 -0.21418595 -0.32379007 -0.941034 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5 -1.0 -0.36010137 -1.0 -0.20326108 0.5 -1.0 -0.3369559 -0.22637285 -1.0 0.5 -1.0 (2,.,.) = -0.24511681 -1.0 -0.7901563 -1.0 -0.033373486 0.22657289 -0.7928737 0.5 0.49224186 -0.21418595 -0.32379007 -0.941034 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import HardTanh from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(HardTanh(-1, 0.5, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.38707977, 0.94085094, 0.50552125, 0.42818523], [0.5544486 , 0.36521357, 0.42551631, 0.93228245], [0.29155494, 0.61710319, 0.93137551, 0.05688166]], [[0.75222706, 0.36454257, 0.83076327, 0.82004643], [0.29213453, 0.71532663, 0.99556398, 0.57001469], [0.58088671, 0.32646428, 0.60736 , 0.14861018]]] Output is [[[0.38707978, 0.5 , 0.5 , 0.42818522], [0.5 , 0.36521357, 0.4255163 , 0.5 ], [0.29155496, 0.5 , 0.5 , 0.05688166]], [[0.5 , 0.36454257, 0.5 , 0.5 ], [0.29213452, 0.5 , 0.5 , 0.5 ], [0.5 , 0.3264643 , 0.5 , 0.14861017]]]","title":"HardTanh"},{"location":"KerasStyleAPIGuide/Layers/advanced-activation/","text":"PReLU Applies parametric ReLU, where parameter varies the slope of the negative part. It follows: f(x) = max(0, x) + a * min(0, x) Scala: PReLU(nOutputPlane = 0, inputShape = null) Python: PReLU(nOutputPlane=0, input_shape=None) Parameters: nOutputPlane : Input map number. Default is 0, which means using PReLU in shared version and has only one parameter. inputShape : A Single Shape, does not include the batch dimension. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(PReLU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.9026888 -1.0402212 1.3878769 -0.17167428 0.08202032 1.2682742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.2256722 -0.2600553 1.3878769 -0.04291857 0.08202032 1.2682742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import PReLU model = Sequential() model.add(PReLU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.61639702 0.08877075 0.93652509] [0.38800821 0.76286851 0.95777973]] Output is [[0.616397 0.08877075 0.9365251 ] [0.3880082 0.7628685 0.9577797 ]] ELU Exponential Linear Unit. It follows: f(x) = alpha * (exp(x) - 1.) for x 0, f(x) = x for x = 0. Scala: ELU(alpha = 1.0, inputShape = null) Python: ELU(alpha=1.0, input_shape=None, name=None) Parameters: alpha : Scale for the negative factor. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ELU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.13405465 0.05160992 -1.4711418 1.5808829 -1.3145303 0.6709266 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.1254577 0.05160992 -0.77033687 1.5808829 -0.73139954 0.6709266 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ELU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ELU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.90404922 0.23530925 0.49711093] [0.43009161 0.22446032 0.90144771]] Output is [[0.9040492 0.23530924 0.49711093] [0.43009162 0.22446032 0.9014477 ]] SReLU S-shaped Rectified Linear Unit. It follows: f(x) = t^r + a^r(x - t^r) for x = t^r, f(x) = x for t^r x t^l, f(x) = t^l + a^l(x - t^l) for x = t^l. Scala: SReLU(tLeftInit = zero , aLeftInit = glorot_uniform , tRightInit = glorot_uniform , aRightInit = one , sharedAxes = null, inputShape = null) Python: SReLU(t_left_init= zero , a_left_init= glorot_uniform , t_right_init= glorot_uniform , a_right_init= one , shared_axes=None, input_shape=None, name=None) Parameters: tLeftInit : String representation of the initialization method for the left part intercept. See here for available initialization strings. Default is 'zero'. aLeftInit : String representation of the initialization method for the left part slope. See here for available initialization strings. Default is 'glorot_uniform'. tRightInit : String representation of ithe nitialization method for the right part intercept. See here for available initialization strings. Default is 'glorot_uniform'. aRightInit : String representation of the initialization method for the right part slope. See here for available initialization strings. Default is 'one'. sharedAxes : The axes along which to share learnable parameters for the activation function. Default is null. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SReLU[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.5599429 0.22811626 -0.027771426 -0.56582874 1.9261217 1.2686813 (2,.,.) = 0.7538568 0.8725621 0.19803657 0.49057 0.0537252 0.8684544 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5599429 0.22811626 -0.009864618 0.07011698 1.9261217 1.2686813 (2,.,.) = 0.7538568 0.87256205 0.19803657 0.49057 0.0537252 0.8684544 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SReLU(input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.42998132 0.47736492 0.9554154 ] [0.93264942 0.56851545 0.39508313]] [[0.5164102 0.22304862 0.44380779] [0.69137804 0.26413953 0.60638032]]] Output is [[[0.42998132 0.47736493 0.9554154 ] [0.93264943 0.5685154 0.39508313]] [[0.5164102 0.22304863 0.44380778] [0.69137806 0.26413953 0.60638034]]] ThresholdedReLU Thresholded Rectified Linear Unit. It follows: f(x) = x for x theta, f(x) = 0 otherwise. Scala: ThresholdedReLU(theta = 1.0, inputShape = null) Python: ThresholdedReLU(theta=1.0, input_shape=None, name=None) Parameters: theta : Threshold location of activation. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ThresholdedReLU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 2.220999 1.2022058 -1.0015608 0.6532913 0.31831574 1.6747104 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 2.220999 1.2022058 0.0 0.0 0.0 1.6747104 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ThresholdedReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ThresholdedReLU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.91854565 0.58317415 0.33089385] [0.82472184 0.70572913 0.32803604]] Output is [[0.0 0.0 0.0] [0.0 0.0 0.0]]","title":"Advanced Activations"},{"location":"KerasStyleAPIGuide/Layers/advanced-activation/#prelu","text":"Applies parametric ReLU, where parameter varies the slope of the negative part. It follows: f(x) = max(0, x) + a * min(0, x) Scala: PReLU(nOutputPlane = 0, inputShape = null) Python: PReLU(nOutputPlane=0, input_shape=None) Parameters: nOutputPlane : Input map number. Default is 0, which means using PReLU in shared version and has only one parameter. inputShape : A Single Shape, does not include the batch dimension. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(PReLU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.9026888 -1.0402212 1.3878769 -0.17167428 0.08202032 1.2682742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.2256722 -0.2600553 1.3878769 -0.04291857 0.08202032 1.2682742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import PReLU model = Sequential() model.add(PReLU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.61639702 0.08877075 0.93652509] [0.38800821 0.76286851 0.95777973]] Output is [[0.616397 0.08877075 0.9365251 ] [0.3880082 0.7628685 0.9577797 ]]","title":"PReLU"},{"location":"KerasStyleAPIGuide/Layers/advanced-activation/#elu","text":"Exponential Linear Unit. It follows: f(x) = alpha * (exp(x) - 1.) for x 0, f(x) = x for x = 0. Scala: ELU(alpha = 1.0, inputShape = null) Python: ELU(alpha=1.0, input_shape=None, name=None) Parameters: alpha : Scale for the negative factor. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ELU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.13405465 0.05160992 -1.4711418 1.5808829 -1.3145303 0.6709266 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.1254577 0.05160992 -0.77033687 1.5808829 -0.73139954 0.6709266 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ELU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ELU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.90404922 0.23530925 0.49711093] [0.43009161 0.22446032 0.90144771]] Output is [[0.9040492 0.23530924 0.49711093] [0.43009162 0.22446032 0.9014477 ]]","title":"ELU"},{"location":"KerasStyleAPIGuide/Layers/advanced-activation/#srelu","text":"S-shaped Rectified Linear Unit. It follows: f(x) = t^r + a^r(x - t^r) for x = t^r, f(x) = x for t^r x t^l, f(x) = t^l + a^l(x - t^l) for x = t^l. Scala: SReLU(tLeftInit = zero , aLeftInit = glorot_uniform , tRightInit = glorot_uniform , aRightInit = one , sharedAxes = null, inputShape = null) Python: SReLU(t_left_init= zero , a_left_init= glorot_uniform , t_right_init= glorot_uniform , a_right_init= one , shared_axes=None, input_shape=None, name=None) Parameters: tLeftInit : String representation of the initialization method for the left part intercept. See here for available initialization strings. Default is 'zero'. aLeftInit : String representation of the initialization method for the left part slope. See here for available initialization strings. Default is 'glorot_uniform'. tRightInit : String representation of ithe nitialization method for the right part intercept. See here for available initialization strings. Default is 'glorot_uniform'. aRightInit : String representation of the initialization method for the right part slope. See here for available initialization strings. Default is 'one'. sharedAxes : The axes along which to share learnable parameters for the activation function. Default is null. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SReLU[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.5599429 0.22811626 -0.027771426 -0.56582874 1.9261217 1.2686813 (2,.,.) = 0.7538568 0.8725621 0.19803657 0.49057 0.0537252 0.8684544 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5599429 0.22811626 -0.009864618 0.07011698 1.9261217 1.2686813 (2,.,.) = 0.7538568 0.87256205 0.19803657 0.49057 0.0537252 0.8684544 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SReLU(input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.42998132 0.47736492 0.9554154 ] [0.93264942 0.56851545 0.39508313]] [[0.5164102 0.22304862 0.44380779] [0.69137804 0.26413953 0.60638032]]] Output is [[[0.42998132 0.47736493 0.9554154 ] [0.93264943 0.5685154 0.39508313]] [[0.5164102 0.22304863 0.44380778] [0.69137806 0.26413953 0.60638034]]]","title":"SReLU"},{"location":"KerasStyleAPIGuide/Layers/advanced-activation/#thresholdedrelu","text":"Thresholded Rectified Linear Unit. It follows: f(x) = x for x theta, f(x) = 0 otherwise. Scala: ThresholdedReLU(theta = 1.0, inputShape = null) Python: ThresholdedReLU(theta=1.0, input_shape=None, name=None) Parameters: theta : Threshold location of activation. Default is 1.0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ThresholdedReLU[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 2.220999 1.2022058 -1.0015608 0.6532913 0.31831574 1.6747104 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 2.220999 1.2022058 0.0 0.0 0.0 1.6747104 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ThresholdedReLU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ThresholdedReLU(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.91854565 0.58317415 0.33089385] [0.82472184 0.70572913 0.32803604]] Output is [[0.0 0.0 0.0] [0.0 0.0 0.0]]","title":"ThresholdedReLU"},{"location":"KerasStyleAPIGuide/Layers/convolutional/","text":"LocallyConnected2D A Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input. The input is 2D tensor with shape: (batch_size, channels, rows, cols). Scala: LocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = valid , subsample = (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: LocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.71993834 0.018790463 0.08133635 0.35603827 -1.1757486 1.8503827 -1.4548069 -0.6309117 -0.53039306 -0.14174776 0.7653523 -0.1891388 (1,2,.,.) = 1.0949191 0.13689162 0.35839355 -0.14805469 -2.5264592 -0.34186792 1.3190275 -0.11725446 -0.48823252 -1.5305915 -1.0556486 1.792275 (2,1,.,.) = 0.92393816 0.83243525 0.22506136 0.6694662 0.7662836 -0.23876576 -0.7719174 0.13114463 0.042082224 1.2212821 -1.2496184 -0.18717249 (2,2,.,.) = 0.726698 0.42673108 0.0786712 -1.4069401 -0.090565465 0.49527475 0.08590904 -0.51858175 1.4575573 0.9669369 0.21832618 0.34654656 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.022375792 0.669761 -0.25723624 0.99919814 0.93189466 0.8592935 (1,2,.,.) = 0.12613812 -1.0531536 0.8148589 0.66276294 0.12609969 0.6590149 (2,1,.,.) = -0.1259023 0.32203823 0.07248953 -0.125191 -0.1285046 0.021367729 (2,2,.,.) = -0.13560611 -0.038621478 -0.08420516 -0.0021556932 -0.094522506 -0.08551059 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import LocallyConnected2D model = Sequential() model.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.75179142 0.10678918 0.92663152 0.2041142 ] [0.03534582 0.13742629 0.94115987 0.17303432] [0.91112368 0.19837546 0.45643767 0.16589123]] [[0.22996923 0.22878544 0.75623624 0.7058976 ] [0.14107232 0.49484648 0.71194356 0.53604538] [0.46257205 0.46902871 0.48046811 0.83579709]]] [[[0.9397535 0.51814825 0.10492714 0.24623405] [0.69800376 0.12353963 0.69536497 0.05159074] [0.56722731 0.33348394 0.47648031 0.25398067]] [[0.51018599 0.3416568 0.14112375 0.76505795] [0.16242231 0.16735028 0.79000471 0.98701885] [0.79852431 0.77458166 0.12551857 0.43866238]]]] Output is [[[[ 0.14901309 -0.11168094 0.28349853] [ 0.21792562 0.49922782 -0.06560349]] [[ 0.6176302 -0.4638375 -0.13387583] [-0.04903107 0.07764787 -0.33653474]]] [[[ 0.24676235 -0.46874076 0.33973938] [ 0.21408634 0.36619198 0.17972258]] [[ 0.35941058 -0.23446569 -0.09271184] [ 0.39490524 -0.00668371 -0.25355732]]]] Convolution1D Applies convolution operator for filtering neighborhoods of 1-D inputs. You can also use Conv1D as an alias of this layer. The input of this layer should be 3D. Scala: Convolution1D(nbFilter, filterLength, init = glorot_uniform , activation = null, borderMode = valid , subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Convolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. filterLength : The extension (spatial or temporal) of each filter. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsampleLength : Factor by which to subsample output. Integer. Default is 1. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Convolution1D(8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.4253887 -0.044403594 -1.1169672 -0.19499049 0.85463065 0.6665206 0.21340805 0.56255895 1.1126599 -0.3423326 0.09643264 -0.34345046 (2,.,.) = -0.04046587 -0.2710401 0.10183265 1.4503858 1.0639644 1.5317003 -0.18313104 -0.7098296 0.612399 1.7357533 0.4641411 0.13530721 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.22175728 0.76192796 1.7907748 1.1534728 -1.5304534 0.07466106 -0.18292685 0.6038852 (2,.,.) = 0.85337734 0.43939286 -0.16770163 -0.8380078 0.7825804 -0.3485601 0.3017909 0.5823619 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Convolution1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Convolution1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.06092268 0.0508438 0.47256153 0.80004565] [0.48706905 0.65704781 0.04297214 0.42288264] [0.92286158 0.85394381 0.46423248 0.87896669]] [[0.216527 0.13880484 0.93482372 0.44812419] [0.95553331 0.27084259 0.58913626 0.01879454] [0.6656435 0.1985877 0.94133745 0.57504128]]] Output is [[[ 0.7461933 -2.3189526 -1.454972 -0.7323345 1.5272427 -0.87963724 0.6278059 -0.23403725]] [[ 1.2397771 -0.9249111 -1.1432207 -0.92868984 0.53766745 -1.0271561 -0.9593589 -0.4768026 ]]] Convolution2D Applies a 2D convolution over an input image composed of several input planes. You can also use Conv2D as an alias of this layer. The input of this layer should be 4D, i.e. (samples, channels, rows, cols). The output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols). Scala: Convolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, borderMode = valid , subsample = (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Convolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Convolution2D[Float](4, 2, 2, activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.8852683 -0.81495345 -1.2799169 0.9779215 1.1456866 -0.10803124 -0.44350016 -1.7670554 -0.9059258 -0.08115104 -0.888267 1.8203543 (1,2,.,.) = -0.69458634 0.31331652 1.4600077 -0.93392456 1.4808512 0.2082488 -0.008410408 0.013914147 0.86024827 1.124567 0.28874534 -0.4866409 (2,1,.,.) = -0.020653103 0.8077344 -0.9391865 0.2743323 0.09707443 -0.1877453 2.3798819 1.71017 0.14860597 0.8954743 2.0009918 1.0548053 (2,2,.,.) = -0.06750481 -2.1010966 -0.51831937 -0.40519416 1.2983296 1.9960507 0.31097296 -1.0400984 -0.20703147 0.32478333 -0.5247251 1.2356688 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.49652004 0.62284863 0.0 1.2256577 0.11462581 0.761484 (1,2,.,.) = 0.0 0.0 1.6321466 0.69082737 0.10713227 0.0 (1,3,.,.) = 0.0 0.0 1.0226117 0.0 0.0 0.0 (1,4,.,.) = 0.017812707 0.044630717 0.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.79017955 0.0 1.1551664 0.0 0.0 (2,2,.,.) = 0.0 0.0 0.0 0.0 0.9762883 0.0 (2,3,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 (2,4,.,.) = 0.0 0.0 0.1633394 0.66279346 0.07180607 1.7188346 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Convolution2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[ 0.70766604, 0.56604946, 0.89172683, 0.35057259], [ 0.89700606, 0.71675588, 0.92357667, 0.73319623], [ 0.38198447, 0.66954234, 0.46397678, 0.81329758]], [[ 0.86972625, 0.16386155, 0.73140259, 0.07359015], [ 0.43441431, 0.16852341, 0.15025034, 0.34109183], [ 0.89670592, 0.06335869, 0.72356566, 0.54245763]]], [[[ 0.37727322, 0.14688331, 0.06249512, 0.29553298], [ 0.50554043, 0.33364744, 0.95334248, 0.40551935], [ 0.81317402, 0.59253283, 0.8249684 , 0.80419637]], [[ 0.71737738, 0.09376579, 0.3793706 , 0.91432729], [ 0.34433954, 0.74886398, 0.97859311, 0.9538775 ], [ 0.45521369, 0.79446047, 0.35239537, 0.12803574]]]]) Output is array([[[[ 0.0732559 , 0.70261478, 0.16962567], [ 0.3641817 , 0.56304729, 0.71597064]], [[-0.5932048 , -0.04155506, -0.49025974], [-0.57992101, -0.00230447, -0.33811107]], [[ 0.13634545, 0.27157408, -0.01450583], [ 0.34469086, 0.46334854, 0.55308509]], [[-0.01247289, 0.69034004, -0.01554111], [ 0.07790593, 0.09984782, 0.1278697 ]]], [[[ 0.02547407, 0.64045584, 0.21886043], [ 0.43482357, 0.45493811, 0.26216859]], [[-0.39469361, -0.34455007, -0.2396858 ], [-0.15447566, -0.35714447, -0.44134659]], [[ 0.30956799, 0.9154281 , 0.75450832], [ 0.37207305, 0.55432665, -0.29964659]], [[-0.48307419, -0.29406634, -0.29416537], [ 0.0138942 , 0.26592475, 0.38921899]]]], dtype=float32) AtrousConvolution2D Applies an atrous convolution operator for filtering windows of 2-D inputs. A.k.a dilated convolution or convolution with holes. Bias will be included in this layer. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. You can also use AtrousConv2D as an alias of this layer. The input of this layer should be 4D. Scala: AtrousConvolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, inputShape = null) Python: AtrousConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), atrous_rate=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsample : Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1). atrousRate : Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1). dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AtrousConvolution2D[Float](4, 2, 2, activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.57626903 -0.56916714 0.46516004 -1.189643 -0.117406875 -1.1139084 1.115328 0.23275337 1.452733 -0.30968842 -0.6693723 -0.22098665 (1,2,.,.) = 0.06541251 -0.7000564 -0.460471 -0.5291468 -0.6625642 0.6460361 -0.556095 1.6327276 1.1914377 -0.69054496 -0.7461783 -1.0129389 (2,1,.,.) = -0.19123174 0.06803144 -0.010993495 -0.79966563 -0.010654963 2.0806832 1.972848 -1.8525643 -0.84387285 1.2974458 -0.42781293 0.3540522 (2,2,.,.) = 1.6231914 0.52689505 0.47506556 -1.030227 0.5143046 -0.9930063 -2.2869735 0.03994834 -1.5566326 -1.0937842 0.82693833 -0.08408405 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.11401264 0.0 1.1396459 0.0 0.0 0.88493514 (1,2,.,.) = 0.0 8.398667 1.1495202 0.0 0.0 0.1630742 (1,3,.,.) = 0.0 0.92470163 0.0 0.0 0.6321572 0.0 (1,4,.,.) = 0.0 1.1912066 0.0 0.0 1.27647 0.13422263 (2,1,.,.) = 0.0 0.0 0.51365596 0.0 0.4207713 1.1226959 (2,2,.,.) = 0.0 0.67600054 0.63635653 0.40892223 2.0596464 1.7690754 (2,3,.,.) = 1.1899394 0.0 0.0 1.7185769 0.39178902 0.0 (2,4,.,.) = 0.44333076 0.73385376 0.0 2.516453 0.36223468 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AtrousConvolution2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.52102612 0.30683086 0.38543426 0.0026452 ] [0.66805249 0.60656045 0.94601998 0.46574414] [0.49391338 0.14274225 0.70473703 0.30427041]] [[0.89066007 0.51782675 0.7063052 0.53440807] [0.67377917 0.51541465 0.02137767 0.63357007] [0.6614106 0.15849977 0.94459604 0.46852022]]] [[[0.79639026 0.94468413 0.73165819 0.54531867] [0.97741046 0.64477619 0.52373183 0.06861999] [0.37278645 0.53198045 0.95098245 0.86249644]] [[0.47186038 0.81694951 0.78009033 0.20925898] [0.69942883 0.37150324 0.58907364 0.88754231] [0.64083971 0.4480097 0.91716521 0.66808943]]]] Output is [[[[-0.32139003 -0.34667802 -0.35534883] [-0.09653517 -0.35052428 -0.09859636]] [[-0.3138999 -0.5563417 -0.6694119 ] [-0.03151364 0.35521197 0.31497604]] [[-0.34939283 -0.7537081 -0.3939833 ] [-0.25708836 0.06015673 -0.16755156]] [[-0.04791902 0.02060626 -0.5639752 ] [ 0.16054101 0.22528952 -0.02460545]]] [[[-0.13129832 -0.5262137 -0.12281597] [-0.36988598 -0.5532047 -0.43338764]] [[-0.21627764 -0.17562683 0.23560521] [ 0.23035726 -0.03152001 -0.46413773]] [[-0.63740283 -0.33359224 0.15731882] [-0.12795202 -0.25798583 -0.5261132 ]] [[-0.01759483 -0.07666921 -0.00890112] [ 0.27595833 -0.14117064 -0.3357542 ]]]] LocallyConnected1D Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input. Border mode currently supported for this layer is 'valid'. The input of this layer should be 3D. Scala: LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Dimensionality of the output. filterLength : The extension (spatial or temporal) of each filter. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsampleLength : Integer. Factor by which to subsample output. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.6755046 0.47923228 -0.41470557 -1.4644535 -1.580751 -0.36924785 -1.1507624 0.20131736 -0.4983051 -2.0898817 0.1623063 0.8118141 (2,.,.) = 1.5955191 -1.1017833 1.6614468 1.7959124 1.1084127 0.528379 -1.114553 -1.030853 0.37758648 -2.5828059 1.0172523 -1.6773314 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.20011228 0.7842446 -0.57892114 0.2405633 -0.35126245 -0.5116563 (2,.,.) = -0.33687726 0.7863857 0.30202985 0.33251244 -0.7414977 0.14271683 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LocallyConnected1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LocallyConnected1D(6, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.67992353 0.88287213 0.98861104 0.17401607] [0.23660068 0.02779148 0.52982599 0.19876749] [0.38880073 0.6498778 0.81532701 0.91719509]] [[0.30532677 0.1574227 0.40535271 0.03174637] [0.37303714 0.27821415 0.02314422 0.64516966] [0.74813923 0.9884225 0.40667151 0.21894944]]] Output is [[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816 0.94942856]] [[ 0.5890693 0.0179258 -0.31232932 0.4427027 -0.30954808 0.4486028 ]]] UpSampling2D UpSampling layer for 2D inputs. Repeats the rows and columns of the data by the specified size. The input of this layer should be 4D. Scala: UpSampling2D(size = (2, 2), dimOrdering = th , inputShape = null) Python: UpSampling2D(size=(2, 2), dim_ordering= th , input_shape=None, name=None) Parameters: size : Length 2. UpSampling factors for rows and columns. Default is (2, 2). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2))) val input = Tensor[Float](1, 2, 2, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.07563081 -1.921836 -1.7368479 0.1043008 (1,2,.,.) = -1.825055 -0.096810855 -0.89331573 0.72812295 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) -0.07563081 -0.07563081 -1.921836 -1.921836 -0.07563081 -0.07563081 -1.921836 -1.921836 -1.7368479 -1.7368479 0.1043008 0.1043008 -1.7368479 -1.7368479 0.1043008 0.1043008 (1,2,.,.) = -1.825055 -1.825055 -0.096810855 -0.096810855 -1.825055 -1.825055 -0.096810855 -0.096810855 -0.89331573 -0.89331573 0.72812295 0.72812295 -0.89331573 -0.89331573 0.72812295 0.72812295 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import UpSampling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(UpSampling2D((2, 2), input_shape=(2, 2, 2))) input = np.random.random([1, 2, 2, 2]) output = model.forward(input) Input is: [[[[0.55660253 0.21984387] [0.36271854 0.57464162]] [[0.55307278 0.33007518] [0.31527167 0.87789644]]]] Output is: [[[[0.55660254 0.55660254 0.21984388 0.21984388] [0.55660254 0.55660254 0.21984388 0.21984388] [0.36271855 0.36271855 0.57464164 0.57464164] [0.36271855 0.36271855 0.57464164 0.57464164]] [[0.55307275 0.55307275 0.33007517 0.33007517] [0.55307275 0.55307275 0.33007517 0.33007517] [0.31527168 0.31527168 0.8778964 0.8778964 ] [0.31527168 0.31527168 0.8778964 0.8778964 ]]]] UpSampling3D UpSampling layer for 3D inputs. Repeats the 1st, 2nd and 3rd dimensions of the data by the specified size. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). The input of this layer should be 5D. Scala: UpSampling3D(size = (2, 2, 2), dimOrdering = th , inputShape = null) Python: UpSampling3D(size=(2, 2, 2), dim_ordering= th , input_shape=None, name=None) Parameters: size : Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2). dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2))) val input = Tensor[Float](1, 1, 1, 2, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 0.05876646 0.8743367 -0.15551122 0.9405281 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.05876646 0.05876646 0.8743367 0.8743367 0.05876646 0.05876646 0.8743367 0.8743367 -0.15551122 -0.15551122 0.9405281 0.9405281 -0.15551122 -0.15551122 0.9405281 0.9405281 (1,1,2,.,.) = 0.05876646 0.05876646 0.8743367 0.8743367 0.05876646 0.05876646 0.8743367 0.8743367 -0.15551122 -0.15551122 0.9405281 0.9405281 -0.15551122 -0.15551122 0.9405281 0.9405281 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import UpSampling3D model = Sequential() model.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2))) input = np.random.random([1, 1, 1, 2, 2]) output = model.forward(input) Input is: [[[[[0.01897243 0.87927954] - [0.13656585 0.3003842 ]]]]] Output is [[[[[0.01897243 0.01897243 0.87927955 0.87927955] [0.01897243 0.01897243 0.87927955 0.87927955] [0.13656585 0.13656585 0.3003842 0.3003842 ] [0.13656585 0.13656585 0.3003842 0.3003842 ]] [[0.01897243 0.01897243 0.87927955 0.87927955] [0.01897243 0.01897243 0.87927955 0.87927955] [0.13656585 0.13656585 0.3003842 0.3003842 ] [0.13656585 0.13656585 0.3003842 0.3003842 ]]]]] AtrousConvolution1D Applies an atrous convolution operator for filtering neighborhoods of 1-D inputs. A.k.a dilated convolution or convolution with holes. Bias will be included in this layer. Border mode currently supported for this layer is 'valid'. You can also use AtrousConv1D as an alias of this layer. The input of this layer should be 3D. Scala: AtrousConvolution1D(nbFilter, filterLength, init = glorot_uniform , activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null) Python: AtrousConvolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution kernels to use. filterLength : The extension (spatial or temporal) of each filter. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsampleLength : Factor by which to subsample output. Integer. Default is 1. atrousRate : Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.18186663 -0.43034658 0.26391524 -1.4132749 -0.17445838 1.3798479 0.1737039 1.152537 0.27590567 0.009284354 -0.80261934 -0.9434588 (2,.,.) = -0.20791245 0.21988653 0.8744776 0.2940677 0.07080339 0.51823103 -0.46097854 -0.037812505 0.35226902 0.79622966 0.011483789 0.88822025 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.026210725 1.2229221 0.45232815 -1.0826558 0.849349 0.086645454 0.041758537 0.3721839 (2,.,.) = -0.14264873 0.060507685 -0.217965 0.42317814 0.17935039 -0.05465065 -0.6533742 -0.009769946 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import AtrousConvolution1D model = Sequential() model.add(AtrousConvolution1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.44706076 0.5902202 0.3784323 0.4098717 ] [0.74646876 0.98997355 0.64164388 0.61591103] [0.88695659 0.16591123 0.6575717 0.55897158]] [[0.51990872 0.82065542 0.18409799 0.99078291] [0.03853884 0.0781884 0.82290244 0.99992993] [0.02394716 0.10870804 0.17077537 0.77893951]]] Output is [[[-0.09361145 0.48225394 -0.3777458 -0.84651476 0.3678655 -0.02871403 1.0220621 0.7548751 ]] [[-0.0299319 0.37761992 -0.08759689 -0.01757497 -0.01414538 -0.2547227 0.70025307 0.49045497]]] ZeroPadding1D Zero-padding layer for 1D input (e.g. temporal sequence). The input of this layer should be 3D. Scala: ZeroPadding1D(padding = 1, inputShape = null) Python: ZeroPadding1D(padding=1, input_shape=None, name=None) Parameters: padding : How many zeros to add at the beginning and at the end of the padding dimension. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.7421485 -0.13270181 -0.12605186 -0.7442475 0.36977226 -0.90300065 -0.34193754 -0.035565257 -0.23300397 0.8183156 0.7023575 -0.16938858 (2,.,.) = -0.7785278 0.36642975 -1.0542017 -0.29036212 -0.22632122 0.46808097 -0.68293047 1.2529073 -0.8619831 1.3846883 1.0762612 1.1351995 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.0 0.0 0.0 0.0 0.7421485 -0.13270181 -0.12605186 -0.7442475 0.36977226 -0.90300065 -0.34193754 -0.035565257 -0.23300397 0.8183156 0.7023575 -0.16938858 0.0 0.0 0.0 0.0 (2,.,.) = 0.0 0.0 0.0 0.0 -0.7785278 0.36642975 -1.0542017 -0.29036212 -0.22632122 0.46808097 -0.68293047 1.2529073 -0.8619831 1.3846883 1.0762612 1.1351995 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding1D(1, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.74177145 0.75805981 0.2091588 0.46929227] [0.46041743 0.13213793 0.51065024 0.36081853] [0.60803218 0.27764702 0.31788482 0.65445294]] [[0.96255443 0.74692762 0.50050961 0.88456158] [0.55492653 0.50850271 0.17788885 0.91569285] [0.27356035 0.74622588 0.39690752 0.75229177]]] Output is [[[0.0 0.0 0.0 0.0 ] [0.74177146 0.7580598 0.2091588 0.46929225] [0.46041742 0.13213794 0.5106502 0.36081854] [0.60803217 0.27764702 0.31788483 0.6544529 ] [0.0 0.0 0.0 0.0 ]] [[0.0 0.0 0.0 0.0 ] [0.96255445 0.7469276 0.5005096 0.8845616 ] [0.5549265 0.5085027 0.17788884 0.91569287] [0.27356035 0.7462259 0.39690754 0.75229174] [0.0 0.0 0.0 0.0 ]]] ZeroPadding3D Zero-padding layer for 3D data (spatial or spatio-temporal). The input of this layer should be 5D. Scala: ZeroPadding3D(padding = (1, 1, 1), dimOrdering = th , inputShape = null) Python: ZeroPadding3D(padding=(1, 1, 1), dim_ordering= th , input_shape=None, name=None) Parameters: padding : Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2))) val input = Tensor[Float](1, 1, 2, 1, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.59840345 -0.06308561 (1,1,2,.,.) = 0.48804763 0.2723002 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 (1,1,2,.,.) = 0.0 0.0 0.0 0.0 0.0 -0.59840345 -0.06308561 0.0 0.0 0.0 0.0 0.0 (1,1,3,.,.) = 0.0 0.0 0.0 0.0 0.0 0.48804763 0.2723002 0.0 0.0 0.0 0.0 0.0 (1,1,4,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2))) input = np.random.random([1, 1, 2, 1, 2]) output = model.forward(input) Input is: [[[[[0.03167021, 0.15764403]], [[0.26572586, 0.48872052]]]]] Output is [[[[[0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0.03167021, 0.15764403, 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0.26572585, 0.48872054, 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ]]]]] Cropping1D Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1). The input of this layer should be 3D, i.e. (batch, axis_to_crop, features). The output of this layer should be 3D, i.e. (batch, cropped_axis, features). Scala: Cropping1D(cropping = (1, 1), inputShape = null) Python: Cropping1D(cropping=(1, 1), input_shape=None, name=None) Parameters: cropping : Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1). inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.06297628 -0.8408224 0.21813048 -0.14371997 0.9278932 0.069493145 -0.2900171 0.536517 3.430168 -0.53643423 0.12677099 0.3572487 (2,.,.) = 1.493348 -1.1703341 -0.37385875 -0.239736 0.33984247 -0.6005885 1.2722077 -0.5043763 0.012092848 0.40293974 0.61356264 2.4283617 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.9278932 0.069493145 -0.2900171 0.536517 (2,.,.) = 0.33984247 -0.6005885 1.2722077 -0.5043763 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4] Python example: from zoo.pipeline.api.keras.layers import Cropping1D from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Cropping1D(input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.12013423, 0.21359734, 0.92871231, 0.92152503], [ 0.3649771 , 0.39968689, 0.92007275, 0.16493056], [ 0.11018303, 0.7591447 , 0.35932136, 0.97727728]], [[ 0.06645696, 0.21909036, 0.01219254, 0.46561466], [ 0.64316144, 0.53577975, 0.38302965, 0.56807556], [ 0.25223652, 0.23857826, 0.1884081 , 0.42532243]]]) Output is: array([[[ 0.36497709, 0.3996869 , 0.92007273, 0.16493057]], [[ 0.64316142, 0.53577977, 0.38302964, 0.56807554]]], dtype=float32) Cropping2D Cropping layer for 2D input (e.g. picture). The input of this layer should be 4D. Scala: Cropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = th , inputShape = null) Python: Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering= th , input_shape=None, name=None) Parameters: cropping : Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.6840084 0.293568 0.045959193 0.91535753 -0.49666363 -0.05026308 0.22163485 0.08330725 0.36190453 -0.023894459 0.40037137 0.15155333 (1,2,.,.) = 1.0107938 0.05100493 -0.88689697 0.111396775 0.065911256 -0.41727677 0.62742686 -0.5435138 -1.0133605 0.7352207 -0.77922934 -0.36588958 (2,1,.,.) = -0.6847248 0.8627568 -0.5600547 0.48514402 -0.9261762 -0.34248486 -0.09243064 -0.13134436 -0.23247129 1.2801572 -1.377833 -1.7608607 (2,2,.,.) = 1.1907105 0.30009162 -1.2604285 1.0099201 -1.211673 -0.08809458 0.4386406 -0.6264226 0.112140626 0.3690179 0.832656 1.3931179 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.293568 0.045959193 0.91535753 -0.05026308 0.22163485 0.08330725 (1,2,.,.) = 0.05100493 -0.88689697 0.111396775 -0.41727677 0.62742686 -0.5435138 (2,1,.,.) = 0.8627568 -0.5600547 0.48514402 -0.34248486 -0.09243064 -0.13134436 (2,2,.,.) = 0.30009162 -1.2604285 1.0099201 -0.08809458 0.4386406 -0.6264226 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import Cropping2D from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097], [0.36859968, 0.44601991, 0.94679033, 0.93842937], [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]], [[0.32265899, 0.37304445, 0.09097587, 0.52496901], [0.70275446, 0.10796127, 0.74849378, 0.99118752], [0.34310691, 0.60435919, 0.22227177, 0.48464358]]], [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216], [0.48278365, 0.0968289 , 0.9465143 , 0.49814986], [0.36140084, 0.98581155, 0.14834531, 0.71290525]], [[0.8909849 , 0.66729728, 0.53332039, 0.83958965], [0.3645429 , 0.40645471, 0.02596942, 0.80835778], [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]]) Output is: array([[[[0.78710294, 0.4518868 , 0.787381 ], [0.44601992, 0.94679034, 0.93842936]], [[0.37304446, 0.09097587, 0.524969 ], [0.10796127, 0.7484938 , 0.9911875 ]]], [[[0.6009071 , 0.09771059, 0.19654216], [0.0968289 , 0.9465143 , 0.49814987]], [[0.6672973 , 0.53332037, 0.83958966], [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32) Cropping3D Cropping layer for 3D data (e.g. spatial or spatio-temporal). The input of this layer should be 5D. Scala: Cropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = th , inputShape = null) Python: Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering= th , input_shape=None, name=None) Parameters: cropping : Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)). dimOrdering : Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5))) val input = Tensor[Float](2, 2, 3, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.12339484 0.25661087 0.04387503 -1.1047344 -1.1413815 1.1830065 -0.07189157 -0.5418846 0.5576781 -0.5460917 -0.5679186 -0.30854696 1.2614665 -0.6774269 -0.63295823 0.5269464 -2.7981617 -0.056265026 -1.0814936 -1.0848739 (1,1,2,.,.) = -1.9100302 0.461067 0.4014941 0.60723174 -0.40414023 0.34300476 0.7107094 1.3142885 1.5696589 0.97591686 0.38320687 0.07036536 -0.43628898 0.58050656 -0.57882625 -0.43699506 -0.0094956765 0.15171598 0.038076796 -1.2433665 (1,1,3,.,.) = 0.39671394 0.880047 0.30971292 -0.3369089 0.13062176 -0.27803114 -0.62177086 0.16659822 0.89428085 0.23684736 1.6151237 -1.1479733 -0.2229254 1.1361892 0.79478127 -1.8207864 1.6544164 0.07977915 -1.1316417 -0.25483203 (1,2,1,.,.) = 1.3165517 -0.9479057 -1.4662051 -0.3343554 -0.4522552 -1.5829691 0.6378519 -0.16399206 1.4724066 1.2387054 -1.1467208 -0.6325814 -1.2106491 -0.035734158 0.19871919 2.285004 1.0482147 -2.0056705 -0.80917794 2.523167 (1,2,2,.,.) = -0.57108706 -0.23606259 -0.45569882 -0.034214735 -1.9130942 -0.2743481 1.61177 -0.7052599 0.17889105 -0.31241596 0.22377247 1.5860337 -0.3226252 -0.1341058 0.9239994 0.03615294 0.6233593 0.757827 -0.72271305 0.9429943 (1,2,3,.,.) = -0.4409662 0.8867786 2.0036085 0.16242673 -0.3332395 0.09082064 0.04958198 -0.27834833 1.8025815 -0.04848101 0.2690667 -1.1263227 -0.95486647 0.09473259 0.98166656 -0.9509363 -0.10084029 -0.35410827 0.29626986 0.97203517 (2,1,1,.,.) = 0.42096403 0.14016314 0.20216857 -0.678293 -1.0970931 -0.4981112 0.12429344 1.7156922 -0.24384527 -0.010780937 0.03672217 2.3021698 1.568247 -0.43173146 -0.5550057 0.30469602 1.4772439 -0.21195345 0.04221814 -1.6883365 (2,1,2,.,.) = 0.22468264 0.72787744 -0.9597003 -0.28472963 -1.4575284 1.0487963 0.4982454 -1.0186157 -1.9877508 -1.133779 0.17539643 -0.35151628 -1.8955303 2.1854792 0.59556997 0.6893949 -0.19556235 0.25862908 0.24450152 0.17786922 (2,1,3,.,.) = 1.147159 -0.8849993 0.9826487 0.95360875 -0.9210176 1.3439047 0.6739913 0.06558858 0.91963255 -1.1758618 1.747105 -0.7225308 -1.0160877 0.67554474 -0.7762811 0.21184689 -0.43668815 -1.0738864 0.04661594 0.9613895 (2,2,1,.,.) = -0.377159 -0.28094378 0.1081715 1.3683178 1.2572801 0.47781375 0.4545212 0.55356956 1.0366637 -0.1962683 -1.820227 -0.111765414 1.9194998 -1.6089902 -1.6960226 0.14896627 0.9360371 0.49156702 0.08601956 -0.08815153 (2,2,2,.,.) = 0.056315728 -0.13061485 -0.49018836 -0.59103477 -1.6910721 -0.023719765 -0.44977355 0.11218439 0.224829 1.400084 0.31496882 -1.6386473 -0.6715097 0.14816228 0.3240011 -0.80607724 -0.37951842 -0.2187672 1.1087769 0.43044603 (2,2,3,.,.) = -1.6647842 -0.5720825 -1.5150099 0.42346838 1.495052 -0.3567161 -1.4341534 -0.19422509 -1.2871891 -1.2758921 -0.47077888 -0.42217267 0.67764246 1.2170314 0.8420698 -0.4263702 1.2792329 0.38645822 -2.4653213 -1.512707 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.7107094 1.3142885 1.5696589 0.07036536 -0.43628898 0.58050656 (1,2,1,.,.) = 1.61177 -0.7052599 0.17889105 1.5860337 -0.3226252 -0.1341058 (2,1,1,.,.) = 0.4982454 -1.0186157 -1.9877508 -0.35151628 -1.8955303 2.1854792 (2,2,1,.,.) = -0.44977355 0.11218439 0.224829 -1.6386473 -0.6715097 0.14816228 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Cropping3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5))) input = np.random.random([2, 2, 3, 4, 5]) output = model.forward(input) Input is: array([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759], [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911], [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353], [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]], [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575], [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304], [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954], [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]], [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445], [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542], [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911], [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]], [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093], [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295], [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334], [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]], [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699], [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744], [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854], [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]], [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005], [0.9700492 , 0.590918 , 0.88279087, 0.36807701, 0.48872168], [0.847832 , 0.64009568, 0.97971251, 0.06989564, 0.80387185], [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]], [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475], [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919], [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606], [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]], [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397], [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274], [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272], [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]], [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231], [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435], [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504], [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]], [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ], [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764], [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024], [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]], [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993 ], [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ], [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089], [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]], [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002], [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841], [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372], [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]]) Output is: array([[[[[0.6530752 , 0.4779544 , 0.18358642], [0.57958406, 0.7861404 , 0.12632357]]], [[[0.8930068 , 0.8599061 , 0.38889495], [0.4575138 , 0.1316247 , 0.04326183]]]], [[[[0.68833065, 0.76978064, 0.14479478], [0.03855975, 0.12752528, 0.9758718 ]]], [[[0.6639144 , 0.49371347, 0.9227675 ], [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32) ZeroPadding2D Zero-padding layer for 2D input (e.g. picture). The input of this layer should be 4D. Scala: ZeroPadding2D(padding = (1, 1), dimOrdering = th , inputShape = null) Python: ZeroPadding2D(padding=(1, 1), dim_ordering= th , input_shape=None, name=None) Parameters: padding : How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3))) val input = Tensor[Float](2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 1.2227936 0.30803198 -1.3921114 0.43359384 -0.038079295 -1.241585 (1,2,.,.) = -1.1766883 -2.015887 -0.7110933 -0.5415997 -0.50294536 -1.3715594 (2,1,.,.) = 0.10733734 1.3369694 0.037685163 -1.2942516 0.2693859 0.6846867 (2,2,.,.) = -1.4678168 0.21972063 0.40070927 0.45242524 -0.03342953 -0.8016073 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 1.2227936 0.30803198 -1.3921114 0.0 0.0 0.43359384 -0.038079295 -1.241585 0.0 0.0 0.0 0.0 0.0 0.0 (1,2,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 -1.1766883 -2.015887 -0.7110933 0.0 0.0 -0.5415997 -0.50294536 -1.3715594 0.0 0.0 0.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.10733734 1.3369694 0.037685163 0.0 0.0 -1.2942516 0.2693859 0.6846867 0.0 0.0 0.0 0.0 0.0 0.0 (2,2,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 -1.4678168 0.21972063 0.40070927 0.0 0.0 0.45242524 -0.03342953 -0.8016073 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding2D(input_shape=(2, 2, 3))) input = np.random.random([2, 2, 2, 3]) output = model.forward(input) Input is: array([[[[0.0544422 , 0.21723616, 0.69071413], [0.68166784, 0.78673863, 0.63838101]], [[0.43930351, 0.62153019, 0.5539688 ], [0.79930636, 0.07007638, 0.13261168]]], [[[0.21493318, 0.21060602, 0.12101637], [0.90132665, 0.95799647, 0.09733214]], [[0.21548934, 0.27369217, 0.06024094], [0.85388521, 0.63911987, 0.34428558]]]]) Output is: array([[[[0. , 0. , 0. , 0. , 0. ], [0. , 0.0544422 , 0.21723616, 0.6907141 , 0. ], [0. , 0.68166786, 0.78673863, 0.638381 , 0. ], [0. , 0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. , 0. ], [0. , 0.43930352, 0.6215302 , 0.5539688 , 0. ], [0. , 0.79930633, 0.07007638, 0.13261168, 0. ], [0. , 0. , 0. , 0. , 0. ]]], [[[0. , 0. , 0. , 0. , 0. ], [0. , 0.21493319, 0.21060602, 0.12101637, 0. ], [0. , 0.90132666, 0.9579965 , 0.09733213, 0. ], [0. , 0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. , 0. ], [0. , 0.21548934, 0.27369216, 0.06024094, 0. ], [0. , 0.85388523, 0.63911986, 0.34428558, 0. ], [0. , 0. , 0. , 0. , 0. ]]]], dtype=float32) ShareConvolution2D Applies a 2D convolution over an input image composed of several input planes. You can also use ShareConv2D as an alias of this layer. Data format currently supported for this layer is DataFormat.NCHW (dimOrdering='th'). The input of this layer should be 4D. Scala: ShareConvolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, subsample = (1, 1), padH = 0, padW = 0, propagateBack = true, dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: ShareConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, subsample=(1, 1), pad_h=0, pad_w=0, propagate_back=True, dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : Initialization method for the weights of the layer. Default is Xavier. You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method. activation : Activation function to use. Default is null. You can also pass in corresponding string representations such as 'relu' or 'sigmoid', etc. for simple activations in the factory method. subsample : Int array of length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). padH : The additional zeros added to the height dimension. Default is 0. padW : The additional zeros added to the width dimension. Default is 0. propagateBack : Whether to propagate gradient back. Default is true. dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th'). wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3))) val input = Tensor[Float](1, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.033261865 -0.5991786 1.7385886 -0.56382173 0.4827164 -0.62269926 (1,2,.,.) = -0.31000894 -0.05032834 -1.1754748 2.594314 -1.0447274 -1.2348005 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.39924833 (1,2,.,.) = -0.05582048 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1] Python example: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import ShareConvolution2D import numpy as np model = Sequential() model.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3))) input = np.random.random([1, 2, 2, 3]) output = model.forward(input) Input is: array([[[[0.94476901, 0.20822355, 0.12900894], [0.07171242, 0.40400603, 0.87892258]], [[0.40369527, 0.92786425, 0.17116734], [0.73204729, 0.89770083, 0.86390069]]]]) Output is array([[[[ 0.1860767 ]], [[-0.00958405]]]], dtype=float32) UpSampling1D UpSampling layer for 1D inputs. Repeats each temporal step 'length' times along the time axis. The input of this layer should be 3D. Scala: UpSampling1D(length = 2, inputShape = null) Python: UpSampling1D(length=2, input_shape=None, name=None) Parameters: length : Integer. UpSampling factor. Default is 2. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.8499613 0.6955453 -2.8545783 -0.26392975 -0.5695636 0.13427743 (2,.,.) = 0.52427506 -0.7843101 -0.12673262 1.0643414 0.69714475 -0.013671399 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.8499613 0.6955453 -2.8545783 -0.8499613 0.6955453 -2.8545783 -0.8499613 0.6955453 -2.8545783 -0.26392975 -0.5695636 0.13427743 -0.26392975 -0.5695636 0.13427743 -0.26392975 -0.5695636 0.13427743 (2,.,.) = 0.52427506 -0.7843101 -0.12673262 0.52427506 -0.7843101 -0.12673262 0.52427506 -0.7843101 -0.12673262 1.0643414 0.69714475 -0.013671399 1.0643414 0.69714475 -0.013671399 1.0643414 0.69714475 -0.013671399 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3] Python example: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import UpSampling1D import numpy as np model = Sequential() model.add(UpSampling1D(length=3, input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.22908319, 0.6684591 , 0.12425427], [0.02378978, 0.12953109, 0.70786959]], [[0.40711686, 0.64417535, 0.92019981], [0.28788481, 0.77902591, 0.93019748]]]) Output is array([[[0.2290832 , 0.6684591 , 0.12425426], [0.2290832 , 0.6684591 , 0.12425426], [0.2290832 , 0.6684591 , 0.12425426], [0.02378978, 0.12953109, 0.7078696 ], [0.02378978, 0.12953109, 0.7078696 ], [0.02378978, 0.12953109, 0.7078696 ]], [[0.40711686, 0.64417535, 0.9201998 ], [0.40711686, 0.64417535, 0.9201998 ], [0.40711686, 0.64417535, 0.9201998 ], [0.2878848 , 0.7790259 , 0.9301975 ], [0.2878848 , 0.7790259 , 0.9301975 ], [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)","title":"Convolutional Layers"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#locallyconnected2d","text":"A Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input. The input is 2D tensor with shape: (batch_size, channels, rows, cols). Scala: LocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = valid , subsample = (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: LocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.71993834 0.018790463 0.08133635 0.35603827 -1.1757486 1.8503827 -1.4548069 -0.6309117 -0.53039306 -0.14174776 0.7653523 -0.1891388 (1,2,.,.) = 1.0949191 0.13689162 0.35839355 -0.14805469 -2.5264592 -0.34186792 1.3190275 -0.11725446 -0.48823252 -1.5305915 -1.0556486 1.792275 (2,1,.,.) = 0.92393816 0.83243525 0.22506136 0.6694662 0.7662836 -0.23876576 -0.7719174 0.13114463 0.042082224 1.2212821 -1.2496184 -0.18717249 (2,2,.,.) = 0.726698 0.42673108 0.0786712 -1.4069401 -0.090565465 0.49527475 0.08590904 -0.51858175 1.4575573 0.9669369 0.21832618 0.34654656 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.022375792 0.669761 -0.25723624 0.99919814 0.93189466 0.8592935 (1,2,.,.) = 0.12613812 -1.0531536 0.8148589 0.66276294 0.12609969 0.6590149 (2,1,.,.) = -0.1259023 0.32203823 0.07248953 -0.125191 -0.1285046 0.021367729 (2,2,.,.) = -0.13560611 -0.038621478 -0.08420516 -0.0021556932 -0.094522506 -0.08551059 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import LocallyConnected2D model = Sequential() model.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.75179142 0.10678918 0.92663152 0.2041142 ] [0.03534582 0.13742629 0.94115987 0.17303432] [0.91112368 0.19837546 0.45643767 0.16589123]] [[0.22996923 0.22878544 0.75623624 0.7058976 ] [0.14107232 0.49484648 0.71194356 0.53604538] [0.46257205 0.46902871 0.48046811 0.83579709]]] [[[0.9397535 0.51814825 0.10492714 0.24623405] [0.69800376 0.12353963 0.69536497 0.05159074] [0.56722731 0.33348394 0.47648031 0.25398067]] [[0.51018599 0.3416568 0.14112375 0.76505795] [0.16242231 0.16735028 0.79000471 0.98701885] [0.79852431 0.77458166 0.12551857 0.43866238]]]] Output is [[[[ 0.14901309 -0.11168094 0.28349853] [ 0.21792562 0.49922782 -0.06560349]] [[ 0.6176302 -0.4638375 -0.13387583] [-0.04903107 0.07764787 -0.33653474]]] [[[ 0.24676235 -0.46874076 0.33973938] [ 0.21408634 0.36619198 0.17972258]] [[ 0.35941058 -0.23446569 -0.09271184] [ 0.39490524 -0.00668371 -0.25355732]]]]","title":"LocallyConnected2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#convolution1d","text":"Applies convolution operator for filtering neighborhoods of 1-D inputs. You can also use Conv1D as an alias of this layer. The input of this layer should be 3D. Scala: Convolution1D(nbFilter, filterLength, init = glorot_uniform , activation = null, borderMode = valid , subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Convolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. filterLength : The extension (spatial or temporal) of each filter. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsampleLength : Factor by which to subsample output. Integer. Default is 1. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Convolution1D(8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.4253887 -0.044403594 -1.1169672 -0.19499049 0.85463065 0.6665206 0.21340805 0.56255895 1.1126599 -0.3423326 0.09643264 -0.34345046 (2,.,.) = -0.04046587 -0.2710401 0.10183265 1.4503858 1.0639644 1.5317003 -0.18313104 -0.7098296 0.612399 1.7357533 0.4641411 0.13530721 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.22175728 0.76192796 1.7907748 1.1534728 -1.5304534 0.07466106 -0.18292685 0.6038852 (2,.,.) = 0.85337734 0.43939286 -0.16770163 -0.8380078 0.7825804 -0.3485601 0.3017909 0.5823619 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Convolution1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Convolution1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.06092268 0.0508438 0.47256153 0.80004565] [0.48706905 0.65704781 0.04297214 0.42288264] [0.92286158 0.85394381 0.46423248 0.87896669]] [[0.216527 0.13880484 0.93482372 0.44812419] [0.95553331 0.27084259 0.58913626 0.01879454] [0.6656435 0.1985877 0.94133745 0.57504128]]] Output is [[[ 0.7461933 -2.3189526 -1.454972 -0.7323345 1.5272427 -0.87963724 0.6278059 -0.23403725]] [[ 1.2397771 -0.9249111 -1.1432207 -0.92868984 0.53766745 -1.0271561 -0.9593589 -0.4768026 ]]]","title":"Convolution1D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#convolution2d","text":"Applies a 2D convolution over an input image composed of several input planes. You can also use Conv2D as an alias of this layer. The input of this layer should be 4D, i.e. (samples, channels, rows, cols). The output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols). Scala: Convolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, borderMode = valid , subsample = (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Convolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. borderMode : Either 'valid' or 'same'. Default is 'valid'. subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Convolution2D[Float](4, 2, 2, activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.8852683 -0.81495345 -1.2799169 0.9779215 1.1456866 -0.10803124 -0.44350016 -1.7670554 -0.9059258 -0.08115104 -0.888267 1.8203543 (1,2,.,.) = -0.69458634 0.31331652 1.4600077 -0.93392456 1.4808512 0.2082488 -0.008410408 0.013914147 0.86024827 1.124567 0.28874534 -0.4866409 (2,1,.,.) = -0.020653103 0.8077344 -0.9391865 0.2743323 0.09707443 -0.1877453 2.3798819 1.71017 0.14860597 0.8954743 2.0009918 1.0548053 (2,2,.,.) = -0.06750481 -2.1010966 -0.51831937 -0.40519416 1.2983296 1.9960507 0.31097296 -1.0400984 -0.20703147 0.32478333 -0.5247251 1.2356688 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.49652004 0.62284863 0.0 1.2256577 0.11462581 0.761484 (1,2,.,.) = 0.0 0.0 1.6321466 0.69082737 0.10713227 0.0 (1,3,.,.) = 0.0 0.0 1.0226117 0.0 0.0 0.0 (1,4,.,.) = 0.017812707 0.044630717 0.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.79017955 0.0 1.1551664 0.0 0.0 (2,2,.,.) = 0.0 0.0 0.0 0.0 0.9762883 0.0 (2,3,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 (2,4,.,.) = 0.0 0.0 0.1633394 0.66279346 0.07180607 1.7188346 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Convolution2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[ 0.70766604, 0.56604946, 0.89172683, 0.35057259], [ 0.89700606, 0.71675588, 0.92357667, 0.73319623], [ 0.38198447, 0.66954234, 0.46397678, 0.81329758]], [[ 0.86972625, 0.16386155, 0.73140259, 0.07359015], [ 0.43441431, 0.16852341, 0.15025034, 0.34109183], [ 0.89670592, 0.06335869, 0.72356566, 0.54245763]]], [[[ 0.37727322, 0.14688331, 0.06249512, 0.29553298], [ 0.50554043, 0.33364744, 0.95334248, 0.40551935], [ 0.81317402, 0.59253283, 0.8249684 , 0.80419637]], [[ 0.71737738, 0.09376579, 0.3793706 , 0.91432729], [ 0.34433954, 0.74886398, 0.97859311, 0.9538775 ], [ 0.45521369, 0.79446047, 0.35239537, 0.12803574]]]]) Output is array([[[[ 0.0732559 , 0.70261478, 0.16962567], [ 0.3641817 , 0.56304729, 0.71597064]], [[-0.5932048 , -0.04155506, -0.49025974], [-0.57992101, -0.00230447, -0.33811107]], [[ 0.13634545, 0.27157408, -0.01450583], [ 0.34469086, 0.46334854, 0.55308509]], [[-0.01247289, 0.69034004, -0.01554111], [ 0.07790593, 0.09984782, 0.1278697 ]]], [[[ 0.02547407, 0.64045584, 0.21886043], [ 0.43482357, 0.45493811, 0.26216859]], [[-0.39469361, -0.34455007, -0.2396858 ], [-0.15447566, -0.35714447, -0.44134659]], [[ 0.30956799, 0.9154281 , 0.75450832], [ 0.37207305, 0.55432665, -0.29964659]], [[-0.48307419, -0.29406634, -0.29416537], [ 0.0138942 , 0.26592475, 0.38921899]]]], dtype=float32)","title":"Convolution2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution2d","text":"Applies an atrous convolution operator for filtering windows of 2-D inputs. A.k.a dilated convolution or convolution with holes. Bias will be included in this layer. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. You can also use AtrousConv2D as an alias of this layer. The input of this layer should be 4D. Scala: AtrousConvolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = th , wRegularizer = null, bRegularizer = null, inputShape = null) Python: AtrousConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), atrous_rate=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsample : Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1). atrousRate : Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1). dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AtrousConvolution2D[Float](4, 2, 2, activation = relu , inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.57626903 -0.56916714 0.46516004 -1.189643 -0.117406875 -1.1139084 1.115328 0.23275337 1.452733 -0.30968842 -0.6693723 -0.22098665 (1,2,.,.) = 0.06541251 -0.7000564 -0.460471 -0.5291468 -0.6625642 0.6460361 -0.556095 1.6327276 1.1914377 -0.69054496 -0.7461783 -1.0129389 (2,1,.,.) = -0.19123174 0.06803144 -0.010993495 -0.79966563 -0.010654963 2.0806832 1.972848 -1.8525643 -0.84387285 1.2974458 -0.42781293 0.3540522 (2,2,.,.) = 1.6231914 0.52689505 0.47506556 -1.030227 0.5143046 -0.9930063 -2.2869735 0.03994834 -1.5566326 -1.0937842 0.82693833 -0.08408405 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.11401264 0.0 1.1396459 0.0 0.0 0.88493514 (1,2,.,.) = 0.0 8.398667 1.1495202 0.0 0.0 0.1630742 (1,3,.,.) = 0.0 0.92470163 0.0 0.0 0.6321572 0.0 (1,4,.,.) = 0.0 1.1912066 0.0 0.0 1.27647 0.13422263 (2,1,.,.) = 0.0 0.0 0.51365596 0.0 0.4207713 1.1226959 (2,2,.,.) = 0.0 0.67600054 0.63635653 0.40892223 2.0596464 1.7690754 (2,3,.,.) = 1.1899394 0.0 0.0 1.7185769 0.39178902 0.0 (2,4,.,.) = 0.44333076 0.73385376 0.0 2.516453 0.36223468 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AtrousConvolution2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.52102612 0.30683086 0.38543426 0.0026452 ] [0.66805249 0.60656045 0.94601998 0.46574414] [0.49391338 0.14274225 0.70473703 0.30427041]] [[0.89066007 0.51782675 0.7063052 0.53440807] [0.67377917 0.51541465 0.02137767 0.63357007] [0.6614106 0.15849977 0.94459604 0.46852022]]] [[[0.79639026 0.94468413 0.73165819 0.54531867] [0.97741046 0.64477619 0.52373183 0.06861999] [0.37278645 0.53198045 0.95098245 0.86249644]] [[0.47186038 0.81694951 0.78009033 0.20925898] [0.69942883 0.37150324 0.58907364 0.88754231] [0.64083971 0.4480097 0.91716521 0.66808943]]]] Output is [[[[-0.32139003 -0.34667802 -0.35534883] [-0.09653517 -0.35052428 -0.09859636]] [[-0.3138999 -0.5563417 -0.6694119 ] [-0.03151364 0.35521197 0.31497604]] [[-0.34939283 -0.7537081 -0.3939833 ] [-0.25708836 0.06015673 -0.16755156]] [[-0.04791902 0.02060626 -0.5639752 ] [ 0.16054101 0.22528952 -0.02460545]]] [[[-0.13129832 -0.5262137 -0.12281597] [-0.36988598 -0.5532047 -0.43338764]] [[-0.21627764 -0.17562683 0.23560521] [ 0.23035726 -0.03152001 -0.46413773]] [[-0.63740283 -0.33359224 0.15731882] [-0.12795202 -0.25798583 -0.5261132 ]] [[-0.01759483 -0.07666921 -0.00890112] [ 0.27595833 -0.14117064 -0.3357542 ]]]]","title":"AtrousConvolution2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#locallyconnected1d","text":"Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input. Border mode currently supported for this layer is 'valid'. The input of this layer should be 3D. Scala: LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Dimensionality of the output. filterLength : The extension (spatial or temporal) of each filter. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsampleLength : Integer. Factor by which to subsample output. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.6755046 0.47923228 -0.41470557 -1.4644535 -1.580751 -0.36924785 -1.1507624 0.20131736 -0.4983051 -2.0898817 0.1623063 0.8118141 (2,.,.) = 1.5955191 -1.1017833 1.6614468 1.7959124 1.1084127 0.528379 -1.114553 -1.030853 0.37758648 -2.5828059 1.0172523 -1.6773314 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.20011228 0.7842446 -0.57892114 0.2405633 -0.35126245 -0.5116563 (2,.,.) = -0.33687726 0.7863857 0.30202985 0.33251244 -0.7414977 0.14271683 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LocallyConnected1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LocallyConnected1D(6, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.67992353 0.88287213 0.98861104 0.17401607] [0.23660068 0.02779148 0.52982599 0.19876749] [0.38880073 0.6498778 0.81532701 0.91719509]] [[0.30532677 0.1574227 0.40535271 0.03174637] [0.37303714 0.27821415 0.02314422 0.64516966] [0.74813923 0.9884225 0.40667151 0.21894944]]] Output is [[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816 0.94942856]] [[ 0.5890693 0.0179258 -0.31232932 0.4427027 -0.30954808 0.4486028 ]]]","title":"LocallyConnected1D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#upsampling2d","text":"UpSampling layer for 2D inputs. Repeats the rows and columns of the data by the specified size. The input of this layer should be 4D. Scala: UpSampling2D(size = (2, 2), dimOrdering = th , inputShape = null) Python: UpSampling2D(size=(2, 2), dim_ordering= th , input_shape=None, name=None) Parameters: size : Length 2. UpSampling factors for rows and columns. Default is (2, 2). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2))) val input = Tensor[Float](1, 2, 2, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.07563081 -1.921836 -1.7368479 0.1043008 (1,2,.,.) = -1.825055 -0.096810855 -0.89331573 0.72812295 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) -0.07563081 -0.07563081 -1.921836 -1.921836 -0.07563081 -0.07563081 -1.921836 -1.921836 -1.7368479 -1.7368479 0.1043008 0.1043008 -1.7368479 -1.7368479 0.1043008 0.1043008 (1,2,.,.) = -1.825055 -1.825055 -0.096810855 -0.096810855 -1.825055 -1.825055 -0.096810855 -0.096810855 -0.89331573 -0.89331573 0.72812295 0.72812295 -0.89331573 -0.89331573 0.72812295 0.72812295 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import UpSampling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(UpSampling2D((2, 2), input_shape=(2, 2, 2))) input = np.random.random([1, 2, 2, 2]) output = model.forward(input) Input is: [[[[0.55660253 0.21984387] [0.36271854 0.57464162]] [[0.55307278 0.33007518] [0.31527167 0.87789644]]]] Output is: [[[[0.55660254 0.55660254 0.21984388 0.21984388] [0.55660254 0.55660254 0.21984388 0.21984388] [0.36271855 0.36271855 0.57464164 0.57464164] [0.36271855 0.36271855 0.57464164 0.57464164]] [[0.55307275 0.55307275 0.33007517 0.33007517] [0.55307275 0.55307275 0.33007517 0.33007517] [0.31527168 0.31527168 0.8778964 0.8778964 ] [0.31527168 0.31527168 0.8778964 0.8778964 ]]]]","title":"UpSampling2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#upsampling3d","text":"UpSampling layer for 3D inputs. Repeats the 1st, 2nd and 3rd dimensions of the data by the specified size. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). The input of this layer should be 5D. Scala: UpSampling3D(size = (2, 2, 2), dimOrdering = th , inputShape = null) Python: UpSampling3D(size=(2, 2, 2), dim_ordering= th , input_shape=None, name=None) Parameters: size : Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2). dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2))) val input = Tensor[Float](1, 1, 1, 2, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 0.05876646 0.8743367 -0.15551122 0.9405281 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.05876646 0.05876646 0.8743367 0.8743367 0.05876646 0.05876646 0.8743367 0.8743367 -0.15551122 -0.15551122 0.9405281 0.9405281 -0.15551122 -0.15551122 0.9405281 0.9405281 (1,1,2,.,.) = 0.05876646 0.05876646 0.8743367 0.8743367 0.05876646 0.05876646 0.8743367 0.8743367 -0.15551122 -0.15551122 0.9405281 0.9405281 -0.15551122 -0.15551122 0.9405281 0.9405281 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import UpSampling3D model = Sequential() model.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2))) input = np.random.random([1, 1, 1, 2, 2]) output = model.forward(input) Input is: [[[[[0.01897243 0.87927954] - [0.13656585 0.3003842 ]]]]] Output is [[[[[0.01897243 0.01897243 0.87927955 0.87927955] [0.01897243 0.01897243 0.87927955 0.87927955] [0.13656585 0.13656585 0.3003842 0.3003842 ] [0.13656585 0.13656585 0.3003842 0.3003842 ]] [[0.01897243 0.01897243 0.87927955 0.87927955] [0.01897243 0.01897243 0.87927955 0.87927955] [0.13656585 0.13656585 0.3003842 0.3003842 ] [0.13656585 0.13656585 0.3003842 0.3003842 ]]]]]","title":"UpSampling3D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution1d","text":"Applies an atrous convolution operator for filtering neighborhoods of 1-D inputs. A.k.a dilated convolution or convolution with holes. Bias will be included in this layer. Border mode currently supported for this layer is 'valid'. You can also use AtrousConv1D as an alias of this layer. The input of this layer should be 3D. Scala: AtrousConvolution1D(nbFilter, filterLength, init = glorot_uniform , activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null) Python: AtrousConvolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution kernels to use. filterLength : The extension (spatial or temporal) of each filter. init : String representation of the initialization method for the weights of the layer. See here for available initialization strings. Default is 'glorot_uniform'. activation : String representation of the activation function to use. See here for available activation strings. Default is null. subsampleLength : Factor by which to subsample output. Integer. Default is 1. atrousRate : Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.18186663 -0.43034658 0.26391524 -1.4132749 -0.17445838 1.3798479 0.1737039 1.152537 0.27590567 0.009284354 -0.80261934 -0.9434588 (2,.,.) = -0.20791245 0.21988653 0.8744776 0.2940677 0.07080339 0.51823103 -0.46097854 -0.037812505 0.35226902 0.79622966 0.011483789 0.88822025 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.026210725 1.2229221 0.45232815 -1.0826558 0.849349 0.086645454 0.041758537 0.3721839 (2,.,.) = -0.14264873 0.060507685 -0.217965 0.42317814 0.17935039 -0.05465065 -0.6533742 -0.009769946 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import AtrousConvolution1D model = Sequential() model.add(AtrousConvolution1D(8, 3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.44706076 0.5902202 0.3784323 0.4098717 ] [0.74646876 0.98997355 0.64164388 0.61591103] [0.88695659 0.16591123 0.6575717 0.55897158]] [[0.51990872 0.82065542 0.18409799 0.99078291] [0.03853884 0.0781884 0.82290244 0.99992993] [0.02394716 0.10870804 0.17077537 0.77893951]]] Output is [[[-0.09361145 0.48225394 -0.3777458 -0.84651476 0.3678655 -0.02871403 1.0220621 0.7548751 ]] [[-0.0299319 0.37761992 -0.08759689 -0.01757497 -0.01414538 -0.2547227 0.70025307 0.49045497]]]","title":"AtrousConvolution1D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#zeropadding1d","text":"Zero-padding layer for 1D input (e.g. temporal sequence). The input of this layer should be 3D. Scala: ZeroPadding1D(padding = 1, inputShape = null) Python: ZeroPadding1D(padding=1, input_shape=None, name=None) Parameters: padding : How many zeros to add at the beginning and at the end of the padding dimension. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.7421485 -0.13270181 -0.12605186 -0.7442475 0.36977226 -0.90300065 -0.34193754 -0.035565257 -0.23300397 0.8183156 0.7023575 -0.16938858 (2,.,.) = -0.7785278 0.36642975 -1.0542017 -0.29036212 -0.22632122 0.46808097 -0.68293047 1.2529073 -0.8619831 1.3846883 1.0762612 1.1351995 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.0 0.0 0.0 0.0 0.7421485 -0.13270181 -0.12605186 -0.7442475 0.36977226 -0.90300065 -0.34193754 -0.035565257 -0.23300397 0.8183156 0.7023575 -0.16938858 0.0 0.0 0.0 0.0 (2,.,.) = 0.0 0.0 0.0 0.0 -0.7785278 0.36642975 -1.0542017 -0.29036212 -0.22632122 0.46808097 -0.68293047 1.2529073 -0.8619831 1.3846883 1.0762612 1.1351995 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding1D(1, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.74177145 0.75805981 0.2091588 0.46929227] [0.46041743 0.13213793 0.51065024 0.36081853] [0.60803218 0.27764702 0.31788482 0.65445294]] [[0.96255443 0.74692762 0.50050961 0.88456158] [0.55492653 0.50850271 0.17788885 0.91569285] [0.27356035 0.74622588 0.39690752 0.75229177]]] Output is [[[0.0 0.0 0.0 0.0 ] [0.74177146 0.7580598 0.2091588 0.46929225] [0.46041742 0.13213794 0.5106502 0.36081854] [0.60803217 0.27764702 0.31788483 0.6544529 ] [0.0 0.0 0.0 0.0 ]] [[0.0 0.0 0.0 0.0 ] [0.96255445 0.7469276 0.5005096 0.8845616 ] [0.5549265 0.5085027 0.17788884 0.91569287] [0.27356035 0.7462259 0.39690754 0.75229174] [0.0 0.0 0.0 0.0 ]]]","title":"ZeroPadding1D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#zeropadding3d","text":"Zero-padding layer for 3D data (spatial or spatio-temporal). The input of this layer should be 5D. Scala: ZeroPadding3D(padding = (1, 1, 1), dimOrdering = th , inputShape = null) Python: ZeroPadding3D(padding=(1, 1, 1), dim_ordering= th , input_shape=None, name=None) Parameters: padding : Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2))) val input = Tensor[Float](1, 1, 2, 1, 2).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.59840345 -0.06308561 (1,1,2,.,.) = 0.48804763 0.2723002 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 (1,1,2,.,.) = 0.0 0.0 0.0 0.0 0.0 -0.59840345 -0.06308561 0.0 0.0 0.0 0.0 0.0 (1,1,3,.,.) = 0.0 0.0 0.0 0.0 0.0 0.48804763 0.2723002 0.0 0.0 0.0 0.0 0.0 (1,1,4,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2))) input = np.random.random([1, 1, 2, 1, 2]) output = model.forward(input) Input is: [[[[[0.03167021, 0.15764403]], [[0.26572586, 0.48872052]]]]] Output is [[[[[0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0.03167021, 0.15764403, 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0.26572585, 0.48872054, 0. ], [0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ]]]]]","title":"ZeroPadding3D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#cropping1d","text":"Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1). The input of this layer should be 3D, i.e. (batch, axis_to_crop, features). The output of this layer should be 3D, i.e. (batch, cropped_axis, features). Scala: Cropping1D(cropping = (1, 1), inputShape = null) Python: Cropping1D(cropping=(1, 1), input_shape=None, name=None) Parameters: cropping : Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1). inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.06297628 -0.8408224 0.21813048 -0.14371997 0.9278932 0.069493145 -0.2900171 0.536517 3.430168 -0.53643423 0.12677099 0.3572487 (2,.,.) = 1.493348 -1.1703341 -0.37385875 -0.239736 0.33984247 -0.6005885 1.2722077 -0.5043763 0.012092848 0.40293974 0.61356264 2.4283617 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.9278932 0.069493145 -0.2900171 0.536517 (2,.,.) = 0.33984247 -0.6005885 1.2722077 -0.5043763 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4] Python example: from zoo.pipeline.api.keras.layers import Cropping1D from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Cropping1D(input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.12013423, 0.21359734, 0.92871231, 0.92152503], [ 0.3649771 , 0.39968689, 0.92007275, 0.16493056], [ 0.11018303, 0.7591447 , 0.35932136, 0.97727728]], [[ 0.06645696, 0.21909036, 0.01219254, 0.46561466], [ 0.64316144, 0.53577975, 0.38302965, 0.56807556], [ 0.25223652, 0.23857826, 0.1884081 , 0.42532243]]]) Output is: array([[[ 0.36497709, 0.3996869 , 0.92007273, 0.16493057]], [[ 0.64316142, 0.53577977, 0.38302964, 0.56807554]]], dtype=float32)","title":"Cropping1D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#cropping2d","text":"Cropping layer for 2D input (e.g. picture). The input of this layer should be 4D. Scala: Cropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = th , inputShape = null) Python: Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering= th , input_shape=None, name=None) Parameters: cropping : Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.6840084 0.293568 0.045959193 0.91535753 -0.49666363 -0.05026308 0.22163485 0.08330725 0.36190453 -0.023894459 0.40037137 0.15155333 (1,2,.,.) = 1.0107938 0.05100493 -0.88689697 0.111396775 0.065911256 -0.41727677 0.62742686 -0.5435138 -1.0133605 0.7352207 -0.77922934 -0.36588958 (2,1,.,.) = -0.6847248 0.8627568 -0.5600547 0.48514402 -0.9261762 -0.34248486 -0.09243064 -0.13134436 -0.23247129 1.2801572 -1.377833 -1.7608607 (2,2,.,.) = 1.1907105 0.30009162 -1.2604285 1.0099201 -1.211673 -0.08809458 0.4386406 -0.6264226 0.112140626 0.3690179 0.832656 1.3931179 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.293568 0.045959193 0.91535753 -0.05026308 0.22163485 0.08330725 (1,2,.,.) = 0.05100493 -0.88689697 0.111396775 -0.41727677 0.62742686 -0.5435138 (2,1,.,.) = 0.8627568 -0.5600547 0.48514402 -0.34248486 -0.09243064 -0.13134436 (2,2,.,.) = 0.30009162 -1.2604285 1.0099201 -0.08809458 0.4386406 -0.6264226 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import Cropping2D from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097], [0.36859968, 0.44601991, 0.94679033, 0.93842937], [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]], [[0.32265899, 0.37304445, 0.09097587, 0.52496901], [0.70275446, 0.10796127, 0.74849378, 0.99118752], [0.34310691, 0.60435919, 0.22227177, 0.48464358]]], [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216], [0.48278365, 0.0968289 , 0.9465143 , 0.49814986], [0.36140084, 0.98581155, 0.14834531, 0.71290525]], [[0.8909849 , 0.66729728, 0.53332039, 0.83958965], [0.3645429 , 0.40645471, 0.02596942, 0.80835778], [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]]) Output is: array([[[[0.78710294, 0.4518868 , 0.787381 ], [0.44601992, 0.94679034, 0.93842936]], [[0.37304446, 0.09097587, 0.524969 ], [0.10796127, 0.7484938 , 0.9911875 ]]], [[[0.6009071 , 0.09771059, 0.19654216], [0.0968289 , 0.9465143 , 0.49814987]], [[0.6672973 , 0.53332037, 0.83958966], [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32)","title":"Cropping2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#cropping3d","text":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). The input of this layer should be 5D. Scala: Cropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = th , inputShape = null) Python: Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering= th , input_shape=None, name=None) Parameters: cropping : Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)). dimOrdering : Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5))) val input = Tensor[Float](2, 2, 3, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.12339484 0.25661087 0.04387503 -1.1047344 -1.1413815 1.1830065 -0.07189157 -0.5418846 0.5576781 -0.5460917 -0.5679186 -0.30854696 1.2614665 -0.6774269 -0.63295823 0.5269464 -2.7981617 -0.056265026 -1.0814936 -1.0848739 (1,1,2,.,.) = -1.9100302 0.461067 0.4014941 0.60723174 -0.40414023 0.34300476 0.7107094 1.3142885 1.5696589 0.97591686 0.38320687 0.07036536 -0.43628898 0.58050656 -0.57882625 -0.43699506 -0.0094956765 0.15171598 0.038076796 -1.2433665 (1,1,3,.,.) = 0.39671394 0.880047 0.30971292 -0.3369089 0.13062176 -0.27803114 -0.62177086 0.16659822 0.89428085 0.23684736 1.6151237 -1.1479733 -0.2229254 1.1361892 0.79478127 -1.8207864 1.6544164 0.07977915 -1.1316417 -0.25483203 (1,2,1,.,.) = 1.3165517 -0.9479057 -1.4662051 -0.3343554 -0.4522552 -1.5829691 0.6378519 -0.16399206 1.4724066 1.2387054 -1.1467208 -0.6325814 -1.2106491 -0.035734158 0.19871919 2.285004 1.0482147 -2.0056705 -0.80917794 2.523167 (1,2,2,.,.) = -0.57108706 -0.23606259 -0.45569882 -0.034214735 -1.9130942 -0.2743481 1.61177 -0.7052599 0.17889105 -0.31241596 0.22377247 1.5860337 -0.3226252 -0.1341058 0.9239994 0.03615294 0.6233593 0.757827 -0.72271305 0.9429943 (1,2,3,.,.) = -0.4409662 0.8867786 2.0036085 0.16242673 -0.3332395 0.09082064 0.04958198 -0.27834833 1.8025815 -0.04848101 0.2690667 -1.1263227 -0.95486647 0.09473259 0.98166656 -0.9509363 -0.10084029 -0.35410827 0.29626986 0.97203517 (2,1,1,.,.) = 0.42096403 0.14016314 0.20216857 -0.678293 -1.0970931 -0.4981112 0.12429344 1.7156922 -0.24384527 -0.010780937 0.03672217 2.3021698 1.568247 -0.43173146 -0.5550057 0.30469602 1.4772439 -0.21195345 0.04221814 -1.6883365 (2,1,2,.,.) = 0.22468264 0.72787744 -0.9597003 -0.28472963 -1.4575284 1.0487963 0.4982454 -1.0186157 -1.9877508 -1.133779 0.17539643 -0.35151628 -1.8955303 2.1854792 0.59556997 0.6893949 -0.19556235 0.25862908 0.24450152 0.17786922 (2,1,3,.,.) = 1.147159 -0.8849993 0.9826487 0.95360875 -0.9210176 1.3439047 0.6739913 0.06558858 0.91963255 -1.1758618 1.747105 -0.7225308 -1.0160877 0.67554474 -0.7762811 0.21184689 -0.43668815 -1.0738864 0.04661594 0.9613895 (2,2,1,.,.) = -0.377159 -0.28094378 0.1081715 1.3683178 1.2572801 0.47781375 0.4545212 0.55356956 1.0366637 -0.1962683 -1.820227 -0.111765414 1.9194998 -1.6089902 -1.6960226 0.14896627 0.9360371 0.49156702 0.08601956 -0.08815153 (2,2,2,.,.) = 0.056315728 -0.13061485 -0.49018836 -0.59103477 -1.6910721 -0.023719765 -0.44977355 0.11218439 0.224829 1.400084 0.31496882 -1.6386473 -0.6715097 0.14816228 0.3240011 -0.80607724 -0.37951842 -0.2187672 1.1087769 0.43044603 (2,2,3,.,.) = -1.6647842 -0.5720825 -1.5150099 0.42346838 1.495052 -0.3567161 -1.4341534 -0.19422509 -1.2871891 -1.2758921 -0.47077888 -0.42217267 0.67764246 1.2170314 0.8420698 -0.4263702 1.2792329 0.38645822 -2.4653213 -1.512707 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.7107094 1.3142885 1.5696589 0.07036536 -0.43628898 0.58050656 (1,2,1,.,.) = 1.61177 -0.7052599 0.17889105 1.5860337 -0.3226252 -0.1341058 (2,1,1,.,.) = 0.4982454 -1.0186157 -1.9877508 -0.35151628 -1.8955303 2.1854792 (2,2,1,.,.) = -0.44977355 0.11218439 0.224829 -1.6386473 -0.6715097 0.14816228 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Cropping3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5))) input = np.random.random([2, 2, 3, 4, 5]) output = model.forward(input) Input is: array([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759], [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911], [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353], [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]], [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575], [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304], [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954], [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]], [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445], [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542], [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911], [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]], [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093], [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295], [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334], [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]], [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699], [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744], [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854], [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]], [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005], [0.9700492 , 0.590918 , 0.88279087, 0.36807701, 0.48872168], [0.847832 , 0.64009568, 0.97971251, 0.06989564, 0.80387185], [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]], [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475], [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919], [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606], [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]], [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397], [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274], [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272], [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]], [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231], [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435], [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504], [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]], [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ], [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764], [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024], [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]], [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993 ], [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ], [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089], [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]], [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002], [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841], [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372], [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]]) Output is: array([[[[[0.6530752 , 0.4779544 , 0.18358642], [0.57958406, 0.7861404 , 0.12632357]]], [[[0.8930068 , 0.8599061 , 0.38889495], [0.4575138 , 0.1316247 , 0.04326183]]]], [[[[0.68833065, 0.76978064, 0.14479478], [0.03855975, 0.12752528, 0.9758718 ]]], [[[0.6639144 , 0.49371347, 0.9227675 ], [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32)","title":"Cropping3D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#zeropadding2d","text":"Zero-padding layer for 2D input (e.g. picture). The input of this layer should be 4D. Scala: ZeroPadding2D(padding = (1, 1), dimOrdering = th , inputShape = null) Python: ZeroPadding2D(padding=(1, 1), dim_ordering= th , input_shape=None, name=None) Parameters: padding : How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols). dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3))) val input = Tensor[Float](2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 1.2227936 0.30803198 -1.3921114 0.43359384 -0.038079295 -1.241585 (1,2,.,.) = -1.1766883 -2.015887 -0.7110933 -0.5415997 -0.50294536 -1.3715594 (2,1,.,.) = 0.10733734 1.3369694 0.037685163 -1.2942516 0.2693859 0.6846867 (2,2,.,.) = -1.4678168 0.21972063 0.40070927 0.45242524 -0.03342953 -0.8016073 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 1.2227936 0.30803198 -1.3921114 0.0 0.0 0.43359384 -0.038079295 -1.241585 0.0 0.0 0.0 0.0 0.0 0.0 (1,2,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 -1.1766883 -2.015887 -0.7110933 0.0 0.0 -0.5415997 -0.50294536 -1.3715594 0.0 0.0 0.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.10733734 1.3369694 0.037685163 0.0 0.0 -1.2942516 0.2693859 0.6846867 0.0 0.0 0.0 0.0 0.0 0.0 (2,2,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 -1.4678168 0.21972063 0.40070927 0.0 0.0 0.45242524 -0.03342953 -0.8016073 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import ZeroPadding2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(ZeroPadding2D(input_shape=(2, 2, 3))) input = np.random.random([2, 2, 2, 3]) output = model.forward(input) Input is: array([[[[0.0544422 , 0.21723616, 0.69071413], [0.68166784, 0.78673863, 0.63838101]], [[0.43930351, 0.62153019, 0.5539688 ], [0.79930636, 0.07007638, 0.13261168]]], [[[0.21493318, 0.21060602, 0.12101637], [0.90132665, 0.95799647, 0.09733214]], [[0.21548934, 0.27369217, 0.06024094], [0.85388521, 0.63911987, 0.34428558]]]]) Output is: array([[[[0. , 0. , 0. , 0. , 0. ], [0. , 0.0544422 , 0.21723616, 0.6907141 , 0. ], [0. , 0.68166786, 0.78673863, 0.638381 , 0. ], [0. , 0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. , 0. ], [0. , 0.43930352, 0.6215302 , 0.5539688 , 0. ], [0. , 0.79930633, 0.07007638, 0.13261168, 0. ], [0. , 0. , 0. , 0. , 0. ]]], [[[0. , 0. , 0. , 0. , 0. ], [0. , 0.21493319, 0.21060602, 0.12101637, 0. ], [0. , 0.90132666, 0.9579965 , 0.09733213, 0. ], [0. , 0. , 0. , 0. , 0. ]], [[0. , 0. , 0. , 0. , 0. ], [0. , 0.21548934, 0.27369216, 0.06024094, 0. ], [0. , 0.85388523, 0.63911986, 0.34428558, 0. ], [0. , 0. , 0. , 0. , 0. ]]]], dtype=float32)","title":"ZeroPadding2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#shareconvolution2d","text":"Applies a 2D convolution over an input image composed of several input planes. You can also use ShareConv2D as an alias of this layer. Data format currently supported for this layer is DataFormat.NCHW (dimOrdering='th'). The input of this layer should be 4D. Scala: ShareConvolution2D(nbFilter, nbRow, nbCol, init = glorot_uniform , activation = null, subsample = (1, 1), padH = 0, padW = 0, propagateBack = true, dimOrdering = th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: ShareConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, subsample=(1, 1), pad_h=0, pad_w=0, propagate_back=True, dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: nbFilter : Number of convolution filters to use. nbRow : Number of rows in the convolution kernel. nbCol : Number of columns in the convolution kernel. init : Initialization method for the weights of the layer. Default is Xavier. You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method. activation : Activation function to use. Default is null. You can also pass in corresponding string representations such as 'relu' or 'sigmoid', etc. for simple activations in the factory method. subsample : Int array of length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1). padH : The additional zeros added to the height dimension. Default is 0. padW : The additional zeros added to the width dimension. Default is 0. propagateBack : Whether to propagate gradient back. Default is true. dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th'). wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3))) val input = Tensor[Float](1, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.033261865 -0.5991786 1.7385886 -0.56382173 0.4827164 -0.62269926 (1,2,.,.) = -0.31000894 -0.05032834 -1.1754748 2.594314 -1.0447274 -1.2348005 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.39924833 (1,2,.,.) = -0.05582048 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1] Python example: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import ShareConvolution2D import numpy as np model = Sequential() model.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3))) input = np.random.random([1, 2, 2, 3]) output = model.forward(input) Input is: array([[[[0.94476901, 0.20822355, 0.12900894], [0.07171242, 0.40400603, 0.87892258]], [[0.40369527, 0.92786425, 0.17116734], [0.73204729, 0.89770083, 0.86390069]]]]) Output is array([[[[ 0.1860767 ]], [[-0.00958405]]]], dtype=float32)","title":"ShareConvolution2D"},{"location":"KerasStyleAPIGuide/Layers/convolutional/#upsampling1d","text":"UpSampling layer for 1D inputs. Repeats each temporal step 'length' times along the time axis. The input of this layer should be 3D. Scala: UpSampling1D(length = 2, inputShape = null) Python: UpSampling1D(length=2, input_shape=None, name=None) Parameters: length : Integer. UpSampling factor. Default is 2. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.8499613 0.6955453 -2.8545783 -0.26392975 -0.5695636 0.13427743 (2,.,.) = 0.52427506 -0.7843101 -0.12673262 1.0643414 0.69714475 -0.013671399 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.8499613 0.6955453 -2.8545783 -0.8499613 0.6955453 -2.8545783 -0.8499613 0.6955453 -2.8545783 -0.26392975 -0.5695636 0.13427743 -0.26392975 -0.5695636 0.13427743 -0.26392975 -0.5695636 0.13427743 (2,.,.) = 0.52427506 -0.7843101 -0.12673262 0.52427506 -0.7843101 -0.12673262 0.52427506 -0.7843101 -0.12673262 1.0643414 0.69714475 -0.013671399 1.0643414 0.69714475 -0.013671399 1.0643414 0.69714475 -0.013671399 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3] Python example: from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import UpSampling1D import numpy as np model = Sequential() model.add(UpSampling1D(length=3, input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.22908319, 0.6684591 , 0.12425427], [0.02378978, 0.12953109, 0.70786959]], [[0.40711686, 0.64417535, 0.92019981], [0.28788481, 0.77902591, 0.93019748]]]) Output is array([[[0.2290832 , 0.6684591 , 0.12425426], [0.2290832 , 0.6684591 , 0.12425426], [0.2290832 , 0.6684591 , 0.12425426], [0.02378978, 0.12953109, 0.7078696 ], [0.02378978, 0.12953109, 0.7078696 ], [0.02378978, 0.12953109, 0.7078696 ]], [[0.40711686, 0.64417535, 0.9201998 ], [0.40711686, 0.64417535, 0.9201998 ], [0.40711686, 0.64417535, 0.9201998 ], [0.2878848 , 0.7790259 , 0.9301975 ], [0.2878848 , 0.7790259 , 0.9301975 ], [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)","title":"UpSampling1D"},{"location":"KerasStyleAPIGuide/Layers/core/","text":"Masking Use a mask value to skip timesteps for a sequence. Scala: Masking(maskValue = 0.0, inputShape = null) Python: Masking(mask_value=0.0, input_shape=None, name=None) Parameters: maskValue : Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Masking import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Masking[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 1.4539868 1.5623108 -1.4101523 0.77073747 -0.18994702 2.2574463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.4539868 1.5623108 -1.4101523 0.77073747 -0.18994702 2.2574463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from bigdl.nn.keras.topology import Sequential from bigdl.nn.keras.layer import Masking model = Sequential() model.add(Masking(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.31542103 0.20640659 0.22282763] [0.99352167 0.90135718 0.24504717]] Output is [[0.31542102 0.2064066 0.22282763] [0.9935217 0.9013572 0.24504717]] SparseDense SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense: firstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward gradient to next layer in the backpropagation by default, as the gradInput of SparseDense is useless and very big in most cases. But, considering model like Wide Deep, we provide backwardStart and backwardLength to backward part of the gradient to next layer. The most common input is 2D. Scala: SparseDense(outputDim, init = glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null) Python: SparseDense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None) Parameters: outputDim : The size of the output dimension. init : String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'. activation : String representation of the activation function to use. Default is null. wRegularizer : An instance of [Regularizer], applied to the input weights matrices. Default is null. bRegularizer : An instance of [Regularizer], applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. backwardStart : Backward start index, counting from 1. backwardLength : Backward length. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4)) layer.build(Shape(-1, 2, 4)) val input = Tensor[Float](Array(2, 4)).rand() input.setValue(1, 1, 1f) input.setValue(2, 3, 3f) val sparseInput = Tensor.sparse(input) val output = layer.forward(sparseInput) Input is: input: (0, 0) : 1.0 (0, 1) : 0.2992794 (0, 2) : 0.11227019 (0, 3) : 0.722947 (1, 0) : 0.6147614 (1, 1) : 0.4288646 (1, 2) : 3.0 (1, 3) : 0.7749917 [com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4] Output is: output: 0.053516 0.33429605 0.22587383 -0.8998945 0.24308181 0.76745665 -1.614114 0.5381658 -2.2226436 -0.15573677 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SparseDense from zoo.pipeline.api.keras.models import Sequential from bigdl.util.common import JTensor model = Sequential() model.add(SparseDense(output_dim=2, input_shape=(3, 4))) input = JTensor.sparse( a_ndarray=np.array([1, 3, 2, 4]), i_ndarray = np.array([[0, 0, 1, 2], [0, 3, 2, 1]]), shape = np.array([3, 4]) ) output = model.forward(input) Input is: JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2] [0 3 2 1]], float Output is [[ 1.57136 2.29596 ] [ 0.5791738 -1.6598101 ] [ 2.331141 -0.84687066]] ``` ## **SoftShrink** Applies the soft shrinkage function element-wise to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Remark: This layer is from Torch and wrapped in Keras style. **Scala:** ```scala SoftShrink(value = 0.5, inputShape = null) Python: SoftShrink(value = 0.5, input_shape=None, name=None) Parameters: value : value The threshold value. Default is 0.5. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.36938807 0.023556225 -1.1655436 -0.34449077 0.9444338 -0.086538695 -1.0425501 1.364976 -1.2563878 -0.1842559 0.43428117 1.0756494 (1,2,.,.) = -0.19888283 1.251872 0.114836805 -0.6208773 0.0051822234 -0.8998633 0.06937465 -0.3929931 -0.1058129 0.6945743 -0.40083578 -0.6252444 (2,1,.,.) = -0.9899709 -0.77926594 -0.15497442 -0.15031165 -0.6028622 0.86623466 -2.1543107 0.41970536 -0.8215522 0.3014275 -0.32184362 0.14445356 (2,2,.,.) = 0.74701905 0.10044397 -0.40519297 0.03822808 0.30726334 0.27862388 1.731753 0.032177072 -1.3476961 -0.2294767 0.99794704 0.7398458 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 -0.56554353 0.0 0.34443378 0.0 -0.44255006 0.764976 -0.6563878 0.0 0.0 0.47564936 (1,2,.,.) = 0.0 0.6518719 0.0 -0.020877302 0.0 -0.29986328 0.0 0.0 0.0 0.09457427 0.0 -0.025244355 (2,1,.,.) = -0.3899709 -0.17926592 0.0 0.0 -0.0028621554 0.26623464 -1.5543107 0.0 -0.2215522 0.0 0.0 0.0 (2,2,.,.) = 0.14701903 0.0 0.0 0.0 0.0 0.0 1.131753 0.0 -0.74769604 0.0 0.397947 0.13984579 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SoftShrink from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SoftShrink(0.6, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[ 0.43421006, 0.28394451, 0.15221226, 0.47268966], [ 0.22426224, 0.24855662, 0.790498 , 0.67767582], [ 0.14879562, 0.56077882, 0.61470262, 0.94875862]], [[ 0.72404932, 0.89780875, 0.08456734, 0.01303937], [ 0.25023568, 0.45392504, 0.587254 , 0.51164461], [ 0.12277567, 0.05571182, 0.17076456, 0.71660884]]], [[[ 0.06369975, 0.85395557, 0.35752425, 0.606633 ], [ 0.67640252, 0.86861737, 0.18040722, 0.55467108], [ 0.24102058, 0.37580645, 0.81601612, 0.56513788]], [[ 0.8461435 , 0.65668365, 0.17969807, 0.51602926], [ 0.86191073, 0.34245714, 0.62795207, 0.36706125], [ 0.80344028, 0.81056003, 0.80959083, 0.15366483]]]]) Output is array([[[[ 0. , 0. , 0. , 0. ], [ 0. , 0. , 0.19049799, 0.07767582], [ 0. , 0. , 0.01470262, 0.34875858]], [[ 0.12404931, 0.29780871, 0. , 0. ], [ 0. , 0. , 0. , 0. ], [ 0. , 0. , 0. , 0.1166088 ]]], [[[ 0. , 0.25395554, 0. , 0.00663298], [ 0.07640249, 0.26861733, 0. , 0. ], [ 0. , 0. , 0.21601611, 0. ]], [[ 0.24614346, 0.05668366, 0. , 0. ], [ 0.26191074, 0. , 0.02795208, 0. ], [ 0.20344025, 0.21056002, 0.20959079, 0. ]]]], dtype=float32) ``` --- ## **Reshape** Reshapes an output to a certain shape. Supports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8). **Scala:** ```scala Reshape(targetShape, inputShape = null) Python: Reshape(target_shape, input_shape=None, name=None) Parameters: targetShape : The target shape that you desire to have. Batch dimension should be excluded. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.7092276 -1.3941092 -0.6348466 0.71309644 0.3605411 0.025597548 0.4287048 -0.548675 0.4623341 -2.3912702 0.22030865 -0.058272455 (1,2,.,.) = -1.5049093 -1.8828062 0.8230564 -0.020209199 -0.3415721 1.1219939 1.1089007 -0.74697906 -1.503861 -1.616539 0.048006497 1.1613717 (2,1,.,.) = 0.21216023 1.0107462 0.8586909 -0.05644316 -0.31436008 1.6892323 -0.9961186 -0.08169463 0.3559391 0.010261055 -0.70408463 -1.2480727 (2,2,.,.) = 1.7663039 0.07122444 0.073556066 -0.7847014 0.17604464 -0.99110585 -1.0302067 -0.39024687 -0.0260166 -0.43142694 0.28443158 0.72679126 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -1.7092276 -1.3941092 -0.6348466 0.71309644 0.3605411 0.025597548 0.4287048 -0.548675 0.4623341 -2.3912702 0.22030865 -0.058272455 -1.5049093 -1.8828062 0.8230564 -0.020209199 -0.3415721 1.1219939 1.1089007 -0.74697906 -1.503861 -1.616539 0.048006497 1.1613717 (2,.,.) = 0.21216023 1.0107462 0.8586909 -0.05644316 -0.31436008 1.6892323 -0.9961186 -0.08169463 0.3559391 0.010261055 -0.70408463 -1.2480727 1.7663039 0.07122444 0.073556066 -0.7847014 0.17604464 -0.99110585 -1.0302067 -0.39024687 -0.0260166 -0.43142694 0.28443158 0.72679126 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Reshape from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.39260304 0.10383185 0.87490319 0.89167328] [0.61649117 0.43285247 0.86851582 0.97743004] [0.90018969 0.04303951 0.74263493 0.14208656]] [[0.66193405 0.93432157 0.76160537 0.70437459] [0.99953431 0.23016734 0.42293405 0.66078049] [0.03357645 0.9695145 0.30111138 0.67109948]]] [[[0.39640201 0.92930203 0.86027666 0.13958544] [0.34584767 0.14743425 0.93804016 0.38053062] [0.55068792 0.77375329 0.84161166 0.48131356]] [[0.90116368 0.53253689 0.03332962 0.58278686] [0.34935685 0.32599554 0.97641892 0.57696434] [0.53974677 0.90682861 0.20027319 0.05962118]]]] Output is [[[0.39260304 0.10383185 0.8749032 0.89167327 0.6164912 0.43285248 0.86851585 0.97743005] [0.9001897 0.04303951 0.74263495 0.14208655 0.661934 0.9343216 0.7616054 0.7043746 ] [0.9995343 0.23016734 0.42293406 0.6607805 0.03357645 0.9695145 0.30111137 0.6710995 ]] [[0.396402 0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063] [0.5506879 0.7737533 0.8416117 0.48131356 0.9011637 0.53253686 0.03332962 0.58278686] [0.34935686 0.32599553 0.9764189 0.5769643 0.53974676 0.9068286 0.20027319 0.05962119]]] Merge Used to merge a list of inputs into a single output, following some merge mode. Merge must have at least two input layers. Scala: Merge(layers = null, mode = sum , concatAxis = -1, inputShape = null) Python: Merge(layers=None, mode= sum , concat_axis=-1, input_shape=None, name=None) Parameters: layers : A list of layer instances. Must be more than one layer. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concatAxis : Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val l1 = InputLayer[Float](inputShape = Shape(2, 3)) val l2 = InputLayer[Float](inputShape = Shape(2, 3)) val layer = Merge[Float](layers = List(l1, l2), mode = sum ) model.add(layer) val input1 = Tensor[Float](2, 2, 3).rand(0, 1) val input2 = Tensor[Float](2, 2, 3).rand(0, 1) val input = T(1 - input1, 2 - input2) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.utils.Table = { 2: (1,.,.) = 0.87815475 0.15025006 0.34412447 0.07909282 0.008027249 0.111715704 (2,.,.) = 0.52245367 0.2547527 0.35857987 0.7718501 0.26783863 0.8642062 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] 1: (1,.,.) = 0.5377018 0.28364193 0.3424284 0.0075349305 0.9018168 0.9435114 (2,.,.) = 0.09112563 0.88585275 0.3100201 0.7910178 0.57497376 0.39764535 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] } Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.4158566 0.433892 0.6865529 0.08662775 0.90984404 1.0552272 (2,.,.) = 0.6135793 1.1406054 0.66859996 1.5628679 0.8428124 1.2618515 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Merge, InputLayer from zoo.pipeline.api.keras.models import Sequential model = Sequential() l1 = InputLayer(input_shape=(3, 4)) l2 = InputLayer(input_shape=(3, 4)) model.add(Merge(layers=[l1, l2], mode='sum')) input = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])] output = model.forward(input) Input is: [[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492], [0.63922826, 0.45101604, 0.4555552 , 0.70105653], [0.75790798, 0.78551523, 0.00686686, 0.61290369]], [[0.00430865, 0.3303661 , 0.59915782, 0.90362298], [0.26230717, 0.99383052, 0.50630521, 0.99119486], [0.56138318, 0.68165639, 0.10644523, 0.51860127]]], [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321], [0.49354248, 0.97936826, 0.2266097 , 0.88083622], [0.11011776, 0.65762034, 0.17446099, 0.76658969]], [[0.58266689, 0.86322199, 0.87122999, 0.19031255], [0.42275118, 0.76379413, 0.21355413, 0.81132937], [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]] Output is [[[1.1313012 0.90907556 1.6311111 1.4896882 ] [1.1327708 1.4303843 0.6821649 1.5818927 ] [0.8680257 1.4431355 0.18132785 1.3794935 ]] [[0.5869755 1.1935881 1.4703878 1.0939355 ] [0.68505836 1.7576246 0.71985936 1.8025242 ] [1.5343305 1.3676738 0.50516313 1.1503248 ]]] MaxoutDense A dense maxout layer that takes the element-wise maximum of linear layers. This allows the layer to learn a convex, piecewise linear activation function over the inputs. The input of this layer should be 2D. Scala: MaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: MaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None) Parameters: outputDim : The size of output dimension. nbFeature : Number of Dense layers to use internally. Integer. Default is 4. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MaxoutDense(2, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -1.3550005 -1.1668127 -1.2882779 0.83600295 -1.94683 1.323666 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.71675766 1.2987505 0.9871184 0.6634239 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MaxoutDense from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MaxoutDense(2, input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.15996114 0.8391686 0.81922903] [0.52929427 0.35061754 0.88167693]] Output is [[0.4479192 0.4842512] [0.16833156 0.521764 ]] Squeeze Delete the singleton dimension(s). The batch dimension needs to be unchanged. For example, if input has size (2, 1, 3, 4, 1): Squeeze(1) will give output size (2, 3, 4, 1), Squeeze() will give output size (2, 3, 4) Scala: Squeeze(dims = null, inputShape = null) Python: Squeeze(dim=None, input_shape=None, name=None) Parameters: dims : The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32))) val input = Tensor[Float](1, 1, 1, 32).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.5521966 -1.2199087 0.365958 1.3845297 0.115254946 -0.20352958 2.4912808 0.987046 -0.2115477 3.0530396 -1.0043625 1.4688021 -1.2412603 -0.25383064 0.49164283 -0.40329486 0.26323202 0.7979045 0.025444122 0.47221214 1.3995043 0.48498031 -0.86961967 -0.058370713 -0.85965866 -1.2727696 0.45570874 0.73393697 0.2567143 1.4261572 -0.37773672 -0.7339463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5521966 -1.2199087 0.365958 1.3845297 0.115254946 -0.20352958 2.4912808 0.987046 -0.2115477 3.0530396 -1.0043625 1.4688021 -1.2412603 -0.25383064 0.49164283 -0.40329486 0.26323202 0.7979045 0.025444122 0.47221214 1.3995043 0.48498031 -0.86961967 -0.058370713 -0.85965866 -1.2727696 0.45570874 0.73393697 0.2567143 1.4261572 -0.37773672 -0.7339463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Squeeze from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Squeeze(1, input_shape=(1, 1, 32))) input = np.random.random([1, 1, 1, 32]) output = model.forward(input) Input is: [[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281, 0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763, 0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269, 0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821, 0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 , 0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729, 0.89774196, 0.77838838]]]] Output is [[[0.20585343, 0.470117 , 0.14553176, 0.939156 , 0.5723428 , 0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763, 0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 , 0.48919672, 0.284064 , 0.20962799, 0.8807176 , 0.45501822, 0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 , 0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 , 0.897742 , 0.7783884 ]]] BinaryThreshold Threshold the input. If an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1. Scala: BinaryThreshold(value = 1e-6, inputShape = null) Python: BinaryThreshold(value=1e-6, input_shape=None, name=None) Parameters: value : The threshold value to compare with. Default is 1e-6. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.1907398 -0.18995096 -2.0344417 -1.3789974 -1.8801064 -0.74757665 -0.4339697 0.0058485097 0.7012256 -0.6363152 2.0156987 -0.5512639 (1,2,.,.) = -0.5251603 0.082127444 0.29550993 1.6357868 -1.3828015 -0.11842779 0.3316966 -0.14360528 0.21216457 -0.117370956 -0.12934707 -0.35854268 (2,1,.,.) = -0.9071151 -2.8566089 -0.4796377 -0.915065 -0.8439908 -0.25404388 -0.39926198 -0.15191565 -1.0496653 -0.403675 -1.3591816 0.5311797 (2,2,.,.) = 0.53509855 -0.08892822 1.2196561 -0.62759316 -0.47476718 -0.43337926 -0.10406987 1.4035174 -1.7120812 1.1328355 0.9219375 1.3813454 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 0.0 (1,2,.,.) = 0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 (2,2,.,.) = 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import BinaryThreshold from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(BinaryThreshold(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767], [0.72650405, 0.53096719, 0.66346109, 0.0589329 ], [0.12994731, 0.92181174, 0.43129874, 0.97306968]], [[0.3031087 , 0.20339982, 0.69034712, 0.40191 ], [0.57517034, 0.30159448, 0.4801747 , 0.75175084], [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]], [[[0.46102959, 0.33029002, 0.69340103, 0.32885719], [0.84405147, 0.03421879, 0.68242578, 0.03560338], [0.12244515, 0.3610654 , 0.01312785, 0.84485178]], [[0.73472287, 0.75707757, 0.77070527, 0.40863145], [0.01137898, 0.82896826, 0.1498069 , 0.22309423], [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]]) Output is array([[[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]], [[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]]], dtype=float32) Sqrt Applies an element-wise square root operation to the input. Scala: Sqrt(inputShape = null) Python: Sqrt(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Sqrt[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 0.6950394 0.5234307 1.7375475 0.25833175 0.02685826 -0.6046901 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.8336902 0.7234851 1.3181607 0.50826347 0.16388491 NaN [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Sqrt from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Sqrt(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.2484558 , 0.65280218, 0.35286984], [0.19616094, 0.30966802, 0.82148169]] Output is [[0.4984534 , 0.80796176, 0.5940285 ], [0.4429006 , 0.55647826, 0.9063563 ]] Mul Multiply a single scalar factor to the incoming data Scala: Mul(inputShape = null) Python: Mul(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Mul import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Mul[Float](inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.2316265 -2.008802 -1.3908259 -0.61135375 -0.48992255 0.1786112 0.18872596 0.49621895 -0.6931602 -0.919745 -0.09019699 -0.41218707 (2,.,.) = -0.3135355 -0.4385771 -0.3317269 1.0412029 -0.8859662 0.17758773 -0.73779273 -0.4445366 0.3921595 1.6923207 0.014470488 0.4044164 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.59036994 -0.9629025 -0.6666808 -0.29304734 -0.2348403 0.0856158 0.09046422 0.23785843 -0.33226058 -0.44087213 -0.043235175 -0.19757845 (2,.,.) = -0.15029064 -0.21022828 -0.15901053 0.49909195 -0.42468053 0.0851252 -0.3536548 -0.21308492 0.18797839 0.81119984 0.006936308 0.19385365 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Mul from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Mul(input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.22607292, 0.59806062, 0.19428923, 0.22928606], [ 0.13804536, 0.1615547 , 0.52824658, 0.52794904], [ 0.4049169 , 0.94109084, 0.58158453, 0.78368633]], [[ 0.86233305, 0.47995805, 0.80430949, 0.9931171 ], [ 0.35179631, 0.33615276, 0.87756877, 0.73560288], [ 0.29775703, 0.11404466, 0.77695536, 0.97580018]]]) Output is array([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998], [-0.13730718, -0.1606908 , -0.52542186, -0.52512592], [-0.40275168, -0.93605846, -0.57847458, -0.77949566]], [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ], [-0.34991512, -0.33435524, -0.87287611, -0.73166931], [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32) MulConstant Multiply the input by a (non-learnable) scalar constant. Scala: MulConstant(constant, inputShape = null) Python: MulConstant(constant, input_shape=None, name=None) Parameters: constant : The scalar constant to be multiplied. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MulConstant[Float](2.2, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.16873977 1.0812985 1.0942211 -0.67091423 1.0086882 0.5915831 0.26184535 -1.361431 1.5616825 -0.037591368 1.2794676 1.0692137 (2,.,.) = 0.29868057 -0.23266982 -0.7679556 -2.209848 -0.13954644 -0.1368473 -0.54510623 1.8397199 -0.58691734 -0.56410027 -1.5567777 0.050648995 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.3712275 2.3788567 2.4072864 -1.4760114 2.219114 1.3014828 0.57605976 -2.9951482 3.4357016 -0.08270101 2.8148286 2.3522704 (2,.,.) = 0.6570973 -0.5118736 -1.6895024 -4.8616657 -0.3070022 -0.30106407 -1.1992338 4.047384 -1.2912182 -1.2410206 -3.424911 0.11142779 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MulConstant from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MulConstant(2.2, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.39874191, 0.66634984, 0.23907766, 0.31587494], [0.78842014, 0.93057835, 0.80739529, 0.71541279], [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]], [[0.60142458, 0.41221671, 0.00890549, 0.32069845], [0.51122554, 0.76280426, 0.87579418, 0.17182832], [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]] Output is [[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ], [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ], [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]], [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ], [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234], [1.19093 , 0.43591645, 2.0356452 , 1.2356553 ]]] Scale Scale is the combination of CMul and CAdd. Computes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input. Similarly, perform an expanded bias and perform an element-wise add. Scala: Scale(size, inputShape = null) Python: Scale(size, input_shape=None, name=None) Parameters: size : Size of the weight and bias. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Scale import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() var array = Array(1, 2) model.add(Scale[Float](array, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.006399727 -0.06412822 -0.2334789 0.31029955 1.6557469 1.9614618 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.09936619 0.57585865 0.20324506 0.38537437 -0.8598822 -1.0186496 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Scale from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Scale((2, 1), input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.7242994 , 0.77888884, 0.71470432], [0.03058471, 0.00602764, 0.57513629]] Output is [[1.0946966 , 1.1255064 , 1.0892813 ], [0.58151895, 0.5909191 , 0.37307182]] Log Applies a log transformation to the input. Scala: Log(inputShape = null) Python: Log(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Log import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Log[Float](inputShape = Shape(2, 4, 4))) val input = Tensor[Float](1, 2, 4, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.38405678 -0.5502389 -0.383079 -0.988537 -0.6294056 -0.7838047 0.8747865 -1.0659786 -2.2445498 -0.5488076 -0.42898977 0.6916364 1.6542299 -0.9966279 -0.38244298 1.6954672 (1,2,.,.) = 0.43478605 -0.6678534 1.9530942 -0.5209587 0.12899925 0.20572199 2.0359943 0.55223215 0.65247816 0.8792108 -0.38860792 0.48663738 -1.0084358 0.31141177 0.69208467 0.48385203 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.95696485 NaN NaN NaN NaN NaN -0.13377543 NaN NaN NaN NaN -0.36869493 0.5033356 NaN NaN 0.5279584 (1,2,.,.) = -0.83290124 NaN 0.6694149 NaN -2.0479486 -1.5812296 0.7109843 -0.5937868 -0.4269776 -0.12873057 NaN -0.720236 NaN -1.1666392 -0.36804697 -0.72597617 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Log from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Log(input_shape=(2, 4, 4))) input = np.random.random([1, 2, 4, 4]) output = model.forward(input) Input is: [[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453], [0.46529477, 0.81511804, 0.24435558, 0.45003562], [0.15170845, 0.35157662, 0.0925214 , 0.63852947], [0.27817508, 0.42572846, 0.44363004, 0.03536394]], [[0.65027784, 0.00429838, 0.07434429, 0.18653305], [0.19659183, 0.66647529, 0.77821197, 0.65894478], [0.28212032, 0.52307663, 0.09589939, 0.71547588], [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]] Output is [[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032], [-0.76508415, -0.20442237, -1.4091308 , -0.79842854], [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742], [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]], [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ], [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554], [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743], [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]] Identity Identity just return the input to output. It's useful in same parallel container to get an origin input. Scala: Identity(inputShape = null) Python: Identity(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Identity import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Identity[Float](inputShape = Shape(4, 4))) val input = Tensor[Float](3, 4, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.9601166 -0.86010313 0.0023731247 -0.81219757 1.1469674 -1.5375912 -1.5348053 -0.34829113 -1.236773 -0.7183283 -0.89256984 0.8605067 0.7937664 0.52992857 -1.6157389 0.36134166 (2,.,.) = -0.44434744 -0.23848957 -0.01632014 -0.58109635 -0.19856784 -2.3421717 -0.5868049 -0.76775354 0.80254126 1.78778 -1.1835604 1.4489703 0.8731402 0.8906672 0.2800079 -0.6715317 (3,.,.) = 1.4093032 2.358169 -1.4620789 1.1904576 -0.18263042 -0.31869793 2.01061 1.2159953 -0.5801479 1.2949371 -0.7510707 -1.0707517 0.30815956 -1.161963 -0.26964024 -0.4759499 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.9601166 -0.86010313 0.0023731247 -0.81219757 1.1469674 -1.5375912 -1.5348053 -0.34829113 -1.236773 -0.7183283 -0.89256984 0.8605067 0.7937664 0.52992857 -1.6157389 0.36134166 (2,.,.) = -0.44434744 -0.23848957 -0.01632014 -0.58109635 -0.19856784 -2.3421717 -0.5868049 -0.76775354 0.80254126 1.78778 -1.1835604 1.4489703 0.8731402 0.8906672 0.2800079 -0.6715317 (3,.,.) = 1.4093032 2.358169 -1.4620789 1.1904576 -0.18263042 -0.31869793 2.01061 1.2159953 -0.5801479 1.2949371 -0.7510707 -1.0707517 0.30815956 -1.161963 -0.26964024 -0.4759499 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Identity from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Identity(input_shape=(4, 4))) input = np.random.random([3, 4, 4]) output = model.forward(input) Input is: [[[0.36751123, 0.92287101, 0.73894405, 0.33699379], [0.69405782, 0.9653215 , 0.2617223 , 0.68205229], [0.71455325, 0.99419333, 0.90886495, 0.10232991], [0.1644055 , 0.30013138, 0.98921154, 0.26803146]], [[0.35898357, 0.72067882, 0.13236563, 0.71935521], [0.30865626, 0.71098844, 0.86718946, 0.12531168], [0.84916882, 0.84221518, 0.52186664, 0.87239729], [0.50637899, 0.10890469, 0.86832705, 0.93581179]], [[0.19640105, 0.09341008, 0.12043328, 0.09261859], [0.66019486, 0.07251262, 0.80929761, 0.39094486], [0.63027391, 0.39537796, 0.55578905, 0.53933265], [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]] Output is [[[0.36751124, 0.922871 , 0.73894405, 0.33699378], [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ], [0.71455324, 0.9941933 , 0.908865 , 0.10232991], [0.1644055 , 0.30013138, 0.98921156, 0.26803148]], [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ], [0.30865628, 0.71098846, 0.86718947, 0.12531169], [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ], [0.506379 , 0.10890469, 0.868327 , 0.9358118 ]], [[0.19640104, 0.09341008, 0.12043328, 0.09261858], [0.6601949 , 0.07251262, 0.8092976 , 0.39094487], [0.63027394, 0.39537796, 0.55578905, 0.5393326 ], [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]] Select Select an index of the input in the given dim and return the subset part. The batch dimension needs to be unchanged. For example, if input is: [[1, 2, 3], [4, 5, 6]] Select(1, 1) will give output [2 5] Select(1, -1) will give output [3 6] Scala: Select(dim, index, inputShape = null) Python: Select(dim, index, input_shape=None, name=None) Parameters: dim : The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input. index : The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Select import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3))) val input = Tensor[Float](1, 3, 1, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.67646945 -0.5485965 -0.11103154 (1,2,.,.) = -0.13488655 0.43843046 -0.04482145 (1,3,.,.) = -0.18094881 0.19431554 -1.7624844 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.18094881 0.19431554 -1.7624844 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3] Python example: from zoo.pipeline.api.keras.layers import Select from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Select(1, 2, input_shape=(3, 1, 3))) input = np.random.random([1, 3, 1, 3]) output = model.forward(input) Input is: array([[[[0.53306099, 0.95147881, 0.15222129]], [[0.89604861, 0.90160974, 0.5230576 ]], [[0.70779386, 0.14438568, 0.37601195]]]]) Output is: array([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32) Dense A densely-connected NN layer. The most common input is 2D. Scala: Dense(outputDim, init = glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Dense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None) Parameters: outputDim : The size of the output dimension. init : Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method. activation : Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method. wRegularizer : An instance of Regularizer , applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Dense import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Dense[Float](5, activation = relu , inputShape = Shape(4))) val input = Tensor[Float](2, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 1.4289935 -1.7659454 -0.08306135 -1.0153456 1.0191492 0.37392816 1.3076705 -0.19495767 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.5421522 0.49008092 0.0 0.0 0.0 0.07940009 0.0 0.12953377 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Dense from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Dense(5, activation= relu , input_shape=(4, ))) input = np.random.random([2, 4]) output = model.forward(input) Input is: array([[0.64593485, 0.67393322, 0.72505368, 0.04654095], [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]]) Output is array([[0. , 0. , 1.2698183 , 0. , 0.10656227], [0. , 0. , 0.6236721 , 0.00299606, 0.29664695]], dtype=float32) Negative Computes the negative value of each element of the input. Scala: Negative(inputShape = null) Python: Negative(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Negative import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Negative[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.031705 -0.5723963 1.998631 -0.32908052 2.4069138 -2.4111257 (2,.,.) = 0.5355049 -1.4404331 -0.38116863 -0.45641592 -1.1485358 0.94766915 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -1.031705 0.5723963 -1.998631 0.32908052 -2.4069138 2.4111257 (2,.,.) = -0.5355049 1.4404331 0.38116863 0.45641592 1.1485358 -0.94766915 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import Negative from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Negative(input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.39261261, 0.03164615, 0.32179116], [0.11969367, 0.61610712, 0.42573733]], [[0.36794656, 0.90912174, 0.540356 ], [0.42667627, 0.04154093, 0.84692964]]]) Output is array([[[-0.3926126 , -0.03164615, -0.32179114], [-0.11969367, -0.6161071 , -0.42573732]], [[-0.36794657, -0.90912175, -0.540356 ], [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32) CAdd This layer has a bias with given size. The bias will be added element-wise to the input. If the element number of the bias matches the input, a simple element-wise addition will be done. Or the bias will be expanded to the same size of the input. The expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised). Scala: CAdd(size, bRegularizer = null, inputShape = null) Python: CAdd(size, b_regularizer=None, input_shape=None, name=None) Parameters: size : the size of the bias bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.2183351 0.32434112 0.89350265 0.3348259 0.78677046 0.24054797 (2,.,.) = 0.9945844 0.72363794 0.7737936 0.05522544 0.3517818 0.7417069 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.1358028 0.6956667 1.0837181 0.6767027 0.7955346 0.5063505 (2,.,.) = 0.9120521 1.0949634 0.96400905 0.3971022 0.36054593 1.0075095 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import CAdd from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(CAdd([2, 1], input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.4122004 , 0.73289359, 0.11500016], [0.26974491, 0.32166632, 0.91408442]], [[0.66824327, 0.80271314, 0.75981145], [0.39271431, 0.07312566, 0.4966805 ]]]) Output is array([[[ 0.06560206, 0.38629526, -0.23159817], [ 0.44287407, 0.4947955 , 1.0872136 ]], [[ 0.32164496, 0.45611483, 0.41321313], [ 0.56584346, 0.24625483, 0.6698097 ]]], dtype=float32) RepeatVector Repeats the input n times. The input of this layer should be 2D, i.e. (num_samples, features). The output of thi layer should be 3D, i.e. (num_samples, n, features). Scala: RepeatVector(n, inputShape = null) Python: RepeatVector(n, input_shape=None, name=None) Parameters: n : Repetition factor. Integer. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(RepeatVector[Float](4, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.31839952 -0.3495366 0.542486 -0.54981124 -0.8428188 0.8225184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 (2,.,.) = -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import RepeatVector from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(RepeatVector(4, input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: array([[ 0.90715922, 0.54594769, 0.53952404], [ 0.08989831, 0.07265549, 0.45830114]]) Output is array([[[ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402]], [[ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116]]], dtype=float32) GaussianSampler Takes {mean, log_variance} as input and samples from the Gaussian distribution. Scala: GaussianSampler(inputShape = null) Python: GaussianSampler(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler import com.intel.analytics.bigdl.utils.{Shape, MultiShape, T} import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val shape1 = Shape(2, 3) val shape2 = Shape(2, 3) model.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2)))) val input1 = Tensor[Float](2, 2, 3).rand(0, 1) val input2 = Tensor[Float](2, 2, 3).rand(0, 1) val input = T(1 - input1, 2 - input2) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.utils.Table = { 2: (1,.,.) = 0.9996127 0.8964211 0.7424038 0.40628982 0.37035564 0.20108517 (2,.,.) = 0.6974727 0.60202897 0.1535999 0.012422224 0.5993025 0.96206 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] 1: (1,.,.) = 0.21060324 0.576583 0.21633287 0.1484059 0.2730577 0.25317845 (2,.,.) = 0.58513683 0.58095694 0.18811373 0.7029449 0.41235915 0.44636542 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] } Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.5258198 1.9536011 -1.8591263 -1.0618867 -0.751225 0.35412917 (2,.,.) = 1.3334517 -0.60312974 0.7324476 0.09502721 0.8094909 0.44807082 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GaussianSampler model = Sequential() model.add(GaussianSampler(input_shape=[(3,),(3,)])) input1 = np.random.random([2, 3]) input2 = np.random.random([2, 3]) input = [input1, input2] output = model.forward(input) Input is: [[[0.79941342, 0.87462822, 0.9516901 ], [0.20111287, 0.54634077, 0.83614511]], [[0.31886989, 0.22829382, 0.84355419], [0.51186641, 0.28043938, 0.29440057]]] Output is [[ 0.71405387 2.2944303 -0.41778684] [ 0.84234 2.3337283 -0.18952972]] Exp Applies element-wise exp to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: Exp(inputShape = null) Python: Exp(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Exp import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Exp[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.5841372 -0.13795324 -2.144475 0.09272669 1.055668 -1.2310301 1.2145554 -0.6073714 0.9296467 0.2923885 1.3364213 0.1652137 (1,2,.,.) = 0.2099718 -0.3856573 -0.92586 -0.5317779 0.6618383 -0.9677452 -1.5014665 -0.35464883 2.045924 -0.317644 -1.812726 0.95438373 (2,1,.,.) = -0.4536791 -0.34785584 1.6424289 -0.07981159 -0.8022624 -0.4211059 0.3461831 1.9598864 -0.84695745 -0.6115283 0.7729755 2.3077402 (2,2,.,.) = -0.08438411 -0.908458 0.6688936 -0.7292123 -0.26337254 0.55425745 -0.14925817 -0.010179609 -0.62562865 -1.0517743 -0.23839666 -1.144982 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.20512469 0.8711394 0.11712951 1.0971619 2.8738942 0.29199165 3.3687959 0.544781 2.533614 1.3396233 3.8054006 1.1796452 (1,2,.,.) = 1.2336433 0.6800035 0.39619055 0.5875594 1.9383523 0.37993878 0.22280318 0.7014197 7.7363033 0.7278619 0.16320862 2.5970695 (2,1,.,.) = 0.63528657 0.70620066 5.167706 0.92329025 0.44831353 0.6563206 1.4136615 7.0985208 0.42871734 0.5425211 2.1662023 10.051684 (2,2,.,.) = 0.9190782 0.4031454 1.9520763 0.48228875 0.76845556 1.740648 0.8613467 0.98987204 0.53492504 0.34931743 0.7878901 0.31822965 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Exp model = Sequential() model.add(Exp(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.93104587 0.94000338 0.84870765 0.98645553] [0.83708846 0.33375541 0.50119834 0.24879265] [0.51966475 0.84514791 0.15496452 0.61538968]] [[0.57250337 0.42520832 0.94850757 0.54317573] [0.64228691 0.9904079 0.01008592 0.51365217] [0.78640595 0.7717037 0.51277595 0.24245034]]] [[[0.82184752 0.92537331 0.20632728 0.47539445] [0.44604637 0.1507692 0.5437313 0.2074501 ] [0.93661363 0.93962609 0.29230559 0.74850958]] [[0.11659768 0.76177132 0.33194573 0.20695088] [0.49636212 0.85987328 0.49767861 0.96774006] [0.67669121 0.15542122 0.69981032 0.3349874 ]]]] Output is [[[[2.5371614 2.5599902 2.3366253 2.6817122] [2.3096325 1.3962016 1.6506982 1.2824761] [1.6814638 2.3283222 1.1676165 1.8503776]] [[1.7726992 1.5299091 2.5818534 1.721465 ] [1.9008229 2.6923325 1.010137 1.6713842] [2.1954916 2.163449 1.6699204 1.2743679]]] [[[2.2746985 2.52281 1.2291554 1.6086487] [1.5621239 1.1627283 1.7224218 1.2305363] [2.551327 2.5590243 1.3395122 2.1138473]] [[1.1236672 2.1420672 1.3936772 1.2299222] [1.6427343 2.3628614 1.6448984 2.6319895] [1.9673574 1.16815 2.0133708 1.3979228]]]] Square Applies an element-wise square operation to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: Square(inputShape = null) Python: Square(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Square import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Square[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.108013034 1.8879265 1.2232096 -1.5076439 1.4895755 -0.37966672 -0.34892964 0.15224025 -0.9296686 -1.1523775 0.14153497 -0.26954007 (1,2,.,.) = -1.0875931 2.190617 -0.6903083 1.0039362 -0.1275677 -1.1096588 0.37359753 -0.17367937 0.23349741 0.14639114 -0.2330162 0.5343827 (2,1,.,.) = 0.3222191 0.21463287 -1.0157064 -0.22627507 1.1714277 0.43371263 1.069315 0.5122436 0.1958086 -1.4601041 2.5394423 -0.470833 (2,2,.,.) = -0.38708544 -0.951611 -0.37234613 0.26813275 1.9477026 0.32779223 -1.2308712 -2.2376378 0.19652915 0.3304719 -1.7674786 -0.86961496 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.011666816 3.5642662 1.4962418 2.2729902 2.218835 0.14414681 0.1217519 0.023177093 0.86428374 1.3279738 0.020032147 0.07265185 (1,2,.,.) = 1.1828587 4.7988033 0.47652552 1.0078878 0.016273517 1.2313428 0.13957511 0.030164523 0.05452104 0.021430366 0.054296546 0.28556487 (2,1,.,.) = 0.10382515 0.046067268 1.0316595 0.05120041 1.3722429 0.18810664 1.1434345 0.26239353 0.038341008 2.131904 6.448767 0.22168371 (2,2,.,.) = 0.14983514 0.9055635 0.13864164 0.07189517 3.7935455 0.10744774 1.5150439 5.007023 0.038623706 0.109211676 3.1239805 0.7562302 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Square model = Sequential() model.add(Square(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.8708819 0.2698243 0.55854849 0.71699472] [0.66647234 0.72310216 0.8082119 0.66566951] [0.6714764 0.61394108 0.35063125 0.60473593]] [[0.37993365 0.64222557 0.96762005 0.18931697] [0.00529722 0.99133455 0.09786619 0.28988077] [0.60052911 0.83712995 0.59847519 0.54361243]]] [[[0.32832672 0.83316023 0.41272485 0.01963383] [0.89593955 0.73433713 0.67529323 0.69711912] [0.81251711 0.56755577 0.31958151 0.09795917]] [[0.46465895 0.22818875 0.31505317 0.41912166] [0.87865447 0.3799063 0.091204 0.68144165] [0.88274284 0.70479132 0.32074672 0.71771481]]]] Output is [[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01] [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01] [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]] [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02] [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02] [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]] [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04] [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01] [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]] [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01] [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01] [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]] Power Applies an element-wise power operation with scale and shift to the input. f(x) = (shift + scale * x)^power^ Power(power, scale = 1, shift = 0, inputShape = null) Python: Power(power, scale=1, shift=0, input_shape=None, name=None) Parameters: power : The exponent scale : The scale parameter. Default is 1. shift : The shift parameter. Default is 0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Power import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Power[Float](2, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.24691099 0.7588585 0.5785183 0.10356348 0.2252714 0.3129436 (2,.,.) = 0.6277785 0.75136995 0.044648796 0.46396527 0.9793776 0.92727077 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.060965035 0.5758662 0.3346834 0.010725395 0.050747205 0.0979337 (2,.,.) = 0.39410582 0.5645568 0.001993515 0.21526377 0.95918053 0.8598311 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import Power from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Power(2, input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.5300817 , 0.18128031, 0.19534253], [0.28380639, 0.78365165, 0.6893 ]], [[0.05574091, 0.400077 , 0.77051193], [0.033559 , 0.61051396, 0.13970227]]]) Output is array([[[0.2809866 , 0.03286255, 0.03815871], [0.08054607, 0.61410993, 0.4751345 ]], [[0.00310705, 0.16006161, 0.5936886 ], [0.00112621, 0.37272733, 0.01951673]]], dtype=float32) AddConstant Add a (non-learnable) scalar constant to the input. AddConstant(constant, inputShape = null) Python: AddConstant(constant, input_shape=None, name=None) Parameters: constant : The scalar constant to be added. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AddConstant[Float](1, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.5658301 0.3508225 0.4012322 0.1941942 0.18934165 0.6909284 (2,.,.) = 0.5985211 0.5485885 0.778548 0.16745302 0.10363362 0.92185616 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.5658301 1.3508224 1.4012322 1.1941942 1.1893417 1.6909285 (2,.,.) = 1.5985211 1.5485885 1.778548 1.167453 1.1036336 1.9218562 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import AddConstant from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(AddConstant(1, input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.71730919, 0.07752598, 0.10448237], [0.52319608, 0.38668494, 0.19588814]], [[0.15496092, 0.48405899, 0.41441248], [0.13792111, 0.7523953 , 0.55991187]]]) Output is array([[[1.7173092, 1.077526 , 1.1044824], [1.5231961, 1.3866849, 1.1958882]], [[1.1549609, 1.484059 , 1.4144125], [1.1379211, 1.7523953, 1.5599118]]], dtype=float32) Narrow Narrow the input with the number of dimensions not being reduced. The batch dimension needs to be unchanged. For example, if input is: [[1 2 3], [4 5 6]] Narrow(1, 1, 2) will give output [[2 3], [5 6]] Narrow(1, 2, -1) will give output [3, 6] Narrow(dim, offset, length = 1, inputShape = null) Python: Narrow(dim, offset, length=1, input_shape=None, name=None) Parameters: dim : The dimension to narrow. 0-based index. Cannot narrow the batch dimension. -1 means the last dimension of the input. offset : Non-negative integer. The start index on the given dimension. 0-based index. length : The length to narrow. Default is 1. Can use a negative length such as -1 in the case where input size is unknown. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.13770224 0.63719153 0.7776689 0.46612367 0.9026256 0.11982094 0.8282868 0.05095969 0.889799 0.6386537 0.35438475 0.298043 (1,2,.,.) = 0.5029727 0.20103335 0.20150806 0.06437344 0.2255908 0.5388977 0.59737855 0.5210477 0.4055072 0.11848069 0.7118382 0.9796308 (2,1,.,.) = 0.63957494 0.1921936 0.7749439 0.19744827 0.91683346 0.16140814 0.9753973 0.8161283 0.8481694 0.8802563 0.1233245 0.5732614 (2,2,.,.) = 0.275001 0.35905758 0.15939762 0.09233412 0.16610192 0.032060683 0.37298614 0.48936844 0.031097537 0.82767457 0.10246291 0.9951448 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.5029727 0.20103335 0.20150806 0.06437344 0.2255908 0.5388977 0.59737855 0.5210477 0.4055072 0.11848069 0.7118382 0.9796308 (2,1,.,.) = 0.275001 0.35905758 0.15939762 0.09233412 0.16610192 0.032060683 0.37298614 0.48936844 0.031097537 0.82767457 0.10246291 0.9951448 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4] Python example: from zoo.pipeline.api.keras.layers import Narrow from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Narrow(1, 1, input_shape=(2, 3, 4))) input = np.random.rand(2, 2, 3, 4) output = model.forward(input) Input is: array([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923], [0.28316902, 0.3004414 , 0.40298034, 0.37476436], [0.18825825, 0.38979411, 0.32963262, 0.37783457]], [[0.14824117, 0.43532988, 0.57077087, 0.91535978], [0.46375725, 0.90511296, 0.18859044, 0.92820822], [0.13675737, 0.48270908, 0.04260755, 0.97255687]]], [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529], [0.07472717, 0.5715716 , 0.57029986, 0.26475783], [0.56757079, 0.27602746, 0.45799196, 0.74420842]], [[0.89048761, 0.08280716, 0.99030481, 0.35956427], [0.70802689, 0.14425212, 0.08320864, 0.82271697], [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]]) Output is array([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ], [0.46375725, 0.905113 , 0.18859044, 0.92820823], [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]], [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427], [0.7080269 , 0.14425212, 0.08320864, 0.82271695], [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]], dtype=float32) Permute Permutes the dimensions of the input according to a given pattern. Useful for connecting RNNs and convnets together. Permute(dims, inputShape = null) Python: Permute(dims, input_shape=None, name=None) Parameters: dims : Int array. Permutation pattern, does not include the batch dimension. Indexing starts at 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Permute import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3))) val input = Tensor[Float](2, 2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.8451549 0.06361471 0.7324815 0.31086245 0.21210302 0.35112163 (1,2,.,.) = 0.61466074 0.50173014 0.8759959 0.19090249 0.671227 0.73089105 (2,1,.,.) = 0.47867084 0.9341955 0.063592255 0.24063066 0.502274 0.9114748 (2,2,.,.) = 0.93335986 0.25173688 0.88615775 0.5394321 0.330763 0.89036304 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.8451549 0.06361471 0.7324815 0.61466074 0.50173014 0.8759959 (1,2,.,.) = 0.31086245 0.21210302 0.35112163 0.19090249 0.671227 0.73089105 (2,1,.,.) = 0.47867084 0.9341955 0.063592255 0.93335986 0.25173688 0.88615775 (2,2,.,.) = 0.24063066 0.502274 0.9114748 0.5394321 0.330763 0.89036304 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import Permute from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Permute((2, 1, 3), input_shape=(2, 2, 3))) input = np.random.rand(2, 2, 2, 3) output = model.forward(input) Input is: array([[[[0.14016896, 0.7275626 , 0.79087092], [0.57259566, 0.97387138, 0.70001999]], [[0.9232002 , 0.07644555, 0.24705828], [0.17257354, 0.93951155, 0.46183983]]], [[[0.79432476, 0.64299062, 0.33959594], [0.58608318, 0.338014 , 0.92602687]], [[0.32638575, 0.69032582, 0.25168083], [0.46813027, 0.95118373, 0.13145026]]]]) Output is array([[[[0.14016896, 0.7275626 , 0.7908709 ], [0.9232002 , 0.07644555, 0.24705827]], [[0.57259566, 0.97387135, 0.70002 ], [0.17257354, 0.93951154, 0.46183982]]], [[[0.79432476, 0.64299065, 0.33959594], [0.32638577, 0.6903258 , 0.25168082]], [[0.5860832 , 0.338014 , 0.9260269 ], [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32) ResizeBilinear Resize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout. ResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering = th , inputShape = null) Python: ResizeBilinear(output_height, output_width, align_corner=False, dim_ordering= th , input_shape=(2, 3, 5, 7), name=None) Parameters: outputHeight : output height outputWidth : output width alignCorners : align corner or not dimOrdering : Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential() model.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5))) val input = Tensor[Float](2, 2, 3, 5).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.6991891 0.007127314 0.73871046 0.95916307 0.9433856 0.41275907 0.37573513 0.99193203 0.06930728 0.5922364 0.024281504 0.2592453 0.3898136 0.6635241 0.85888565 (1,2,.,.) = 0.38028112 0.43709648 0.62538666 0.8468501 0.6445014 0.45252413 0.48801896 0.59471387 0.013207023 0.3567462 0.85187584 0.49279585 0.7973665 0.81287366 0.07852263 (2,1,.,.) = 0.1452374 0.6140467 0.36384684 0.066476084 0.96101314 0.54862195 0.66091377 0.86857307 0.6844842 0.7368217 0.25342992 0.71737933 0.12789607 0.21691357 0.7543404 (2,2,.,.) = 0.79176855 0.1204049 0.58971256 0.115073755 0.10459962 0.5225398 0.742363 0.7612815 0.9881919 0.13359445 0.9026869 0.13972941 0.92064524 0.9435532 0.5502235 [com.intel.analytics.bigdl.tensor.DenseTensor of... Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.6991891 0.4948494 0.9539039 0.21852028 0.5664119 0.48613077 (1,2,.,.) = 0.38028112 0.56262326 0.7794005 0.6522 0.6274959 0.34790504 (2,1,.,.) = 0.1452374 0.4472468 0.36465502 0.40102595 0.5618719 0.54899293 (2,2,.,.) = 0.79176855 0.43327665 0.111582376 0.71261334 0.70765764 0.75788474 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import ResizeBilinear from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5))) input = np.random.rand(2, 2, 3, 5, 5) output = model.forward(input) Input is: array([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189], [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155], [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]], [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775], [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264], [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]], [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452], [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ], [0.608378 , 0.10531177, 0.78000335, 0.51679768, 0.65067605]], [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255], [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493], [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]]) Output is array([[[[0.43790358, 0.61913717, 0.2543214 ], [0.6172875 , 0.52657175, 0.3151154 ]], [[0.329656 , 0.13861606, 0.20514478], [0.46164483, 0.541788 , 0.5311798 ]]], [[[0.09462238, 0.57138187, 0.8545758 ], [0.7116966 , 0.5389645 , 0.48184 ]], [[0.12074634, 0.6571231 , 0.752728 ], [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)","title":"Core Layers"},{"location":"KerasStyleAPIGuide/Layers/core/#masking","text":"Use a mask value to skip timesteps for a sequence. Scala: Masking(maskValue = 0.0, inputShape = null) Python: Masking(mask_value=0.0, input_shape=None, name=None) Parameters: maskValue : Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Masking import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Masking[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 1.4539868 1.5623108 -1.4101523 0.77073747 -0.18994702 2.2574463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.4539868 1.5623108 -1.4101523 0.77073747 -0.18994702 2.2574463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from bigdl.nn.keras.topology import Sequential from bigdl.nn.keras.layer import Masking model = Sequential() model.add(Masking(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.31542103 0.20640659 0.22282763] [0.99352167 0.90135718 0.24504717]] Output is [[0.31542102 0.2064066 0.22282763] [0.9935217 0.9013572 0.24504717]]","title":"Masking"},{"location":"KerasStyleAPIGuide/Layers/core/#sparsedense","text":"SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense: firstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward gradient to next layer in the backpropagation by default, as the gradInput of SparseDense is useless and very big in most cases. But, considering model like Wide Deep, we provide backwardStart and backwardLength to backward part of the gradient to next layer. The most common input is 2D. Scala: SparseDense(outputDim, init = glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null) Python: SparseDense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None) Parameters: outputDim : The size of the output dimension. init : String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'. activation : String representation of the activation function to use. Default is null. wRegularizer : An instance of [Regularizer], applied to the input weights matrices. Default is null. bRegularizer : An instance of [Regularizer], applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. backwardStart : Backward start index, counting from 1. backwardLength : Backward length. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4)) layer.build(Shape(-1, 2, 4)) val input = Tensor[Float](Array(2, 4)).rand() input.setValue(1, 1, 1f) input.setValue(2, 3, 3f) val sparseInput = Tensor.sparse(input) val output = layer.forward(sparseInput) Input is: input: (0, 0) : 1.0 (0, 1) : 0.2992794 (0, 2) : 0.11227019 (0, 3) : 0.722947 (1, 0) : 0.6147614 (1, 1) : 0.4288646 (1, 2) : 3.0 (1, 3) : 0.7749917 [com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4] Output is: output: 0.053516 0.33429605 0.22587383 -0.8998945 0.24308181 0.76745665 -1.614114 0.5381658 -2.2226436 -0.15573677 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SparseDense from zoo.pipeline.api.keras.models import Sequential from bigdl.util.common import JTensor model = Sequential() model.add(SparseDense(output_dim=2, input_shape=(3, 4))) input = JTensor.sparse( a_ndarray=np.array([1, 3, 2, 4]), i_ndarray = np.array([[0, 0, 1, 2], [0, 3, 2, 1]]), shape = np.array([3, 4]) ) output = model.forward(input) Input is: JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2] [0 3 2 1]], float Output is [[ 1.57136 2.29596 ] [ 0.5791738 -1.6598101 ] [ 2.331141 -0.84687066]] ``` ## **SoftShrink** Applies the soft shrinkage function element-wise to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Remark: This layer is from Torch and wrapped in Keras style. **Scala:** ```scala SoftShrink(value = 0.5, inputShape = null) Python: SoftShrink(value = 0.5, input_shape=None, name=None) Parameters: value : value The threshold value. Default is 0.5. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.36938807 0.023556225 -1.1655436 -0.34449077 0.9444338 -0.086538695 -1.0425501 1.364976 -1.2563878 -0.1842559 0.43428117 1.0756494 (1,2,.,.) = -0.19888283 1.251872 0.114836805 -0.6208773 0.0051822234 -0.8998633 0.06937465 -0.3929931 -0.1058129 0.6945743 -0.40083578 -0.6252444 (2,1,.,.) = -0.9899709 -0.77926594 -0.15497442 -0.15031165 -0.6028622 0.86623466 -2.1543107 0.41970536 -0.8215522 0.3014275 -0.32184362 0.14445356 (2,2,.,.) = 0.74701905 0.10044397 -0.40519297 0.03822808 0.30726334 0.27862388 1.731753 0.032177072 -1.3476961 -0.2294767 0.99794704 0.7398458 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 -0.56554353 0.0 0.34443378 0.0 -0.44255006 0.764976 -0.6563878 0.0 0.0 0.47564936 (1,2,.,.) = 0.0 0.6518719 0.0 -0.020877302 0.0 -0.29986328 0.0 0.0 0.0 0.09457427 0.0 -0.025244355 (2,1,.,.) = -0.3899709 -0.17926592 0.0 0.0 -0.0028621554 0.26623464 -1.5543107 0.0 -0.2215522 0.0 0.0 0.0 (2,2,.,.) = 0.14701903 0.0 0.0 0.0 0.0 0.0 1.131753 0.0 -0.74769604 0.0 0.397947 0.13984579 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SoftShrink from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SoftShrink(0.6, input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[ 0.43421006, 0.28394451, 0.15221226, 0.47268966], [ 0.22426224, 0.24855662, 0.790498 , 0.67767582], [ 0.14879562, 0.56077882, 0.61470262, 0.94875862]], [[ 0.72404932, 0.89780875, 0.08456734, 0.01303937], [ 0.25023568, 0.45392504, 0.587254 , 0.51164461], [ 0.12277567, 0.05571182, 0.17076456, 0.71660884]]], [[[ 0.06369975, 0.85395557, 0.35752425, 0.606633 ], [ 0.67640252, 0.86861737, 0.18040722, 0.55467108], [ 0.24102058, 0.37580645, 0.81601612, 0.56513788]], [[ 0.8461435 , 0.65668365, 0.17969807, 0.51602926], [ 0.86191073, 0.34245714, 0.62795207, 0.36706125], [ 0.80344028, 0.81056003, 0.80959083, 0.15366483]]]]) Output is array([[[[ 0. , 0. , 0. , 0. ], [ 0. , 0. , 0.19049799, 0.07767582], [ 0. , 0. , 0.01470262, 0.34875858]], [[ 0.12404931, 0.29780871, 0. , 0. ], [ 0. , 0. , 0. , 0. ], [ 0. , 0. , 0. , 0.1166088 ]]], [[[ 0. , 0.25395554, 0. , 0.00663298], [ 0.07640249, 0.26861733, 0. , 0. ], [ 0. , 0. , 0.21601611, 0. ]], [[ 0.24614346, 0.05668366, 0. , 0. ], [ 0.26191074, 0. , 0.02795208, 0. ], [ 0.20344025, 0.21056002, 0.20959079, 0. ]]]], dtype=float32) ``` --- ## **Reshape** Reshapes an output to a certain shape. Supports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8). **Scala:** ```scala Reshape(targetShape, inputShape = null) Python: Reshape(target_shape, input_shape=None, name=None) Parameters: targetShape : The target shape that you desire to have. Batch dimension should be excluded. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.7092276 -1.3941092 -0.6348466 0.71309644 0.3605411 0.025597548 0.4287048 -0.548675 0.4623341 -2.3912702 0.22030865 -0.058272455 (1,2,.,.) = -1.5049093 -1.8828062 0.8230564 -0.020209199 -0.3415721 1.1219939 1.1089007 -0.74697906 -1.503861 -1.616539 0.048006497 1.1613717 (2,1,.,.) = 0.21216023 1.0107462 0.8586909 -0.05644316 -0.31436008 1.6892323 -0.9961186 -0.08169463 0.3559391 0.010261055 -0.70408463 -1.2480727 (2,2,.,.) = 1.7663039 0.07122444 0.073556066 -0.7847014 0.17604464 -0.99110585 -1.0302067 -0.39024687 -0.0260166 -0.43142694 0.28443158 0.72679126 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -1.7092276 -1.3941092 -0.6348466 0.71309644 0.3605411 0.025597548 0.4287048 -0.548675 0.4623341 -2.3912702 0.22030865 -0.058272455 -1.5049093 -1.8828062 0.8230564 -0.020209199 -0.3415721 1.1219939 1.1089007 -0.74697906 -1.503861 -1.616539 0.048006497 1.1613717 (2,.,.) = 0.21216023 1.0107462 0.8586909 -0.05644316 -0.31436008 1.6892323 -0.9961186 -0.08169463 0.3559391 0.010261055 -0.70408463 -1.2480727 1.7663039 0.07122444 0.073556066 -0.7847014 0.17604464 -0.99110585 -1.0302067 -0.39024687 -0.0260166 -0.43142694 0.28443158 0.72679126 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Reshape from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.39260304 0.10383185 0.87490319 0.89167328] [0.61649117 0.43285247 0.86851582 0.97743004] [0.90018969 0.04303951 0.74263493 0.14208656]] [[0.66193405 0.93432157 0.76160537 0.70437459] [0.99953431 0.23016734 0.42293405 0.66078049] [0.03357645 0.9695145 0.30111138 0.67109948]]] [[[0.39640201 0.92930203 0.86027666 0.13958544] [0.34584767 0.14743425 0.93804016 0.38053062] [0.55068792 0.77375329 0.84161166 0.48131356]] [[0.90116368 0.53253689 0.03332962 0.58278686] [0.34935685 0.32599554 0.97641892 0.57696434] [0.53974677 0.90682861 0.20027319 0.05962118]]]] Output is [[[0.39260304 0.10383185 0.8749032 0.89167327 0.6164912 0.43285248 0.86851585 0.97743005] [0.9001897 0.04303951 0.74263495 0.14208655 0.661934 0.9343216 0.7616054 0.7043746 ] [0.9995343 0.23016734 0.42293406 0.6607805 0.03357645 0.9695145 0.30111137 0.6710995 ]] [[0.396402 0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063] [0.5506879 0.7737533 0.8416117 0.48131356 0.9011637 0.53253686 0.03332962 0.58278686] [0.34935686 0.32599553 0.9764189 0.5769643 0.53974676 0.9068286 0.20027319 0.05962119]]]","title":"SparseDense"},{"location":"KerasStyleAPIGuide/Layers/core/#merge","text":"Used to merge a list of inputs into a single output, following some merge mode. Merge must have at least two input layers. Scala: Merge(layers = null, mode = sum , concatAxis = -1, inputShape = null) Python: Merge(layers=None, mode= sum , concat_axis=-1, input_shape=None, name=None) Parameters: layers : A list of layer instances. Must be more than one layer. mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'. concatAxis : Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.{Shape, T} import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val l1 = InputLayer[Float](inputShape = Shape(2, 3)) val l2 = InputLayer[Float](inputShape = Shape(2, 3)) val layer = Merge[Float](layers = List(l1, l2), mode = sum ) model.add(layer) val input1 = Tensor[Float](2, 2, 3).rand(0, 1) val input2 = Tensor[Float](2, 2, 3).rand(0, 1) val input = T(1 - input1, 2 - input2) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.utils.Table = { 2: (1,.,.) = 0.87815475 0.15025006 0.34412447 0.07909282 0.008027249 0.111715704 (2,.,.) = 0.52245367 0.2547527 0.35857987 0.7718501 0.26783863 0.8642062 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] 1: (1,.,.) = 0.5377018 0.28364193 0.3424284 0.0075349305 0.9018168 0.9435114 (2,.,.) = 0.09112563 0.88585275 0.3100201 0.7910178 0.57497376 0.39764535 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] } Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.4158566 0.433892 0.6865529 0.08662775 0.90984404 1.0552272 (2,.,.) = 0.6135793 1.1406054 0.66859996 1.5628679 0.8428124 1.2618515 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Merge, InputLayer from zoo.pipeline.api.keras.models import Sequential model = Sequential() l1 = InputLayer(input_shape=(3, 4)) l2 = InputLayer(input_shape=(3, 4)) model.add(Merge(layers=[l1, l2], mode='sum')) input = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])] output = model.forward(input) Input is: [[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492], [0.63922826, 0.45101604, 0.4555552 , 0.70105653], [0.75790798, 0.78551523, 0.00686686, 0.61290369]], [[0.00430865, 0.3303661 , 0.59915782, 0.90362298], [0.26230717, 0.99383052, 0.50630521, 0.99119486], [0.56138318, 0.68165639, 0.10644523, 0.51860127]]], [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321], [0.49354248, 0.97936826, 0.2266097 , 0.88083622], [0.11011776, 0.65762034, 0.17446099, 0.76658969]], [[0.58266689, 0.86322199, 0.87122999, 0.19031255], [0.42275118, 0.76379413, 0.21355413, 0.81132937], [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]] Output is [[[1.1313012 0.90907556 1.6311111 1.4896882 ] [1.1327708 1.4303843 0.6821649 1.5818927 ] [0.8680257 1.4431355 0.18132785 1.3794935 ]] [[0.5869755 1.1935881 1.4703878 1.0939355 ] [0.68505836 1.7576246 0.71985936 1.8025242 ] [1.5343305 1.3676738 0.50516313 1.1503248 ]]]","title":"Merge"},{"location":"KerasStyleAPIGuide/Layers/core/#maxoutdense","text":"A dense maxout layer that takes the element-wise maximum of linear layers. This allows the layer to learn a convex, piecewise linear activation function over the inputs. The input of this layer should be 2D. Scala: MaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: MaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None) Parameters: outputDim : The size of output dimension. nbFeature : Number of Dense layers to use internally. Integer. Default is 4. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MaxoutDense(2, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -1.3550005 -1.1668127 -1.2882779 0.83600295 -1.94683 1.323666 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.71675766 1.2987505 0.9871184 0.6634239 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MaxoutDense from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MaxoutDense(2, input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.15996114 0.8391686 0.81922903] [0.52929427 0.35061754 0.88167693]] Output is [[0.4479192 0.4842512] [0.16833156 0.521764 ]]","title":"MaxoutDense"},{"location":"KerasStyleAPIGuide/Layers/core/#squeeze","text":"Delete the singleton dimension(s). The batch dimension needs to be unchanged. For example, if input has size (2, 1, 3, 4, 1): Squeeze(1) will give output size (2, 3, 4, 1), Squeeze() will give output size (2, 3, 4) Scala: Squeeze(dims = null, inputShape = null) Python: Squeeze(dim=None, input_shape=None, name=None) Parameters: dims : The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32))) val input = Tensor[Float](1, 1, 1, 32).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.5521966 -1.2199087 0.365958 1.3845297 0.115254946 -0.20352958 2.4912808 0.987046 -0.2115477 3.0530396 -1.0043625 1.4688021 -1.2412603 -0.25383064 0.49164283 -0.40329486 0.26323202 0.7979045 0.025444122 0.47221214 1.3995043 0.48498031 -0.86961967 -0.058370713 -0.85965866 -1.2727696 0.45570874 0.73393697 0.2567143 1.4261572 -0.37773672 -0.7339463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.5521966 -1.2199087 0.365958 1.3845297 0.115254946 -0.20352958 2.4912808 0.987046 -0.2115477 3.0530396 -1.0043625 1.4688021 -1.2412603 -0.25383064 0.49164283 -0.40329486 0.26323202 0.7979045 0.025444122 0.47221214 1.3995043 0.48498031 -0.86961967 -0.058370713 -0.85965866 -1.2727696 0.45570874 0.73393697 0.2567143 1.4261572 -0.37773672 -0.7339463 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Squeeze from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Squeeze(1, input_shape=(1, 1, 32))) input = np.random.random([1, 1, 1, 32]) output = model.forward(input) Input is: [[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281, 0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763, 0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269, 0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821, 0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 , 0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729, 0.89774196, 0.77838838]]]] Output is [[[0.20585343, 0.470117 , 0.14553176, 0.939156 , 0.5723428 , 0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763, 0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 , 0.48919672, 0.284064 , 0.20962799, 0.8807176 , 0.45501822, 0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 , 0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 , 0.897742 , 0.7783884 ]]]","title":"Squeeze"},{"location":"KerasStyleAPIGuide/Layers/core/#binarythreshold","text":"Threshold the input. If an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1. Scala: BinaryThreshold(value = 1e-6, inputShape = null) Python: BinaryThreshold(value=1e-6, input_shape=None, name=None) Parameters: value : The threshold value to compare with. Default is 1e-6. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.1907398 -0.18995096 -2.0344417 -1.3789974 -1.8801064 -0.74757665 -0.4339697 0.0058485097 0.7012256 -0.6363152 2.0156987 -0.5512639 (1,2,.,.) = -0.5251603 0.082127444 0.29550993 1.6357868 -1.3828015 -0.11842779 0.3316966 -0.14360528 0.21216457 -0.117370956 -0.12934707 -0.35854268 (2,1,.,.) = -0.9071151 -2.8566089 -0.4796377 -0.915065 -0.8439908 -0.25404388 -0.39926198 -0.15191565 -1.0496653 -0.403675 -1.3591816 0.5311797 (2,2,.,.) = 0.53509855 -0.08892822 1.2196561 -0.62759316 -0.47476718 -0.43337926 -0.10406987 1.4035174 -1.7120812 1.1328355 0.9219375 1.3813454 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 0.0 (1,2,.,.) = 0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 (2,1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 (2,2,.,.) = 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import BinaryThreshold from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(BinaryThreshold(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: array([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767], [0.72650405, 0.53096719, 0.66346109, 0.0589329 ], [0.12994731, 0.92181174, 0.43129874, 0.97306968]], [[0.3031087 , 0.20339982, 0.69034712, 0.40191 ], [0.57517034, 0.30159448, 0.4801747 , 0.75175084], [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]], [[[0.46102959, 0.33029002, 0.69340103, 0.32885719], [0.84405147, 0.03421879, 0.68242578, 0.03560338], [0.12244515, 0.3610654 , 0.01312785, 0.84485178]], [[0.73472287, 0.75707757, 0.77070527, 0.40863145], [0.01137898, 0.82896826, 0.1498069 , 0.22309423], [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]]) Output is array([[[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]], [[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]]], dtype=float32)","title":"BinaryThreshold"},{"location":"KerasStyleAPIGuide/Layers/core/#sqrt","text":"Applies an element-wise square root operation to the input. Scala: Sqrt(inputShape = null) Python: Sqrt(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Sqrt[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 0.6950394 0.5234307 1.7375475 0.25833175 0.02685826 -0.6046901 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.8336902 0.7234851 1.3181607 0.50826347 0.16388491 NaN [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Sqrt from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Sqrt(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.2484558 , 0.65280218, 0.35286984], [0.19616094, 0.30966802, 0.82148169]] Output is [[0.4984534 , 0.80796176, 0.5940285 ], [0.4429006 , 0.55647826, 0.9063563 ]]","title":"Sqrt"},{"location":"KerasStyleAPIGuide/Layers/core/#mul","text":"Multiply a single scalar factor to the incoming data Scala: Mul(inputShape = null) Python: Mul(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Mul import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Mul[Float](inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.2316265 -2.008802 -1.3908259 -0.61135375 -0.48992255 0.1786112 0.18872596 0.49621895 -0.6931602 -0.919745 -0.09019699 -0.41218707 (2,.,.) = -0.3135355 -0.4385771 -0.3317269 1.0412029 -0.8859662 0.17758773 -0.73779273 -0.4445366 0.3921595 1.6923207 0.014470488 0.4044164 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.59036994 -0.9629025 -0.6666808 -0.29304734 -0.2348403 0.0856158 0.09046422 0.23785843 -0.33226058 -0.44087213 -0.043235175 -0.19757845 (2,.,.) = -0.15029064 -0.21022828 -0.15901053 0.49909195 -0.42468053 0.0851252 -0.3536548 -0.21308492 0.18797839 0.81119984 0.006936308 0.19385365 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Mul from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Mul(input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.22607292, 0.59806062, 0.19428923, 0.22928606], [ 0.13804536, 0.1615547 , 0.52824658, 0.52794904], [ 0.4049169 , 0.94109084, 0.58158453, 0.78368633]], [[ 0.86233305, 0.47995805, 0.80430949, 0.9931171 ], [ 0.35179631, 0.33615276, 0.87756877, 0.73560288], [ 0.29775703, 0.11404466, 0.77695536, 0.97580018]]]) Output is array([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998], [-0.13730718, -0.1606908 , -0.52542186, -0.52512592], [-0.40275168, -0.93605846, -0.57847458, -0.77949566]], [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ], [-0.34991512, -0.33435524, -0.87287611, -0.73166931], [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32)","title":"Mul"},{"location":"KerasStyleAPIGuide/Layers/core/#mulconstant","text":"Multiply the input by a (non-learnable) scalar constant. Scala: MulConstant(constant, inputShape = null) Python: MulConstant(constant, input_shape=None, name=None) Parameters: constant : The scalar constant to be multiplied. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MulConstant[Float](2.2, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.16873977 1.0812985 1.0942211 -0.67091423 1.0086882 0.5915831 0.26184535 -1.361431 1.5616825 -0.037591368 1.2794676 1.0692137 (2,.,.) = 0.29868057 -0.23266982 -0.7679556 -2.209848 -0.13954644 -0.1368473 -0.54510623 1.8397199 -0.58691734 -0.56410027 -1.5567777 0.050648995 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.3712275 2.3788567 2.4072864 -1.4760114 2.219114 1.3014828 0.57605976 -2.9951482 3.4357016 -0.08270101 2.8148286 2.3522704 (2,.,.) = 0.6570973 -0.5118736 -1.6895024 -4.8616657 -0.3070022 -0.30106407 -1.1992338 4.047384 -1.2912182 -1.2410206 -3.424911 0.11142779 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MulConstant from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MulConstant(2.2, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: [[[0.39874191, 0.66634984, 0.23907766, 0.31587494], [0.78842014, 0.93057835, 0.80739529, 0.71541279], [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]], [[0.60142458, 0.41221671, 0.00890549, 0.32069845], [0.51122554, 0.76280426, 0.87579418, 0.17182832], [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]] Output is [[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ], [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ], [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]], [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ], [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234], [1.19093 , 0.43591645, 2.0356452 , 1.2356553 ]]]","title":"MulConstant"},{"location":"KerasStyleAPIGuide/Layers/core/#scale","text":"Scale is the combination of CMul and CAdd. Computes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input. Similarly, perform an expanded bias and perform an element-wise add. Scala: Scale(size, inputShape = null) Python: Scale(size, input_shape=None, name=None) Parameters: size : Size of the weight and bias. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Scale import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() var array = Array(1, 2) model.add(Scale[Float](array, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.006399727 -0.06412822 -0.2334789 0.31029955 1.6557469 1.9614618 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.09936619 0.57585865 0.20324506 0.38537437 -0.8598822 -1.0186496 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Scale from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Scale((2, 1), input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.7242994 , 0.77888884, 0.71470432], [0.03058471, 0.00602764, 0.57513629]] Output is [[1.0946966 , 1.1255064 , 1.0892813 ], [0.58151895, 0.5909191 , 0.37307182]]","title":"Scale"},{"location":"KerasStyleAPIGuide/Layers/core/#log","text":"Applies a log transformation to the input. Scala: Log(inputShape = null) Python: Log(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Log import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Log[Float](inputShape = Shape(2, 4, 4))) val input = Tensor[Float](1, 2, 4, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.38405678 -0.5502389 -0.383079 -0.988537 -0.6294056 -0.7838047 0.8747865 -1.0659786 -2.2445498 -0.5488076 -0.42898977 0.6916364 1.6542299 -0.9966279 -0.38244298 1.6954672 (1,2,.,.) = 0.43478605 -0.6678534 1.9530942 -0.5209587 0.12899925 0.20572199 2.0359943 0.55223215 0.65247816 0.8792108 -0.38860792 0.48663738 -1.0084358 0.31141177 0.69208467 0.48385203 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.95696485 NaN NaN NaN NaN NaN -0.13377543 NaN NaN NaN NaN -0.36869493 0.5033356 NaN NaN 0.5279584 (1,2,.,.) = -0.83290124 NaN 0.6694149 NaN -2.0479486 -1.5812296 0.7109843 -0.5937868 -0.4269776 -0.12873057 NaN -0.720236 NaN -1.1666392 -0.36804697 -0.72597617 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Log from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Log(input_shape=(2, 4, 4))) input = np.random.random([1, 2, 4, 4]) output = model.forward(input) Input is: [[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453], [0.46529477, 0.81511804, 0.24435558, 0.45003562], [0.15170845, 0.35157662, 0.0925214 , 0.63852947], [0.27817508, 0.42572846, 0.44363004, 0.03536394]], [[0.65027784, 0.00429838, 0.07434429, 0.18653305], [0.19659183, 0.66647529, 0.77821197, 0.65894478], [0.28212032, 0.52307663, 0.09589939, 0.71547588], [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]] Output is [[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032], [-0.76508415, -0.20442237, -1.4091308 , -0.79842854], [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742], [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]], [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ], [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554], [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743], [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]]","title":"Log"},{"location":"KerasStyleAPIGuide/Layers/core/#identity","text":"Identity just return the input to output. It's useful in same parallel container to get an origin input. Scala: Identity(inputShape = null) Python: Identity(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Identity import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Identity[Float](inputShape = Shape(4, 4))) val input = Tensor[Float](3, 4, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.9601166 -0.86010313 0.0023731247 -0.81219757 1.1469674 -1.5375912 -1.5348053 -0.34829113 -1.236773 -0.7183283 -0.89256984 0.8605067 0.7937664 0.52992857 -1.6157389 0.36134166 (2,.,.) = -0.44434744 -0.23848957 -0.01632014 -0.58109635 -0.19856784 -2.3421717 -0.5868049 -0.76775354 0.80254126 1.78778 -1.1835604 1.4489703 0.8731402 0.8906672 0.2800079 -0.6715317 (3,.,.) = 1.4093032 2.358169 -1.4620789 1.1904576 -0.18263042 -0.31869793 2.01061 1.2159953 -0.5801479 1.2949371 -0.7510707 -1.0707517 0.30815956 -1.161963 -0.26964024 -0.4759499 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.9601166 -0.86010313 0.0023731247 -0.81219757 1.1469674 -1.5375912 -1.5348053 -0.34829113 -1.236773 -0.7183283 -0.89256984 0.8605067 0.7937664 0.52992857 -1.6157389 0.36134166 (2,.,.) = -0.44434744 -0.23848957 -0.01632014 -0.58109635 -0.19856784 -2.3421717 -0.5868049 -0.76775354 0.80254126 1.78778 -1.1835604 1.4489703 0.8731402 0.8906672 0.2800079 -0.6715317 (3,.,.) = 1.4093032 2.358169 -1.4620789 1.1904576 -0.18263042 -0.31869793 2.01061 1.2159953 -0.5801479 1.2949371 -0.7510707 -1.0707517 0.30815956 -1.161963 -0.26964024 -0.4759499 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Identity from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Identity(input_shape=(4, 4))) input = np.random.random([3, 4, 4]) output = model.forward(input) Input is: [[[0.36751123, 0.92287101, 0.73894405, 0.33699379], [0.69405782, 0.9653215 , 0.2617223 , 0.68205229], [0.71455325, 0.99419333, 0.90886495, 0.10232991], [0.1644055 , 0.30013138, 0.98921154, 0.26803146]], [[0.35898357, 0.72067882, 0.13236563, 0.71935521], [0.30865626, 0.71098844, 0.86718946, 0.12531168], [0.84916882, 0.84221518, 0.52186664, 0.87239729], [0.50637899, 0.10890469, 0.86832705, 0.93581179]], [[0.19640105, 0.09341008, 0.12043328, 0.09261859], [0.66019486, 0.07251262, 0.80929761, 0.39094486], [0.63027391, 0.39537796, 0.55578905, 0.53933265], [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]] Output is [[[0.36751124, 0.922871 , 0.73894405, 0.33699378], [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ], [0.71455324, 0.9941933 , 0.908865 , 0.10232991], [0.1644055 , 0.30013138, 0.98921156, 0.26803148]], [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ], [0.30865628, 0.71098846, 0.86718947, 0.12531169], [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ], [0.506379 , 0.10890469, 0.868327 , 0.9358118 ]], [[0.19640104, 0.09341008, 0.12043328, 0.09261858], [0.6601949 , 0.07251262, 0.8092976 , 0.39094487], [0.63027394, 0.39537796, 0.55578905, 0.5393326 ], [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]]","title":"Identity"},{"location":"KerasStyleAPIGuide/Layers/core/#select","text":"Select an index of the input in the given dim and return the subset part. The batch dimension needs to be unchanged. For example, if input is: [[1, 2, 3], [4, 5, 6]] Select(1, 1) will give output [2 5] Select(1, -1) will give output [3 6] Scala: Select(dim, index, inputShape = null) Python: Select(dim, index, input_shape=None, name=None) Parameters: dim : The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input. index : The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Select import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3))) val input = Tensor[Float](1, 3, 1, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.67646945 -0.5485965 -0.11103154 (1,2,.,.) = -0.13488655 0.43843046 -0.04482145 (1,3,.,.) = -0.18094881 0.19431554 -1.7624844 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.18094881 0.19431554 -1.7624844 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3] Python example: from zoo.pipeline.api.keras.layers import Select from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Select(1, 2, input_shape=(3, 1, 3))) input = np.random.random([1, 3, 1, 3]) output = model.forward(input) Input is: array([[[[0.53306099, 0.95147881, 0.15222129]], [[0.89604861, 0.90160974, 0.5230576 ]], [[0.70779386, 0.14438568, 0.37601195]]]]) Output is: array([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32)","title":"Select"},{"location":"KerasStyleAPIGuide/Layers/core/#dense","text":"A densely-connected NN layer. The most common input is 2D. Scala: Dense(outputDim, init = glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Dense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None) Parameters: outputDim : The size of the output dimension. init : Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method. activation : Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method. wRegularizer : An instance of Regularizer , applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Dense import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Dense[Float](5, activation = relu , inputShape = Shape(4))) val input = Tensor[Float](2, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 1.4289935 -1.7659454 -0.08306135 -1.0153456 1.0191492 0.37392816 1.3076705 -0.19495767 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.5421522 0.49008092 0.0 0.0 0.0 0.07940009 0.0 0.12953377 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Dense from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Dense(5, activation= relu , input_shape=(4, ))) input = np.random.random([2, 4]) output = model.forward(input) Input is: array([[0.64593485, 0.67393322, 0.72505368, 0.04654095], [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]]) Output is array([[0. , 0. , 1.2698183 , 0. , 0.10656227], [0. , 0. , 0.6236721 , 0.00299606, 0.29664695]], dtype=float32)","title":"Dense"},{"location":"KerasStyleAPIGuide/Layers/core/#negative","text":"Computes the negative value of each element of the input. Scala: Negative(inputShape = null) Python: Negative(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Negative import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Negative[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.031705 -0.5723963 1.998631 -0.32908052 2.4069138 -2.4111257 (2,.,.) = 0.5355049 -1.4404331 -0.38116863 -0.45641592 -1.1485358 0.94766915 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -1.031705 0.5723963 -1.998631 0.32908052 -2.4069138 2.4111257 (2,.,.) = -0.5355049 1.4404331 0.38116863 0.45641592 1.1485358 -0.94766915 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import Negative from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Negative(input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.39261261, 0.03164615, 0.32179116], [0.11969367, 0.61610712, 0.42573733]], [[0.36794656, 0.90912174, 0.540356 ], [0.42667627, 0.04154093, 0.84692964]]]) Output is array([[[-0.3926126 , -0.03164615, -0.32179114], [-0.11969367, -0.6161071 , -0.42573732]], [[-0.36794657, -0.90912175, -0.540356 ], [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32)","title":"Negative"},{"location":"KerasStyleAPIGuide/Layers/core/#cadd","text":"This layer has a bias with given size. The bias will be added element-wise to the input. If the element number of the bias matches the input, a simple element-wise addition will be done. Or the bias will be expanded to the same size of the input. The expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised). Scala: CAdd(size, bRegularizer = null, inputShape = null) Python: CAdd(size, b_regularizer=None, input_shape=None, name=None) Parameters: size : the size of the bias bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.2183351 0.32434112 0.89350265 0.3348259 0.78677046 0.24054797 (2,.,.) = 0.9945844 0.72363794 0.7737936 0.05522544 0.3517818 0.7417069 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.1358028 0.6956667 1.0837181 0.6767027 0.7955346 0.5063505 (2,.,.) = 0.9120521 1.0949634 0.96400905 0.3971022 0.36054593 1.0075095 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import CAdd from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(CAdd([2, 1], input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.4122004 , 0.73289359, 0.11500016], [0.26974491, 0.32166632, 0.91408442]], [[0.66824327, 0.80271314, 0.75981145], [0.39271431, 0.07312566, 0.4966805 ]]]) Output is array([[[ 0.06560206, 0.38629526, -0.23159817], [ 0.44287407, 0.4947955 , 1.0872136 ]], [[ 0.32164496, 0.45611483, 0.41321313], [ 0.56584346, 0.24625483, 0.6698097 ]]], dtype=float32)","title":"CAdd"},{"location":"KerasStyleAPIGuide/Layers/core/#repeatvector","text":"Repeats the input n times. The input of this layer should be 2D, i.e. (num_samples, features). The output of thi layer should be 3D, i.e. (num_samples, n, features). Scala: RepeatVector(n, inputShape = null) Python: RepeatVector(n, input_shape=None, name=None) Parameters: n : Repetition factor. Integer. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(RepeatVector[Float](4, inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.31839952 -0.3495366 0.542486 -0.54981124 -0.8428188 0.8225184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 -0.31839952 -0.3495366 0.542486 (2,.,.) = -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 -0.54981124 -0.8428188 0.8225184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import RepeatVector from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(RepeatVector(4, input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: array([[ 0.90715922, 0.54594769, 0.53952404], [ 0.08989831, 0.07265549, 0.45830114]]) Output is array([[[ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402], [ 0.90715921, 0.54594767, 0.53952402]], [[ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116], [ 0.08989831, 0.07265549, 0.45830116]]], dtype=float32)","title":"RepeatVector"},{"location":"KerasStyleAPIGuide/Layers/core/#gaussiansampler","text":"Takes {mean, log_variance} as input and samples from the Gaussian distribution. Scala: GaussianSampler(inputShape = null) Python: GaussianSampler(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler import com.intel.analytics.bigdl.utils.{Shape, MultiShape, T} import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val shape1 = Shape(2, 3) val shape2 = Shape(2, 3) model.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2)))) val input1 = Tensor[Float](2, 2, 3).rand(0, 1) val input2 = Tensor[Float](2, 2, 3).rand(0, 1) val input = T(1 - input1, 2 - input2) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.utils.Table = { 2: (1,.,.) = 0.9996127 0.8964211 0.7424038 0.40628982 0.37035564 0.20108517 (2,.,.) = 0.6974727 0.60202897 0.1535999 0.012422224 0.5993025 0.96206 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] 1: (1,.,.) = 0.21060324 0.576583 0.21633287 0.1484059 0.2730577 0.25317845 (2,.,.) = 0.58513683 0.58095694 0.18811373 0.7029449 0.41235915 0.44636542 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] } Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.5258198 1.9536011 -1.8591263 -1.0618867 -0.751225 0.35412917 (2,.,.) = 1.3334517 -0.60312974 0.7324476 0.09502721 0.8094909 0.44807082 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GaussianSampler model = Sequential() model.add(GaussianSampler(input_shape=[(3,),(3,)])) input1 = np.random.random([2, 3]) input2 = np.random.random([2, 3]) input = [input1, input2] output = model.forward(input) Input is: [[[0.79941342, 0.87462822, 0.9516901 ], [0.20111287, 0.54634077, 0.83614511]], [[0.31886989, 0.22829382, 0.84355419], [0.51186641, 0.28043938, 0.29440057]]] Output is [[ 0.71405387 2.2944303 -0.41778684] [ 0.84234 2.3337283 -0.18952972]]","title":"GaussianSampler"},{"location":"KerasStyleAPIGuide/Layers/core/#exp","text":"Applies element-wise exp to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: Exp(inputShape = null) Python: Exp(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Exp import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Exp[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.5841372 -0.13795324 -2.144475 0.09272669 1.055668 -1.2310301 1.2145554 -0.6073714 0.9296467 0.2923885 1.3364213 0.1652137 (1,2,.,.) = 0.2099718 -0.3856573 -0.92586 -0.5317779 0.6618383 -0.9677452 -1.5014665 -0.35464883 2.045924 -0.317644 -1.812726 0.95438373 (2,1,.,.) = -0.4536791 -0.34785584 1.6424289 -0.07981159 -0.8022624 -0.4211059 0.3461831 1.9598864 -0.84695745 -0.6115283 0.7729755 2.3077402 (2,2,.,.) = -0.08438411 -0.908458 0.6688936 -0.7292123 -0.26337254 0.55425745 -0.14925817 -0.010179609 -0.62562865 -1.0517743 -0.23839666 -1.144982 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.20512469 0.8711394 0.11712951 1.0971619 2.8738942 0.29199165 3.3687959 0.544781 2.533614 1.3396233 3.8054006 1.1796452 (1,2,.,.) = 1.2336433 0.6800035 0.39619055 0.5875594 1.9383523 0.37993878 0.22280318 0.7014197 7.7363033 0.7278619 0.16320862 2.5970695 (2,1,.,.) = 0.63528657 0.70620066 5.167706 0.92329025 0.44831353 0.6563206 1.4136615 7.0985208 0.42871734 0.5425211 2.1662023 10.051684 (2,2,.,.) = 0.9190782 0.4031454 1.9520763 0.48228875 0.76845556 1.740648 0.8613467 0.98987204 0.53492504 0.34931743 0.7878901 0.31822965 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Exp model = Sequential() model.add(Exp(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.93104587 0.94000338 0.84870765 0.98645553] [0.83708846 0.33375541 0.50119834 0.24879265] [0.51966475 0.84514791 0.15496452 0.61538968]] [[0.57250337 0.42520832 0.94850757 0.54317573] [0.64228691 0.9904079 0.01008592 0.51365217] [0.78640595 0.7717037 0.51277595 0.24245034]]] [[[0.82184752 0.92537331 0.20632728 0.47539445] [0.44604637 0.1507692 0.5437313 0.2074501 ] [0.93661363 0.93962609 0.29230559 0.74850958]] [[0.11659768 0.76177132 0.33194573 0.20695088] [0.49636212 0.85987328 0.49767861 0.96774006] [0.67669121 0.15542122 0.69981032 0.3349874 ]]]] Output is [[[[2.5371614 2.5599902 2.3366253 2.6817122] [2.3096325 1.3962016 1.6506982 1.2824761] [1.6814638 2.3283222 1.1676165 1.8503776]] [[1.7726992 1.5299091 2.5818534 1.721465 ] [1.9008229 2.6923325 1.010137 1.6713842] [2.1954916 2.163449 1.6699204 1.2743679]]] [[[2.2746985 2.52281 1.2291554 1.6086487] [1.5621239 1.1627283 1.7224218 1.2305363] [2.551327 2.5590243 1.3395122 2.1138473]] [[1.1236672 2.1420672 1.3936772 1.2299222] [1.6427343 2.3628614 1.6448984 2.6319895] [1.9673574 1.16815 2.0133708 1.3979228]]]]","title":"Exp"},{"location":"KerasStyleAPIGuide/Layers/core/#square","text":"Applies an element-wise square operation to the input. When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: Square(inputShape = null) Python: Square(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a MultiShape object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Square import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Square[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.108013034 1.8879265 1.2232096 -1.5076439 1.4895755 -0.37966672 -0.34892964 0.15224025 -0.9296686 -1.1523775 0.14153497 -0.26954007 (1,2,.,.) = -1.0875931 2.190617 -0.6903083 1.0039362 -0.1275677 -1.1096588 0.37359753 -0.17367937 0.23349741 0.14639114 -0.2330162 0.5343827 (2,1,.,.) = 0.3222191 0.21463287 -1.0157064 -0.22627507 1.1714277 0.43371263 1.069315 0.5122436 0.1958086 -1.4601041 2.5394423 -0.470833 (2,2,.,.) = -0.38708544 -0.951611 -0.37234613 0.26813275 1.9477026 0.32779223 -1.2308712 -2.2376378 0.19652915 0.3304719 -1.7674786 -0.86961496 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.011666816 3.5642662 1.4962418 2.2729902 2.218835 0.14414681 0.1217519 0.023177093 0.86428374 1.3279738 0.020032147 0.07265185 (1,2,.,.) = 1.1828587 4.7988033 0.47652552 1.0078878 0.016273517 1.2313428 0.13957511 0.030164523 0.05452104 0.021430366 0.054296546 0.28556487 (2,1,.,.) = 0.10382515 0.046067268 1.0316595 0.05120041 1.3722429 0.18810664 1.1434345 0.26239353 0.038341008 2.131904 6.448767 0.22168371 (2,2,.,.) = 0.14983514 0.9055635 0.13864164 0.07189517 3.7935455 0.10744774 1.5150439 5.007023 0.038623706 0.109211676 3.1239805 0.7562302 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import Square model = Sequential() model.add(Square(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.8708819 0.2698243 0.55854849 0.71699472] [0.66647234 0.72310216 0.8082119 0.66566951] [0.6714764 0.61394108 0.35063125 0.60473593]] [[0.37993365 0.64222557 0.96762005 0.18931697] [0.00529722 0.99133455 0.09786619 0.28988077] [0.60052911 0.83712995 0.59847519 0.54361243]]] [[[0.32832672 0.83316023 0.41272485 0.01963383] [0.89593955 0.73433713 0.67529323 0.69711912] [0.81251711 0.56755577 0.31958151 0.09795917]] [[0.46465895 0.22818875 0.31505317 0.41912166] [0.87865447 0.3799063 0.091204 0.68144165] [0.88274284 0.70479132 0.32074672 0.71771481]]]] Output is [[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01] [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01] [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]] [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02] [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02] [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]] [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04] [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01] [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]] [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01] [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01] [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]]","title":"Square"},{"location":"KerasStyleAPIGuide/Layers/core/#power","text":"Applies an element-wise power operation with scale and shift to the input. f(x) = (shift + scale * x)^power^ Power(power, scale = 1, shift = 0, inputShape = null) Python: Power(power, scale=1, shift=0, input_shape=None, name=None) Parameters: power : The exponent scale : The scale parameter. Default is 1. shift : The shift parameter. Default is 0. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Power import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Power[Float](2, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.24691099 0.7588585 0.5785183 0.10356348 0.2252714 0.3129436 (2,.,.) = 0.6277785 0.75136995 0.044648796 0.46396527 0.9793776 0.92727077 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.060965035 0.5758662 0.3346834 0.010725395 0.050747205 0.0979337 (2,.,.) = 0.39410582 0.5645568 0.001993515 0.21526377 0.95918053 0.8598311 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import Power from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Power(2, input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.5300817 , 0.18128031, 0.19534253], [0.28380639, 0.78365165, 0.6893 ]], [[0.05574091, 0.400077 , 0.77051193], [0.033559 , 0.61051396, 0.13970227]]]) Output is array([[[0.2809866 , 0.03286255, 0.03815871], [0.08054607, 0.61410993, 0.4751345 ]], [[0.00310705, 0.16006161, 0.5936886 ], [0.00112621, 0.37272733, 0.01951673]]], dtype=float32)","title":"Power"},{"location":"KerasStyleAPIGuide/Layers/core/#addconstant","text":"Add a (non-learnable) scalar constant to the input. AddConstant(constant, inputShape = null) Python: AddConstant(constant, input_shape=None, name=None) Parameters: constant : The scalar constant to be added. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AddConstant[Float](1, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.5658301 0.3508225 0.4012322 0.1941942 0.18934165 0.6909284 (2,.,.) = 0.5985211 0.5485885 0.778548 0.16745302 0.10363362 0.92185616 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.5658301 1.3508224 1.4012322 1.1941942 1.1893417 1.6909285 (2,.,.) = 1.5985211 1.5485885 1.778548 1.167453 1.1036336 1.9218562 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Python example: from zoo.pipeline.api.keras.layers import AddConstant from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(AddConstant(1, input_shape=(2, 3))) input = np.random.rand(2, 2, 3) output = model.forward(input) Input is: array([[[0.71730919, 0.07752598, 0.10448237], [0.52319608, 0.38668494, 0.19588814]], [[0.15496092, 0.48405899, 0.41441248], [0.13792111, 0.7523953 , 0.55991187]]]) Output is array([[[1.7173092, 1.077526 , 1.1044824], [1.5231961, 1.3866849, 1.1958882]], [[1.1549609, 1.484059 , 1.4144125], [1.1379211, 1.7523953, 1.5599118]]], dtype=float32)","title":"AddConstant"},{"location":"KerasStyleAPIGuide/Layers/core/#narrow","text":"Narrow the input with the number of dimensions not being reduced. The batch dimension needs to be unchanged. For example, if input is: [[1 2 3], [4 5 6]] Narrow(1, 1, 2) will give output [[2 3], [5 6]] Narrow(1, 2, -1) will give output [3, 6] Narrow(dim, offset, length = 1, inputShape = null) Python: Narrow(dim, offset, length=1, input_shape=None, name=None) Parameters: dim : The dimension to narrow. 0-based index. Cannot narrow the batch dimension. -1 means the last dimension of the input. offset : Non-negative integer. The start index on the given dimension. 0-based index. length : The length to narrow. Default is 1. Can use a negative length such as -1 in the case where input size is unknown. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.13770224 0.63719153 0.7776689 0.46612367 0.9026256 0.11982094 0.8282868 0.05095969 0.889799 0.6386537 0.35438475 0.298043 (1,2,.,.) = 0.5029727 0.20103335 0.20150806 0.06437344 0.2255908 0.5388977 0.59737855 0.5210477 0.4055072 0.11848069 0.7118382 0.9796308 (2,1,.,.) = 0.63957494 0.1921936 0.7749439 0.19744827 0.91683346 0.16140814 0.9753973 0.8161283 0.8481694 0.8802563 0.1233245 0.5732614 (2,2,.,.) = 0.275001 0.35905758 0.15939762 0.09233412 0.16610192 0.032060683 0.37298614 0.48936844 0.031097537 0.82767457 0.10246291 0.9951448 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.5029727 0.20103335 0.20150806 0.06437344 0.2255908 0.5388977 0.59737855 0.5210477 0.4055072 0.11848069 0.7118382 0.9796308 (2,1,.,.) = 0.275001 0.35905758 0.15939762 0.09233412 0.16610192 0.032060683 0.37298614 0.48936844 0.031097537 0.82767457 0.10246291 0.9951448 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4] Python example: from zoo.pipeline.api.keras.layers import Narrow from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Narrow(1, 1, input_shape=(2, 3, 4))) input = np.random.rand(2, 2, 3, 4) output = model.forward(input) Input is: array([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923], [0.28316902, 0.3004414 , 0.40298034, 0.37476436], [0.18825825, 0.38979411, 0.32963262, 0.37783457]], [[0.14824117, 0.43532988, 0.57077087, 0.91535978], [0.46375725, 0.90511296, 0.18859044, 0.92820822], [0.13675737, 0.48270908, 0.04260755, 0.97255687]]], [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529], [0.07472717, 0.5715716 , 0.57029986, 0.26475783], [0.56757079, 0.27602746, 0.45799196, 0.74420842]], [[0.89048761, 0.08280716, 0.99030481, 0.35956427], [0.70802689, 0.14425212, 0.08320864, 0.82271697], [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]]) Output is array([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ], [0.46375725, 0.905113 , 0.18859044, 0.92820823], [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]], [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427], [0.7080269 , 0.14425212, 0.08320864, 0.82271695], [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]], dtype=float32)","title":"Narrow"},{"location":"KerasStyleAPIGuide/Layers/core/#permute","text":"Permutes the dimensions of the input according to a given pattern. Useful for connecting RNNs and convnets together. Permute(dims, inputShape = null) Python: Permute(dims, input_shape=None, name=None) Parameters: dims : Int array. Permutation pattern, does not include the batch dimension. Indexing starts at 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Permute import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3))) val input = Tensor[Float](2, 2, 2, 3).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.8451549 0.06361471 0.7324815 0.31086245 0.21210302 0.35112163 (1,2,.,.) = 0.61466074 0.50173014 0.8759959 0.19090249 0.671227 0.73089105 (2,1,.,.) = 0.47867084 0.9341955 0.063592255 0.24063066 0.502274 0.9114748 (2,2,.,.) = 0.93335986 0.25173688 0.88615775 0.5394321 0.330763 0.89036304 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.8451549 0.06361471 0.7324815 0.61466074 0.50173014 0.8759959 (1,2,.,.) = 0.31086245 0.21210302 0.35112163 0.19090249 0.671227 0.73089105 (2,1,.,.) = 0.47867084 0.9341955 0.063592255 0.93335986 0.25173688 0.88615775 (2,2,.,.) = 0.24063066 0.502274 0.9114748 0.5394321 0.330763 0.89036304 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import Permute from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(Permute((2, 1, 3), input_shape=(2, 2, 3))) input = np.random.rand(2, 2, 2, 3) output = model.forward(input) Input is: array([[[[0.14016896, 0.7275626 , 0.79087092], [0.57259566, 0.97387138, 0.70001999]], [[0.9232002 , 0.07644555, 0.24705828], [0.17257354, 0.93951155, 0.46183983]]], [[[0.79432476, 0.64299062, 0.33959594], [0.58608318, 0.338014 , 0.92602687]], [[0.32638575, 0.69032582, 0.25168083], [0.46813027, 0.95118373, 0.13145026]]]]) Output is array([[[[0.14016896, 0.7275626 , 0.7908709 ], [0.9232002 , 0.07644555, 0.24705827]], [[0.57259566, 0.97387135, 0.70002 ], [0.17257354, 0.93951154, 0.46183982]]], [[[0.79432476, 0.64299065, 0.33959594], [0.32638577, 0.6903258 , 0.25168082]], [[0.5860832 , 0.338014 , 0.9260269 ], [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32)","title":"Permute"},{"location":"KerasStyleAPIGuide/Layers/core/#resizebilinear","text":"Resize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout. ResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering = th , inputShape = null) Python: ResizeBilinear(output_height, output_width, align_corner=False, dim_ordering= th , input_shape=(2, 3, 5, 7), name=None) Parameters: outputHeight : output height outputWidth : output width alignCorners : align corner or not dimOrdering : Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential() model.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5))) val input = Tensor[Float](2, 2, 3, 5).rand() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.6991891 0.007127314 0.73871046 0.95916307 0.9433856 0.41275907 0.37573513 0.99193203 0.06930728 0.5922364 0.024281504 0.2592453 0.3898136 0.6635241 0.85888565 (1,2,.,.) = 0.38028112 0.43709648 0.62538666 0.8468501 0.6445014 0.45252413 0.48801896 0.59471387 0.013207023 0.3567462 0.85187584 0.49279585 0.7973665 0.81287366 0.07852263 (2,1,.,.) = 0.1452374 0.6140467 0.36384684 0.066476084 0.96101314 0.54862195 0.66091377 0.86857307 0.6844842 0.7368217 0.25342992 0.71737933 0.12789607 0.21691357 0.7543404 (2,2,.,.) = 0.79176855 0.1204049 0.58971256 0.115073755 0.10459962 0.5225398 0.742363 0.7612815 0.9881919 0.13359445 0.9026869 0.13972941 0.92064524 0.9435532 0.5502235 [com.intel.analytics.bigdl.tensor.DenseTensor of... Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.6991891 0.4948494 0.9539039 0.21852028 0.5664119 0.48613077 (1,2,.,.) = 0.38028112 0.56262326 0.7794005 0.6522 0.6274959 0.34790504 (2,1,.,.) = 0.1452374 0.4472468 0.36465502 0.40102595 0.5618719 0.54899293 (2,2,.,.) = 0.79176855 0.43327665 0.111582376 0.71261334 0.70765764 0.75788474 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3] Python example: from zoo.pipeline.api.keras.layers import ResizeBilinear from zoo.pipeline.api.keras.models import Sequential import numpy as np model = Sequential() model.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5))) input = np.random.rand(2, 2, 3, 5, 5) output = model.forward(input) Input is: array([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189], [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155], [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]], [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775], [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264], [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]], [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452], [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ], [0.608378 , 0.10531177, 0.78000335, 0.51679768, 0.65067605]], [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255], [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493], [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]]) Output is array([[[[0.43790358, 0.61913717, 0.2543214 ], [0.6172875 , 0.52657175, 0.3151154 ]], [[0.329656 , 0.13861606, 0.20514478], [0.46164483, 0.541788 , 0.5311798 ]]], [[[0.09462238, 0.57138187, 0.8545758 ], [0.7116966 , 0.5389645 , 0.48184 ]], [[0.12074634, 0.6571231 , 0.752728 ], [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)","title":"ResizeBilinear"},{"location":"KerasStyleAPIGuide/Layers/dropout/","text":"SpatialDropout3D Spatial 3D version of Dropout. This version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead. The input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3) Scala: SpatialDropout3D(p = 0.5, dimOrdering = th , inputShape = null) Python: SpatialDropout3D(p=0.5, dim_ordering= th , input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 1.5842006 -1.486708 -1.0261744 -0.8227147 0.1386223 -0.46191332 (1,1,2,.,.) = -0.7794714 0.52259976 1.5326598 0.32597166 0.84018683 -0.24034925 (1,2,1,.,.) = 0.5037644 -0.42065156 1.1590574 1.4855213 -1.4098096 0.5154563 (1,2,2,.,.) = 2.1119535 0.4159602 -0.33109334 -1.9544226 0.014503485 -0.7715549 (2,1,1,.,.) = 1.1496683 0.20273614 -2.6363356 -1.6820912 -1.1656585 -0.8387814 (2,1,2,.,.) = -1.1125584 -1.9073812 0.78532314 -1.0033096 -0.24038585 1.0534006 (2,2,1,.,.) = 0.46944886 -1.8767697 0.7275591 0.36211884 0.34403932 -1.3721423 (2,2,2,.,.) = 0.37117565 -0.45195773 0.66517854 0.3873176 -1.8218406 1.9105781 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.0 -0.0 -0.0 -0.0 0.0 -0.0 (1,1,2,.,.) = -0.0 0.0 0.0 0.0 0.0 -0.0 (1,2,1,.,.) = 0.0 -0.0 0.0 0.0 -0.0 0.0 (1,2,2,.,.) = 0.0 0.0 -0.0 -0.0 0.0 -0.0 (2,1,1,.,.) = 0.0 0.0 -0.0 -0.0 -0.0 -0.0 (2,1,2,.,.) = -0.0 -0.0 0.0 -0.0 -0.0 0.0 (2,2,1,.,.) = 0.0 -0.0 0.0 0.0 0.0 -0.0 (2,2,2,.,.) = 0.0 -0.0 0.0 0.0 -0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import SpatialDropout3D model = Sequential() model.add(SpatialDropout3D(input_shape=(2, 2, 2, 2))) input = np.random.random([2, 2, 2, 2, 2]) output = model.forward(input) Input is: [[[[[0.19861794 0.32822715] [0.78735804 0.0586697 ]] [[0.22181565 0.09894792] [0.43668179 0.22321872]]] [[[0.81122679 0.44084158] [0.70199098 0.10383273]] [[0.78102397 0.62514588] [0.6933126 0.7830806 ]]]] [[[[0.22229716 0.90939922] [0.2453606 0.49500498]] [[0.95518136 0.78983711] [0.724247 0.62801332]]] [[[0.89800761 0.5523274 ] [0.83153558 0.58200981]] [[0.84787731 0.16651971] [0.22528241 0.68706778]]]]] Output is [[[[[0.19861795 0.32822713] [0.78735805 0.0586697 ]] [[0.22181565 0.09894791] [0.43668178 0.22321871]]] [[[0.8112268 0.4408416 ] [0.70199096 0.10383273]] [[0.781024 0.62514585] [0.6933126 0.7830806 ]]]] [[[[0. 0. ] [0. 0. ]] [[0. 0. ] [0. 0. ]]] [[[0.89800763 0.5523274 ] [0.8315356 0.5820098 ]] [[0.8478773 0.16651972] [0.22528242 0.6870678 ]]]]] Dropout Applies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting. Scala: Dropout(p, inputShape = null) Python: Dropout(p, input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Dropout[Float](0.3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.5496527 0.34846303 1.8184849 -0.8750735 -0.2907603 0.124056354 -0.5447822 -0.34512782 1.003834 -0.27847317 -0.16524693 -0.12172801 (2,.,.) = -0.50297844 -0.78188837 -1.5617784 -1.2353797 -1.5052266 -1.6246556 0.5203618 1.144502 -0.18044183 -0.032648038 -1.9599762 -0.6970337 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 2.2137897 0.49780434 2.5978355 -1.250105 0.0 0.17722337 0.0 0.0 1.4340487 0.0 0.0 -0.17389716 (2,.,.) = -0.71854067 -1.1169834 -2.231112 -1.7648282 -2.1503239 -2.3209367 0.743374 1.635003 -0.25777406 0.0 -2.799966 -0.99576247 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Dropout from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Dropout(0.3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815], [0.70987046, 0.11246564, 0.68062359, 0.48074257], [0.61979472, 0.36682032, 0.08320745, 0.41117697]], [[0.19616717, 0.18093539, 0.52080897, 0.73326568], [0.72752776, 0.81963229, 0.05652756, 0.37253947], [0.70200807, 0.27836313, 0.24421078, 0.58191582]]]) Output is array([[[1.1523907 , 0.7672588 , 0. , 0.6953831 ], [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ], [0. , 0.5240291 , 0.11886779, 0.58739567]], [[0.2802388 , 0. , 0.74401283, 1.0475224 ], [1.0393254 , 1.1709033 , 0.08075366, 0.53219926], [1.0028687 , 0.39766163, 0. , 0.8313083 ]]], dtype=float32) GaussianDropout Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time. Scala: GaussianDropout(p, inputShape = null) Python: GaussianDropout(p, input_shape=None, name=None) Parameters: p : Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8969221 2.454179 -0.26737544 0.86235714 -0.61781764 -0.48739514 0.2337097 1.0086832 1.7666794 -1.120229 -0.28245732 0.845279 (2,.,.) = 1.2763704 -0.3854067 0.0061038486 0.931373 0.67848265 -3.098805 -0.1240183 0.36834922 0.9772534 -0.639048 -0.078967154 1.4179249 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.8251847 4.3458977 -0.6353459 -0.10734326 -0.4009521 -0.5479114 0.1226105 2.0534828 -0.03313 -2.271632 0.122886114 -0.44396263 (2,.,.) = 0.45101312 -0.48233575 0.008046541 2.2945886 1.3415622 -1.9070724 -0.1681036 0.60575134 0.88338673 -1.4186113 -0.012104415 0.3102114 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GaussianDropout from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GaussianDropout(0.45, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.55167758, 0.07427833, 0.59777983, 0.86986969], [ 0.53097779, 0.4174687 , 0.58065922, 0.73479602], [ 0.43731939, 0.64465237, 0.32946076, 0.59878638]], [[ 0.26428987, 0.29575131, 0.36229906, 0.66938424], [ 0.74325536, 0.08672916, 0.35460851, 0.00122828], [ 0.27095285, 0.09442922, 0.02280022, 0.68735133]]]) Output is array([[[ 1.29282939e+00, 7.24226162e-02, 5.17048061e-01, 8.93751144e-01], [ 5.48077464e-01, -1.90222517e-01, 4.40389782e-01, 1.86340976e+00], [ 4.28632259e-01, 1.25118005e+00, 4.43376899e-01, 1.07255065e+00]], [[ -4.06714790e-02, 9.10973027e-02, 1.28347218e+00, 1.03069496e+00], [ 2.37148595e+00, 3.56667452e-02, 1.25722930e-01, 1.17819163e-05], [ 3.79356921e-01, 8.55060294e-02, 3.33660096e-02, 3.40193957e-02]]], dtype=float32) SpatialDropout2D Spatial 2D version of Dropout. This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead. The input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last). Scala: SpatialDropout2D(p = 0.5, dimOrdering = th , inputShape = null) Python: SpatialDropout2D(p=0.5, dim_ordering= th , input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 1.266674 -0.19261484 0.8210725 -0.22291088 -0.38138267 1.7019615 1.1729054 0.59097356 -0.50952524 -1.9868233 -0.17180282 -1.2743127 (1,2,.,.) = -0.13727586 -0.7740464 1.2427979 -0.46285817 -1.747042 1.3353567 1.1310997 -0.26019064 0.9580778 -0.69689065 -0.77704996 0.704949 (2,1,.,.) = 0.040080033 0.08806901 0.44471294 0.4693497 -1.2577269 -2.5343444 -0.5290871 0.73988694 -0.4042877 -0.20460072 -0.68553877 0.59006995 (2,2,.,.) = -0.06227895 -0.9075216 1.226318 1.0563084 -0.6985987 -0.20155957 0.1005844 -0.49736363 1.3935218 -2.8411357 -1.6742039 0.26154035 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 -0.0 0.0 -0.0 -0.0 0.0 0.0 0.0 -0.0 -0.0 -0.0 -0.0 (1,2,.,.) = -0.13727586 -0.7740464 1.2427979 -0.46285817 -1.747042 1.3353567 1.1310997 -0.26019064 0.9580778 -0.69689065 -0.77704996 0.704949 (2,1,.,.) = 0.040080033 0.08806901 0.44471294 0.4693497 -1.2577269 -2.5343444 -0.5290871 0.73988694 -0.4042877 -0.20460072 -0.68553877 0.59006995 (2,2,.,.) = -0.06227895 -0.9075216 1.226318 1.0563084 -0.6985987 -0.20155957 0.1005844 -0.49736363 1.3935218 -2.8411357 -1.6742039 0.26154035 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import SpatialDropout2D model = Sequential() model.add(SpatialDropout2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.45638721 0.87479404 0.28319946 0.85046252] [0.90687581 0.29446766 0.23341603 0.92425726] [0.51232495 0.83895807 0.90536451 0.41231943]] [[0.00397271 0.28512243 0.32912336 0.27304027] [0.97274043 0.92907157 0.25843125 0.201849 ] [0.42783297 0.91400856 0.19290376 0.83749261]]] [[[0.03282751 0.60866148 0.47616452 0.4300911 ] [0.75731354 0.34609462 0.66514783 0.18193801] [0.6748754 0.94068849 0.38504096 0.66447561]] [[0.61274329 0.56573389 0.21795374 0.45314279] [0.2883045 0.22641016 0.83014439 0.21362862] [0.33618578 0.47346473 0.96971251 0.2937416 ]]]] Output is [[[[0.45638722 0.87479407 0.28319946 0.8504625 ] [0.9068758 0.29446766 0.23341602 0.9242573 ] [0.5123249 0.8389581 0.9053645 0.41231942]] [[0.00397271 0.28512242 0.32912338 0.27304026] [0.9727404 0.92907155 0.25843126 0.201849 ] [0.42783296 0.91400856 0.19290376 0.8374926 ]]] [[[0.03282751 0.6086615 0.47616452 0.4300911 ] [0.75731355 0.3460946 0.66514784 0.18193801] [0.6748754 0.9406885 0.38504097 0.6644756 ]] [[0. 0. 0. 0. ] [0. 0. 0. 0. ] [0. 0. 0. 0. ]]]] GaussianNoise Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time. Scala: GaussianNoise(sigma, inputShape = null) Python: GaussianNoise(sigma, input_shape=None, name=None) Parameters: sigma : Standard deviation of the noise distribution. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.57896155 -0.19616802 1.7000706 -2.2136402 0.2245884 -0.167104 0.08521592 -0.31111532 -1.2676435 1.9858241 -0.27946314 -0.72280097 (2,.,.) = 1.263968 -0.1366611 0.7511876 -0.42096275 -0.2524562 -2.082302 -1.3312799 0.035666652 -1.6895409 -0.8562052 0.69322604 -0.080461726 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.25664312 0.1474515 2.066732 -1.5476861 0.34144306 1.1049318 0.4146787 -0.15529981 -1.3980585 2.0075183 0.09995845 -0.9865419 (2,.,.) = 0.8450401 0.0076646805 0.5062498 -0.5671178 0.89790833 -2.1620805 -1.5945435 -0.74607164 -1.7677919 -0.6946467 0.35671985 0.9388765 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GaussianNoise from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GaussianNoise(0.6, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[0.87836839, 0.29835789, 0.99199298, 0.61462649], [0.24045628, 0.9334569 , 0.69817451, 0.80795268], [0.82978091, 0.32160601, 0.97033687, 0.34726345]], [[0.11581215, 0.2012782 , 0.89101947, 0.24642749], [0.51231345, 0.47586449, 0.53419205, 0.71586367], [0.88794988, 0.20960408, 0.46741968, 0.31609195]]]) Output is array([[[ 0.9021132 , 0.05798048, 0.9235187 , 0.8105377 ], [ 0.82122934, 0.87509984, 1.3449373 , 0.115228 ], [ 0.2612275 , 0.02238336, 0.8971698 , 0.3349191 ]], [[-0.7950512 , -0.4547084 , 1.6517348 , 1.5761411 ], [ 0.9232183 , 0.33405185, 0.6043875 , 0.54677534], [ 1.4350419 , -1.4409285 , -0.31246042, 0.5502143 ]]], dtype=float32)","title":"Dropout Layers"},{"location":"KerasStyleAPIGuide/Layers/dropout/#spatialdropout3d","text":"Spatial 3D version of Dropout. This version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead. The input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3) Scala: SpatialDropout3D(p = 0.5, dimOrdering = th , inputShape = null) Python: SpatialDropout3D(p=0.5, dim_ordering= th , input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 1.5842006 -1.486708 -1.0261744 -0.8227147 0.1386223 -0.46191332 (1,1,2,.,.) = -0.7794714 0.52259976 1.5326598 0.32597166 0.84018683 -0.24034925 (1,2,1,.,.) = 0.5037644 -0.42065156 1.1590574 1.4855213 -1.4098096 0.5154563 (1,2,2,.,.) = 2.1119535 0.4159602 -0.33109334 -1.9544226 0.014503485 -0.7715549 (2,1,1,.,.) = 1.1496683 0.20273614 -2.6363356 -1.6820912 -1.1656585 -0.8387814 (2,1,2,.,.) = -1.1125584 -1.9073812 0.78532314 -1.0033096 -0.24038585 1.0534006 (2,2,1,.,.) = 0.46944886 -1.8767697 0.7275591 0.36211884 0.34403932 -1.3721423 (2,2,2,.,.) = 0.37117565 -0.45195773 0.66517854 0.3873176 -1.8218406 1.9105781 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 0.0 -0.0 -0.0 -0.0 0.0 -0.0 (1,1,2,.,.) = -0.0 0.0 0.0 0.0 0.0 -0.0 (1,2,1,.,.) = 0.0 -0.0 0.0 0.0 -0.0 0.0 (1,2,2,.,.) = 0.0 0.0 -0.0 -0.0 0.0 -0.0 (2,1,1,.,.) = 0.0 0.0 -0.0 -0.0 -0.0 -0.0 (2,1,2,.,.) = -0.0 -0.0 0.0 -0.0 -0.0 0.0 (2,2,1,.,.) = 0.0 -0.0 0.0 0.0 0.0 -0.0 (2,2,2,.,.) = 0.0 -0.0 0.0 0.0 -0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import SpatialDropout3D model = Sequential() model.add(SpatialDropout3D(input_shape=(2, 2, 2, 2))) input = np.random.random([2, 2, 2, 2, 2]) output = model.forward(input) Input is: [[[[[0.19861794 0.32822715] [0.78735804 0.0586697 ]] [[0.22181565 0.09894792] [0.43668179 0.22321872]]] [[[0.81122679 0.44084158] [0.70199098 0.10383273]] [[0.78102397 0.62514588] [0.6933126 0.7830806 ]]]] [[[[0.22229716 0.90939922] [0.2453606 0.49500498]] [[0.95518136 0.78983711] [0.724247 0.62801332]]] [[[0.89800761 0.5523274 ] [0.83153558 0.58200981]] [[0.84787731 0.16651971] [0.22528241 0.68706778]]]]] Output is [[[[[0.19861795 0.32822713] [0.78735805 0.0586697 ]] [[0.22181565 0.09894791] [0.43668178 0.22321871]]] [[[0.8112268 0.4408416 ] [0.70199096 0.10383273]] [[0.781024 0.62514585] [0.6933126 0.7830806 ]]]] [[[[0. 0. ] [0. 0. ]] [[0. 0. ] [0. 0. ]]] [[[0.89800763 0.5523274 ] [0.8315356 0.5820098 ]] [[0.8478773 0.16651972] [0.22528242 0.6870678 ]]]]]","title":"SpatialDropout3D"},{"location":"KerasStyleAPIGuide/Layers/dropout/#dropout","text":"Applies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting. Scala: Dropout(p, inputShape = null) Python: Dropout(p, input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Dropout[Float](0.3, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.5496527 0.34846303 1.8184849 -0.8750735 -0.2907603 0.124056354 -0.5447822 -0.34512782 1.003834 -0.27847317 -0.16524693 -0.12172801 (2,.,.) = -0.50297844 -0.78188837 -1.5617784 -1.2353797 -1.5052266 -1.6246556 0.5203618 1.144502 -0.18044183 -0.032648038 -1.9599762 -0.6970337 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 2.2137897 0.49780434 2.5978355 -1.250105 0.0 0.17722337 0.0 0.0 1.4340487 0.0 0.0 -0.17389716 (2,.,.) = -0.71854067 -1.1169834 -2.231112 -1.7648282 -2.1503239 -2.3209367 0.743374 1.635003 -0.25777406 0.0 -2.799966 -0.99576247 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Dropout from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Dropout(0.3, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815], [0.70987046, 0.11246564, 0.68062359, 0.48074257], [0.61979472, 0.36682032, 0.08320745, 0.41117697]], [[0.19616717, 0.18093539, 0.52080897, 0.73326568], [0.72752776, 0.81963229, 0.05652756, 0.37253947], [0.70200807, 0.27836313, 0.24421078, 0.58191582]]]) Output is array([[[1.1523907 , 0.7672588 , 0. , 0.6953831 ], [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ], [0. , 0.5240291 , 0.11886779, 0.58739567]], [[0.2802388 , 0. , 0.74401283, 1.0475224 ], [1.0393254 , 1.1709033 , 0.08075366, 0.53219926], [1.0028687 , 0.39766163, 0. , 0.8313083 ]]], dtype=float32)","title":"Dropout"},{"location":"KerasStyleAPIGuide/Layers/dropout/#gaussiandropout","text":"Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time. Scala: GaussianDropout(p, inputShape = null) Python: GaussianDropout(p, input_shape=None, name=None) Parameters: p : Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.8969221 2.454179 -0.26737544 0.86235714 -0.61781764 -0.48739514 0.2337097 1.0086832 1.7666794 -1.120229 -0.28245732 0.845279 (2,.,.) = 1.2763704 -0.3854067 0.0061038486 0.931373 0.67848265 -3.098805 -0.1240183 0.36834922 0.9772534 -0.639048 -0.078967154 1.4179249 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 1.8251847 4.3458977 -0.6353459 -0.10734326 -0.4009521 -0.5479114 0.1226105 2.0534828 -0.03313 -2.271632 0.122886114 -0.44396263 (2,.,.) = 0.45101312 -0.48233575 0.008046541 2.2945886 1.3415622 -1.9070724 -0.1681036 0.60575134 0.88338673 -1.4186113 -0.012104415 0.3102114 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GaussianDropout from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GaussianDropout(0.45, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[ 0.55167758, 0.07427833, 0.59777983, 0.86986969], [ 0.53097779, 0.4174687 , 0.58065922, 0.73479602], [ 0.43731939, 0.64465237, 0.32946076, 0.59878638]], [[ 0.26428987, 0.29575131, 0.36229906, 0.66938424], [ 0.74325536, 0.08672916, 0.35460851, 0.00122828], [ 0.27095285, 0.09442922, 0.02280022, 0.68735133]]]) Output is array([[[ 1.29282939e+00, 7.24226162e-02, 5.17048061e-01, 8.93751144e-01], [ 5.48077464e-01, -1.90222517e-01, 4.40389782e-01, 1.86340976e+00], [ 4.28632259e-01, 1.25118005e+00, 4.43376899e-01, 1.07255065e+00]], [[ -4.06714790e-02, 9.10973027e-02, 1.28347218e+00, 1.03069496e+00], [ 2.37148595e+00, 3.56667452e-02, 1.25722930e-01, 1.17819163e-05], [ 3.79356921e-01, 8.55060294e-02, 3.33660096e-02, 3.40193957e-02]]], dtype=float32)","title":"GaussianDropout"},{"location":"KerasStyleAPIGuide/Layers/dropout/#spatialdropout2d","text":"Spatial 2D version of Dropout. This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead. The input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last). Scala: SpatialDropout2D(p = 0.5, dimOrdering = th , inputShape = null) Python: SpatialDropout2D(p=0.5, dim_ordering= th , input_shape=None, name=None) Parameters: p : Fraction of the input units to drop. Between 0 and 1. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 1.266674 -0.19261484 0.8210725 -0.22291088 -0.38138267 1.7019615 1.1729054 0.59097356 -0.50952524 -1.9868233 -0.17180282 -1.2743127 (1,2,.,.) = -0.13727586 -0.7740464 1.2427979 -0.46285817 -1.747042 1.3353567 1.1310997 -0.26019064 0.9580778 -0.69689065 -0.77704996 0.704949 (2,1,.,.) = 0.040080033 0.08806901 0.44471294 0.4693497 -1.2577269 -2.5343444 -0.5290871 0.73988694 -0.4042877 -0.20460072 -0.68553877 0.59006995 (2,2,.,.) = -0.06227895 -0.9075216 1.226318 1.0563084 -0.6985987 -0.20155957 0.1005844 -0.49736363 1.3935218 -2.8411357 -1.6742039 0.26154035 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.0 -0.0 0.0 -0.0 -0.0 0.0 0.0 0.0 -0.0 -0.0 -0.0 -0.0 (1,2,.,.) = -0.13727586 -0.7740464 1.2427979 -0.46285817 -1.747042 1.3353567 1.1310997 -0.26019064 0.9580778 -0.69689065 -0.77704996 0.704949 (2,1,.,.) = 0.040080033 0.08806901 0.44471294 0.4693497 -1.2577269 -2.5343444 -0.5290871 0.73988694 -0.4042877 -0.20460072 -0.68553877 0.59006995 (2,2,.,.) = -0.06227895 -0.9075216 1.226318 1.0563084 -0.6985987 -0.20155957 0.1005844 -0.49736363 1.3935218 -2.8411357 -1.6742039 0.26154035 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import SpatialDropout2D model = Sequential() model.add(SpatialDropout2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.45638721 0.87479404 0.28319946 0.85046252] [0.90687581 0.29446766 0.23341603 0.92425726] [0.51232495 0.83895807 0.90536451 0.41231943]] [[0.00397271 0.28512243 0.32912336 0.27304027] [0.97274043 0.92907157 0.25843125 0.201849 ] [0.42783297 0.91400856 0.19290376 0.83749261]]] [[[0.03282751 0.60866148 0.47616452 0.4300911 ] [0.75731354 0.34609462 0.66514783 0.18193801] [0.6748754 0.94068849 0.38504096 0.66447561]] [[0.61274329 0.56573389 0.21795374 0.45314279] [0.2883045 0.22641016 0.83014439 0.21362862] [0.33618578 0.47346473 0.96971251 0.2937416 ]]]] Output is [[[[0.45638722 0.87479407 0.28319946 0.8504625 ] [0.9068758 0.29446766 0.23341602 0.9242573 ] [0.5123249 0.8389581 0.9053645 0.41231942]] [[0.00397271 0.28512242 0.32912338 0.27304026] [0.9727404 0.92907155 0.25843126 0.201849 ] [0.42783296 0.91400856 0.19290376 0.8374926 ]]] [[[0.03282751 0.6086615 0.47616452 0.4300911 ] [0.75731355 0.3460946 0.66514784 0.18193801] [0.6748754 0.9406885 0.38504097 0.6644756 ]] [[0. 0. 0. 0. ] [0. 0. 0. 0. ] [0. 0. 0. 0. ]]]]","title":"SpatialDropout2D"},{"location":"KerasStyleAPIGuide/Layers/dropout/#gaussiannoise","text":"Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time. Scala: GaussianNoise(sigma, inputShape = null) Python: GaussianNoise(sigma, input_shape=None, name=None) Parameters: sigma : Standard deviation of the noise distribution. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4))) val input = Tensor[Float](2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.57896155 -0.19616802 1.7000706 -2.2136402 0.2245884 -0.167104 0.08521592 -0.31111532 -1.2676435 1.9858241 -0.27946314 -0.72280097 (2,.,.) = 1.263968 -0.1366611 0.7511876 -0.42096275 -0.2524562 -2.082302 -1.3312799 0.035666652 -1.6895409 -0.8562052 0.69322604 -0.080461726 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.25664312 0.1474515 2.066732 -1.5476861 0.34144306 1.1049318 0.4146787 -0.15529981 -1.3980585 2.0075183 0.09995845 -0.9865419 (2,.,.) = 0.8450401 0.0076646805 0.5062498 -0.5671178 0.89790833 -2.1620805 -1.5945435 -0.74607164 -1.7677919 -0.6946467 0.35671985 0.9388765 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GaussianNoise from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GaussianNoise(0.6, input_shape=(3, 4))) input = np.random.random([2, 3, 4]) output = model.forward(input) Input is: array([[[0.87836839, 0.29835789, 0.99199298, 0.61462649], [0.24045628, 0.9334569 , 0.69817451, 0.80795268], [0.82978091, 0.32160601, 0.97033687, 0.34726345]], [[0.11581215, 0.2012782 , 0.89101947, 0.24642749], [0.51231345, 0.47586449, 0.53419205, 0.71586367], [0.88794988, 0.20960408, 0.46741968, 0.31609195]]]) Output is array([[[ 0.9021132 , 0.05798048, 0.9235187 , 0.8105377 ], [ 0.82122934, 0.87509984, 1.3449373 , 0.115228 ], [ 0.2612275 , 0.02238336, 0.8971698 , 0.3349191 ]], [[-0.7950512 , -0.4547084 , 1.6517348 , 1.5761411 ], [ 0.9232183 , 0.33405185, 0.6043875 , 0.54677534], [ 1.4350419 , -1.4409285 , -0.31246042, 0.5502143 ]]], dtype=float32)","title":"GaussianNoise"},{"location":"KerasStyleAPIGuide/Layers/embedding/","text":"SparseEmbedding SparseEmbedding is the sparse version of layer Embedding. The input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors. If the input is a SparseTensor, the values are positive integer ids, values in each row of this SparseTensor will be turned into a dense vector. If the input is two SparseTensors, the first tensor should be the integer ids, just like the SparseTensor input. And the second tensor is the corresponding weights of the integer ids. This layer can only be used as the first layer in a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: SparseEmbedding(inputDim, outputDim, combiner = sum , max_norm = -1.0, init = uniform , wRegularizer = null, inputShape = null) Python: SparseEmbedding(input_dim, output_dim, combiner= sum , max_norm=-1.0, init= uniform , W_regularizer=None, input_shape=None, name=None) Parameters: inputDim : Int 0. Size of the vocabulary. outputDim : Int = 0. Dimension of the dense embedding. init : String representation of the initialization method for the weights of the layer. Default is \"uniform\". combiner : A string specifying the reduce type. Currently \"mean\", \"sum\", \"sqrtn\" is supported. maxNorm : If provided, each embedding is normalized to have l2 norm equal to maxNorm before combining. wRegularizer : An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val indices1 = Array(0, 0, 1, 2) val indices2 = Array(0, 1, 0, 3) val values = Array(2f, 4, 1, 2) val input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4)) val layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4, combiner = sum , inputShape = Shape(10)) layer.build(Shape(-1, 10)) val output = layer.forward(input) Input is: input: (0, 0) : 2.0 (0, 1) : 4.0 (1, 0) : 1.0 (2, 3) : 2.0 [com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4] Output is: -0.03674142 -0.01844017 -0.015794257 -0.045957662 -0.02645839 -0.024193227 -0.046255145 -0.047514524 -0.042759597 0.002117775 -0.041510757 1.9092667E-4 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SparseEmbedding from zoo.pipeline.api.keras.models import Sequential from bigdl.util.common import JTensor model = Sequential() model.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, ))) input = JTensor.sparse( a_ndarray=np.array([1, 3, 2, 4]), i_ndarray = np.array([[0, 0, 1, 2], [0, 3, 2, 1]]), shape = np.array([3, 4]) ) output = model.forward(input) Input is: JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2] [0 3 2 1]], float Output is [[ 0.00771878 -0.05676365 0.03861053 0.04300173] [-0.04647886 -0.03346863 0.04642192 -0.0145219 ] [ 0.03964841 0.0243053 0.04841208 0.04862341]] WordEmbedding Embedding layer that directly loads pre-trained word vectors as weights. Turn non-negative integers (indices) into dense vectors of fixed size. Currently only GloVe embedding is supported. The input of this layer should be 2D. This layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension). Scala: WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1) Python: WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None) Parameters: embeddingFile : The path to the embedding file. Currently the following GloVe files are supported: \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\" \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\". You can download them from: https://nlp.stanford.edu/projects/glove/. wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now. inputLength : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.T val model = Sequential[Double]() model.add(WordEmbedding[Double]( /path/to/glove.6B.50d.txt , wordIndex = WordEmbedding.getWordIndex( /path/to/glove.6B.50d.txt ), inputLength = 1)) val input = Tensor(data = Array(0.418), shape = Array(1, 1)) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Double] = 0.418 [com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50] Python example: import numpy as np from zoo.pipeline.api.keras.layers import WordEmbedding from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(WordEmbedding( /path/to/glove.6B.50d.txt , word_index=WordEmbedding.get_word_index( /path/to/glove.6B.50d.txt ), input_length=1)) input = np.random.random([1, 1]) output = model.forward(input) Input is: array([[0.18575166]]) Output is array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)","title":"Embedding Layers"},{"location":"KerasStyleAPIGuide/Layers/embedding/#sparseembedding","text":"SparseEmbedding is the sparse version of layer Embedding. The input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors. If the input is a SparseTensor, the values are positive integer ids, values in each row of this SparseTensor will be turned into a dense vector. If the input is two SparseTensors, the first tensor should be the integer ids, just like the SparseTensor input. And the second tensor is the corresponding weights of the integer ids. This layer can only be used as the first layer in a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension). Scala: SparseEmbedding(inputDim, outputDim, combiner = sum , max_norm = -1.0, init = uniform , wRegularizer = null, inputShape = null) Python: SparseEmbedding(input_dim, output_dim, combiner= sum , max_norm=-1.0, init= uniform , W_regularizer=None, input_shape=None, name=None) Parameters: inputDim : Int 0. Size of the vocabulary. outputDim : Int = 0. Dimension of the dense embedding. init : String representation of the initialization method for the weights of the layer. Default is \"uniform\". combiner : A string specifying the reduce type. Currently \"mean\", \"sum\", \"sqrtn\" is supported. maxNorm : If provided, each embedding is normalized to have l2 norm equal to maxNorm before combining. wRegularizer : An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val indices1 = Array(0, 0, 1, 2) val indices2 = Array(0, 1, 0, 3) val values = Array(2f, 4, 1, 2) val input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4)) val layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4, combiner = sum , inputShape = Shape(10)) layer.build(Shape(-1, 10)) val output = layer.forward(input) Input is: input: (0, 0) : 2.0 (0, 1) : 4.0 (1, 0) : 1.0 (2, 3) : 2.0 [com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4] Output is: -0.03674142 -0.01844017 -0.015794257 -0.045957662 -0.02645839 -0.024193227 -0.046255145 -0.047514524 -0.042759597 0.002117775 -0.041510757 1.9092667E-4 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SparseEmbedding from zoo.pipeline.api.keras.models import Sequential from bigdl.util.common import JTensor model = Sequential() model.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, ))) input = JTensor.sparse( a_ndarray=np.array([1, 3, 2, 4]), i_ndarray = np.array([[0, 0, 1, 2], [0, 3, 2, 1]]), shape = np.array([3, 4]) ) output = model.forward(input) Input is: JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2] [0 3 2 1]], float Output is [[ 0.00771878 -0.05676365 0.03861053 0.04300173] [-0.04647886 -0.03346863 0.04642192 -0.0145219 ] [ 0.03964841 0.0243053 0.04841208 0.04862341]]","title":"SparseEmbedding"},{"location":"KerasStyleAPIGuide/Layers/embedding/#wordembedding","text":"Embedding layer that directly loads pre-trained word vectors as weights. Turn non-negative integers (indices) into dense vectors of fixed size. Currently only GloVe embedding is supported. The input of this layer should be 2D. This layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension). Scala: WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1) Python: WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None) Parameters: embeddingFile : The path to the embedding file. Currently the following GloVe files are supported: \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\" \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\". You can download them from: https://nlp.stanford.edu/projects/glove/. wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now. inputLength : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.T val model = Sequential[Double]() model.add(WordEmbedding[Double]( /path/to/glove.6B.50d.txt , wordIndex = WordEmbedding.getWordIndex( /path/to/glove.6B.50d.txt ), inputLength = 1)) val input = Tensor(data = Array(0.418), shape = Array(1, 1)) val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Double] = 0.418 [com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50] Python example: import numpy as np from zoo.pipeline.api.keras.layers import WordEmbedding from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(WordEmbedding( /path/to/glove.6B.50d.txt , word_index=WordEmbedding.get_word_index( /path/to/glove.6B.50d.txt ), input_length=1)) input = np.random.random([1, 1]) output = model.forward(input) Input is: array([[0.18575166]]) Output is array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)","title":"WordEmbedding"},{"location":"KerasStyleAPIGuide/Layers/initialization/","text":"","title":"Initialization"},{"location":"KerasStyleAPIGuide/Layers/normalization/","text":"BatchNormalization Batch normalization layer. Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. It is a feature-wise normalization, each feature map in the input will be normalized separately. The input of this layer should be 4D. Scala: BatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = zero , gammaInit = one , dimOrdering = th , inputShape = null) Python: BatchNormalization(epsilon=0.001, momentum=0.99, beta_init= zero , gamma_init= one , dim_ordering= th , input_shape=None, name=None) Parameters: epsilon : Fuzz parameter. Default is 0.001. momentum : Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99. betaInit : Name of initialization function for shift parameter. See here for available initialization strings. Default is 'zero'. gammaInit : Name of initialization function for scale parameter. See here for available initialization strings. Default is 'one'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.35774308 -0.0018262876 -1.0186636 -0.8283433 0.1458402 -0.8954456 0.65028995 0.74481136 0.46434486 -0.33841616 -0.2882468 0.27368018 (1,2,.,.) = -0.85313565 -1.0957539 -0.7689828 1.7338694 0.66673565 1.0302666 -1.0154791 0.9704916 -1.518189 0.34307054 -0.8662138 0.53776205 (2,1,.,.) = -1.5997988 0.4131082 -0.83005565 1.3930303 1.061352 -0.6628746 0.8510218 -0.36472544 1.4967325 -0.082105584 -1.2064567 0.5379558 (2,2,.,.) = 0.76886225 0.8283977 -2.815423 -1.1129401 -0.76033413 -0.09757436 -1.1177903 0.057090428 -1.1909146 1.3031846 1.8407855 2.2742975 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.42506456 -0.016198127 -1.2640586 -1.0304978 0.16501783 -1.1128457 0.7840774 0.9000738 0.55588603 -0.4292604 -0.3676927 0.32190278 (1,2,.,.) = -0.66352594 -0.8604744 -0.59521383 1.4365083 0.57024884 0.86534977 -0.7953103 0.8168265 -1.2033914 0.30750957 -0.6741423 0.4655529 (2,1,.,.) = -1.9772263 0.49300852 -1.0325992 1.6955665 1.2885318 -0.827435 1.030415 -0.4615471 1.8228296 -0.11471669 -1.4945178 0.6462212 (2,2,.,.) = 0.6531514 0.7014801 -2.2564375 -0.8744255 -0.5881931 -0.050189503 -0.8783628 0.0753616 -0.9377223 1.0868944 1.5232987 1.8752075 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import BatchNormalization model = Sequential() model.add(BatchNormalization(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.90728825 0.06248136 0.38908736 0.41036892] [0.32752508 0.19828444 0.16125344 0.71703399] [0.91384765 0.10565062 0.5159064 0.11213003]] [[0.45955865 0.37912534 0.11220941 0.6227701 ] [0.74682518 0.31436052 0.35600359 0.46670668] [0.17039808 0.01137162 0.06768781 0.48850118]]] [[[0.41052004 0.51787735 0.22106962 0.72647921] [0.69059405 0.22422016 0.55071537 0.33162262] [0.92135018 0.81511106 0.76329409 0.30857876]] [[0.02103797 0.62061211 0.06155861 0.48460782] [0.95476727 0.66571869 0.53735588 0.09358965] [0.32302843 0.29893286 0.56494356 0.14670565]]]] Output is [[[[ 1.5911555 -1.4893758 -0.2984292 -0.22082737] [-0.52291185 -0.9941791 -1.1292102 0.8974061 ] [ 1.6150738 -1.3319621 0.16400792 -1.3083354 ]] [[ 0.3420891 0.02168216 -1.0415802 0.99224377] [ 1.4864182 -0.2363091 -0.07042356 0.37056333] [-0.809785 -1.4432687 -1.2189325 0.45738205]]] [[[-0.2202763 0.17119484 -0.91109455 0.9318476 ] [ 0.8009946 -0.8996063 0.29093656 -0.5079704 ] [ 1.6424314 1.2550375 1.0660906 -0.59199834]] [[-1.4047626 0.98364717 -1.2433482 0.44187275] [ 2.314758 1.1633297 0.6519953 -1.1157522 ] [-0.20178048 -0.2977654 0.761891 -0.9041641 ]]]] LRN2D Local Response Normalization between different feature maps. Scala: LRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering = th , inputShape = null) Python: LRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering= th , input_shape=None, name=None) Parameters: alpha : Double. The scaling parameter. Default is 0.0001. k : Double. A constant. Default is 1.0. beta : Double. The exponent. Default is 0.75. n : The number of channels to sum over. Default is 5. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering = tf , inputShape = Shape(3, 3, 3))) val input = Tensor[Float](2, 3, 3, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.6331058 -1.1622255 -0.20002009 0.031907756 1.4720777 0.36692062 0.16142464 -0.87992615 1.9201758 (1,2,.,.) = -1.0693451 -1.0901353 0.6909652 0.13340907 1.0220904 -1.0232266 -1.4288133 0.8749622 -0.07012164 (1,3,.,.) = -0.04984741 -1.4627954 1.2438095 1.5584376 -0.36223406 -0.862751 -0.68516856 -0.0066024275 -0.55539906 (2,1,.,.) = 1.8261654 -0.39168724 0.4531422 -0.09046966 0.61876625 0.4553172 0.58150214 -2.6587567 0.46114618 (2,2,.,.) = 0.75011647 -2.220607 -1.4024881 -0.5560173 0.19422908 -2.5069134 -0.7417007 1.3029631 -0.660577 (2,3,.,.) = -0.17827246 1.8794266 1.2124214 0.5774041 0.25620413 0.6461205 0.33391082 -0.532468 1.3129597 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.5884632 -1.0802679 -0.1859234 0.02965645 1.3681923 0.34102687 0.15005784 -0.81763095 1.7842402 (1,2,.,.) = -0.9938776 -1.0131469 0.6422488 0.12401139 0.94998133 -0.95103925 -1.3279068 0.81316966 -0.065184206 (1,3,.,.) = -0.046330474 -1.3593558 1.1558554 1.4484164 -0.33663353 -0.8019933 -0.63694555 -0.0061375294 -0.5163186 (2,1,.,.) = 1.6970686 -0.36398944 0.42125463 -0.08410302 0.5752084 0.4232657 0.54015917 -2.469669 0.4283661 (2,2,.,.) = 0.6969334 -2.0627165 -1.3028492 -0.5168911 0.18043552 -2.32896 -0.68936265 1.210961 -0.6139712 (2,3,.,.) = -0.16566847 1.7462649 1.1265225 0.53676987 0.23816296 0.60064477 0.31041232 -0.49490157 1.2203434 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LRN2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering= tf , input_shape=(3, 3, 3))) input = np.random.random([2, 3, 3, 3]) output = model.forward(input) Input is: [[[[0.56356835, 0.57442602, 0.31515783], [0.64858065, 0.45682821, 0.63889742], [0.56114806, 0.32727298, 0.54948325]], [[0.25249933, 0.27872938, 0.2341261 ], [0.22254477, 0.0855324 , 0.95981825], [0.55280765, 0.722852 , 0.95902286]], [[0.65021279, 0.00722661, 0.64386904], [0.36467587, 0.84466816, 0.05716471], [0.16279813, 0.57831132, 0.52848513]]], [[[0.94372659, 0.32741784, 0.03196349], [0.06181632, 0.8300082 , 0.36091632], [0.4961609 , 0.5816011 , 0.95777095]], [[0.12676416, 0.32625023, 0.58114797], [0.05347868, 0.5303113 , 0.20170834], [0.76583324, 0.39418884, 0.84815322]], [[0.62523604, 0.56888912, 0.69009855], [0.34074716, 0.05078519, 0.05212047], [0.50672308, 0.30567418, 0.47902636]]]] Output is [[[[0.5238933 , 0.53398067, 0.2929779 ], [0.602922 , 0.42464924, 0.59392124], [0.52165645, 0.30423048, 0.5108133 ]], [[0.23473667, 0.2591199 , 0.21765617], [0.20689127, 0.07950803, 0.8922195 ], [0.51387984, 0.6718813 , 0.89142925]], [[0.604453 , 0.00671771, 0.59855634], [0.3389953 , 0.7851862 , 0.05313992], [0.15134202, 0.53759885, 0.49128178]]], [[[0.87725437, 0.30435583, 0.02971505], [0.05746418, 0.77156085, 0.33550152], [0.46123454, 0.54060525, 0.89028406]], [[0.11784688, 0.30328864, 0.5402475 ], [0.04971581, 0.4929952 , 0.1875149 ], [0.7119114 , 0.36640498, 0.7884236 ]], [[0.58121526, 0.5288076 , 0.64150494], [0.31677726, 0.04721269, 0.04845466], [0.4710655 , 0.28415698, 0.44531912]]]] WithinChannelLRN2D The local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size). Scala: WithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null) Python: WithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None) Parameters: size : The side length of the square region to sum over. Default is 5. alpha : The scaling parameter. Default is 1.0. beta : The exponent. Default is 0.75. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4))) val input = Tensor[Float](1, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.11547339 -0.52518076 0.22743009 0.24847448 -0.72996384 1.5127875 1.285603 -0.8665928 2.2911248 0.062601104 -0.07974513 -0.26207858 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.089576244 -0.39988548 0.17317083 0.21585277 -0.5662553 1.1518734 0.97888964 -0.7528196 1.7772957 0.047666013 -0.060719892 -0.22767082 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import WithinChannelLRN2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(WithinChannelLRN2D(input_shape=(3, 4))) input = np.random.random([1, 3, 4]) output = model.forward(input) Input is: [[[0.96982874, 0.80581477, 0.35435895, 0.45537825], [0.61421818, 0.54708709, 0.86205409, 0.07374387], [0.67227822, 0.25118575, 0.36258901, 0.28671433]]] Output is [[[0.87259495, 0.71950066, 0.3164021 , 0.42620906], [0.55263746, 0.48848635, 0.76971596, 0.06902022], [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]","title":"Normalization Layers"},{"location":"KerasStyleAPIGuide/Layers/normalization/#batchnormalization","text":"Batch normalization layer. Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. It is a feature-wise normalization, each feature map in the input will be normalized separately. The input of this layer should be 4D. Scala: BatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = zero , gammaInit = one , dimOrdering = th , inputShape = null) Python: BatchNormalization(epsilon=0.001, momentum=0.99, beta_init= zero , gamma_init= one , dim_ordering= th , input_shape=None, name=None) Parameters: epsilon : Fuzz parameter. Default is 0.001. momentum : Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99. betaInit : Name of initialization function for shift parameter. See here for available initialization strings. Default is 'zero'. gammaInit : Name of initialization function for scale parameter. See here for available initialization strings. Default is 'one'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.35774308 -0.0018262876 -1.0186636 -0.8283433 0.1458402 -0.8954456 0.65028995 0.74481136 0.46434486 -0.33841616 -0.2882468 0.27368018 (1,2,.,.) = -0.85313565 -1.0957539 -0.7689828 1.7338694 0.66673565 1.0302666 -1.0154791 0.9704916 -1.518189 0.34307054 -0.8662138 0.53776205 (2,1,.,.) = -1.5997988 0.4131082 -0.83005565 1.3930303 1.061352 -0.6628746 0.8510218 -0.36472544 1.4967325 -0.082105584 -1.2064567 0.5379558 (2,2,.,.) = 0.76886225 0.8283977 -2.815423 -1.1129401 -0.76033413 -0.09757436 -1.1177903 0.057090428 -1.1909146 1.3031846 1.8407855 2.2742975 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.42506456 -0.016198127 -1.2640586 -1.0304978 0.16501783 -1.1128457 0.7840774 0.9000738 0.55588603 -0.4292604 -0.3676927 0.32190278 (1,2,.,.) = -0.66352594 -0.8604744 -0.59521383 1.4365083 0.57024884 0.86534977 -0.7953103 0.8168265 -1.2033914 0.30750957 -0.6741423 0.4655529 (2,1,.,.) = -1.9772263 0.49300852 -1.0325992 1.6955665 1.2885318 -0.827435 1.030415 -0.4615471 1.8228296 -0.11471669 -1.4945178 0.6462212 (2,2,.,.) = 0.6531514 0.7014801 -2.2564375 -0.8744255 -0.5881931 -0.050189503 -0.8783628 0.0753616 -0.9377223 1.0868944 1.5232987 1.8752075 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import BatchNormalization model = Sequential() model.add(BatchNormalization(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.90728825 0.06248136 0.38908736 0.41036892] [0.32752508 0.19828444 0.16125344 0.71703399] [0.91384765 0.10565062 0.5159064 0.11213003]] [[0.45955865 0.37912534 0.11220941 0.6227701 ] [0.74682518 0.31436052 0.35600359 0.46670668] [0.17039808 0.01137162 0.06768781 0.48850118]]] [[[0.41052004 0.51787735 0.22106962 0.72647921] [0.69059405 0.22422016 0.55071537 0.33162262] [0.92135018 0.81511106 0.76329409 0.30857876]] [[0.02103797 0.62061211 0.06155861 0.48460782] [0.95476727 0.66571869 0.53735588 0.09358965] [0.32302843 0.29893286 0.56494356 0.14670565]]]] Output is [[[[ 1.5911555 -1.4893758 -0.2984292 -0.22082737] [-0.52291185 -0.9941791 -1.1292102 0.8974061 ] [ 1.6150738 -1.3319621 0.16400792 -1.3083354 ]] [[ 0.3420891 0.02168216 -1.0415802 0.99224377] [ 1.4864182 -0.2363091 -0.07042356 0.37056333] [-0.809785 -1.4432687 -1.2189325 0.45738205]]] [[[-0.2202763 0.17119484 -0.91109455 0.9318476 ] [ 0.8009946 -0.8996063 0.29093656 -0.5079704 ] [ 1.6424314 1.2550375 1.0660906 -0.59199834]] [[-1.4047626 0.98364717 -1.2433482 0.44187275] [ 2.314758 1.1633297 0.6519953 -1.1157522 ] [-0.20178048 -0.2977654 0.761891 -0.9041641 ]]]]","title":"BatchNormalization"},{"location":"KerasStyleAPIGuide/Layers/normalization/#lrn2d","text":"Local Response Normalization between different feature maps. Scala: LRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering = th , inputShape = null) Python: LRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering= th , input_shape=None, name=None) Parameters: alpha : Double. The scaling parameter. Default is 0.0001. k : Double. A constant. Default is 1.0. beta : Double. The exponent. Default is 0.75. n : The number of channels to sum over. Default is 5. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering = tf , inputShape = Shape(3, 3, 3))) val input = Tensor[Float](2, 3, 3, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -0.6331058 -1.1622255 -0.20002009 0.031907756 1.4720777 0.36692062 0.16142464 -0.87992615 1.9201758 (1,2,.,.) = -1.0693451 -1.0901353 0.6909652 0.13340907 1.0220904 -1.0232266 -1.4288133 0.8749622 -0.07012164 (1,3,.,.) = -0.04984741 -1.4627954 1.2438095 1.5584376 -0.36223406 -0.862751 -0.68516856 -0.0066024275 -0.55539906 (2,1,.,.) = 1.8261654 -0.39168724 0.4531422 -0.09046966 0.61876625 0.4553172 0.58150214 -2.6587567 0.46114618 (2,2,.,.) = 0.75011647 -2.220607 -1.4024881 -0.5560173 0.19422908 -2.5069134 -0.7417007 1.3029631 -0.660577 (2,3,.,.) = -0.17827246 1.8794266 1.2124214 0.5774041 0.25620413 0.6461205 0.33391082 -0.532468 1.3129597 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = -0.5884632 -1.0802679 -0.1859234 0.02965645 1.3681923 0.34102687 0.15005784 -0.81763095 1.7842402 (1,2,.,.) = -0.9938776 -1.0131469 0.6422488 0.12401139 0.94998133 -0.95103925 -1.3279068 0.81316966 -0.065184206 (1,3,.,.) = -0.046330474 -1.3593558 1.1558554 1.4484164 -0.33663353 -0.8019933 -0.63694555 -0.0061375294 -0.5163186 (2,1,.,.) = 1.6970686 -0.36398944 0.42125463 -0.08410302 0.5752084 0.4232657 0.54015917 -2.469669 0.4283661 (2,2,.,.) = 0.6969334 -2.0627165 -1.3028492 -0.5168911 0.18043552 -2.32896 -0.68936265 1.210961 -0.6139712 (2,3,.,.) = -0.16566847 1.7462649 1.1265225 0.53676987 0.23816296 0.60064477 0.31041232 -0.49490157 1.2203434 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LRN2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering= tf , input_shape=(3, 3, 3))) input = np.random.random([2, 3, 3, 3]) output = model.forward(input) Input is: [[[[0.56356835, 0.57442602, 0.31515783], [0.64858065, 0.45682821, 0.63889742], [0.56114806, 0.32727298, 0.54948325]], [[0.25249933, 0.27872938, 0.2341261 ], [0.22254477, 0.0855324 , 0.95981825], [0.55280765, 0.722852 , 0.95902286]], [[0.65021279, 0.00722661, 0.64386904], [0.36467587, 0.84466816, 0.05716471], [0.16279813, 0.57831132, 0.52848513]]], [[[0.94372659, 0.32741784, 0.03196349], [0.06181632, 0.8300082 , 0.36091632], [0.4961609 , 0.5816011 , 0.95777095]], [[0.12676416, 0.32625023, 0.58114797], [0.05347868, 0.5303113 , 0.20170834], [0.76583324, 0.39418884, 0.84815322]], [[0.62523604, 0.56888912, 0.69009855], [0.34074716, 0.05078519, 0.05212047], [0.50672308, 0.30567418, 0.47902636]]]] Output is [[[[0.5238933 , 0.53398067, 0.2929779 ], [0.602922 , 0.42464924, 0.59392124], [0.52165645, 0.30423048, 0.5108133 ]], [[0.23473667, 0.2591199 , 0.21765617], [0.20689127, 0.07950803, 0.8922195 ], [0.51387984, 0.6718813 , 0.89142925]], [[0.604453 , 0.00671771, 0.59855634], [0.3389953 , 0.7851862 , 0.05313992], [0.15134202, 0.53759885, 0.49128178]]], [[[0.87725437, 0.30435583, 0.02971505], [0.05746418, 0.77156085, 0.33550152], [0.46123454, 0.54060525, 0.89028406]], [[0.11784688, 0.30328864, 0.5402475 ], [0.04971581, 0.4929952 , 0.1875149 ], [0.7119114 , 0.36640498, 0.7884236 ]], [[0.58121526, 0.5288076 , 0.64150494], [0.31677726, 0.04721269, 0.04845466], [0.4710655 , 0.28415698, 0.44531912]]]]","title":"LRN2D"},{"location":"KerasStyleAPIGuide/Layers/normalization/#withinchannellrn2d","text":"The local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size). Scala: WithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null) Python: WithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None) Parameters: size : The side length of the square region to sum over. Default is 5. alpha : The scaling parameter. Default is 1.0. beta : The exponent. Default is 0.75. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4))) val input = Tensor[Float](1, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.11547339 -0.52518076 0.22743009 0.24847448 -0.72996384 1.5127875 1.285603 -0.8665928 2.2911248 0.062601104 -0.07974513 -0.26207858 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.089576244 -0.39988548 0.17317083 0.21585277 -0.5662553 1.1518734 0.97888964 -0.7528196 1.7772957 0.047666013 -0.060719892 -0.22767082 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4] Python example: import numpy as np from zoo.pipeline.api.keras.layers import WithinChannelLRN2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(WithinChannelLRN2D(input_shape=(3, 4))) input = np.random.random([1, 3, 4]) output = model.forward(input) Input is: [[[0.96982874, 0.80581477, 0.35435895, 0.45537825], [0.61421818, 0.54708709, 0.86205409, 0.07374387], [0.67227822, 0.25118575, 0.36258901, 0.28671433]]] Output is [[[0.87259495, 0.71950066, 0.3164021 , 0.42620906], [0.55263746, 0.48848635, 0.76971596, 0.06902022], [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]","title":"WithinChannelLRN2D"},{"location":"KerasStyleAPIGuide/Layers/pooling/","text":"MaxPooling1D Max pooling operation for temporal data. The input is 3D tensor with shape:(batch_size, steps, feature_dim). Scala: MaxPooling1D(poolLength = 2, stride = -1, borderMode = valid , inputShape = null) Python: MaxPooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None) Parameters: poolLength : Size of the region to which max pooling is applied. Integer. Default is 2. stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength. borderMode : Either 'valid' or 'same'. Default is 'valid'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential val model = Sequential[Float]() model.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5))) val input = Tensor[Float](3, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.2339195 -1.2134796 0.16991705 -0.10169973 -1.2464932 0.37946555 0.29533234 -1.2552645 -2.6928735 -0.44519955 0.98743796 -1.0912303 -0.13897413 1.0241779 -0.5951304 -0.31459442 -0.088579334 -0.58336115 -0.6427486 -0.1447043 (2,.,.) = 0.14750746 0.07493488 -0.8554524 -1.6551514 0.16679412 -0.82279974 0.25704315 0.09921734 -0.8135057 2.7640774 -1.0111052 0.34388593 -0.7569789 1.0547938 1.6738676 0.4396624 -1.0570261 0.061429325 1.1752373 -0.14648575 (3,.,.) = -0.95818335 0.8790822 -0.99111855 -0.9717616 -0.39238095 1.2533073 0.23365906 1.7784269 1.0600376 1.6816885 0.7145845 0.4711851 -0.4465603 -0.77884597 0.484986 0.42429695 -2.00715 0.6520644 1.3022201 -0.48169184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.98743796 0.29533234 0.16991705 1.0241779 -0.44519955 (2,.,.) = 0.14750746 0.34388593 0.09921734 1.0547938 2.7640774 (3,.,.) = 1.2533073 0.8790822 1.7784269 1.0600376 1.6816885 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import MaxPooling1D model = Sequential() model.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192] [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637] [0.24147633 0.2116796 0.54433489 0.22961905 0.88685975] [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]] [[0.42306184 0.43404804 0.22141668 0.0316458 0.08445576] [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813] [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895] [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]] [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853] [0.9950283 0.55710408 0.70919634 0.52309929 0.14311439] [0.25394468 0.41519219 0.8074057 0.05341861 0.98447171] [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]] Output is: [[[0.27837703 0.8728293 0.9429287 0.48428997 0.8868598 ]] [[0.9070284 0.43404803 0.52975726 0.43238723 0.50049895]] [[0.9950283 0.99869156 0.877897 0.6784016 0.98447174]]] MaxPooling2D Max pooling operation for spatial data. The input is 4D tensor with shape:(batch_size, rows, cols, channels). Scala: MaxPooling2D(poolSize = (2, 2), strides = null, borderMode = valid , dimOrdering = th , inputShape = null) Python: MaxPooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension. strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D val model = Sequential[Float]() model.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.02138003 -0.20666665 -0.93250555 0.41267508 -0.40883347 0.4919021 0.7189889 1.3442185 -0.08697278 -0.025719838 2.1126 0.69069535 (1,2,.,.) = -0.1685801 -0.07843445 1.3499486 -0.5944459 0.29377022 0.061167963 -0.60608864 -0.08283464 0.03402891 -1.0627178 1.9463096 0.0011169242 (2,1,.,.) = -1.4524128 1.3868454 2.3057284 1.574949 -1.165581 0.79445213 -0.63500565 -0.17981622 -0.98042095 -1.7876958 0.8024988 -0.90554804 (2,2,.,.) = -1.6468426 1.1864686 -0.683854 -1.5643677 2.8272789 -0.5537863 -0.563258 -0.01623243 -0.31333938 0.03472893 -1.730748 -0.15463233 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: (1,1,.,.) = 0.4919021 1.3442185 (1,2,.,.) = 0.29377022 1.3499486 (2,1,.,.) = 1.3868454 2.3057284 (2,2,.,.) = 2.8272789 -0.01623243 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2] Python example: import numpy as np from bigdl.nn.keras.topology import Sequential from bigdl.nn.keras.layer import MaxPooling2D model = Sequential() model.add(MaxPooling2D(input_shape = (2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.58589442 0.94643201 0.24779969 0.55347075] [0.50604116 0.69884915 0.81253572 0.58586743] [0.94560389 0.11573268 0.12562681 0.63301697]] [[0.11736968 0.75641404 0.19342809 0.37670404] [0.55561582 0.54354621 0.9506264 0.65929266] [0.72911388 0.00499644 0.24280364 0.28822998]]] [[[0.53249492 0.43969012 0.20407128 0.49541971] [0.00369797 0.75294821 0.15204289 0.41394393] [0.19416915 0.93034988 0.0358259 0.38001445]] [[0.88946341 0.30646232 0.5347175 0.87568066] [0.00439823 0.97792811 0.34842225 0.20433116] [0.42777728 0.93583737 0.54341935 0.31203758]]]] Output is: [[[[0.946432 0.8125357 ]] [[0.75641406 0.95062643]]] [[[0.7529482 0.4954197 ]] [[0.9779281 0.8756807 ]]]] AveragePooling3D Applies average pooling operation for 3D data (spatial or spatio-temporal). Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels). Scala: AveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = th , inputShape = null) Python: AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension. strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize. dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.71569425 -0.39595184 -0.47607258 -0.12621938 -0.66759187 0.86833215 (1,1,2,.,.) = 1.219894 -0.07514859 0.6606987 0.073906526 -1.2547257 -0.49249622 (1,2,1,.,.) = -1.0730773 0.2780401 -0.8603222 -0.31499937 0.94786566 -1.6953986 (1,2,2,.,.) = 0.31038517 1.7660809 -0.9849316 -1.5245554 0.24002236 0.473947 (2,1,1,.,.) = -0.988634 -0.0028023662 -2.1534977 0.58303267 0.72106487 0.22115333 (2,1,2,.,.) = 1.3964092 -0.59152335 -0.6552192 2.0191588 -0.32599944 0.84014076 (2,2,1,.,.) = 1.4505147 -2.4253457 -0.37597662 -0.7049585 1.3384854 -1.1081233 (2,2,2,.,.) = -0.8498942 1.169977 0.78120154 0.13814813 -0.7438999 -0.9272572 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = -0.24269137 (1,2,1,.,.) = 0.07872025 (2,1,1,.,.) = 0.3513383 (2,2,1,.,.) = -0.078371644 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import AveragePooling3D model = Sequential() model.add(AveragePooling3D(input_shape = (2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[0.95796698 0.76067104 0.47285625] [0.90296063 0.64177821 0.23302549]] [[0.37135542 0.38455108 0.66999497] [0.06756778 0.16411331 0.39038159]]] [[[0.9884323 0.97861344 0.69852249] [0.53289779 0.51290587 0.54822396]] [[0.77241923 0.06470524 0.00757586] [0.65977832 0.31973607 0.7551191 ]]]] [[[[0.56819589 0.20398916 0.26409867] [0.81165023 0.65269175 0.16519667]] [[0.7350688 0.52442381 0.29116889] [0.45458689 0.29734681 0.39667421]]] [[[0.33577239 0.54035235 0.41285576] [0.01023886 0.23677996 0.18901205]] [[0.67638612 0.54170351 0.0068781 ] [0.95769069 0.88558419 0.4262852 ]]]]] Output is: [[[[[0.5313706 ]]] [[[0.603686 ]]]] [[[[0.5309942 ]]] [[[0.52306354]]]]] GlobalMaxPooling1D Global max pooling operation for temporal data. The input is 3D with the shape:(batch_size, steps, features). Scala: GlobalMaxPooling1D(inputShape = null) Python: GlobalMaxPooling1D(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.2998451 2.1855159 -0.05535197 -0.6448657 0.74119943 -0.8761581 (2,.,.) = 1.3994918 -1.5119147 -0.6625015 1.803635 -2.2516544 -0.016894706 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.2998451 2.1855159 -0.05535197 1.803635 -1.5119147 -0.016894706 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling1D model = Sequential() model.add(GlobalMaxPooling1D(input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.05589183 0.73674405 0.49270549] [0.03348098 0.82000941 0.81752936]] [[0.97310222 0.8878789 0.72330625] [0.86144601 0.88568162 0.47241316]]] Output is: [[0.05589183 0.8200094 0.8175294 ] [0.9731022 0.8878789 0.72330624]] MaxPooling3D Applies max pooling operation for 3D data (spatial or spatio-temporal). Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input of this layer should be 5D. Scala: MaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = th , inputShape = null) Python: MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension. strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize. dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.5052603 0.8938585 0.44785392 -0.48919395 0.35026026 0.541859 (1,1,2,.,.) = 1.5306468 0.24512683 1.71524 -0.49025944 2.1886358 0.15880944 (1,2,1,.,.) = -0.5133986 -0.16549884 -0.2971134 1.5887301 1.8269571 1.3843931 (1,2,2,.,.) = 0.07515256 1.6993935 -0.3392596 1.2611006 0.20215735 1.3105171 (2,1,1,.,.) = -2.0070438 0.35554957 0.21326075 -0.4078646 -1.5748956 -1.1007504 (2,1,2,.,.) = 1.0571382 -1.6031493 1.4638771 -0.25891435 1.4923956 -0.24045596 (2,2,1,.,.) = -0.57790893 0.14577095 1.3165486 0.81937057 -0.3797079 1.2544848 (2,2,2,.,.) = -0.42183575 -0.63774794 -2.0576336 0.43662143 1.9010457 -0.061519064 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 2.1886358 (1,2,1,.,.) = 1.8269571 (2,1,1,.,.) = 1.4923956 (2,2,1,.,.) = 1.9010457 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MaxPooling3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MaxPooling3D(input_shape=(2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[0.73349746 0.9811588 0.86071417] [0.33287621 0.37991739 0.87029317]] [[0.62537904 0.48099174 0.06194759] [0.38747972 0.05175308 0.36096032]]] [[[0.63260385 0.69990236 0.63353249] [0.19081261 0.56210617 0.75985185]] [[0.8624058 0.47224318 0.26524027] [0.75317792 0.39251436 0.98938982]]]] [[[[0.00556086 0.18833728 0.80340438] [0.9317538 0.88142596 0.90724509]] [[0.90243612 0.04594116 0.43662143] [0.24205094 0.58687822 0.57977055]]] [[[0.17240398 0.18346483 0.02520754] [0.06968248 0.02442692 0.56078895]] [[0.69503427 0.09528588 0.46104647] [0.16752596 0.88175901 0.71032998]]]]] Output is: [[[[[0.9811588]]] [[[0.8624058]]]] [[[[0.9317538]]] [[[0.881759 ]]]]] GlobalMaxPooling2D Global max pooling operation for spatial data. The input of this layer should be 4D. Scala: GlobalMaxPooling2D(dimOrdering = th , inputShape = null) Python: GlobalMaxPooling2D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.12648843 0.15536028 1.3401515 -0.25693455 0.6002777 0.6886729 -1.0650102 -0.22140503 -0.7598008 0.8800106 -0.061039474 -1.3625065 (1,2,.,.) = -0.37492484 -0.6727478 -0.12211597 1.3243467 -0.72237 0.6942101 -1.455304 -0.23814173 -0.38509718 -0.9179013 -0.99926376 0.18432678 (2,1,.,.) = 0.4457857 -0.36717635 -0.6653158 -1.9075912 -0.49489713 -0.70543754 0.85306334 0.21031244 0.08930698 0.046588574 0.9523686 -0.87959886 (2,2,.,.) = -0.8523849 0.55808693 -1.5779148 1.312412 -0.9923541 -0.562809 1.1512411 0.33178216 1.056546 -2.0607772 -0.8233232 0.024466092 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.3401515 1.3243467 0.9523686 1.312412 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling2D model = Sequential() model.add(GlobalMaxPooling2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.82189558 0.20668687 0.84669433 0.58740261] - [0.33005685 0.93836385 0.51005935 0.11894048] - [0.39757919 0.17126568 0.38237808 0.35911186]] - - [[0.98544456 0.10949685 0.47642379 0.21039236] - [0.51058537 0.9625007 0.2519618 0.03186033] - [0.28042435 0.08481816 0.37535567 0.60848855]]] - - - [[[0.34468892 0.48365864 0.01397789 0.16565704] - [0.91387839 0.78507728 0.0912983 0.06167101] - [0.49026863 0.17870698 0.43566122 0.79984653]] - - [[0.15157888 0.07546447 0.47063241 0.46052913] - [0.92483801 0.51271677 0.45300461 0.40369727] - [0.94152848 0.61306339 0.43241425 0.88775481]]]] Output is: [[0.93836385 0.98544455] - [0.9138784 0.9415285 ]] GlobalMaxPooling3D Applies global max pooling operation for 3D data. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels). The output of this layer should be 2D, i.e. (batch_size, channels). Scala: GlobalMaxPooling3D(dimOrdering = th , inputShape = null) Python: GlobalMaxPooling3D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 0.50938565 1.6374807 0.8158744 -0.3293317 -0.17766304 0.9067782 (1,1,2,.,.) = 1.5450556 -1.0339675 0.056255028 -0.8867852 -0.05401365 -0.9615863 (1,2,1,.,.) = -0.98946816 0.21851462 -0.4431965 -0.7591889 1.1842074 0.98533714 (1,2,2,.,.) = -0.12944926 0.58315176 -1.5754528 -0.93392104 -0.38259965 0.3566876 (2,1,1,.,.) = -0.1219873 -0.06568 0.5519306 0.32932717 1.4409258 0.68309426 (2,1,2,.,.) = -1.4289209 0.47897565 -1.0722001 -0.64675856 0.7097152 0.31949154 (2,2,1,.,.) = -0.89986056 -0.13643691 0.69211197 0.08849494 0.8695818 1.5527223 (2,2,2,.,.) = 1.3823601 0.36978078 0.10262361 0.05734055 -0.41569084 0.009035309 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.6374807 1.1842074 1.4409258 1.5527223 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling3D model = Sequential() model.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[ 0.8402289 0.11503692 0.27831015] [ 0.45756199 0.15043262 0.78778086]] [[ 0.37076324 0.65032926 0.74508221] [ 0.32223229 0.81980455 0.14822856]]] [[[ 0.72858223 0.04609062 0.86802821] [ 0.22619071 0.23091766 0.68856216]] [[ 0.54321111 0.94913088 0.59588331] [ 0.90821291 0.42860528 0.39355229]]]] [[[[ 0.06834657 0.41250882 0.55612858] [ 0.72871084 0.59139003 0.83317638]] [[ 0.99382906 0.24782635 0.27295274] [ 0.65663701 0.7994264 0.73672449]]] [[[ 0.11487664 0.74224294 0.39289158] [ 0.34253228 0.47903629 0.66238715]] [[ 0.13219379 0.12541975 0.93002441] [ 0.58895306 0.38519765 0.27216034]]]]] Output is: [[ 0.84022892 0.94913089] [ 0.99382907 0.93002439]] AveragePooling2D Average pooling operation for spatial data. The input of this layer should be 4D. Scala: AveragePooling2D(poolSize = (2, 2), strides = null, borderMode = valid , dimOrdering = th , inputShape = null) Python: AveragePooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension. strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.9929163 0.73885435 -0.34893242 1.1493853 -0.45246652 -0.32470804 1.2192643 0.30351913 1.3251832 0.52051955 -1.1398637 -2.427732 (1,2,.,.) = -0.5123787 -0.5055035 0.3858232 0.71986055 0.9580216 0.36081943 1.4867425 0.9852266 -0.6051215 -0.15555465 -1.4472512 0.51882136 (2,1,.,.) = -1.5209191 0.006158142 1.5162845 -0.06919313 0.56743985 -0.499725 -0.44013703 -0.12666322 0.78009427 1.9432178 1.4082893 -0.6143322 (2,2,.,.) = -1.387891 0.023748515 -0.8295103 -0.9282333 1.1375008 -1.4631946 -0.67415875 -0.7773346 -2.297338 1.0384767 1.7125391 -1.7680352 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.23864903 0.5808091 (1,2,.,.) = 0.075239725 0.89441323 (2,1,.,.) = -0.36176154 0.22007278 (2,2,.,.) = -0.4224591 -0.8023093 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AveragePooling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AveragePooling2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.23128514 0.69922098 0.52158685 0.43063779] [0.89149649 0.33910949 0.4402748 0.08933058] [0.71712488 0.21574851 0.76768248 0.57027882]] [[0.08349921 0.85318742 0.49922456 0.6256355 ] [0.22331336 0.78402155 0.91424506 0.18895412] [0.89722286 0.31067545 0.82655572 0.37775551]]] [[[0.9706926 0.28398186 0.36623623 0.23701637] [0.49936358 0.50951663 0.48116156 0.89941571] [0.06519683 0.34624179 0.2462403 0.48512833]] [[0.58408752 0.68318898 0.67886418 0.43403476] [0.87328453 0.8412756 0.59168164 0.49972216] [0.82188585 0.63685579 0.50966912 0.51439279]]]] Output is: [[[[0.540278 0.3704575 ]] [[0.48600537 0.5570148 ]]] [[[0.56588864 0.49595746]] [[0.7454592 0.5510757 ]]]] AveragePooling1D Applies average pooling operation for temporal data. The input of this layer should be 3D. Scala: AveragePooling1D(poolSize = 2, strides = -1, dimOrdering = valid , inputShape = null) Python: AveragePooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None) Parameters: poolLength : Size of the region to which average pooling is applied. Integer. Default is 2. stride : Factor by which to downscale. Positive integer, or -1. 2 will halve the input. If -1, it will default to poolLength. Default is -1, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling1D[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 2.0454981 -0.9984553 -0.22548687 -2.9674191 0.61953986 0.9267055 (2,.,.) = 0.2458116 -0.06563047 0.11032024 0.29159164 1.0789983 0.6236742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.4609605 -0.18945771 0.3506093 (2,.,.) = 0.2687016 0.50668395 0.36699724 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AveragePooling1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AveragePooling1D(input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.27910133, 0.62511864, 0.11819567], [0.60144333, 0.17082084, 0.32399398]], [[0.44947572, 0.97199261, 0.95654852], [0.72464095, 0.50742734, 0.09491157]]]) Output is: array([[[0.44027233, 0.39796975, 0.22109482]], [[0.5870583 , 0.73971 , 0.52573 ]]], dtype=float32) GlobalAveragePooling2D Applies global average pooling operation for spatial data. The input of this layer should be 4D. Scala: GlobalAveragePooling2D(dimOrdering = th , inputShape = null) Python: GlobalAveragePooling2D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3))) val input = Tensor[Float](2, 2, 3, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.3950379 0.23557353 -1.8424573 0.07449951 0.6322816 0.8831866 0.8229907 1.5395391 -0.84414214 (1,2,.,.) = 2.1792102 -1.0315448 -1.1207858 -1.1498563 1.876386 -0.67528623 0.54306036 0.7579748 0.09953801 (2,1,.,.) = -0.5101911 -1.1826278 -0.5852779 0.53600776 0.6960143 -2.8790317 -0.4959711 -1.2831435 -0.09703717 (2,2,.,.) = 0.5213661 -0.4794566 -0.48301712 0.3673898 -0.048692267 -0.043640807 -0.60638505 -0.07805356 1.2334769 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.011825972 0.16429958 -0.64458424 0.04255416 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GlobalAveragePooling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GlobalAveragePooling2D(input_shape = (2, 3, 3))) input = np.random.random([2, 2, 3, 3]) output = model.forward(input) Input is: array([[[[0.54771885, 0.53283909, 0.46927443], [0.47621227, 0.76883995, 0.52303474], [0.60008681, 0.60752329, 0.98198994]], [[0.28667601, 0.47522264, 0.4943029 ], [0.00561534, 0.39171735, 0.23420212], [0.50868123, 0.40796681, 0.82682555]]], [[[0.78836132, 0.58607316, 0.93814738], [0.34578363, 0.32976447, 0.49251034], [0.22992651, 0.04771577, 0.56071013]], [[0.34291469, 0.13181605, 0.68202722], [0.16404025, 0.54052442, 0.79312374], [0.0254005 , 0.71477398, 0.94485338]]]]) Output is: array([[0.61194664, 0.40346777], [0.47988808, 0.4821638 ]], dtype=float32)","title":"Pooling Layers"},{"location":"KerasStyleAPIGuide/Layers/pooling/#maxpooling1d","text":"Max pooling operation for temporal data. The input is 3D tensor with shape:(batch_size, steps, feature_dim). Scala: MaxPooling1D(poolLength = 2, stride = -1, borderMode = valid , inputShape = null) Python: MaxPooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None) Parameters: poolLength : Size of the region to which max pooling is applied. Integer. Default is 2. stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength. borderMode : Either 'valid' or 'same'. Default is 'valid'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential val model = Sequential[Float]() model.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5))) val input = Tensor[Float](3, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -1.2339195 -1.2134796 0.16991705 -0.10169973 -1.2464932 0.37946555 0.29533234 -1.2552645 -2.6928735 -0.44519955 0.98743796 -1.0912303 -0.13897413 1.0241779 -0.5951304 -0.31459442 -0.088579334 -0.58336115 -0.6427486 -0.1447043 (2,.,.) = 0.14750746 0.07493488 -0.8554524 -1.6551514 0.16679412 -0.82279974 0.25704315 0.09921734 -0.8135057 2.7640774 -1.0111052 0.34388593 -0.7569789 1.0547938 1.6738676 0.4396624 -1.0570261 0.061429325 1.1752373 -0.14648575 (3,.,.) = -0.95818335 0.8790822 -0.99111855 -0.9717616 -0.39238095 1.2533073 0.23365906 1.7784269 1.0600376 1.6816885 0.7145845 0.4711851 -0.4465603 -0.77884597 0.484986 0.42429695 -2.00715 0.6520644 1.3022201 -0.48169184 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = 0.98743796 0.29533234 0.16991705 1.0241779 -0.44519955 (2,.,.) = 0.14750746 0.34388593 0.09921734 1.0547938 2.7640774 (3,.,.) = 1.2533073 0.8790822 1.7784269 1.0600376 1.6816885 [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import MaxPooling1D model = Sequential() model.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5))) input = np.random.random([3, 4, 5]) output = model.forward(input) Input is: [[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192] [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637] [0.24147633 0.2116796 0.54433489 0.22961905 0.88685975] [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]] [[0.42306184 0.43404804 0.22141668 0.0316458 0.08445576] [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813] [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895] [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]] [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853] [0.9950283 0.55710408 0.70919634 0.52309929 0.14311439] [0.25394468 0.41519219 0.8074057 0.05341861 0.98447171] [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]] Output is: [[[0.27837703 0.8728293 0.9429287 0.48428997 0.8868598 ]] [[0.9070284 0.43404803 0.52975726 0.43238723 0.50049895]] [[0.9950283 0.99869156 0.877897 0.6784016 0.98447174]]]","title":"MaxPooling1D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#maxpooling2d","text":"Max pooling operation for spatial data. The input is 4D tensor with shape:(batch_size, rows, cols, channels). Scala: MaxPooling2D(poolSize = (2, 2), strides = null, borderMode = valid , dimOrdering = th , inputShape = null) Python: MaxPooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension. strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.bigdl.tensor.Tensor import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D val model = Sequential[Float]() model.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.02138003 -0.20666665 -0.93250555 0.41267508 -0.40883347 0.4919021 0.7189889 1.3442185 -0.08697278 -0.025719838 2.1126 0.69069535 (1,2,.,.) = -0.1685801 -0.07843445 1.3499486 -0.5944459 0.29377022 0.061167963 -0.60608864 -0.08283464 0.03402891 -1.0627178 1.9463096 0.0011169242 (2,1,.,.) = -1.4524128 1.3868454 2.3057284 1.574949 -1.165581 0.79445213 -0.63500565 -0.17981622 -0.98042095 -1.7876958 0.8024988 -0.90554804 (2,2,.,.) = -1.6468426 1.1864686 -0.683854 -1.5643677 2.8272789 -0.5537863 -0.563258 -0.01623243 -0.31333938 0.03472893 -1.730748 -0.15463233 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: (1,1,.,.) = 0.4919021 1.3442185 (1,2,.,.) = 0.29377022 1.3499486 (2,1,.,.) = 1.3868454 2.3057284 (2,2,.,.) = 2.8272789 -0.01623243 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2] Python example: import numpy as np from bigdl.nn.keras.topology import Sequential from bigdl.nn.keras.layer import MaxPooling2D model = Sequential() model.add(MaxPooling2D(input_shape = (2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.58589442 0.94643201 0.24779969 0.55347075] [0.50604116 0.69884915 0.81253572 0.58586743] [0.94560389 0.11573268 0.12562681 0.63301697]] [[0.11736968 0.75641404 0.19342809 0.37670404] [0.55561582 0.54354621 0.9506264 0.65929266] [0.72911388 0.00499644 0.24280364 0.28822998]]] [[[0.53249492 0.43969012 0.20407128 0.49541971] [0.00369797 0.75294821 0.15204289 0.41394393] [0.19416915 0.93034988 0.0358259 0.38001445]] [[0.88946341 0.30646232 0.5347175 0.87568066] [0.00439823 0.97792811 0.34842225 0.20433116] [0.42777728 0.93583737 0.54341935 0.31203758]]]] Output is: [[[[0.946432 0.8125357 ]] [[0.75641406 0.95062643]]] [[[0.7529482 0.4954197 ]] [[0.9779281 0.8756807 ]]]]","title":"MaxPooling2D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#averagepooling3d","text":"Applies average pooling operation for 3D data (spatial or spatio-temporal). Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels). Scala: AveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = th , inputShape = null) Python: AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension. strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize. dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.71569425 -0.39595184 -0.47607258 -0.12621938 -0.66759187 0.86833215 (1,1,2,.,.) = 1.219894 -0.07514859 0.6606987 0.073906526 -1.2547257 -0.49249622 (1,2,1,.,.) = -1.0730773 0.2780401 -0.8603222 -0.31499937 0.94786566 -1.6953986 (1,2,2,.,.) = 0.31038517 1.7660809 -0.9849316 -1.5245554 0.24002236 0.473947 (2,1,1,.,.) = -0.988634 -0.0028023662 -2.1534977 0.58303267 0.72106487 0.22115333 (2,1,2,.,.) = 1.3964092 -0.59152335 -0.6552192 2.0191588 -0.32599944 0.84014076 (2,2,1,.,.) = 1.4505147 -2.4253457 -0.37597662 -0.7049585 1.3384854 -1.1081233 (2,2,2,.,.) = -0.8498942 1.169977 0.78120154 0.13814813 -0.7438999 -0.9272572 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = -0.24269137 (1,2,1,.,.) = 0.07872025 (2,1,1,.,.) = 0.3513383 (2,2,1,.,.) = -0.078371644 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import AveragePooling3D model = Sequential() model.add(AveragePooling3D(input_shape = (2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[0.95796698 0.76067104 0.47285625] [0.90296063 0.64177821 0.23302549]] [[0.37135542 0.38455108 0.66999497] [0.06756778 0.16411331 0.39038159]]] [[[0.9884323 0.97861344 0.69852249] [0.53289779 0.51290587 0.54822396]] [[0.77241923 0.06470524 0.00757586] [0.65977832 0.31973607 0.7551191 ]]]] [[[[0.56819589 0.20398916 0.26409867] [0.81165023 0.65269175 0.16519667]] [[0.7350688 0.52442381 0.29116889] [0.45458689 0.29734681 0.39667421]]] [[[0.33577239 0.54035235 0.41285576] [0.01023886 0.23677996 0.18901205]] [[0.67638612 0.54170351 0.0068781 ] [0.95769069 0.88558419 0.4262852 ]]]]] Output is: [[[[[0.5313706 ]]] [[[0.603686 ]]]] [[[[0.5309942 ]]] [[[0.52306354]]]]]","title":"AveragePooling3D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling1d","text":"Global max pooling operation for temporal data. The input is 3D with the shape:(batch_size, steps, features). Scala: GlobalMaxPooling1D(inputShape = null) Python: GlobalMaxPooling1D(input_shape=None, name=None) Parameters: inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 1.2998451 2.1855159 -0.05535197 -0.6448657 0.74119943 -0.8761581 (2,.,.) = 1.3994918 -1.5119147 -0.6625015 1.803635 -2.2516544 -0.016894706 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.2998451 2.1855159 -0.05535197 1.803635 -1.5119147 -0.016894706 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling1D model = Sequential() model.add(GlobalMaxPooling1D(input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.05589183 0.73674405 0.49270549] [0.03348098 0.82000941 0.81752936]] [[0.97310222 0.8878789 0.72330625] [0.86144601 0.88568162 0.47241316]]] Output is: [[0.05589183 0.8200094 0.8175294 ] [0.9731022 0.8878789 0.72330624]]","title":"GlobalMaxPooling1D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#maxpooling3d","text":"Applies max pooling operation for 3D data (spatial or spatio-temporal). Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input of this layer should be 5D. Scala: MaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = th , inputShape = null) Python: MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension. strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize. dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = -0.5052603 0.8938585 0.44785392 -0.48919395 0.35026026 0.541859 (1,1,2,.,.) = 1.5306468 0.24512683 1.71524 -0.49025944 2.1886358 0.15880944 (1,2,1,.,.) = -0.5133986 -0.16549884 -0.2971134 1.5887301 1.8269571 1.3843931 (1,2,2,.,.) = 0.07515256 1.6993935 -0.3392596 1.2611006 0.20215735 1.3105171 (2,1,1,.,.) = -2.0070438 0.35554957 0.21326075 -0.4078646 -1.5748956 -1.1007504 (2,1,2,.,.) = 1.0571382 -1.6031493 1.4638771 -0.25891435 1.4923956 -0.24045596 (2,2,1,.,.) = -0.57790893 0.14577095 1.3165486 0.81937057 -0.3797079 1.2544848 (2,2,2,.,.) = -0.42183575 -0.63774794 -2.0576336 0.43662143 1.9010457 -0.061519064 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,1,.,.) = 2.1886358 (1,2,1,.,.) = 1.8269571 (2,1,1,.,.) = 1.4923956 (2,2,1,.,.) = 1.9010457 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1] Python example: import numpy as np from zoo.pipeline.api.keras.layers import MaxPooling3D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(MaxPooling3D(input_shape=(2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[0.73349746 0.9811588 0.86071417] [0.33287621 0.37991739 0.87029317]] [[0.62537904 0.48099174 0.06194759] [0.38747972 0.05175308 0.36096032]]] [[[0.63260385 0.69990236 0.63353249] [0.19081261 0.56210617 0.75985185]] [[0.8624058 0.47224318 0.26524027] [0.75317792 0.39251436 0.98938982]]]] [[[[0.00556086 0.18833728 0.80340438] [0.9317538 0.88142596 0.90724509]] [[0.90243612 0.04594116 0.43662143] [0.24205094 0.58687822 0.57977055]]] [[[0.17240398 0.18346483 0.02520754] [0.06968248 0.02442692 0.56078895]] [[0.69503427 0.09528588 0.46104647] [0.16752596 0.88175901 0.71032998]]]]] Output is: [[[[[0.9811588]]] [[[0.8624058]]]] [[[[0.9317538]]] [[[0.881759 ]]]]]","title":"MaxPooling3D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling2d","text":"Global max pooling operation for spatial data. The input of this layer should be 4D. Scala: GlobalMaxPooling2D(dimOrdering = th , inputShape = null) Python: GlobalMaxPooling2D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.12648843 0.15536028 1.3401515 -0.25693455 0.6002777 0.6886729 -1.0650102 -0.22140503 -0.7598008 0.8800106 -0.061039474 -1.3625065 (1,2,.,.) = -0.37492484 -0.6727478 -0.12211597 1.3243467 -0.72237 0.6942101 -1.455304 -0.23814173 -0.38509718 -0.9179013 -0.99926376 0.18432678 (2,1,.,.) = 0.4457857 -0.36717635 -0.6653158 -1.9075912 -0.49489713 -0.70543754 0.85306334 0.21031244 0.08930698 0.046588574 0.9523686 -0.87959886 (2,2,.,.) = -0.8523849 0.55808693 -1.5779148 1.312412 -0.9923541 -0.562809 1.1512411 0.33178216 1.056546 -2.0607772 -0.8233232 0.024466092 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.3401515 1.3243467 0.9523686 1.312412 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling2D model = Sequential() model.add(GlobalMaxPooling2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.82189558 0.20668687 0.84669433 0.58740261] - [0.33005685 0.93836385 0.51005935 0.11894048] - [0.39757919 0.17126568 0.38237808 0.35911186]] - - [[0.98544456 0.10949685 0.47642379 0.21039236] - [0.51058537 0.9625007 0.2519618 0.03186033] - [0.28042435 0.08481816 0.37535567 0.60848855]]] - - - [[[0.34468892 0.48365864 0.01397789 0.16565704] - [0.91387839 0.78507728 0.0912983 0.06167101] - [0.49026863 0.17870698 0.43566122 0.79984653]] - - [[0.15157888 0.07546447 0.47063241 0.46052913] - [0.92483801 0.51271677 0.45300461 0.40369727] - [0.94152848 0.61306339 0.43241425 0.88775481]]]] Output is: [[0.93836385 0.98544455] - [0.9138784 0.9415285 ]]","title":"GlobalMaxPooling2D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling3d","text":"Applies global max pooling operation for 3D data. Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th'). Border mode currently supported for this layer is 'valid'. The input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels). The output of this layer should be 2D, i.e. (batch_size, channels). Scala: GlobalMaxPooling3D(dimOrdering = th , inputShape = null) Python: GlobalMaxPooling3D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3))) val input = Tensor[Float](2, 2, 2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,1,.,.) = 0.50938565 1.6374807 0.8158744 -0.3293317 -0.17766304 0.9067782 (1,1,2,.,.) = 1.5450556 -1.0339675 0.056255028 -0.8867852 -0.05401365 -0.9615863 (1,2,1,.,.) = -0.98946816 0.21851462 -0.4431965 -0.7591889 1.1842074 0.98533714 (1,2,2,.,.) = -0.12944926 0.58315176 -1.5754528 -0.93392104 -0.38259965 0.3566876 (2,1,1,.,.) = -0.1219873 -0.06568 0.5519306 0.32932717 1.4409258 0.68309426 (2,1,2,.,.) = -1.4289209 0.47897565 -1.0722001 -0.64675856 0.7097152 0.31949154 (2,2,1,.,.) = -0.89986056 -0.13643691 0.69211197 0.08849494 0.8695818 1.5527223 (2,2,2,.,.) = 1.3823601 0.36978078 0.10262361 0.05734055 -0.41569084 0.009035309 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 1.6374807 1.1842074 1.4409258 1.5527223 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.models import Sequential from zoo.pipeline.api.keras.layers import GlobalMaxPooling3D model = Sequential() model.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3))) input = np.random.random([2, 2, 2, 2, 3]) output = model.forward(input) Input is: [[[[[ 0.8402289 0.11503692 0.27831015] [ 0.45756199 0.15043262 0.78778086]] [[ 0.37076324 0.65032926 0.74508221] [ 0.32223229 0.81980455 0.14822856]]] [[[ 0.72858223 0.04609062 0.86802821] [ 0.22619071 0.23091766 0.68856216]] [[ 0.54321111 0.94913088 0.59588331] [ 0.90821291 0.42860528 0.39355229]]]] [[[[ 0.06834657 0.41250882 0.55612858] [ 0.72871084 0.59139003 0.83317638]] [[ 0.99382906 0.24782635 0.27295274] [ 0.65663701 0.7994264 0.73672449]]] [[[ 0.11487664 0.74224294 0.39289158] [ 0.34253228 0.47903629 0.66238715]] [[ 0.13219379 0.12541975 0.93002441] [ 0.58895306 0.38519765 0.27216034]]]]] Output is: [[ 0.84022892 0.94913089] [ 0.99382907 0.93002439]]","title":"GlobalMaxPooling3D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#averagepooling2d","text":"Average pooling operation for spatial data. The input of this layer should be 4D. Scala: AveragePooling2D(poolSize = (2, 2), strides = null, borderMode = valid , dimOrdering = th , inputShape = null) Python: AveragePooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None) Parameters: poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension. strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4))) val input = Tensor[Float](2, 2, 3, 4).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = 0.9929163 0.73885435 -0.34893242 1.1493853 -0.45246652 -0.32470804 1.2192643 0.30351913 1.3251832 0.52051955 -1.1398637 -2.427732 (1,2,.,.) = -0.5123787 -0.5055035 0.3858232 0.71986055 0.9580216 0.36081943 1.4867425 0.9852266 -0.6051215 -0.15555465 -1.4472512 0.51882136 (2,1,.,.) = -1.5209191 0.006158142 1.5162845 -0.06919313 0.56743985 -0.499725 -0.44013703 -0.12666322 0.78009427 1.9432178 1.4082893 -0.6143322 (2,2,.,.) = -1.387891 0.023748515 -0.8295103 -0.9282333 1.1375008 -1.4631946 -0.67415875 -0.7773346 -2.297338 1.0384767 1.7125391 -1.7680352 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,1,.,.) = 0.23864903 0.5808091 (1,2,.,.) = 0.075239725 0.89441323 (2,1,.,.) = -0.36176154 0.22007278 (2,2,.,.) = -0.4224591 -0.8023093 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AveragePooling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AveragePooling2D(input_shape=(2, 3, 4))) input = np.random.random([2, 2, 3, 4]) output = model.forward(input) Input is: [[[[0.23128514 0.69922098 0.52158685 0.43063779] [0.89149649 0.33910949 0.4402748 0.08933058] [0.71712488 0.21574851 0.76768248 0.57027882]] [[0.08349921 0.85318742 0.49922456 0.6256355 ] [0.22331336 0.78402155 0.91424506 0.18895412] [0.89722286 0.31067545 0.82655572 0.37775551]]] [[[0.9706926 0.28398186 0.36623623 0.23701637] [0.49936358 0.50951663 0.48116156 0.89941571] [0.06519683 0.34624179 0.2462403 0.48512833]] [[0.58408752 0.68318898 0.67886418 0.43403476] [0.87328453 0.8412756 0.59168164 0.49972216] [0.82188585 0.63685579 0.50966912 0.51439279]]]] Output is: [[[[0.540278 0.3704575 ]] [[0.48600537 0.5570148 ]]] [[[0.56588864 0.49595746]] [[0.7454592 0.5510757 ]]]]","title":"AveragePooling2D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#averagepooling1d","text":"Applies average pooling operation for temporal data. The input of this layer should be 3D. Scala: AveragePooling1D(poolSize = 2, strides = -1, dimOrdering = valid , inputShape = null) Python: AveragePooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None) Parameters: poolLength : Size of the region to which average pooling is applied. Integer. Default is 2. stride : Factor by which to downscale. Positive integer, or -1. 2 will halve the input. If -1, it will default to poolLength. Default is -1, and in this case it will be equal to poolSize. borderMode : Either 'valid' or 'same'. Default is 'valid'. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(AveragePooling1D[Float](inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 2.0454981 -0.9984553 -0.22548687 -2.9674191 0.61953986 0.9267055 (2,.,.) = 0.2458116 -0.06563047 0.11032024 0.29159164 1.0789983 0.6236742 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = (1,.,.) = -0.4609605 -0.18945771 0.3506093 (2,.,.) = 0.2687016 0.50668395 0.36699724 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import AveragePooling1D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(AveragePooling1D(input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[0.27910133, 0.62511864, 0.11819567], [0.60144333, 0.17082084, 0.32399398]], [[0.44947572, 0.97199261, 0.95654852], [0.72464095, 0.50742734, 0.09491157]]]) Output is: array([[[0.44027233, 0.39796975, 0.22109482]], [[0.5870583 , 0.73971 , 0.52573 ]]], dtype=float32)","title":"AveragePooling1D"},{"location":"KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling2d","text":"Applies global average pooling operation for spatial data. The input of this layer should be 4D. Scala: GlobalAveragePooling2D(dimOrdering = th , inputShape = null) Python: GlobalAveragePooling2D(dim_ordering= th , input_shape=None, name=None) Parameters: dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3))) val input = Tensor[Float](2, 2, 3, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,1,.,.) = -1.3950379 0.23557353 -1.8424573 0.07449951 0.6322816 0.8831866 0.8229907 1.5395391 -0.84414214 (1,2,.,.) = 2.1792102 -1.0315448 -1.1207858 -1.1498563 1.876386 -0.67528623 0.54306036 0.7579748 0.09953801 (2,1,.,.) = -0.5101911 -1.1826278 -0.5852779 0.53600776 0.6960143 -2.8790317 -0.4959711 -1.2831435 -0.09703717 (2,2,.,.) = 0.5213661 -0.4794566 -0.48301712 0.3673898 -0.048692267 -0.043640807 -0.60638505 -0.07805356 1.2334769 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.011825972 0.16429958 -0.64458424 0.04255416 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GlobalAveragePooling2D from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GlobalAveragePooling2D(input_shape = (2, 3, 3))) input = np.random.random([2, 2, 3, 3]) output = model.forward(input) Input is: array([[[[0.54771885, 0.53283909, 0.46927443], [0.47621227, 0.76883995, 0.52303474], [0.60008681, 0.60752329, 0.98198994]], [[0.28667601, 0.47522264, 0.4943029 ], [0.00561534, 0.39171735, 0.23420212], [0.50868123, 0.40796681, 0.82682555]]], [[[0.78836132, 0.58607316, 0.93814738], [0.34578363, 0.32976447, 0.49251034], [0.22992651, 0.04771577, 0.56071013]], [[0.34291469, 0.13181605, 0.68202722], [0.16404025, 0.54052442, 0.79312374], [0.0254005 , 0.71477398, 0.94485338]]]]) Output is: array([[0.61194664, 0.40346777], [0.47988808, 0.4821638 ]], dtype=float32)","title":"GlobalAveragePooling2D"},{"location":"KerasStyleAPIGuide/Layers/recurrent/","text":"SimpleRNN A fully-connected recurrent neural network cell. The output is to be fed back to input. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: SimpleRNN(outputDim, activation = tanh , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: SimpleRNN(output_dim, activation= tanh , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SimpleRNN[Float](8, activation = relu , inputShape = Shape(4, 5))) val input = Tensor[Float](2, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.71328646 0.24269831 -0.75013286 -1.6663225 0.35494477 0.073439054 -1.1181073 -0.6577777 1.3154761 0.15396282 0.41183218 -1.2667576 -0.11167632 0.946616 0.06427766 0.013886308 -0.20620999 1.1173447 1.9083043 1.7680032 (2,.,.) = -2.3510098 -0.8492037 0.042268332 -0.43801674 -0.010638754 1.298793 -0.24814601 0.31325665 -0.19119295 -2.072075 -0.11629801 0.27296612 0.94443846 0.37293285 -0.82289046 0.6044998 0.93386084 -1.3502276 -1.7753356 1.6173482 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.0 0.020557694 0.0 0.39700085 0.622244 0.0 0.36524248 0.88961613 0.0 1.4797685 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SimpleRNN from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SimpleRNN(8, activation= relu , input_shape=(4, 5))) input = np.random.random([2, 4, 5]) output = model.forward(input) Input is: [[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231] [0.2162183 0.33225502 0.09725628 0.80813221 0.29556109] [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253] [0.36175687 0.63291153 0.08437936 0.71581099 0.790709 ]] [[0.35387003 0.36532078 0.9834315 0.07562338 0.05600369] [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385] [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574] [0.80773506 0.35121494 0.66889362 0.530684 0.52066982]]] Output is: [[0.77534926 0.23742369 0.14946866 0.0 0.16289112 0.0 0.71689016 0.24594748] [0.8987881 0.06123672 0.3312829 0.29757586 0.0 0.0 1.0179179 0.23447856]] LSTM Long Short Term Memory unit architecture. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: LSTM(outputDim, activation = tanh , innerActivation = hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: LSTM(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. innerActivation : String representation of the activation function for inner cells. See here for available activation strings. Default is 'hard_sigmoid'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LSTM[Float](8, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.6857518 0.21570909 -0.019308459 0.17754157 0.25172755 -1.189466 (2,.,.) = 0.23807438 1.6879119 -0.36335373 0.9826865 0.49549296 0.8100107 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.13552098 -0.043483295 -0.10553853 0.19386405 0.18295142 0.037892513 -0.05510225 -0.2420117 -0.04152686 -0.13908584 0.18151914 0.14170776 0.15598273 0.18968433 -0.042683482 -0.05782121 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LSTM from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LSTM(8, input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[ 0.67619723, 0.5168176 , 0.8093504 ], [ 0.93787417, 0.53016934, 0.51934568]], [[ 0.57334472, 0.40007739, 0.65670337], [ 0.74457042, 0.15209156, 0.02015092]]]) Output is: array([[-0.01563799, 0.16000053, -0.20192699, 0.08859081, -0.14184587, 0.11160418, 0.19090165, 0.03475797], [-0.02395577, 0.10148412, -0.13211192, 0.05772379, -0.16488783, 0.13513438, 0.15624164, 0.02866406]], dtype=float32) GRU Gated Recurrent Unit architecture. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: GRU(outputDim, activation = tanh , innerActivation = hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: GRU(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. innerActivation : String representation of the activation function for inner cells. See here for available activation strings. Default is 'hard_sigmoid'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.GRU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GRU[Float](8, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.010477358 -1.1201298 -0.86472356 0.12688802 -0.6696582 0.08027417 (2,.,.) = 0.1724209 -0.52319324 -0.8808063 0.17918338 -0.552886 -0.11891741 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.12018716 -0.31560755 0.2867627 0.6728765 0.13287778 0.2112865 0.13381396 -0.4267934 -0.18521798 -0.30512968 0.14875418 0.63962734 0.1841841 0.25272882 0.016909363 -0.38463163 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GRU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GRU(8, input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.25026651 0.35433442 0.01417391] [0.77236921 0.97315472 0.66090386]] [[0.76037554 0.41029034 0.68725938] [0.17888889 0.67670088 0.70580547]]] Output is: [[-0.03584666 0.07984452 -0.06159414 -0.13331707 0.34015405 -0.07107028 0.12444386 -0.06606203] [ 0.02881907 0.04856917 -0.15306929 -0.24991018 0.23814955 0.0303434 0.06634206 -0.15335503]] Highway Densely connected highway network. Highway layers are a natural extension of LSTMs to feedforward networks. The input of this layer should be 2D, i.e. (batch, input dim). Scala: Highway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Highway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: activation : String representation of the activation function to use. See here for available activation strings. Default is null. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Highway import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Highway[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.26041138 0.4286919 1.723103 1.4516269 0.5557163 -0.1149741 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.006746907 -0.109112576 1.3375516 0.6065166 0.41575465 -0.06849813 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Highway from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Highway(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.5762107 0.45679288 0.00370956] [0.24133312 0.38104653 0.05249192]] Output is: [[0.5762107 0.4567929 0.00370956] [0.24133313 0.38104653 0.05249191]]","title":"Recurrent Layers"},{"location":"KerasStyleAPIGuide/Layers/recurrent/#simplernn","text":"A fully-connected recurrent neural network cell. The output is to be fed back to input. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: SimpleRNN(outputDim, activation = tanh , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: SimpleRNN(output_dim, activation= tanh , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(SimpleRNN[Float](8, activation = relu , inputShape = Shape(4, 5))) val input = Tensor[Float](2, 4, 5).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.71328646 0.24269831 -0.75013286 -1.6663225 0.35494477 0.073439054 -1.1181073 -0.6577777 1.3154761 0.15396282 0.41183218 -1.2667576 -0.11167632 0.946616 0.06427766 0.013886308 -0.20620999 1.1173447 1.9083043 1.7680032 (2,.,.) = -2.3510098 -0.8492037 0.042268332 -0.43801674 -0.010638754 1.298793 -0.24814601 0.31325665 -0.19119295 -2.072075 -0.11629801 0.27296612 0.94443846 0.37293285 -0.82289046 0.6044998 0.93386084 -1.3502276 -1.7753356 1.6173482 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.0 0.020557694 0.0 0.39700085 0.622244 0.0 0.36524248 0.88961613 0.0 1.4797685 0.0 0.0 0.0 0.0 0.0 0.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import SimpleRNN from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(SimpleRNN(8, activation= relu , input_shape=(4, 5))) input = np.random.random([2, 4, 5]) output = model.forward(input) Input is: [[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231] [0.2162183 0.33225502 0.09725628 0.80813221 0.29556109] [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253] [0.36175687 0.63291153 0.08437936 0.71581099 0.790709 ]] [[0.35387003 0.36532078 0.9834315 0.07562338 0.05600369] [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385] [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574] [0.80773506 0.35121494 0.66889362 0.530684 0.52066982]]] Output is: [[0.77534926 0.23742369 0.14946866 0.0 0.16289112 0.0 0.71689016 0.24594748] [0.8987881 0.06123672 0.3312829 0.29757586 0.0 0.0 1.0179179 0.23447856]]","title":"SimpleRNN"},{"location":"KerasStyleAPIGuide/Layers/recurrent/#lstm","text":"Long Short Term Memory unit architecture. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: LSTM(outputDim, activation = tanh , innerActivation = hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: LSTM(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. innerActivation : String representation of the activation function for inner cells. See here for available activation strings. Default is 'hard_sigmoid'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. name : String to set the name of the layer. If not specified, its name will by default to be a generated string. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(LSTM[Float](8, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = 0.6857518 0.21570909 -0.019308459 0.17754157 0.25172755 -1.189466 (2,.,.) = 0.23807438 1.6879119 -0.36335373 0.9826865 0.49549296 0.8100107 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.13552098 -0.043483295 -0.10553853 0.19386405 0.18295142 0.037892513 -0.05510225 -0.2420117 -0.04152686 -0.13908584 0.18151914 0.14170776 0.15598273 0.18968433 -0.042683482 -0.05782121 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import LSTM from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(LSTM(8, input_shape = (2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: array([[[ 0.67619723, 0.5168176 , 0.8093504 ], [ 0.93787417, 0.53016934, 0.51934568]], [[ 0.57334472, 0.40007739, 0.65670337], [ 0.74457042, 0.15209156, 0.02015092]]]) Output is: array([[-0.01563799, 0.16000053, -0.20192699, 0.08859081, -0.14184587, 0.11160418, 0.19090165, 0.03475797], [-0.02395577, 0.10148412, -0.13211192, 0.05772379, -0.16488783, 0.13513438, 0.15624164, 0.02866406]], dtype=float32)","title":"LSTM"},{"location":"KerasStyleAPIGuide/Layers/recurrent/#gru","text":"Gated Recurrent Unit architecture. The input of this layer should be 3D, i.e. (batch, time steps, input dim). Scala: GRU(outputDim, activation = tanh , innerActivation = hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null) Python: GRU(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None) Parameters: outputDim : Hidden unit size. Dimension of internal projections and final output. activation : String representation of the activation function to use. See here for available activation strings. Default is 'tanh'. innerActivation : String representation of the activation function for inner cells. See here for available activation strings. Default is 'hard_sigmoid'. returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false. goBackwards : Whether the input sequence will be processed backwards. Default is false. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. uRegularizer : An instance of Regularizer , applied the recurrent weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.GRU import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(GRU[Float](8, inputShape = Shape(2, 3))) val input = Tensor[Float](2, 2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = (1,.,.) = -0.010477358 -1.1201298 -0.86472356 0.12688802 -0.6696582 0.08027417 (2,.,.) = 0.1724209 -0.52319324 -0.8808063 0.17918338 -0.552886 -0.11891741 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.12018716 -0.31560755 0.2867627 0.6728765 0.13287778 0.2112865 0.13381396 -0.4267934 -0.18521798 -0.30512968 0.14875418 0.63962734 0.1841841 0.25272882 0.016909363 -0.38463163 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8] Python example: import numpy as np from zoo.pipeline.api.keras.layers import GRU from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(GRU(8, input_shape=(2, 3))) input = np.random.random([2, 2, 3]) output = model.forward(input) Input is: [[[0.25026651 0.35433442 0.01417391] [0.77236921 0.97315472 0.66090386]] [[0.76037554 0.41029034 0.68725938] [0.17888889 0.67670088 0.70580547]]] Output is: [[-0.03584666 0.07984452 -0.06159414 -0.13331707 0.34015405 -0.07107028 0.12444386 -0.06606203] [ 0.02881907 0.04856917 -0.15306929 -0.24991018 0.23814955 0.0303434 0.06634206 -0.15335503]]","title":"GRU"},{"location":"KerasStyleAPIGuide/Layers/recurrent/#highway","text":"Densely connected highway network. Highway layers are a natural extension of LSTMs to feedforward networks. The input of this layer should be 2D, i.e. (batch, input dim). Scala: Highway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null) Python: Highway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None) Parameters: activation : String representation of the activation function to use. See here for available activation strings. Default is null. wRegularizer : An instance of Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null. bRegularizer : An instance of Regularizer , applied to the bias. Default is null. bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.Highway import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() model.add(Highway[Float](inputShape = Shape(3))) val input = Tensor[Float](2, 3).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = -0.26041138 0.4286919 1.723103 1.4516269 0.5557163 -0.1149741 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = -0.006746907 -0.109112576 1.3375516 0.6065166 0.41575465 -0.06849813 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3] Python example: import numpy as np from zoo.pipeline.api.keras.layers import Highway from zoo.pipeline.api.keras.models import Sequential model = Sequential() model.add(Highway(input_shape=(3, ))) input = np.random.random([2, 3]) output = model.forward(input) Input is: [[0.5762107 0.45679288 0.00370956] [0.24133312 0.38104653 0.05249192]] Output is: [[0.5762107 0.4567929 0.00370956] [0.24133313 0.38104653 0.05249191]]","title":"Highway"},{"location":"KerasStyleAPIGuide/Layers/self-attention/","text":"TransformerLayer A network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Refer https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf Input is a Table which consists of 2 tensors. 1. Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary 2. Position id tensor: shape (batch, seqLen) with positions in the sentence. Output is a Tensor which output the states of Transformer layer With Default Embedding: Scala: TransformerLayer[Float](vocab = 40990, seqLen = 77, nBlock = 12, residPdrop = 0.1, attnPdrop = 0.1, nHead = 12, hiddenSize = 768, embeddingDrop = 0, initializerRange = 0.02, bidirectional = false, outputAllBlock = false) Python: TransformerLayer.init(vocab=40990, seq_len=77, n_block=12, hidden_drop=0.1, attn_drop=0.1, n_head=12, hidden_size=768, embedding_drop=0.1, initializer_range=0.02, bidirectional=False, output_all_block=False) Parameters: vocab : vocabulary size of training data, default is 40990 seqLen : max sequence length of training data, default is 77 nBlock : block number, default is 12 residPdrop : drop probability of projection, default is 0.1 attnPdrop : drop probability of attention, default is 0.1 nHead : head number, default is 12 hiddenSize : is also embedding size embeddingDrop : drop probability of embedding layer, default is 0.1 initializerRange : weight initialization range, default is 0.02 bidirectional : whether unidirectional or bidirectional, default is false * outputAllBlock : whether output all blocks' output, default is false With Customized Embedding: Scala: TransformerLayer[Float](nBlock = 3, residPdrop = 0.1, attnPdrop = 0.1, nHead = 12, bidirectional = false, initializerRange = 0.02, outputAllBlock = true, embeddingLayer = embedding.asInstanceOf[KerasLayer[Activity, Tensor[Float], Float]]) Python: TransformerLayer(n_block=12, hidden_drop=0.1, attn_drop=0.1, n_head=12, initializer_range=0.02, bidirectional=False, output_all_block=False, embedding_layer=embedding, input_shape=((seq_len,), (seq_len,)), intermediate_size=0) Parameters: nBlock : block number residPdrop : drop probability of projection attnPdrop : drop probability of attention nHead : head number initializerRange : weight initialization range bidirectional : whether unidirectional or bidirectional outputAllBlock : whether output all blocks' output embeddingLayer : embedding layer Scala example: val shape1 = Shape(20) val shape2 = Shape(20) val input1 = Variable[Float](shape1) val input2 = Variable[Float](shape2) val input = Array(input1, input2) val seq = TransformerLayer[Float](200, hiddenSize = 128, nHead = 8, seqLen = 20, nBlock = 1).from(input: _*) val model = Model[Float](input, seq) val trainToken = Tensor[Float](1, 20).rand() val trainPos = Tensor.ones[Float](1, 20) val input3 = T(trainToken, trainPos) val output = model.forward(input3) Input is: { 2: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x20] 1: 0.8087359 0.16409875 0.7404631 0.4836999 0.034994964 0.033039592 0.6694243 0.84700763 0.32154092 0.17410904 0.66117364 0.30495027 0.19573595 0.058101892 0.65923077 0.84077805 0.50113535 0.48393667 0.06523132 0.0667426 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20] } Output is: { 2: 0.83383083 0.72725344 0.16394942 -0.79005975 0.8877357 -0.9060916 -0.6796065 0.46835706 -0.4700584 0.43868023 0.6641587 0.6711142 -0.70056283 -0.42694178 0.7615595 -0.25590983 0.21654142 0.35254374 0.83790034 0.1103606 -0.20419843 -0.9739706 0.6150182 0.4499923 0.3355538 -0.01543447 -0.99528116 0.45984524 -0.22544041 0.10049125 0.8418835 -0.116228305 -0.112435654 0.5183222 -0.59375525 0.31828925 0.50506884 0.14892755 0.94327587 -0.19001998 0.54074824 -0.07616825 -0.79334164 -0.49726814 0.23889944 -0.91731304 -0.5484148 0.5048103 0.9743351 0.10505025 0.81167877 -0.47498485 -0.83443964 -0.89340115 0.6443838 0.10184191 -0.38618097 -0.32026938 0.51587516 -0.40602723 -0.2931675 -0.86100364 0.109585665 0.9023708 0.46609795 0.0028693299 -0.5746851 -0.45607233 -0.9075561 -0.91294044 0.8077997 0.23019081 0.51124465 -0.39125186 0.16946821 -0.36827865 -0.32563296 0.62560886 -0.7278883 0.8076773 0.89344263 -0.9259615 0.21476166 0.67077845 0.5857905 -0.32905066 -0.16318946 0.6435858 -0.28905967 -0.6991412 -0.5289766 -0.6954091 0.1577004 0.5618301 -0.6290018 0.114078626 -0.52474076 0.27916297 -0.76610357 0.67119384 -0.4308661 0.063731246 -0.5281069 -0.65910465 0.5383283 -0.2875557 0.24594739 -0.6789035 0.7002648 -0.64659894 -0.70994437 -0.8416273 0.4666695 -0.55062526 0.14995292 -0.978979 0.40934727 -0.9028927 0.38194665 0.2334618 -0.9481384 -0.51903373 -0.947906 0.2667679 -0.76987743 -0.7490675 0.6777159 0.9593161 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x128] 1: (1,.,.) = 0.8369983 -0.9907519 0.74404025 ... 0.6154673 0.107825294 -0.806892 0.7676861 -0.962961 0.73240614 ... 0.534349 0.0049344404 -0.81643736 0.7487803 -0.9717681 0.7315394 ... 0.59831613 0.010904985 -0.82502025 ... 0.06956328 -1.2103055 1.4155688 ... -0.759053 0.6966926 -0.53496075 0.0759853 -1.2265961 1.4023252 ... -0.7500985 0.68647313 -0.52275336 0.06356962 -1.2309887 1.3984702 ... -0.751963 0.69192046 -0.52820134 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20x128] } Python example: model = TransformerLayer.init( vocab=200, hidden_size=128, n_head=4, seq_len=20) train_token = np.random.randint(20, size=(2, 20)) train_pos = np.zeros((2, 20), dtype=np.int32) input = [train_token, train_pos] output = model.forward(input) Input is: type 'list' : [array([[11, 2, 16, 6, 17, 18, 2, 4, 5, 16, 18, 15, 13, 19, 5, 15, 14, 14, 2, 9], [10, 15, 13, 6, 12, 0, 11, 3, 16, 13, 6, 13, 17, 13, 3, 4, 15, 5, 7, 15]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)] Output is type 'list' : [array([[[ 0.26004127, -0.31793368, -1.1605529 , ..., -0.81875914, -0.02121837, -0.8328352 ], [-0.8622302 , -0.35201085, 0.63190293, ..., 2.0652232 , 1.5278 , 0.38224357], [-2.5103235 , 1.4465114 , 0.71134603, ..., 1.1776686 , 0.6882701 , 0.3534629 ], ..., [-0.22725764, 1.2112792 , -0.40597847, ..., 2.2241254 , 0.2580125 , -1.1470895 ], [-0.56174546, 1.3353435 , -0.7445968 , ..., 1.1259638 , 0.6951011 , -1.1421459 ], [-0.6615135 , 1.1899865 , -0.81727505, ..., 2.0474243 , 0.20160393, -0.7789728 ]], [[-1.1624268 , -0.5375418 , -0.7274868 , ..., -0.99061227, -0.57117355, 1.0684316 ], [ 0.11317759, -0.7231343 , 0.7723393 , ..., 1.6518786 , 1.0916579 , 0.18682887], [-1.9651127 , 0.9987117 , 0.32025027, ..., 0.94719195, -0.21028236, -0.02251417], ..., [-0.6677234 , 0.69822913, -0.9714249 , ..., 2.208334 , 0.7719772 , -0.93855625], [-0.63691545, 1.3876344 , -0.8491991 , ..., 2.060551 , 0.34702447, -0.8160082 ], [-0.6608573 , 1.2608795 , -0.46634364, ..., 2.100828 , 0.2967869 , -1.0938305 ]]], dtype=float32), array([[ 0.06879381, 0.6821829 , -0.8267953 , -0.02695777, -0.53899264, 0.8241045 , 0.6976903 , 0.31741282, 0.23590134, 0.5565326 , 0.95292866, 0.5658284 , -0.2916065 , -0.37934095, -0.2774958 , 0.73409927, -0.71731025, 0.07897043, 0.88609815, -0.27966806, 0.93520796, 0.72740096, 0.1626402 , -0.26063287, 0.28597558, -0.12945679, 0.7151408 , -0.8463592 , -0.48385444, -0.29313505, 0.86453205, -0.93834317, 0.41815573, 0.92436415, 0.8209114 , 0.6627246 , -0.574135 , 0.607416 , 0.04769071, -0.29779348, -0.26268572, -0.78998053, -0.7522611 , 0.89941144, -0.15754697, 0.9298859 , -0.8327022 , -0.63423705, -0.63789636, -0.14168388, -0.56104964, -0.80995566, 0.9244693 , 0.4679966 , -0.16284083, 0.8478645 , 0.29836348, -0.15369722, -0.4490478 , 0.11052075, 0.23767054, 0.59320366, -0.79055625, 0.22201608, -0.88366413, -0.4410687 , 0.8762162 , -0.6516914 , -0.5993653 , -0.5972125 , -0.86697286, -0.17644943, 0.95839834, -0.06382846, 0.7430881 , -0.59690744, 0.3901914 , 0.06803267, 0.9142394 , 0.7583274 , -0.18442968, 0.56280667, -0.37844184, -0.41195455, -0.8376329 , 0.87641823, -0.98970294, -0.6764397 , -0.86945957, -0.69273126, 0.9911777 , 0.417286 , -0.8774987 , 0.17141937, 0.7204654 , -0.62387246, -0.8795049 , 0.62618923, -0.29725042, -0.4565646 , -0.47798416, -0.97555065, -0.94241685, -0.97800356, 0.8523641 , -0.96860206, 0.5378995 , -0.73754525, -0.01649606, -0.4274561 , -0.5290453 , 0.11851768, 0.48821065, 0.4822751 , 0.49497148, -0.5734494 , -0.29612035, -0.7254394 , -0.1418346 , -0.56686646, 0.03665365, -0.9586826 , -0.0983429 , -0.09348761, -0.96338177, 0.76481736, 0.87975204, 0.70463663], [-0.09654156, 0.78266025, -0.9125131 , -0.6706971 , -0.58709925, -0.94729275, -0.32309514, -0.95263994, 0.2036015 , -0.9297767 , 0.6164713 , 0.3484337 , 0.46247053, 0.21615174, -0.8382687 , -0.55828595, -0.59234536, -0.9643932 , 0.9310115 , -0.12657425, 0.63812125, 0.80040973, -0.47581342, 0.9823402 , -0.5400171 , 0.5864317 , -0.19979174, -0.5721838 , 0.9190707 , 0.31628668, 0.08952013, 0.8719338 , 0.26684833, 0.8955768 , -0.9275499 , -0.81994563, 0.28863704, -0.16376448, 0.15855551, 0.04302022, 0.4440408 , -0.7293209 , 0.2255107 , 0.16333969, 0.38721767, -0.04512435, -0.5473172 , -0.5812051 , -0.8219114 , -0.43659028, -0.04860768, -0.8912252 , 0.62100273, 0.7187475 , -0.06158534, 0.6554498 , -0.62163985, 0.63035303, 0.19207267, -0.68847877, 0.10341872, -0.88906926, -0.38804066, -0.8157233 , -0.81641346, 0.8846337 , -0.70225614, 0.6281251 , -0.81235796, 0.77828485, 0.9393982 , -0.42554784, 0.4150426 , -0.32612413, -0.721988 , 0.96166253, -0.6080237 , -0.7312329 , 0.06843777, -0.09806018, -0.7357863 , -0.28613612, -0.8895085 , -0.9027925 , 0.56311375, 0.85699487, -0.32128897, 0.80635303, -0.01190906, -0.23292968, -0.5115769 , 0.17153661, -0.79993784, 0.6232265 , -0.06049479, -0.83510727, 0.9652135 , 0.08310007, -0.9671807 , -0.17466563, 0.48009604, 0.594712 , 0.19612817, -0.9279629 , -0.59968966, -0.36079255, -0.7250685 , 0.59395283, 0.7574965 , -0.4377294 , 0.45312116, 0.7117049 , -0.82085943, -0.10442825, 0.73688287, 0.38598123, 0.35439053, -0.3862137 , -0.56253886, 0.7388591 , -0.6024478 , -0.699977 , -0.46581215, -0.79513186, 0.09657894, 0.280869 , -0.38445532, -0.98311806]], dtype=float32)] BERT Bidirectional Encoder Representations from Transformers. Refer https://arxiv.org/pdf/1810.04805.pdf Input is a Table which consists of 4 tensors. 1. Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary 2. Token type id tensor: shape (batch, seqLen) with the token types in (0, 1). 0 means sentence A and 1 means a sentence B (see BERT paper for more details). 3. Position id tensor: shape (batch, seqLen) with positions in the sentence. 4. Attention_mask tensor: shape (batch, seqLen) with indices in (0, 1). It's a mask to be used if the input sequence length is smaller than seqLen in the current batch. Output is an Activity which output the states of BERT layer With Default Embedding: Scala: BERT[Float](vocab: Int = 40990, hiddenSize: Int = 768, nBlock: Int = 12, nHead: Int = 12, maxPositionLen: Int = 512, intermediateSize: Int = 3072, hiddenPDrop: Double = 0.1, attnPDrop: Double = 0.1, initializerRange: Double = 0.02, outputAllBlock: Boolean = true, inputSeqLen: Int = -1 ) Python: BERT.init(vocab=40990, hidden_size=768, n_block=12, n_head=12, seq_len=512, intermediate_size=3072, hidden_drop=0.1, attn_drop=0.1, initializer_range=0.02, output_all_block=True) Parameters: vocab : vocabulary size of training data, default is 40990 hiddenSize : size of the encoder layers, default is 768 nBlock : block number, default is 12 nHead : head number, default is 12 maxPositionLen : sequence length, default is 512 intermediateSize : The size of the \"intermediate\" (i.e., feed-forward), default is 3072 hiddenPDrop : The dropout probability for all fully connected layers, default is 0.1 attnPdrop : drop probability of attention, default is 0.1 initializerRange : weight initialization range, default is 0.02 outputAllBlock : whether output all blocks' output, default is false * inputSeqLen : sequence length of input, default is -1 which means the same with maxPositionLen With Customized Embedding: Scala: BERT[Float](nBlock = 12, nHead = 12, intermediateSize = 3072, hiddenPDrop = 0.1, attnPDrop = 0.1, initializerRange = 0.02, outputAllBlock = true, embeddingLayer = embedding) Python: BERT(n_block=12, n_head=12, intermediate_size=3072, hidden_drop=0.1, attn_drop=0.1, initializer_range=0.02, output_all_block=True, embedding_layer=embedding, input_shape=((seq_len,), (seq_len,), (seq_len,), (1, 1, seq_len))) Parameters: nBlock : block number nHead : head number intermediateSize : The size of the \"intermediate\" (i.e., feed-forward) hiddenPDrop : The dropout probability for all fully connected layers attnPdrop : drop probability of attention initializerRange : weight initialization range outputAllBlock : whether output all blocks' output embeddingLayer : embedding layer Loading from existing pretrained model: Scala: BERT[Float](path = , weightPath = null, inputSeqLen = 11, hiddenPDrop = 0.1, attnPDrop = 0.1, outputAllBlock = true) Python: BERT.init_from_existing_model(path= , weight_path=None, input_seq_len=-1.0, hidden_drop=-1.0, attn_drop=-1.0, output_all_block=True) Parameters: path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any inputSeqLen : sequence length of input, will be ignored if existing model is built with customized embedding hiddenPDrop : The dropout probability for all fully connected layers, will be ignored if existing model is built with customized embedding * attnPdrop : drop probability of attention, will be ignored if existing model is built with customized embedding Scala example: val layer = BERT[Float](vocab = 100, hiddenSize = 10, nBlock = 3, nHead = 2, intermediateSize = 64, hiddenPDrop = 0.1, attnPDrop = 0.1, maxPositionLen = 10, outputAllBlock = false, inputSeqLen = 10) val shape = Shape(List(Shape(1, 10), Shape(1, 10), Shape(1, 10), Shape(1, 1, 1, 10))) layer.build(shape) val inputIds = Tensor[Float](Array[Float](7, 20, 39, 27, 10, 39, 30, 21, 17, 15), Array(1, 10)) val segmentIds = Tensor[Float](Array[Float](0, 0, 0, 0, 0, 1, 1, 1, 1, 1), Array(1, 10)) val positionIds = Tensor[Float](Array[Float](0, 1, 2, 3, 4, 5, 6, 7, 8, 9), Array(1, 10)) val masks = Tensor[Float](1, 1, 1, 10).fill(1.0f) val output = layer.forward(T(inputIds, segmentIds, positionIds, masks)) Input is: { 2: 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 4: (1,1,.,.) = 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x10] 1: 7.0 20.0 39.0 27.0 10.0 39.0 30.0 21.0 17.0 15.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 3: 0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] } Output is: { 2: 0.5398573 0.08571402 -0.9461041 -0.35362077 -0.24374364 0.24349216 0.9587727 -0.03278971 -0.826852 -0.8808889 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 1: (1,.,.) = 1.3381815 1.7575556 -1.1870699 0.8455374 -1.6000531 0.115945406 -0.33695826 -0.39254665 -0.33637434 -0.20421773 -0.08370285 0.056055143 -0.91990083 1.6324282 -0.093128644 -0.4484297 -2.0828273 0.10244746 0.577287 1.2597716 0.3563086 0.37092525 -0.5089354 0.4525072 1.7706354 0.65231055 -2.0269241 -0.2548585 0.3711578 -1.1831268 0.2429675 -0.023419544 -0.28389466 0.6601246 -0.009858845 -0.028412571 -2.5104556 1.0338438 1.3621751 -0.44306967 1.7147139 1.1627073 -0.19394834 0.8043055 -1.0080436 -1.7716306 -0.7668168 -0.19861369 0.45103902 -0.19371253 0.077525005 0.0722655 1.0745171 0.07997274 0.06562643 1.6474637 0.18938908 -2.377528 -0.6107291 -0.21850263 -1.3190242 1.7057956 0.32655835 0.5711799 -0.80318034 0.2776545 1.4860673 -0.676896 -0.39734793 -1.1708072 -0.4327645 -0.19849697 0.3695452 -0.08213705 1.2378154 0.591234 -1.505518 1.684885 -1.6251724 -0.03939093 0.6422535 -0.582018 1.6665243 -1.0995792 0.19488664 1.3563607 -0.60793823 -0.05846788 -1.7225715 0.21054967 -1.0927358 -0.37666538 0.70802236 -2.0131714 0.94964516 1.4701655 0.053027537 0.051168486 -0.58528 0.83582383 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10x10] } Python example: layer = BERT.init( vocab=200, hidden_size=128, n_head=4, seq_len=20, intermediate_size=20) train_token = np.random.randint(20, size=(2, 20)) token_type_id = np.zeros((2, 20), dtype=np.int32) train_pos = np.zeros((2, 20), dtype=np.int32) mask_attention = np.ones((2, 1, 1, 20), dtype=np.int32) input = [train_token, token_type_id, train_pos, mask_attention] output = layer.forward(input) Input is: type 'list' : [array([[ 8, 19, 5, 8, 4, 13, 13, 12, 1, 6, 16, 14, 19, 0, 11, 18, 1, 17, 0, 0], [17, 10, 15, 19, 15, 2, 18, 8, 1, 11, 10, 17, 7, 2, 0, 0, 9, 14, 11, 6]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]], dtype=int32)] Output is type 'list' : [array([[[ 1.01330066e+00, 4.74100798e-01, 3.81211847e-01, ..., -8.00989151e-01, -6.18815482e-01, -1.09804094e+00], [-6.29726201e-02, 6.71391249e-01, -2.28019580e-01, ..., 3.97501498e-01, -3.32217604e-01, -2.04850674e+00], [ 5.04802346e-01, 1.00434709e+00, -7.63663530e-01, ..., -1.11675525e+00, 1.41550392e-01, -6.47688091e-01], ..., [ 5.07664750e-04, 6.47843182e-01, -5.33694960e-02, ..., -2.01566055e-01, -6.62943959e-01, -2.93835902e+00], [-1.49255514e-01, -5.47551095e-01, -3.36264402e-01, ..., 1.11121520e-01, -4.42977905e-01, -2.13847613e+00], [-1.33390293e-01, -5.50503194e-01, -3.49355727e-01, ..., 9.34313685e-02, -4.41935956e-01, -8.25921223e-02]], [[ 1.34967836e-02, 3.90778482e-02, -2.22317409e-02, ..., -9.81532633e-02, -6.08992100e-01, -2.77224326e+00], [-5.21431923e-01, -6.74456656e-02, -4.66892511e-01, ..., 1.05466165e-01, -2.67068297e-01, -9.00964141e-01], [ 9.41378593e-01, 5.21076620e-01, -5.35079956e-01, ..., -3.15736473e-01, 8.08603615e-02, -2.44178265e-01], ..., [ 4.16017324e-02, -5.65874994e-01, 6.68676615e-01, ..., -6.28256857e-01, -9.09847617e-02, -2.42878512e-01], [-1.36971796e+00, 5.37231266e-01, -1.33729517e+00, ..., -1.47498712e-01, 8.00304264e-02, -5.09030581e-01], [ 3.98404837e-01, -7.18296226e-03, -1.08256066e+00, ..., -5.17360926e-01, 5.50065935e-01, -2.32753420e+00]]], dtype=float32), array([[[ 1.0795887 , 0.44977495, 0.45561683, ..., -0.729603 , -0.6098092 , -1.0323973 ], [ 0.0154253 , 0.6424524 , -0.15503715, ..., 0.45100495, -0.3161888 , -1.9826275 ], [ 0.58491707, 0.9876782 , -0.69952184, ..., -1.0432141 , 0.1380458 , -0.5642554 ], ..., [ 0.06806332, 0.61824507, 0.02341641, ..., -0.21342012, -0.63312817, -2.8557966 ], [-0.06217962, -0.5528828 , -0.34740448, ..., 0.16651583, -0.41633344, -2.064906 ], [-0.04626712, -0.57442385, -0.277238 , ..., 0.13806444, -0.43256086, -0.01180306]], [[ 0.10532085, 0.01057051, 0.07536474, ..., -0.03406155, -0.572023 , -2.6935408 ], [-0.42477775, -0.10768362, -0.37653154, ..., 0.17155378, -0.27841952, -0.8244427 ], [ 1.0290473 , 0.5059685 , -0.5359356 , ..., -0.25725254, 0.1034779 , -0.16898313], ..., [ 0.14118548, -0.5945706 , 0.7681386 , ..., -0.55807835, -0.07778832, -0.15940095], [-1.2648381 , 0.50598496, -1.2431567 , ..., -0.06980868, 0.10642368, -0.4181047 ], [ 0.48330045, -0.05184587, -0.9985824 , ..., -0.5360492 , 0.56541353, -2.2607849 ]]], dtype=float32), array([[[ 1.1541002 , 0.47630545, 0.40673187, ..., -0.7284888 , -0.55945337, -1.0810231 ], [ 0.10070852, 0.64252985, -0.2007717 , ..., 0.4489277 , -0.24709189, -2.0173872 ], [ 0.67520154, 0.9793912 , -0.7441366 , ..., -1.0376649 , 0.20359974, -0.6060102 ], ..., [ 0.07809319, 0.63523245, -0.02464442, ..., -0.21328981, -0.5693355 , -2.8386393 ], [ 0.02228299, -0.5229728 , -0.33483037, ..., 0.16430138, -0.40036577, -2.094183 ], [ 0.02232744, -0.54113156, -0.3307599 , ..., 0.14321396, -0.3796677 , -0.04973204]], [[ 0.20497712, 0.02804335, 0.028764 , ..., -0.01617111, -0.5416485 , -2.7333891 ], [-0.3361876 , -0.08618001, -0.41299412, ..., 0.17708196, -0.23643918, -0.8763187 ], [ 1.1118197 , 0.5178778 , -0.57264006, ..., -0.2597192 , 0.15024357, -0.23373066], ..., [ 0.23304611, -0.57528406, 0.71815467, ..., -0.5524511 , -0.04103457, -0.15449452], [-1.1629226 , 0.5377656 , -1.2816569 , ..., -0.05795323, 0.1603044 , -0.47194824], [ 0.5773567 , -0.04114214, -1.0306932 , ..., -0.52537155, 0.5703101 , -2.3124278 ]]], dtype=float32), array([[[ 1.1319652e+00, 4.2663044e-01, 3.9611375e-01, ..., -7.7264631e-01, -5.3006041e-01, -1.0942854e+00], [ 7.3858641e-02, 6.1578143e-01, -2.0985913e-01, ..., 4.0289888e-01, -2.2484708e-01, -2.0233095e+00], [ 6.3545388e-01, 9.4610500e-01, -7.6165521e-01, ..., -1.0820770e+00, 2.2266804e-01, -6.0132843e-01], ..., [ 3.9479308e-02, 6.0636342e-01, -2.8302141e-02, ..., -2.6316714e-01, -5.5309945e-01, -2.8510940e+00], [-2.8412668e-03, -5.5100703e-01, -3.4540960e-01, ..., 1.5979633e-01, -3.8844827e-01, -2.0994248e+00], [-1.4572166e-02, -5.7526213e-01, -3.3382124e-01, ..., 1.0289014e-01, -3.6059290e-01, -6.5041430e-02]], [[ 1.5256011e-01, 3.3955947e-03, 1.7648729e-02, ..., -4.9600061e-02, -5.1613468e-01, -2.7417533e+00], [-3.6988521e-01, -8.8330485e-02, -4.2416954e-01, ..., 1.2959087e-01, -2.1623056e-01, -8.8821554e-01], [ 1.0618008e+00, 5.0827748e-01, -5.8256608e-01, ..., -2.9023758e-01, 1.6930477e-01, -2.3869993e-01], ..., [ 1.8475071e-01, -5.8594310e-01, 7.0973599e-01, ..., -5.9211296e-01, -1.7043589e-02, -1.5649734e-01], [-1.2073172e+00, 5.1577950e-01, -1.2952001e+00, ..., -1.0562765e-01, 1.8499596e-01, -4.6483174e-01], [ 5.8209622e-01, -5.3714752e-02, -1.0255412e+00, ..., -5.6718546e-01, 5.9832001e-01, -2.3260906e+00]]], dtype=float32), array([[[ 1.1358043 , 0.38664085, 0.43075162, ..., -0.762137 , -0.53836805, -1.1419276 ], [ 0.0705715 , 0.61749744, -0.1978054 , ..., 0.39686537, -0.23118263, -2.0863478 ], [ 0.6286853 , 0.9499371 , -0.75073713, ..., -1.0837915 , 0.20451419, -0.64585996], ..., [ 0.04084783, 0.5485716 , 0.02199897, ..., -0.265642 , -0.54954815, -2.8985202 ], [-0.00433184, -0.5782148 , -0.28893095, ..., 0.15305014, -0.3942154 , -2.1390564 ], [-0.01938614, -0.6034715 , -0.3210429 , ..., 0.11286073, -0.3612479 , -0.12291119]], [[ 0.13899514, -0.04281238, 0.05966739, ..., -0.05543021, -0.51721877, -2.7725601 ], [-0.38874203, -0.13524944, -0.37960985, ..., 0.12579904, -0.23764463, -0.94251025], [ 1.0436667 , 0.4891924 , -0.5470476 , ..., -0.30531114, 0.143379 , -0.28663573], ..., [ 0.17597033, -0.6172772 , 0.75050735, ..., -0.59396976, -0.02840331, -0.20918237], [-1.2121452 , 0.47985265, -1.2640744 , ..., -0.11457531, 0.17777829, -0.5216857 ], [ 0.5724598 , -0.08497301, -0.99838203, ..., -0.569392 , 0.5878865 , -2.3820512 ]]], dtype=float32), array([[[ 1.1923821 , 0.40376186, 0.4216827 , ..., -0.7753511 , -0.58085346, -1.1371452 ], [ 0.13859609, 0.6558944 , -0.1899949 , ..., 0.37358993, -0.27038255, -2.0870223 ], [ 0.7083764 , 0.977537 , -0.76046735, ..., -1.101789 , 0.1981793 , -0.6461577 ], ..., [ 0.10095584, 0.5967537 , 0.02207649, ..., -0.28193793, -0.5789527 , -2.9001386 ], [ 0.05901275, -0.53504837, -0.28481779, ..., 0.13802934, -0.41621858, -2.1443312 ], [ 0.04528951, -0.5612042 , -0.31392562, ..., 0.09289672, -0.38395336, -0.12475596]], [[ 0.19919002, -0.0038989 , 0.06975131, ..., -0.05898362, -0.5476832 , -2.7802918 ], [-0.32966843, -0.10950038, -0.3582222 , ..., 0.08165199, -0.2624505 , -0.93702954], [ 1.119693 , 0.5142474 , -0.5341173 , ..., -0.3251373 , 0.10789905, -0.30592436], ..., [ 0.24882485, -0.5699529 , 0.77695113, ..., -0.63034034, -0.07624292, -0.2281592 ], [-1.1650497 , 0.5175082 , -1.2281002 , ..., -0.14287077, 0.15133552, -0.532626 ], [ 0.64303875, -0.05680082, -0.9739305 , ..., -0.5787345 , 0.5447517 , -2.403577 ]]], dtype=float32), array([[[ 1.1747141 , 0.44174162, 0.3848741 , ..., -0.8011676 , -0.5708256 , -1.143519 ], [ 0.11874287, 0.7037242 , -0.22899102, ..., 0.36200705, -0.22287843, -2.0832918 ], [ 0.68290263, 1.0014081 , -0.8112288 , ..., -1.0980991 , 0.22316812, -0.637702 ], ..., [ 0.07541095, 0.63492006, 0.02669529, ..., -0.27486983, -0.53397936, -2.8813968 ], [ 0.07104072, -0.54481 , -0.33232585, ..., 0.12730087, -0.37563673, -2.1450465 ], [ 0.03186123, -0.51601535, -0.35520643, ..., 0.09008651, -0.33910847, -0.11906879]], [[ 0.19884765, 0.06095114, 0.00477777, ..., -0.0960753 , -0.49155453, -2.7463722 ], [-0.32222956, -0.08950429, -0.4053724 , ..., 0.05162536, -0.21072339, -0.9155606 ], [ 1.1117101 , 0.56429935, -0.59156317, ..., -0.3369357 , 0.14969075, -0.29045773], ..., [ 0.25635508, -0.5126209 , 0.7268977 , ..., -0.62107044, -0.01715574, -0.21087953], [-1.1460723 , 0.56120336, -1.2668271 , ..., -0.16734022, 0.19381218, -0.517316 ], [ 0.63978064, -0.01486263, -1.0128225 , ..., -0.56719303, 0.58368987, -2.3722165 ]]], dtype=float32), array([[[ 1.20512652e+00, 4.72038895e-01, 3.60962778e-01, ..., -9.00623977e-01, -5.82258105e-01, -1.14907408e+00], [ 1.55033678e-01, 7.28412509e-01, -2.72546947e-01, ..., 2.74131984e-01, -2.24478737e-01, -2.06169677e+00], [ 7.13116527e-01, 1.01666617e+00, -8.43635857e-01, ..., -1.18351495e+00, 2.21053749e-01, -6.17874563e-01], ..., [ 1.19287886e-01, 6.56103075e-01, -7.38978712e-03, ..., -3.54864419e-01, -5.37513494e-01, -2.87535477e+00], [ 1.16591401e-01, -5.55387378e-01, -3.71099353e-01, ..., 2.78753694e-02, -3.70597601e-01, -2.16417289e+00], [ 8.63942727e-02, -4.81025964e-01, -3.91344100e-01, ..., -1.84133966e-02, -3.39215338e-01, -1.10263892e-01]], [[ 2.64633745e-01, 7.25395158e-02, -1.39633343e-02, ..., -1.85173869e-01, -5.20042717e-01, -2.70796871e+00], [-2.58721560e-01, -6.35206550e-02, -4.14235502e-01, ..., 4.62563671e-02, -2.47269630e-01, -8.77729058e-01], [ 1.17845881e+00, 5.93900442e-01, -6.18097663e-01, ..., -4.23726231e-01, 1.19810022e-01, -2.55170494e-01], ..., [ 3.06802571e-01, -4.83913153e-01, 7.05836833e-01, ..., -6.99279726e-01, -5.64565696e-02, -1.74492225e-01], [-1.07746637e+00, 5.83848476e-01, -1.28454113e+00, ..., -2.29663596e-01, 1.96212217e-01, -5.23399591e-01], [ 7.02956200e-01, 2.42653489e-03, -1.03614473e+00, ..., -6.54396653e-01, 5.55146933e-01, -2.35132337e+00]]], dtype=float32), array([[[ 1.1732985 , 0.48227564, 0.4141097 , ..., -0.9222415 , -0.5581617 , -1.1467376 ], [ 0.10594734, 0.75098526, -0.23052076, ..., 0.23048519, -0.23638739, -2.033264 ], [ 0.6784295 , 1.0418617 , -0.810519 , ..., -1.2120562 , 0.24596576, -0.60291487], ..., [ 0.07915874, 0.6732479 , 0.02875949, ..., -0.38714084, -0.5037479 , -2.8571 ], [ 0.07176737, -0.52642834, -0.31701285, ..., -0.01229298, -0.34029967, -2.1321528 ], [ 0.04126783, -0.46029058, -0.34176344, ..., -0.05429364, -0.31155083, -0.10451217]], [[ 0.22600769, 0.09270672, 0.02146479, ..., -0.22232075, -0.48217994, -2.6969097 ], [-0.29719839, -0.05968198, -0.37710896, ..., 0.02224515, -0.20888865, -0.872187 ], [ 1.1335284 , 0.60064685, -0.58743286, ..., -0.45202363, 0.13883159, -0.2602308 ], ..., [ 0.27142784, -0.47967467, 0.70926106, ..., -0.71909636, -0.01251143, -0.1811402 ], [-1.095905 , 0.6111897 , -1.2443895 , ..., -0.27054876, 0.22430526, -0.5081292 ], [ 0.7027022 , 0.01059689, -1.0006222 , ..., -0.6746712 , 0.58800125, -2.352779 ]]], dtype=float32), array([[[ 1.2434555 , 0.44558033, 0.4151337 , ..., -0.8851603 , -0.5718673 , -1.1482117 ], [ 0.11962966, 0.72577155, -0.25604928, ..., 0.2687037 , -0.2457071 , -2.0307996 ], [ 0.763747 , 1.0119921 , -0.8592167 , ..., -1.1870402 , 0.2256221 , -0.6277423 ], ..., [ 0.08759235, 0.64535457, 0.03834408, ..., -0.35554865, -0.5139612 , -2.8475935 ], [ 0.13679026, -0.55156755, -0.32664305, ..., 0.01780019, -0.3558066 , -2.1313274 ], [ 0.11818186, -0.4789727 , -0.3590175 , ..., -0.01446133, -0.32358617, -0.10938768]], [[ 0.29418862, 0.09591774, 0.00587363, ..., -0.18236086, -0.49953887, -2.694323 ], [-0.22257486, -0.07352418, -0.4024905 , ..., 0.05929026, -0.22622454, -0.8882016 ], [ 1.19449 , 0.5713768 , -0.6041051 , ..., -0.4231223 , 0.1122172 , -0.28642637], ..., [ 0.3465784 , -0.4939726 , 0.68308717, ..., -0.68765515, -0.04439323, -0.20094715], [-1.0187647 , 0.59667283, -1.2578517 , ..., -0.24298497, 0.19871093, -0.53237087], [ 0.71921486, 0.00342394, -1.026827 , ..., -0.63569874, 0.5502706 , -2.3338537 ]]], dtype=float32), array([[[ 1.2440691 , 0.477769 , 0.40438044, ..., -0.8634442 , -0.516493 , -1.2156196 ], [ 0.09270077, 0.7480357 , -0.26808444, ..., 0.2696572 , -0.19946648, -2.0294373 ], [ 0.7727248 , 1.0203358 , -0.8804002 , ..., -1.1491328 , 0.26056868, -0.70166045], ..., [ 0.07362438, 0.6428618 , 0.02992919, ..., -0.3656686 , -0.47058144, -2.8904293 ], [ 0.11636666, -0.52916086, -0.3162666 , ..., 0.0035085 , -0.32273746, -2.211205 ], [ 0.09450418, -0.46651682, -0.38872302, ..., -0.02868051, -0.284238 , -0.20115192]], [[ 0.24763471, 0.10591529, -0.02833212, ..., -0.19653179, -0.44746324, -2.6951957 ], [-0.2705241 , -0.05053078, -0.38580215, ..., 0.0737243 , -0.18193349, -0.9320284 ], [ 1.1450722 , 0.5878723 , -0.6142542 , ..., -0.4155699 , 0.1653907 , -0.3516124 ], ..., [ 0.31275982, -0.48012054, 0.6611108 , ..., -0.6956505 , 0.01540092, -0.20229349], [-1.0758246 , 0.6180846 , -1.2664212 , ..., -0.20339848, 0.25243902, -0.5957573 ], [ 0.6647455 , 0.02233337, -1.0082287 , ..., -0.6396673 , 0.6092897 , -2.3386178 ]]], dtype=float32), array([[[ 1.16829467e+00, 4.73457277e-01, 3.55845094e-01, ..., -8.79491448e-01, -5.13881445e-01, -1.31691360e+00], [ 2.06558462e-02, 7.50393629e-01, -2.97149330e-01, ..., 2.75190771e-01, -1.88330606e-01, -2.13159895e+00], [ 6.88944340e-01, 1.01597929e+00, -9.25147057e-01, ..., -1.15003026e+00, 2.47588441e-01, -7.96685874e-01], ..., [ 2.88018938e-02, 6.88098967e-01, -2.68854816e-02, ..., -3.84741157e-01, -4.76365626e-01, -2.96942425e+00], [ 5.18963784e-02, -4.60506737e-01, -3.59559625e-01, ..., -1.14138005e-02, -3.24753582e-01, -2.23346853e+00], [ 7.39114806e-02, -4.01132107e-01, -4.24620807e-01, ..., -3.33240032e-02, -2.84682035e-01, -3.12762260e-01]], [[ 2.14906067e-01, 1.72432721e-01, -8.47420394e-02, ..., -2.10198522e-01, -4.30923790e-01, -2.79578996e+00], [-3.10599983e-01, 1.65538397e-03, -4.26579088e-01, ..., 5.09980768e-02, -1.56658575e-01, -1.01907480e+00], [ 1.09326482e+00, 6.40747488e-01, -6.59607410e-01, ..., -4.15965647e-01, 1.87072530e-01, -4.48307097e-01], ..., [ 2.86490113e-01, -4.34108675e-01, 6.18547022e-01, ..., -7.17846394e-01, 3.06018218e-02, -2.91922033e-01], [-1.13503909e+00, 6.14412308e-01, -1.32140326e+00, ..., -2.04109967e-01, 2.61365235e-01, -6.73554838e-01], [ 6.21745884e-01, 8.54183882e-02, -1.06341887e+00, ..., -6.34258091e-01, 6.15509987e-01, -2.41539836e+00]]], dtype=float32), array([[ 0.5620128 , -0.2001392 , -0.11440954, -0.04526514, -0.8816746 , -0.5549258 , 0.51452374, 0.13439347, 0.53412014, 0.46277392, 0.8692565 , -0.90509814, 0.31514823, 0.8086619 , 0.58900446, -0.3894673 , -0.45003602, 0.37346584, 0.69269675, 0.21574067, -0.72299725, 0.528553 , -0.83846116, 0.98062813, -0.05183166, 0.33388335, -0.63176596, 0.21661893, 0.43943346, 0.33758652, -0.24407507, -0.17800584, 0.59364974, 0.47616154, 0.558793 , 0.27490366, -0.9666731 , -0.8721832 , 0.743239 , 0.04293209, -0.5673905 , -0.14399827, -0.41138482, 0.8764746 , -0.11112919, 0.21457899, 0.88060266, 0.88843846, 0.18521515, -0.84538144, -0.57872075, 0.7840174 , 0.8682007 , -0.5286343 , 0.2563142 , 0.9634152 , 0.03505438, 0.91062546, 0.3279442 , -0.61855054, 0.22826263, 0.42789218, -0.48171976, -0.13283452, -0.86695194, 0.9060679 , 0.78916115, 0.16227603, -0.36374012, -0.5703023 , 0.19644596, -0.6927085 , 0.19042683, -0.43984833, -0.7866716 , 0.9690585 , -0.42288277, 0.8037468 , 0.70858365, 0.87470776, 0.630474 , 0.17134413, 0.99327976, -0.46532467, -0.00972999, 0.9460259 , 0.09055056, 0.7293024 , -0.9081666 , 0.15192512, -0.8813194 , -0.7241285 , 0.11484392, 0.5220332 , 0.6182944 , 0.5697724 , 0.80298615, -0.916839 , 0.8679731 , 0.3047138 , -0.7162764 , -0.852553 , 0.8317937 , 0.6582049 , -0.06668244, 0.36977607, 0.80465484, 0.10356631, 0.5558003 , 0.29966184, 0.93551975, -0.89290446, 0.15027076, -0.66376805, -0.6382408 , 0.6717352 , 0.9509484 , -0.79286 , -0.18582785, -0.36172768, -0.9791676 , -0.94657 , -0.47834975, 0.4030182 , 0.8983884 , 0.74833804, -0.24173705, -0.6059107 ], [ 0.01938096, -0.08230975, 0.2434453 , -0.8368162 , -0.31632444, -0.137336 , 0.8550923 , -0.51500845, 0.5093535 , 0.7847338 , 0.2958318 , -0.3608949 , 0.3377346 , 0.7592404 , -0.10613706, 0.45210105, -0.39598942, -0.32519925, 0.89480245, 0.6049605 , -0.81980604, 0.6129146 , 0.5854233 , 0.8875059 , 0.8888534 , 0.38860276, -0.81435287, -0.8599018 , -0.7989145 , 0.87724596, -0.09401844, 0.8232204 , 0.5973142 , -0.47759202, -0.2035289 , 0.86339366, -0.78711975, -0.8843788 , 0.50736386, 0.7154904 , 0.02759624, -0.29022685, -0.21070601, 0.37119249, -0.93711466, -0.41830346, 0.49852479, 0.7634121 , -0.73495114, -0.8023139 , -0.56360126, 0.7008394 , 0.9837745 , -0.09430382, 0.35603583, 0.98780483, 0.3609371 , -0.31916958, -0.48238578, -0.65934813, 0.67085034, -0.43169144, 0.86363876, -0.1453511 , -0.8397705 , -0.35035503, 0.88129896, 0.16335464, 0.34733585, 0.24485897, -0.5006221 , -0.9430847 , -0.80959797, -0.8578838 , -0.7431067 , 0.49626076, -0.03579912, -0.5582668 , 0.9786438 , 0.2536843 , 0.895339 , -0.42590025, 0.9813974 , 0.4913268 , -0.95859706, 0.5229873 , -0.75750285, 0.01685579, -0.37524623, -0.4403388 , -0.91602516, -0.63672376, 0.28235126, 0.5060775 , 0.03505507, 0.8782664 , 0.06858374, -0.81789017, 0.41628596, 0.9114354 , 0.79067975, -0.76645094, 0.90893763, 0.95445615, -0.8870664 , 0.50881255, 0.30905575, 0.4437762 , -0.2528932 , -0.14799164, 0.93950725, -0.7908481 , 0.44684762, -0.9644589 , 0.37588173, 0.9690541 , -0.6058538 , 0.2965665 , -0.07335383, -0.6774956 , -0.9477332 , -0.8670143 , 0.03564278, -0.8282162 , 0.24308446, 0.5860108 , -0.93586445, -0.8312509 ]], dtype=float32)]","title":"Self attention"},{"location":"KerasStyleAPIGuide/Layers/self-attention/#transformerlayer","text":"A network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Refer https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf Input is a Table which consists of 2 tensors. 1. Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary 2. Position id tensor: shape (batch, seqLen) with positions in the sentence. Output is a Tensor which output the states of Transformer layer With Default Embedding: Scala: TransformerLayer[Float](vocab = 40990, seqLen = 77, nBlock = 12, residPdrop = 0.1, attnPdrop = 0.1, nHead = 12, hiddenSize = 768, embeddingDrop = 0, initializerRange = 0.02, bidirectional = false, outputAllBlock = false) Python: TransformerLayer.init(vocab=40990, seq_len=77, n_block=12, hidden_drop=0.1, attn_drop=0.1, n_head=12, hidden_size=768, embedding_drop=0.1, initializer_range=0.02, bidirectional=False, output_all_block=False) Parameters: vocab : vocabulary size of training data, default is 40990 seqLen : max sequence length of training data, default is 77 nBlock : block number, default is 12 residPdrop : drop probability of projection, default is 0.1 attnPdrop : drop probability of attention, default is 0.1 nHead : head number, default is 12 hiddenSize : is also embedding size embeddingDrop : drop probability of embedding layer, default is 0.1 initializerRange : weight initialization range, default is 0.02 bidirectional : whether unidirectional or bidirectional, default is false * outputAllBlock : whether output all blocks' output, default is false With Customized Embedding: Scala: TransformerLayer[Float](nBlock = 3, residPdrop = 0.1, attnPdrop = 0.1, nHead = 12, bidirectional = false, initializerRange = 0.02, outputAllBlock = true, embeddingLayer = embedding.asInstanceOf[KerasLayer[Activity, Tensor[Float], Float]]) Python: TransformerLayer(n_block=12, hidden_drop=0.1, attn_drop=0.1, n_head=12, initializer_range=0.02, bidirectional=False, output_all_block=False, embedding_layer=embedding, input_shape=((seq_len,), (seq_len,)), intermediate_size=0) Parameters: nBlock : block number residPdrop : drop probability of projection attnPdrop : drop probability of attention nHead : head number initializerRange : weight initialization range bidirectional : whether unidirectional or bidirectional outputAllBlock : whether output all blocks' output embeddingLayer : embedding layer Scala example: val shape1 = Shape(20) val shape2 = Shape(20) val input1 = Variable[Float](shape1) val input2 = Variable[Float](shape2) val input = Array(input1, input2) val seq = TransformerLayer[Float](200, hiddenSize = 128, nHead = 8, seqLen = 20, nBlock = 1).from(input: _*) val model = Model[Float](input, seq) val trainToken = Tensor[Float](1, 20).rand() val trainPos = Tensor.ones[Float](1, 20) val input3 = T(trainToken, trainPos) val output = model.forward(input3) Input is: { 2: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x20] 1: 0.8087359 0.16409875 0.7404631 0.4836999 0.034994964 0.033039592 0.6694243 0.84700763 0.32154092 0.17410904 0.66117364 0.30495027 0.19573595 0.058101892 0.65923077 0.84077805 0.50113535 0.48393667 0.06523132 0.0667426 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20] } Output is: { 2: 0.83383083 0.72725344 0.16394942 -0.79005975 0.8877357 -0.9060916 -0.6796065 0.46835706 -0.4700584 0.43868023 0.6641587 0.6711142 -0.70056283 -0.42694178 0.7615595 -0.25590983 0.21654142 0.35254374 0.83790034 0.1103606 -0.20419843 -0.9739706 0.6150182 0.4499923 0.3355538 -0.01543447 -0.99528116 0.45984524 -0.22544041 0.10049125 0.8418835 -0.116228305 -0.112435654 0.5183222 -0.59375525 0.31828925 0.50506884 0.14892755 0.94327587 -0.19001998 0.54074824 -0.07616825 -0.79334164 -0.49726814 0.23889944 -0.91731304 -0.5484148 0.5048103 0.9743351 0.10505025 0.81167877 -0.47498485 -0.83443964 -0.89340115 0.6443838 0.10184191 -0.38618097 -0.32026938 0.51587516 -0.40602723 -0.2931675 -0.86100364 0.109585665 0.9023708 0.46609795 0.0028693299 -0.5746851 -0.45607233 -0.9075561 -0.91294044 0.8077997 0.23019081 0.51124465 -0.39125186 0.16946821 -0.36827865 -0.32563296 0.62560886 -0.7278883 0.8076773 0.89344263 -0.9259615 0.21476166 0.67077845 0.5857905 -0.32905066 -0.16318946 0.6435858 -0.28905967 -0.6991412 -0.5289766 -0.6954091 0.1577004 0.5618301 -0.6290018 0.114078626 -0.52474076 0.27916297 -0.76610357 0.67119384 -0.4308661 0.063731246 -0.5281069 -0.65910465 0.5383283 -0.2875557 0.24594739 -0.6789035 0.7002648 -0.64659894 -0.70994437 -0.8416273 0.4666695 -0.55062526 0.14995292 -0.978979 0.40934727 -0.9028927 0.38194665 0.2334618 -0.9481384 -0.51903373 -0.947906 0.2667679 -0.76987743 -0.7490675 0.6777159 0.9593161 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x128] 1: (1,.,.) = 0.8369983 -0.9907519 0.74404025 ... 0.6154673 0.107825294 -0.806892 0.7676861 -0.962961 0.73240614 ... 0.534349 0.0049344404 -0.81643736 0.7487803 -0.9717681 0.7315394 ... 0.59831613 0.010904985 -0.82502025 ... 0.06956328 -1.2103055 1.4155688 ... -0.759053 0.6966926 -0.53496075 0.0759853 -1.2265961 1.4023252 ... -0.7500985 0.68647313 -0.52275336 0.06356962 -1.2309887 1.3984702 ... -0.751963 0.69192046 -0.52820134 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20x128] } Python example: model = TransformerLayer.init( vocab=200, hidden_size=128, n_head=4, seq_len=20) train_token = np.random.randint(20, size=(2, 20)) train_pos = np.zeros((2, 20), dtype=np.int32) input = [train_token, train_pos] output = model.forward(input) Input is: type 'list' : [array([[11, 2, 16, 6, 17, 18, 2, 4, 5, 16, 18, 15, 13, 19, 5, 15, 14, 14, 2, 9], [10, 15, 13, 6, 12, 0, 11, 3, 16, 13, 6, 13, 17, 13, 3, 4, 15, 5, 7, 15]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)] Output is type 'list' : [array([[[ 0.26004127, -0.31793368, -1.1605529 , ..., -0.81875914, -0.02121837, -0.8328352 ], [-0.8622302 , -0.35201085, 0.63190293, ..., 2.0652232 , 1.5278 , 0.38224357], [-2.5103235 , 1.4465114 , 0.71134603, ..., 1.1776686 , 0.6882701 , 0.3534629 ], ..., [-0.22725764, 1.2112792 , -0.40597847, ..., 2.2241254 , 0.2580125 , -1.1470895 ], [-0.56174546, 1.3353435 , -0.7445968 , ..., 1.1259638 , 0.6951011 , -1.1421459 ], [-0.6615135 , 1.1899865 , -0.81727505, ..., 2.0474243 , 0.20160393, -0.7789728 ]], [[-1.1624268 , -0.5375418 , -0.7274868 , ..., -0.99061227, -0.57117355, 1.0684316 ], [ 0.11317759, -0.7231343 , 0.7723393 , ..., 1.6518786 , 1.0916579 , 0.18682887], [-1.9651127 , 0.9987117 , 0.32025027, ..., 0.94719195, -0.21028236, -0.02251417], ..., [-0.6677234 , 0.69822913, -0.9714249 , ..., 2.208334 , 0.7719772 , -0.93855625], [-0.63691545, 1.3876344 , -0.8491991 , ..., 2.060551 , 0.34702447, -0.8160082 ], [-0.6608573 , 1.2608795 , -0.46634364, ..., 2.100828 , 0.2967869 , -1.0938305 ]]], dtype=float32), array([[ 0.06879381, 0.6821829 , -0.8267953 , -0.02695777, -0.53899264, 0.8241045 , 0.6976903 , 0.31741282, 0.23590134, 0.5565326 , 0.95292866, 0.5658284 , -0.2916065 , -0.37934095, -0.2774958 , 0.73409927, -0.71731025, 0.07897043, 0.88609815, -0.27966806, 0.93520796, 0.72740096, 0.1626402 , -0.26063287, 0.28597558, -0.12945679, 0.7151408 , -0.8463592 , -0.48385444, -0.29313505, 0.86453205, -0.93834317, 0.41815573, 0.92436415, 0.8209114 , 0.6627246 , -0.574135 , 0.607416 , 0.04769071, -0.29779348, -0.26268572, -0.78998053, -0.7522611 , 0.89941144, -0.15754697, 0.9298859 , -0.8327022 , -0.63423705, -0.63789636, -0.14168388, -0.56104964, -0.80995566, 0.9244693 , 0.4679966 , -0.16284083, 0.8478645 , 0.29836348, -0.15369722, -0.4490478 , 0.11052075, 0.23767054, 0.59320366, -0.79055625, 0.22201608, -0.88366413, -0.4410687 , 0.8762162 , -0.6516914 , -0.5993653 , -0.5972125 , -0.86697286, -0.17644943, 0.95839834, -0.06382846, 0.7430881 , -0.59690744, 0.3901914 , 0.06803267, 0.9142394 , 0.7583274 , -0.18442968, 0.56280667, -0.37844184, -0.41195455, -0.8376329 , 0.87641823, -0.98970294, -0.6764397 , -0.86945957, -0.69273126, 0.9911777 , 0.417286 , -0.8774987 , 0.17141937, 0.7204654 , -0.62387246, -0.8795049 , 0.62618923, -0.29725042, -0.4565646 , -0.47798416, -0.97555065, -0.94241685, -0.97800356, 0.8523641 , -0.96860206, 0.5378995 , -0.73754525, -0.01649606, -0.4274561 , -0.5290453 , 0.11851768, 0.48821065, 0.4822751 , 0.49497148, -0.5734494 , -0.29612035, -0.7254394 , -0.1418346 , -0.56686646, 0.03665365, -0.9586826 , -0.0983429 , -0.09348761, -0.96338177, 0.76481736, 0.87975204, 0.70463663], [-0.09654156, 0.78266025, -0.9125131 , -0.6706971 , -0.58709925, -0.94729275, -0.32309514, -0.95263994, 0.2036015 , -0.9297767 , 0.6164713 , 0.3484337 , 0.46247053, 0.21615174, -0.8382687 , -0.55828595, -0.59234536, -0.9643932 , 0.9310115 , -0.12657425, 0.63812125, 0.80040973, -0.47581342, 0.9823402 , -0.5400171 , 0.5864317 , -0.19979174, -0.5721838 , 0.9190707 , 0.31628668, 0.08952013, 0.8719338 , 0.26684833, 0.8955768 , -0.9275499 , -0.81994563, 0.28863704, -0.16376448, 0.15855551, 0.04302022, 0.4440408 , -0.7293209 , 0.2255107 , 0.16333969, 0.38721767, -0.04512435, -0.5473172 , -0.5812051 , -0.8219114 , -0.43659028, -0.04860768, -0.8912252 , 0.62100273, 0.7187475 , -0.06158534, 0.6554498 , -0.62163985, 0.63035303, 0.19207267, -0.68847877, 0.10341872, -0.88906926, -0.38804066, -0.8157233 , -0.81641346, 0.8846337 , -0.70225614, 0.6281251 , -0.81235796, 0.77828485, 0.9393982 , -0.42554784, 0.4150426 , -0.32612413, -0.721988 , 0.96166253, -0.6080237 , -0.7312329 , 0.06843777, -0.09806018, -0.7357863 , -0.28613612, -0.8895085 , -0.9027925 , 0.56311375, 0.85699487, -0.32128897, 0.80635303, -0.01190906, -0.23292968, -0.5115769 , 0.17153661, -0.79993784, 0.6232265 , -0.06049479, -0.83510727, 0.9652135 , 0.08310007, -0.9671807 , -0.17466563, 0.48009604, 0.594712 , 0.19612817, -0.9279629 , -0.59968966, -0.36079255, -0.7250685 , 0.59395283, 0.7574965 , -0.4377294 , 0.45312116, 0.7117049 , -0.82085943, -0.10442825, 0.73688287, 0.38598123, 0.35439053, -0.3862137 , -0.56253886, 0.7388591 , -0.6024478 , -0.699977 , -0.46581215, -0.79513186, 0.09657894, 0.280869 , -0.38445532, -0.98311806]], dtype=float32)]","title":"TransformerLayer"},{"location":"KerasStyleAPIGuide/Layers/self-attention/#bert","text":"Bidirectional Encoder Representations from Transformers. Refer https://arxiv.org/pdf/1810.04805.pdf Input is a Table which consists of 4 tensors. 1. Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary 2. Token type id tensor: shape (batch, seqLen) with the token types in (0, 1). 0 means sentence A and 1 means a sentence B (see BERT paper for more details). 3. Position id tensor: shape (batch, seqLen) with positions in the sentence. 4. Attention_mask tensor: shape (batch, seqLen) with indices in (0, 1). It's a mask to be used if the input sequence length is smaller than seqLen in the current batch. Output is an Activity which output the states of BERT layer With Default Embedding: Scala: BERT[Float](vocab: Int = 40990, hiddenSize: Int = 768, nBlock: Int = 12, nHead: Int = 12, maxPositionLen: Int = 512, intermediateSize: Int = 3072, hiddenPDrop: Double = 0.1, attnPDrop: Double = 0.1, initializerRange: Double = 0.02, outputAllBlock: Boolean = true, inputSeqLen: Int = -1 ) Python: BERT.init(vocab=40990, hidden_size=768, n_block=12, n_head=12, seq_len=512, intermediate_size=3072, hidden_drop=0.1, attn_drop=0.1, initializer_range=0.02, output_all_block=True) Parameters: vocab : vocabulary size of training data, default is 40990 hiddenSize : size of the encoder layers, default is 768 nBlock : block number, default is 12 nHead : head number, default is 12 maxPositionLen : sequence length, default is 512 intermediateSize : The size of the \"intermediate\" (i.e., feed-forward), default is 3072 hiddenPDrop : The dropout probability for all fully connected layers, default is 0.1 attnPdrop : drop probability of attention, default is 0.1 initializerRange : weight initialization range, default is 0.02 outputAllBlock : whether output all blocks' output, default is false * inputSeqLen : sequence length of input, default is -1 which means the same with maxPositionLen With Customized Embedding: Scala: BERT[Float](nBlock = 12, nHead = 12, intermediateSize = 3072, hiddenPDrop = 0.1, attnPDrop = 0.1, initializerRange = 0.02, outputAllBlock = true, embeddingLayer = embedding) Python: BERT(n_block=12, n_head=12, intermediate_size=3072, hidden_drop=0.1, attn_drop=0.1, initializer_range=0.02, output_all_block=True, embedding_layer=embedding, input_shape=((seq_len,), (seq_len,), (seq_len,), (1, 1, seq_len))) Parameters: nBlock : block number nHead : head number intermediateSize : The size of the \"intermediate\" (i.e., feed-forward) hiddenPDrop : The dropout probability for all fully connected layers attnPdrop : drop probability of attention initializerRange : weight initialization range outputAllBlock : whether output all blocks' output embeddingLayer : embedding layer Loading from existing pretrained model: Scala: BERT[Float](path = , weightPath = null, inputSeqLen = 11, hiddenPDrop = 0.1, attnPDrop = 0.1, outputAllBlock = true) Python: BERT.init_from_existing_model(path= , weight_path=None, input_seq_len=-1.0, hidden_drop=-1.0, attn_drop=-1.0, output_all_block=True) Parameters: path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. Amazon S3 path should be like \"s3a://bucket/xxx\". weightPath : The path for pre-trained weights if any inputSeqLen : sequence length of input, will be ignored if existing model is built with customized embedding hiddenPDrop : The dropout probability for all fully connected layers, will be ignored if existing model is built with customized embedding * attnPdrop : drop probability of attention, will be ignored if existing model is built with customized embedding Scala example: val layer = BERT[Float](vocab = 100, hiddenSize = 10, nBlock = 3, nHead = 2, intermediateSize = 64, hiddenPDrop = 0.1, attnPDrop = 0.1, maxPositionLen = 10, outputAllBlock = false, inputSeqLen = 10) val shape = Shape(List(Shape(1, 10), Shape(1, 10), Shape(1, 10), Shape(1, 1, 1, 10))) layer.build(shape) val inputIds = Tensor[Float](Array[Float](7, 20, 39, 27, 10, 39, 30, 21, 17, 15), Array(1, 10)) val segmentIds = Tensor[Float](Array[Float](0, 0, 0, 0, 0, 1, 1, 1, 1, 1), Array(1, 10)) val positionIds = Tensor[Float](Array[Float](0, 1, 2, 3, 4, 5, 6, 7, 8, 9), Array(1, 10)) val masks = Tensor[Float](1, 1, 1, 10).fill(1.0f) val output = layer.forward(T(inputIds, segmentIds, positionIds, masks)) Input is: { 2: 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 4: (1,1,.,.) = 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x10] 1: 7.0 20.0 39.0 27.0 10.0 39.0 30.0 21.0 17.0 15.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 3: 0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] } Output is: { 2: 0.5398573 0.08571402 -0.9461041 -0.35362077 -0.24374364 0.24349216 0.9587727 -0.03278971 -0.826852 -0.8808889 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10] 1: (1,.,.) = 1.3381815 1.7575556 -1.1870699 0.8455374 -1.6000531 0.115945406 -0.33695826 -0.39254665 -0.33637434 -0.20421773 -0.08370285 0.056055143 -0.91990083 1.6324282 -0.093128644 -0.4484297 -2.0828273 0.10244746 0.577287 1.2597716 0.3563086 0.37092525 -0.5089354 0.4525072 1.7706354 0.65231055 -2.0269241 -0.2548585 0.3711578 -1.1831268 0.2429675 -0.023419544 -0.28389466 0.6601246 -0.009858845 -0.028412571 -2.5104556 1.0338438 1.3621751 -0.44306967 1.7147139 1.1627073 -0.19394834 0.8043055 -1.0080436 -1.7716306 -0.7668168 -0.19861369 0.45103902 -0.19371253 0.077525005 0.0722655 1.0745171 0.07997274 0.06562643 1.6474637 0.18938908 -2.377528 -0.6107291 -0.21850263 -1.3190242 1.7057956 0.32655835 0.5711799 -0.80318034 0.2776545 1.4860673 -0.676896 -0.39734793 -1.1708072 -0.4327645 -0.19849697 0.3695452 -0.08213705 1.2378154 0.591234 -1.505518 1.684885 -1.6251724 -0.03939093 0.6422535 -0.582018 1.6665243 -1.0995792 0.19488664 1.3563607 -0.60793823 -0.05846788 -1.7225715 0.21054967 -1.0927358 -0.37666538 0.70802236 -2.0131714 0.94964516 1.4701655 0.053027537 0.051168486 -0.58528 0.83582383 [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10x10] } Python example: layer = BERT.init( vocab=200, hidden_size=128, n_head=4, seq_len=20, intermediate_size=20) train_token = np.random.randint(20, size=(2, 20)) token_type_id = np.zeros((2, 20), dtype=np.int32) train_pos = np.zeros((2, 20), dtype=np.int32) mask_attention = np.ones((2, 1, 1, 20), dtype=np.int32) input = [train_token, token_type_id, train_pos, mask_attention] output = layer.forward(input) Input is: type 'list' : [array([[ 8, 19, 5, 8, 4, 13, 13, 12, 1, 6, 16, 14, 19, 0, 11, 18, 1, 17, 0, 0], [17, 10, 15, 19, 15, 2, 18, 8, 1, 11, 10, 17, 7, 2, 0, 0, 9, 14, 11, 6]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]], dtype=int32)] Output is type 'list' : [array([[[ 1.01330066e+00, 4.74100798e-01, 3.81211847e-01, ..., -8.00989151e-01, -6.18815482e-01, -1.09804094e+00], [-6.29726201e-02, 6.71391249e-01, -2.28019580e-01, ..., 3.97501498e-01, -3.32217604e-01, -2.04850674e+00], [ 5.04802346e-01, 1.00434709e+00, -7.63663530e-01, ..., -1.11675525e+00, 1.41550392e-01, -6.47688091e-01], ..., [ 5.07664750e-04, 6.47843182e-01, -5.33694960e-02, ..., -2.01566055e-01, -6.62943959e-01, -2.93835902e+00], [-1.49255514e-01, -5.47551095e-01, -3.36264402e-01, ..., 1.11121520e-01, -4.42977905e-01, -2.13847613e+00], [-1.33390293e-01, -5.50503194e-01, -3.49355727e-01, ..., 9.34313685e-02, -4.41935956e-01, -8.25921223e-02]], [[ 1.34967836e-02, 3.90778482e-02, -2.22317409e-02, ..., -9.81532633e-02, -6.08992100e-01, -2.77224326e+00], [-5.21431923e-01, -6.74456656e-02, -4.66892511e-01, ..., 1.05466165e-01, -2.67068297e-01, -9.00964141e-01], [ 9.41378593e-01, 5.21076620e-01, -5.35079956e-01, ..., -3.15736473e-01, 8.08603615e-02, -2.44178265e-01], ..., [ 4.16017324e-02, -5.65874994e-01, 6.68676615e-01, ..., -6.28256857e-01, -9.09847617e-02, -2.42878512e-01], [-1.36971796e+00, 5.37231266e-01, -1.33729517e+00, ..., -1.47498712e-01, 8.00304264e-02, -5.09030581e-01], [ 3.98404837e-01, -7.18296226e-03, -1.08256066e+00, ..., -5.17360926e-01, 5.50065935e-01, -2.32753420e+00]]], dtype=float32), array([[[ 1.0795887 , 0.44977495, 0.45561683, ..., -0.729603 , -0.6098092 , -1.0323973 ], [ 0.0154253 , 0.6424524 , -0.15503715, ..., 0.45100495, -0.3161888 , -1.9826275 ], [ 0.58491707, 0.9876782 , -0.69952184, ..., -1.0432141 , 0.1380458 , -0.5642554 ], ..., [ 0.06806332, 0.61824507, 0.02341641, ..., -0.21342012, -0.63312817, -2.8557966 ], [-0.06217962, -0.5528828 , -0.34740448, ..., 0.16651583, -0.41633344, -2.064906 ], [-0.04626712, -0.57442385, -0.277238 , ..., 0.13806444, -0.43256086, -0.01180306]], [[ 0.10532085, 0.01057051, 0.07536474, ..., -0.03406155, -0.572023 , -2.6935408 ], [-0.42477775, -0.10768362, -0.37653154, ..., 0.17155378, -0.27841952, -0.8244427 ], [ 1.0290473 , 0.5059685 , -0.5359356 , ..., -0.25725254, 0.1034779 , -0.16898313], ..., [ 0.14118548, -0.5945706 , 0.7681386 , ..., -0.55807835, -0.07778832, -0.15940095], [-1.2648381 , 0.50598496, -1.2431567 , ..., -0.06980868, 0.10642368, -0.4181047 ], [ 0.48330045, -0.05184587, -0.9985824 , ..., -0.5360492 , 0.56541353, -2.2607849 ]]], dtype=float32), array([[[ 1.1541002 , 0.47630545, 0.40673187, ..., -0.7284888 , -0.55945337, -1.0810231 ], [ 0.10070852, 0.64252985, -0.2007717 , ..., 0.4489277 , -0.24709189, -2.0173872 ], [ 0.67520154, 0.9793912 , -0.7441366 , ..., -1.0376649 , 0.20359974, -0.6060102 ], ..., [ 0.07809319, 0.63523245, -0.02464442, ..., -0.21328981, -0.5693355 , -2.8386393 ], [ 0.02228299, -0.5229728 , -0.33483037, ..., 0.16430138, -0.40036577, -2.094183 ], [ 0.02232744, -0.54113156, -0.3307599 , ..., 0.14321396, -0.3796677 , -0.04973204]], [[ 0.20497712, 0.02804335, 0.028764 , ..., -0.01617111, -0.5416485 , -2.7333891 ], [-0.3361876 , -0.08618001, -0.41299412, ..., 0.17708196, -0.23643918, -0.8763187 ], [ 1.1118197 , 0.5178778 , -0.57264006, ..., -0.2597192 , 0.15024357, -0.23373066], ..., [ 0.23304611, -0.57528406, 0.71815467, ..., -0.5524511 , -0.04103457, -0.15449452], [-1.1629226 , 0.5377656 , -1.2816569 , ..., -0.05795323, 0.1603044 , -0.47194824], [ 0.5773567 , -0.04114214, -1.0306932 , ..., -0.52537155, 0.5703101 , -2.3124278 ]]], dtype=float32), array([[[ 1.1319652e+00, 4.2663044e-01, 3.9611375e-01, ..., -7.7264631e-01, -5.3006041e-01, -1.0942854e+00], [ 7.3858641e-02, 6.1578143e-01, -2.0985913e-01, ..., 4.0289888e-01, -2.2484708e-01, -2.0233095e+00], [ 6.3545388e-01, 9.4610500e-01, -7.6165521e-01, ..., -1.0820770e+00, 2.2266804e-01, -6.0132843e-01], ..., [ 3.9479308e-02, 6.0636342e-01, -2.8302141e-02, ..., -2.6316714e-01, -5.5309945e-01, -2.8510940e+00], [-2.8412668e-03, -5.5100703e-01, -3.4540960e-01, ..., 1.5979633e-01, -3.8844827e-01, -2.0994248e+00], [-1.4572166e-02, -5.7526213e-01, -3.3382124e-01, ..., 1.0289014e-01, -3.6059290e-01, -6.5041430e-02]], [[ 1.5256011e-01, 3.3955947e-03, 1.7648729e-02, ..., -4.9600061e-02, -5.1613468e-01, -2.7417533e+00], [-3.6988521e-01, -8.8330485e-02, -4.2416954e-01, ..., 1.2959087e-01, -2.1623056e-01, -8.8821554e-01], [ 1.0618008e+00, 5.0827748e-01, -5.8256608e-01, ..., -2.9023758e-01, 1.6930477e-01, -2.3869993e-01], ..., [ 1.8475071e-01, -5.8594310e-01, 7.0973599e-01, ..., -5.9211296e-01, -1.7043589e-02, -1.5649734e-01], [-1.2073172e+00, 5.1577950e-01, -1.2952001e+00, ..., -1.0562765e-01, 1.8499596e-01, -4.6483174e-01], [ 5.8209622e-01, -5.3714752e-02, -1.0255412e+00, ..., -5.6718546e-01, 5.9832001e-01, -2.3260906e+00]]], dtype=float32), array([[[ 1.1358043 , 0.38664085, 0.43075162, ..., -0.762137 , -0.53836805, -1.1419276 ], [ 0.0705715 , 0.61749744, -0.1978054 , ..., 0.39686537, -0.23118263, -2.0863478 ], [ 0.6286853 , 0.9499371 , -0.75073713, ..., -1.0837915 , 0.20451419, -0.64585996], ..., [ 0.04084783, 0.5485716 , 0.02199897, ..., -0.265642 , -0.54954815, -2.8985202 ], [-0.00433184, -0.5782148 , -0.28893095, ..., 0.15305014, -0.3942154 , -2.1390564 ], [-0.01938614, -0.6034715 , -0.3210429 , ..., 0.11286073, -0.3612479 , -0.12291119]], [[ 0.13899514, -0.04281238, 0.05966739, ..., -0.05543021, -0.51721877, -2.7725601 ], [-0.38874203, -0.13524944, -0.37960985, ..., 0.12579904, -0.23764463, -0.94251025], [ 1.0436667 , 0.4891924 , -0.5470476 , ..., -0.30531114, 0.143379 , -0.28663573], ..., [ 0.17597033, -0.6172772 , 0.75050735, ..., -0.59396976, -0.02840331, -0.20918237], [-1.2121452 , 0.47985265, -1.2640744 , ..., -0.11457531, 0.17777829, -0.5216857 ], [ 0.5724598 , -0.08497301, -0.99838203, ..., -0.569392 , 0.5878865 , -2.3820512 ]]], dtype=float32), array([[[ 1.1923821 , 0.40376186, 0.4216827 , ..., -0.7753511 , -0.58085346, -1.1371452 ], [ 0.13859609, 0.6558944 , -0.1899949 , ..., 0.37358993, -0.27038255, -2.0870223 ], [ 0.7083764 , 0.977537 , -0.76046735, ..., -1.101789 , 0.1981793 , -0.6461577 ], ..., [ 0.10095584, 0.5967537 , 0.02207649, ..., -0.28193793, -0.5789527 , -2.9001386 ], [ 0.05901275, -0.53504837, -0.28481779, ..., 0.13802934, -0.41621858, -2.1443312 ], [ 0.04528951, -0.5612042 , -0.31392562, ..., 0.09289672, -0.38395336, -0.12475596]], [[ 0.19919002, -0.0038989 , 0.06975131, ..., -0.05898362, -0.5476832 , -2.7802918 ], [-0.32966843, -0.10950038, -0.3582222 , ..., 0.08165199, -0.2624505 , -0.93702954], [ 1.119693 , 0.5142474 , -0.5341173 , ..., -0.3251373 , 0.10789905, -0.30592436], ..., [ 0.24882485, -0.5699529 , 0.77695113, ..., -0.63034034, -0.07624292, -0.2281592 ], [-1.1650497 , 0.5175082 , -1.2281002 , ..., -0.14287077, 0.15133552, -0.532626 ], [ 0.64303875, -0.05680082, -0.9739305 , ..., -0.5787345 , 0.5447517 , -2.403577 ]]], dtype=float32), array([[[ 1.1747141 , 0.44174162, 0.3848741 , ..., -0.8011676 , -0.5708256 , -1.143519 ], [ 0.11874287, 0.7037242 , -0.22899102, ..., 0.36200705, -0.22287843, -2.0832918 ], [ 0.68290263, 1.0014081 , -0.8112288 , ..., -1.0980991 , 0.22316812, -0.637702 ], ..., [ 0.07541095, 0.63492006, 0.02669529, ..., -0.27486983, -0.53397936, -2.8813968 ], [ 0.07104072, -0.54481 , -0.33232585, ..., 0.12730087, -0.37563673, -2.1450465 ], [ 0.03186123, -0.51601535, -0.35520643, ..., 0.09008651, -0.33910847, -0.11906879]], [[ 0.19884765, 0.06095114, 0.00477777, ..., -0.0960753 , -0.49155453, -2.7463722 ], [-0.32222956, -0.08950429, -0.4053724 , ..., 0.05162536, -0.21072339, -0.9155606 ], [ 1.1117101 , 0.56429935, -0.59156317, ..., -0.3369357 , 0.14969075, -0.29045773], ..., [ 0.25635508, -0.5126209 , 0.7268977 , ..., -0.62107044, -0.01715574, -0.21087953], [-1.1460723 , 0.56120336, -1.2668271 , ..., -0.16734022, 0.19381218, -0.517316 ], [ 0.63978064, -0.01486263, -1.0128225 , ..., -0.56719303, 0.58368987, -2.3722165 ]]], dtype=float32), array([[[ 1.20512652e+00, 4.72038895e-01, 3.60962778e-01, ..., -9.00623977e-01, -5.82258105e-01, -1.14907408e+00], [ 1.55033678e-01, 7.28412509e-01, -2.72546947e-01, ..., 2.74131984e-01, -2.24478737e-01, -2.06169677e+00], [ 7.13116527e-01, 1.01666617e+00, -8.43635857e-01, ..., -1.18351495e+00, 2.21053749e-01, -6.17874563e-01], ..., [ 1.19287886e-01, 6.56103075e-01, -7.38978712e-03, ..., -3.54864419e-01, -5.37513494e-01, -2.87535477e+00], [ 1.16591401e-01, -5.55387378e-01, -3.71099353e-01, ..., 2.78753694e-02, -3.70597601e-01, -2.16417289e+00], [ 8.63942727e-02, -4.81025964e-01, -3.91344100e-01, ..., -1.84133966e-02, -3.39215338e-01, -1.10263892e-01]], [[ 2.64633745e-01, 7.25395158e-02, -1.39633343e-02, ..., -1.85173869e-01, -5.20042717e-01, -2.70796871e+00], [-2.58721560e-01, -6.35206550e-02, -4.14235502e-01, ..., 4.62563671e-02, -2.47269630e-01, -8.77729058e-01], [ 1.17845881e+00, 5.93900442e-01, -6.18097663e-01, ..., -4.23726231e-01, 1.19810022e-01, -2.55170494e-01], ..., [ 3.06802571e-01, -4.83913153e-01, 7.05836833e-01, ..., -6.99279726e-01, -5.64565696e-02, -1.74492225e-01], [-1.07746637e+00, 5.83848476e-01, -1.28454113e+00, ..., -2.29663596e-01, 1.96212217e-01, -5.23399591e-01], [ 7.02956200e-01, 2.42653489e-03, -1.03614473e+00, ..., -6.54396653e-01, 5.55146933e-01, -2.35132337e+00]]], dtype=float32), array([[[ 1.1732985 , 0.48227564, 0.4141097 , ..., -0.9222415 , -0.5581617 , -1.1467376 ], [ 0.10594734, 0.75098526, -0.23052076, ..., 0.23048519, -0.23638739, -2.033264 ], [ 0.6784295 , 1.0418617 , -0.810519 , ..., -1.2120562 , 0.24596576, -0.60291487], ..., [ 0.07915874, 0.6732479 , 0.02875949, ..., -0.38714084, -0.5037479 , -2.8571 ], [ 0.07176737, -0.52642834, -0.31701285, ..., -0.01229298, -0.34029967, -2.1321528 ], [ 0.04126783, -0.46029058, -0.34176344, ..., -0.05429364, -0.31155083, -0.10451217]], [[ 0.22600769, 0.09270672, 0.02146479, ..., -0.22232075, -0.48217994, -2.6969097 ], [-0.29719839, -0.05968198, -0.37710896, ..., 0.02224515, -0.20888865, -0.872187 ], [ 1.1335284 , 0.60064685, -0.58743286, ..., -0.45202363, 0.13883159, -0.2602308 ], ..., [ 0.27142784, -0.47967467, 0.70926106, ..., -0.71909636, -0.01251143, -0.1811402 ], [-1.095905 , 0.6111897 , -1.2443895 , ..., -0.27054876, 0.22430526, -0.5081292 ], [ 0.7027022 , 0.01059689, -1.0006222 , ..., -0.6746712 , 0.58800125, -2.352779 ]]], dtype=float32), array([[[ 1.2434555 , 0.44558033, 0.4151337 , ..., -0.8851603 , -0.5718673 , -1.1482117 ], [ 0.11962966, 0.72577155, -0.25604928, ..., 0.2687037 , -0.2457071 , -2.0307996 ], [ 0.763747 , 1.0119921 , -0.8592167 , ..., -1.1870402 , 0.2256221 , -0.6277423 ], ..., [ 0.08759235, 0.64535457, 0.03834408, ..., -0.35554865, -0.5139612 , -2.8475935 ], [ 0.13679026, -0.55156755, -0.32664305, ..., 0.01780019, -0.3558066 , -2.1313274 ], [ 0.11818186, -0.4789727 , -0.3590175 , ..., -0.01446133, -0.32358617, -0.10938768]], [[ 0.29418862, 0.09591774, 0.00587363, ..., -0.18236086, -0.49953887, -2.694323 ], [-0.22257486, -0.07352418, -0.4024905 , ..., 0.05929026, -0.22622454, -0.8882016 ], [ 1.19449 , 0.5713768 , -0.6041051 , ..., -0.4231223 , 0.1122172 , -0.28642637], ..., [ 0.3465784 , -0.4939726 , 0.68308717, ..., -0.68765515, -0.04439323, -0.20094715], [-1.0187647 , 0.59667283, -1.2578517 , ..., -0.24298497, 0.19871093, -0.53237087], [ 0.71921486, 0.00342394, -1.026827 , ..., -0.63569874, 0.5502706 , -2.3338537 ]]], dtype=float32), array([[[ 1.2440691 , 0.477769 , 0.40438044, ..., -0.8634442 , -0.516493 , -1.2156196 ], [ 0.09270077, 0.7480357 , -0.26808444, ..., 0.2696572 , -0.19946648, -2.0294373 ], [ 0.7727248 , 1.0203358 , -0.8804002 , ..., -1.1491328 , 0.26056868, -0.70166045], ..., [ 0.07362438, 0.6428618 , 0.02992919, ..., -0.3656686 , -0.47058144, -2.8904293 ], [ 0.11636666, -0.52916086, -0.3162666 , ..., 0.0035085 , -0.32273746, -2.211205 ], [ 0.09450418, -0.46651682, -0.38872302, ..., -0.02868051, -0.284238 , -0.20115192]], [[ 0.24763471, 0.10591529, -0.02833212, ..., -0.19653179, -0.44746324, -2.6951957 ], [-0.2705241 , -0.05053078, -0.38580215, ..., 0.0737243 , -0.18193349, -0.9320284 ], [ 1.1450722 , 0.5878723 , -0.6142542 , ..., -0.4155699 , 0.1653907 , -0.3516124 ], ..., [ 0.31275982, -0.48012054, 0.6611108 , ..., -0.6956505 , 0.01540092, -0.20229349], [-1.0758246 , 0.6180846 , -1.2664212 , ..., -0.20339848, 0.25243902, -0.5957573 ], [ 0.6647455 , 0.02233337, -1.0082287 , ..., -0.6396673 , 0.6092897 , -2.3386178 ]]], dtype=float32), array([[[ 1.16829467e+00, 4.73457277e-01, 3.55845094e-01, ..., -8.79491448e-01, -5.13881445e-01, -1.31691360e+00], [ 2.06558462e-02, 7.50393629e-01, -2.97149330e-01, ..., 2.75190771e-01, -1.88330606e-01, -2.13159895e+00], [ 6.88944340e-01, 1.01597929e+00, -9.25147057e-01, ..., -1.15003026e+00, 2.47588441e-01, -7.96685874e-01], ..., [ 2.88018938e-02, 6.88098967e-01, -2.68854816e-02, ..., -3.84741157e-01, -4.76365626e-01, -2.96942425e+00], [ 5.18963784e-02, -4.60506737e-01, -3.59559625e-01, ..., -1.14138005e-02, -3.24753582e-01, -2.23346853e+00], [ 7.39114806e-02, -4.01132107e-01, -4.24620807e-01, ..., -3.33240032e-02, -2.84682035e-01, -3.12762260e-01]], [[ 2.14906067e-01, 1.72432721e-01, -8.47420394e-02, ..., -2.10198522e-01, -4.30923790e-01, -2.79578996e+00], [-3.10599983e-01, 1.65538397e-03, -4.26579088e-01, ..., 5.09980768e-02, -1.56658575e-01, -1.01907480e+00], [ 1.09326482e+00, 6.40747488e-01, -6.59607410e-01, ..., -4.15965647e-01, 1.87072530e-01, -4.48307097e-01], ..., [ 2.86490113e-01, -4.34108675e-01, 6.18547022e-01, ..., -7.17846394e-01, 3.06018218e-02, -2.91922033e-01], [-1.13503909e+00, 6.14412308e-01, -1.32140326e+00, ..., -2.04109967e-01, 2.61365235e-01, -6.73554838e-01], [ 6.21745884e-01, 8.54183882e-02, -1.06341887e+00, ..., -6.34258091e-01, 6.15509987e-01, -2.41539836e+00]]], dtype=float32), array([[ 0.5620128 , -0.2001392 , -0.11440954, -0.04526514, -0.8816746 , -0.5549258 , 0.51452374, 0.13439347, 0.53412014, 0.46277392, 0.8692565 , -0.90509814, 0.31514823, 0.8086619 , 0.58900446, -0.3894673 , -0.45003602, 0.37346584, 0.69269675, 0.21574067, -0.72299725, 0.528553 , -0.83846116, 0.98062813, -0.05183166, 0.33388335, -0.63176596, 0.21661893, 0.43943346, 0.33758652, -0.24407507, -0.17800584, 0.59364974, 0.47616154, 0.558793 , 0.27490366, -0.9666731 , -0.8721832 , 0.743239 , 0.04293209, -0.5673905 , -0.14399827, -0.41138482, 0.8764746 , -0.11112919, 0.21457899, 0.88060266, 0.88843846, 0.18521515, -0.84538144, -0.57872075, 0.7840174 , 0.8682007 , -0.5286343 , 0.2563142 , 0.9634152 , 0.03505438, 0.91062546, 0.3279442 , -0.61855054, 0.22826263, 0.42789218, -0.48171976, -0.13283452, -0.86695194, 0.9060679 , 0.78916115, 0.16227603, -0.36374012, -0.5703023 , 0.19644596, -0.6927085 , 0.19042683, -0.43984833, -0.7866716 , 0.9690585 , -0.42288277, 0.8037468 , 0.70858365, 0.87470776, 0.630474 , 0.17134413, 0.99327976, -0.46532467, -0.00972999, 0.9460259 , 0.09055056, 0.7293024 , -0.9081666 , 0.15192512, -0.8813194 , -0.7241285 , 0.11484392, 0.5220332 , 0.6182944 , 0.5697724 , 0.80298615, -0.916839 , 0.8679731 , 0.3047138 , -0.7162764 , -0.852553 , 0.8317937 , 0.6582049 , -0.06668244, 0.36977607, 0.80465484, 0.10356631, 0.5558003 , 0.29966184, 0.93551975, -0.89290446, 0.15027076, -0.66376805, -0.6382408 , 0.6717352 , 0.9509484 , -0.79286 , -0.18582785, -0.36172768, -0.9791676 , -0.94657 , -0.47834975, 0.4030182 , 0.8983884 , 0.74833804, -0.24173705, -0.6059107 ], [ 0.01938096, -0.08230975, 0.2434453 , -0.8368162 , -0.31632444, -0.137336 , 0.8550923 , -0.51500845, 0.5093535 , 0.7847338 , 0.2958318 , -0.3608949 , 0.3377346 , 0.7592404 , -0.10613706, 0.45210105, -0.39598942, -0.32519925, 0.89480245, 0.6049605 , -0.81980604, 0.6129146 , 0.5854233 , 0.8875059 , 0.8888534 , 0.38860276, -0.81435287, -0.8599018 , -0.7989145 , 0.87724596, -0.09401844, 0.8232204 , 0.5973142 , -0.47759202, -0.2035289 , 0.86339366, -0.78711975, -0.8843788 , 0.50736386, 0.7154904 , 0.02759624, -0.29022685, -0.21070601, 0.37119249, -0.93711466, -0.41830346, 0.49852479, 0.7634121 , -0.73495114, -0.8023139 , -0.56360126, 0.7008394 , 0.9837745 , -0.09430382, 0.35603583, 0.98780483, 0.3609371 , -0.31916958, -0.48238578, -0.65934813, 0.67085034, -0.43169144, 0.86363876, -0.1453511 , -0.8397705 , -0.35035503, 0.88129896, 0.16335464, 0.34733585, 0.24485897, -0.5006221 , -0.9430847 , -0.80959797, -0.8578838 , -0.7431067 , 0.49626076, -0.03579912, -0.5582668 , 0.9786438 , 0.2536843 , 0.895339 , -0.42590025, 0.9813974 , 0.4913268 , -0.95859706, 0.5229873 , -0.75750285, 0.01685579, -0.37524623, -0.4403388 , -0.91602516, -0.63672376, 0.28235126, 0.5060775 , 0.03505507, 0.8782664 , 0.06858374, -0.81789017, 0.41628596, 0.9114354 , 0.79067975, -0.76645094, 0.90893763, 0.95445615, -0.8870664 , 0.50881255, 0.30905575, 0.4437762 , -0.2528932 , -0.14799164, 0.93950725, -0.7908481 , 0.44684762, -0.9644589 , 0.37588173, 0.9690541 , -0.6058538 , 0.2965665 , -0.07335383, -0.6774956 , -0.9477332 , -0.8670143 , 0.03564278, -0.8282162 , 0.24308446, 0.5860108 , -0.93586445, -0.8312509 ]], dtype=float32)]","title":"BERT"},{"location":"KerasStyleAPIGuide/Layers/wrappers/","text":"KerasLayerWrapper Wrap a torch style layer to keras style layer. This layer can be built multiple times. Scala: KerasLayerWrapper(torchLayer, inputShape = null) Python: KerasLayerWrapper(torch_layer, input_shape=None) Parameters: torchLayer : a torch style layer. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.nn.Linear import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20)) model.add(dense) val input = Tensor[Float](2, 20).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 0.55278283 -0.5434559 -0.13098523 0.3069534 -0.12007129 0.031956512 -0.019634819 -0.09178751 -1.2957728 1.3516346 1.3507701 -0.93318635 -1.1111038 1.0057137 0.093072094 0.16315712 -0.18079235 0.80998576 0.6703253 0.21223836 -1.007659 1.5507021 -0.14909777 0.49734116 1.4081444 0.1438721 1.7318599 -1.3321369 -0.6123855 0.43861434 0.9198252 1.1758715 -0.5824179 -0.90594006 -0.33974242 -0.58157283 1.3687168 -2.160458 -0.18854974 0.4541929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.5819317 0.7231704 0.21700777 -0.1763548 0.02167879 0.19229038 0.7264892 -0.7566038 -0.8883222 0.47539598 -0.92322034 -0.33127156 0.48748493 -0.7715719 1.0859711 0.5226875 -0.6108173 -0.29417562 0.75702786 0.009688854 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10] Python example: import numpy as np from zoo.pipeline.api.keras.layers import KerasLayerWrapper from zoo.pipeline.api.keras.models import Sequential from bigdl.nn.layer import Linear model = Sequential() model.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, ))) input = np.random.random([2, 20]) output = model.forward(input) Input is: [[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444, 0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214, 0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721, 0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057], [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703, 0.74951992, 0.71846465, 0.72513163, 0.141432 , 0.54936796, 0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522, 0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]] Output is [[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539, 0.03494176, -0.66940045, 0.6229225 , 0.38492152, -0.527405 ], [-0.36529738, -0.57997525, 0.08127502, -0.7578952 , -0.1762895 , -0.10188193, -0.18423618, 0.37726521, 0.21360731, -0.5451691 ]]","title":"Layer Wrappers"},{"location":"KerasStyleAPIGuide/Layers/wrappers/#keraslayerwrapper","text":"Wrap a torch style layer to keras style layer. This layer can be built multiple times. Scala: KerasLayerWrapper(torchLayer, inputShape = null) Python: KerasLayerWrapper(torch_layer, input_shape=None) Parameters: torchLayer : a torch style layer. inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a Shape object. For Python API, it should be a shape tuple. Batch dimension should be excluded. Scala example: import com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential import com.intel.analytics.bigdl.nn.Linear import com.intel.analytics.bigdl.utils.Shape import com.intel.analytics.bigdl.tensor.Tensor val model = Sequential[Float]() val dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20)) model.add(dense) val input = Tensor[Float](2, 20).randn() val output = model.forward(input) Input is: input: com.intel.analytics.bigdl.tensor.Tensor[Float] = 0.55278283 -0.5434559 -0.13098523 0.3069534 -0.12007129 0.031956512 -0.019634819 -0.09178751 -1.2957728 1.3516346 1.3507701 -0.93318635 -1.1111038 1.0057137 0.093072094 0.16315712 -0.18079235 0.80998576 0.6703253 0.21223836 -1.007659 1.5507021 -0.14909777 0.49734116 1.4081444 0.1438721 1.7318599 -1.3321369 -0.6123855 0.43861434 0.9198252 1.1758715 -0.5824179 -0.90594006 -0.33974242 -0.58157283 1.3687168 -2.160458 -0.18854974 0.4541929 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20] Output is: output: com.intel.analytics.bigdl.nn.abstractnn.Activity = 0.5819317 0.7231704 0.21700777 -0.1763548 0.02167879 0.19229038 0.7264892 -0.7566038 -0.8883222 0.47539598 -0.92322034 -0.33127156 0.48748493 -0.7715719 1.0859711 0.5226875 -0.6108173 -0.29417562 0.75702786 0.009688854 [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10] Python example: import numpy as np from zoo.pipeline.api.keras.layers import KerasLayerWrapper from zoo.pipeline.api.keras.models import Sequential from bigdl.nn.layer import Linear model = Sequential() model.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, ))) input = np.random.random([2, 20]) output = model.forward(input) Input is: [[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444, 0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214, 0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721, 0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057], [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703, 0.74951992, 0.71846465, 0.72513163, 0.141432 , 0.54936796, 0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522, 0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]] Output is [[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539, 0.03494176, -0.66940045, 0.6229225 , 0.38492152, -0.527405 ], [-0.36529738, -0.57997525, 0.08127502, -0.7578952 , -0.1762895 , -0.10188193, -0.18423618, 0.37726521, 0.21360731, -0.5451691 ]]","title":"KerasLayerWrapper"},{"location":"KerasStyleAPIGuide/Optimization/objectives/","text":"Usage of objectives An objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model: Scala: model.compile(loss = mean_squared_error , optimizer = sgd ) Python: model.compile(loss='mean_squared_error', optimizer='sgd') Scala: model.compile(loss = MeanSquaredError(sizeAverage = true), optimizer = sgd ) Python: model.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd') Available objectives MeanSquaredError The mean squared error criterion e.g. input: a, target: b, total elements: n loss(a, b) = 1/n * sum(|a_i - b_i|^2) Scala: loss = MeanSquaredError(sizeAverage = true) Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanSquaredError(size_average=True) Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True MeanAbsoluteError Measures the mean absolute value of the element-wise difference between input and target Scala: loss = MeanAbsoluteError(sizeAverage = true) Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanAbsoluteError(size_average=True) Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True BinaryCrossEntropy Also known as logloss. Scala: loss = BinaryCrossEntropy(weights = null, sizeAverage = true) Parameters: weights A tensor assigning weight to each of the classes sizeAverage whether to divide the sequence length. Default is true. Python: loss = BinaryCrossEntropy(weights=None, size_average=True) Parameters: weights A tensor assigning weight to each of the classes size_average whether to divide the sequence length. Default is True. SparseCategoricalCrossEntropy A loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0. Scala: loss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1) Parameters: logProbAsInput Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities. zeroBasedLabel Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1. weights Tensor. Weights of each class if you have an unbalanced training set. Default is null. sizeAverage Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch. paddingValue Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1. Python: loss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1) Parameters: log_prob_as_input Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities. zero_based_label Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1. weights A Numpy array. Weights of each class if you have an unbalanced training set. Default is None. size_average Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch. padding_value Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1. MeanAbsolutePercentageError Compute mean absolute percentage error for intput and target Scala: loss = MeanAbsolutePercentageError() Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanAbsolutePercentageError() Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True MeanSquaredLogarithmicError Compute mean squared logarithmic error for input and target Scala: loss = MeanSquaredLogarithmicError() Python: loss = MeanSquaredLogarithmicError() CategoricalCrossEntropy This is same with cross entropy criterion, except the target tensor is a one-hot tensor. Scala: loss = CategoricalCrossEntropy() Python: loss = CategoricalCrossEntropy() Hinge Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y. Scala: loss = Hinge(margin = 1.0, sizeAverage = true) Parameters: margin if unspecified, is by default 1. sizeAverage whether to average the loss, is by default true Python: loss = Hinge(margin=1.0, size_average=True) Parameters: margin if unspecified, is by default 1. size_average whether to average the loss, is by default True RankHinge Hinge loss for pairwise ranking problems. Scala: loss = RankHinge(margin = 1.0) Parameters: margin if unspecified, is by default 1. Python: loss = RankHinge(margin=1.0) Parameters: margin if unspecified, is by default 1. SquaredHinge Creates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y. Scala: loss = SquaredHinge(margin = 1.0, sizeAverage = true) Parameters: margin if unspecified, is by default 1. sizeAverage whether to average the loss, is by default true Python: loss = SquaredHinge(margin=1.0, size_average=True) Parameters: margin if unspecified, is by default 1. size_average whether to average the loss, is by default True Poisson Compute Poisson error for intput and target Scala: loss = Poisson() Python: loss = Poisson() CosineProximity Computes the negative of the mean cosine proximity between predictions and targets. Scala: loss = CosineProximity() Python: loss = CosineProximity() KullbackLeiblerDivergence Loss calculated as: y_true = K.clip(y_true, K.epsilon(), 1) y_pred = K.clip(y_pred, K.epsilon(), 1) and output K.sum(y_true * K.log(y_true / y_pred), axis=-1) Scala: loss = KullbackLeiblerDivergence() Python: loss = KullbackLeiblerDivergence()","title":"Objectives"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#usage-of-objectives","text":"An objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model: Scala: model.compile(loss = mean_squared_error , optimizer = sgd ) Python: model.compile(loss='mean_squared_error', optimizer='sgd') Scala: model.compile(loss = MeanSquaredError(sizeAverage = true), optimizer = sgd ) Python: model.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd')","title":"Usage of objectives"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#available-objectives","text":"","title":"Available objectives"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#meansquarederror","text":"The mean squared error criterion e.g. input: a, target: b, total elements: n loss(a, b) = 1/n * sum(|a_i - b_i|^2) Scala: loss = MeanSquaredError(sizeAverage = true) Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanSquaredError(size_average=True) Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True","title":"MeanSquaredError"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#meanabsoluteerror","text":"Measures the mean absolute value of the element-wise difference between input and target Scala: loss = MeanAbsoluteError(sizeAverage = true) Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanAbsoluteError(size_average=True) Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True","title":"MeanAbsoluteError"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#binarycrossentropy","text":"Also known as logloss. Scala: loss = BinaryCrossEntropy(weights = null, sizeAverage = true) Parameters: weights A tensor assigning weight to each of the classes sizeAverage whether to divide the sequence length. Default is true. Python: loss = BinaryCrossEntropy(weights=None, size_average=True) Parameters: weights A tensor assigning weight to each of the classes size_average whether to divide the sequence length. Default is True.","title":"BinaryCrossEntropy"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#sparsecategoricalcrossentropy","text":"A loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0. Scala: loss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1) Parameters: logProbAsInput Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities. zeroBasedLabel Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1. weights Tensor. Weights of each class if you have an unbalanced training set. Default is null. sizeAverage Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch. paddingValue Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1. Python: loss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1) Parameters: log_prob_as_input Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities. zero_based_label Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1. weights A Numpy array. Weights of each class if you have an unbalanced training set. Default is None. size_average Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch. padding_value Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.","title":"SparseCategoricalCrossEntropy"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#meanabsolutepercentageerror","text":"Compute mean absolute percentage error for intput and target Scala: loss = MeanAbsolutePercentageError() Parameters: sizeAverage a boolean indicating whether to divide the sum of squared error by n. Default: true Python: loss = MeanAbsolutePercentageError() Parameters: size_average a boolean indicating whether to divide the sum of squared error by n. Default: True","title":"MeanAbsolutePercentageError"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#meansquaredlogarithmicerror","text":"Compute mean squared logarithmic error for input and target Scala: loss = MeanSquaredLogarithmicError() Python: loss = MeanSquaredLogarithmicError()","title":"MeanSquaredLogarithmicError"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#categoricalcrossentropy","text":"This is same with cross entropy criterion, except the target tensor is a one-hot tensor. Scala: loss = CategoricalCrossEntropy() Python: loss = CategoricalCrossEntropy()","title":"CategoricalCrossEntropy"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#hinge","text":"Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y. Scala: loss = Hinge(margin = 1.0, sizeAverage = true) Parameters: margin if unspecified, is by default 1. sizeAverage whether to average the loss, is by default true Python: loss = Hinge(margin=1.0, size_average=True) Parameters: margin if unspecified, is by default 1. size_average whether to average the loss, is by default True","title":"Hinge"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#rankhinge","text":"Hinge loss for pairwise ranking problems. Scala: loss = RankHinge(margin = 1.0) Parameters: margin if unspecified, is by default 1. Python: loss = RankHinge(margin=1.0) Parameters: margin if unspecified, is by default 1.","title":"RankHinge"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#squaredhinge","text":"Creates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y. Scala: loss = SquaredHinge(margin = 1.0, sizeAverage = true) Parameters: margin if unspecified, is by default 1. sizeAverage whether to average the loss, is by default true Python: loss = SquaredHinge(margin=1.0, size_average=True) Parameters: margin if unspecified, is by default 1. size_average whether to average the loss, is by default True","title":"SquaredHinge"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#poisson","text":"Compute Poisson error for intput and target Scala: loss = Poisson() Python: loss = Poisson()","title":"Poisson"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#cosineproximity","text":"Computes the negative of the mean cosine proximity between predictions and targets. Scala: loss = CosineProximity() Python: loss = CosineProximity()","title":"CosineProximity"},{"location":"KerasStyleAPIGuide/Optimization/objectives/#kullbackleiblerdivergence","text":"Loss calculated as: y_true = K.clip(y_true, K.epsilon(), 1) y_pred = K.clip(y_pred, K.epsilon(), 1) and output K.sum(y_true * K.log(y_true / y_pred), axis=-1) Scala: loss = KullbackLeiblerDivergence() Python: loss = KullbackLeiblerDivergence()","title":"KullbackLeiblerDivergence"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/","text":"Usage of optimizers An optimizer is one of the two arguments required for compiling a model. Scala: model.compile(loss = mean_squared_error , optimizer = sgd ) Python: model.compile(loss='mean_squared_error', optimizer='sgd') Scala: model.compile(loss = mean_squared_error , optimizer = Adam()) Python: model.compile(loss='mean_squared_error', optimizer=Adam()) Available optimizers SGD A plain implementation of SGD which provides optimize method. After setting optimization method when create Optimize, Optimize will call optimization method at the end of each iteration. Scala: val optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, nesterov = false, learningRateSchedule = Default(), learningRates = null, weightDecays = null) Parameters: learningRate : learning rate learningRateDecay : learning rate decay weightDecay : weight decay momentum : momentum dampening : dampening for momentum nesterov : enables Nesterov momentum learningRateSchedule : learning rate scheduler learningRates : 1D tensor of individual learning rates weightDecays : 1D tensor of individual weight decays Python: optim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, momentum=0.0, dampening=DOUBLEMAX, nesterov=False, leaningrate_schedule=None, learningrates=None, weightdecays=None) Parameters: learningrate : learning rate learningrate_decay : learning rate decay weightdecay : weight decay momentum : momentum dampening : dampening for momentum nesterov : enables Nesterov momentum leaningrate_schedule : learning rate scheduler learningrates : 1D tensor of individual learning rates weightdecays : 1D tensor of individual weight decays Adam An implementation of Adam optimization, first-order gradient-based optimization of stochastic objective functions. http://arxiv.org/pdf/1412.6980.pdf Scala: val optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8) Parameters: learningRate learning rate. Default value is 1e-3. learningRateDecay learning rate decay. Default value is 0.0. beta1 first moment coefficient. Default value is 0.9. beta2 second moment coefficient. Default value is 0.999. Epsilon for numerical stability. Default value is 1e-8. Python: optim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8) Parameters: learningrate learning rate. Default value is 1e-3. learningrate_decay learning rate decay. Default value is 0.0. beta1 first moment coefficient. Default value is 0.9. beta2 second moment coefficient. Default value is 0.999. epsilon for numerical stability. Default value is 1e-8. Adamax An implementation of Adamax: http://arxiv.org/pdf/1412.6980.pdf Scala: val optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8) Parameters: learningRate : learning rate beta1 : first moment coefficient beta2 : second moment coefficient Epsilon : for numerical stability Python: optim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8) Parameters: learningrate : learning rate beta1 : first moment coefficient beta2 : second moment coefficient epsilon : for numerical stability Adadelta AdaDelta implementation for SGD It has been proposed in ADADELTA: An Adaptive Learning Rate Method . http://arxiv.org/abs/1212.5701. Scala: val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10) Parameters: decayRate : decayRate, also called interpolation parameter rho Epsilon : for numerical stability Python: optim_method = AdaDelta(decayrate=0.9, epsilon=1e-10) Parameters: decayrate : decayRate, also called interpolation parameter rho epsilon : for numerical stability Adagrad An implementation of Adagrad. See the original paper: http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf Scala: val optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0) learningRate : learning rate learningRateDecay : learning rate decay weightDecay : weight decay Python: optim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0) Parameters: learningrate : learning rate learningrate_decay : learning rate decay weightdecay : weight decay Rmsprop An implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf , Sec 4.2) Scala: val optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8) Parameters: learningRate : learning rate learningRateDecay : learning rate decay decayRate : decayRate, also called rho Epsilon : for numerical stability Python: optim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8) Parameters: learningrate : learning rate learningrate_decay : learning rate decay decayrate : decayRate, also called rho epsilon : for numerical stability","title":"Optimizers"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#usage-of-optimizers","text":"An optimizer is one of the two arguments required for compiling a model. Scala: model.compile(loss = mean_squared_error , optimizer = sgd ) Python: model.compile(loss='mean_squared_error', optimizer='sgd') Scala: model.compile(loss = mean_squared_error , optimizer = Adam()) Python: model.compile(loss='mean_squared_error', optimizer=Adam())","title":"Usage of optimizers"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#available-optimizers","text":"","title":"Available optimizers"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#sgd","text":"A plain implementation of SGD which provides optimize method. After setting optimization method when create Optimize, Optimize will call optimization method at the end of each iteration. Scala: val optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, nesterov = false, learningRateSchedule = Default(), learningRates = null, weightDecays = null) Parameters: learningRate : learning rate learningRateDecay : learning rate decay weightDecay : weight decay momentum : momentum dampening : dampening for momentum nesterov : enables Nesterov momentum learningRateSchedule : learning rate scheduler learningRates : 1D tensor of individual learning rates weightDecays : 1D tensor of individual weight decays Python: optim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, momentum=0.0, dampening=DOUBLEMAX, nesterov=False, leaningrate_schedule=None, learningrates=None, weightdecays=None) Parameters: learningrate : learning rate learningrate_decay : learning rate decay weightdecay : weight decay momentum : momentum dampening : dampening for momentum nesterov : enables Nesterov momentum leaningrate_schedule : learning rate scheduler learningrates : 1D tensor of individual learning rates weightdecays : 1D tensor of individual weight decays","title":"SGD"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#adam","text":"An implementation of Adam optimization, first-order gradient-based optimization of stochastic objective functions. http://arxiv.org/pdf/1412.6980.pdf Scala: val optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8) Parameters: learningRate learning rate. Default value is 1e-3. learningRateDecay learning rate decay. Default value is 0.0. beta1 first moment coefficient. Default value is 0.9. beta2 second moment coefficient. Default value is 0.999. Epsilon for numerical stability. Default value is 1e-8. Python: optim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8) Parameters: learningrate learning rate. Default value is 1e-3. learningrate_decay learning rate decay. Default value is 0.0. beta1 first moment coefficient. Default value is 0.9. beta2 second moment coefficient. Default value is 0.999. epsilon for numerical stability. Default value is 1e-8.","title":"Adam"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#adamax","text":"An implementation of Adamax: http://arxiv.org/pdf/1412.6980.pdf Scala: val optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8) Parameters: learningRate : learning rate beta1 : first moment coefficient beta2 : second moment coefficient Epsilon : for numerical stability Python: optim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8) Parameters: learningrate : learning rate beta1 : first moment coefficient beta2 : second moment coefficient epsilon : for numerical stability","title":"Adamax"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#adadelta","text":"AdaDelta implementation for SGD It has been proposed in ADADELTA: An Adaptive Learning Rate Method . http://arxiv.org/abs/1212.5701. Scala: val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10) Parameters: decayRate : decayRate, also called interpolation parameter rho Epsilon : for numerical stability Python: optim_method = AdaDelta(decayrate=0.9, epsilon=1e-10) Parameters: decayrate : decayRate, also called interpolation parameter rho epsilon : for numerical stability","title":"Adadelta"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#adagrad","text":"An implementation of Adagrad. See the original paper: http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf Scala: val optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0) learningRate : learning rate learningRateDecay : learning rate decay weightDecay : weight decay Python: optim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0) Parameters: learningrate : learning rate learningrate_decay : learning rate decay weightdecay : weight decay","title":"Adagrad"},{"location":"KerasStyleAPIGuide/Optimization/optimizers/#rmsprop","text":"An implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf , Sec 4.2) Scala: val optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8) Parameters: learningRate : learning rate learningRateDecay : learning rate decay decayRate : decayRate, also called rho Epsilon : for numerical stability Python: optim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8) Parameters: learningrate : learning rate learningrate_decay : learning rate decay decayrate : decayRate, also called rho epsilon : for numerical stability","title":"Rmsprop"},{"location":"KerasStyleAPIGuide/Optimization/training/","text":"This page shows how to train, evaluate or predict a model using the Keras-Style API. You may refer to the User Guide page to see how to define a model in Python or Scala correspondingly. You may refer to Layers section to find all the available layers. After defining a model with the Keras-Style API, you can call the following methods on the model: Compile Configure the learning process. Must be called before fit or evaluate . Scala: compile(optimizer, loss, metrics = null) Parameters: optimizer : Optimization method to be used. loss : Criterion to be used. metrics : Validation method(s) to be used. Default is null if no validation is needed. Alternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\") Python compile(optimizer, loss, metrics=None) Parameters: optimizer : Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'. loss : Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see here ). metrics : List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy']. Fit Train a model for a fixed number of epochs on a DataSet. Scala: fit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null) Parameters: x : Training dataset. RDD of Sample or ImageSet or TextSet . batchSize : Number of samples per gradient update. Default is 32. nbEpoch : Number of epochs to train. Default is 10. validationData : RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null. Python fit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True) Parameters: x : Training data. A Numpy array or RDD of Sample or ImageSet or TextSet . y : Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet. batch_size : Number of samples per gradient update. Default is 32. nb_epoch : Number of epochs to train. Default is 10. validation_data : Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays. Can also be RDD of Sample or ImageSet or TextSet. Default is None if no validation is involved. distributed : Boolean. Whether to train the model in distributed mode or local mode. Default is True. In local mode, x and y must both be Numpy arrays. Evaluate Evaluate a model on a given dataset in distributed mode. Scala: evaluate(x, batchSize = 32) Parameters: x : Evaluation dataset. RDD of Sample or ImageSet or TextSet . batchSize : Number of samples per batch. Default is 32. Python evaluate(x, y=None, batch_size=32) Parameters: x : Evaluation data. A Numpy array or RDD of Sample or ImageSet or TextSet . y : Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet. batch_size : Number of samples per batch. Default is 32. Predict Use a model to do prediction. Scala: predict(x, batchPerThread = 4) Parameters: x : Prediction dataset. RDD of Sample or ImageSet or TextSet . batchPerThread : The total batchSize is batchPerThread * numOfCores. Python predict(x, batch_per_thread=4, distributed=True) Parameters: x : Prediction data. A Numpy array or RDD of Sample or ImageSet or TextSet . batch_per_thread : The default value is 4. When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False, the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array. Use a model to predict class labels. Scala: predictClasses(x, batchPerThread = 4, zeroBasedLabel = true) Parameters: x : Prediction dataset. RDD of Sample or ImageSet or TextSet . batchPerThread : The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions. zeroBasedLabel : Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1. Python predict_classes(x, batch_per_thread=4, zero_based_label=True) Parameters: x : Prediction data. A Numpy array or RDD of Sample or ImageSet or TextSet . batch_per_thread : The default value is 4. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. zero_based_label : Boolean. Whether result labels start from 0. Default is True. If False, result labels start from 1.","title":"Train, evaluate or predict a model"},{"location":"KerasStyleAPIGuide/Optimization/training/#compile","text":"Configure the learning process. Must be called before fit or evaluate . Scala: compile(optimizer, loss, metrics = null) Parameters: optimizer : Optimization method to be used. loss : Criterion to be used. metrics : Validation method(s) to be used. Default is null if no validation is needed. Alternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\") Python compile(optimizer, loss, metrics=None) Parameters: optimizer : Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'. loss : Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see here ). metrics : List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy'].","title":"Compile"},{"location":"KerasStyleAPIGuide/Optimization/training/#fit","text":"Train a model for a fixed number of epochs on a DataSet. Scala: fit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null) Parameters: x : Training dataset. RDD of Sample or ImageSet or TextSet . batchSize : Number of samples per gradient update. Default is 32. nbEpoch : Number of epochs to train. Default is 10. validationData : RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null. Python fit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True) Parameters: x : Training data. A Numpy array or RDD of Sample or ImageSet or TextSet . y : Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet. batch_size : Number of samples per gradient update. Default is 32. nb_epoch : Number of epochs to train. Default is 10. validation_data : Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays. Can also be RDD of Sample or ImageSet or TextSet. Default is None if no validation is involved. distributed : Boolean. Whether to train the model in distributed mode or local mode. Default is True. In local mode, x and y must both be Numpy arrays.","title":"Fit"},{"location":"KerasStyleAPIGuide/Optimization/training/#evaluate","text":"Evaluate a model on a given dataset in distributed mode. Scala: evaluate(x, batchSize = 32) Parameters: x : Evaluation dataset. RDD of Sample or ImageSet or TextSet . batchSize : Number of samples per batch. Default is 32. Python evaluate(x, y=None, batch_size=32) Parameters: x : Evaluation data. A Numpy array or RDD of Sample or ImageSet or TextSet . y : Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet. batch_size : Number of samples per batch. Default is 32.","title":"Evaluate"},{"location":"KerasStyleAPIGuide/Optimization/training/#predict","text":"Use a model to do prediction. Scala: predict(x, batchPerThread = 4) Parameters: x : Prediction dataset. RDD of Sample or ImageSet or TextSet . batchPerThread : The total batchSize is batchPerThread * numOfCores. Python predict(x, batch_per_thread=4, distributed=True) Parameters: x : Prediction data. A Numpy array or RDD of Sample or ImageSet or TextSet . batch_per_thread : The default value is 4. When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False, the total batch size is batch_per_thread * numOfCores. distributed : Boolean. Whether to do prediction in distributed mode or local mode. Default is True. In local mode, x must be a Numpy array. Use a model to predict class labels. Scala: predictClasses(x, batchPerThread = 4, zeroBasedLabel = true) Parameters: x : Prediction dataset. RDD of Sample or ImageSet or TextSet . batchPerThread : The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions. zeroBasedLabel : Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1. Python predict_classes(x, batch_per_thread=4, zero_based_label=True) Parameters: x : Prediction data. A Numpy array or RDD of Sample or ImageSet or TextSet . batch_per_thread : The default value is 4. When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions. When distributed is False the total batch size is batch_per_thread * numOfCores. zero_based_label : Boolean. Whether result labels start from 0. Default is True. If False, result labels start from 1.","title":"Predict"},{"location":"ProgrammingGuide/anomaly-detection/","text":"Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. A sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions. Hightlights Keras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training. Models are defined base on LSTM. Build an AnomalyDetction model You can call the following API in Scala and Python respectively to create an AnomalyDetrctor model Scala import com.intel.analytics.zoo.models.anomalydetection._ val model = AnomalyDetector(featureShape, hiddenLayers, dropouts) featureShape The input shape of features, fist dimension is unroll length, second dimension is feature size. hiddenLayers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Python from zoo.models.anomalydetection import AnomalyDetector model = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2]) feature_shape The input shape of features, fist dimension is unroll length, second dimension is feature size. hidden_layers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Train an AnomalyDetector model After building the model, we can compile and train it using RDD of Sample . Note that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples. Scala import com.intel.analytics.bigdl.optim._ model.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9), loss = MeanSquaredError[Float]()) model.fit(trainRdd, batchSize = 1024, nbEpoch = 20) Python model.compile(loss='mse', optimizer='rmsprop') model.fit(train, batch_size = 1024, nb_epoch = 20) Do prediction to detect anomalies After training the model, it can be used to predict values using previous data, then to detect anomalies. Anomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top anomalySize data points are anomalies). Scala val yPredict = model.predict(testRdd).map(x = x.toTensor.toArray()(0)) val yTruth: RDD[Float] = testRdd.map(x = x.label.toArray()(0)) val anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20) Python y_predict = model.predict(test).map(lambda x: float(x[0])) y_test = test.map(lambda x: float(x.label.to_ndarray()[0])) anomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20) Examples We provide examples to train the AnomalyDetector model and detect possible anomalies using data of NYC taxi passengers See here for the Scala example. See here for the Python example. See a Python notebook for defining and training a model using simple Keras layers, and more details.","title":"Anomaly Detection API"},{"location":"ProgrammingGuide/anomaly-detection/#build-an-anomalydetction-model","text":"You can call the following API in Scala and Python respectively to create an AnomalyDetrctor model Scala import com.intel.analytics.zoo.models.anomalydetection._ val model = AnomalyDetector(featureShape, hiddenLayers, dropouts) featureShape The input shape of features, fist dimension is unroll length, second dimension is feature size. hiddenLayers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1. Python from zoo.models.anomalydetection import AnomalyDetector model = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2]) feature_shape The input shape of features, fist dimension is unroll length, second dimension is feature size. hidden_layers Units of hidden layers of LSTM. dropouts Fraction of the input units to drop out. Float between 0 and 1.","title":"Build an AnomalyDetction model"},{"location":"ProgrammingGuide/anomaly-detection/#train-an-anomalydetector-model","text":"After building the model, we can compile and train it using RDD of Sample . Note that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples. Scala import com.intel.analytics.bigdl.optim._ model.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9), loss = MeanSquaredError[Float]()) model.fit(trainRdd, batchSize = 1024, nbEpoch = 20) Python model.compile(loss='mse', optimizer='rmsprop') model.fit(train, batch_size = 1024, nb_epoch = 20)","title":"Train an AnomalyDetector model"},{"location":"ProgrammingGuide/anomaly-detection/#do-prediction-to-detect-anomalies","text":"After training the model, it can be used to predict values using previous data, then to detect anomalies. Anomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top anomalySize data points are anomalies). Scala val yPredict = model.predict(testRdd).map(x = x.toTensor.toArray()(0)) val yTruth: RDD[Float] = testRdd.map(x = x.label.toArray()(0)) val anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20) Python y_predict = model.predict(test).map(lambda x: float(x[0])) y_test = test.map(lambda x: float(x.label.to_ndarray()[0])) anomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20)","title":"Do prediction to detect anomalies"},{"location":"ProgrammingGuide/anomaly-detection/#examples","text":"We provide examples to train the AnomalyDetector model and detect possible anomalies using data of NYC taxi passengers See here for the Scala example. See here for the Python example. See a Python notebook for defining and training a model using simple Keras layers, and more details.","title":"Examples"},{"location":"ProgrammingGuide/autograd/","text":"Overview autograd provides automatic differentiation for math operations, so that you can easily build your own custom loss and layer (in both Python and Scala), as illustracted below. (See more examples here ). Conceptually we use reverse mode together with the chain rule for automatic differentiation. Variable is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input variables and roots are the output variables . CustomLoss 1.Define a custom function using autograd from zoo.pipeline.api.autograd import * def mean_absolute_error(y_true, y_pred): return mean(abs(y_true - y_pred), axis=1) Use CustomLoss in compile method. # You can pass the loss function directly into `loss` model.compile(optimizer = SGD(), loss = mean_absolute_error) model.fit(x = ..., y = ...) Use CustomLoss in nnframe pipeline. # 1) Create a CustomLoss object from function. loss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2]) # 2) Passing the CustomLoss object to NNClassifier. classifier = NNClassifier(lrModel, loss, SeqToTensor([1000])) Use forward and backward to evaluate a CustomLoss for debugging. # y_pred_shape=[2] is a shape without batch loss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2]) error = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2])) grad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2])) Lambda layer 1.Define custom function using autograd from zoo.pipeline.api.autograd import * def add_one_func(x): return x + 1.0 2.Define model using Keras-style API and custom Lambda layer from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * model = Sequential().add(Dense(1, input_shape=(2,))) \\ .add(Lambda(function=add_one_func)) # Evaluation for debug purpose. model.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size Construct variable computation without Lambda layer The returning type for each operation is a Variable , so you can connect those Variable together freely without using Lambda . i.e Dense[Float](3).from(input2) or input1 + input2 Shape inference is supported as well, which means you can check the output shape of a Variable by calling get_output_shape() Python import zoo.pipeline.api.autograd as auto from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * input = Input(shape=[2, 20]) # create a variable time = TimeDistributed(layer=Dense(30))(input) # time is a variable t1 = time.index_select(1, 0) # t1 is a variable t2 = time.index_select(1, 1) diff = auto.abs(t1 - t2) assert diff.get_output_shape() == (None, 30) assert diff.get_input_shape() == (None, 30) model = Model(input, diff) data = np.random.uniform(0, 1, [10, 2, 20]) output = model.forward(data) Scala - In respect of backward compatibility, the scala API is slightly different with the python API. - layer.inputs(node) would return a node(backward compatibility). - layer.from(variable) would return a variable.(You may want to use this style as it can support autograd.) import com.intel.analytics.zoo.pipeline.api.autograd.Variable import com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad import com.intel.analytics.zoo.pipeline.api.keras.models.Model import com.intel.analytics.zoo.pipeline.api.keras.layers._ val input1 = Variable[Float](inputShape = Shape(3)) val input2 = Variable[Float](inputShape = Shape(3)) val diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2)) val model = Model[Float](input = Array(input1, input2), output = diff) val inputValue = Tensor[Float](1, 3).randn() // In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table. val out = model.forward(T(inputValue, inputValue)).toTensor[Float] Define a model using trainable Parameter Build a Linear Model (Wx + b) by using trainable Parameter which is equivalent to use Dense layer. * Scala import com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable} import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input = Variable[Float](Shape(3)) val w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize val bias = Parameter[Float](Shape(2)) val cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias val model = Model[Float](input = input, output = cDense) Python from zoo.pipeline.api.autograd import * from zoo.pipeline.api.keras.models import * input = Variable((3,)) w = Parameter((2, 3)) # outputSize * inputSize bias = Parameter((2,)) cDense = mm(input, w, axes = (1, 1)) + bias model = Model(input = input, output = cDense)","title":"Autograd"},{"location":"ProgrammingGuide/autograd/#overview","text":"autograd provides automatic differentiation for math operations, so that you can easily build your own custom loss and layer (in both Python and Scala), as illustracted below. (See more examples here ). Conceptually we use reverse mode together with the chain rule for automatic differentiation. Variable is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input variables and roots are the output variables .","title":"Overview"},{"location":"ProgrammingGuide/autograd/#customloss","text":"1.Define a custom function using autograd from zoo.pipeline.api.autograd import * def mean_absolute_error(y_true, y_pred): return mean(abs(y_true - y_pred), axis=1) Use CustomLoss in compile method. # You can pass the loss function directly into `loss` model.compile(optimizer = SGD(), loss = mean_absolute_error) model.fit(x = ..., y = ...) Use CustomLoss in nnframe pipeline. # 1) Create a CustomLoss object from function. loss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2]) # 2) Passing the CustomLoss object to NNClassifier. classifier = NNClassifier(lrModel, loss, SeqToTensor([1000])) Use forward and backward to evaluate a CustomLoss for debugging. # y_pred_shape=[2] is a shape without batch loss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2]) error = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2])) grad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))","title":"CustomLoss"},{"location":"ProgrammingGuide/autograd/#lambda-layer","text":"1.Define custom function using autograd from zoo.pipeline.api.autograd import * def add_one_func(x): return x + 1.0 2.Define model using Keras-style API and custom Lambda layer from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * model = Sequential().add(Dense(1, input_shape=(2,))) \\ .add(Lambda(function=add_one_func)) # Evaluation for debug purpose. model.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size","title":"Lambda layer"},{"location":"ProgrammingGuide/autograd/#construct-variable-computation-without-lambda-layer","text":"The returning type for each operation is a Variable , so you can connect those Variable together freely without using Lambda . i.e Dense[Float](3).from(input2) or input1 + input2 Shape inference is supported as well, which means you can check the output shape of a Variable by calling get_output_shape() Python import zoo.pipeline.api.autograd as auto from zoo.pipeline.api.keras.layers import * from zoo.pipeline.api.keras.models import * input = Input(shape=[2, 20]) # create a variable time = TimeDistributed(layer=Dense(30))(input) # time is a variable t1 = time.index_select(1, 0) # t1 is a variable t2 = time.index_select(1, 1) diff = auto.abs(t1 - t2) assert diff.get_output_shape() == (None, 30) assert diff.get_input_shape() == (None, 30) model = Model(input, diff) data = np.random.uniform(0, 1, [10, 2, 20]) output = model.forward(data) Scala - In respect of backward compatibility, the scala API is slightly different with the python API. - layer.inputs(node) would return a node(backward compatibility). - layer.from(variable) would return a variable.(You may want to use this style as it can support autograd.) import com.intel.analytics.zoo.pipeline.api.autograd.Variable import com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad import com.intel.analytics.zoo.pipeline.api.keras.models.Model import com.intel.analytics.zoo.pipeline.api.keras.layers._ val input1 = Variable[Float](inputShape = Shape(3)) val input2 = Variable[Float](inputShape = Shape(3)) val diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2)) val model = Model[Float](input = Array(input1, input2), output = diff) val inputValue = Tensor[Float](1, 3).randn() // In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table. val out = model.forward(T(inputValue, inputValue)).toTensor[Float]","title":"Construct variable computation without Lambda layer"},{"location":"ProgrammingGuide/autograd/#define-a-model-using-trainable-parameter","text":"Build a Linear Model (Wx + b) by using trainable Parameter which is equivalent to use Dense layer. * Scala import com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable} import com.intel.analytics.zoo.pipeline.api.keras.models.Model val input = Variable[Float](Shape(3)) val w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize val bias = Parameter[Float](Shape(2)) val cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias val model = Model[Float](input = input, output = cDense) Python from zoo.pipeline.api.autograd import * from zoo.pipeline.api.keras.models import * input = Variable((3,)) w = Parameter((2, 3)) # outputSize * inputSize bias = Parameter((2,)) cDense = mm(input, w, axes = (1, 1)) + bias model = Model(input = input, output = cDense)","title":"Define a model using trainable Parameter"},{"location":"ProgrammingGuide/bert-classifier/","text":"Analytics Zoo provides a built-in BERTClassifier in TFPark for Natural Language Processing (NLP) classification tasks based on TFEstimator and BERT. Bidirectional Encoder Representations from Transformers (BERT) is Google's state-of-the-art pre-trained NLP model. You may refer to here for more details. BERTClassifier is a pre-built TFEstimator that takes the hidden state of the first token to do classification. In this page, we show the general steps how to train and evaluate an BERTClassifier in a distributed fashion and use this estimator for distributed inference. Remarks : You need to install tensorflow==1.10 on your driver node. Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other systems, you need to manually compile the TensorFlow source code. Instructions can be found here . BERTClassifier Construction You can easily construct an estimator for classification based on BERT using the following API. from zoo.tfpark.text.estimator import BERTClassifier estimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint, optimizer=tf.train.AdamOptimizer(learning_rate), model_dir= /tmp/bert ) Data Preparation BERT has three inputs of the same sequence length: input_ids, input_mask and token_type_ids. The preprocessing steps should follow BERT's conventions. You may refer to BERT TensorFlow run_classifier example for more details. To construct the input function for BERTClassifier, you can use the following API: from zoo.tfpark.text.estimator import bert_input_fn input_fn = bert_input_fn(rdd, max_seq_length, batch_size) For training and evaluation, each element in rdd should be a tuple: (feature dict, label). Label is supposed to be an integer. For prediction, each element in rdd should be a feature dict. The keys of feature dict should be input_ids , input_mask and token_type_ids and the values should be the corresponding preprocessed results of max_seq_length for a record. Estimator Training You can easily call train to train the BERTClassifier in a distributed fashion. estimator.train(train_input_fn, steps) You can find the trained checkpoints saved under model_dir , which is specified when you initiate BERTClassifier. Estimator Evaluation You can easily call evaluate to evaluate the BERTClassifier in a distributed fashion using top1 accuracy. result = estimator.evaluate(eval_input_fn, eval_methods=[ acc ]) Estimator Inference You can easily call predict to use the trained BERTClassifier for distributed inference. predictions_rdd = estimator.predict(test_input_fn)","title":"BERT Classifier"},{"location":"ProgrammingGuide/bert-classifier/#bertclassifier-construction","text":"You can easily construct an estimator for classification based on BERT using the following API. from zoo.tfpark.text.estimator import BERTClassifier estimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint, optimizer=tf.train.AdamOptimizer(learning_rate), model_dir= /tmp/bert )","title":"BERTClassifier Construction"},{"location":"ProgrammingGuide/bert-classifier/#data-preparation","text":"BERT has three inputs of the same sequence length: input_ids, input_mask and token_type_ids. The preprocessing steps should follow BERT's conventions. You may refer to BERT TensorFlow run_classifier example for more details. To construct the input function for BERTClassifier, you can use the following API: from zoo.tfpark.text.estimator import bert_input_fn input_fn = bert_input_fn(rdd, max_seq_length, batch_size) For training and evaluation, each element in rdd should be a tuple: (feature dict, label). Label is supposed to be an integer. For prediction, each element in rdd should be a feature dict. The keys of feature dict should be input_ids , input_mask and token_type_ids and the values should be the corresponding preprocessed results of max_seq_length for a record.","title":"Data Preparation"},{"location":"ProgrammingGuide/bert-classifier/#estimator-training","text":"You can easily call train to train the BERTClassifier in a distributed fashion. estimator.train(train_input_fn, steps) You can find the trained checkpoints saved under model_dir , which is specified when you initiate BERTClassifier.","title":"Estimator Training"},{"location":"ProgrammingGuide/bert-classifier/#estimator-evaluation","text":"You can easily call evaluate to evaluate the BERTClassifier in a distributed fashion using top1 accuracy. result = estimator.evaluate(eval_input_fn, eval_methods=[ acc ])","title":"Estimator Evaluation"},{"location":"ProgrammingGuide/bert-classifier/#estimator-inference","text":"You can easily call predict to use the trained BERTClassifier for distributed inference. predictions_rdd = estimator.predict(test_input_fn)","title":"Estimator Inference"},{"location":"ProgrammingGuide/data/","text":"ImageSet ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read an ImageSet from local/distributed folder, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala example: Create LocalImageSet, assume there is an image file \"/tmp/test.jpg\" and an image folder \"/tmp/image/\" import com.intel.analytics.bigdl.transform.vision.image.ImageFeature import com.intel.analytics.zoo.feature.image.ImageSet // create LocalImageSet from an image val localImageSet = ImageSet.read( /tmp/test.jpg ) // create LocalImageSet from an image folder val localImageSet2 = ImageSet.read( /tmp/image/ ) // create LocalImageSet from array of ImageFeature val array = Array[ImageFeature]() val localImageSet3 = ImageSet.array(array) Create DistributedImageSet, assume there is an image file \"/tmp/test.jpg\" and an image folder import com.intel.analytics.bigdl.transform.vision.image.ImageFeature import com.intel.analytics.zoo.feature.image.ImageSet import org.apache.spark.SparkContext import org.apache.spark.sql.SQLContext val conf = new SparkConf().setAppName( ImageSpec ).setMaster( local[2] ) val sc = NNContext.initNNContext(conf) val sqlContext = new SQLContext(sc) // create DistributedImageSet from an image val distributedImageSet = ImageSet.read( /tmp/test.jpg , sc, 2) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) // create DistributedImageSet from rdd of ImageFeature val array = Array[ImageFeature]() val rdd = sc.parallelize(array) val distributedImageSet3 = ImageSet.rdd(rdd) Python example: Create LocalImageSet from bigdl.util.common import * from zoo.feature.image.imageset import * # create LocalImageSet from an image local_image_set = ImageSet.read( /tmp/test.jpg ) # create LocalImageSet from an image folder local_image_set2 = ImageSet.read( /tmp/image/ ) # create LocalImageSet from list of images image = cv2.imread( /tmp/test.jpg ) local_image_set3 = LocalImageSet([image]) Create DistributedImageSet from zoo.common.nncontext import * from zoo.feature.image.imageset import * sc = init_nncontext(init_spark_conf().setMaster( local[2] ).setAppName( test image )) # create DistributedImageSet from an image distributed_image_set = ImageSet.read( /tmp/test.jpg , sc, 2) # create DistributedImageSet from an image folder distributed_image_set = ImageSet.read( /tmp/image/ , sc, 2) # create DistributedImageSet from image rdd image = cv2.imread( /tmp/test.jpg ) image_rdd = sc.parallelize([image], 2) distributed_image_set = DistributedImageSet(image_rdd)","title":"Data"},{"location":"ProgrammingGuide/data/#imageset","text":"ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read an ImageSet from local/distributed folder, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala example: Create LocalImageSet, assume there is an image file \"/tmp/test.jpg\" and an image folder \"/tmp/image/\" import com.intel.analytics.bigdl.transform.vision.image.ImageFeature import com.intel.analytics.zoo.feature.image.ImageSet // create LocalImageSet from an image val localImageSet = ImageSet.read( /tmp/test.jpg ) // create LocalImageSet from an image folder val localImageSet2 = ImageSet.read( /tmp/image/ ) // create LocalImageSet from array of ImageFeature val array = Array[ImageFeature]() val localImageSet3 = ImageSet.array(array) Create DistributedImageSet, assume there is an image file \"/tmp/test.jpg\" and an image folder import com.intel.analytics.bigdl.transform.vision.image.ImageFeature import com.intel.analytics.zoo.feature.image.ImageSet import org.apache.spark.SparkContext import org.apache.spark.sql.SQLContext val conf = new SparkConf().setAppName( ImageSpec ).setMaster( local[2] ) val sc = NNContext.initNNContext(conf) val sqlContext = new SQLContext(sc) // create DistributedImageSet from an image val distributedImageSet = ImageSet.read( /tmp/test.jpg , sc, 2) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) // create DistributedImageSet from rdd of ImageFeature val array = Array[ImageFeature]() val rdd = sc.parallelize(array) val distributedImageSet3 = ImageSet.rdd(rdd) Python example: Create LocalImageSet from bigdl.util.common import * from zoo.feature.image.imageset import * # create LocalImageSet from an image local_image_set = ImageSet.read( /tmp/test.jpg ) # create LocalImageSet from an image folder local_image_set2 = ImageSet.read( /tmp/image/ ) # create LocalImageSet from list of images image = cv2.imread( /tmp/test.jpg ) local_image_set3 = LocalImageSet([image]) Create DistributedImageSet from zoo.common.nncontext import * from zoo.feature.image.imageset import * sc = init_nncontext(init_spark_conf().setMaster( local[2] ).setAppName( test image )) # create DistributedImageSet from an image distributed_image_set = ImageSet.read( /tmp/test.jpg , sc, 2) # create DistributedImageSet from an image folder distributed_image_set = ImageSet.read( /tmp/image/ , sc, 2) # create DistributedImageSet from image rdd image = cv2.imread( /tmp/test.jpg ) image_rdd = sc.parallelize([image], 2) distributed_image_set = DistributedImageSet(image_rdd)","title":"ImageSet"},{"location":"ProgrammingGuide/image-classification/","text":"Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink. Image Classification examples Analytics Zoo provides several typical kind of pre-trained Image Classfication models : Alexnet , Inception-V1 , VGG , Resnet , Densenet , Mobilenet , Squeezenet models. To use these models, please check below examples. Scala Scala example It's very easy to apply the model for inference with below code piece. val imc = ImageClassifier.loadModel[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val output = imc.predictImageSet(data) User can also define his own configuration to do the inference with below code piece. val imc = ImageClassifier.loadModel[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preprocessing) val output = imc.predictImageSet(data, config) Python Python example It's very easy to apply the model for inference with below code piece. imc = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = imc.predict_image_set(image_set) User can also define his own configuration to do the inference with below code piece. imc = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(preprocessing) output = imc.predict_image_set(image_set) For preprocessors for Image Classification models, please check Image Classification Config Download link Alexnet Alexnet Quantize Inception-V1 Inception-V1 Quantize Inception-V3 Inception-V3 Quantize VGG-16 VGG-16 Quantize VGG-19 VGG-19 Quantize Resnet-50 Resnet-50 Quantize Resnet-50 Int8 Densenet-161 Densenet-161 Quantize Mobilenet Mobilenet-V2 Mobilenet-V2 Quantize Squeezenet Squeezenet Quantize","title":"Image Classification API"},{"location":"ProgrammingGuide/image-classification/#image-classification-examples","text":"Analytics Zoo provides several typical kind of pre-trained Image Classfication models : Alexnet , Inception-V1 , VGG , Resnet , Densenet , Mobilenet , Squeezenet models. To use these models, please check below examples. Scala Scala example It's very easy to apply the model for inference with below code piece. val imc = ImageClassifier.loadModel[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val output = imc.predictImageSet(data) User can also define his own configuration to do the inference with below code piece. val imc = ImageClassifier.loadModel[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val preprocessing = ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() val config = ImageConfigure[Float](preprocessing) val output = imc.predictImageSet(data, config) Python Python example It's very easy to apply the model for inference with below code piece. imc = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = imc.predict_image_set(image_set) User can also define his own configuration to do the inference with below code piece. imc = ImageClassifier.load_model(model_path) image_set = ImageSet.read(img_path, sc) preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(preprocessing) output = imc.predict_image_set(image_set) For preprocessors for Image Classification models, please check Image Classification Config","title":"Image Classification examples"},{"location":"ProgrammingGuide/image-classification/#download-link","text":"Alexnet Alexnet Quantize Inception-V1 Inception-V1 Quantize Inception-V3 Inception-V3 Quantize VGG-16 VGG-16 Quantize VGG-19 VGG-19 Quantize Resnet-50 Resnet-50 Quantize Resnet-50 Int8 Densenet-161 Densenet-161 Quantize Mobilenet Mobilenet-V2 Mobilenet-V2 Quantize Squeezenet Squeezenet Quantize","title":"Download link"},{"location":"ProgrammingGuide/inference/","text":"Inference Model is a package in Analytics Zoo aiming to provide high-level APIs to speed-up development. It allows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Inference Model provides Java, Scala and Python interfaces. Highlights Easy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Support transformation of various input data type, thus supporting future prediction tasks. Transparently support the OpenVINO toolkit, which deliver a significant boost for inference speed ( up to 19.9x ). Load and predict with pre-trained model Basic usage of Inference Model: Directly use InferenceModel or write a subclass extends InferenceModel ( AbstractInferenceModel in Java). Load pre-trained models with corresponding load methods, e.g, doLoad for Analytics Zoo, and doLoadTF for TensorFlow. Do prediction with predict method. Supported models: Analytics Zoo Models Caffe Models TensorFlow Models OpenVINO models Predict input and output predictInput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Input data for prediction. JTensor is a 1D List, with Array[Int] shape. predictOutput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Prediction result. OpenVINO requirements: System requirements : Ubuntu 16.04.3 LTS (64 bit) Windows 10 (64 bit) CentOS 7.4 (64 bit) macOS 10.13, 10.14 (64 bit) Python requirements: tensorflow =1.2.0 networkx =1.11 numpy =1.12.0 protobuf==3.6.1 Java Write a subclass that extends AbstractInferenceModel , implement or override methods. Then, load model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with load , loadCaffe , doLoadOpenVINO and loadTF ), and do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel; import com.intel.analytics.zoo.pipeline.inference.JTensor; public class ExtendedInferenceModel extends AbstractInferenceModel { public ExtendedInferenceModel() { super(); } } ExtendedInferenceModel model = new ExtendedInferenceModel(); // Load Analytics Zoo model model.load(modelPath, weightPath); // Predict List List JTensor result = model.predict(inputList); Scala New an instance of InferenceModel , and load model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with doLoad , doLoadCaffe , doLoadOpenVINO and doLoadTF ), then do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.InferenceModel val model = new InferenceModel() // Load Analytics Zoo model model.doLoad(modelPath, weightPath) // Predict val result = model.doPredict(inputList) In some cases, you may want to write a subclass that extends InferenceModel , implement or override methods. Then, load model with corresponding load methods, and do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.InferenceModel class ExtendedInferenceModel extends InferenceModel { } val model = new ExtendedInferenceModel() // Load Analytics Zoo model model.doLoad(modelPath, weightPath) // Predict val result = model.doPredict(inputList) Python New an instance of InferenceModel , and load Zoo model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with load , load_caffe , load_openvino and load_tf ), then do prediction with predict method. from zoo.pipeline.inference import InferenceModel model = InferenceModel() # Load Analytics Zoo model model.load(model_path, weight_path) # Predict result = model.predict(input_list) In some cases, you may want to write a subclass that extends InferenceModel , implement or override methods. Then, load model with corresponding load methods, and do prediction with predict method. from zoo.pipeline.inference import InferenceModel class ExtendedInferenceModel(InferenceModel): def __init__(self): pass model = ExtendedInferenceModel() # Load Analytics Zoo model model.load(model_path, weight_path) # Predict result = model.predict(input_list) Examples We provide examples based on InferenceModel. See here for the Java example. See here for the Scala example.","title":"Model Serving"},{"location":"ProgrammingGuide/inference/#load-and-predict-with-pre-trained-model","text":"Basic usage of Inference Model: Directly use InferenceModel or write a subclass extends InferenceModel ( AbstractInferenceModel in Java). Load pre-trained models with corresponding load methods, e.g, doLoad for Analytics Zoo, and doLoadTF for TensorFlow. Do prediction with predict method. Supported models: Analytics Zoo Models Caffe Models TensorFlow Models OpenVINO models Predict input and output predictInput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Input data for prediction. JTensor is a 1D List, with Array[Int] shape. predictOutput : JList[JList[JTensor]] or Tensor for Scale and Java, Numpy for Python. Prediction result. OpenVINO requirements: System requirements : Ubuntu 16.04.3 LTS (64 bit) Windows 10 (64 bit) CentOS 7.4 (64 bit) macOS 10.13, 10.14 (64 bit) Python requirements: tensorflow =1.2.0 networkx =1.11 numpy =1.12.0 protobuf==3.6.1 Java Write a subclass that extends AbstractInferenceModel , implement or override methods. Then, load model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with load , loadCaffe , doLoadOpenVINO and loadTF ), and do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel; import com.intel.analytics.zoo.pipeline.inference.JTensor; public class ExtendedInferenceModel extends AbstractInferenceModel { public ExtendedInferenceModel() { super(); } } ExtendedInferenceModel model = new ExtendedInferenceModel(); // Load Analytics Zoo model model.load(modelPath, weightPath); // Predict List List JTensor result = model.predict(inputList); Scala New an instance of InferenceModel , and load model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with doLoad , doLoadCaffe , doLoadOpenVINO and doLoadTF ), then do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.InferenceModel val model = new InferenceModel() // Load Analytics Zoo model model.doLoad(modelPath, weightPath) // Predict val result = model.doPredict(inputList) In some cases, you may want to write a subclass that extends InferenceModel , implement or override methods. Then, load model with corresponding load methods, and do prediction with predict method. import com.intel.analytics.zoo.pipeline.inference.InferenceModel class ExtendedInferenceModel extends InferenceModel { } val model = new ExtendedInferenceModel() // Load Analytics Zoo model model.doLoad(modelPath, weightPath) // Predict val result = model.doPredict(inputList) Python New an instance of InferenceModel , and load Zoo model with corresponding load methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with load , load_caffe , load_openvino and load_tf ), then do prediction with predict method. from zoo.pipeline.inference import InferenceModel model = InferenceModel() # Load Analytics Zoo model model.load(model_path, weight_path) # Predict result = model.predict(input_list) In some cases, you may want to write a subclass that extends InferenceModel , implement or override methods. Then, load model with corresponding load methods, and do prediction with predict method. from zoo.pipeline.inference import InferenceModel class ExtendedInferenceModel(InferenceModel): def __init__(self): pass model = ExtendedInferenceModel() # Load Analytics Zoo model model.load(model_path, weight_path) # Predict result = model.predict(input_list)","title":"Load and predict with pre-trained model"},{"location":"ProgrammingGuide/inference/#examples","text":"We provide examples based on InferenceModel. See here for the Java example. See here for the Scala example.","title":"Examples"},{"location":"ProgrammingGuide/metrics/","text":"ValidationMethod is a method to validate the model during model training or evaluation. The trait can be extended by user-defined method. In addition of the ValidationMethods provided in BigDL, Zoo provides several extra metrics for practical industry applications. AUC Area under the ROC curve. More information about ROC can be found https://en.wikipedia.org/wiki/Receiver_operating_characteristic It's used to evaluate a binary(0/1 only) classification mode. It supports single label and multiple labels. Scala: val validation = new AUC(20) example val conf = Engine.createSparkConf() .setAppName( AUC test ) .setMaster( local[1] ) val sc = NNContext.initNNContext(conf) val data = new Array[Sample[Float]](4) var i = 0 while (i data.length) { val input = Tensor[Float](2).fill(1.0f) val label = Tensor[Float](2).fill(1.0f) data(i) = Sample(input, label) i += 1 } val model = Sequential[Float]().add(Linear(2, 2)).add(LogSoftMax()) val dataSet = sc.parallelize(data, 4) val result = model.evaluate(dataSet, Array(new AUC[Float](20).asInstanceOf[ValidationMethod[Float]])) Python: validation = AUC(20) example from zoo.common.nncontext import * from bigdl.nn.layer import * from zoo.pipeline.api.keras.metrics import AUC sc = init_nncontext() data_len = 4 batch_size = 8 FEATURES_DIM = 2 def gen_rand_sample(): features = np.random.uniform(0, 1, (FEATURES_DIM)) label = np.ones(FEATURES_DIM) return Sample.from_ndarray(features, label) trainingData = sc.parallelize(range(0, data_len)).map( lambda i: gen_rand_sample()) model = Sequential() model.add(Linear(2, 2)).add(LogSoftMax()) test_results = model.evaluate(trainingData, batch_size, [AUC(20)])","title":"Metrics"},{"location":"ProgrammingGuide/metrics/#auc","text":"Area under the ROC curve. More information about ROC can be found https://en.wikipedia.org/wiki/Receiver_operating_characteristic It's used to evaluate a binary(0/1 only) classification mode. It supports single label and multiple labels. Scala: val validation = new AUC(20) example val conf = Engine.createSparkConf() .setAppName( AUC test ) .setMaster( local[1] ) val sc = NNContext.initNNContext(conf) val data = new Array[Sample[Float]](4) var i = 0 while (i data.length) { val input = Tensor[Float](2).fill(1.0f) val label = Tensor[Float](2).fill(1.0f) data(i) = Sample(input, label) i += 1 } val model = Sequential[Float]().add(Linear(2, 2)).add(LogSoftMax()) val dataSet = sc.parallelize(data, 4) val result = model.evaluate(dataSet, Array(new AUC[Float](20).asInstanceOf[ValidationMethod[Float]])) Python: validation = AUC(20) example from zoo.common.nncontext import * from bigdl.nn.layer import * from zoo.pipeline.api.keras.metrics import AUC sc = init_nncontext() data_len = 4 batch_size = 8 FEATURES_DIM = 2 def gen_rand_sample(): features = np.random.uniform(0, 1, (FEATURES_DIM)) label = np.ones(FEATURES_DIM) return Sample.from_ndarray(features, label) trainingData = sc.parallelize(range(0, data_len)).map( lambda i: gen_rand_sample()) model = Sequential() model.add(Linear(2, 2)).add(LogSoftMax()) test_results = model.evaluate(trainingData, batch_size, [AUC(20)])","title":"AUC"},{"location":"ProgrammingGuide/nnframes/","text":"Overview NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to facilitate Spark users and speed-up development. It supports native integration with Spark ML Pipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib. NNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and Spark 2.x. Highlights Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models. Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML. In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL. Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep). Rich toolset for feature extraction and processing, including image, audio and texts. Examples: The examples are included in the Analytics Zoo source code. image classification: model inference using pre-trained Inception v1 model. Scala version Python version image classification: transfer learning from pre-trained Inception v1 model. Scala version Python version Primary APIs NNEstimator and NNModel Analytics Zoo provides NNEstimator for model training with Spark DataFrame, which provides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer pattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator is a NNModel, which is a Spark ML Transformer. please check our NNEstimator API for detailed usage. NNClassifier and NNClassifierModel NNClassifier and NNClassifierModel extends NNEstimator and NNModel and focus on classification tasks, where both label column and prediction column are of Double type. NNImageReader NNImageReader loads image into Spark DataFrame. please check our ImageProcessing for detailed usage.","title":"DataFrame and ML Pipeline"},{"location":"ProgrammingGuide/nnframes/#overview","text":"NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to facilitate Spark users and speed-up development. It supports native integration with Spark ML Pipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib. NNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and Spark 2.x. Highlights Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models. Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML. In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL. Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep). Rich toolset for feature extraction and processing, including image, audio and texts.","title":"Overview"},{"location":"ProgrammingGuide/nnframes/#examples","text":"The examples are included in the Analytics Zoo source code. image classification: model inference using pre-trained Inception v1 model. Scala version Python version image classification: transfer learning from pre-trained Inception v1 model. Scala version Python version","title":"Examples:"},{"location":"ProgrammingGuide/nnframes/#primary-apis","text":"NNEstimator and NNModel Analytics Zoo provides NNEstimator for model training with Spark DataFrame, which provides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer pattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator is a NNModel, which is a Spark ML Transformer. please check our NNEstimator API for detailed usage. NNClassifier and NNClassifierModel NNClassifier and NNClassifierModel extends NNEstimator and NNModel and focus on classification tasks, where both label column and prediction column are of Double type. NNImageReader NNImageReader loads image into Spark DataFrame. please check our ImageProcessing for detailed usage.","title":"Primary APIs"},{"location":"ProgrammingGuide/object-detection/","text":"Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Apache Spark, Apache Storm or Apache Flink. Object Detection examples Analytics Zoo provides two typical kind of pre-trained Object Detection models : SSD and Faster-RCNN on dataset PASCAL and COCO . For the usage of these models, please check below examples. Scala Scala example It's very easy to apply the model for inference with below code piece. val model = ObjectDetector.load[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val output = model.predictImageSet(data) For preprocessors for Object Detection models, please check Object Detection Config Note: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set imageCodec when loading images ImageSet.read . See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples Users can also do the inference directly using Analytics zoo. Sample code for SSD VGG on PASCAL as below: val model = ObjectDetector.load[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val preprocessor = Resize(300, 300) - ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) - MatToTensor() - ImageFrameToSample() val output = model.predictImageset(data) Python Python example It's very easy to apply the model for inference with below code piece. model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set) User can also define his own configuration to do the inference with below code piece. model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(preprocessing) output = model.predict_image_set(image_set) For preprocessors for Object Detection models, please check Object Detection Config Download link PASCAL VOC models SSD 300x300 MobileNet SSD 300x300 VGG SSD 300x300 VGG Quantize SSD 512x512 VGG SSD 512x512 VGG Quantize Faster-RCNN VGG Faster-RCNN VGG Compress Faster-RCNN VGG Compress Quantize Faster-RCNN PvaNet Faster-RCNN PvaNet Compress Faster-RCNN PvaNet Compress Quantize COCO models SSD 300x300 VGG SSD 300x300 VGG Quantize SSD 512x512 VGG SSD 512x512 VGG Quantize","title":"Object Detection API"},{"location":"ProgrammingGuide/object-detection/#object-detection-examples","text":"Analytics Zoo provides two typical kind of pre-trained Object Detection models : SSD and Faster-RCNN on dataset PASCAL and COCO . For the usage of these models, please check below examples. Scala Scala example It's very easy to apply the model for inference with below code piece. val model = ObjectDetector.load[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val output = model.predictImageSet(data) For preprocessors for Object Detection models, please check Object Detection Config Note: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set imageCodec when loading images ImageSet.read . See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples Users can also do the inference directly using Analytics zoo. Sample code for SSD VGG on PASCAL as below: val model = ObjectDetector.load[Float](params.model) val data = ImageSet.read(params.image, sc, params.nPartition) val preprocessor = Resize(300, 300) - ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) - MatToTensor() - ImageFrameToSample() val output = model.predictImageset(data) Python Python example It's very easy to apply the model for inference with below code piece. model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) output = model.predict_image_set(image_set) User can also define his own configuration to do the inference with below code piece. model = ObjectDetector.load_model(model_path) image_set = ImageSet.read(img_path, sc) preprocessing = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) config = ImageConfigure(preprocessing) output = model.predict_image_set(image_set) For preprocessors for Object Detection models, please check Object Detection Config","title":"Object Detection examples"},{"location":"ProgrammingGuide/object-detection/#download-link","text":"PASCAL VOC models SSD 300x300 MobileNet SSD 300x300 VGG SSD 300x300 VGG Quantize SSD 512x512 VGG SSD 512x512 VGG Quantize Faster-RCNN VGG Faster-RCNN VGG Compress Faster-RCNN VGG Compress Quantize Faster-RCNN PvaNet Faster-RCNN PvaNet Compress Faster-RCNN PvaNet Compress Quantize COCO models SSD 300x300 VGG SSD 300x300 VGG Quantize SSD 512x512 VGG SSD 512x512 VGG Quantize","title":"Download link"},{"location":"ProgrammingGuide/recommendation/","text":"Analytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model. Highlights Easy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer. Recommenders can handle either explict or implicit feedback, given corresponding features. It provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). The examples/notebooks are included in the Analytics Zoo source code. Wide and Deep Learning Model. Scala example Python notebook NCF. Scala example Python notebook Wide and Deep Scala Build a WND model for recommendation. val wideAndDeep = WideAndDeep(modelType = wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10)) Compile and train a WND model. wideAndDeep.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5), loss = SparseCategoricalCrossEntropy[Float](), metrics = List(new Top1Accuracy[Float]())) wideAndDeep.fit(trainRdds, batchSize, nbEpoch, validationRdds) Predict and recommend items(users) for users(items) with given features. val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds) val userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3) val itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3) See more details in our Recommender API and Scala example . Python Compile and train a WND model. wide_n_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10)) Train a WND model using BigDL Optimizer wide_n_deep.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6), loss= sparse_categorical_crossentropy , metrics=['accuracy']) wide_n_deep.fit(train_rdd, nb_epoch, batch_size, val_rdd) Predict and recommend items(users) for users(items) with given features. userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds) userRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3) itemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3) See more details in our Recommender API and Python notebook . Neural network-based Collaborative Filtering Scala Build a NCF model for recommendation. val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20) Compile and train a NCF model ncf.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5), loss = SparseCategoricalCrossEntropy[Float](), metrics = List(new Top1Accuracy[Float]())) ncf.fit(trainRdds, batchSize, nbEpoch, validationRdds) Predict and recommend items(users) for users(items) with given features. val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds) val userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3) val itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3) See more details in our Recommender API and Scala example Python Build a NCF model for recommendation. ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20) Compile and train a NCF model ncf.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6), loss= sparse_categorical_crossentropy , metrics=['accuracy']) ncf.fit(train_rdd, nb_epoch, batch_size, val_rdd) Predict and recommend items(users) for users(items) with given features. userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds) userRecs = ncf.recommend_for_user(valPairFeatureRdds, 3) itemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3) See more details in our Recommender API and Python notebook .","title":"Recommendation API"},{"location":"ProgrammingGuide/recommendation/#wide-and-deep","text":"Scala Build a WND model for recommendation. val wideAndDeep = WideAndDeep(modelType = wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10)) Compile and train a WND model. wideAndDeep.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5), loss = SparseCategoricalCrossEntropy[Float](), metrics = List(new Top1Accuracy[Float]())) wideAndDeep.fit(trainRdds, batchSize, nbEpoch, validationRdds) Predict and recommend items(users) for users(items) with given features. val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds) val userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3) val itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3) See more details in our Recommender API and Scala example . Python Compile and train a WND model. wide_n_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10)) Train a WND model using BigDL Optimizer wide_n_deep.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6), loss= sparse_categorical_crossentropy , metrics=['accuracy']) wide_n_deep.fit(train_rdd, nb_epoch, batch_size, val_rdd) Predict and recommend items(users) for users(items) with given features. userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds) userRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3) itemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3) See more details in our Recommender API and Python notebook .","title":"Wide and Deep"},{"location":"ProgrammingGuide/recommendation/#neural-network-based-collaborative-filtering","text":"Scala Build a NCF model for recommendation. val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20) Compile and train a NCF model ncf.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5), loss = SparseCategoricalCrossEntropy[Float](), metrics = List(new Top1Accuracy[Float]())) ncf.fit(trainRdds, batchSize, nbEpoch, validationRdds) Predict and recommend items(users) for users(items) with given features. val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds) val userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3) val itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3) See more details in our Recommender API and Scala example Python Build a NCF model for recommendation. ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20) Compile and train a NCF model ncf.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6), loss= sparse_categorical_crossentropy , metrics=['accuracy']) ncf.fit(train_rdd, nb_epoch, batch_size, val_rdd) Predict and recommend items(users) for users(items) with given features. userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds) userRecs = ncf.recommend_for_user(valPairFeatureRdds, 3) itemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3) See more details in our Recommender API and Python notebook .","title":"Neural network-based Collaborative Filtering"},{"location":"ProgrammingGuide/run-on-dataproc/","text":"Deploy Analytics Zoo with BigDL on Dataproc Before using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc (you may refer to https://cloud.google.com/sdk/docs/how-to for more instructions). Now you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/) gcloud command-line tool. Note: The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]). So at the time of writing you should download and place the updated version of this script somewhere accessible for you (into your own Google Storage bucket, for example) and set appropriate location for --initialization-actions . You can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed in it. By default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8). So you must specify to download Analytics Zoo instead (which includes BigDL) with: bigdl-download-url property in metadata: gcloud dataproc clusters create CLUSTER_NAME \\ --image-version 1.3 \\ --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\ --initialization-action-timeout 10m \\ --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip' To download a different version of Zoo or one targeted to a different version of Spark/Scala, find the download URL from the Analytics Zoo releases page or maven repository , and set the metadata key \"bigdl-download-url\" . More information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl Once the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node. Cloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK. E.g., gcloud compute --project PROJECT_ID ssh --zone ZONE CLUSTER_NAME Google cloud SDK will perform the authentication for you and open an SSH client (Eg Putty). You should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. Now you can run jobs with Zoo and BigDL on Google Dataproc as usual with gcloud dataproc jobs submit spark .","title":"Run on Google Cloud Dataproc"},{"location":"ProgrammingGuide/run-on-dataproc/#deploy-analytics-zoo-with-bigdl-on-dataproc","text":"Before using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc (you may refer to https://cloud.google.com/sdk/docs/how-to for more instructions). Now you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/) gcloud command-line tool. Note: The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]). So at the time of writing you should download and place the updated version of this script somewhere accessible for you (into your own Google Storage bucket, for example) and set appropriate location for --initialization-actions . You can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed in it. By default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8). So you must specify to download Analytics Zoo instead (which includes BigDL) with: bigdl-download-url property in metadata: gcloud dataproc clusters create CLUSTER_NAME \\ --image-version 1.3 \\ --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\ --initialization-action-timeout 10m \\ --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip' To download a different version of Zoo or one targeted to a different version of Spark/Scala, find the download URL from the Analytics Zoo releases page or maven repository , and set the metadata key \"bigdl-download-url\" . More information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl Once the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node. Cloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK. E.g., gcloud compute --project PROJECT_ID ssh --zone ZONE CLUSTER_NAME Google cloud SDK will perform the authentication for you and open an SSH client (Eg Putty). You should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. Now you can run jobs with Zoo and BigDL on Google Dataproc as usual with gcloud dataproc jobs submit spark .","title":"Deploy Analytics Zoo with BigDL on Dataproc"},{"location":"ProgrammingGuide/seq2seq/","text":"Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more. Highlights Easy-to-use models, could be fed into NNFrames or BigDL Optimizer for training. Support SimpleRNN, LSTM and GRU. Support transform encoder states before fed into decoder Build a Seq2seq model You can call the following API in Scala and Python respectively to create a Seq2seq . Scala val encoder = RNNEncoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize)) val decoder = RNNDecoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize)) val bridge = Bridge[Float](bridgeType= dense , decoderHiddenSize=3) val model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge) rnnType : currently support \"simplernn | lstm | gru\" numLayer : number of layers hiddenSize : hidden size embedding : embedding layer bridgeType : currently only support \"dense | densenonlinear\" input_shape : shape of encoder input output_shape : shape of decoder input Python encoder = RNNEncoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4) decoder = RNNDecoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4) bridge = Bridge.initialize(bridge_type= dense , decoder_hidden_size=4) seq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge) rnn_type : currently support \"simplernn | lstm | gru\" nlayers : number of layers hidden_size : hidden size bridge_type : currently only support \"dense | densenonlinear\" input_shape : shape of encoder input output_shape : shape of decoder input Train a Seq2seq model After building the model, we can use BigDL Optimizer to train it (with validation) using RDD of Sample . feature is expected to be a sequence(eg. batch x seqLen x feature) and label is also a sequence(eg. batch x seqLen x feature). Scala import com.intel.analytics.bigdl.optim._ import com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ClassNLLCriterion} val optimizer = Optimizer( model, trainSet, TimeDistributedMaskCriterion( ClassNLLCriterion(paddingValue = padId), paddingValue = padId ), batchSize = 128) optimizer .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001)) .setEndWhen(Trigger.maxEpoch(20)) .optimize() Also we can use Seq2seq.fit api to train the model. model.compile( optimizer = optimMethod, loss = TimeDistributedMaskCriterion( ClassNLLCriterion(paddingValue = padId), paddingValue = padId )) model.fit( trainSet, batchSize = param.batchSize, nbEpoch = 20) Python from bigdl.optim.optimizer import * optimizer = Optimizer( model=seq2seq, training_rdd=train_rdd, criterion=TimeDistributedMaskCriterion(ClassNLLCriterion()), end_trigger=MaxEpoch(20), batch_size=128, optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001)) optimizer.set_validation( batch_size=128, trigger=EveryEpoch()) Also we can use Seq2seq.fit api to train the model. model.compile(optimizer, loss, metrics) model.fit(x, batch_size=32, nb_epoch=10, validation_data=None) Do prediction Predict output with given input Scala val result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput) input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize startSign : a tensor which represents start and is fed into decoder maxSeqLen : max sequence length for final output stopSign : a tensor that indicates model should stop infer further if current output is the same with stopSign buildOutput : Feeding model output to buildOutput to generate final result Python result = model.infer(input, start_sign, max_seq_len, stop_sign, build_output) input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize start_sign : a ndarray which represents start and is fed into decoder max_seq_len : max sequence length for final output stop_sign : a ndarray that indicates model should stop infer further if current output is the same with stopSign build_output : Feeding model output to buildOutput to generate final result Examples We provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction. See here for the Scala example.","title":"Sequence to Sequence API"},{"location":"ProgrammingGuide/seq2seq/#build-a-seq2seq-model","text":"You can call the following API in Scala and Python respectively to create a Seq2seq . Scala val encoder = RNNEncoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize)) val decoder = RNNDecoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize)) val bridge = Bridge[Float](bridgeType= dense , decoderHiddenSize=3) val model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge) rnnType : currently support \"simplernn | lstm | gru\" numLayer : number of layers hiddenSize : hidden size embedding : embedding layer bridgeType : currently only support \"dense | densenonlinear\" input_shape : shape of encoder input output_shape : shape of decoder input Python encoder = RNNEncoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4) decoder = RNNDecoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4) bridge = Bridge.initialize(bridge_type= dense , decoder_hidden_size=4) seq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge) rnn_type : currently support \"simplernn | lstm | gru\" nlayers : number of layers hidden_size : hidden size bridge_type : currently only support \"dense | densenonlinear\" input_shape : shape of encoder input output_shape : shape of decoder input","title":"Build a Seq2seq model"},{"location":"ProgrammingGuide/seq2seq/#train-a-seq2seq-model","text":"After building the model, we can use BigDL Optimizer to train it (with validation) using RDD of Sample . feature is expected to be a sequence(eg. batch x seqLen x feature) and label is also a sequence(eg. batch x seqLen x feature). Scala import com.intel.analytics.bigdl.optim._ import com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ClassNLLCriterion} val optimizer = Optimizer( model, trainSet, TimeDistributedMaskCriterion( ClassNLLCriterion(paddingValue = padId), paddingValue = padId ), batchSize = 128) optimizer .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001)) .setEndWhen(Trigger.maxEpoch(20)) .optimize() Also we can use Seq2seq.fit api to train the model. model.compile( optimizer = optimMethod, loss = TimeDistributedMaskCriterion( ClassNLLCriterion(paddingValue = padId), paddingValue = padId )) model.fit( trainSet, batchSize = param.batchSize, nbEpoch = 20) Python from bigdl.optim.optimizer import * optimizer = Optimizer( model=seq2seq, training_rdd=train_rdd, criterion=TimeDistributedMaskCriterion(ClassNLLCriterion()), end_trigger=MaxEpoch(20), batch_size=128, optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001)) optimizer.set_validation( batch_size=128, trigger=EveryEpoch()) Also we can use Seq2seq.fit api to train the model. model.compile(optimizer, loss, metrics) model.fit(x, batch_size=32, nb_epoch=10, validation_data=None)","title":"Train a Seq2seq model"},{"location":"ProgrammingGuide/seq2seq/#do-prediction","text":"Predict output with given input Scala val result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput) input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize startSign : a tensor which represents start and is fed into decoder maxSeqLen : max sequence length for final output stopSign : a tensor that indicates model should stop infer further if current output is the same with stopSign buildOutput : Feeding model output to buildOutput to generate final result Python result = model.infer(input, start_sign, max_seq_len, stop_sign, build_output) input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize start_sign : a ndarray which represents start and is fed into decoder max_seq_len : max sequence length for final output stop_sign : a ndarray that indicates model should stop infer further if current output is the same with stopSign build_output : Feeding model output to buildOutput to generate final result","title":"Do prediction"},{"location":"ProgrammingGuide/seq2seq/#examples","text":"We provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction. See here for the Scala example.","title":"Examples"},{"location":"ProgrammingGuide/tensorflow/","text":"Analytics-Zoo provides a set APIs for running TensorFlow model on Spark in a distributed fashion. System Requirement TensorFlow version: 1.10 OS version (all 64-bit): Ubuntu 16.04 or later , macOS 10.12.6 or later , Windows 7 or later (TensorFlow is only tested and supported on these 64-bit systems as stated here ). To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here . TFPark API TFPark is a set of high-level api modeling after tf.keras and tf.estimator to help user to train and evaluate TensorFlow models on Spark and BigDL. Users can define their model using tf.keras API or using model_fn similar to tf.estimator . TFDataset TFDatasets represents a distributed collection of elements (backed by a RDD) to be fed into a TensorFlow graph. TFDatasets can be created from numpy.ndarrays, an rdd of numpy.ndarrays as well as ImageSet, TextSet and FeatureSet. It acts as an interface connecting RDD data to TensorFlow models. from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=BATCH_SIZE) More on TFDataset API API Guide KerasModel KerasModel enables user to use tf.keras API to define TensorFlow models and perform training or evaluation on top of Spark and BigDL in a distributed fashion. Create a KerasModel from zoo.tfpark import KerasModel, TFDataset import tensorflow as tf model = tf.keras.Sequential( [tf.keras.layers.Flatten(input_shape=(28, 28, 1)), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(10, activation='softmax'), ] ) model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy']) keras_model = KerasModel(model) Perform training on TFDataset and save model keras_model.fit(training_dataset, epochs=max_epoch) model.save_weights( /tmp/model.h5 ) Loading saved model and preform evaluation or inference model.load_weights( /tmp/model.h5 ) evaluation_results = model.evaluate(eval_dataset) predictions = model.predict(pred_dataset) More on KerasModel API API Guide TFEstimator TFEstimator wraps a model defined by model_fn . The model_fn is almost identical to TensorFlow's model_fn except users are required to return a TFEstimator object. Users do not need to construct backward graph (calling optimizer.minimize(...) ) but set a loss tensor in TFEstimator . Define a model_fn import tensorflow as tf from zoo.tfpark.estimator import TFEstimator, TFEstimatorSpec def model_fn(features, labels, mode): hidden = tf.layers.dense(features, 32, activation=tf.nn.relu) logits = tf.layers.dense(hidden, 10) if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN: loss = tf.reduce_mean( tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)) return TFEstimatorSpec(mode, predictions=logits, loss=loss) else: return TFEstimatorSpec(mode, predictions=logits) Define a input_fn import tensorflow as tf sc = init_nncontext() def input_fn(mode): if mode == tf.estimator.ModeKeys.TRAIN: training_rdd = get_data_rdd( train , sc) dataset = TFDataset.from_rdd(training_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=320) elif mode == tf.estimator.ModeKeys.EVAL: validation_rdd = get_data_rdd( validation , sc) dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=320) else: testing_rdd = get_data_rdd( test , sc) dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), batch_per_thread=80) return dataset Create TFEstimator and perform training, evaluation or inference estimator = TFEstimator(model_fn, tf.train.AdamOptimizer(), model_dir= /tmp/estimator ) estimator.train(input_fn, steps=10000) evaluation_result = estimator.evaluate(input_fn, [ acc ]) predictions = estimator.predict(input_fn) More on TFEstimator API API Guide Low level API Concepts TFOptimizer is the class that does all the hard work in distributed training, such as model distribution and parameter synchronization. It takes the user specified loss (a TensorFlow scalar tensor) as an argument and runs stochastic gradient descent using the given optimMethod on all the Variables that contribute to this loss. TFPredictor takes a list of user specified TensorFlow tensors as the model outputs, and feed all the elements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the model prediction for the corresponding input elements. Training 1.Data wrangling and analysis using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=BATCH_SIZE) 2.Deep learning model development using TensorFlow import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors squeezed_labels = tf.squeeze(labels) with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=True) loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels)) You can also construct your model using Keras provided by Tensorflow. from tensorflow.keras.models import Model from tensorflow.keras.layers import * data = Input(shape=[28, 28, 1]) x = Flatten()(data) x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) predictions = Dense(10, activation='softmax')(x) model = Model(inputs=data, outputs=predictions) model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy']) 3.Distributed training on Spark and BigDL from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) For Keras model: from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) 4.Save the variable to checkpoint saver = tf.train.Saver() saver.save(optimizer.sess, /tmp/lenet/ ) For Keras model, you can also Keras' save_weights api. model.save_weights( /tmp/keras.h5 ) Inference 1.Data processing using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays testing_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), batch_per_thread=4) 2.Reconstruct the model for inference and load the checkpoint import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=False) sess = tf.Session() saver = tf.train.Saver() saver.restore(sess, /tmp/lenet ) As before, you can also construct and restore your model using Keras provided by Tensorflow. from tensorflow.keras.models import Model from tensorflow.keras.layers import * data = Input(shape=[28, 28, 1]) x = Flatten()(data) x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) predictions = Dense(10, activation='softmax')(x) model = Model(inputs=data, outputs=predictions) model.load_weights( /tmp/mnist_keras.h5 ) 3.Run predictions predictor = TFPredictor.from_outputs(sess, [logits]) predictions_rdd = predictor.predict() For keras model: predictor = TFPredictor.from_keras(model, dataset) predictions_rdd = predictor.predict() Relationship to TFNet TFNet is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors). It implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers to construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API. You can think of TFDatasets , TFOptimizer , TFPredictor as a set API for training/testing TensorFlow models on Spark/BigDL, while TFNet as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph. For more information on TFNet, please refer to the API Guide","title":"TFPark"},{"location":"ProgrammingGuide/tensorflow/#system-requirement","text":"TensorFlow version: 1.10 OS version (all 64-bit): Ubuntu 16.04 or later , macOS 10.12.6 or later , Windows 7 or later (TensorFlow is only tested and supported on these 64-bit systems as stated here ). To run on other system may require you to manually compile the TensorFlow source code. Instructions can be found here .","title":"System Requirement"},{"location":"ProgrammingGuide/tensorflow/#tfpark-api","text":"TFPark is a set of high-level api modeling after tf.keras and tf.estimator to help user to train and evaluate TensorFlow models on Spark and BigDL. Users can define their model using tf.keras API or using model_fn similar to tf.estimator .","title":"TFPark API"},{"location":"ProgrammingGuide/tensorflow/#tfdataset","text":"TFDatasets represents a distributed collection of elements (backed by a RDD) to be fed into a TensorFlow graph. TFDatasets can be created from numpy.ndarrays, an rdd of numpy.ndarrays as well as ImageSet, TextSet and FeatureSet. It acts as an interface connecting RDD data to TensorFlow models. from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=BATCH_SIZE) More on TFDataset API API Guide","title":"TFDataset"},{"location":"ProgrammingGuide/tensorflow/#kerasmodel","text":"KerasModel enables user to use tf.keras API to define TensorFlow models and perform training or evaluation on top of Spark and BigDL in a distributed fashion. Create a KerasModel from zoo.tfpark import KerasModel, TFDataset import tensorflow as tf model = tf.keras.Sequential( [tf.keras.layers.Flatten(input_shape=(28, 28, 1)), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(10, activation='softmax'), ] ) model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy']) keras_model = KerasModel(model) Perform training on TFDataset and save model keras_model.fit(training_dataset, epochs=max_epoch) model.save_weights( /tmp/model.h5 ) Loading saved model and preform evaluation or inference model.load_weights( /tmp/model.h5 ) evaluation_results = model.evaluate(eval_dataset) predictions = model.predict(pred_dataset) More on KerasModel API API Guide","title":"KerasModel"},{"location":"ProgrammingGuide/tensorflow/#tfestimator","text":"TFEstimator wraps a model defined by model_fn . The model_fn is almost identical to TensorFlow's model_fn except users are required to return a TFEstimator object. Users do not need to construct backward graph (calling optimizer.minimize(...) ) but set a loss tensor in TFEstimator . Define a model_fn import tensorflow as tf from zoo.tfpark.estimator import TFEstimator, TFEstimatorSpec def model_fn(features, labels, mode): hidden = tf.layers.dense(features, 32, activation=tf.nn.relu) logits = tf.layers.dense(hidden, 10) if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN: loss = tf.reduce_mean( tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)) return TFEstimatorSpec(mode, predictions=logits, loss=loss) else: return TFEstimatorSpec(mode, predictions=logits) Define a input_fn import tensorflow as tf sc = init_nncontext() def input_fn(mode): if mode == tf.estimator.ModeKeys.TRAIN: training_rdd = get_data_rdd( train , sc) dataset = TFDataset.from_rdd(training_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=320) elif mode == tf.estimator.ModeKeys.EVAL: validation_rdd = get_data_rdd( validation , sc) dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=320) else: testing_rdd = get_data_rdd( test , sc) dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), batch_per_thread=80) return dataset Create TFEstimator and perform training, evaluation or inference estimator = TFEstimator(model_fn, tf.train.AdamOptimizer(), model_dir= /tmp/estimator ) estimator.train(input_fn, steps=10000) evaluation_result = estimator.evaluate(input_fn, [ acc ]) predictions = estimator.predict(input_fn) More on TFEstimator API API Guide","title":"TFEstimator"},{"location":"ProgrammingGuide/tensorflow/#low-level-api","text":"","title":"Low level API"},{"location":"ProgrammingGuide/tensorflow/#concepts","text":"TFOptimizer is the class that does all the hard work in distributed training, such as model distribution and parameter synchronization. It takes the user specified loss (a TensorFlow scalar tensor) as an argument and runs stochastic gradient descent using the given optimMethod on all the Variables that contribute to this loss. TFPredictor takes a list of user specified TensorFlow tensors as the model outputs, and feed all the elements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the model prediction for the corresponding input elements.","title":"Concepts"},{"location":"ProgrammingGuide/tensorflow/#training","text":"1.Data wrangling and analysis using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays train_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(train_rdd, features=(tf.float32, [28, 28, 1]), labels=(tf.int32, []), batch_size=BATCH_SIZE) 2.Deep learning model development using TensorFlow import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors squeezed_labels = tf.squeeze(labels) with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=True) loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels)) You can also construct your model using Keras provided by Tensorflow. from tensorflow.keras.models import Model from tensorflow.keras.layers import * data = Input(shape=[28, 28, 1]) x = Flatten()(data) x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) predictions = Dense(10, activation='softmax')(x) model = Model(inputs=data, outputs=predictions) model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy']) 3.Distributed training on Spark and BigDL from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_loss(loss, Adam(1e-3)) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) For Keras model: from zoo.pipeline.api.net import TFOptimizer from bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary optimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset) optimizer.set_train_summary(TrainSummary( /tmp/az_lenet , lenet )) optimizer.optimize(end_trigger=MaxEpoch(5)) 4.Save the variable to checkpoint saver = tf.train.Saver() saver.save(optimizer.sess, /tmp/lenet/ ) For Keras model, you can also Keras' save_weights api. model.save_weights( /tmp/keras.h5 )","title":"Training"},{"location":"ProgrammingGuide/tensorflow/#inference","text":"1.Data processing using PySpark from zoo import init_nncontext from zoo.pipeline.api.net import TFDataset from tensorflow as tf sc = init_nncontext() # Each record in the train_rdd consists of a list of NumPy ndrrays testing_rdd = sc.parallelize(file_list) .map(lambda x: read_image_and_label(x)) .map(lambda image_label: decode_to_ndarrays(image_label)) # TFDataset represents a distributed set of elements, # in which each element contains one or more TensorFlow Tensor objects. dataset = TFDataset.from_rdd(testing_rdd, features=(tf.float32, [28, 28, 1]), batch_per_thread=4) 2.Reconstruct the model for inference and load the checkpoint import tensorflow as tf slim = tf.contrib.slim images, labels = dataset.tensors with slim.arg_scope(lenet.lenet_arg_scope()): logits, end_points = lenet.lenet(images, num_classes=10, is_training=False) sess = tf.Session() saver = tf.train.Saver() saver.restore(sess, /tmp/lenet ) As before, you can also construct and restore your model using Keras provided by Tensorflow. from tensorflow.keras.models import Model from tensorflow.keras.layers import * data = Input(shape=[28, 28, 1]) x = Flatten()(data) x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) predictions = Dense(10, activation='softmax')(x) model = Model(inputs=data, outputs=predictions) model.load_weights( /tmp/mnist_keras.h5 ) 3.Run predictions predictor = TFPredictor.from_outputs(sess, [logits]) predictions_rdd = predictor.predict() For keras model: predictor = TFPredictor.from_keras(model, dataset) predictions_rdd = predictor.predict()","title":"Inference"},{"location":"ProgrammingGuide/tensorflow/#relationship-to-tfnet","text":"TFNet is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors). It implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers to construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API. You can think of TFDatasets , TFOptimizer , TFPredictor as a set API for training/testing TensorFlow models on Spark/BigDL, while TFNet as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph. For more information on TFNet, please refer to the API Guide","title":"Relationship to TFNet"},{"location":"ProgrammingGuide/text-classification/","text":"Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts. Highlights Easy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer. The encoders we support include CNN, LSTM and GRU. Build a TextClassifier model You can call the following API in Scala and Python respectively to create a TextClassifier with pre-trained GloVe word embeddings as the first layer . Scala val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = cnn , encoderOutputDim = 256) classNum : The number of text categories to be classified. Positive integer. embeddingFile The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. sequenceLength : The length of a sequence. Positive integer. Default is 500. encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\". encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256. Python text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256) class_num : The number of text categories to be classified. Positive int. embedding_file The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. sequence_length : The length of a sequence. Positive int. Default is 500. encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'. encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256. Train a TextClassifier model After building the model, we can call compile and fit to train it (with validation). For training and validation data, you can first read files as TextSet (see here ) and then do preprocessing (see here ). Scala model.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy())) model.fit(trainSet, batchSize, nbEpoch, validateSet) Python model.compile(optimizer=Adagrad(learning_rate, loss= sparse_categorical_crossentropy , metrics=['accuracy']) model.fit(train_set, batch_size, nb_epoch, validate_set) Do prediction After training the model, it can be used to predict probability distributions. Scala val predictSet = textClassifier.predict(validateSet) Python predict_set = text_classifier.predict(validate_set) Examples We provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction. See here for the Scala example. See here for the Python example.","title":"Text Classification API"},{"location":"ProgrammingGuide/text-classification/#build-a-textclassifier-model","text":"You can call the following API in Scala and Python respectively to create a TextClassifier with pre-trained GloVe word embeddings as the first layer . Scala val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = cnn , encoderOutputDim = 256) classNum : The number of text categories to be classified. Positive integer. embeddingFile The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. sequenceLength : The length of a sequence. Positive integer. Default is 500. encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\". encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256. Python text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256) class_num : The number of text categories to be classified. Positive int. embedding_file The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. sequence_length : The length of a sequence. Positive int. Default is 500. encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'. encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.","title":"Build a TextClassifier model"},{"location":"ProgrammingGuide/text-classification/#train-a-textclassifier-model","text":"After building the model, we can call compile and fit to train it (with validation). For training and validation data, you can first read files as TextSet (see here ) and then do preprocessing (see here ). Scala model.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy())) model.fit(trainSet, batchSize, nbEpoch, validateSet) Python model.compile(optimizer=Adagrad(learning_rate, loss= sparse_categorical_crossentropy , metrics=['accuracy']) model.fit(train_set, batch_size, nb_epoch, validate_set)","title":"Train a TextClassifier model"},{"location":"ProgrammingGuide/text-classification/#do-prediction","text":"After training the model, it can be used to predict probability distributions. Scala val predictSet = textClassifier.predict(validateSet) Python predict_set = text_classifier.predict(validate_set)","title":"Do prediction"},{"location":"ProgrammingGuide/text-classification/#examples","text":"We provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction. See here for the Scala example. See here for the Python example.","title":"Examples"},{"location":"ProgrammingGuide/text-matching/","text":"Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering). More text matching models will be supported in the future. Highlights Easy-to-use Keras-Style defined model which provides compile and fit methods for training. Alternatively, it could be fed into NNFrames or BigDL Optimizer. The model can be used for both ranking and classification tasks. Build a KNRM Model Kernel-pooling Neural Ranking Model with RBF kernel. See here for more details. You can call the following API in Scala and Python respectively to create a KNRM with pre-trained GloVe word embeddings . Scala val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = ranking ) text1Length : Sequence length of text1 (query). text2Length : Sequence length of text2 (doc). embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true. kernelNum : Integer 1. The number of kernels to use. Default is 21. sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1. exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. Python knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking ) text1_length : Sequence length of text1 (query). text2_length : Sequence length of text2 (doc). embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. train_embed : Boolean. Whether to train the embedding layer or not. Default is True. kernel_num : Int 1. The number of kernels to use. Default is 21. sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1. exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. Pairwise training For ranking, the model can be trained pairwisely with the following steps: Read train relations. See here for more details. Read text1 and text2 corpus as TextSet. See here for more details. Preprocess text1 and text2 corpus. See here for more details. Generate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1. During the training process, we intend to optimize the margin loss within each pair. We provide the following API to generate a TextSet for pairwise training: Scala val trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2) relations : RDD or array of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by calling tokenize , word2idx and shapeSequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is an array, then corpus1 and corpus2 must both be LocalTextSet. Python train_set = TextSet.from_relation_pairs(relations, corpus1, corpus2) relations : RDD or list of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by calling tokenize , word2idx and shape_sequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is a list, then corpus1 and corpus2 must both be LocalTextSet. Call compile and fit to train the model: Scala val model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length))) model.compile(optimizer = new SGD(learningRate), loss = RankHinge()) model.fit(trainSet, batchSize, nbEpoch) Python model = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length))) model.compile(optimizer=SGD(learning_rate), loss='rank_hinge') model.fit(train_set, batch_size, nb_epoch) Listwise evaluation Given text1 and a list of text2 candidates, we provide metrics NDCG and MAP to listwisely evaluate a ranking model with the following steps: Read validation relations. See here for more details. Read text1 and text2 corpus as TextSet. See here for more details. Preprocess text1 and text2 corpus same as the training phase. See here for more details. Generate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1. We provide the following API to generate a TextSet for listwise evaluation: Scala val validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2) relations : RDD or array of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by calling tokenize , word2idx and shapeSequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is an array, then corpus1 and corpus2 must both be LocalTextSet. Python validate_set = TextSet.from_relation_lists(relations, corpus1, corpus2) relations : RDD or list of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by calling tokenize , word2idx and shape_sequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is a list, then corpus1 and corpus2 must both be LocalTextSet. Call evaluateNDCG or evaluateMAP to evaluate the model: Scala knrm.evaluateNDCG(validateSet, k, threshold = 0.0) knrm.evaluateMAP(validateSet, threshold = 0.0) Python knrm.evaluate_ndcg(validate_set, k, threshold=0.0) knrm.evaluate_map(validate_set, threshold=0.0) k : Positive integer. Rank position in NDCG. threshold : If label threshold, then it will be considered as a positive record. Default is 0.0. Examples We provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking. See here for the Scala example. See here for the Python example.","title":"Text Matching API"},{"location":"ProgrammingGuide/text-matching/#build-a-knrm-model","text":"Kernel-pooling Neural Ranking Model with RBF kernel. See here for more details. You can call the following API in Scala and Python respectively to create a KNRM with pre-trained GloVe word embeddings . Scala val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = ranking ) text1Length : Sequence length of text1 (query). text2Length : Sequence length of text2 (doc). embeddingFile : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map. trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true. kernelNum : Integer 1. The number of kernels to use. Default is 21. sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1. exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'. Python knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking ) text1_length : Sequence length of text1 (query). text2_length : Sequence length of text2 (doc). embedding_file : The path to the word embedding file. Currently only glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt are supported. You can download from here . word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to start from 1 with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary. train_embed : Boolean. Whether to train the embedding layer or not. Default is True. kernel_num : Int 1. The number of kernels to use. Default is 21. sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1. exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001. target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training. For classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and you are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.","title":"Build a KNRM Model"},{"location":"ProgrammingGuide/text-matching/#pairwise-training","text":"For ranking, the model can be trained pairwisely with the following steps: Read train relations. See here for more details. Read text1 and text2 corpus as TextSet. See here for more details. Preprocess text1 and text2 corpus. See here for more details. Generate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1. During the training process, we intend to optimize the margin loss within each pair. We provide the following API to generate a TextSet for pairwise training: Scala val trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2) relations : RDD or array of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by calling tokenize , word2idx and shapeSequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is an array, then corpus1 and corpus2 must both be LocalTextSet. Python train_set = TextSet.from_relation_pairs(relations, corpus1, corpus2) relations : RDD or list of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by calling tokenize , word2idx and shape_sequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is a list, then corpus1 and corpus2 must both be LocalTextSet. Call compile and fit to train the model: Scala val model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length))) model.compile(optimizer = new SGD(learningRate), loss = RankHinge()) model.fit(trainSet, batchSize, nbEpoch) Python model = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length))) model.compile(optimizer=SGD(learning_rate), loss='rank_hinge') model.fit(train_set, batch_size, nb_epoch)","title":"Pairwise training"},{"location":"ProgrammingGuide/text-matching/#listwise-evaluation","text":"Given text1 and a list of text2 candidates, we provide metrics NDCG and MAP to listwisely evaluate a ranking model with the following steps: Read validation relations. See here for more details. Read text1 and text2 corpus as TextSet. See here for more details. Preprocess text1 and text2 corpus same as the training phase. See here for more details. Generate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1. We provide the following API to generate a TextSet for listwise evaluation: Scala val validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2) relations : RDD or array of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by calling tokenize , word2idx and shapeSequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is an array, then corpus1 and corpus2 must both be LocalTextSet. Python validate_set = TextSet.from_relation_lists(relations, corpus1, corpus2) relations : RDD or list of Relation. corpus1 : TextSet that contains all id1 in relations. corpus2 : TextSet that contains all id2 in relations. For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by calling tokenize , word2idx and shape_sequence in order. If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet. If relations is a list, then corpus1 and corpus2 must both be LocalTextSet. Call evaluateNDCG or evaluateMAP to evaluate the model: Scala knrm.evaluateNDCG(validateSet, k, threshold = 0.0) knrm.evaluateMAP(validateSet, threshold = 0.0) Python knrm.evaluate_ndcg(validate_set, k, threshold=0.0) knrm.evaluate_map(validate_set, threshold=0.0) k : Positive integer. Rank position in NDCG. threshold : If label threshold, then it will be considered as a positive record. Default is 0.0.","title":"Listwise evaluation"},{"location":"ProgrammingGuide/text-matching/#examples","text":"We provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking. See here for the Scala example. See here for the Python example.","title":"Examples"},{"location":"ProgrammingGuide/text-models/","text":"There are a number of built-in compiled text models in Analytics Zoo TFPark for Natural Language Processing (NLP) tasks based on KerasModel . See this page for more details about how to construct built-in models for intent extraction, named entity extraction and pos tagging. etc. In this page, we show the general steps how to train and evaluate an NER model in a distributed fashion and use this model for distributed inference. For other models, the steps are more or less quite similar. Remarks : You need to install tensorflow==1.10 on your driver node. Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later , macOS 10.12.6 or later and Windows 7 or later . To run on other systems, you need to manually compile the TensorFlow source code. Instructions can be found here . Model Construction You can easily construct a model for named entity recognition using the following API. from zoo.tfpark.text.keras import NER model = NER(num_entities, word_vocab_size, char_vocab_size, word_length) Data Preparation The NER model has two inputs: word indices and character indices. Thus, each raw text record needs to go through word-wise tokenization, character-wise segmentation and alignment to the same target length for preprocessing. If you are using numpy arrays, then the input x should be a list of two numpy arrays: x_words of shape (batch, sequence_length) for word indices x_chars of shape (batch, sequence_length, word_length) for character indices. x = [x_words, x_char] If there are labels (for training and evaluation), y should be another numpy array of shape (batch, sequence_length, word_length) for entity tags. Alternatively, you can construct a TFDataSet directly if you are dealing with RDD. Each record in TFDataSet should contain word indices, character indices and labels (if any) as well. Model Training You can easily call fit to train the NER model in a distributed fashion. You don't need to specify y if x is already a TFDataSet. model.fit(x, y, batch_size, epochs, distributed=True) Model Evaluation You can easily call evaluate to evaluate the NER model in a distributed fashion. You don't need to specify y if x is already a TFDataSet. result = model.evaluate(x, y, distributed=True) Model Save and Load After training, you can save the NER model to a single HDF5 file. model.save_model(path) For inference, you can load a directly trained NER model (with weights) from HDF5 file. from zoo.tfpark.text.keras import NER model = NER.load_model(path) Model Inference You can easily call predict to use the trained NER model for distributed inference. Note that you don't necessarily need labels for prediction. predictions = model.predict(x, distributed=True)","title":"Text Models"},{"location":"ProgrammingGuide/text-models/#model-construction","text":"You can easily construct a model for named entity recognition using the following API. from zoo.tfpark.text.keras import NER model = NER(num_entities, word_vocab_size, char_vocab_size, word_length)","title":"Model Construction"},{"location":"ProgrammingGuide/text-models/#data-preparation","text":"The NER model has two inputs: word indices and character indices. Thus, each raw text record needs to go through word-wise tokenization, character-wise segmentation and alignment to the same target length for preprocessing. If you are using numpy arrays, then the input x should be a list of two numpy arrays: x_words of shape (batch, sequence_length) for word indices x_chars of shape (batch, sequence_length, word_length) for character indices. x = [x_words, x_char] If there are labels (for training and evaluation), y should be another numpy array of shape (batch, sequence_length, word_length) for entity tags. Alternatively, you can construct a TFDataSet directly if you are dealing with RDD. Each record in TFDataSet should contain word indices, character indices and labels (if any) as well.","title":"Data Preparation"},{"location":"ProgrammingGuide/text-models/#model-training","text":"You can easily call fit to train the NER model in a distributed fashion. You don't need to specify y if x is already a TFDataSet. model.fit(x, y, batch_size, epochs, distributed=True)","title":"Model Training"},{"location":"ProgrammingGuide/text-models/#model-evaluation","text":"You can easily call evaluate to evaluate the NER model in a distributed fashion. You don't need to specify y if x is already a TFDataSet. result = model.evaluate(x, y, distributed=True)","title":"Model Evaluation"},{"location":"ProgrammingGuide/text-models/#model-save-and-load","text":"After training, you can save the NER model to a single HDF5 file. model.save_model(path) For inference, you can load a directly trained NER model (with weights) from HDF5 file. from zoo.tfpark.text.keras import NER model = NER.load_model(path)","title":"Model Save and Load"},{"location":"ProgrammingGuide/text-models/#model-inference","text":"You can easily call predict to use the trained NER model for distributed inference. Note that you don't necessarily need labels for prediction. predictions = model.predict(x, distributed=True)","title":"Model Inference"},{"location":"ProgrammingGuide/transferlearning/","text":"Overview Analytics Zoo provides some useful utilities for transfer learning. Loading a pre-trained model We can use the Net api to load a pre-trained model, including models saved by Analytics Zoo, BigDL, Torch, Caffe and Tensorflow. Please refer to Net API Guide Remove the last a few layers When a model is loaded using Net , we can use the newGraph(output) api to define a Model with the output specified by the parameter. For example, In scala: val inception = Net.loadBigDL[Float](inception_path) .newGraph(output = pool5/drop_7x7_s1 ) In python: full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) The returning model's output layer is \"pool5/drop_7x7_s1\". Freeze some layers In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo, we can use the freezeUpTo(endPoint) api to do that. For example, In scala: inception.freezeUpTo( pool4/3x3_s2 ) // freeze layer pool4/3x3_s2 and the layers before it In python: # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) This will freeze all the layers from the input layer to \"pool4/3x3_s2\" Example For a complete example, refer to the scala transfer learning example and python transfer learning example","title":"Transfer Learning"},{"location":"ProgrammingGuide/transferlearning/#overview","text":"Analytics Zoo provides some useful utilities for transfer learning.","title":"Overview"},{"location":"ProgrammingGuide/transferlearning/#loading-a-pre-trained-model","text":"We can use the Net api to load a pre-trained model, including models saved by Analytics Zoo, BigDL, Torch, Caffe and Tensorflow. Please refer to Net API Guide","title":"Loading a pre-trained model"},{"location":"ProgrammingGuide/transferlearning/#remove-the-last-a-few-layers","text":"When a model is loaded using Net , we can use the newGraph(output) api to define a Model with the output specified by the parameter. For example, In scala: val inception = Net.loadBigDL[Float](inception_path) .newGraph(output = pool5/drop_7x7_s1 ) In python: full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) The returning model's output layer is \"pool5/drop_7x7_s1\".","title":"Remove the last a few layers"},{"location":"ProgrammingGuide/transferlearning/#freeze-some-layers","text":"In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo, we can use the freezeUpTo(endPoint) api to do that. For example, In scala: inception.freezeUpTo( pool4/3x3_s2 ) // freeze layer pool4/3x3_s2 and the layers before it In python: # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) This will freeze all the layers from the input layer to \"pool4/3x3_s2\"","title":"Freeze some layers"},{"location":"ProgrammingGuide/transferlearning/#example","text":"For a complete example, refer to the scala transfer learning example and python transfer learning example","title":"Example"},{"location":"ProgrammingGuide/usercases-overview/","text":"Analytics Zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in analytics-zoo/apps . Anomaly Detection demostrates using LSTM network to detect anomalies in time series data. Fraud Detection demostrates using feed-forward neural network to detect frauds in credit card transactions data. Image Augmentation demostrates how to do image augmentation for vision projects. Object Detection demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos. Recommendation demonstrates how to use Analytics Zoo Recommendation APIs (i.e. Neural Collaborative Filtering , Wide and Deep ) to do recommendation on data with explicit feedback. Sentiment Analysis demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU, Bi-LSTM). Variational AutoEncoder demostrates how to use variational autoencoder to generate faces and digital numbers.","title":"Reference Use Cases"},{"location":"ProgrammingGuide/workingwithimages/","text":"Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats. Load Image Analytics Zoo provides APIs to read image to different formats: Load to Data Frame Analytics Zoo can process image data as Spark Data Frame. NNImageReader is the primary DataFrame-based image loading interface to read images into DataFrame. Scala example: import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.pipeline.nnframes.NNImageReader val sc = NNContext.initNNContext( app ) val imageDF1 = NNImageReader.readImages( /tmp , sc) val imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc) val imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc) Python: from zoo.common.nncontext import * from zoo.pipeline.nnframes import * sc = init_nncontext( app ) imageDF1 = NNImageReader.readImages( /tmp , sc) imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc) imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc) The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be accessed from com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema . Each record in \"image\" column represents one image record, in the format of Row(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file, and data holds the original file bytes for the image file. mode represents the OpenCV-compatible type: CV_8UC3, CV_8UC1 in most cases. val byteSchema = StructType( StructField( origin , StringType, true) :: StructField( height , IntegerType, false) :: StructField( width , IntegerType, false) :: StructField( nChannels , IntegerType, false) :: // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases StructField( mode , IntegerType, false) :: // Bytes in OpenCV-compatible order: row-wise BGR in most cases StructField( data , BinaryType, false) :: Nil) After loading the image, user can compose the preprocess steps with the Preprocessing defined in com.intel.analytics.zoo.feature.image . Load to ImageSet ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read image data as ImageSet from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala example: // create LocalImageSet from an image folder val localImageSet = ImageSet.read( /tmp/image/ ) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) Python example: # create LocalImageSet from an image folder local_image_frame2 = ImageSet.read( /tmp/image/ ) # create DistributedImageSet from an image folder distributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2) Image Transformer Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV: ImageBrightness : Adjust the image brightness. ImageHue : Adjust the image hue. ImageSaturation : Adjust the image Saturation. ImageContrast : Adjust the image Contrast. ImageChannelOrder : Random change the channel order of an image ImageColorJitter : Random adjust brightness, contrast, hue, saturation ImageResize : Resize image ImageAspectScale : Resize the image, keep the aspect ratio. scale according to the short edge ImageRandomAspectScale : Resize the image by randomly choosing a scale ImageChannelNormalize : Image channel normalize ImagePixelNormalizer : Pixel level normalizer ImageCenterCrop : Crop a cropWidth x cropHeight patch from center of image. ImageRandomCrop : Random crop a cropWidth x cropHeight patch from an image. ImageFixedCrop : Crop a fixed area of image ImageDetectionCrop : Crop from object detections, each image should has a tensor detection, ImageExpand : Expand image, fill the blank part with the meanR, meanG, meanB ImageFiller : Fill part of image with certain pixel value ImageHFlip : Flip the image horizontally ImageRandomPreprocessing : It is a wrapper for transformers to control the transform probability ImageBytesToMat : Transform byte array(original image file in byte) to OpenCVMat ImageMatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released. ImageMatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released. ImageSetToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released. More examples can be found here You can also define your own Transformer by extending ImageProcessing , and override the function transformMat to do the actual transformation to ImageFeature . Build Image Transformation Pipeline You can easily build the image transformation pipeline by chaining transformers. Scala example: import com.intel.analytics.bigdl.numeric.NumericFloat import com.intel.analytics.zoo.feature.image._ val imgAug = ImageBytesToMat() - ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() In the above example, the transformations will perform sequentially. Assume you have an ImageSet containing original bytes array, ImageBytesToMat will transform the bytes array to OpenCVMat . ImageColorJitter , ImageExpand , ImageResize , ImageHFlip and ImageChannelNormalize will transform over OpenCVMat , note that OpenCVMat is overwrite by default. ImageMatToTensor transform OpenCVMat to Tensor , and OpenCVMat is released in this step. ImageSetToSample transform the tensors that map inputKeys and targetKeys to sample, which can be used by the following prediction or training tasks. Python example: from zoo.feature.image.imagePreprocessing import * from zoo.feature.common import ChainedPreprocessing img_aug = ChainedPreprocessing([ImageBytesToMat(), ImageColorJitter(), ImageExpand(), ImageResize(300, 300, -1), ImageHFlip(), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) Image Train Train with Image DataFrame You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call fit method to let Analytics Zoo train the model For detail APIs, please refer to: NNFrames Scala example: val batchsize = 128 val nEpochs = 10 val featureTransformer = RowToImageFeature() - ImageResize(256, 256) - ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor() - ImageFeatureToTensor() val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer) .setFeaturesCol( image ) .setLearningRate(0.003) .setBatchSize(batchsize) .setMaxEpoch(nEpochs) .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize) val trainedModel = classifier.fit(trainDf) Python example: batchsize = 128 nEpochs = 10 featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123, 117, 104), ImageMatToTensor(), ImageFeatureToTensor()]) classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\ .setFeaturesCol( image )\\ .setLearningRate(0.003)\\ .setBatchSize(batchsize)\\ .setMaxEpoch(nEpochs)\\ .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size) trainedModel = classifier.fit(trainDf) Train with ImageSet You can train Zoo Keras model with ImageSet. Just call fit method to let Analytics Zoo train the model. Python example: from zoo.common.nncontext import * from zoo.feature.common import * from zoo.feature.image.imagePreprocessing import * from zoo.pipeline.api.keras.layers import Dense, Input, Flatten from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.net import * from bigdl.optim.optimizer import * sc = init_nncontext( train keras ) img_path= /tmp/image image_set = ImageSet.read(img_path,sc, min_partitions=1) transformer = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) image_data = transformer(image_set) labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]) label_rdd = sc.parallelize(labels, 1) samples = image_data.get_image().zip(label_rdd).map( lambda tuple: Sample.from_ndarray(tuple[0], tuple[1])) # create model model_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) inputNode = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputNode) flatten = Flatten()(inception) logits = Dense(2)(flatten) lrModel = Model(inputNode, logits) batchsize = 4 nEpochs = 10 lrModel.compile(optimizer=Adam(learningrate=1e-4), loss='categorical_crossentropy', metrics=['accuracy']) lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs) Image Predict Predict with Image DataFrame After training with NNEstimator/NNCLassifier , you'll get a trained NNModel/NNClassifierModel . You can call transform to predict Image DataFrame with this NNModel/NNClassifierModel . Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to transform to Image DataFrame. After prediction, there is a new column prediction in the prediction image dataframe. Scala example: val batchsize = 128 val nEpochs = 10 val featureTransformer = RowToImageFeature() - ImageResize(256, 256) - ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor() - ImageFeatureToTensor() val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer) .setFeaturesCol( image ) .setLearningRate(0.003) .setBatchSize(batchsize) .setMaxEpoch(nEpochs) .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize) val trainedModel = classifier.fit(trainDf) // predict with trained model val predictions = trainedModel.transform(testDf) predictions.select(col( image ), col( label ), col( prediction )).show(false) // predict with loaded pre-trained model val model = Module.loadModule[Float](modelPath) val dlmodel = NNClassifierModel(model, featureTransformer) .setBatchSize(batchsize) .setFeaturesCol( image ) .setPredictionCol( prediction ) val resultDF = dlmodel.transform(testDf) Python example: batchsize = 128 nEpochs = 10 featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123, 117, 104), ImageMatToTensor(), ImageFeatureToTensor()]) classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\ .setFeaturesCol( image )\\ .setLearningRate(0.003)\\ .setBatchSize(batchsize)\\ .setMaxEpoch(nEpochs)\\ .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size) trainedModel = classifier.fit(trainDf) # predict with trained model predictions = trainedModel.transform(testDf) predictions.select( image , label , prediction ).show(False) # predict with loaded pre-trained model model = Model.loadModel(model_path) dlmodel = NNClassifierModel(model, featureTransformer)\\ .setBatchSize(batchsize)\\ .setFeaturesCol( image )\\ .setPredictionCol( prediction ) resultDF = dlmodel.transform(testDf) Predict with ImageSet After training Zoo Keras model, you can call predict to predict ImageSet. Or you can load pre-trained Analytics-Zoo/BigDL model. Then call to predictImageSet to predict ImageSet. Predict with trained Zoo Keras Model Python example: from zoo.common.nncontext import * from zoo.feature.common import * from zoo.feature.image.imagePreprocessing import * from zoo.pipeline.api.keras.layers import Dense, Input, Flatten from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.net import * from bigdl.optim.optimizer import * sc = init_nncontext( train keras ) img_path= /tmp/image image_set = ImageSet.read(img_path,sc, min_partitions=1) transformer = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) image_data = transformer(image_set) labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]) label_rdd = sc.parallelize(labels, 1) samples = image_data.get_image().zip(label_rdd).map( lambda tuple: Sample.from_ndarray(tuple[0], tuple[1])) # create model model_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) inputNode = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputNode) flatten = Flatten()(inception) logits = Dense(2)(flatten) lrModel = Model(inputNode, logits) batchsize = 4 nEpochs = 10 lrModel.compile(optimizer=Adam(learningrate=1e-4), loss='categorical_crossentropy', metrics=['accuracy']) lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs) prediction = lrModel.predict(samples) result = prediction.collect() Predict with loaded Model You can load pre-trained Analytics-Zoo/BigDL model. Then call to predictImageSet to predict ImageSet. For details, you can check guide of image classificaion or object detection 3D Image Support For 3D images, we can support above operations based on ImageSet. For details, please refer to image API guide Caching Images in Persistent Memory Here is a scala example to train Inception V1 with ImageNet-2012 dataset. If you set the option memoryType to PMEM , the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide here on how to set up the system environment. In the InceptionV1 example, we use an new dataset called FeatureSet to cache the data. Only scala API is currently available. Scala example: scala val rawData = readFromSeqFiles(path, sc, classNumber) val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM) readFromSeqFiles read the Sequence File into RDD[ByteRecord] , then FeatureSet.rdd(rawData, memoryType = PMEM) will cache the data to Intel Optane DC Persistent Memory.","title":"Working with Images"},{"location":"ProgrammingGuide/workingwithimages/#load-image","text":"Analytics Zoo provides APIs to read image to different formats:","title":"Load Image"},{"location":"ProgrammingGuide/workingwithimages/#load-to-data-frame","text":"Analytics Zoo can process image data as Spark Data Frame. NNImageReader is the primary DataFrame-based image loading interface to read images into DataFrame. Scala example: import com.intel.analytics.zoo.common.NNContext import com.intel.analytics.zoo.pipeline.nnframes.NNImageReader val sc = NNContext.initNNContext( app ) val imageDF1 = NNImageReader.readImages( /tmp , sc) val imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc) val imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc) Python: from zoo.common.nncontext import * from zoo.pipeline.nnframes import * sc = init_nncontext( app ) imageDF1 = NNImageReader.readImages( /tmp , sc) imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc) imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc) The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be accessed from com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema . Each record in \"image\" column represents one image record, in the format of Row(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file, and data holds the original file bytes for the image file. mode represents the OpenCV-compatible type: CV_8UC3, CV_8UC1 in most cases. val byteSchema = StructType( StructField( origin , StringType, true) :: StructField( height , IntegerType, false) :: StructField( width , IntegerType, false) :: StructField( nChannels , IntegerType, false) :: // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases StructField( mode , IntegerType, false) :: // Bytes in OpenCV-compatible order: row-wise BGR in most cases StructField( data , BinaryType, false) :: Nil) After loading the image, user can compose the preprocess steps with the Preprocessing defined in com.intel.analytics.zoo.feature.image .","title":"Load to Data Frame"},{"location":"ProgrammingGuide/workingwithimages/#load-to-imageset","text":"ImageSet is a collection of ImageFeature . It can be a DistributedImageSet for distributed image RDD or LocalImageSet for local image array. You can read image data as ImageSet from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature]. Scala example: // create LocalImageSet from an image folder val localImageSet = ImageSet.read( /tmp/image/ ) // create DistributedImageSet from an image folder val distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2) Python example: # create LocalImageSet from an image folder local_image_frame2 = ImageSet.read( /tmp/image/ ) # create DistributedImageSet from an image folder distributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)","title":"Load to ImageSet"},{"location":"ProgrammingGuide/workingwithimages/#image-transformer","text":"Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV: ImageBrightness : Adjust the image brightness. ImageHue : Adjust the image hue. ImageSaturation : Adjust the image Saturation. ImageContrast : Adjust the image Contrast. ImageChannelOrder : Random change the channel order of an image ImageColorJitter : Random adjust brightness, contrast, hue, saturation ImageResize : Resize image ImageAspectScale : Resize the image, keep the aspect ratio. scale according to the short edge ImageRandomAspectScale : Resize the image by randomly choosing a scale ImageChannelNormalize : Image channel normalize ImagePixelNormalizer : Pixel level normalizer ImageCenterCrop : Crop a cropWidth x cropHeight patch from center of image. ImageRandomCrop : Random crop a cropWidth x cropHeight patch from an image. ImageFixedCrop : Crop a fixed area of image ImageDetectionCrop : Crop from object detections, each image should has a tensor detection, ImageExpand : Expand image, fill the blank part with the meanR, meanG, meanB ImageFiller : Fill part of image with certain pixel value ImageHFlip : Flip the image horizontally ImageRandomPreprocessing : It is a wrapper for transformers to control the transform probability ImageBytesToMat : Transform byte array(original image file in byte) to OpenCVMat ImageMatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released. ImageMatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released. ImageSetToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released. More examples can be found here You can also define your own Transformer by extending ImageProcessing , and override the function transformMat to do the actual transformation to ImageFeature .","title":"Image Transformer"},{"location":"ProgrammingGuide/workingwithimages/#build-image-transformation-pipeline","text":"You can easily build the image transformation pipeline by chaining transformers. Scala example: import com.intel.analytics.bigdl.numeric.NumericFloat import com.intel.analytics.zoo.feature.image._ val imgAug = ImageBytesToMat() - ImageResize(256, 256)- ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor[Float]() - ImageSetToSample[Float]() In the above example, the transformations will perform sequentially. Assume you have an ImageSet containing original bytes array, ImageBytesToMat will transform the bytes array to OpenCVMat . ImageColorJitter , ImageExpand , ImageResize , ImageHFlip and ImageChannelNormalize will transform over OpenCVMat , note that OpenCVMat is overwrite by default. ImageMatToTensor transform OpenCVMat to Tensor , and OpenCVMat is released in this step. ImageSetToSample transform the tensors that map inputKeys and targetKeys to sample, which can be used by the following prediction or training tasks. Python example: from zoo.feature.image.imagePreprocessing import * from zoo.feature.common import ChainedPreprocessing img_aug = ChainedPreprocessing([ImageBytesToMat(), ImageColorJitter(), ImageExpand(), ImageResize(300, 300, -1), ImageHFlip(), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()])","title":"Build Image Transformation Pipeline"},{"location":"ProgrammingGuide/workingwithimages/#image-train","text":"","title":"Image Train"},{"location":"ProgrammingGuide/workingwithimages/#train-with-image-dataframe","text":"You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call fit method to let Analytics Zoo train the model For detail APIs, please refer to: NNFrames Scala example: val batchsize = 128 val nEpochs = 10 val featureTransformer = RowToImageFeature() - ImageResize(256, 256) - ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor() - ImageFeatureToTensor() val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer) .setFeaturesCol( image ) .setLearningRate(0.003) .setBatchSize(batchsize) .setMaxEpoch(nEpochs) .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize) val trainedModel = classifier.fit(trainDf) Python example: batchsize = 128 nEpochs = 10 featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123, 117, 104), ImageMatToTensor(), ImageFeatureToTensor()]) classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\ .setFeaturesCol( image )\\ .setLearningRate(0.003)\\ .setBatchSize(batchsize)\\ .setMaxEpoch(nEpochs)\\ .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size) trainedModel = classifier.fit(trainDf)","title":"Train with Image DataFrame"},{"location":"ProgrammingGuide/workingwithimages/#train-with-imageset","text":"You can train Zoo Keras model with ImageSet. Just call fit method to let Analytics Zoo train the model. Python example: from zoo.common.nncontext import * from zoo.feature.common import * from zoo.feature.image.imagePreprocessing import * from zoo.pipeline.api.keras.layers import Dense, Input, Flatten from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.net import * from bigdl.optim.optimizer import * sc = init_nncontext( train keras ) img_path= /tmp/image image_set = ImageSet.read(img_path,sc, min_partitions=1) transformer = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) image_data = transformer(image_set) labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]) label_rdd = sc.parallelize(labels, 1) samples = image_data.get_image().zip(label_rdd).map( lambda tuple: Sample.from_ndarray(tuple[0], tuple[1])) # create model model_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) inputNode = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputNode) flatten = Flatten()(inception) logits = Dense(2)(flatten) lrModel = Model(inputNode, logits) batchsize = 4 nEpochs = 10 lrModel.compile(optimizer=Adam(learningrate=1e-4), loss='categorical_crossentropy', metrics=['accuracy']) lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)","title":"Train with ImageSet"},{"location":"ProgrammingGuide/workingwithimages/#image-predict","text":"","title":"Image Predict"},{"location":"ProgrammingGuide/workingwithimages/#predict-with-image-dataframe","text":"After training with NNEstimator/NNCLassifier , you'll get a trained NNModel/NNClassifierModel . You can call transform to predict Image DataFrame with this NNModel/NNClassifierModel . Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to transform to Image DataFrame. After prediction, there is a new column prediction in the prediction image dataframe. Scala example: val batchsize = 128 val nEpochs = 10 val featureTransformer = RowToImageFeature() - ImageResize(256, 256) - ImageCenterCrop(224, 224) - ImageChannelNormalize(123, 117, 104) - ImageMatToTensor() - ImageFeatureToTensor() val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer) .setFeaturesCol( image ) .setLearningRate(0.003) .setBatchSize(batchsize) .setMaxEpoch(nEpochs) .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize) val trainedModel = classifier.fit(trainDf) // predict with trained model val predictions = trainedModel.transform(testDf) predictions.select(col( image ), col( label ), col( prediction )).show(false) // predict with loaded pre-trained model val model = Module.loadModule[Float](modelPath) val dlmodel = NNClassifierModel(model, featureTransformer) .setBatchSize(batchsize) .setFeaturesCol( image ) .setPredictionCol( prediction ) val resultDF = dlmodel.transform(testDf) Python example: batchsize = 128 nEpochs = 10 featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123, 117, 104), ImageMatToTensor(), ImageFeatureToTensor()]) classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\ .setFeaturesCol( image )\\ .setLearningRate(0.003)\\ .setBatchSize(batchsize)\\ .setMaxEpoch(nEpochs)\\ .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size) trainedModel = classifier.fit(trainDf) # predict with trained model predictions = trainedModel.transform(testDf) predictions.select( image , label , prediction ).show(False) # predict with loaded pre-trained model model = Model.loadModel(model_path) dlmodel = NNClassifierModel(model, featureTransformer)\\ .setBatchSize(batchsize)\\ .setFeaturesCol( image )\\ .setPredictionCol( prediction ) resultDF = dlmodel.transform(testDf)","title":"Predict with Image DataFrame"},{"location":"ProgrammingGuide/workingwithimages/#predict-with-imageset","text":"After training Zoo Keras model, you can call predict to predict ImageSet. Or you can load pre-trained Analytics-Zoo/BigDL model. Then call to predictImageSet to predict ImageSet.","title":"Predict with ImageSet"},{"location":"ProgrammingGuide/workingwithimages/#predict-with-trained-zoo-keras-model","text":"Python example: from zoo.common.nncontext import * from zoo.feature.common import * from zoo.feature.image.imagePreprocessing import * from zoo.pipeline.api.keras.layers import Dense, Input, Flatten from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.net import * from bigdl.optim.optimizer import * sc = init_nncontext( train keras ) img_path= /tmp/image image_set = ImageSet.read(img_path,sc, min_partitions=1) transformer = ChainedPreprocessing( [ImageResize(256, 256), ImageCenterCrop(224, 224), ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageSetToSample()]) image_data = transformer(image_set) labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]) label_rdd = sc.parallelize(labels, 1) samples = image_data.get_image().zip(label_rdd).map( lambda tuple: Sample.from_ndarray(tuple[0], tuple[1])) # create model model_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model full_model = Net.load_bigdl(model_path) # create a new model by remove layers after pool5/drop_7x7_s1 model = full_model.new_graph([ pool5/drop_7x7_s1 ]) # freeze layers from input to pool4/3x3_s2 inclusive model.freeze_up_to([ pool4/3x3_s2 ]) inputNode = Input(name= input , shape=(3, 224, 224)) inception = model.to_keras()(inputNode) flatten = Flatten()(inception) logits = Dense(2)(flatten) lrModel = Model(inputNode, logits) batchsize = 4 nEpochs = 10 lrModel.compile(optimizer=Adam(learningrate=1e-4), loss='categorical_crossentropy', metrics=['accuracy']) lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs) prediction = lrModel.predict(samples) result = prediction.collect()","title":"Predict with trained Zoo Keras Model"},{"location":"ProgrammingGuide/workingwithimages/#predict-with-loaded-model","text":"You can load pre-trained Analytics-Zoo/BigDL model. Then call to predictImageSet to predict ImageSet. For details, you can check guide of image classificaion or object detection","title":"Predict with loaded Model"},{"location":"ProgrammingGuide/workingwithimages/#3d-image-support","text":"For 3D images, we can support above operations based on ImageSet. For details, please refer to image API guide","title":"3D Image Support"},{"location":"ProgrammingGuide/workingwithimages/#caching-images-in-persistent-memory","text":"Here is a scala example to train Inception V1 with ImageNet-2012 dataset. If you set the option memoryType to PMEM , the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide here on how to set up the system environment. In the InceptionV1 example, we use an new dataset called FeatureSet to cache the data. Only scala API is currently available. Scala example: scala val rawData = readFromSeqFiles(path, sc, classNumber) val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM) readFromSeqFiles read the Sequence File into RDD[ByteRecord] , then FeatureSet.rdd(rawData, memoryType = PMEM) will cache the data to Intel Optane DC Persistent Memory.","title":"Caching Images in Persistent Memory"},{"location":"ProgrammingGuide/workingwithtexts/","text":"Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline, including text loading, pre-processing, training and inference, etc. TextSet TextSet is a collection of TextFeatures where each TextFeature keeps information of a single text record. TextSet can either be a DistributedTextSet consisting of text RDD or a LocalTextSet consisting of text array. Read texts as TextSet Read texts from a directory Read texts with labels from a directory. Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. Each category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. Each text will be a given a label according to the directory where it is located. Scala textSet = TextSet.read(path, sc = null, minPartitions = 1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read(path, sc=None, min_partitions=1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1. Read texts from csv file Read texts with id from csv file. Each record is supposed to contain id(String) and text(String) in order. Note that the csv file should be without header. Scala textSet = TextSet.readCSV(path, sc = null, minPartitions = 1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read_csv(path, sc=None, min_partitions=1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1. Read texts from parquet file Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet. Scala textSet = TextSet.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python text_set = TextSet.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext. Build Text Transformation Pipeline You can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to here for more details. Scala Example transformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample() Python Example transformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample() Text Training After doing text transformation, you can directly feed the transformed TextSet into the model for training. Scala model.fit(transformedTextSet, batchSize, nbEpoch) Python model.fit(transformed_text_set, batch_size, nb_epoch) Word Index Save and Load Save word index After training the model, you can save the word index correspondence to text file, which can be used for future inference. Each separate line will be \"word id\". For LocalTextSet, save txt to a local file system. For DistributedTextSet, save txt to a local or distributed file system (such as HDFS). Scala transformedTextSet.saveWordIndex(path) Python transformed_text_set.save_word_index(path) Load word index During text prediction, you can load the saved word index back, so that the prediction TextSet uses exactly the same word index as the training process. Each separate line should be \"word id\". For LocalTextSet, load txt to a local file system. For DistributedTextSet, load txt to a local or distributed file system (such as HDFS). Scala textSet.loadWordIndex(path) Python text_set.load_word_index(path) Text Prediction Given a raw TextSet to do prediction, you need to first load the saved word index back as instructed above and go through the same transformation process as what you did in your training. Note that here you do not need to specify any argument when calling word2idx in the preprocessing pipeline as now you are using exactly the loaded word index. Then you can directly feed the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature. Scala predictionTextSet = model.predict(transformedTextSet) Python prediction_text_set = model.predict(transformed_text_set) Examples You can refer to our TextClassification example for TextSet transformation, training and inference. See here for the Scala example. See here for the Python example.","title":"Working with Texts"},{"location":"ProgrammingGuide/workingwithtexts/#textset","text":"TextSet is a collection of TextFeatures where each TextFeature keeps information of a single text record. TextSet can either be a DistributedTextSet consisting of text RDD or a LocalTextSet consisting of text array.","title":"TextSet"},{"location":"ProgrammingGuide/workingwithtexts/#read-texts-as-textset","text":"","title":"Read texts as TextSet"},{"location":"ProgrammingGuide/workingwithtexts/#read-texts-from-a-directory","text":"Read texts with labels from a directory. Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. Each category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. Each text will be a given a label according to the directory where it is located. Scala textSet = TextSet.read(path, sc = null, minPartitions = 1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read(path, sc=None, min_partitions=1) path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1.","title":"Read texts from a directory"},{"location":"ProgrammingGuide/workingwithtexts/#read-texts-from-csv-file","text":"Read texts with id from csv file. Each record is supposed to contain id(String) and text(String) in order. Note that the csv file should be without header. Scala textSet = TextSet.readCSV(path, sc = null, minPartitions = 1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is null and in this case texts will be read as a LocalTextSet. minPartitions : Integer. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not null. Default is 1. Python text_set = TextSet.read_csv(path, sc=None, min_partitions=1) path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined. sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. Default is None and in this case texts will be read as a LocalTextSet. min_partitions : Int. A suggestion value of the minimal partition number for input texts. Only need to specify this when sc is not None. Default is 1.","title":"Read texts from csv file"},{"location":"ProgrammingGuide/workingwithtexts/#read-texts-from-parquet-file","text":"Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet. Scala textSet = TextSet.readParquet(path, sqlContext) path : The path to the parquet file. sqlContext : An instance of SQLContext. Python text_set = TextSet.read_parquet(path, sc) path : The path to the parquet file. sc : An instance of SparkContext.","title":"Read texts from parquet file"},{"location":"ProgrammingGuide/workingwithtexts/#build-text-transformation-pipeline","text":"You can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to here for more details. Scala Example transformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample() Python Example transformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample()","title":"Build Text Transformation Pipeline"},{"location":"ProgrammingGuide/workingwithtexts/#text-training","text":"After doing text transformation, you can directly feed the transformed TextSet into the model for training. Scala model.fit(transformedTextSet, batchSize, nbEpoch) Python model.fit(transformed_text_set, batch_size, nb_epoch)","title":"Text Training"},{"location":"ProgrammingGuide/workingwithtexts/#word-index-save-and-load","text":"","title":"Word Index Save and Load"},{"location":"ProgrammingGuide/workingwithtexts/#save-word-index","text":"After training the model, you can save the word index correspondence to text file, which can be used for future inference. Each separate line will be \"word id\". For LocalTextSet, save txt to a local file system. For DistributedTextSet, save txt to a local or distributed file system (such as HDFS). Scala transformedTextSet.saveWordIndex(path) Python transformed_text_set.save_word_index(path)","title":"Save word index"},{"location":"ProgrammingGuide/workingwithtexts/#load-word-index","text":"During text prediction, you can load the saved word index back, so that the prediction TextSet uses exactly the same word index as the training process. Each separate line should be \"word id\". For LocalTextSet, load txt to a local file system. For DistributedTextSet, load txt to a local or distributed file system (such as HDFS). Scala textSet.loadWordIndex(path) Python text_set.load_word_index(path)","title":"Load word index"},{"location":"ProgrammingGuide/workingwithtexts/#text-prediction","text":"Given a raw TextSet to do prediction, you need to first load the saved word index back as instructed above and go through the same transformation process as what you did in your training. Note that here you do not need to specify any argument when calling word2idx in the preprocessing pipeline as now you are using exactly the loaded word index. Then you can directly feed the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature. Scala predictionTextSet = model.predict(transformedTextSet) Python prediction_text_set = model.predict(transformed_text_set)","title":"Text Prediction"},{"location":"ProgrammingGuide/workingwithtexts/#examples","text":"You can refer to our TextClassification example for TextSet transformation, training and inference. See here for the Scala example. See here for the Python example.","title":"Examples"},{"location":"PythonUserGuide/examples/","text":"Analytics Zoo provides plenty of examples and notebooks ready for re-use as listed below. Image Classification : This example illustrates how to classify images with a pre-trained model. Object Detection : This example illustrates how to detect objects in images with a pre-trained model. Recommendation: There are two Python notebooks for recommendation models, including Wide and Deep and Neural Collaborative Filtering . Text Classification : This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU TextClassifier model on 20 Newsgroup dataset. DataFrame : There are three examples to show how to perform transfer learning and model inference using pre-trained Inception v1 model with DataFrame-based API. TFNet : This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences. QARanker : This example trains and evaluates a KNRM model on WikiQA dataset for ranking. Distributed TensorFlow : There are several examples to demonstrate how to run distributed TensorFlow and Keras on Spark/BigDL. Anomaly Detection : This example illustrates how to use LSTM to detect anomalies on NYC taxi passengers dataset. See here for more notebooks on user applications and demos.","title":"Examples"},{"location":"PythonUserGuide/install/","text":"For Python users, Analytics Zoo can be installed either from pip or without pip . NOTE : Only Python 2.7 , Python 3.5 and Python 3.6 are supported for now. Install from pip You can use the following command to install the latest release version of analytics-zoo via pip easily: pip install analytics-zoo==0.5.0 # for Python 2.7 pip3 install analytics-zoo==0.5.0 # for Python 3.5 and Python 3.6 Note that you might need to add sudo if you don't have the permission for installation. Important: Installing analytics-zoo from pip will automatically install pyspark . To avoid possible conflicts, you are highly recommended to unset SPARK_HOME if it exists in your environment. Please always first call init_nncontext() at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine. from zoo.common.nncontext import * sc = init_nncontext() Remarks: We've tested this package with pip 9.0.1. pip install --upgrade pip if necessary. Pip install supports Mac and Linux platforms. Pip install only supports local mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to install without pip . You need to install Java = JDK8 before running Analytics Zoo, which is required by pyspark . pyspark==2.4.3 , bigdl==0.8.0 and their dependencies will automatically be installed if they haven't been detected in the current Python environment. Install without pip If you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies. Steps: Download Spark Note that Python 3.6 is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and =2.2.0. See this issue for more discussion. You are recommended to download Analytics Zoo prebuilt release package from the Release Page and extract it. Alternatively, you can also build the Analytics Zoo from source . Install Python dependencies. Analytics Zoo only depends on numpy and six for now. For Spark standalone cluster Remark : If you're running in cluster mode, you need to install Python dependencies on both client and each worker node. Install numpy: sudo apt-get install python-numpy (Ubuntu) Install six: sudo apt-get install python-six (Ubuntu) For Yarn cluster You can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency). You can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command), and then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment. Follow the steps below to create the virtual environment: Make sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first. On Ubuntu, you can run these commands to install: apt-get update apt-get install -y python-setuptools python-dev apt-get install -y gcc make apt-get install -y zip easy_install pip Create the virtualenv package for dependencies. export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package Run ${ANALYTICS_ZOO_HOME}/bin/python_package.sh to create the dependency virtual environment according to the dependencies listed in requirements.txt . You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models. After running this script, there will be venv.zip and venv directory generated in current directory. You can use them to submit your Python jobs. Please refer to here for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster. FAQ In case you encounter the following errors when you create the environment package using the above command: virtualenv ImportError: No module named urllib3 Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda. AttributeError: 'module' object has no attribute 'sslwrap' Try upgrading gevent with pip install --upgrade gevent .","title":"Install"},{"location":"PythonUserGuide/install/#install-from-pip","text":"You can use the following command to install the latest release version of analytics-zoo via pip easily: pip install analytics-zoo==0.5.0 # for Python 2.7 pip3 install analytics-zoo==0.5.0 # for Python 3.5 and Python 3.6 Note that you might need to add sudo if you don't have the permission for installation. Important: Installing analytics-zoo from pip will automatically install pyspark . To avoid possible conflicts, you are highly recommended to unset SPARK_HOME if it exists in your environment. Please always first call init_nncontext() at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine. from zoo.common.nncontext import * sc = init_nncontext() Remarks: We've tested this package with pip 9.0.1. pip install --upgrade pip if necessary. Pip install supports Mac and Linux platforms. Pip install only supports local mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to install without pip . You need to install Java = JDK8 before running Analytics Zoo, which is required by pyspark . pyspark==2.4.3 , bigdl==0.8.0 and their dependencies will automatically be installed if they haven't been detected in the current Python environment.","title":"Install from pip"},{"location":"PythonUserGuide/install/#install-without-pip","text":"If you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies. Steps: Download Spark Note that Python 3.6 is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and =2.2.0. See this issue for more discussion. You are recommended to download Analytics Zoo prebuilt release package from the Release Page and extract it. Alternatively, you can also build the Analytics Zoo from source . Install Python dependencies. Analytics Zoo only depends on numpy and six for now.","title":"Install without pip"},{"location":"PythonUserGuide/install/#for-spark-standalone-cluster","text":"Remark : If you're running in cluster mode, you need to install Python dependencies on both client and each worker node. Install numpy: sudo apt-get install python-numpy (Ubuntu) Install six: sudo apt-get install python-six (Ubuntu)","title":"For Spark standalone cluster"},{"location":"PythonUserGuide/install/#for-yarn-cluster","text":"You can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency). You can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command), and then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment. Follow the steps below to create the virtual environment: Make sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first. On Ubuntu, you can run these commands to install: apt-get update apt-get install -y python-setuptools python-dev apt-get install -y gcc make apt-get install -y zip easy_install pip Create the virtualenv package for dependencies. export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package Run ${ANALYTICS_ZOO_HOME}/bin/python_package.sh to create the dependency virtual environment according to the dependencies listed in requirements.txt . You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models. After running this script, there will be venv.zip and venv directory generated in current directory. You can use them to submit your Python jobs. Please refer to here for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster. FAQ In case you encounter the following errors when you create the environment package using the above command: virtualenv ImportError: No module named urllib3 Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda. AttributeError: 'module' object has no attribute 'sslwrap' Try upgrading gevent with pip install --upgrade gevent .","title":"For Yarn cluster"},{"location":"PythonUserGuide/python-faq/","text":"This page lists solutions to some common questions. ImportError : from zoo.pipeline.api.keras.layers import * Check if the path is pointing to python-api.zip: --py-files ${ANALYTICS_ZOO_PY_ZIP} Check if the path is pointing to python-api.zip: export PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH Python in worker has a different version 2.7 than that in driver 3.5 export PYSPARK_PYTHON=/usr/local/bin/python3.5 This path should be valid on every worker node. export PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.5 This path should be valid on every driver node. TypeError : 'JavaPackage' object is not callable Check if every path within the launch script is valid especially the path that ends with jar. If there are extra jars involved, check if the Spark version Analytics Zoo is built and the Spark version the extra jar is built are compatible. java.lang. NoSuchMethodError :XXX or Py4JError : ofFloat does not exist in the JVM Check if the Spark version matches, i.e check if you are using Spark 2.x but the underneath Analytics Zoo is compiled with Spark 1.6. If there are extra jars involved, also check if the Spark version matches.","title":"FAQ"},{"location":"PythonUserGuide/run/","text":"You need to first install analytics-zoo, either from pip or without pip . NOTE : Only Python 2.7 , Python 3.5 and Python 3.6 are supported for now. Run after pip install Important: Installing analytics-zoo from pip will automatically install pyspark . To avoid possible conflicts, you are highly recommended to unset SPARK_HOME if it exists in your environment. Please always first call init_nncontext() at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine. from zoo.common.nncontext import * sc = init_nncontext() Use an Interactive Shell Type python in the command line to start a REPL. Try to run the example code to verify the installation. Use Jupyter Notebook Start jupyter notebook as you normally do, e.g. jupyter notebook --notebook-dir=./ --ip=* --no-browser Try to run the example code to verify the installation. Configurations Increase memory export SPARK_DRIVER_MEMORY=20g Add extra jars or python packages Set the environment variables BIGDL_JARS and BIGDL_PACKAGES BEFORE creating SparkContext : export BIGDL_JARS=... export BIGDL_PACKAGES=... Run without pip install Note that Python 3.6 is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and =2.2.0. See this issue for more discussion. Set SPARK_HOME and ANALYTICS_ZOO_HOME If you download Analytics Zoo from the Release Page : export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package If you build Analytics Zoo by yourself: export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo Update spark-analytics-zoo.conf (Optional) If you have some customized properties in some files, which will be used with the --properties-file option in spark-submit/pyspark , you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf. Run with pyspark ${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*] --master set the master URL to connect to --jars if there are extra jars needed. --py-files if there are extra python packages needed. You can also specify other options available for pyspark in the above command if needed. Try to run the example code for verification. Run with spark-submit An Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies (e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try running the Analytics Zoo Object Detection Python example as follows: ${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path Run with Jupyter Notebook With the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks (such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries, Spark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive visualization tools. Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g., sudo apt install python sudo apt install python-pip sudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud Launch the Jupyter Notebook as follows: ${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*] --master set the master URL to connect to --jars if there are extra jars needed. --py-files if there are extra python packages needed. You can also specify other options available for pyspark in the above command if needed. After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using your browser. You can find the exact URL in the console output when you started Jupyter; by default, the dashboard URL is http://your_node:8888/ Try to run the example code for verification. Run with virtual environment on Yarn If you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide here , you can run Python programs using Analytics Zoo using the following command. Here we use Analytics Zoo Object Detection Python example for illustration. Yarn cluster mode export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package export VENV_HOME=the parent directory of venv.zip and venv folder PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\ --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=venv.zip/venv/bin/python \\ --master yarn-cluster \\ --executor-memory 10g \\ --driver-memory 10g \\ --executor-cores 8 \\ --num-executors 2 \\ --archives ${VENV_HOME}/venv.zip \\ predict.py model_path image_path output_path Yarn client mode export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package export VENV_HOME=the parent directory of venv.zip and venv folder PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\ --master yarn \\ --deploy-mode client \\ --executor-memory 10g \\ --driver-memory 10g \\ --executor-cores 16 \\ --num-executors 2 \\ --archives ${VENV_HOME}/venv.zip \\ predict.py model_path image_path output_path Example code To verify if Analytics Zoo can run successfully, run the following simple code: import zoo from zoo.common.nncontext import * from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * # Get the current Analytics Zoo version zoo.__version__ # Create a SparkContext and initialize the BigDL engine. sc = init_nncontext() # Create a Sequential model containing a Dense layer. model = Sequential() model.add(Dense(8, input_shape=(10, )))","title":"Run"},{"location":"PythonUserGuide/run/#run-after-pip-install","text":"Important: Installing analytics-zoo from pip will automatically install pyspark . To avoid possible conflicts, you are highly recommended to unset SPARK_HOME if it exists in your environment. Please always first call init_nncontext() at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine. from zoo.common.nncontext import * sc = init_nncontext() Use an Interactive Shell Type python in the command line to start a REPL. Try to run the example code to verify the installation. Use Jupyter Notebook Start jupyter notebook as you normally do, e.g. jupyter notebook --notebook-dir=./ --ip=* --no-browser Try to run the example code to verify the installation. Configurations Increase memory export SPARK_DRIVER_MEMORY=20g Add extra jars or python packages Set the environment variables BIGDL_JARS and BIGDL_PACKAGES BEFORE creating SparkContext : export BIGDL_JARS=... export BIGDL_PACKAGES=...","title":"Run after pip install"},{"location":"PythonUserGuide/run/#run-without-pip-install","text":"Note that Python 3.6 is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and =2.2.0. See this issue for more discussion. Set SPARK_HOME and ANALYTICS_ZOO_HOME If you download Analytics Zoo from the Release Page : export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package If you build Analytics Zoo by yourself: export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo Update spark-analytics-zoo.conf (Optional) If you have some customized properties in some files, which will be used with the --properties-file option in spark-submit/pyspark , you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.","title":"Run without pip install"},{"location":"PythonUserGuide/run/#run-with-pyspark","text":"${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*] --master set the master URL to connect to --jars if there are extra jars needed. --py-files if there are extra python packages needed. You can also specify other options available for pyspark in the above command if needed. Try to run the example code for verification.","title":"Run with pyspark"},{"location":"PythonUserGuide/run/#run-with-spark-submit","text":"An Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies (e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try running the Analytics Zoo Object Detection Python example as follows: ${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path","title":"Run with spark-submit"},{"location":"PythonUserGuide/run/#run-with-jupyter-notebook","text":"With the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks (such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries, Spark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive visualization tools. Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g., sudo apt install python sudo apt install python-pip sudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud Launch the Jupyter Notebook as follows: ${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*] --master set the master URL to connect to --jars if there are extra jars needed. --py-files if there are extra python packages needed. You can also specify other options available for pyspark in the above command if needed. After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using your browser. You can find the exact URL in the console output when you started Jupyter; by default, the dashboard URL is http://your_node:8888/ Try to run the example code for verification.","title":"Run with Jupyter Notebook"},{"location":"PythonUserGuide/run/#run-with-virtual-environment-on-yarn","text":"If you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide here , you can run Python programs using Analytics Zoo using the following command. Here we use Analytics Zoo Object Detection Python example for illustration. Yarn cluster mode export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package export VENV_HOME=the parent directory of venv.zip and venv folder PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\ --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=venv.zip/venv/bin/python \\ --master yarn-cluster \\ --executor-memory 10g \\ --driver-memory 10g \\ --executor-cores 8 \\ --num-executors 2 \\ --archives ${VENV_HOME}/venv.zip \\ predict.py model_path image_path output_path Yarn client mode export SPARK_HOME=the root directory of Spark export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package export VENV_HOME=the parent directory of venv.zip and venv folder PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\ --master yarn \\ --deploy-mode client \\ --executor-memory 10g \\ --driver-memory 10g \\ --executor-cores 16 \\ --num-executors 2 \\ --archives ${VENV_HOME}/venv.zip \\ predict.py model_path image_path output_path","title":"Run with virtual environment on Yarn"},{"location":"PythonUserGuide/run/#example-code","text":"To verify if Analytics Zoo can run successfully, run the following simple code: import zoo from zoo.common.nncontext import * from zoo.pipeline.api.keras.models import * from zoo.pipeline.api.keras.layers import * # Get the current Analytics Zoo version zoo.__version__ # Create a SparkContext and initialize the BigDL engine. sc = init_nncontext() # Create a Sequential model containing a Dense layer. model = Sequential() model.add(Dense(8, input_shape=(10, )))","title":"Example code"},{"location":"ScalaUserGuide/examples/","text":"Analytics Zoo provides plenty of examples ready for re-use as listed below. Image Classification : This example illustrates how to do the image classification with pre-trained model. Object Detection : This example illustrates how to detect objects in image with pre-trained model. Recommendation : There are two Scala examples for recommender models, including wide and deep(WND) model and Neural network-based Collaborative Filtering(NCF) model. Text Classification : This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU TextClassifier model on 20 Newsgroup dataset DataFrame : There are three examples to show how to perform transfer learning/model inference using pre-trained Inception v1 model with DataFrame-based API. TFNet : TFNet can encapsulate a frozen TensorFlow graph as an Analytics Zoo layer for inference. This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences using Analytics Zoo on Spark. QARanker : This example trains and evaluates a KNRM model on WikiQA dataset for ranking. Anomaly Detection : This example illustrates how to use LSTM to detect anomalies on NYC taxi passengers dataset. Seq2seq : This example illustrates how to train a seq2seq model and generate answer for a given query with a seq2seq model using Analytics Zoo on Spark.","title":"Examples"},{"location":"ScalaUserGuide/install/","text":"Download a pre-built library You can download the Analytics Zoo release and nightly build from the Release Page Link with Analytics Zoo 0.5.0 Release Currently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project: dependency groupId com.intel.analytics.zoo /groupId artifactId analytics-zoo-bigdl_0.8.0-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.0] /artifactId version 0.5.0 /version /dependency SBT developers can use libraryDependencies += com.intel.analytics.zoo % analytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1] % 0.5.0 Remarks: Please choose the available suffix above according to your Spark platform and the BigDL version you want to use. You don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo. Download Analytics Zoo Source Analytics Zoo source code is available at GitHub $ git clone https://github.com/intel-analytics/analytics-zoo.git By default, git clone will download the development version of Analytics Zoo, if you want a release version, you can use command git checkout to change the version. Setup Build Environment The following instructions are aligned with master code. Maven 3 is needed to build Analytics Zoo, you can download it from the maven website . After installing Maven 3, please set the environment variable MAVEN_OPTS as follows: $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d. Build with script (Recommended) It is highly recommended that you build Analytics Zoo using the make-dist.sh script . And it will handle the MAVEN_OPTS variable. Once downloaded, you can build Analytics Zoo with the following commands: $ bash make-dist.sh After that, you can find a dist folder, which contains all the needed files to run a Analytics Zoo program. The files in dist include: dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes. dist/lib/analytics-zoo-VERSION-python-api.zip : This zip package contains all Python files of Analytics Zoo. The instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use Java 8 when running with Spark 2.x; otherwise you may observe very poor performance. Build for Spark 1.6 To build for Spark 1.6(which uses Scala 2.10 by default), pass -P spark_1.6 to the make-dist.sh script: $ bash make-dist.sh -P spark_1.6 Build for Scala 2.10 or 2.11 By default, make-dist.sh uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass -P scala_2.10 or -P scala_2.11 to make-dist.sh as appropriate. Build with Maven To build Analytics Zoo directly using Maven, run the command below: $ mvn clean package -DskipTests After that, you can find that jar packages in PATH_TO_ANALYTICS_ZOO /target/, where PATH_TO_ANALYTICS_ZOO is the path to the directory of the Analytics Zoo. Note that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven: -P spark_1.6 : build for Spark 1.6 (using Scala 2.10). -P scala_2.10 (or -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11) Setup IDE We set the scope of spark related library to provided in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time. This will cause a problem in IDE. When you run applications, it will throw NoClassDefFoundError because the library scope is provided . You can easily change the scopes by the all-in-one profile. In Intellij, go to View - Tools Windows - Maven Projects. Then in the Maven Projects panel, Profiles - click \"all-in-one\".","title":"Install"},{"location":"ScalaUserGuide/install/#download-a-pre-built-library","text":"You can download the Analytics Zoo release and nightly build from the Release Page","title":"Download a pre-built library"},{"location":"ScalaUserGuide/install/#link-with-analytics-zoo-050-release","text":"Currently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project: dependency groupId com.intel.analytics.zoo /groupId artifactId analytics-zoo-bigdl_0.8.0-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.0] /artifactId version 0.5.0 /version /dependency SBT developers can use libraryDependencies += com.intel.analytics.zoo % analytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1] % 0.5.0 Remarks: Please choose the available suffix above according to your Spark platform and the BigDL version you want to use. You don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo.","title":"Link with Analytics Zoo 0.5.0 Release"},{"location":"ScalaUserGuide/install/#download-analytics-zoo-source","text":"Analytics Zoo source code is available at GitHub $ git clone https://github.com/intel-analytics/analytics-zoo.git By default, git clone will download the development version of Analytics Zoo, if you want a release version, you can use command git checkout to change the version.","title":"Download Analytics Zoo Source"},{"location":"ScalaUserGuide/install/#setup-build-environment","text":"The following instructions are aligned with master code. Maven 3 is needed to build Analytics Zoo, you can download it from the maven website . After installing Maven 3, please set the environment variable MAVEN_OPTS as follows: $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.","title":"Setup Build Environment"},{"location":"ScalaUserGuide/install/#build-with-script-recommended","text":"It is highly recommended that you build Analytics Zoo using the make-dist.sh script . And it will handle the MAVEN_OPTS variable. Once downloaded, you can build Analytics Zoo with the following commands: $ bash make-dist.sh After that, you can find a dist folder, which contains all the needed files to run a Analytics Zoo program. The files in dist include: dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes. dist/lib/analytics-zoo-VERSION-python-api.zip : This zip package contains all Python files of Analytics Zoo. The instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use Java 8 when running with Spark 2.x; otherwise you may observe very poor performance.","title":"Build with script (Recommended)"},{"location":"ScalaUserGuide/install/#build-for-spark-16","text":"To build for Spark 1.6(which uses Scala 2.10 by default), pass -P spark_1.6 to the make-dist.sh script: $ bash make-dist.sh -P spark_1.6","title":"Build for Spark 1.6"},{"location":"ScalaUserGuide/install/#build-for-scala-210-or-211","text":"By default, make-dist.sh uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass -P scala_2.10 or -P scala_2.11 to make-dist.sh as appropriate.","title":"Build for Scala 2.10 or 2.11"},{"location":"ScalaUserGuide/install/#build-with-maven","text":"To build Analytics Zoo directly using Maven, run the command below: $ mvn clean package -DskipTests After that, you can find that jar packages in PATH_TO_ANALYTICS_ZOO /target/, where PATH_TO_ANALYTICS_ZOO is the path to the directory of the Analytics Zoo. Note that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven: -P spark_1.6 : build for Spark 1.6 (using Scala 2.10). -P scala_2.10 (or -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11)","title":"Build with Maven"},{"location":"ScalaUserGuide/install/#setup-ide","text":"We set the scope of spark related library to provided in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time. This will cause a problem in IDE. When you run applications, it will throw NoClassDefFoundError because the library scope is provided . You can easily change the scopes by the all-in-one profile. In Intellij, go to View - Tools Windows - Maven Projects. Then in the Maven Projects panel, Profiles - click \"all-in-one\".","title":"Setup IDE"},{"location":"ScalaUserGuide/run/","text":"Set Environment Variables Set ANALYTICS_ZOO_HOME and SPARK_HOME : If you download Analytics Zoo from the Release Page export SPARK_HOME=folder path where you extract the spark package export ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package If you build Analytics Zoo by yourself export SPARK_HOME=folder path where you extract the spark package export ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder Use Interactive Spark Shell You can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support: ${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*] You will see a welcome message looking like below: Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /___/ .__/\\_,_/_/ /_/\\_\\ version 1.6.0 /_/ Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79) Spark context available as sc. scala Now you'll be able to play with Analytics Zoo API's. For instance, to load a pre-trained object detection model, you may try below code: scala import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector scala ObjectDetector.loadModel[Float](params.modelPath) Run as a Spark Program You can run a analytics zoo program, e.g., the Object Detection , as a standard Spark program (running in either local mode or cluster mode) as follows: Download the pre-trained model from here . Prepare predict images Run the following command: # Spark local mode spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark standalone mode spark-submit --master spark://... --executor-cores cores_per_executor \\ --total-executor-cores total_cores_for_the_job \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark yarn client mode spark-submit --master yarn --deploy-mode client \\ --executor-cores cores_per_executor \\ --num-executors executors_number \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark yarn cluster mode spark-submit --master yarn --deploy-mode cluster \\ --executor-cores cores_per_executor \\ --num-executors executors_number \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model If you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below. import com.intel.analytics.zoo.common.NNContext val sc = NNContext.initNNContext(conf)","title":"Run"},{"location":"ScalaUserGuide/run/#set-environment-variables","text":"Set ANALYTICS_ZOO_HOME and SPARK_HOME : If you download Analytics Zoo from the Release Page export SPARK_HOME=folder path where you extract the spark package export ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package If you build Analytics Zoo by yourself export SPARK_HOME=folder path where you extract the spark package export ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder","title":"Set Environment Variables"},{"location":"ScalaUserGuide/run/#use-interactive-spark-shell","text":"You can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support: ${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*] You will see a welcome message looking like below: Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /___/ .__/\\_,_/_/ /_/\\_\\ version 1.6.0 /_/ Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79) Spark context available as sc. scala Now you'll be able to play with Analytics Zoo API's. For instance, to load a pre-trained object detection model, you may try below code: scala import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector scala ObjectDetector.loadModel[Float](params.modelPath)","title":"Use Interactive Spark Shell"},{"location":"ScalaUserGuide/run/#run-as-a-spark-program","text":"You can run a analytics zoo program, e.g., the Object Detection , as a standard Spark program (running in either local mode or cluster mode) as follows: Download the pre-trained model from here . Prepare predict images Run the following command: # Spark local mode spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark standalone mode spark-submit --master spark://... --executor-cores cores_per_executor \\ --total-executor-cores total_cores_for_the_job \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark yarn client mode spark-submit --master yarn --deploy-mode client \\ --executor-cores cores_per_executor \\ --num-executors executors_number \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model # Spark yarn cluster mode spark-submit --master yarn --deploy-mode cluster \\ --executor-cores cores_per_executor \\ --num-executors executors_number \\ --class com.intel.analytics.zoo.examples.objectdetection.Predict \\ dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\ --image path_to_your_images --output path_to_output --model path_to_model If you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below. import com.intel.analytics.zoo.common.NNContext val sc = NNContext.initNNContext(conf)","title":"Run as a Spark Program"}]}