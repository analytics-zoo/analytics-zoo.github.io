<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Sequence to Sequence - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Build a Seq2seq Model", url: "#build-a-seq2seq-model", children: [
              {title: "Build an Encoder", url: "#build-an-encoder" },
              {title: "Build a Decoder", url: "#build-a-decoder" },
              {title: "Build a Bridge", url: "#build-a-bridge" },
              {title: "Build a Seq2seq", url: "#build-a-seq2seq" },
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Sequence to Sequence</strong></h1>
    <hr>
    <p>Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more.
The model could be fed into NNFrames or BigDL Optimizer directly for training.</p>
<hr />
<h2 id="build-a-seq2seq-model"><strong>Build a Seq2seq Model</strong></h2>
<p>Before build Seq2seq Model, you need build <code>Encoder</code>, <code>Decoder</code>. And <code>Bridge</code> if you want to do some transformation before passing encoder states to decoder.</p>
<h3 id="build-an-encoder"><strong>Build an Encoder</strong></h3>
<p>Currently we only support <code>RNNEncoder</code> which enables you to put RNN layers into encoder.
You can call the following API in Scala and Python respectively to create a <code>RNNEncoder</code>.</p>
<p><strong>Scala</strong></p>
<pre><code class="scala">val encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding)
</code></pre>

<ul>
<li><code>rnnType</code> style of recurrent unit, one of [SimpleRNN, LSTM, GRU]</li>
<li><code>numLayers</code> number of layers used in encoder</li>
<li><code>hiddenSize</code> hidden size of encoder</li>
<li><code>embedding</code> embedding layer in encoder, default is <code>null</code></li>
</ul>
<p>You can also define RNN layers yourself</p>
<pre><code class="scala">val encoder = RNNEncoder(rnns, embedding, inputShape)
</code></pre>

<ul>
<li><code>rnns</code> rnn layers used for encoder, support stacked rnn layers</li>
<li><code>embedding</code> embedding layer in encoder, default is <code>null</code></li>
</ul>
<p><strong>Python</strong></p>
<pre><code class="python">encoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding)
</code></pre>

<ul>
<li><code>rnn_type</code> style of recurrent unit, one of [SimpleRNN, LSTM, GRU]</li>
<li><code>nlayers</code> number of layers used in encoder</li>
<li><code>hidden_size</code> hidden size of encoder</li>
<li><code>embedding</code> embedding layer in encoder, default is <code>None</code></li>
</ul>
<p>Or</p>
<pre><code class="python">encoder = RNNEncoder(rnns, embedding, input_shape)
</code></pre>

<ul>
<li><code>rnns</code> rnn layers used for encoder, support stacked rnn layers</li>
<li><code>embedding</code> embedding layer in encoder, default is <code>None</code></li>
</ul>
<h3 id="build-a-decoder"><strong>Build a Decoder</strong></h3>
<p>Similar to Encoder, we only support <code>RNNDecoder</code> and API is pretty much the same with <code>RNNEncoder</code></p>
<p><strong>Scala</strong></p>
<pre><code class="scala">val decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding)
</code></pre>

<ul>
<li><code>rnnType</code> style of recurrent unit, one of [SimpleRNN, LSTM, GRU]</li>
<li><code>numLayers</code> number of layers used in decoder</li>
<li><code>hiddenSize</code> hidden size of decoder</li>
<li><code>embedding</code> embedding layer in decoder, default is <code>null</code></li>
</ul>
<p>You can also define RNN layers yourself</p>
<pre><code class="scala">val decoder = RNNDecoder(rnns, embedding, inputShape)
</code></pre>

<ul>
<li><code>rnns</code> rnn layers used for decoder, support stacked rnn layers</li>
<li><code>embedding</code> embedding layer in decoder, default is <code>null</code></li>
</ul>
<p><strong>Python</strong></p>
<pre><code class="python">encoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding):
</code></pre>

<ul>
<li><code>rnn_type</code> style of recurrent unit, one of [SimpleRNN, LSTM, GRU]</li>
<li><code>nlayers</code> number of layers used in decoder</li>
<li><code>hidden_size</code> hidden size of decoder</li>
<li><code>embedding</code> embedding layer in decoder, default is <code>None</code></li>
</ul>
<p>Or</p>
<pre><code class="python">decoder = RNNDecoder(rnns, embedding, input_shape)
</code></pre>

<ul>
<li><code>rnns</code> rnn layers used for decoder, support stacked rnn layers</li>
<li><code>embedding</code> embedding layer in decoder, default is <code>None</code></li>
</ul>
<h3 id="build-a-bridge"><strong>Build a Bridge</strong></h3>
<p>By default, encoder states are directly fed into decoder. In this case, you don't need build a <code>Bridge</code>. But if you want to do some transformation before feed encoder states to decoder,
please use following API to create a <code>Bridge</code>.</p>
<p><strong>Scala</strong></p>
<pre><code class="scala">val bridge = Bridge(bridgeType, decoderHiddenSize)
</code></pre>

<ul>
<li><code>bridgeType</code> currently only support "dense | densenonlinear"</li>
<li><code>decoderHiddenSize</code> hidden size of decoder</li>
</ul>
<p>You can also specify various keras layers as a <code>Bridge</code></p>
<pre><code class="scala">val bridge = Bridge(bridge)
</code></pre>

<ul>
<li><code>bridge</code> keras layers used to do the transformation</li>
</ul>
<p><strong>Python</strong></p>
<pre><code class="python">bridge = Bridge.initialize(bridge_type, decoder_hidden_size)
</code></pre>

<ul>
<li><code>bridge_type</code>: currently only support "dense | densenonlinear"</li>
<li><code>decoder_hidden_size</code>: hidden size of decoder</li>
</ul>
<p>Or</p>
<pre><code class="python">bridge = Bridge.initialize_from_keras_layer(bridge)
</code></pre>

<ul>
<li><code>bridge</code> keras layers used to do the transformation</li>
</ul>
<h3 id="build-a-seq2seq"><strong>Build a Seq2seq</strong></h3>
<p><strong>Scala</strong></p>
<pre><code class="scala">val seq2seq = Seq2seq(encoder,
    decoder,
    inputShape,
    outputShape,
    bridge,
    generator)
</code></pre>

<ul>
<li><code>encoder</code> an encoder object</li>
<li><code>decoder</code> a decoder object</li>
<li><code>inputShape</code> shape of encoder input, for variable length, please input -1</li>
<li><code>outputShape</code> shape of decoder input, for variable length, please input -1</li>
<li><code>bridge</code> connect encoder and decoder, you can input <code>null</code></li>
<li><code>generator</code> Feeding decoder output to generator to generate final result, <code>null</code> is supported</li>
</ul>
<p>See <a href="https://github.com/intel-analytics/analytics-zoo/tree/master/zoo/src/main/scala/com/intel/analytics/zoo/examples/chatbot">here</a> for the Scala example that trains the Seq2seq model and uses the model to do prediction.</p>
<p><strong>Python</strong></p>
<pre><code class="python">seq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge,
                 generator)
</code></pre>

<ul>
<li><code>encoder</code> an encoder object</li>
<li><code>decoder</code> a decoder object</li>
<li><code>input_shape</code> shape of encoder input, for variable length, please input -1</li>
<li><code>output_shape</code> shape of decoder input, for variable length, please input -1</li>
<li><code>bridge</code> connect encoder and decoder, you can input <code>null</code></li>
<li><code>generator</code> Feeding decoder output to generator to generate final result, <code>None</code> is supported</li>
</ul>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>