<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        
        <link rel="shortcut icon" href="img/favicon.ico">
        <title>Analytics Zoo</title>
        <link href="css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="css/font-awesome.min.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <link href="extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="js/jquery-1.10.2.min.js" defer></script>
        <script src="js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
            ga('send', 'pageview');
        </script> 
    </head>

    <body class="homepage">

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href=".">Analytics Zoo</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="active">
                                <a href=".">Overview</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Releases <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="release-download/">Download</a>
</li>
                                    
<li >
    <a href="release-docs/">Documentation</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">Python</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="PythonUserGuide/install/">Install</a>
</li>
            
<li >
    <a href="PythonUserGuide/run/">Run</a>
</li>
            
<li >
    <a href="PythonUserGuide/examples/">Examples</a>
</li>
            
<li >
    <a href="PythonUserGuide/python-faq/">FAQ</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Scala</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="ScalaUserGuide/install/">Install</a>
</li>
            
<li >
    <a href="ScalaUserGuide/run/">Run</a>
</li>
            
<li >
    <a href="ScalaUserGuide/examples/">Examples</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Programming Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">Pipeline APIs</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="ProgrammingGuide/nnframes/">DataFrame and ML Pipeline</a>
</li>
            
<li >
    <a href="ProgrammingGuide/autograd/">Autograd</a>
</li>
            
<li >
    <a href="ProgrammingGuide/transferlearning/">Transfer Learning</a>
</li>
            
<li >
    <a href="ProgrammingGuide/inference/">Model Serving</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">TFPark API</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="ProgrammingGuide/tensorflow/">TFPark</a>
</li>
            
<li >
    <a href="ProgrammingGuide/text-models/">Text Models</a>
</li>
            
<li >
    <a href="ProgrammingGuide/bert-classifier/">BERT Classifier</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Feature Engineering</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="ProgrammingGuide/workingwithimages/">Working with Images</a>
</li>
            
<li >
    <a href="ProgrammingGuide/workingwithtexts/">Working with Texts</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Built-in Models</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="ProgrammingGuide/object-detection/">Object Detection API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/image-classification/">Image Classification API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/text-classification/">Text Classification API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/recommendation/">Recommendation API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/anomaly-detection/">Anomaly Detection API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/text-matching/">Text Matching API</a>
</li>
            
<li >
    <a href="ProgrammingGuide/seq2seq/">Sequence to Sequence API</a>
</li>
    </ul>
  </li>
                                    
<li >
    <a href="ProgrammingGuide/usercases-overview/">Reference Use Cases</a>
</li>
                                    
<li >
    <a href="ProgrammingGuide/run-on-dataproc/">Run on Google Cloud Dataproc</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">White Paper <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="wp-bigdl/">BigDL</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">Pipeline APIs</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="APIGuide/PipelineAPI/nnframes/">NNFrames</a>
</li>
            
<li >
    <a href="APIGuide/PipelineAPI/math/">Autograd-Math</a>
</li>
            
<li >
    <a href="APIGuide/PipelineAPI/variable/">Autograd-Variable</a>
</li>
            
<li >
    <a href="APIGuide/PipelineAPI/net/">Net</a>
</li>
            
<li >
    <a href="APIGuide/PipelineAPI/inference/">Inference</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">TFPark API</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="APIGuide/TFPark/model/">KerasModel</a>
</li>
            
<li >
    <a href="APIGuide/TFPark/estimator/">TFEstimator</a>
</li>
            
<li >
    <a href="APIGuide/TFPark/text-models/">Text Models</a>
</li>
            
<li >
    <a href="APIGuide/TFPark/bert-classifier/">BERT Classifier</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Feature Engineering</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="APIGuide/FeatureEngineering/featureset/">FeatureSet</a>
</li>
            
<li >
    <a href="APIGuide/FeatureEngineering/relation/">Relation</a>
</li>
            
<li >
    <a href="APIGuide/FeatureEngineering/image/">Image</a>
</li>
            
<li >
    <a href="APIGuide/FeatureEngineering/text/">Text</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Models</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="APIGuide/Models/object-detection/">Object Detection</a>
</li>
            
<li >
    <a href="APIGuide/Models/image-classification/">Image Classification</a>
</li>
            
<li >
    <a href="APIGuide/Models/text-classification/">Text Classification</a>
</li>
            
<li >
    <a href="APIGuide/Models/recommendation/">Recommendation</a>
</li>
            
<li >
    <a href="APIGuide/Models/anomaly-detection/">Anomaly Detection</a>
</li>
            
<li >
    <a href="APIGuide/Models/text-matching/">Text Matching</a>
</li>
            
<li >
    <a href="APIGuide/Models/seq2seq/">Sequence to Sequence</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Keras-Style API Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="KerasStyleAPIGuide/keras-api-python/">Python Guide</a>
</li>
                                    
<li >
    <a href="KerasStyleAPIGuide/keras-api-scala/">Scala Guide</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Layers</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="KerasStyleAPIGuide/Layers/activation/">Activation</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/initialization/">Initialization</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/core/">Core Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/convolutional/">Convolutional Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/pooling/">Pooling Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/recurrent/">Recurrent Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/normalization/">Normalization Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/embedding/">Embedding Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/dropout/">Dropout Layers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/advanced-activation/">Advanced Activations</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Layers/wrappers/">Layer Wrappers</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Optimization</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="KerasStyleAPIGuide/Optimization/training/">Train, evaluate or predict a model</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Optimization/optimizers/">Optimizers</a>
</li>
            
<li >
    <a href="KerasStyleAPIGuide/Optimization/objectives/">Objectives</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li >
                                <a href="powered-by/">Powered by</a>
                            </li>
                            <li >
                                <a href="presentations/">Presentations</a>
                            </li>
                            <li >
                                <a href="known-issues/">FAQ and Known Issues</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="disabled">
                                <a rel="next" >
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="release-download/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/intel-analytics/analytics-zoo/edit/master/docs/index.md">Edit on Fork on GitHub </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#analytics-zoo">Analytics Zoo</a></li>
            <li><a href="#what-is-analytics-zoo">What is Analytics Zoo?</a></li>
            <li><a href="#how-to-use-analytics-zoo">How to use Analytics Zoo?</a></li>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#distributed-tensorflow-and-keras-on-sparkbigdl">Distributed TensorFlow and Keras on Spark/BigDL</a></li>
            <li><a href="#high-level-abstractions-and-apis">High level abstractions and APIs</a></li>
            <li><a href="#built-in-deep-learning-models">Built-in deep learning models</a></li>
            <li><a href="#reference-use-cases">Reference use cases</a></li>
            <li><a href="#docker-images-and-builders">Docker images and builders</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="analytics-zoo"><font size="6">Analytics Zoo</font></h1>
<p><em>A unified analytics + AI platform for <strong>distributed TensorFlow, Keras and BigDL on Apache Spark</strong></em></p>
<hr />
<h2 id="what-is-analytics-zoo">What is Analytics Zoo?</h2>
<p><strong>Analytics Zoo</strong> provides a unified analytics + AI platform that seamlessly unites <em><strong>Spark, TensorFlow, Keras and BigDL</strong></em> programs into an integrated pipeline; the entire pipeline can then transparently scale out to a large Hadoop/Spark cluster for distributed training or inference. </p>
<ul>
<li><em>Data wrangling and analysis using PySpark</em></li>
<li><em>Deep learning model development using TensorFlow or Keras</em></li>
<li><em>Distributed training/inference on Spark and BigDL</em></li>
<li><em>All within a single unified pipeline and in a user-transparent fashion!</em></li>
</ul>
<p>In addition, Analytics Zoo also provides a rich set of analytics and AI support for the end-to-end pipeline, including:</p>
<ul>
<li><em>Easy-to-use abstractions and APIs</em> (e.g., transfer learning support, autograd operations, Spark DataFrame and ML pipeline support, online model serving API, etc.) </li>
<li><em>Common feature engineering operations</em> (for image, text, 3D image, etc.)</li>
<li><em>Built-in deep learning models</em> (e.g., object detection, image classification, text classification, recommendation, anomaly detection, text matching, sequence to sequence etc.)</li>
<li><em>Reference use cases</em> (e.g., anomaly detection, sentiment analysis, fraud detection, image similarity, etc.)</li>
</ul>
<h2 id="how-to-use-analytics-zoo">How to use Analytics Zoo?</h2>
<ul>
<li>
<p>To get started, please refer to the <a href="https://analytics-zoo.github.io/master/#PythonUserGuide/install/">Python install guide</a> or <a href="https://analytics-zoo.github.io/master/#ScalaUserGuide/install/">Scala install guide</a>.</p>
</li>
<li>
<p>For running distributed TensorFlow on Spark and BigDL, please refer to the quick start <a href="#distributed-tensorflow-and-keras-on-sparkbigdl">here</a> and the details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/tensorflow/">here</a>.</p>
</li>
<li>
<p>For more information, You may refer to the <a href="https://analytics-zoo.github.io/master/">Analytics Zoo document website</a>.</p>
</li>
<li>
<p>For additional questions and discussions, you can join the <a href="https://groups.google.com/forum/#!forum/bigdl-user-group">Google User Group</a> (or subscribe to the <a href="mailto:bigdl-user-group+subscribe@googlegroups.com">Mail List</a>).</p>
</li>
</ul>
<hr />
<h2 id="overview">Overview</h2>
<ul>
<li>
<p><a href="#distributed-tensorflow-and-keras-on-sparkbigdl">Distributed TensorFlow and Keras on Spark/BigDL</a></p>
<ul>
<li>Data wrangling and analysis using PySpark</li>
<li>Deep learning model development using TensorFlow or Keras</li>
<li>Distributed training/inference on Spark and BigDL</li>
<li>All within a single unified pipeline and in a user-transparent fashion!</li>
</ul>
</li>
<li>
<p><a href="#high-level-abstractions-and-apis">High level abstractions and APIs</a></p>
<ul>
<li><a href="#transfer-learning">Transfer learning</a>: customize pretrained model for <em>feature extraction or fine-tuning</em></li>
<li><a href="#autograd"><code>autograd</code></a>: build custom layer/loss using <em>auto differentiation operations</em> </li>
<li><a href="#nnframes"><code>nnframes</code></a>: native deep learning support in <em>Spark DataFrames and ML Pipelines</em></li>
<li><a href="#model-serving">Model serving</a>: productionize <em>model serving and inference</em> using <a href="https://en.wikipedia.org/wiki/Plain_old_Java_object">POJO</a> APIs</li>
</ul>
</li>
<li>
<p><a href="#built-in-deep-learning-models">Built-in deep learning models</a></p>
<ul>
<li><a href="#object-detection-api">Object detection API</a>: high-level API and pretrained models (e.g., SSD and Faster-RCNN) for <em>object detection</em></li>
<li><a href="#image-classification-api">Image classification API</a>: high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for <em>image classification</em></li>
<li><a href="#text-classification-api">Text classification API</a>: high-level API and pre-defined models (using CNN, LSTM, etc.) for <em>text classification</em></li>
<li><a href="#recommendation-api">Recommendation API</a>: high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for <em>recommendation</em></li>
<li><a href="#anomaly-detection-api">Anomaly detection API</a>: high-level API and pre-defined models based on LSTM for <em>anomaly detection</em></li>
<li><a href="#text-matching-api">Text matching API</a>: high-level API and pre-defined KNRM model for <em>text matching</em></li>
<li><a href="#sequence-to-sequence-api">Sequence to sequence API</a>: high-level API and pre-defined models for <em>sequence to sequence</em></li>
</ul>
</li>
<li>
<p><a href="#reference-use-cases">Reference use cases</a>: a collection of end-to-end <em>reference use cases</em> (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)</p>
</li>
<li>
<p><a href="#docker-images-and-builders">Docker images and builders</a></p>
<ul>
<li><a href="#analytics-zoo-in-docker">Analytics-Zoo in Docker</a></li>
<li><a href="#how-to-build-it">How to build it</a></li>
<li><a href="#how-to-use-the-image">How to use the image</a></li>
<li><a href="#notice">Notice</a></li>
</ul>
</li>
</ul>
<h2 id="distributed-tensorflow-and-keras-on-sparkbigdl"><em>Distributed TensorFlow and Keras on Spark/BigDL</em></h2>
<p>To make it easy to build and productionize the deep learning applications for Big Data, Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline (as illustrated below), which can then transparently run on a large-scale Hadoop/Spark clusters for distributed training and inference. (Please see more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/tensorflow/">here</a>).</p>
<p>1.Data wrangling and analysis using PySpark</p>
<pre><code class="python">   from zoo import init_nncontext
   from zoo.pipeline.api.net import TFDataset

   sc = init_nncontext()

   #Each record in the train_rdd consists of a list of NumPy ndrrays
   train_rdd = sc.parallelize(file_list)
     .map(lambda x: read_image_and_label(x))
     .map(lambda image_label: decode_to_ndarrays(image_label))

   #TFDataset represents a distributed set of elements,
   #in which each element contains one or more TensorFlow Tensor objects. 
   dataset = TFDataset.from_rdd(train_rdd,
                                names=[&quot;features&quot;, &quot;labels&quot;],
                                shapes=[[28, 28, 1], [1]],
                                types=[tf.float32, tf.int32],
                                batch_size=BATCH_SIZE)
</code></pre>

<p>2.Deep learning model development using TensorFlow</p>
<pre><code class="python">   import tensorflow as tf

   slim = tf.contrib.slim

   images, labels = dataset.tensors
   labels = tf.squeeze(labels)
   with slim.arg_scope(lenet.lenet_arg_scope()):
        logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)

   loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))
</code></pre>

<p>3.Distributed training on Spark and BigDL</p>
<pre><code class="python">   from zoo.pipeline.api.net import TFOptimizer
   from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary

   optimizer = TFOptimizer.from_loss(loss, Adam(1e-3))
   optimizer.set_train_summary(TrainSummary(&quot;/tmp/az_lenet&quot;, &quot;lenet&quot;))
   optimizer.optimize(end_trigger=MaxEpoch(5))
</code></pre>

<p>4.Alternatively, using Keras APIs for model development and distributed training</p>
<pre><code class="python">   from zoo.pipeline.api.keras.models import *
   from zoo.pipeline.api.keras.layers import *

   model = Sequential()
   model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))
   model.add(Convolution2D(6, 5, 5, activation=&quot;tanh&quot;, name=&quot;conv1_5x5&quot;))
   model.add(MaxPooling2D())
   model.add(Convolution2D(12, 5, 5, activation=&quot;tanh&quot;, name=&quot;conv2_5x5&quot;))
   model.add(MaxPooling2D())
   model.add(Flatten())
   model.add(Dense(100, activation=&quot;tanh&quot;, name=&quot;fc1&quot;))
   model.add(Dense(class_num, activation=&quot;softmax&quot;, name=&quot;fc2&quot;))

   model.compile(loss='sparse_categorical_crossentropy',
                 optimizer='adam')
   model.fit(train_rdd, batch_size=BATCH_SIZE, nb_epoch=5)
</code></pre>

<h2 id="high-level-abstractions-and-apis"><em>High level abstractions and APIs</em></h2>
<p>Analytics Zoo provides a set of easy-to-use, high level abstractions and APIs that natively transfer learning, autograd and custom layer/loss, Spark DataFrames and ML Pipelines, online model serving, etc. etc.</p>
<h3 id="transfer-learning"><em>Transfer learning</em></h3>
<p>Using the high level transfer learning APIs, you can easily customize pretrained models for <em>feature extraction or fine-tuning</em>. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/transferlearning/">here</a>)</p>
<p>1.Load an existing model (pretrained in Caffe)</p>
<pre><code class="python">   from zoo.pipeline.api.net import *
   full_model = Net.load_caffe(def_path, model_path)
</code></pre>

<p>2.Remove the last few layers</p>
<pre><code class="python">   # create a new model by removing layers after pool5/drop_7x7_s1
   model = full_model.new_graph([&quot;pool5/drop_7x7_s1&quot;])
</code></pre>

<p>3.Freeze the first few layers</p>
<pre><code class="python">   # freeze layers from input to pool4/3x3_s2 inclusive
   model.freeze_up_to([&quot;pool4/3x3_s2&quot;])
</code></pre>

<p>4.Add a few new layers</p>
<pre><code class="python">   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *
   inputs = Input(name=&quot;input&quot;, shape=(3, 224, 224))
   inception = model.to_keras()(inputs)
   flatten = Flatten()(inception)
   logits = Dense(2)(flatten)
   newModel = Model(inputs, logits)
</code></pre>

<h3 id="autograd"><em><code>autograd</code></em></h3>
<p><code>autograd</code> provides automatic differentiation for math operations, so that you can easily build your own <em>custom loss and layer</em> (in both Python and Scala), as illustrated below. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/autograd/">here</a>)</p>
<p>1.Define model using Keras-style API and <code>autograd</code> </p>
<pre><code class="python">   import zoo.pipeline.api.autograd as A
   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *

   input = Input(shape=[2, 20])
   features = TimeDistributed(layer=Dense(30))(input)
   f1 = features.index_select(1, 0)
   f2 = features.index_select(1, 1)
   diff = A.abs(f1 - f2)
   model = Model(input, diff)
</code></pre>

<p>2.Optionally define custom loss function using <code>autograd</code></p>
<pre><code class="python">   def mean_absolute_error(y_true, y_pred):
       return mean(abs(y_true - y_pred), axis=1)
</code></pre>

<p>3.Train model with <em>custom loss function</em></p>
<pre><code class="python">   model.compile(optimizer=SGD(), loss=mean_absolute_error)
   model.fit(x=..., y=...)
</code></pre>

<h3 id="nnframes"><em><code>nnframes</code></em></h3>
<p><code>nnframes</code> provides <em>native deep learning support in Spark DataFrames and ML Pipelines</em>, so that you can easily build complex deep learning pipelines in just a few lines, as illustrated below. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/nnframes/">here</a>)</p>
<p>1.Initialize <em>NNContext</em> and load images into <em>DataFrames</em> using <code>NNImageReader</code></p>
<pre><code class="python">   from zoo.common.nncontext import *
   from zoo.pipeline.nnframes import *
   from zoo.feature.image import *
   sc = init_nncontext()
   imageDF = NNImageReader.readImages(image_path, sc)
</code></pre>

<p>2.Process loaded data using <em>DataFrames transformations</em></p>
<pre><code class="python">   getName = udf(lambda row: ...)
   getLabel = udf(lambda name: ...)
   df = imageDF.withColumn(&quot;name&quot;, getName(col(&quot;image&quot;))).withColumn(&quot;label&quot;, getLabel(col('name')))
</code></pre>

<p>3.Processing image using built-in <em>feature engineering operations</em></p>
<pre><code>   transformer = RowToImageFeature() -&gt; ImageResize(64, 64) -&gt; ImageChannelNormalize(123.0, 117.0, 104.0) \
                 -&gt; ImageMatToTensor() -&gt; ImageFeatureToTensor())
</code></pre>

<p>4.Define model using <em>Keras-style APIs</em></p>
<pre><code class="python">   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *
   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \
                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))
</code></pre>

<p>5.Train model using <em>Spark ML Pipelines</em></p>
<pre><code class="python">   classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \
                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol(&quot;image&quot;).setCachingSample(False)
   nnModel = classifier.fit(df)
</code></pre>

<h3 id="model-serving"><em>Model Serving</em></h3>
<p>Using the <a href="https://en.wikipedia.org/wiki/Plain_old_Java_object">POJO</a> model serving API, you can productionize model serving and inference in any Java based frameworks (e.g., <a href="https://spring.io">Spring Framework</a>, Apache <a href="http://storm.apache.org">Storm</a>, <a href="http://kafka.apache.org">Kafka</a> or <a href="http://flink.apache.org">Flink</a>, etc.), as illustrated below:</p>
<pre><code class="python">import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;
import com.intel.analytics.zoo.pipeline.inference.JTensor;

public class TextClassificationModel extends AbstractInferenceModel {
    public TextClassificationModel() {
        super();
    }
}

TextClassificationModel model = new TextClassificationModel();
model.load(modelPath, weightPath);

List&lt;JTensor&gt; inputs = preprocess(...);
List&lt;List&lt;JTensor&gt;&gt; result = model.predict(inputs);
...
</code></pre>

<h2 id="built-in-deep-learning-models"><em>Built-in deep learning models</em></h2>
<p>Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as <em>object detection</em>, <em>image classification</em>, <em>text classification</em>, <em>recommendation</em>, <em>anomaly detection</em>, <em>text matching</em>, <em>sequence to sequence</em>,  etc.</p>
<h3 id="object-detection-api"><em>Object detection API</em></h3>
<p>Using <em>Analytics Zoo Object Detection API</em> (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/object-detection/">here</a>)</p>
<p>1.Download object detection models in Analytics Zoo</p>
<p>You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/object-detection/#download-link">detection model zoo</a>.</p>
<p>2.Use <em>Object Detection API</em> for off-the-shell inference</p>
<pre><code class="python">   from zoo.models.image.objectdetection import *
   model = ObjectDetector.load_model(model_path)
   image_set = ImageSet.read(img_path, sc)
   output = model.predict_image_set(image_set)
</code></pre>

<h3 id="image-classification-api"><em>Image classification API</em></h3>
<p>Using <em>Analytics Zoo Image Classification API</em> (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/image-classification/">here</a>)</p>
<p>1.Download image classification models in Analytics Zoo</p>
<p>You can download a collection of image classification models (pretrained on the ImageNet dataset) from <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/image-classification/#download-link">image classification model zoo</a>.</p>
<p>2.Use <em>Image classification API</em> for off-the-shell inference</p>
<pre><code class="python">   from zoo.models.image.imageclassification import *
   model = ImageClassifier.load_model(model_path)
   image_set = ImageSet.read(img_path, sc)
   output = model.predict_image_set(image_set)
</code></pre>

<h3 id="text-classification-api"><em>Text classification API</em></h3>
<p><em>Analytics Zoo Text Classification API</em> provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/text-classification/">here</a>)</p>
<h3 id="recommendation-api"><em>Recommendation API</em></h3>
<p><em>Analytics Zoo Recommendation API</em> provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/recommendation/">here</a>)</p>
<h3 id="anomaly-detection-api"><em>Anomaly detection API</em></h3>
<p><em>Analytics Zoo Anomaly Detection API</em> provides a set of pre-defined models based on LSTM to detect anomalies for time series data. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/anomaly-detection/">here</a>)</p>
<h3 id="text-matching-api"><em>Text matching API</em></h3>
<p><em>Analytics Zoo Text Matching API</em> provides pre-defined KNRM model for ranking or classification. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/text-matching/">here</a>)</p>
<h3 id="sequence-to-sequence-api"><em>Sequence to sequence API</em></h3>
<p><em>Analytics Zoo Sequence to Sequence API</em> provides a set of pre-defined models based on Recurrent neural network for sequence to sequence problems. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/seq2seq/">here</a>)</p>
<h2 id="reference-use-cases"><em>Reference use cases</em></h2>
<p>Analytics Zoo provides a collection of end-to-end reference use cases, including <em>time series anomaly detection</em>, <em>sentiment analysis</em>, <em>fraud detection</em>, <em>image similarity</em>, etc. (See more details <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/usercases-overview/">here</a>)</p>
<h2 id="docker-images-and-builders"><em>Docker images and builders</em></h2>
<h3 id="analytics-zoo-in-docker"><em>Analytics-Zoo in Docker</em></h3>
<p><strong>By default, the Analytics-Zoo image has installed below packages:</strong>
- git
- maven
- Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152)
- python 2.7.6
- pip
- numpy
- scipy
- pandas
- scikit-learn
- matplotlib
- seaborn
- jupyter
- wordcloud
- moviepy
- requests
- tensorflow_
- spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION})
- Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION})
- Analytics-Zoo source code (in /opt/work/analytics-zoo)</p>
<p><strong>The work dir for Analytics-Zoo is /opt/work.</strong>
- download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.
- start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a specified jupyter notebook.
- analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution.
- analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution.
- spark-${SPARK_VERSION} is the Spark home.
- analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.</p>
<h3 id="how-to-build-it"><em>How to build it</em></h3>
<p><strong>By default, you can build a Analytics-Zoo:default image with latest nightly-build Analytics-Zoo distributions:</strong></p>
<pre><code class="bash">sudo docker build --rm -t intelanalytics/analytics-zoo:default .
</code></pre>

<p><strong>If you need http and https proxy to build the image:</strong></p>
<pre><code class="bash">sudo docker build \
    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \
    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \
    --rm -t intelanalytics/analytics-zoo:default .
</code></pre>

<p><strong>You can also specify the ANALYTICS_ZOO_VERSION and SPARK_VERSION to build a specific Analytics-Zoo image:</strong></p>
<pre><code class="bash">sudo docker build \
    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \
    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \
    --build-arg ANALYTICS_ZOO_VERSION=0.3.0 \
    --build-arg BIGDL_VERSION=0.6.0 \
    --build-arg SPARK_VERSION=2.3.1 \
    --rm -t intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 .
</code></pre>

<h3 id="how-to-use-the-image"><em>How to use the image</em></h3>
<p><strong>To start a notebook directly with a specified port(e.g. 12345). You can view the notebook on http://[host-ip]:12345</strong></p>
<pre><code class="bash">sudo docker run -it --rm -p 12345:12345 \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    intelanalytics/analytics-zoo:default

sudo docker run -it --rm --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    intelanalytics/analytics-zoo:default

sudo docker run -it --rm -p 12345:12345 \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1

sudo docker run -it --rm --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1
</code></pre>

<p><strong>If you need http and https proxy in your environment:</strong></p>
<pre><code class="bash">sudo docker run -it --rm -p 12345:12345 \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    -e http_proxy=http://your-proxy-host:your-proxy-port \
    -e https_proxy=https://your-proxy-host:your-proxy-port \
    intelanalytics/analytics-zoo:default

sudo docker run -it --rm --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    -e http_proxy=http://your-proxy-host:your-proxy-port \
    -e https_proxy=https://your-proxy-host:your-proxy-port \
    intelanalytics/analytics-zoo:default

sudo docker run -it --rm -p 12345:12345 \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    -e http_proxy=http://your-proxy-host:your-proxy-port \
    -e https_proxy=https://your-proxy-host:your-proxy-port \
    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1

sudo docker run -it --rm --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    -e http_proxy=http://your-proxy-host:your-proxy-port \
    -e https_proxy=https://your-proxy-host:your-proxy-port \
    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1
</code></pre>

<p><strong>You can also start the container first</strong></p>
<pre><code class="bash">sudo docker run -it --rm --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;your-token&quot; \
    intelanalytics/analytics-zoo:default bash
</code></pre>

<p><strong>In the container, after setting proxy and ports, you can start the Notebook by:</strong></p>
<pre><code class="bash">/opt/work/start-notebook.sh
</code></pre>

<h3 id="notice"><em>Notice</em></h3>
<p><strong>If you need nightly build version of Analytics-Zoo, please pull the image form Dockerhub with:</strong></p>
<pre><code class="bash">sudo docker pull intelanalytics/analytics-zoo:latest
</code></pre>

<p><strong>Please follow the readme in each app folder to test the jupyter notebooks !!!</strong></p>
<p><strong>With 0.3+ version of Anaytics-Zoo Docker image, you can specify the runtime conf of spark</strong></p>
<pre><code class="bash">sudo docker run -itd --net=host \
    -e NotebookPort=12345 \
    -e NotebookToken=&quot;1234qwer&quot; \
    -e http_proxy=http://your-proxy-host:your-proxy-port  \
    -e https_proxy=https://your-proxy-host:your-proxy-port  \
    -e RUNTIME_DRIVER_CORES=4 \
    -e RUNTIME_DRIVER_MEMORY=20g \
    -e RUNTIME_EXECUTOR_CORES=4 \
    -e RUNTIME_EXECUTOR_MEMORY=20g \
    -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \
    intelanalytics/analytics-zoo:latest
</code></pre></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = ".",
                shortcuts = {"search": 83, "next": 78, "help": 191, "previous": 80};
        </script>
        <script src="js/base.js" defer></script>
        <script src="search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

<!--
MkDocs version : 1.0.4
Build Date UTC : 2019-06-03 00:34:14
-->
