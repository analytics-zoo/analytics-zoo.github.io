<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Working with Images - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Load Image", url: "#load-image", children: [
              {title: "Load to Data Frame", url: "#load-to-data-frame" },
              {title: "Load to ImageSet", url: "#load-to-imageset" },
          ]},
          {title: "Image Transformer", url: "#image-transformer", children: [
          ]},
          {title: "Build Image Transformation Pipeline", url: "#build-image-transformation-pipeline", children: [
          ]},
          {title: "Image Train", url: "#image-train", children: [
              {title: "Train with Image DataFrame", url: "#train-with-image-dataframe" },
              {title: "Train with ImageSet", url: "#train-with-imageset" },
          ]},
          {title: "Image Predict", url: "#image-predict", children: [
              {title: "Predict with Image DataFrame", url: "#predict-with-image-dataframe" },
              {title: "Predict with ImageSet", url: "#predict-with-imageset" },
          ]},
        ];

    </script>
    <script src="/js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Working with Images</strong></h1>
    <hr>
    <p>Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.</p>
<h2 id="load-image">Load Image</h2>
<p>Analytics Zoo provides APIs to read image to different formats:</p>
<h3 id="load-to-data-frame">Load to Data Frame</h3>
<p>Analytics Zoo can process image data as Spark Data Frame.
<code>NNImageReader</code> is the primary DataFrame-based image loading interface to read images into DataFrame.</p>
<p>Scala example:</p>
<pre><code class="scala">import com.intel.analytics.zoo.common.NNContext
import com.intel.analytics.zoo.pipeline.nnframes.NNImageReader

val sc = NNContext.initNNContext(&quot;app&quot;)
val imageDF1 = NNImageReader.readImages(&quot;/tmp&quot;, sc)
val imageDF2 = NNImageReader.readImages(&quot;/tmp/*.jpg&quot;, sc)
val imageDF3 = NNImageReader.readImages(&quot;/tmp/a.jpg, /tmp/b.jpg&quot;, sc)

</code></pre>

<p>Python:</p>
<pre><code class="python">from zoo.common.nncontext import *
from zoo.pipeline.nnframes import *

sc = init_nncontext(&quot;app&quot;)
imageDF1 = NNImageReader.readImages(&quot;/tmp&quot;, sc)
imageDF2 = NNImageReader.readImages(&quot;/tmp/*.jpg&quot;, sc)
imageDF3 = NNImageReader.readImages(&quot;/tmp/a.jpg, /tmp/b.jpg&quot;, sc)
</code></pre>

<p>The output DataFrame contains a sinlge column named "image". The schema of "image" column can be
accessed from <code>com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema</code>.
Each record in "image" column represents one image record, in the format of
Row(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,
and <code>data</code> holds the original file bytes for the image file. <code>mode</code> represents the OpenCV-compatible
type: CV_8UC3, CV_8UC1 in most cases.</p>
<pre><code class="scala">  val byteSchema = StructType(
    StructField(&quot;origin&quot;, StringType, true) ::
      StructField(&quot;height&quot;, IntegerType, false) ::
      StructField(&quot;width&quot;, IntegerType, false) ::
      StructField(&quot;nChannels&quot;, IntegerType, false) ::
      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases
      StructField(&quot;mode&quot;, IntegerType, false) ::
      // Bytes in OpenCV-compatible order: row-wise BGR in most cases
      StructField(&quot;data&quot;, BinaryType, false) :: Nil)
</code></pre>

<p>After loading the image, user can compose the preprocess steps with the <code>Preprocessing</code> defined
in <code>com.intel.analytics.zoo.feature.image</code>.</p>
<h3 id="load-to-imageset">Load to ImageSet</h3>
<p><code>ImageSet</code> is a collection of <code>ImageFeature</code>. It can be a <code>DistributedImageSet</code> for distributed image RDD or
 <code>LocalImageSet</code> for local image array.
You can read image data as <code>ImageSet</code> from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">// create LocalImageSet from an image folder
val localImageSet = ImageSet.read(&quot;/tmp/image/&quot;)

// create DistributedImageSet from an image folder
val distributedImageSet2 = ImageSet.read(&quot;/tmp/image/&quot;, sc, 2)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python"># create LocalImageSet from an image folder
local_image_frame2 = ImageSet.read(&quot;/tmp/image/&quot;)

# create DistributedImageSet from an image folder
distributed_image_frame = ImageSet.read(&quot;/tmp/image/&quot;, sc, 2)
</code></pre>

<h2 id="image-transformer">Image Transformer</h2>
<p>Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV:</p>
<ul>
<li><code>ImageBrightness</code>: Adjust the image brightness.</li>
<li><code>ImageHue</code>: Adjust the image hue.</li>
<li><code>ImageSaturation</code>: Adjust the image Saturation.</li>
<li><code>ImageContrast</code>: Adjust the image Contrast.</li>
<li><code>ImageChannelOrder</code>: Random change the channel order of an image</li>
<li><code>ImageColorJitter</code>: Random adjust brightness, contrast, hue, saturation</li>
<li><code>ImageResize</code>: Resize image</li>
<li><code>ImageAspectScale</code>: Resize the image, keep the aspect ratio. scale according to the short edge</li>
<li><code>ImageRandomAspectScale</code>: Resize the image by randomly choosing a scale</li>
<li><code>ImageChannelNormalize</code>: Image channel normalize</li>
<li><code>ImagePixelNormalizer</code>: Pixel level normalizer</li>
<li><code>ImageCenterCrop</code>: Crop a <code>cropWidth</code> x <code>cropHeight</code> patch from center of image.</li>
<li><code>ImageRandomCrop</code>: Random crop a <code>cropWidth</code> x <code>cropHeight</code> patch from an image.</li>
<li><code>ImageFixedCrop</code>: Crop a fixed area of image</li>
<li><code>ImageDetectionCrop</code>: Crop from object detections, each image should has a tensor detection,</li>
<li><code>ImageExpand</code>: Expand image, fill the blank part with the meanR, meanG, meanB</li>
<li><code>ImageFiller</code>: Fill part of image with certain pixel value</li>
<li><code>ImageHFlip</code>: Flip the image horizontally</li>
<li><code>ImageRandomTransformer</code>: It is a wrapper for transformers to control the transform probability</li>
<li><code>ImageBytesToMat</code>: Transform byte array(original image file in byte) to OpenCVMat</li>
<li><code>ImageMatToFloats</code>: Transform OpenCVMat to float array, note that in this transformer, the mat is released.</li>
<li><code>ImageMatToTensor</code>: Transform opencv mat to tensor, note that in this transformer, the mat is released.</li>
<li><code>ImageSetToSample</code>: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.</li>
</ul>
<p>More examples can be found <a href="../../APIGuide/FeatureEngineering/image/">here</a></p>
<p>You can also define your own Transformer by extending <code>ImageProcessing</code>,
and override the function <code>transformMat</code> to do the actual transformation to <code>ImageFeature</code>.</p>
<h2 id="build-image-transformation-pipeline"><strong>Build Image Transformation Pipeline</strong></h2>
<p>You can easily build the image transformation pipeline by chaining transformers.</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.numeric.NumericFloat
import com.intel.analytics.zoo.feature.image._


val imgAug = ImageBytesToMat() -&gt; ImageResize(256, 256)-&gt; ImageCenterCrop(224, 224) -&gt;
             ImageChannelNormalize(123, 117, 104) -&gt;
             ImageMatToTensor[Float]() -&gt;
             ImageSetToSample[Float]()
</code></pre>

<p>In the above example, the transformations will perform sequentially.</p>
<p>Assume you have an ImageSet containing original bytes array,</p>
<ul>
<li>
<p><code>ImageBytesToMat</code> will transform the bytes array to <code>OpenCVMat</code>.</p>
</li>
<li>
<p><code>ImageColorJitter</code>, <code>ImageExpand</code>, <code>ImageResize</code>, <code>ImageHFlip</code> and <code>ImageChannelNormalize</code> will transform over <code>OpenCVMat</code>,
note that <code>OpenCVMat</code> is overwrite by default.</p>
</li>
<li>
<p><code>ImageMatToTensor</code> transform <code>OpenCVMat</code> to <code>Tensor</code>, and <code>OpenCVMat</code> is released in this step.</p>
</li>
<li>
<p><code>ImageSetToSample</code> transform the tensors that map inputKeys and targetKeys to sample,
which can be used by the following prediction or training tasks.</p>
</li>
</ul>
<p><strong>Python example:</strong></p>
<pre><code class="python">from zoo.feature.image.imagePreprocessing import *

img_aug = ChainedPreprocessing([ImageBytesToMat(),
      ImageColorJitter(),
      ImageExpand(),
      ImageResize(300, 300, -1),
      ImageHFlip(),
      ImageChannelNormalize(123.0, 117.0, 104.0),
      ImageMatToTensor(),
      ImageSetToSample()])
</code></pre>

<h2 id="image-train"><strong>Image Train</strong></h2>
<h3 id="train-with-image-dataframe">Train with Image DataFrame</h3>
<p>You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call <code>fit</code> method to let Analytics Zoo train the model</p>
<p>For detail APIs, please refer to: <a href="../../APIGuide/PipelineAPI/nnframes/">NNFrames</a></p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">val batchsize = 128
val nEpochs = 10
val featureTransformer = RowToImageFeature() -&gt; ImageResize(256, 256) -&gt;
                                   ImageCenterCrop(224, 224) -&gt;
                                   ImageChannelNormalize(123, 117, 104) -&gt;
                                   ImageMatToTensor() -&gt;
                                   ImageFeatureToTensor()
val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)
        .setFeaturesCol(&quot;image&quot;)
        .setLearningRate(0.003)
        .setBatchSize(batchsize)
        .setMaxEpoch(nEpochs)
        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)
val trainedModel = classifier.fit(trainDf)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">batchsize = 128
nEpochs = 10
featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),
                                   ImageCenterCrop(224, 224),
                                   ImageChannelNormalize(123, 117, 104),
                                   ImageMatToTensor(),
                                   ImageFeatureToTensor()])
classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\
        .setFeaturesCol(&quot;image&quot;)\
        .setLearningRate(0.003)\
        .setBatchSize(batchsize)\
        .setMaxEpoch(nEpochs)\
        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)
trainedModel = classifier.fit(trainDf)
</code></pre>

<h3 id="train-with-imageset">Train with ImageSet</h3>
<p>You can train Zoo Keras model with ImageSet. Just call <code>fit</code> method to let Analytics Zoo train the model.</p>
<p><strong>Python example:</strong></p>
<pre><code class="python">from zoo.common.nncontext import *
from zoo.feature.common import *
from zoo.feature.image.imagePreprocessing import *
from zoo.pipeline.api.keras.layers import Dense, Input, Flatten
from zoo.pipeline.api.keras.models import *
from zoo.pipeline.api.net import *
from bigdl.optim.optimizer import *

sc = init_nncontext(&quot;train keras&quot;)
img_path=&quot;/tmp/image&quot;
image_set = ImageSet.read(img_path,sc, min_partitions=1)
transformer = ChainedPreprocessing(
        [ImageResize(256, 256), ImageCenterCrop(224, 224),
         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),
         ImageSetToSample()])
image_data = transformer(image_set)
labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])
label_rdd = sc.parallelize(labels, 1)
samples = image_data.get_image().zip(label_rdd).map(
        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))
# create model
model_path=&quot;/tmp/bigdl_inception-v1_imagenet_0.4.0.model&quot;
full_model = Net.load_bigdl(model_path)
# create a new model by remove layers after pool5/drop_7x7_s1
model = full_model.new_graph([&quot;pool5/drop_7x7_s1&quot;])
# freeze layers from input to pool4/3x3_s2 inclusive
model.freeze_up_to([&quot;pool4/3x3_s2&quot;])

inputNode = Input(name=&quot;input&quot;, shape=(3, 224, 224))
inception = model.to_keras()(inputNode)
flatten = Flatten()(inception)
logits = Dense(2)(flatten)
lrModel = Model(inputNode, logits)

batchsize = 4
nEpochs = 10
lrModel.compile(optimizer=Adam(learningrate=1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)
</code></pre>

<h2 id="image-predict"><strong>Image Predict</strong></h2>
<h3 id="predict-with-image-dataframe">Predict with Image DataFrame</h3>
<p>After training with <em>NNEstimator/NNCLassifier</em>, you'll get a trained <em>NNModel/NNClassifierModel</em> . You can call <code>transform</code> to predict Image DataFrame with this <em>NNModel/NNClassifierModel</em> . Or you can load pre-trained <em>Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow</em>  model and create <em>NNModel/NNClassifierModel</em> with this model. Then call to <code>transform</code> to Image DataFrame.</p>
<p>After prediction, there is a new column <code>prediction</code> in the prediction image dataframe.</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala"> val batchsize = 128
 val nEpochs = 10
 val featureTransformer = RowToImageFeature() -&gt; ImageResize(256, 256) -&gt;
                                    ImageCenterCrop(224, 224) -&gt;
                                    ImageChannelNormalize(123, 117, 104) -&gt;
                                    ImageMatToTensor() -&gt;
                                    ImageFeatureToTensor()
 val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)
         .setFeaturesCol(&quot;image&quot;)
         .setLearningRate(0.003)
         .setBatchSize(batchsize)
         .setMaxEpoch(nEpochs)
         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)
 val trainedModel = classifier.fit(trainDf)
 // predict with trained model
 val predictions = trainedModel.transform(testDf)
 predictions.select(col(&quot;image&quot;), col(&quot;label&quot;), col(&quot;prediction&quot;)).show(false)

 // predict with loaded pre-trained model
 val model = Module.loadModule[Float](modelPath)
 val dlmodel = NNClassifierModel(model, featureTransformer)
         .setBatchSize(batchsize)
         .setFeaturesCol(&quot;image&quot;)
         .setPredictionCol(&quot;prediction&quot;) 
 val resultDF = dlmodel.transform(testDf)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python"> batchsize = 128
 nEpochs = 10
 featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),
                                    ImageCenterCrop(224, 224),
                                    ImageChannelNormalize(123, 117, 104),
                                    ImageMatToTensor(),
                                    ImageFeatureToTensor()])
 classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\
         .setFeaturesCol(&quot;image&quot;)\
         .setLearningRate(0.003)\
         .setBatchSize(batchsize)\
         .setMaxEpoch(nEpochs)\
         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)
trainedModel = classifier.fit(trainDf)
# predict with trained model
predictions = trainedModel.transform(testDf)
predictions.select(&quot;image&quot;, &quot;label&quot;,&quot;prediction&quot;).show(False)

# predict with loaded pre-trained model
model = Model.loadModel(model_path)
dlmodel = NNClassifierModel(model, featureTransformer)\
         .setBatchSize(batchsize)\
         .setFeaturesCol(&quot;image&quot;)\
         .setPredictionCol(&quot;prediction&quot;) 
resultDF = dlmodel.transform(testDf)
</code></pre>

<h3 id="predict-with-imageset">Predict with ImageSet</h3>
<p>After training Zoo Keras model, you can call <code>predict</code> to predict ImageSet.
Or you can load pre-trained Analytics-Zoo/BigDL model. Then call to <code>predictImageSet</code> to predict ImageSet.</p>
<h4 id="predict-with-trained-zoo-keras-model">Predict with trained Zoo Keras Model</h4>
<p><strong>Python example:</strong></p>
<pre><code class="python">from zoo.common.nncontext import *
from zoo.feature.common import *
from zoo.feature.image.imagePreprocessing import *
from zoo.pipeline.api.keras.layers import Dense, Input, Flatten
from zoo.pipeline.api.keras.models import *
from zoo.pipeline.api.net import *
from bigdl.optim.optimizer import *

sc = init_nncontext(&quot;train keras&quot;)
img_path=&quot;/tmp/image&quot;
image_set = ImageSet.read(img_path,sc, min_partitions=1)
transformer = ChainedPreprocessing(
        [ImageResize(256, 256), ImageCenterCrop(224, 224),
         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),
         ImageSetToSample()])
image_data = transformer(image_set)
labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])
label_rdd = sc.parallelize(labels, 1)
samples = image_data.get_image().zip(label_rdd).map(
        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))
# create model
model_path=&quot;/tmp/bigdl_inception-v1_imagenet_0.4.0.model&quot;
full_model = Net.load_bigdl(model_path)
# create a new model by remove layers after pool5/drop_7x7_s1
model = full_model.new_graph([&quot;pool5/drop_7x7_s1&quot;])
# freeze layers from input to pool4/3x3_s2 inclusive
model.freeze_up_to([&quot;pool4/3x3_s2&quot;])

inputNode = Input(name=&quot;input&quot;, shape=(3, 224, 224))
inception = model.to_keras()(inputNode)
flatten = Flatten()(inception)
logits = Dense(2)(flatten)
lrModel = Model(inputNode, logits)

batchsize = 4
nEpochs = 10
lrModel.compile(optimizer=Adam(learningrate=1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
lrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)
prediction = lrModel.predict(samples)
result = prediction.collect()
</code></pre>

<h4 id="predict-with-loaded-model">Predict with loaded Model</h4>
<p>You can load pre-trained Analytics-Zoo/BigDL model. Then call to <code>predictImageSet</code> to predict ImageSet.</p>
<p>For details, you can check guide of <a href="../image-classification/">image classificaion</a> or <a href="../object-detection/">object detection</a></p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>