<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Convolutional Layers - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Convolution1D", url: "#convolution1d", children: [
          ]},
          {title: "LocallyConnected1D", url: "#locallyconnected1d", children: [
          ]},
          {title: "UpSampling2D", url: "#upsampling2d", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Convolutional Layers</strong></h1>
    <hr>
    <h2 id="convolution1d"><strong>Convolution1D</strong></h2>
<p>Applies convolution operator for filtering neighborhoods of 1-D inputs.</p>
<p>You can also use <code>Conv1D</code> as an alias of this layer.</p>
<p>The input of this layer should be 3D.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">Convolution1D(nbFilter, filterLength, init = &quot;glorot_uniform&quot;, activation = null, borderMode = &quot;valid&quot;, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">Convolution1D(nb_filter, filter_length, init=&quot;glorot_uniform&quot;, activation=None, border_mode=&quot;valid&quot;, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)
</code></pre>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>nbFilter</code>: Number of convolution filters to use.</li>
<li><code>filterLength</code>: The extension (spatial or temporal) of each filter.</li>
<li><code>init</code>: String representation of the initialization method for the weights of the layer. See <a href="../initialization/#available-initialization-methods">here</a> for available initialization strings. Default is 'glorot_uniform'.</li>
<li><code>activation</code>: String representation of the activation function to use. See <a href="../activation/#available-activations">here</a> for available activation strings. Default is null.</li>
<li><code>borderMode</code>: Either 'valid' or 'same'. Default is 'valid'.</li>
<li><code>subsampleLength</code>: Factor by which to subsample output. Integer. Default is 1.</li>
<li><code>wRegularizer</code>: An instance of <a href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.</li>
<li><code>bRegularizer</code>: An instance of <a href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the bias. Default is null.</li>
<li><code>bias</code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</li>
<li><code>inputShape</code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a href="../../keras-api-scala/#shape"><code>Shape</code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D
import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential
import com.intel.analytics.bigdl.utils.Shape
import com.intel.analytics.bigdl.tensor.Tensor

val model = Sequential[Float]()
model.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))
val input = Tensor[Float](2, 3, 4).randn()
val output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="scala">input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
-1.4253887  -0.044403594    -1.1169672  -0.19499049
0.85463065  0.6665206       0.21340805  0.56255895
1.1126599   -0.3423326      0.09643264  -0.34345046

(2,.,.) =
-0.04046587 -0.2710401      0.10183265  1.4503858
1.0639644   1.5317003       -0.18313104 -0.7098296
0.612399    1.7357533       0.4641411   0.13530721

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</code></pre>

<p>Output is:</p>
<pre><code class="scala">output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852

(2,.,.) =
0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">import numpy as np
from zoo.pipeline.api.keras.layers import Convolution1D
from zoo.pipeline.api.keras.models import Sequential

model = Sequential()
model.add(Convolution1D(8, 3, input_shape=(3, 4)))
input = np.random.random([2, 3, 4])
output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="python">[[[0.06092268 0.0508438  0.47256153 0.80004565]
  [0.48706905 0.65704781 0.04297214 0.42288264]
  [0.92286158 0.85394381 0.46423248 0.87896669]]

 [[0.216527   0.13880484 0.93482372 0.44812419]
  [0.95553331 0.27084259 0.58913626 0.01879454]
  [0.6656435  0.1985877  0.94133745 0.57504128]]]
</code></pre>

<p>Output is</p>
<pre><code class="python">[[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]

 [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]
</code></pre>

<hr />
<h2 id="locallyconnected1d"><strong>LocallyConnected1D</strong></h2>
<p>Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</p>
<p>Border mode currently supported for this layer is 'valid'.</p>
<p>The input of this layer should be 3D.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode=&quot;valid&quot;, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)
</code></pre>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>nbFilter</code>: Dimensionality of the output.</li>
<li><code>filterLength</code>: The extension (spatial or temporal) of each filter.</li>
<li><code>activation</code>: String representation of the activation function to use. See <a href="../activation/#available-activations">here</a> for available activation strings. Default is null.</li>
<li><code>subsampleLength</code>: Integer. Factor by which to subsample output.</li>
<li><code>wRegularizer</code>: An instance of <a href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.</li>
<li><code>bRegularizer</code>: An instance of <a href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the bias. Default is null.</li>
<li><code>bias</code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</li>
<li><code>inputShape</code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a href="../../keras-api-scala/#shape"><code>Shape</code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D
import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential
import com.intel.analytics.bigdl.utils.Shape
import com.intel.analytics.bigdl.tensor.Tensor

val model = Sequential[Float]()
model.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))
val input = Tensor[Float](2, 3, 4).randn()
val output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="scala">input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
1.6755046   0.47923228  -0.41470557 -1.4644535
-1.580751   -0.36924785 -1.1507624  0.20131736
-0.4983051  -2.0898817  0.1623063   0.8118141

(2,.,.) =
1.5955191   -1.1017833  1.6614468   1.7959124
1.1084127   0.528379    -1.114553   -1.030853
0.37758648  -2.5828059  1.0172523   -1.6773314

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</code></pre>

<p>Output is:</p>
<pre><code class="scala">output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563

(2,.,.) =
-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">import numpy as np
from zoo.pipeline.api.keras.layers import LocallyConnected1D
from zoo.pipeline.api.keras.models import Sequential

model = Sequential()
model.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))
input = np.random.random([2, 3, 4])
output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="python">[[[0.67992353 0.88287213 0.98861104 0.17401607]
  [0.23660068 0.02779148 0.52982599 0.19876749]
  [0.38880073 0.6498778  0.81532701 0.91719509]]

 [[0.30532677 0.1574227  0.40535271 0.03174637]
  [0.37303714 0.27821415 0.02314422 0.64516966]
  [0.74813923 0.9884225  0.40667151 0.21894944]]]
</code></pre>

<p>Output is</p>
<pre><code class="python">[[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]

 [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]
</code></pre>

<hr />
<h2 id="upsampling2d"><strong>UpSampling2D</strong></h2>
<p>UpSampling layer for 2D inputs.</p>
<p>Repeats the rows and columns of the data by the specified size.</p>
<p>The input of this layer should be 4D.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">UpSampling2D(size = (2, 2), dimOrdering = &quot;th&quot;, inputShape = null)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">UpSampling2D(size=(2, 2), dim_ordering=&quot;th&quot;, input_shape=None, name=None)
</code></pre>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>size</code>: Length 2. UpSampling factors for rows and columns. Default is (2, 2).</li>
<li><code>dimOrdering</code>: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.</li>
<li><code>inputShape</code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a href="../../keras-api-scala/#shape"><code>Shape</code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D
import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential
import com.intel.analytics.bigdl.utils.Shape
import com.intel.analytics.bigdl.tensor.Tensor

val model = Sequential[Float]()
model.add(UpSampling2D((2, 2), inputShape = Shape(2, 2, 2)))
val input = Tensor[Float](1, 2, 2, 2).randn()
val output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="scala">input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-0.07563081 -1.921836
-1.7368479  0.1043008

(1,2,.,.) =
-1.825055   -0.096810855
-0.89331573 0.72812295

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]
</code></pre>

<p>Output is:</p>
<pre><code class="scala">output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
-0.07563081 -0.07563081  -1.921836   -1.921836
-0.07563081 -0.07563081  -1.921836   -1.921836
-1.7368479  -1.7368479   0.1043008   0.1043008
-1.7368479  -1.7368479   0.1043008   0.1043008

(1,2,.,.) =
-1.825055    -1.825055    -0.096810855  -0.096810855
-1.825055    -1.825055    -0.096810855  -0.096810855
-0.89331573  -0.89331573  0.72812295    0.72812295
-0.89331573  -0.89331573  0.72812295    0.72812295

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">import numpy as np
from zoo.pipeline.api.keras.layers import UpSampling2D
from zoo.pipeline.api.keras.models import Sequential

model = Sequential()
model.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))
input = np.random.random([1, 2, 2, 2])
output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="python">[[[[0.55660253 0.21984387]
   [0.36271854 0.57464162]]

  [[0.55307278 0.33007518]
   [0.31527167 0.87789644]]]]
</code></pre>

<p>Output is</p>
<pre><code class="python">[[[[0.55660254 0.55660254 0.21984388 0.21984388]
   [0.55660254 0.55660254 0.21984388 0.21984388]
   [0.36271855 0.36271855 0.57464164 0.57464164]
   [0.36271855 0.36271855 0.57464164 0.57464164]]

  [[0.55307275 0.55307275 0.33007517 0.33007517]
   [0.55307275 0.55307275 0.33007517 0.33007517]
   [0.31527168 0.31527168 0.8778964  0.8778964 ]
   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]
</code></pre>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>