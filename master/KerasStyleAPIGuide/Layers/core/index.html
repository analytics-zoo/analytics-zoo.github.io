<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Core Layers - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "SparseDense", url: "#sparsedense", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Core Layers</strong></h1>
    <hr>
    <h2 id="sparsedense"><strong>SparseDense</strong></h2>
<p>SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:
firstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward
gradient to next layer in the backpropagation by default, as the gradInput of SparseDense is
useless and very big in most cases.</p>
<p>But, considering model like Wide&amp;Deep, we provide backwardStart and backwardLength to backward
part of the gradient to next layer.</p>
<p>The most common input is 2D.</p>
<p>When you use this layer as the first layer of a model, you need to provide the argument
inputShape (a Single Shape, does not include the batch dimension).</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">SparseDense(outputDim, init = &quot;glorot_uniform&quot;, activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">SparseDense(output_dim, init=&quot;glorot_uniform&quot;, activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None)
</code></pre>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>outputDim</code>: The size of the output dimension.</li>
<li><code>init</code>: String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'.</li>
<li><code>activation</code>: String representation of the activation function to use. Default is null.</li>
<li><code>wRegularizer</code>: An instance of [Regularizer], applied to the input weights matrices. Default is null.</li>
<li><code>bRegularizer</code>: An instance of [Regularizer], applied to the bias. Default is null.</li>
<li><code>bias</code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</li>
<li><code>backwardStart</code>: Backward start index, counting from 1.</li>
<li><code>backwardLength</code>: Backward length.</li>
<li><code>inputShape</code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <code>Shape</code> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</li>
<li><code>name</code>: String to set the name of the layer. If not specified, its name will by default to be a generated string.</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense
import com.intel.analytics.bigdl.utils.Shape
import com.intel.analytics.bigdl.tensor.Tensor

val layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4))
layer.build(Shape(-1, 2, 4))
val input = Tensor[Float](Array(2, 4)).rand()
input.setValue(1, 1, 1f)
input.setValue(2, 3, 3f)
val sparseInput = Tensor.sparse(input)
val output = layer.forward(sparseInput)
</code></pre>

<p>Input is:</p>
<pre><code class="scala">input: 
(0, 0) : 1.0
(0, 1) : 0.2992794
(0, 2) : 0.11227019
(0, 3) : 0.722947
(1, 0) : 0.6147614
(1, 1) : 0.4288646
(1, 2) : 3.0
(1, 3) : 0.7749917
[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]
</code></pre>

<p>Output is:</p>
<pre><code class="scala">output: 
0.053516    0.33429605  0.22587383  -0.8998945  0.24308181  
0.76745665  -1.614114   0.5381658   -2.2226436  -0.15573677 
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">import numpy as np
from zoo.pipeline.api.keras.layers import SparseDense
from zoo.pipeline.api.keras.models import Sequential
from bigdl.util.common import JTensor

model = Sequential()
model.add(SparseDense(output_dim=2, input_shape=(3, 4)))
input = JTensor.sparse(
    a_ndarray=np.array([1, 3, 2, 4]),
    i_ndarray = np.array([[0, 0, 1, 2],
             [0, 3, 2, 1]]),
    shape = np.array([3, 4])
)
output = model.forward(input)
</code></pre>

<p>Input is:</p>
<pre><code class="python">JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]
 [0 3 2 1]], float
</code></pre>

<p>Output is
```python
[[ 1.57136     2.29596   ]
 [ 0.5791738  -1.6598101 ]
 [ 2.331141   -0.84687066]]</p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>