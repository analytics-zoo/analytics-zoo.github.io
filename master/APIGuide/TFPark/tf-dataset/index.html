<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>TFDataset - Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "TFDataset", url: "#tfdataset", children: [
              {title: "Methods", url: "#methods" },
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'analytics-zoo.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>TFDataset</strong></h1>
    <hr>
    <h1 id="tfdataset">TFDataset</h1>
<p>TFDatset represents a distributed collection of elements to be feed into TensorFlow graph.
TFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing
the tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the
TFOptimizer or TFPredictor.</p>
<p><strong>Remarks</strong>:</p>
<ul>
<li>You need to install <strong>tensorflow==1.10</strong> on your driver node.</li>
<li>Your operating system (OS) is required to be one of the following 64-bit systems:
<strong>Ubuntu 16.04 or later</strong> and <strong>macOS 10.12.6 or later</strong>.</li>
<li>To run on other systems, you need to manually compile the TensorFlow source code. Instructions can
  be found <a href="https://github.com/tensorflow/tensorflow/tree/v1.10.0/tensorflow/java">here</a>.</li>
</ul>
<h2 id="methods">Methods</h2>
<h3 id="from_rdd"><strong>from_rdd</strong></h3>
<p>Create a TFDataset from a rdd.</p>
<p>For training and evaluation, both <code>features</code> and <code>labels</code> arguments should be specified.
The element of the rdd should be a tuple of two, (features, labels), each has the
same structure of numpy.ndarrays of the argument <code>features</code>, <code>labels</code>.</p>
<p>E.g. if <code>features</code> is [(tf.float32, [10]), (tf.float32, [20])],
and <code>labels</code> is {"label1":(tf.float32, [10]), "label2": (tf.float32, [20])}
then a valid element of the rdd could be</p>
<pre><code>    (
    [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))],
     {"label1": np.zeros(dtype=float, shape=(10,)),
      "label2":np.zeros(dtype=float, shape=(10,))))}
    )
</code></pre>
<p>If <code>labels</code> is not specified,
then the above element should be changed to</p>
<pre><code>    [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))]
</code></pre>
<p>For inference, <code>labels</code> can be not specified.
The element of the rdd should be some ndarrays of the same structure of the <code>features</code>
argument.</p>
<p>A note on the legacy api: if you are using <code>names</code>, <code>shapes</code>, <code>types</code> arguments,
each element of the rdd should be a list of numpy.ndarray.</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_rdd(rdd, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_rdd=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>rdd</strong>: a rdd containing the numpy.ndarrays to be used 
           for training/evaluation/inference</li>
<li>
<p><strong>features</strong>: the structure of input features, should one the following:</p>
<ul>
<li>a tuple (dtype, shape), e.g. (tf.float32, [28, 28, 1]) </li>
<li>a list of such tuple [(dtype1, shape1), (dtype2, shape2)],
                 e.g. [(tf.float32, [10]), (tf.float32, [20])],</li>
<li>a dict of such tuple, mapping string names to tuple {"name": (dtype, shape},
                 e.g. {"input1":(tf.float32, [10]), "input2": (tf.float32, [20])}</li>
</ul>
</li>
<li>
<p><strong>labels</strong>: the structure of input labels, format is the same as features</p>
</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>val_rdd</strong>: validation data with the same structure of rdd</li>
</ul>
<h3 id="from_ndarrays"><strong>from_ndarrays</strong></h3>
<p>Create a TFDataset from a nested structure of numpy ndarrays. Each element
in the resulting TFDataset has the same structure of the argument tensors and
is created by indexing on the first dimension of each ndarray in the tensors
argument.</p>
<p>This method is equivalent to sc.parallize the tensors and call TFDataset.from_rdd</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_ndarrays(tensors, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_tensors=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>tensors</strong>: the numpy ndarrays</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>val_tensors</strong>: the numpy ndarrays used for validation during training</li>
</ul>
<h3 id="from_image_set"><strong>from_image_set</strong></h3>
<p>Create a TFDataset from a ImagetSet. Each ImageFeature in the ImageSet should
already has the "sample" field, i.e. the result of ImageSetToSample transformer</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_image_set(image_set, image, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>image_set</strong>: the ImageSet used to create this TFDataset</li>
<li><strong>image</strong>: a tuple of two, the first element is the type of image, the second element
        is the shape of this element, i.e. (tf.float32, [224, 224, 3]))</li>
<li><strong>label</strong>: a tuple of two, the first element is the type of label, the second element
        is the shape of this element, i.e. (tf.int32, [1]))</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>validation_image_set</strong>: the ImageSet used for validation during training</li>
</ul>
<h3 id="from_text_set"><strong>from_text_set</strong></h3>
<p>Create a TFDataset from a TextSet. The TextSet must be transformed to Sample, i.e.
the result of TextFeatureToSample transformer.</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_text_set(text_set, text, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>text_set</strong>: the TextSet used to create this TFDataset</li>
<li><strong>text</strong>: a tuple of two, the first element is the type of this input feature,
        the second element is the shape of this element, i.e. (tf.float32, [10, 100, 4])).
        text can also be nested structure of this tuple of two.</li>
<li><strong>label</strong>: a tuple of two, the first element is the type of label, the second element
        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of
        this tuple of two.</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>validation_image_set</strong>: The TextSet used for validation during training</li>
</ul>
<h3 id="from_feature_set"><strong>from_feature_set</strong></h3>
<p>Create a TFDataset from a FeatureSet. Currently, the element in this Feature set must be a
ImageFeature that has a sample field, i.e. the result of ImageSetToSample transformer</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_feature_set(dataset, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>dataset</strong>: the feature set used to create this TFDataset</li>
<li><strong>features</strong>: a tuple of two, the first element is the type of this input feature,
        the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])).
        text can also be nested structure of this tuple of two.</li>
<li><strong>labels</strong>: a tuple of two, the first element is the type of label, the second element
        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of
        this tuple of two.</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>validation_dataset</strong>: The FeatureSet used for validation during training</li>
</ul>
<h3 id="from_string_rdd"><strong>from_string_rdd</strong></h3>
<p>Create a TFDataset from a RDD of strings. Each element is the RDD should be a single string.
The returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor
is tf.string, and the shape is (None,). The returning don't have label_tensors. If the
dataset is used for training, the label should be encoded in the string.</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_string_rdd(string_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_string_rdd=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>string_rdd</strong>: the RDD of strings</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>validation_string_rdd</strong>: the RDD of strings to be used in validation</li>
</ul>
<h3 id="from_bytes_rdd"><strong>from_bytes_rdd</strong></h3>
<p>Create a TFDataset from a RDD of bytes. Each element is the RDD should be a bytes object.
The returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor
is tf.string, and the shape is (None,). The returning don't have label_tensors. If the
dataset is used for training, the label should be encoded in the bytes.</p>
<p><strong>Python</strong></p>
<pre><code class="python">from_bytes_rdd(bytes_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_bytes_rdd=None)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>bytes_rdd</strong>: the RDD of bytes</li>
<li><strong>batch_size</strong>: the batch size, used for training, should be a multiple of
        total core num</li>
<li><strong>batch_per_thread</strong>: the batch size for each thread, used for inference or evaluation</li>
<li><strong>hard_code_batch_size</strong>: whether to hard code the batch_size into tensorflow graph,
        if True, the static size of the first dimension of the resulting tensors is
        batch_size/total_core_num (training) or batch_per_thread for inference; if False,
        it is None.</li>
<li><strong>validation_string_rdd</strong>: the RDD of bytes to be used in validation</li>
</ul>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>