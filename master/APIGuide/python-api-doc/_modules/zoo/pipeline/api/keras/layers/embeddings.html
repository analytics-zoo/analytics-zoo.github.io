
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>zoo.pipeline.api.keras.layers.embeddings &#8212; analytics-zoo  documentation</title>
    <link rel="stylesheet" href="../../../../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../../../" src="../../../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../../../index.html">analytics-zoo  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for zoo.pipeline.api.keras.layers.embeddings</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright 2018 Analytics Zoo Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="kn">import</span> <span class="n">JTensor</span>
<span class="kn">from</span> <span class="nn">zoo.common.utils</span> <span class="kn">import</span> <span class="n">callZooFunc</span>
<span class="kn">from</span> <span class="nn">..engine.topology</span> <span class="kn">import</span> <span class="n">ZooKerasLayer</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;=</span> <span class="s1">&#39;3&#39;</span><span class="p">:</span>
    <span class="n">long</span> <span class="o">=</span> <span class="nb">int</span>
    <span class="n">unicode</span> <span class="o">=</span> <span class="nb">str</span>


<div class="viewcode-block" id="Embedding"><a class="viewcode-back" href="../../../../../../zoo.pipeline.api.keras.layers.html#zoo.pipeline.api.keras.layers.embeddings.Embedding">[docs]</a><span class="k">class</span> <span class="nc">Embedding</span><span class="p">(</span><span class="n">ZooKerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn positive integers (indexes) into dense vectors of fixed size.</span>
<span class="sd">    The input of this layer should be 2D.</span>

<span class="sd">    This layer can only be used as the first layer in a model, you need to provide the argument</span>
<span class="sd">    input_length (an integer) or input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_dim: Size of the vocabulary. Int &gt; 0.</span>
<span class="sd">    output_dim: Dimension of the dense embedding. Int &gt; 0.</span>
<span class="sd">    init: String representation of the initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;uniform&#39;.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the embedding matrix. Default is None.</span>
<span class="sd">    weights: Initial weights set to this layer, which should be a numpy array of</span>
<span class="sd">             size (inputDim, outputDim). Default is None and in this case weights are</span>
<span class="sd">             initialized by the initialization method specified by &#39;init&#39;.</span>
<span class="sd">             Otherwise, &#39;weights&#39; will override &#39;init&#39; to take effect.</span>
<span class="sd">    trainable: Whether this layer is trainable or not. Default is True.</span>
<span class="sd">    input_length: Positive int. The sequence length of each input.</span>
<span class="sd">    mask_zero: if maskZero is set to true, the input whose value equals `paddingValue`</span>
<span class="sd">    the output will be masked to zero vector.</span>
<span class="sd">    padding_value: padding value, default 0</span>
<span class="sd">    zero_based_id: default True and input should be 0 based. Otherwise need to be 1 base</span>
<span class="sd">    name: String to set the name of the layer.</span>
<span class="sd">          If not specified, its name will by default to be a generated string.</span>

<span class="sd">    &gt;&gt;&gt; embedding = Embedding(1000, 32, input_length=10, name=&quot;embedding1&quot;)</span>
<span class="sd">    creating: createZooKerasEmbedding</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; embedding = Embedding(10, 200, weights=np.random.random([10, 200]), input_length=10)</span>
<span class="sd">    creating: createZooKerasEmbedding</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">input_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">zero_based_id</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">input_length</span><span class="p">:</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_length</span><span class="p">,)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Embedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                        <span class="n">input_dim</span><span class="p">,</span>
                                        <span class="n">output_dim</span><span class="p">,</span>
                                        <span class="n">init</span><span class="p">,</span>
                                        <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                        <span class="n">trainable</span><span class="p">,</span>
                                        <span class="n">W_regularizer</span><span class="p">,</span>
                                        <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                        <span class="n">mask_zero</span><span class="p">,</span>
                                        <span class="n">padding_value</span><span class="p">,</span>
                                        <span class="n">zero_based_id</span><span class="p">,</span>
                                        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="WordEmbedding"><a class="viewcode-back" href="../../../../../../zoo.pipeline.api.keras.layers.html#zoo.pipeline.api.keras.layers.embeddings.WordEmbedding">[docs]</a><span class="k">class</span> <span class="nc">WordEmbedding</span><span class="p">(</span><span class="n">ZooKerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Embedding layer that directly loads pre-trained word vectors as weights.</span>
<span class="sd">    Turn non-negative integers (indices) into dense vectors of fixed size.</span>
<span class="sd">    Currently only GloVe embedding is supported.</span>
<span class="sd">    The input of this layer should be 2D.</span>

<span class="sd">    This layer can only be used as the first layer in a model, you need to provide the argument</span>
<span class="sd">    input_length (an integer) or input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    embedding_file: The path to the embedding file.</span>
<span class="sd">                    Currently the following GloVe files are supported:</span>
<span class="sd">                    &quot;glove.6B.50d.txt&quot;, &quot;glove.6B.100d.txt&quot;, &quot;glove.6B.200d.txt&quot;</span>
<span class="sd">                    &quot;glove.6B.300d.txt&quot;, &quot;glove.42B.300d.txt&quot;, &quot;glove.840B.300d.txt&quot;.</span>
<span class="sd">                    You can download them from: https://nlp.stanford.edu/projects/glove/.</span>
<span class="sd">    word_index: Dictionary of word (string) and its corresponding index (int).</span>
<span class="sd">                The index is supposed to start from 1 with 0 reserved for unknown words.</span>
<span class="sd">                During the prediction, if you have words that are not in the word_index</span>
<span class="sd">                for the training, you can map them to index 0.</span>
<span class="sd">                Default is None. In this case, all the words in the embedding_file will</span>
<span class="sd">                be taken into account and you can call</span>
<span class="sd">                WordEmbedding.get_word_index(embedding_file) to retrieve the dictionary.</span>
<span class="sd">    trainable: To configure whether the weights of this layer will be updated or not.</span>
<span class="sd">               Only False is supported for now.</span>
<span class="sd">    input_length: Positive int. The sequence length of each input.</span>
<span class="sd">    name: String to set the name of the layer.</span>
<span class="sd">          If not specified, its name will by default to be a generated string.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_file</span><span class="p">,</span> <span class="n">word_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">input_length</span><span class="p">:</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_length</span><span class="p">,)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">embedding_file</span><span class="p">,</span>
                                            <span class="n">word_index</span><span class="p">,</span>
                                            <span class="n">trainable</span><span class="p">,</span>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="WordEmbedding.get_word_index"><a class="viewcode-back" href="../../../../../../zoo.pipeline.api.keras.layers.html#zoo.pipeline.api.keras.layers.embeddings.WordEmbedding.get_word_index">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_word_index</span><span class="p">(</span><span class="n">embedding_file</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the full wordIndex map from the given embedding_file.</span>

<span class="sd">        # Arguments</span>
<span class="sd">        embedding_file: The path to the embedding file.</span>
<span class="sd">                        Currently only the following GloVe files are supported:</span>
<span class="sd">                        &quot;glove.6B.50d.txt&quot;, &quot;glove.6B.100d.txt&quot;, &quot;glove.6B.200d.txt&quot;</span>
<span class="sd">                        &quot;glove.6B.300d.txt&quot;, &quot;glove.42B.300d.txt&quot;, &quot;glove.840B.300d.txt&quot;.</span>
<span class="sd">                        You can download them from: https://nlp.stanford.edu/projects/glove/.</span>

<span class="sd">        # Return</span>
<span class="sd">        Dictionary of word (string) and its corresponding index (int) obtained from</span>
<span class="sd">        the given embedding file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">callZooFunc</span><span class="p">(</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;wordEmbeddingGetWordIndex&quot;</span><span class="p">,</span>
                           <span class="n">embedding_file</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="prepare_embedding"><a class="viewcode-back" href="../../../../../../zoo.pipeline.api.keras.layers.html#zoo.pipeline.api.keras.layers.embeddings.prepare_embedding">[docs]</a><span class="k">def</span> <span class="nf">prepare_embedding</span><span class="p">(</span><span class="n">embedding_file</span><span class="p">,</span> <span class="n">word_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">randomize_unknown</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prepare embedding weights from embedding_file given word_index.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    embedding_file and word_index: See WordEmbedding.</span>
<span class="sd">    randomize_unknown: Boolean. Whether to randomly initialize words that don&#39;t exist in</span>
<span class="sd">                       embedding_file. Default is False and in this case corresponding entries</span>
<span class="sd">                       to unknown words will be zero vectors.</span>
<span class="sd">    normalize: Boolean. Whether to normalize word vectors. Default is False.</span>

<span class="sd">    # Return</span>
<span class="sd">    Pretrained embedding weights as a numpy array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">callZooFunc</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;prepareEmbedding&quot;</span><span class="p">,</span>
                       <span class="n">embedding_file</span><span class="p">,</span>
                       <span class="n">word_index</span><span class="p">,</span>
                       <span class="n">randomize_unknown</span><span class="p">,</span>
                       <span class="n">normalize</span><span class="p">)</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">()</span></div>


<div class="viewcode-block" id="SparseEmbedding"><a class="viewcode-back" href="../../../../../../zoo.pipeline.api.keras.layers.html#zoo.pipeline.api.keras.layers.embeddings.SparseEmbedding">[docs]</a><span class="k">class</span> <span class="nc">SparseEmbedding</span><span class="p">(</span><span class="n">ZooKerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SparseEmbedding is the sparse version of layer Embedding.</span>

<span class="sd">    The input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors.</span>
<span class="sd">    If the input is a SparseTensor, the values are positive integer ids,</span>
<span class="sd">    values in each row of this SparseTensor will be turned into a dense vector.</span>
<span class="sd">    If the input is two SparseTensors, the first tensor should be the integer ids, just</span>
<span class="sd">    like the SparseTensor input. And the second tensor is the corresponding</span>
<span class="sd">    weights of the integer ids.</span>

<span class="sd">    This layer can only be used as the first layer in a model, you need to provide the argument</span>
<span class="sd">    inputShape (a Single Shape, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_dim: Size of the vocabulary. Int &gt; 0.</span>
<span class="sd">    output_dim: Dimension of the dense embedding. Int &gt;= 0.</span>
<span class="sd">    init: String representation of the initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;uniform&#39;.</span>
<span class="sd">    combiner: A string specifying the reduce type.</span>
<span class="sd">              Currently &quot;mean&quot;, &quot;sum&quot;, &quot;sqrtn&quot; is supported.</span>
<span class="sd">    max_norm: If provided, each embedding is normalized to have l2 norm equal to</span>
<span class="sd">               maxNorm before combining.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the embedding matrix. Default is None.</span>
<span class="sd">    input_shape: A Single Shape, does not include the batch dimension.</span>
<span class="sd">    name: String to set the name of the layer.</span>
<span class="sd">          If not specified, its name will by default to be a generated string.</span>

<span class="sd">    &gt;&gt;&gt; sparse_embedding = SparseEmbedding(input_dim=10, output_dim=4, input_shape=(10, ))</span>
<span class="sd">    creating: createZooKerasSparseEmbedding</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">combiner</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SparseEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                              <span class="n">input_dim</span><span class="p">,</span>
                                              <span class="n">output_dim</span><span class="p">,</span>
                                              <span class="n">combiner</span><span class="p">,</span>
                                              <span class="n">max_norm</span><span class="p">,</span>
                                              <span class="n">init</span><span class="p">,</span>
                                              <span class="n">W_regularizer</span><span class="p">,</span>
                                              <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../../../index.html">analytics-zoo  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Intel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.4.
    </div>
  </body>
</html>