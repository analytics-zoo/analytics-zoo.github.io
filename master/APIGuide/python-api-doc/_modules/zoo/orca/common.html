
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>zoo.orca.common &#8212; analytics-zoo  documentation</title>
    <link rel="stylesheet" href="../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">analytics-zoo  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for zoo.orca.common</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright 2018 Analytics Zoo Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">ZooContext</span>


<div class="viewcode-block" id="OrcaContextMeta"><a class="viewcode-back" href="../../../zoo.orca.html#zoo.orca.common.OrcaContextMeta">[docs]</a><span class="k">class</span> <span class="nc">OrcaContextMeta</span><span class="p">(</span><span class="nb">type</span><span class="p">):</span>

    <span class="n">_pandas_read_backend</span> <span class="o">=</span> <span class="s2">&quot;spark&quot;</span>
    <span class="n">__eager_mode</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_serialize_data_creation</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">log_output</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether to redirect Spark driver JVM&#39;s stdout and stderr to the current</span>
<span class="sd">        python process. This is useful when running Analytics Zoo in jupyter notebook.</span>
<span class="sd">        Default to be False. Needs to be set before initializing SparkContext.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ZooContext</span><span class="o">.</span><span class="n">log_output</span>

    <span class="nd">@log_output</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">log_output</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">ZooContext</span><span class="o">.</span><span class="n">log_output</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pandas_read_backend</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The backend for reading csv/json files. Either &quot;spark&quot; or &quot;pandas&quot;.</span>
<span class="sd">        spark backend would call spark.read and pandas backend would call pandas.read.</span>
<span class="sd">        Default to be &quot;spark&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_pandas_read_backend</span>

    <span class="nd">@pandas_read_backend</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">pandas_read_backend</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;spark&quot;</span> <span class="ow">or</span> <span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;pandas&quot;</span><span class="p">,</span> \
            <span class="s2">&quot;pandas_read_backend must be either spark or pandas&quot;</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_pandas_read_backend</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_eager_mode</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether to compute eagerly for SparkXShards.</span>
<span class="sd">        Default to be True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__eager_mode</span>

    <span class="nd">@_eager_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">_eager_mode</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="s2">&quot;_eager_mode should either be True or False&quot;</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">__eager_mode</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">serialize_data_creation</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether add a file lock to the data loading process for PyTorch Horovod training.</span>
<span class="sd">        This would be useful when you run multiple workers on a single node to download data</span>
<span class="sd">        to the same destination.</span>
<span class="sd">        Default to be False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_serialize_data_creation</span>

    <span class="nd">@serialize_data_creation</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">serialize_data_creation</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="s2">&quot;serialize_data_creation should either be True or False&quot;</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_serialize_data_creation</span> <span class="o">=</span> <span class="n">value</span></div>


<div class="viewcode-block" id="OrcaContext"><a class="viewcode-back" href="../../../zoo.orca.html#zoo.orca.common.OrcaContext">[docs]</a><span class="k">class</span> <span class="nc">OrcaContext</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">OrcaContextMeta</span><span class="p">):</span>
    <span class="k">pass</span></div>


<div class="viewcode-block" id="init_orca_context"><a class="viewcode-back" href="../../../zoo.orca.html#zoo.orca.common.init_orca_context">[docs]</a><span class="k">def</span> <span class="nf">init_orca_context</span><span class="p">(</span><span class="n">cluster_mode</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="n">cores</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;2g&quot;</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">init_ray_on_spark</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates or gets a SparkContext for different Spark cluster modes (and launch Ray services</span>
<span class="sd">    across the cluster if necessary).</span>

<span class="sd">    :param cluster_mode: The mode for the Spark cluster. One of &quot;local&quot;, &quot;yarn-client&quot;,</span>
<span class="sd">           &quot;k8s-client&quot;, &quot;standalone&quot; and &quot;spark-submit&quot;. Default to be &quot;local&quot;.</span>

<span class="sd">           For &quot;spark-submit&quot;, you are supposed to use spark-submit to submit the application.</span>
<span class="sd">           In this case, please set the Spark configurations through command line options or</span>
<span class="sd">           the properties file. You need to use &quot;spark-submit&quot; for yarn-cluster or k8s-cluster mode.</span>
<span class="sd">           To make things easier, you are recommended to use the launch scripts we provide:</span>
<span class="sd">           https://github.com/intel-analytics/analytics-zoo/tree/master/scripts.</span>

<span class="sd">           For other cluster modes, you are recommended to install and run analytics-zoo through</span>
<span class="sd">           pip, which is more convenient.</span>
<span class="sd">    :param cores: The number of cores to be used on each node. Default to be 2.</span>
<span class="sd">    :param memory: The memory allocated for each node. Default to be &#39;2g&#39;.</span>
<span class="sd">    :param num_nodes: The number of nodes to be used in the cluster. Default to be 1.</span>
<span class="sd">           For Spark local, num_nodes should always be 1 and you don&#39;t need to change it.</span>
<span class="sd">    :param init_ray_on_spark: Whether to launch Ray services across the cluster.</span>
<span class="sd">           Default to be False and in this case the Ray cluster would be launched lazily when</span>
<span class="sd">           Ray is involved in Project Orca.</span>
<span class="sd">    :param kwargs: The extra keyword arguments used for creating SparkContext and</span>
<span class="sd">           launching Ray if any.</span>

<span class="sd">    :return: An instance of SparkContext.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initializing orca context&quot;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">atexit</span>
    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">stop_orca_context</span><span class="p">)</span>
    <span class="n">cluster_mode</span> <span class="o">=</span> <span class="n">cluster_mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">spark_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">,</span> <span class="s2">&quot;spark_log_level&quot;</span><span class="p">,</span> <span class="s2">&quot;redirect_spark_log&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">spark_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">cluster_mode</span> <span class="o">==</span> <span class="s2">&quot;spark-submit&quot;</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">init_nncontext</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">init_nncontext</span><span class="p">(</span><span class="o">**</span><span class="n">spark_args</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cluster_mode</span> <span class="o">==</span> <span class="s2">&quot;local&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">num_nodes</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;For Spark local mode, num_nodes should be 1&quot;</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;SPARK_DRIVER_MEMORY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">memory</span>
        <span class="k">if</span> <span class="s2">&quot;python_location&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">spark_args</span><span class="p">[</span><span class="s2">&quot;python_location&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;python_location&quot;</span><span class="p">]</span>
        <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">init_spark_on_local</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">init_spark_on_local</span><span class="p">(</span><span class="n">cores</span><span class="p">,</span> <span class="o">**</span><span class="n">spark_args</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cluster_mode</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;yarn&quot;</span><span class="p">):</span>  <span class="c1"># yarn or yarn-client</span>
        <span class="k">if</span> <span class="n">cluster_mode</span> <span class="o">==</span> <span class="s2">&quot;yarn-cluster&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;For yarn-cluster mode, please set cluster_mode to &quot;spark-submit&quot; &#39;</span>
                             <span class="s1">&#39;and submit the application via spark-submit instead&#39;</span><span class="p">)</span>
        <span class="n">hadoop_conf</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;HADOOP_CONF_DIR&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">hadoop_conf</span><span class="p">:</span>
            <span class="k">assert</span> <span class="s2">&quot;hadoop_conf&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">,</span>\
                <span class="s2">&quot;Directory path to hadoop conf not found for yarn-client mode. Please either &quot;</span> \
                <span class="s2">&quot;specify argument hadoop_conf or set the environment variable HADOOP_CONF_DIR&quot;</span>
            <span class="n">hadoop_conf</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;hadoop_conf&quot;</span><span class="p">]</span>
        <span class="kn">from</span> <span class="nn">zoo.util.utils</span> <span class="kn">import</span> <span class="n">detect_conda_env_name</span>
        <span class="n">conda_env_name</span> <span class="o">=</span> <span class="n">detect_conda_env_name</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;driver_cores&quot;</span><span class="p">,</span> <span class="s2">&quot;driver_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;extra_executor_memory_for_ray&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;extra_python_lib&quot;</span><span class="p">,</span> <span class="s2">&quot;penv_archive&quot;</span><span class="p">,</span> <span class="s2">&quot;additional_archive&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;hadoop_user_name&quot;</span><span class="p">,</span> <span class="s2">&quot;spark_yarn_archive&quot;</span><span class="p">,</span> <span class="s2">&quot;jars&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">spark_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">init_spark_on_yarn</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">init_spark_on_yarn</span><span class="p">(</span><span class="n">hadoop_conf</span><span class="o">=</span><span class="n">hadoop_conf</span><span class="p">,</span>
                                <span class="n">conda_name</span><span class="o">=</span><span class="n">conda_env_name</span><span class="p">,</span>
                                <span class="n">num_executors</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">executor_cores</span><span class="o">=</span><span class="n">cores</span><span class="p">,</span>
                                <span class="n">executor_memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="o">**</span><span class="n">spark_args</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cluster_mode</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;k8s&quot;</span><span class="p">):</span>  <span class="c1"># k8s or k8s-client</span>
        <span class="k">if</span> <span class="n">cluster_mode</span> <span class="o">==</span> <span class="s2">&quot;k8s-cluster&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;For k8s-cluster mode, please set cluster_mode to &quot;spark-submit&quot; &#39;</span>
                             <span class="s1">&#39;and submit the application via spark-submit instead&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="s2">&quot;master&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;Please specify master for k8s-client mode&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;container_image&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;Please specify container_image for k8s-client mode&quot;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;driver_cores&quot;</span><span class="p">,</span> <span class="s2">&quot;driver_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;extra_executor_memory_for_ray&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;extra_python_lib&quot;</span><span class="p">,</span> <span class="s2">&quot;jars&quot;</span><span class="p">,</span> <span class="s2">&quot;python_location&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">spark_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">init_spark_on_k8s</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">init_spark_on_k8s</span><span class="p">(</span><span class="n">master</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;master&quot;</span><span class="p">],</span>
                               <span class="n">container_image</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;container_image&quot;</span><span class="p">],</span>
                               <span class="n">num_executors</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">executor_cores</span><span class="o">=</span><span class="n">cores</span><span class="p">,</span>
                               <span class="n">executor_memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="o">**</span><span class="n">spark_args</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cluster_mode</span> <span class="o">==</span> <span class="s2">&quot;standalone&quot;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;driver_cores&quot;</span><span class="p">,</span> <span class="s2">&quot;driver_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;extra_executor_memory_for_ray&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;extra_python_lib&quot;</span><span class="p">,</span> <span class="s2">&quot;jars&quot;</span><span class="p">,</span> <span class="s2">&quot;master&quot;</span><span class="p">,</span> <span class="s2">&quot;python_location&quot;</span><span class="p">,</span> <span class="s2">&quot;enable_numa_binding&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">spark_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">init_spark_standalone</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">init_spark_standalone</span><span class="p">(</span><span class="n">num_executors</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">executor_cores</span><span class="o">=</span><span class="n">cores</span><span class="p">,</span>
                                   <span class="n">executor_memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="o">**</span><span class="n">spark_args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cluster_mode can only be local, yarn-client, standalone or spark-submit, &quot;</span>
                         <span class="s2">&quot;but got: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cluster_mode</span><span class="p">))</span>
    <span class="n">ray_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;redis_port&quot;</span><span class="p">,</span> <span class="s2">&quot;password&quot;</span><span class="p">,</span> <span class="s2">&quot;object_store_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="s2">&quot;env&quot;</span><span class="p">,</span>
                <span class="s2">&quot;extra_params&quot;</span><span class="p">,</span> <span class="s2">&quot;num_ray_nodes&quot;</span><span class="p">,</span> <span class="s2">&quot;ray_node_cpu_cores&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">ray_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="kn">from</span> <span class="nn">zoo.ray</span> <span class="kn">import</span> <span class="n">RayContext</span>
    <span class="n">ray_ctx</span> <span class="o">=</span> <span class="n">RayContext</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="o">**</span><span class="n">ray_args</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">init_ray_on_spark</span><span class="p">:</span>
        <span class="n">driver_cores</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># This is the default value.</span>
        <span class="k">if</span> <span class="s2">&quot;driver_cores&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">driver_cores</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;driver_cores&quot;</span><span class="p">]</span>
        <span class="n">ray_ctx</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">driver_cores</span><span class="o">=</span><span class="n">driver_cores</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sc</span></div>


<div class="viewcode-block" id="stop_orca_context"><a class="viewcode-back" href="../../../zoo.orca.html#zoo.orca.common.stop_orca_context">[docs]</a><span class="k">def</span> <span class="nf">stop_orca_context</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Stop the SparkContext (and stop Ray services across the cluster if necessary).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
    <span class="c1"># If users successfully call stop_orca_context after the program finishes,</span>
    <span class="c1"># namely when there is no active SparkContext, the registered exit function</span>
    <span class="c1"># should do nothing.</span>
    <span class="k">if</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">_active_spark_context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Stopping orca context&quot;</span><span class="p">)</span>
        <span class="kn">from</span> <span class="nn">zoo.ray</span> <span class="kn">import</span> <span class="n">RayContext</span>
        <span class="n">ray_ctx</span> <span class="o">=</span> <span class="n">RayContext</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ray_ctx</span><span class="o">.</span><span class="n">initialized</span><span class="p">:</span>
            <span class="n">ray_ctx</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">sc</span><span class="o">.</span><span class="n">getConf</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.master&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;spark://&quot;</span><span class="p">):</span>
            <span class="kn">from</span> <span class="nn">zoo</span> <span class="kn">import</span> <span class="n">stop_spark_standalone</span>
            <span class="n">stop_spark_standalone</span><span class="p">()</span>
        <span class="n">sc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">analytics-zoo  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Intel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.4.
    </div>
  </body>
</html>