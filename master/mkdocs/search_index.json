{
    "docs": [
        {
            "location": "/",
            "text": "A unified Data Analytics and AI platform for \ndistributed TensorFlow, Keras and PyTorch on Apache Spark/Flink & Ray\n\n\n\n\nWhat is Analytics Zoo?\n\n\nAnalytics Zoo seamless scales TensorFlow, Keras and PyTorch to distributed big data (using Spark, Flink & Ray).\n\n\n \n\n\n\n\n\n\nEnd-to-end pipeline for applying AI models (TensorFlow, PyTorch, OpenVINO, etc.) to distributed big data\n \n\n\n\n\nWrite \nTensorFlow\n or \nPyTorch\n inline with Spark code for distributed training and inference.\n\n\nNative deep learning (TensorFlow/Keras/PyTorch/BigDL) support in \nSpark ML\n Pipelines.\n\n\nDirectly run \nRay\n programs on big data cluster through \nRayOnSpark\n. \n\n\nPlain Java/Python APIs for (TensorFlow/PyTorch/BigDL/OpenVINO) \nModel Inference\n. \n\n\n\n\n\n\n\n\nHigh-level ML workflow for automating machine learning tasks\n\n\n\n\nCluster Serving\n for automatically distributed (TensorFlow/PyTorch/Caffe/OpenVINO) model inference . \n\n\n\n\nScalable \nAutoML\n for time series prediction.\n\n\n\n\n\n\nBuilt-in models\n for \nRecommendation\n, \nTime Series\n, \nComputer Vision\n and \nNLP\n applications.\n\n\n\n\n\n\n\n\nWhy use Analytics Zoo?\n\n\nYou may want to develop your AI solutions using Analytics Zoo if:\n\n\n\n\nYou want to easily apply AI models (e.g., TensorFlow, Keras, PyTorch, BigDL, OpenVINO, etc.) to distributed big data.\n\n\nYou want to transparently scale your AI applications from a single laptop to large clusters with \"zero\" code changes.\n\n\nYou want to deploy your AI pipelines to existing YARN or K8S clusters \nWITHOUT\n any modifications to the clusters.\n\n\nYou want to automate the process of applying machine learning (such as feature engineering, hyperparameter tuning, model selection, distributed inference, etc.). \n\n\n\n\n\n\nHow to use Analytics Zoo?\n\n\n\n\nCheck out the \nGetting Started page\n for a quick overview of how to use Analytics Zoo.\n\n\nRefer to the \nPython\n, \nScala\n and \nDocker\n guides to install Analytics Zoo.\n\n\nVisit the \nDocument Website\n (\nmirror\n in China) for more information on Analytics Zoo.\n\n\nCheck the \nPowered By\n & \nPresentations\n pages for real-world applications using Analytics Zoo.\n\n\nJoin the \nGoogle Group\n (or subscribe to the \nMail List\n) for more questions and discussions on Analytics Zoo.",
            "title": "Overview"
        },
        {
            "location": "/#what-is-analytics-zoo",
            "text": "Analytics Zoo seamless scales TensorFlow, Keras and PyTorch to distributed big data (using Spark, Flink & Ray).       End-to-end pipeline for applying AI models (TensorFlow, PyTorch, OpenVINO, etc.) to distributed big data     Write  TensorFlow  or  PyTorch  inline with Spark code for distributed training and inference.  Native deep learning (TensorFlow/Keras/PyTorch/BigDL) support in  Spark ML  Pipelines.  Directly run  Ray  programs on big data cluster through  RayOnSpark .   Plain Java/Python APIs for (TensorFlow/PyTorch/BigDL/OpenVINO)  Model Inference .      High-level ML workflow for automating machine learning tasks   Cluster Serving  for automatically distributed (TensorFlow/PyTorch/Caffe/OpenVINO) model inference .    Scalable  AutoML  for time series prediction.    Built-in models  for  Recommendation ,  Time Series ,  Computer Vision  and  NLP  applications.",
            "title": "What is Analytics Zoo?"
        },
        {
            "location": "/#why-use-analytics-zoo",
            "text": "You may want to develop your AI solutions using Analytics Zoo if:   You want to easily apply AI models (e.g., TensorFlow, Keras, PyTorch, BigDL, OpenVINO, etc.) to distributed big data.  You want to transparently scale your AI applications from a single laptop to large clusters with \"zero\" code changes.  You want to deploy your AI pipelines to existing YARN or K8S clusters  WITHOUT  any modifications to the clusters.  You want to automate the process of applying machine learning (such as feature engineering, hyperparameter tuning, model selection, distributed inference, etc.).",
            "title": "Why use Analytics Zoo?"
        },
        {
            "location": "/#how-to-use-analytics-zoo",
            "text": "Check out the  Getting Started page  for a quick overview of how to use Analytics Zoo.  Refer to the  Python ,  Scala  and  Docker  guides to install Analytics Zoo.  Visit the  Document Website  ( mirror  in China) for more information on Analytics Zoo.  Check the  Powered By  &  Presentations  pages for real-world applications using Analytics Zoo.  Join the  Google Group  (or subscribe to the  Mail List ) for more questions and discussions on Analytics Zoo.",
            "title": "How to use Analytics Zoo?"
        },
        {
            "location": "/gettingstarted/",
            "text": "This Getting Started document provides quick reference information regarding installing Analytics Zoo, running the applications, and developing your own applications using Analytics Zoo. \n\n\n\n\n1. Try Analytics Zoo\n\n\nUsers can easily try Analytics Zoo with Docker or Google Colab without installing it. For more information: \n\n\n\n\nCheck the \nDocker User Guide\n\n\nCheck the \nGoogle Colab Guide page\n\n\n\n\nPlease also check the \nexamples\n for various Analytics Zoo features (such as distributed TensorFlow and PyTorch on Spark, DL support in Spark ML pipeline, RayOnSpark, Cluster Serving, AutoML, etc.)\n\n\n\n\n2. Install Analytics Zoo\n\n\nAnalytics Zoo installation methods are available for Python and Scala users. \n\n\n2.1 Python\n \n\n\n\n\nCheck the \nPython User Guide\n for how to install Analytics Zoo in Python program environment.\n\n\n\n\n2.2 Scala\n \n\n\n\n\nCheck the \nScala User Guide\n for how to install Analytics Zoo in Scala program environment.\n\n\n\n\n\n\n3. Run Analytics Zoo Applications\n\n\nAnalytics Zoo applications can run on remote or cloud resources, such as YARN, K8s, Databricks, or Google Dataproc. \n\n\n3.1 Run on YARN\n \n\n\n\n\nPython users can follow the instructions in \nPython User Guide\n to run Analytics Zoo applications on YARN.\n\n\nScala users can follow the instructions in \nScala User Guide\n to run Analytics Zoo applications on YARN.\n\n\n\n\n3.2 Run on K8s\n \n\n\n\n\nCheck the \ninstructions\n for how to run Analytics Zoo applicaitons on K8s.\n\n\n\n\n3.3 Run on Databricks\n \n\n\n\n\nCheck the \ninstructions\n for how to run Analytics Zoo applicaitons on Databricks.\n\n\n\n\n3.4 Run on Google Dataproc\n \n\n\n\n\nCheck the \ninstructions\n for how to run Analytics Zoo applications on Google Dataproc environment. \n\n\n\n\n\n\n4. Develop Analytics Zoo Applications\n\n\nAnalytics Zoo provides comprehensive support for for building end-to-end, integrated data analytics and AI applications. \n\n\n4.1 TensorFlow\n \n\n\n\n\nTensorFlow users can leverage \nTFPark APIs\n for running distributed TensorFlow on Spark. \n\n\n\n\n4.2 PyTorch\n \n\n\nPytorch users can use \nTorch Model\n and either:\n- \nNNFrame APIs\n to run Spark ML Pipeline and Dataframe with PyTorch support, or \n- \nEstimator APIs\n to train and evaluate distributed PyTorch on Spark.  \n\n\n4.3 BigDL\n \n\n\nBigDL users can use either: \n\n\n\n\nNNFrame APIs\n to run Spark ML Pipeline and Dataframe with BigDL support, or \n\n\nKeras-style APIs for BigDL\n to build deep learning pipeline.\n\n\n\n\n4.4 Cluster Serving\n \n\n\nAnalytics Zoo Cluster Serving is a real-time distributed serving solution for deep learning (including TF, PyTorch, Caffe, BigDL and OpenVINO). Follow the \nCluster Serving Programming Guide\n to run the Cluster Serving; the \nCluster Serving API Guide\n explains the APIs in more detail. \n\n\n4.5 AutoML\n \n\n\nAnalytics Zoo provides scalable AutoML support for time series prediction (including automatic feature generation, model selection and hyper-parameter tuning). Check the \nAutoML Overview\n for a high level description of the AutoML framework. Please check out the details in the \nProgramming Guide\n and \nAPI Guide\n.",
            "title": "Getting Started"
        },
        {
            "location": "/gettingstarted/#1-try-analytics-zoo",
            "text": "Users can easily try Analytics Zoo with Docker or Google Colab without installing it. For more information:    Check the  Docker User Guide  Check the  Google Colab Guide page   Please also check the  examples  for various Analytics Zoo features (such as distributed TensorFlow and PyTorch on Spark, DL support in Spark ML pipeline, RayOnSpark, Cluster Serving, AutoML, etc.)",
            "title": "1. Try Analytics Zoo"
        },
        {
            "location": "/gettingstarted/#2-install-analytics-zoo",
            "text": "Analytics Zoo installation methods are available for Python and Scala users.   2.1 Python     Check the  Python User Guide  for how to install Analytics Zoo in Python program environment.   2.2 Scala     Check the  Scala User Guide  for how to install Analytics Zoo in Scala program environment.",
            "title": "2. Install Analytics Zoo"
        },
        {
            "location": "/gettingstarted/#3-run-analytics-zoo-applications",
            "text": "Analytics Zoo applications can run on remote or cloud resources, such as YARN, K8s, Databricks, or Google Dataproc.   3.1 Run on YARN     Python users can follow the instructions in  Python User Guide  to run Analytics Zoo applications on YARN.  Scala users can follow the instructions in  Scala User Guide  to run Analytics Zoo applications on YARN.   3.2 Run on K8s     Check the  instructions  for how to run Analytics Zoo applicaitons on K8s.   3.3 Run on Databricks     Check the  instructions  for how to run Analytics Zoo applicaitons on Databricks.   3.4 Run on Google Dataproc     Check the  instructions  for how to run Analytics Zoo applications on Google Dataproc environment.",
            "title": "3. Run Analytics Zoo Applications"
        },
        {
            "location": "/gettingstarted/#4-develop-analytics-zoo-applications",
            "text": "Analytics Zoo provides comprehensive support for for building end-to-end, integrated data analytics and AI applications.   4.1 TensorFlow     TensorFlow users can leverage  TFPark APIs  for running distributed TensorFlow on Spark.    4.2 PyTorch    Pytorch users can use  Torch Model  and either:\n-  NNFrame APIs  to run Spark ML Pipeline and Dataframe with PyTorch support, or \n-  Estimator APIs  to train and evaluate distributed PyTorch on Spark.    4.3 BigDL    BigDL users can use either:    NNFrame APIs  to run Spark ML Pipeline and Dataframe with BigDL support, or   Keras-style APIs for BigDL  to build deep learning pipeline.   4.4 Cluster Serving    Analytics Zoo Cluster Serving is a real-time distributed serving solution for deep learning (including TF, PyTorch, Caffe, BigDL and OpenVINO). Follow the  Cluster Serving Programming Guide  to run the Cluster Serving; the  Cluster Serving API Guide  explains the APIs in more detail.   4.5 AutoML    Analytics Zoo provides scalable AutoML support for time series prediction (including automatic feature generation, model selection and hyper-parameter tuning). Check the  AutoML Overview  for a high level description of the AutoML framework. Please check out the details in the  Programming Guide  and  API Guide .",
            "title": "4. Develop Analytics Zoo Applications"
        },
        {
            "location": "/release-download/",
            "text": "Release 0.10.0 nightly build\n\n\n\n\n\n\n\n\n\n\nBigDL 0.12.1\n\n\n\n\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\nSpark 3.0.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.9.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.12.1\n\n\n\n\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\nSpark 3.0.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.8.1\n\n\n\n\n\n\n\n\n\n\nBigDL 0.10.0\n\n\n\n\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.7.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.10.0\n\n\n\n\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.6.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.9.1\n\n\n\n\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.5.1\n\n\n\n\n\n\n\n\n\n\nBigDL 0.8.0\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.3\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.4.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.7.2\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.3.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.6.0\n\n\nBigDL 0.7.1\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.2.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.6.0\n\n\nBigDL 0.5.0\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.1.0\n\n\n\n\n\n\n\n\n\n\nDownload Links\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload",
            "title": "Download"
        },
        {
            "location": "/release-download/#release-0100-nightly-build",
            "text": "BigDL 0.12.1      Spark 2.1.1  download    Spark 2.2.1  download    Spark 2.3.1  download    Spark 2.4.3  download    Spark 3.0.0  download",
            "title": "Release 0.10.0 nightly build"
        },
        {
            "location": "/release-download/#release-090",
            "text": "BigDL 0.12.1      Spark 2.1.1  download    Spark 2.2.1  download    Spark 2.3.1  download    Spark 2.4.3  download    Spark 3.0.0  download",
            "title": "Release 0.9.0"
        },
        {
            "location": "/release-download/#release-081",
            "text": "BigDL 0.10.0      Spark 2.1.1  download    Spark 2.2.1  download    Spark 2.3.1  download    Spark 2.4.3  download",
            "title": "Release 0.8.1"
        },
        {
            "location": "/release-download/#release-070",
            "text": "BigDL 0.10.0      Spark 2.1.1  download    Spark 2.2.1  download    Spark 2.3.1  download    Spark 2.4.3  download",
            "title": "Release 0.7.0"
        },
        {
            "location": "/release-download/#release-060",
            "text": "BigDL 0.9.1      Spark 2.1.1  download    Spark 2.2.1  download    Spark 2.3.1  download    Spark 2.4.3  download",
            "title": "Release 0.6.0"
        },
        {
            "location": "/release-download/#release-051",
            "text": "BigDL 0.8.0      Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download    Spark 2.3.1  download    Spark 2.4.3  download",
            "title": "Release 0.5.1"
        },
        {
            "location": "/release-download/#release-040",
            "text": "BigDL 0.7.2      Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download    Spark 2.3.1  download    Spark 2.4.0  download",
            "title": "Release 0.4.0"
        },
        {
            "location": "/release-download/#release-030",
            "text": "BigDL 0.6.0  BigDL 0.7.1      Spark 1.6.2  download  download    Spark 2.1.1  download  download    Spark 2.2.0  download  download    Spark 2.3.1  download  download",
            "title": "Release 0.3.0"
        },
        {
            "location": "/release-download/#release-020",
            "text": "BigDL 0.6.0  BigDL 0.5.0      Spark 1.6.2  download  download    Spark 2.1.1  download  download    Spark 2.2.0  download  download",
            "title": "Release 0.2.0"
        },
        {
            "location": "/release-download/#release-010",
            "text": "Download Links      Spark 1.6.0  download    Spark 2.1.0  download    Spark 2.2.0  download",
            "title": "Release 0.1.0"
        },
        {
            "location": "/release-docs/",
            "text": "Release 0.9.0\n\n\nAnalytics-Zoo 0.9.0 Docs\n\n\nRelease 0.8.1\n\n\nAnalytics-Zoo 0.8.1 Docs\n\n\nRelease 0.7.0\n\n\nAnalytics-Zoo 0.7.0 Docs\n\n\nRelease 0.6.0\n\n\nAnalytics-Zoo 0.6.0 Docs\n\n\nRelease 0.5.1\n\n\nAnalytics-Zoo 0.5.1 Docs\n\n\nRelease 0.4.0\n\n\nAnalytics-Zoo 0.4.0 Docs\n\n\nRelease 0.3.0\n\n\nAnalytics-Zoo 0.3.0 Docs\n\n\nRelease 0.2.0\n\n\nAnalytics-Zoo 0.2.0 Docs\n\n\nRelease 0.1.0\n\n\nAnalytics-Zoo 0.1.0 Docs",
            "title": "Documentation"
        },
        {
            "location": "/release-docs/#release-090",
            "text": "Analytics-Zoo 0.9.0 Docs",
            "title": "Release 0.9.0"
        },
        {
            "location": "/release-docs/#release-081",
            "text": "Analytics-Zoo 0.8.1 Docs",
            "title": "Release 0.8.1"
        },
        {
            "location": "/release-docs/#release-070",
            "text": "Analytics-Zoo 0.7.0 Docs",
            "title": "Release 0.7.0"
        },
        {
            "location": "/release-docs/#release-060",
            "text": "Analytics-Zoo 0.6.0 Docs",
            "title": "Release 0.6.0"
        },
        {
            "location": "/release-docs/#release-051",
            "text": "Analytics-Zoo 0.5.1 Docs",
            "title": "Release 0.5.1"
        },
        {
            "location": "/release-docs/#release-040",
            "text": "Analytics-Zoo 0.4.0 Docs",
            "title": "Release 0.4.0"
        },
        {
            "location": "/release-docs/#release-030",
            "text": "Analytics-Zoo 0.3.0 Docs",
            "title": "Release 0.3.0"
        },
        {
            "location": "/release-docs/#release-020",
            "text": "Analytics-Zoo 0.2.0 Docs",
            "title": "Release 0.2.0"
        },
        {
            "location": "/release-docs/#release-010",
            "text": "Analytics-Zoo 0.1.0 Docs",
            "title": "Release 0.1.0"
        },
        {
            "location": "/DockerUserGuide/",
            "text": "In order to simplify the Analytics Zoo installation and configuration, Analytics Zoo docker images have been built and provided on \nDocker Hub\n. These docker images have been pre-built with all the dependencies and readily configured to run a bunch of Analytics Zoo examples out-of-box on Linux (such as Ubuntu, CentOS), MacOS or Windows. The pre-installed packages are listed at the end of this page. This document provides step-by-step instructions for users to easily start using the Analytics Zoo docker:\n\n\n\n\nLaunch an Analytics Zoo Docker container\n\n\nRun Analytics Zoo Jupyter Notebook example in a container\n\n\nStart the Jupyter Notebook service in the container\n\n\nConnect to Jupyter Notebook service\n\n\nRun Analytics Zoo Jupyter Notebook examples\n\n\n\n\n\n\nCreate a new Analytics Zoo Jupyter Notebook example\n\n\nShut Down the Analytics Zoo Docker container\n\n\nBuild a customized Analytics Zoo Docker image\n\n\n\n\n\n\nLaunch an Analytics Zoo Docker Container\n\n\nA Linux user (CentOS or Ubuntu) can pull a Docker image and launch the Docker container with one command line. \n\n\n1. Getting Ready\n\n\n\n\nFresh install OS such as Linux OS (CentOS, Ubuntu etc), MacOS or Windows.\n\n\nDownload and Install Docker following the instructions on: \nhttps://docs.docker.com/get-docker/\n\n\n(Optional) For Docker Desktop users on MacOS and Windows, the default resources (2 CPUs and 2GB memory) is relatively small, you may want to increase them by changing docker desktop configuration. 8GB memory and 4 CPUs should be a good estimator for most examples, and the exact memory requirements vary from different applications. For more information on this, please refer to docker documentation. (\nhere\n for Mac and \nhere\n for windows)\n\n\n(optional) Pull an Analytics Zoo docker image\n\n\nNote: It is optional to pull an Analytics Zoo docker image in advance, as the command \u201cdocker run\u201d in \nLaunch Analytics Zoo Docker container\n step will check the availability of the docker image and pull the image if it is absent. To manually pull the latest docker image, use: \n\n\n\n\nsudo docker pull intelanalytics/analytics-zoo:latest\n\n\n\n\n\n\nSpeed up pulling image by adding mirrors\n\n\n\n\nTo speed up pulling the image from dockerhub in China, add a registry's mirror. For Linux OS (CentOS, Ubuntu etc), if the docker version is higher than 1.12, config the docker daemon. Edit \n/etc/docker/daemon.json\n and add the registry-mirrors key and value:\n\n\n{\n  \"registry-mirrors\": [\"https://<my-docker-mirror-host>\"]\n}\n\n\n\n\nFor example, add the ustc mirror in China.\n\n\n{\n  \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]\n}\n\n\n\n\nFlush changes and restart docker\uff1a\n\n\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n\n\n\n\nIf your docker version is between 1.8 and 1.11, find the docker configuration which location depends on the operation system. Edit and add \nDOCKER_OPTS=\"--registry-mirror=https://<my-docker-mirror-host>\"\n. Restart docker \nsudo service docker restart\n.\n\n\nIf you would like to speed up pulling this image on MacOS or Windows, find the docker setting and config registry-mirrors section by specifying mirror host. Restart docker.\n\n\nThen pull the image. It will be faster.\n\n\nsudo docker pull intelanalytics/analytics-zoo:latest\n\n\n\n\n2. Launch Analytics Zoo Docker container\n\n\nLaunch an Analytics Zoo Docker container with this command line: \n\n\n$sudo docker run -it --rm --net=host -e NotebookPort=12345 -e NotebookToken=\"your-token\" intelanalytics/analytics-zoo:latest bash\n\n\n\n\n\n\nThe value 12345 is a user specified port number. \n\n\nThe value \"your-token\" is a user specified string.\n\n\n\n\nIf you want to specify an Analytics Zoo version, for example 0.7.0, use: \n\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3 bash\n\n\n\n\nIf you need to use http/https proxy, use:  \n\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default bash\n\n\n\n\nOnce the container is sucessfully launched, you will automatically login to the container and see this as the output: \n\n\nroot@[hostname]:/opt/work#\n\n\n\n\nNote: The /opt/work directory contains: \n\n\n\n\n\n\ndownload-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.\n\n\n\n\n\n\nstart-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a - specified jupyter notebook.\n\n\n\n\n\n\nanalytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution.\n\n\n\n\n\n\nanalytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution.\n\n\n\n\n\n\nspark-${SPARK_VERSION} is the Spark home.\n\n\n\n\n\n\nanalytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.\n\n\n\n\n\n\n\n\nRun Analytics Zoo Jupyter Notebook example in a container\n\n\nThis section depends on the previous section \n\u201cLaunch Analytics Zoo Docker container\u201d\n. After the user launches the Analytics Zoo Docker container, the Jupyter Notebook service can be started and Analytics Zoo Jupyter Notebook examples are available. \n\n\nStart the Jupyter Notebook service in the container\n\n\nAfter a Docker container is launched and user login to the container, user can start the Jupyter Notebook service inside the container. \n\n\nIn the /opt/work directory, run this command line to start the Jupyter Notebook service:\n\n\n#start-notebook.sh\n\n\n\n\nAs a result, you will see the output message like below. This means the Jupyter Notebook service has started successfully within the container.\n\n\n[I 01:04:45.625 NotebookApp] Serving notebooks from local directory: /opt/work/analytics-zoo-0.5.0-SNAPSHOT/apps\n[I 01:04:45.625 NotebookApp] The Jupyter Notebook is running at:\n[I 01:04:45.625 NotebookApp] http://(the-host-name or 127.0.0.1):12345/?token=...\n[I 01:04:45.625 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n\n\n\n\nConnect to Jupyter Notebook service from a browser\n\n\nAfter the Jupyter Notebook service is successfully started, users can connect to the Jupyter Notebook service from a browser. \n\n\n\n\nGet the IP address of the container\n\n\nLaunch a browser, and connect to the Jupyter Notebook service with the URL: \nhttps://container-ip-address:port-number/?token=your-token\n\n\n\n\nAs a result, you will see the Jupyter Notebook like this: \n\n\n\n\nRun Analytics Zoo Jupyter Notebook examples\n\n\nAfter connecting to the Jupyter Notebook in the browser, users can run multiple Analytics Zoo Jupyter Notebook examples. The example shown below is the \u201cdogs-vs-cats\u201d. \n\n\n\n\nClick into the \"dogs-vs-cats\" folder: \n\n\n\n\n\n\n\n\nOpen the notebook file: \n\n\n\n\n\n\n\n\nStart to run the \"dogs-vs-cats\" notebook:\n\n\n\n\n\n\n\n\nRun through the example and check the prediction:\n\n\n\n\n\n\n\n\nCreate a new Analytics Zoo Jupyter Notebook example\n\n\nThere are a few ways to quickly start creating a new Analytics Zoo Jupyter Notebook example. Users can \u201cNew\u201d a Python notebook from scratch, or use the existing Jupyter Notebook example as an template and modify based on it. \n\n\n\u201cNew\u201d a Jupyter Notebook and write Analytics Zoo code from scratch\n\n\nOnce the user is connected to the Jupyter Notebook service and opens the address in a browser, the user can instantly click the \u201cNew\u201d button and start creating a Python notebook example in the existing Analytics Zoo Jupyter Notebook folder. \n\n\n\n\n\u201cMake a Copy\u201d from an existing Analytics Zoo Jupyter Notebook example and model after it\n\n\nThe user can also select an existing Analytics Zoo Jupyter Notebook example approximating to his own use case, then click \"Make a Copy\" and start tailing it. \n\n\n\n\n\n\nShut Down the Analytics Zoo Docker container\n\n\nUsers should shut down the Analytics Zoo Docker container after using it. \n\n\nA user can list all the active Docker containers by command line: \n\n\n$sudo docker ps\n\n\n\n\nAs a result, your docker container should be shown like: \n\n\nCONTAINER ID        IMAGE                                        COMMAND                  CREATED             STATUS              PORTS               NAMES\n40de2cdad025        intelanalytics/analytics-zoo:latest          \"/opt/work/start-n...\"   3 hours ago         Up 3 hours                               upbeat_al  \n\n\n\n\nShut down the corresponding docker container by its ID: \n\n\n$sudo docker rm -f 40de2cdad025        \n\n\n\n\n\n\nBuild a customized Analytics Zoo Docker image\n\n\nA set of pre-build Analytics Zoo Docker images have been provided on the \nDocker Hub\n. Users can retrieve these Docker images by  \u201cdocker pull\u201d command and specify a tag for which Docker image to download. For example: \n\n\nsudo docker pull intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3\nsudo docker pull intelanalytics/analytics-zoo:latest \n\n\n\n\nIt is recommended to use a pre-build Docker image on the Docker Hub. However you can build or customize an Analytics Zoo Docker image if you do need to do so. Visit Analytics Zoo \nDockerfile\n. Customize it and build the image. For example: \n\n\n\n\nBuild an Analytics Zoo Docker image with latest Analytics Zoo nightly build: \n\n\n\n\nsudo docker build --rm -t intelanalytics/analytics-zoo:default . \n\n\n\n\n\n\nBuild with http/https proxy: \n\n\n\n\nsudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --rm -t intelanalytics/analytics-zoo:default .\n\n\n\n\n\n\nBuild with specific Analytics Zoo version, BigDL version or Spark version:\n\n\n\n\nsudo docker build \\\n    --build-arg ANALYTICS_ZOO_VERSION=0.7.0 \\\n    --build-arg BIGDL_VERSION=0.12.1 \\\n    --build-arg SPARK_VERSION=2.4.3 \\\n    --rm -t intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3 .\n\n\n\n\n\n\nPre-installed Packages\n\n\nThe Analytics-Zoo Docker images have been pre-built with below packages:\n\n\n\n\n\n\ngit\n\n\n\n\n\n\nmaven\n\n\n\n\n\n\nOracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152)\n\n\n\n\n\n\npython 3.6.9\n\n\n\n\n\n\npip\n\n\n\n\n\n\nnumpy\n\n\n\n\n\n\nscipy\n\n\n\n\n\n\npandas\n\n\n\n\n\n\nscikit-learn\n\n\n\n\n\n\nmatplotlib\n\n\n\n\n\n\nseaborn\n\n\n\n\n\n\njupyter\n\n\n\n\n\n\nwordcloud\n\n\n\n\n\n\nmoviepy\n\n\n\n\n\n\nrequests\n\n\n\n\n\n\ntensorflow\n\n\n\n\n\n\nspark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION})\n\n\n\n\n\n\nAnalytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION})\n\n\n\n\n\n\nAnalytics-Zoo source code (in /opt/work/analytics-zoo)\n\n\n\n\n\n\n\n\nIn addition to the general Analytics Zoo docker image introduced in this page, the Analytics Zoo hyperzoo image is also pre-built, which is added K8s and cluster serving support. To learn about the hyperzoo imgae, visit \nhere\n.",
            "title": "Docker User Guide"
        },
        {
            "location": "/DockerUserGuide/#launch-an-analytics-zoo-docker-container",
            "text": "A Linux user (CentOS or Ubuntu) can pull a Docker image and launch the Docker container with one command line.",
            "title": "Launch an Analytics Zoo Docker Container"
        },
        {
            "location": "/DockerUserGuide/#1-getting-ready",
            "text": "Fresh install OS such as Linux OS (CentOS, Ubuntu etc), MacOS or Windows.  Download and Install Docker following the instructions on: \nhttps://docs.docker.com/get-docker/  (Optional) For Docker Desktop users on MacOS and Windows, the default resources (2 CPUs and 2GB memory) is relatively small, you may want to increase them by changing docker desktop configuration. 8GB memory and 4 CPUs should be a good estimator for most examples, and the exact memory requirements vary from different applications. For more information on this, please refer to docker documentation. ( here  for Mac and  here  for windows)  (optional) Pull an Analytics Zoo docker image  Note: It is optional to pull an Analytics Zoo docker image in advance, as the command \u201cdocker run\u201d in  Launch Analytics Zoo Docker container  step will check the availability of the docker image and pull the image if it is absent. To manually pull the latest docker image, use:    sudo docker pull intelanalytics/analytics-zoo:latest   Speed up pulling image by adding mirrors   To speed up pulling the image from dockerhub in China, add a registry's mirror. For Linux OS (CentOS, Ubuntu etc), if the docker version is higher than 1.12, config the docker daemon. Edit  /etc/docker/daemon.json  and add the registry-mirrors key and value:  {\n  \"registry-mirrors\": [\"https://<my-docker-mirror-host>\"]\n}  For example, add the ustc mirror in China.  {\n  \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]\n}  Flush changes and restart docker\uff1a  sudo systemctl daemon-reload\nsudo systemctl restart docker  If your docker version is between 1.8 and 1.11, find the docker configuration which location depends on the operation system. Edit and add  DOCKER_OPTS=\"--registry-mirror=https://<my-docker-mirror-host>\" . Restart docker  sudo service docker restart .  If you would like to speed up pulling this image on MacOS or Windows, find the docker setting and config registry-mirrors section by specifying mirror host. Restart docker.  Then pull the image. It will be faster.  sudo docker pull intelanalytics/analytics-zoo:latest",
            "title": "1. Getting Ready"
        },
        {
            "location": "/DockerUserGuide/#2-launch-analytics-zoo-docker-container",
            "text": "Launch an Analytics Zoo Docker container with this command line:   $sudo docker run -it --rm --net=host -e NotebookPort=12345 -e NotebookToken=\"your-token\" intelanalytics/analytics-zoo:latest bash   The value 12345 is a user specified port number.   The value \"your-token\" is a user specified string.   If you want to specify an Analytics Zoo version, for example 0.7.0, use:   sudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3 bash  If you need to use http/https proxy, use:    sudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default bash  Once the container is sucessfully launched, you will automatically login to the container and see this as the output:   root@[hostname]:/opt/work#  Note: The /opt/work directory contains:     download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.    start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a - specified jupyter notebook.    analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution.    analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution.    spark-${SPARK_VERSION} is the Spark home.    analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.",
            "title": "2. Launch Analytics Zoo Docker container"
        },
        {
            "location": "/DockerUserGuide/#run-analytics-zoo-jupyter-notebook-example-in-a-container",
            "text": "This section depends on the previous section  \u201cLaunch Analytics Zoo Docker container\u201d . After the user launches the Analytics Zoo Docker container, the Jupyter Notebook service can be started and Analytics Zoo Jupyter Notebook examples are available.",
            "title": "Run Analytics Zoo Jupyter Notebook example in a container"
        },
        {
            "location": "/DockerUserGuide/#start-the-jupyter-notebook-service-in-the-container",
            "text": "After a Docker container is launched and user login to the container, user can start the Jupyter Notebook service inside the container.   In the /opt/work directory, run this command line to start the Jupyter Notebook service:  #start-notebook.sh  As a result, you will see the output message like below. This means the Jupyter Notebook service has started successfully within the container.  [I 01:04:45.625 NotebookApp] Serving notebooks from local directory: /opt/work/analytics-zoo-0.5.0-SNAPSHOT/apps\n[I 01:04:45.625 NotebookApp] The Jupyter Notebook is running at:\n[I 01:04:45.625 NotebookApp] http://(the-host-name or 127.0.0.1):12345/?token=...\n[I 01:04:45.625 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).",
            "title": "Start the Jupyter Notebook service in the container"
        },
        {
            "location": "/DockerUserGuide/#connect-to-jupyter-notebook-service-from-a-browser",
            "text": "After the Jupyter Notebook service is successfully started, users can connect to the Jupyter Notebook service from a browser.    Get the IP address of the container  Launch a browser, and connect to the Jupyter Notebook service with the URL: \nhttps://container-ip-address:port-number/?token=your-token   As a result, you will see the Jupyter Notebook like this:",
            "title": "Connect to Jupyter Notebook service from a browser"
        },
        {
            "location": "/DockerUserGuide/#run-analytics-zoo-jupyter-notebook-examples",
            "text": "After connecting to the Jupyter Notebook in the browser, users can run multiple Analytics Zoo Jupyter Notebook examples. The example shown below is the \u201cdogs-vs-cats\u201d.    Click into the \"dogs-vs-cats\" folder:      Open the notebook file:      Start to run the \"dogs-vs-cats\" notebook:     Run through the example and check the prediction:",
            "title": "Run Analytics Zoo Jupyter Notebook examples"
        },
        {
            "location": "/DockerUserGuide/#create-a-new-analytics-zoo-jupyter-notebook-example",
            "text": "There are a few ways to quickly start creating a new Analytics Zoo Jupyter Notebook example. Users can \u201cNew\u201d a Python notebook from scratch, or use the existing Jupyter Notebook example as an template and modify based on it.",
            "title": "Create a new Analytics Zoo Jupyter Notebook example"
        },
        {
            "location": "/DockerUserGuide/#new-a-jupyter-notebook-and-write-analytics-zoo-code-from-scratch",
            "text": "Once the user is connected to the Jupyter Notebook service and opens the address in a browser, the user can instantly click the \u201cNew\u201d button and start creating a Python notebook example in the existing Analytics Zoo Jupyter Notebook folder.",
            "title": "\u201cNew\u201d a Jupyter Notebook and write Analytics Zoo code from scratch"
        },
        {
            "location": "/DockerUserGuide/#make-a-copy-from-an-existing-analytics-zoo-jupyter-notebook-example-and-model-after-it",
            "text": "The user can also select an existing Analytics Zoo Jupyter Notebook example approximating to his own use case, then click \"Make a Copy\" and start tailing it.",
            "title": "\u201cMake a Copy\u201d from an existing Analytics Zoo Jupyter Notebook example and model after it"
        },
        {
            "location": "/DockerUserGuide/#shut-down-the-analytics-zoo-docker-container",
            "text": "Users should shut down the Analytics Zoo Docker container after using it.   A user can list all the active Docker containers by command line:   $sudo docker ps  As a result, your docker container should be shown like:   CONTAINER ID        IMAGE                                        COMMAND                  CREATED             STATUS              PORTS               NAMES\n40de2cdad025        intelanalytics/analytics-zoo:latest          \"/opt/work/start-n...\"   3 hours ago         Up 3 hours                               upbeat_al    Shut down the corresponding docker container by its ID:   $sudo docker rm -f 40de2cdad025",
            "title": "Shut Down the Analytics Zoo Docker container"
        },
        {
            "location": "/DockerUserGuide/#build-a-customized-analytics-zoo-docker-image",
            "text": "A set of pre-build Analytics Zoo Docker images have been provided on the  Docker Hub . Users can retrieve these Docker images by  \u201cdocker pull\u201d command and specify a tag for which Docker image to download. For example:   sudo docker pull intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3\nsudo docker pull intelanalytics/analytics-zoo:latest   It is recommended to use a pre-build Docker image on the Docker Hub. However you can build or customize an Analytics Zoo Docker image if you do need to do so. Visit Analytics Zoo  Dockerfile . Customize it and build the image. For example:    Build an Analytics Zoo Docker image with latest Analytics Zoo nightly build:    sudo docker build --rm -t intelanalytics/analytics-zoo:default .    Build with http/https proxy:    sudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --rm -t intelanalytics/analytics-zoo:default .   Build with specific Analytics Zoo version, BigDL version or Spark version:   sudo docker build \\\n    --build-arg ANALYTICS_ZOO_VERSION=0.7.0 \\\n    --build-arg BIGDL_VERSION=0.12.1 \\\n    --build-arg SPARK_VERSION=2.4.3 \\\n    --rm -t intelanalytics/analytics-zoo:0.7.0-bigdl_0.10.0-spark_2.4.3 .",
            "title": "Build a customized Analytics Zoo Docker image"
        },
        {
            "location": "/DockerUserGuide/#pre-installed-packages",
            "text": "The Analytics-Zoo Docker images have been pre-built with below packages:    git    maven    Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152)    python 3.6.9    pip    numpy    scipy    pandas    scikit-learn    matplotlib    seaborn    jupyter    wordcloud    moviepy    requests    tensorflow    spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION})    Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION})    Analytics-Zoo source code (in /opt/work/analytics-zoo)     In addition to the general Analytics Zoo docker image introduced in this page, the Analytics Zoo hyperzoo image is also pre-built, which is added K8s and cluster serving support. To learn about the hyperzoo imgae, visit  here .",
            "title": "Pre-installed Packages"
        },
        {
            "location": "/PythonUserGuide/install/",
            "text": "For Python users, Analytics Zoo can be installed either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: We have tested on \nPython 3.6\n and \nPython 3.7\n. Support for Python 2.7 has been removed due to its end of life.\n\n\n\n\nInstall the latest nightly build wheels for pip\n\n\nYou can find the list of the latest nightly build wheels for pip \nhere\n. \nChoose a wheel with timestamp for your platform and click to download it to your local repository.\n\n\nNote that if you are using Linux, you need to choose the file \nanalytics_zoo-VERSION-TIMESTAMP-py2.py3-none-manylinux1_x86_64.whl\n.\nIf you are using Mac, choose \nanalytics_zoo-VERSION-TIMESTAMP-py2.py3-none-macosx_10_11_x86_64.whl\n instead. \n\n\nAfter downloading the target wheel file, go to the download directory and run the following command:\n\n\npip install analytics_zoo-*-py2.py3-none-*_x86_64.whl\n\n\n\n\nSee \nhere\n for some remarks with regard to pip install.\n\n\n\n\nInstall from pip for local usage\n\n\nYou can use the following command to install the latest release version of \nanalytics-zoo\n via pip easily:\n\n\npip install analytics-zoo\n\n\n\n\n\n\nYou are strongly recommended to use Python 3.6 or 3.7. You might need to run \npip3 install analytics-zoo\n instead.\n\n\nYou might need to add \nsudo\n if you don't have the permission for installation.\n\n\nSee \nhere\n if you want to install the latest nightly build version.\n\n\n\n\nImportant:\n\n\n\n\n\n\nInstalling analytics-zoo from pip will automatically install \npyspark\n. To avoid possible conflicts, you are highly recommended to \nunset \nSPARK_HOME\n if it exists in your environment.\n\n\n\n\n\n\nPlease always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\n\n\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nRemarks:\n\n\n\n\nWe've tested this package with pip 9.0.1. \npip install --upgrade pip\n if necessary.\n\n\nPip install supports \nMac\n and \nLinux\n platforms.\n\n\nYou need to install Java \n>= JDK8\n before running Analytics Zoo, which is required by \npyspark\n.\n\n\nbigdl==0.12.1\n, \npyspark==2.4.3\n, \nconda-pack==0.3.1\n and their dependencies will be automatically installed if they haven't been detected in the current Python environment.\n\n\n\n\n\n\nInstall from pip for Yarn cluster\n\n\nYou only need to following these steps on your driver node and we only support \nyarn-client mode\n for now.\n\n\n1) Install \nConda\n in your environment.\n\n\n2) Create a new conda environment (with name \"zoo\" for example):\n\n\nconda create -n zoo python=3.6\nsource activate zoo\n\n\n\n\n3) Install the latest release version of \nanalytics-zoo\n into the created conda environment.\n\n\npip install analytics-zoo\n\n\n\n\nSee \nhere\n if you want to install the latest nightly build version.\n\n\n4) Download JDK8 and set the environment variable: JAVA_HOME (recommended).\n\n\nYou can also install JDK via conda without setting the JAVA_HOME manually:\n\n\nconda install -c anaconda openjdk=8.0.152\n\n\n5) Start \npython\n and then execute the following code to create a SparkContext on Yarn for verification:\n\n\nfrom zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")\n\n\n\n\n\n\nInstall without pip\n\n\nIf you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.\n\n\nSteps:\n\n\n\n\n\n\nDownload Spark\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and >=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\n\n\n\n\nYou are recommended to download Analytics Zoo prebuilt release package from the \nRelease Page\n and extract it.\nAlternatively, you can also build the Analytics Zoo from \nsource\n.\n\n\n\n\n\n\nInstall Python dependencies. Analytics Zoo only depends on \nnumpy\n and \nsix\n for now.\n\n\n\n\n\n\nFor Spark standalone cluster\n\n\n\n\nRemark\n: If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.\n\n\nInstall numpy: \n\nsudo apt-get install python-numpy\n (Ubuntu)\n\n\nInstall six: \n\nsudo apt-get install python-six\n (Ubuntu)\n\n\n\n\nFor Yarn cluster\n\n\nYou can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).\n\n\nYou can first package all the required dependencies into a conda environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that conda environment.\n\n\nFollow the steps below to create the conda environment:\n\n\n1) Install \nConda\n in your environment.\n\n\n2) Create a new conda environment (with name \"environment\" for example):\n\n\nconda create -n environment python=3.6 pip=20.0.2 setuptools=45.2.0 conda-pack==0.3.1\nconda activate environment\n\n\n\n\n3) Install python dependencies into the created conda environment.\nInstall the dependencies according to the dependencies listed in \nrequirements.txt\n. You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.\n\n\npip install -r ${ANALYTICS_ZOO_HOME}/bin/requirements.txt\n\n\n\n\n4) Create conda package for the created conda environment\n\n\nconda pack -o environment.tar.gz\n\n\n\n\nThen you can find the conda package file under the current directory.",
            "title": "Install"
        },
        {
            "location": "/PythonUserGuide/install/#install-the-latest-nightly-build-wheels-for-pip",
            "text": "You can find the list of the latest nightly build wheels for pip  here . \nChoose a wheel with timestamp for your platform and click to download it to your local repository.  Note that if you are using Linux, you need to choose the file  analytics_zoo-VERSION-TIMESTAMP-py2.py3-none-manylinux1_x86_64.whl .\nIf you are using Mac, choose  analytics_zoo-VERSION-TIMESTAMP-py2.py3-none-macosx_10_11_x86_64.whl  instead.   After downloading the target wheel file, go to the download directory and run the following command:  pip install analytics_zoo-*-py2.py3-none-*_x86_64.whl  See  here  for some remarks with regard to pip install.",
            "title": "Install the latest nightly build wheels for pip"
        },
        {
            "location": "/PythonUserGuide/install/#install-from-pip-for-local-usage",
            "text": "You can use the following command to install the latest release version of  analytics-zoo  via pip easily:  pip install analytics-zoo   You are strongly recommended to use Python 3.6 or 3.7. You might need to run  pip3 install analytics-zoo  instead.  You might need to add  sudo  if you don't have the permission for installation.  See  here  if you want to install the latest nightly build version.   Important:    Installing analytics-zoo from pip will automatically install  pyspark . To avoid possible conflicts, you are highly recommended to  unset  SPARK_HOME  if it exists in your environment.    Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.    from zoo.common.nncontext import *\nsc = init_nncontext()  Remarks:   We've tested this package with pip 9.0.1.  pip install --upgrade pip  if necessary.  Pip install supports  Mac  and  Linux  platforms.  You need to install Java  >= JDK8  before running Analytics Zoo, which is required by  pyspark .  bigdl==0.12.1 ,  pyspark==2.4.3 ,  conda-pack==0.3.1  and their dependencies will be automatically installed if they haven't been detected in the current Python environment.",
            "title": "Install from pip for local usage"
        },
        {
            "location": "/PythonUserGuide/install/#install-from-pip-for-yarn-cluster",
            "text": "You only need to following these steps on your driver node and we only support  yarn-client mode  for now.  1) Install  Conda  in your environment.  2) Create a new conda environment (with name \"zoo\" for example):  conda create -n zoo python=3.6\nsource activate zoo  3) Install the latest release version of  analytics-zoo  into the created conda environment.  pip install analytics-zoo  See  here  if you want to install the latest nightly build version.  4) Download JDK8 and set the environment variable: JAVA_HOME (recommended).  You can also install JDK via conda without setting the JAVA_HOME manually:  conda install -c anaconda openjdk=8.0.152  5) Start  python  and then execute the following code to create a SparkContext on Yarn for verification:  from zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")",
            "title": "Install from pip for Yarn cluster"
        },
        {
            "location": "/PythonUserGuide/install/#install-without-pip",
            "text": "If you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.  Steps:    Download Spark   Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and >=2.2.0. See  this issue  for more discussion.     You are recommended to download Analytics Zoo prebuilt release package from the  Release Page  and extract it.\nAlternatively, you can also build the Analytics Zoo from  source .    Install Python dependencies. Analytics Zoo only depends on  numpy  and  six  for now.",
            "title": "Install without pip"
        },
        {
            "location": "/PythonUserGuide/install/#for-spark-standalone-cluster",
            "text": "Remark : If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.  Install numpy:  sudo apt-get install python-numpy  (Ubuntu)  Install six:  sudo apt-get install python-six  (Ubuntu)",
            "title": "For Spark standalone cluster"
        },
        {
            "location": "/PythonUserGuide/install/#for-yarn-cluster",
            "text": "You can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).  You can first package all the required dependencies into a conda environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that conda environment.  Follow the steps below to create the conda environment:  1) Install  Conda  in your environment.  2) Create a new conda environment (with name \"environment\" for example):  conda create -n environment python=3.6 pip=20.0.2 setuptools=45.2.0 conda-pack==0.3.1\nconda activate environment  3) Install python dependencies into the created conda environment.\nInstall the dependencies according to the dependencies listed in  requirements.txt . You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.  pip install -r ${ANALYTICS_ZOO_HOME}/bin/requirements.txt  4) Create conda package for the created conda environment  conda pack -o environment.tar.gz  Then you can find the conda package file under the current directory.",
            "title": "For Yarn cluster"
        },
        {
            "location": "/PythonUserGuide/run/",
            "text": "You need to first \ninstall\n analytics-zoo, either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: We have tested on \nPython 3.6\n and \nPython 3.7\n. Support for Python 2.7 has been removed due to its end of life.\n\n\n\n\nRun after pip install\n\n\nImportant:\n\n\n\n\n\n\nInstalling analytics-zoo from pip will automatically install \npyspark\n. To avoid possible conflicts, you are highly recommended to \nunset \nSPARK_HOME\n if it exists in your environment.\n\n\n\n\n\n\nPlease always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\n\n\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nUse an Interactive Shell\n\n\n\n\nType \npython\n in the command line to start a REPL.\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nUse Jupyter Notebook\n\n\n\n\nStart jupyter notebook as you normally do, e.g.\n\n\n\n\njupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nConfigurations\n\n\n\n\nIncrease memory\n\n\n\n\nexport SPARK_DRIVER_MEMORY=20g\n\n\n\n\n\n\nAdd extra jars or python packages\n\n\n\n\n\u2003 Set the environment variables \nBIGDL_JARS\n and \nBIGDL_PACKAGES\n \nBEFORE\n creating \nSparkContext\n:\n\n\nexport BIGDL_JARS=...\nexport BIGDL_PACKAGES=...\n\n\n\n\n\n\nRun on Yarn after pip install\n\n\nYou should use \ninit_spark_on_yarn\n rather than \ninit_nncontext()\n here to create a SparkContext on Yarn.\n\n\nStart python and then execute the following code:\n\n\nfrom zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")\n\n\n\n\n\n\nRun without pip install\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and >=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nSet SPARK_HOME and ANALYTICS_ZOO_HOME\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo\n\n\n\n\nUpdate spark-analytics-zoo.conf (Optional)\n\n\nIf you have some customized properties in some files, which will be used with the \n--properties-file\n option\nin \nspark-submit/pyspark\n, you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.\n\n\n\n\nRun with pyspark\n\n\n${ANALYTICS_ZOO_HOME}/bin/pyspark-shell-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with spark-submit\n\n\nAn Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo \nObject Detection Python example\n\nas follows:\n\n\n${ANALTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh --master local[*] predict.py model_path image_path output_path\n\n\n\n\n\n\nRun with Jupyter Notebook\n\n\nWith the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.\n\n\nPrerequisites\n: Install all the necessary libraries on the local node where you will run Jupyter, e.g., \n\n\nsudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud\n\n\n\n\nLaunch the Jupyter Notebook as follows:\n\n\n${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nAfter successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with conda environment on Yarn\n\n\nIf you have already created Analytics Zoo dependency conda environment package according to Yarn cluster guide \nhere\n,\nyou can run Python programs using Analytics Zoo using the following command.\n\n\nHere we use Analytics Zoo \nObject Detection Python example\n for illustration.\n\n\n\n\nYarn cluster mode (with conda package name \"environment.tar.gz\" for example)\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport ENV_HOME=the parent directory of your conda environment package\n\nPYSPARK_PYTHON=./environment/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./environment/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --archives ${ENV_HOME}/environment.tar.gz#environment \\\n    predict.py model_path image_path output_path\n\n\n\n\n\n\nYarn client mode (with conda package name \"environment.tar.gz\" for example)\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport ENV_HOME=the parent directory of your conda environment package\n\nmkdir ${ENV_HOME}/environment\ntar -xzf ${ENV_HOME}/environment.tar.gz -C ${ENV_HOME}/environment\n\nPYSPARK_DRIVER_PYTHON=${ENV_HOME}/environment/bin/python PYSPARK_PYTHON=./environment/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --archives ${ENV_HOME}/environment.tar.gz#environment \\\n    predict.py model_path image_path output_path\n\n\n\n\n\n\nExample code\n\n\nTo verify if Analytics Zoo can run successfully, run the following simple code:\n\n\nimport zoo\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))",
            "title": "Run"
        },
        {
            "location": "/PythonUserGuide/run/#run-after-pip-install",
            "text": "Important:    Installing analytics-zoo from pip will automatically install  pyspark . To avoid possible conflicts, you are highly recommended to  unset  SPARK_HOME  if it exists in your environment.    Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.    from zoo.common.nncontext import *\nsc = init_nncontext()  Use an Interactive Shell   Type  python  in the command line to start a REPL.  Try to run the  example code  to verify the installation.   Use Jupyter Notebook   Start jupyter notebook as you normally do, e.g.   jupyter notebook --notebook-dir=./ --ip=* --no-browser   Try to run the  example code  to verify the installation.   Configurations   Increase memory   export SPARK_DRIVER_MEMORY=20g   Add extra jars or python packages   \u2003 Set the environment variables  BIGDL_JARS  and  BIGDL_PACKAGES   BEFORE  creating  SparkContext :  export BIGDL_JARS=...\nexport BIGDL_PACKAGES=...",
            "title": "Run after pip install"
        },
        {
            "location": "/PythonUserGuide/run/#run-on-yarn-after-pip-install",
            "text": "You should use  init_spark_on_yarn  rather than  init_nncontext()  here to create a SparkContext on Yarn.  Start python and then execute the following code:  from zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")",
            "title": "Run on Yarn after pip install"
        },
        {
            "location": "/PythonUserGuide/run/#run-without-pip-install",
            "text": "Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and >=2.2.0. See  this issue  for more discussion.   Set SPARK_HOME and ANALYTICS_ZOO_HOME   If you download Analytics Zoo from the  Release Page :   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package   If you build Analytics Zoo by yourself:   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo  Update spark-analytics-zoo.conf (Optional)  If you have some customized properties in some files, which will be used with the  --properties-file  option\nin  spark-submit/pyspark , you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.",
            "title": "Run without pip install"
        },
        {
            "location": "/PythonUserGuide/run/#run-with-pyspark",
            "text": "${ANALYTICS_ZOO_HOME}/bin/pyspark-shell-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  Try to run the  example code  for verification.",
            "title": "Run with pyspark"
        },
        {
            "location": "/PythonUserGuide/run/#run-with-spark-submit",
            "text": "An Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo  Object Detection Python example \nas follows:  ${ANALTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh --master local[*] predict.py model_path image_path output_path",
            "title": "Run with spark-submit"
        },
        {
            "location": "/PythonUserGuide/run/#run-with-jupyter-notebook",
            "text": "With the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.  Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g.,   sudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud  Launch the Jupyter Notebook as follows:  ${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/  Try to run the  example code  for verification.",
            "title": "Run with Jupyter Notebook"
        },
        {
            "location": "/PythonUserGuide/run/#run-with-conda-environment-on-yarn",
            "text": "If you have already created Analytics Zoo dependency conda environment package according to Yarn cluster guide  here ,\nyou can run Python programs using Analytics Zoo using the following command.  Here we use Analytics Zoo  Object Detection Python example  for illustration.   Yarn cluster mode (with conda package name \"environment.tar.gz\" for example)   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport ENV_HOME=the parent directory of your conda environment package\n\nPYSPARK_PYTHON=./environment/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./environment/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --archives ${ENV_HOME}/environment.tar.gz#environment \\\n    predict.py model_path image_path output_path   Yarn client mode (with conda package name \"environment.tar.gz\" for example)   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport ENV_HOME=the parent directory of your conda environment package\n\nmkdir ${ENV_HOME}/environment\ntar -xzf ${ENV_HOME}/environment.tar.gz -C ${ENV_HOME}/environment\n\nPYSPARK_DRIVER_PYTHON=${ENV_HOME}/environment/bin/python PYSPARK_PYTHON=./environment/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-python-with-zoo.sh \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --archives ${ENV_HOME}/environment.tar.gz#environment \\\n    predict.py model_path image_path output_path",
            "title": "Run with conda environment on Yarn"
        },
        {
            "location": "/PythonUserGuide/run/#example-code",
            "text": "To verify if Analytics Zoo can run successfully, run the following simple code:  import zoo\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))",
            "title": "Example code"
        },
        {
            "location": "/DeveloperGuide/python/",
            "text": "This page gives some general instructions and tips to build and develop Analytics Zoo for Python developers.\n\n\nYou are very welcome to add customized functionalities to Analytics Zoo to meet your own demands. \nYou are also highly encouraged to contribute to Analytics Zoo for extra features so that other community users would get benefits as well.\n\n\n\n\nDownload Analytics Zoo Source Code\n\n\nAnalytics Zoo source code is available at \nGitHub\n:\n\n\ngit clone https://github.com/intel-analytics/analytics-zoo.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of Analytics Zoo. If you want a release version, you can use the command \ngit checkout\n to change the specified version.\n\n\n\n\nBuild whl package for pip install\n\n\nIf you have modified some Python code and want to newly generate the \nwhl\n package for pip install, you can run the following script:\n\n\nbash analytics-zoo/pyzoo/dev/build.sh linux default\n\n\n\n\nArguments:\n\n\n\n\nThe first argument is the \nplatform\n to build for. Either 'linux' or 'mac'.\n\n\nThe second argument is the analytics-zoo \nversion\n to build for. 'default' means the default version for the current branch. You can also specify a different version if you wish, e.g., '0.6.0.dev1'.\n\n\nYou can also add other profiles to build the package, especially Spark and BigDL versions.\nFor example, under the situation that \npyspark==2.4.3\n is a dependency, you need to add profiles \n-Dspark.version=2.4.3 -Dbigdl.artifactId=bigdl-SPARK_2.4 -P spark_2.4+\n to build Analytics Zoo for Spark 2.4.3.\n\n\n\n\nAfter running the above command, you will find a \nwhl\n file under the folder \nanalytics-zoo/pyzoo/dist/\n. You can then directly pip install it to your local Python environment:\n\n\npip install analytics-zoo/pyzoo/dist/analytics_zoo-VERSION-py2.py3-none-PLATFORM_x86_64.whl\n\n\n\n\nSee \nhere\n for more remarks related to pip install.\n\n\nSee \nhere\n for more instructions to run analytics-zoo after pip install.\n\n\n\n\nRun in IDE\n\n\nYou need to do the following preparations before starting the Integrated Development Environment (IDE) to successfully run an Analytics Zoo Python program in the IDE:\n\n\n\n\nBuild Analytics Zoo. See \nhere\n for more instructions.\n\n\nPrepare Spark environment by either setting \nSPARK_HOME\n as the environment variable or pip install \npyspark\n. Note that the Spark version should match the one you build Analytics Zoo on.\n\n\nSet BIGDL_CLASSPATH:\n\n\n\n\nexport BIGDL_CLASSPATH=analytics-zoo/dist/lib/analytics-zoo-*-jar-with-dependencies.jar\n\n\n\n\n\n\nPrepare BigDL Python environment by either downloading BigDL from \nGitHub\n or pip install \nbigdl\n. Note that the BigDL version should match the one you build Analytics Zoo on.\n\n\nAdd \npyzoo\n and \nspark-analytics-zoo.conf\n to \nPYTHONPATH\n:\n\n\n\n\nexport PYTHONPATH=analytics-zoo/pyzoo:analytics-zoo/dist/conf/spark-analytics-zoo.conf:$PYTHONPATH\n\n\n\n\nIf you download BigDL from \nGitHub\n, you also need to add \nBigDL/pyspark\n to \nPYTHONPATH\n:\n\n\nexport PYTHONPATH=BigDL/pyspark:$PYTHONPATH",
            "title": "Develop"
        },
        {
            "location": "/DeveloperGuide/python/#download-analytics-zoo-source-code",
            "text": "Analytics Zoo source code is available at  GitHub :  git clone https://github.com/intel-analytics/analytics-zoo.git  By default,  git clone  will download the development version of Analytics Zoo. If you want a release version, you can use the command  git checkout  to change the specified version.",
            "title": "Download Analytics Zoo Source Code"
        },
        {
            "location": "/DeveloperGuide/python/#build-whl-package-for-pip-install",
            "text": "If you have modified some Python code and want to newly generate the  whl  package for pip install, you can run the following script:  bash analytics-zoo/pyzoo/dev/build.sh linux default  Arguments:   The first argument is the  platform  to build for. Either 'linux' or 'mac'.  The second argument is the analytics-zoo  version  to build for. 'default' means the default version for the current branch. You can also specify a different version if you wish, e.g., '0.6.0.dev1'.  You can also add other profiles to build the package, especially Spark and BigDL versions.\nFor example, under the situation that  pyspark==2.4.3  is a dependency, you need to add profiles  -Dspark.version=2.4.3 -Dbigdl.artifactId=bigdl-SPARK_2.4 -P spark_2.4+  to build Analytics Zoo for Spark 2.4.3.   After running the above command, you will find a  whl  file under the folder  analytics-zoo/pyzoo/dist/ . You can then directly pip install it to your local Python environment:  pip install analytics-zoo/pyzoo/dist/analytics_zoo-VERSION-py2.py3-none-PLATFORM_x86_64.whl  See  here  for more remarks related to pip install.  See  here  for more instructions to run analytics-zoo after pip install.",
            "title": "Build whl package for pip install"
        },
        {
            "location": "/DeveloperGuide/python/#run-in-ide",
            "text": "You need to do the following preparations before starting the Integrated Development Environment (IDE) to successfully run an Analytics Zoo Python program in the IDE:   Build Analytics Zoo. See  here  for more instructions.  Prepare Spark environment by either setting  SPARK_HOME  as the environment variable or pip install  pyspark . Note that the Spark version should match the one you build Analytics Zoo on.  Set BIGDL_CLASSPATH:   export BIGDL_CLASSPATH=analytics-zoo/dist/lib/analytics-zoo-*-jar-with-dependencies.jar   Prepare BigDL Python environment by either downloading BigDL from  GitHub  or pip install  bigdl . Note that the BigDL version should match the one you build Analytics Zoo on.  Add  pyzoo  and  spark-analytics-zoo.conf  to  PYTHONPATH :   export PYTHONPATH=analytics-zoo/pyzoo:analytics-zoo/dist/conf/spark-analytics-zoo.conf:$PYTHONPATH  If you download BigDL from  GitHub , you also need to add  BigDL/pyspark  to  PYTHONPATH :  export PYTHONPATH=BigDL/pyspark:$PYTHONPATH",
            "title": "Run in IDE"
        },
        {
            "location": "/PythonUserGuide/python-lib-version/",
            "text": "This page documents and describes Python library versions that Analytics Zoo supports. We have tested these libraries on Python 3.6 and Python 3.7.\n\n\nName & version\n\nbayesian-optimization==1.1.0\ndask==2.14.0\nh5py==2.10.0\nhorovod==0.19.2\nimageio==2.8.0\nimageio-ffmpeg==0.4.1\nKeras==1.2.2\nmoviepy==1.0.1\nmxnet==1.6.0\nnumpy==1.18.1\nopencv-python==4.2.0.34\npandas==1.0.3\nPillow==7.1.1\nprotobuf==3.11.4\npsutil==5.7.0\npyarrow==0.17.0\npy4j==0.10.7\npyspark==2.4.3\nray==0.8.4\nredis==3.4.1\nscikit-learn==0.22.2.post1\nscipy==1.4.1\nsix==1.14.0\ntensorboard==1.15.0\ntensorboardX==2.0\ntensorflow==1.15.0\ntensorflow-datasets==3.2.0\ntensorflow-estimator==1.15.1\ntensorflow-gan==2.0.0\ntensorflow-hub==0.8.0\ntensorflow-metadata==0.21.1\ntensorflow-probability==0.7.0\nTheano==1.0.4\ntorch==1.7.1\ntorchvision==0.8.2",
            "title": "Library version"
        },
        {
            "location": "/PythonUserGuide/python-faq/",
            "text": "This page lists solutions to some common questions.\n\n\n\n\n\n\nImportError\n: from zoo.pipeline.api.keras.layers import *\n\n\n\n\nCheck if the path is pointing to python-api.zip: \n--py-files ${ANALYTICS_ZOO_PY_ZIP}\n\n\nCheck if the path is pointing to python-api.zip:\n\n\n\n\nexport PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n\n\n\n\n\n\nPython in worker has a different version than that in driver\n\n\n\n\nexport PYSPARK_PYTHON=/usr/local/bin/python3.6\n  This path should be valid on every worker node.\n\n\nexport PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.6\n  This path should be valid on every driver node.\n\n\n\n\n\n\n\n\nTypeError\n: 'JavaPackage' object is not callable\n\n\n\n\nCheck if every path within the launch script is valid especially the path that ends with jar.\n\n\nIf there are extra jars involved, check if the Spark version Analytics Zoo is built and the Spark version the extra jar is built are compatible.\n\n\n\n\n\n\n\n\njava.lang.\nNoSuchMethodError\n:XXX or \nPy4JError\n: ofFloat does not exist in the JVM\n\n\n\n\nCheck if the Spark version matches, i.e check if you are using Spark 2.x but the underneath Analytics Zoo is compiled with Spark 1.6.\n\n\nIf there are extra jars involved, also check if the Spark version matches.",
            "title": "FAQ"
        },
        {
            "location": "/ScalaUserGuide/install/",
            "text": "Download a pre-built library\n\n\nYou can download the Analytics Zoo release and nightly build from the \nRelease Page\n\n\n\n\nLink with a release version\n\n\nCurrently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:\n\n\n<dependency>\n    <groupId>com.intel.analytics.zoo</groupId>\n    <artifactId>analytics-zoo-bigdl_0.12.1-[spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.3|spark_3.0.0]</artifactId>\n    <version>${ANALYTICS_ZOO_VERSION}</version>\n</dependency>\n\n\n\n\nYou can find the latest ANALYTICS_ZOO_VERSION \nhere\n.  \n\n\nSBT developers can use\n\n\nlibraryDependencies += \"com.intel.analytics.zoo\" % \"analytics-zoo-bigdl_0.12.1-[spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.3|spark_3.0.0]\" % \"${ANALYTICS_ZOO_VERSION}\"\n\n\n\n\nRemarks:\n\n\n\n\nPlease choose the available suffix above according to your Spark platform you want to use.\n\n\nYou don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo.\n\n\nYou can find the option \n${ANALYTICS_ZOO_VERSION}\n from the \nRelease Page\n.\n\n\n\n\n\n\nLink with a development version\n\n\nCurrently, Analytics Zoo development version is hosted on \nSonaType\n.\n\n\nTo link your application with the latest Analytics Zoo development version, you should add some dependencies like \nLinking with Analytics Zoo releases\n, but set \n${ANALYTICS_ZOO_VERSION}\n to latest version, and add below repository to your pom.xml.\n\n\n<repository>\n    <id>sonatype</id>\n    <name>sonatype repository</name>\n    <url>https://oss.sonatype.org/content/groups/public/</url>\n    <releases>\n        <enabled>true</enabled>\n    </releases>\n    <snapshots>\n        <enabled>true</enabled>\n    </snapshots>\n</repository>\n\n\n\n\nSBT developers can use\n\n\nresolvers += \"ossrh repository\" at \"https://oss.sonatype.org/content/repositories/snapshots/\"\n\n\n\n\nDownload Analytics Zoo Source\n\n\nAnalytics Zoo source code is available at \nGitHub\n.\n\n\n$ git clone https://github.com/intel-analytics/analytics-zoo.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of Analytics Zoo, if you want a release version, you can use command \ngit checkout\n to change the version.\n\n\nSetup Build Environment\n\n\nThe following instructions are aligned with master code.\n\n\nMaven 3 is needed to build Analytics Zoo, you can download it from the \nmaven website\n.\n\n\nAfter installing Maven 3, please set the environment variable MAVEN_OPTS as follows:\n\n\n$ export MAVEN_OPTS=\"-Xmx2g -XX:ReservedCodeCacheSize=512m\"\n\n\n\n\nWhen compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.\n\n\nBuild with script (Recommended)\n\n\nIt is highly recommended that you build Analytics Zoo using the \nmake-dist.sh script\n. And it will handle the MAVEN_OPTS variable.\n\n\nOnce downloaded, you can build Analytics Zoo with the following commands:\n\n\n$ bash make-dist.sh\n\n\n\n\nAfter that, you can find a \ndist\n folder, which contains all the needed files to run a Analytics Zoo program. The files in \ndist\n include:\n\n\n\n\ndist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n: This jar package contains all dependencies except Spark classes.\n\n\ndist/lib/analytics-zoo-VERSION-python-api.zip\n: This zip package contains all Python files of Analytics Zoo.\n\n\n\n\nThe instructions above will build Analytics Zoo with Spark 2.1.0. It is highly recommended to use \nJava 8\n when running with Spark 2.x; otherwise you may observe very poor performance.\n\n\nBuild with Spark version\n\n\nBy default, \nmake-dist.sh\n uses Spark 2.1.0. To override the default behaviors, for example building analytics-zoo with spark 2.2.0, you can use \nbash make-dist.sh -Dspark.version=2.2.0 -Dbigdl.artifactId=bigdl_SPARK_2.2\n.\n\nAdditionally, we provide a profile to build with spark 2.4, you can use \nbash make-dist.sh -P spark_2.4+\n.\n\n\n\n\nBuild with Maven\n\n\nTo build Analytics Zoo directly using Maven, run the command below:\n\n\n$ mvn clean package -DskipTests\n\n\n\n\nAfter that, you can find that jar packages in \nPATH_TO_ANALYTICS_ZOO\n/target/, where \nPATH_TO_ANALYTICS_ZOO\n is the path to the directory of the Analytics Zoo.\n\n\nNote that the instructions above will build Analytics Zoo with Spark 2.1.0 for Linux. Similarly, you may customize spark version like \nabove\n.\n\n\n\n\nBuild with JDK 11\n\n\nIt's recommended to download \nOracle JDK 11\n. And it will avoid possible incompatibility with maven plugins. Update PATH and make sure your JAVA_HOME environment variable is set to Java 11 if you're running from the command line. Or if you're running from an IDE, you need to make sure it is set to run maven with your current JDK.\n\n\nJdk 11 supports few Scala versions. You can see scala version compatibility \ndescription\n. Analytics Zoo supports Spark3 with Scala 2.12. You can use \n-P spark_3.x\n to specify Spark3 and scala 2.12. Additionally, \nmake-dist.sh\n default uses Java 8. To compile with java 11, it requires to specify building opts \n-Djava.version=11 -Djavac.version=11\n. You can build with \nmake-dist.sh\n or Maven with following command.\n\n\nBuild with \nmake-dist.sh\n:\n\n\n$ bash make-dist.sh -P spark_3.x -Djava.version=11 -Djavac.version=11\n\n\n\n\nOr build with Maven:\n\n\n$ mvn clean package -DskipTests -P spark_3.x -Djava.version=11 -Djavac.version=11\n\n\n\n\n\n\nSetup IDE\n\n\nWe set the scope of spark related library to \nprovided\n in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.\n\n\nThis will cause a problem in IDE. When you run applications, it will throw \nNoClassDefFoundError\n because the library scope is \nprovided\n.\n\n\nYou can easily change the scopes by the \nall-in-one\n profile.\n\n\n\n\nIn Intellij, go to View -> Tools Windows -> Maven Projects. Then in the Maven Projects panel, Profiles -> click \"all-in-one\".",
            "title": "Install"
        },
        {
            "location": "/ScalaUserGuide/install/#download-a-pre-built-library",
            "text": "You can download the Analytics Zoo release and nightly build from the  Release Page",
            "title": "Download a pre-built library"
        },
        {
            "location": "/ScalaUserGuide/install/#link-with-a-release-version",
            "text": "Currently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:  <dependency>\n    <groupId>com.intel.analytics.zoo</groupId>\n    <artifactId>analytics-zoo-bigdl_0.12.1-[spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.3|spark_3.0.0]</artifactId>\n    <version>${ANALYTICS_ZOO_VERSION}</version>\n</dependency>  You can find the latest ANALYTICS_ZOO_VERSION  here .    SBT developers can use  libraryDependencies += \"com.intel.analytics.zoo\" % \"analytics-zoo-bigdl_0.12.1-[spark_2.1.1|spark_2.2.0|spark_2.3.1|spark_2.4.3|spark_3.0.0]\" % \"${ANALYTICS_ZOO_VERSION}\"  Remarks:   Please choose the available suffix above according to your Spark platform you want to use.  You don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo.  You can find the option  ${ANALYTICS_ZOO_VERSION}  from the  Release Page .",
            "title": "Link with a release version"
        },
        {
            "location": "/ScalaUserGuide/install/#link-with-a-development-version",
            "text": "Currently, Analytics Zoo development version is hosted on  SonaType .  To link your application with the latest Analytics Zoo development version, you should add some dependencies like  Linking with Analytics Zoo releases , but set  ${ANALYTICS_ZOO_VERSION}  to latest version, and add below repository to your pom.xml.  <repository>\n    <id>sonatype</id>\n    <name>sonatype repository</name>\n    <url>https://oss.sonatype.org/content/groups/public/</url>\n    <releases>\n        <enabled>true</enabled>\n    </releases>\n    <snapshots>\n        <enabled>true</enabled>\n    </snapshots>\n</repository>  SBT developers can use  resolvers += \"ossrh repository\" at \"https://oss.sonatype.org/content/repositories/snapshots/\"",
            "title": "Link with a development version"
        },
        {
            "location": "/ScalaUserGuide/install/#download-analytics-zoo-source",
            "text": "Analytics Zoo source code is available at  GitHub .  $ git clone https://github.com/intel-analytics/analytics-zoo.git  By default,  git clone  will download the development version of Analytics Zoo, if you want a release version, you can use command  git checkout  to change the version.",
            "title": "Download Analytics Zoo Source"
        },
        {
            "location": "/ScalaUserGuide/install/#setup-build-environment",
            "text": "The following instructions are aligned with master code.  Maven 3 is needed to build Analytics Zoo, you can download it from the  maven website .  After installing Maven 3, please set the environment variable MAVEN_OPTS as follows:  $ export MAVEN_OPTS=\"-Xmx2g -XX:ReservedCodeCacheSize=512m\"  When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.",
            "title": "Setup Build Environment"
        },
        {
            "location": "/ScalaUserGuide/install/#build-with-script-recommended",
            "text": "It is highly recommended that you build Analytics Zoo using the  make-dist.sh script . And it will handle the MAVEN_OPTS variable.  Once downloaded, you can build Analytics Zoo with the following commands:  $ bash make-dist.sh  After that, you can find a  dist  folder, which contains all the needed files to run a Analytics Zoo program. The files in  dist  include:   dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes.  dist/lib/analytics-zoo-VERSION-python-api.zip : This zip package contains all Python files of Analytics Zoo.   The instructions above will build Analytics Zoo with Spark 2.1.0. It is highly recommended to use  Java 8  when running with Spark 2.x; otherwise you may observe very poor performance.",
            "title": "Build with script (Recommended)"
        },
        {
            "location": "/ScalaUserGuide/install/#build-with-spark-version",
            "text": "By default,  make-dist.sh  uses Spark 2.1.0. To override the default behaviors, for example building analytics-zoo with spark 2.2.0, you can use  bash make-dist.sh -Dspark.version=2.2.0 -Dbigdl.artifactId=bigdl_SPARK_2.2 . \nAdditionally, we provide a profile to build with spark 2.4, you can use  bash make-dist.sh -P spark_2.4+ .",
            "title": "Build with Spark version"
        },
        {
            "location": "/ScalaUserGuide/install/#build-with-maven",
            "text": "To build Analytics Zoo directly using Maven, run the command below:  $ mvn clean package -DskipTests  After that, you can find that jar packages in  PATH_TO_ANALYTICS_ZOO /target/, where  PATH_TO_ANALYTICS_ZOO  is the path to the directory of the Analytics Zoo.  Note that the instructions above will build Analytics Zoo with Spark 2.1.0 for Linux. Similarly, you may customize spark version like  above .",
            "title": "Build with Maven"
        },
        {
            "location": "/ScalaUserGuide/install/#build-with-jdk-11",
            "text": "It's recommended to download  Oracle JDK 11 . And it will avoid possible incompatibility with maven plugins. Update PATH and make sure your JAVA_HOME environment variable is set to Java 11 if you're running from the command line. Or if you're running from an IDE, you need to make sure it is set to run maven with your current JDK.  Jdk 11 supports few Scala versions. You can see scala version compatibility  description . Analytics Zoo supports Spark3 with Scala 2.12. You can use  -P spark_3.x  to specify Spark3 and scala 2.12. Additionally,  make-dist.sh  default uses Java 8. To compile with java 11, it requires to specify building opts  -Djava.version=11 -Djavac.version=11 . You can build with  make-dist.sh  or Maven with following command.  Build with  make-dist.sh :  $ bash make-dist.sh -P spark_3.x -Djava.version=11 -Djavac.version=11  Or build with Maven:  $ mvn clean package -DskipTests -P spark_3.x -Djava.version=11 -Djavac.version=11",
            "title": "Build with JDK 11"
        },
        {
            "location": "/ScalaUserGuide/install/#setup-ide",
            "text": "We set the scope of spark related library to  provided  in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.  This will cause a problem in IDE. When you run applications, it will throw  NoClassDefFoundError  because the library scope is  provided .  You can easily change the scopes by the  all-in-one  profile.   In Intellij, go to View -> Tools Windows -> Maven Projects. Then in the Maven Projects panel, Profiles -> click \"all-in-one\".",
            "title": "Setup IDE"
        },
        {
            "location": "/ScalaUserGuide/run/",
            "text": "Set Environment Variables\n\n\nSet \nANALYTICS_ZOO_HOME\n and \nSPARK_HOME\n:\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder\n\n\n\n\n\n\nUse Interactive Spark Shell\n\n\nYou can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:\n\n\n${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]\n\n\n\n\nYou will see a welcome message looking like below:\n\n\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala>\n\n\n\n\nNow you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:\n\n\nscala> import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala> ObjectDetector.loadModel[Float](params.modelPath)\n\n\n\n\n\n\nRun as a Spark Program\n\n\nYou can run a analytics zoo program, e.g., the \nObject Detection\n, as a standard Spark program (running in either local mode or cluster mode) as follows:\n\n\n\n\nDownload the pre-trained model from \nhere\n.\n\n\nPrepare predict images\n\n\nRun the following command:\n\n\n\n\n# Spark local mode\nspark-submit \\ \n  --master local[core_number] \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark standalone mode\nspark-submit \\\n  --master spark://... \\\n  --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark yarn client mode\nspark-submit \\\n  --master yarn \\\n  --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark yarn cluster mode\nspark-submit \\\n  --master yarn \\\n  --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n\n\n\nIf you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.\n\n\nimport com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)",
            "title": "Run"
        },
        {
            "location": "/ScalaUserGuide/run/#set-environment-variables",
            "text": "Set  ANALYTICS_ZOO_HOME  and  SPARK_HOME :   If you download Analytics Zoo from the  Release Page   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package   If you build Analytics Zoo by yourself   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder",
            "title": "Set Environment Variables"
        },
        {
            "location": "/ScalaUserGuide/run/#use-interactive-spark-shell",
            "text": "You can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:  ${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]  You will see a welcome message looking like below:  Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala>  Now you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:  scala> import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala> ObjectDetector.loadModel[Float](params.modelPath)",
            "title": "Use Interactive Spark Shell"
        },
        {
            "location": "/ScalaUserGuide/run/#run-as-a-spark-program",
            "text": "You can run a analytics zoo program, e.g., the  Object Detection , as a standard Spark program (running in either local mode or cluster mode) as follows:   Download the pre-trained model from  here .  Prepare predict images  Run the following command:   # Spark local mode\nspark-submit \\ \n  --master local[core_number] \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark standalone mode\nspark-submit \\\n  --master spark://... \\\n  --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark yarn client mode\nspark-submit \\\n  --master yarn \\\n  --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model\n\n# Spark yarn cluster mode\nspark-submit \\\n  --master yarn \\\n  --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images \\\n  --output path_to_output \\\n  --model path_to_model  If you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.  import com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)",
            "title": "Run as a Spark Program"
        },
        {
            "location": "/examples/",
            "text": "Analytics Zoo Examples\n\n\nDistributed TensorFlow on Spark\n\n\n\n\n\n\nPython examples\n\n\n\n\n\n\nScala examples\n\n\n\n\n\n\nDistributed PyTorch on Spark\n\n\n\n\nPython examples\n\n\n\n\nDeep Learning using Spark Dataframe and ML Pipeline\n\n\n\n\n\n\nPython examples\n\n\n\n\n\n\nScala examples\n\n\n\n\n\n\nRayOnSpark\n\n\n\n\nPython examples\n\n\n\n\nCluster Serving\n\n\n\n\nQuick Start example\n\n\n\n\nInference Model\n\n\n\n\n\n\nPython examples\n\n\n\n\n\n\nScala examples\n\n\n\n\n\n\nExamples for Use Cases\n\n\nRecommendation\n\n\n\n\n\n\nNeural Collaborative Filtering\n\n\n\n\n\n\nWide & Deep\n\n\n\n\n\n\nTime Series\n\n\n\n\nAnomaly Detection\n\n\n\n\nComputer Vision\n\n\n\n\n\n\nObject Detection\n\n\n\n\n\n\nImage Augmentation\n\n\n\n\n\n\nNLP\n\n\n\n\n\n\nText Classification\n\n\n\n\n\n\nQA Ranker",
            "title": "Examples"
        },
        {
            "location": "/examples/#analytics-zoo-examples",
            "text": "",
            "title": "Analytics Zoo Examples"
        },
        {
            "location": "/examples/#distributed-tensorflow-on-spark",
            "text": "Python examples    Scala examples",
            "title": "Distributed TensorFlow on Spark"
        },
        {
            "location": "/examples/#distributed-pytorch-on-spark",
            "text": "Python examples",
            "title": "Distributed PyTorch on Spark"
        },
        {
            "location": "/examples/#deep-learning-using-spark-dataframe-and-ml-pipeline",
            "text": "Python examples    Scala examples",
            "title": "Deep Learning using Spark Dataframe and ML Pipeline"
        },
        {
            "location": "/examples/#rayonspark",
            "text": "Python examples",
            "title": "RayOnSpark"
        },
        {
            "location": "/examples/#cluster-serving",
            "text": "Quick Start example",
            "title": "Cluster Serving"
        },
        {
            "location": "/examples/#inference-model",
            "text": "Python examples    Scala examples",
            "title": "Inference Model"
        },
        {
            "location": "/examples/#examples-for-use-cases",
            "text": "",
            "title": "Examples for Use Cases"
        },
        {
            "location": "/examples/#recommendation",
            "text": "Neural Collaborative Filtering    Wide & Deep",
            "title": "Recommendation"
        },
        {
            "location": "/examples/#time-series",
            "text": "Anomaly Detection",
            "title": "Time Series"
        },
        {
            "location": "/examples/#computer-vision",
            "text": "Object Detection    Image Augmentation",
            "title": "Computer Vision"
        },
        {
            "location": "/examples/#nlp",
            "text": "Text Classification    QA Ranker",
            "title": "NLP"
        },
        {
            "location": "/ProgrammingGuide/nnframes/",
            "text": "Overview\n\n\nNNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.\n\n\nHighlights\n\n\n\n\n\n\nEasy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.\n\n\n\n\n\n\nEffortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.\n\n\n\n\n\n\nIn a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.\n\n\n\n\n\n\nTraining of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).\n\n\n\n\n\n\nRich toolset for feature extraction and processing, including image, audio and texts.\n\n\n\n\n\n\nExamples:\n\n\nThe examples are included in the Analytics Zoo source code.\n\n\n\n\nimage classification: model inference using pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\nimage classification: transfer learning from pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\n\n\nPrimary APIs\n\n\nNNEstimator and NNModel\n\n\nAnalytics Zoo provides \nNNEstimator\n for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark\n\nEstimator\n/\n\nTransfomer\n\npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of\n\nNNEstimator\n is a NNModel, which is a Spark ML Transformer.\n\n\nplease check our\n\nNNEstimator API\n for detailed usage.\n\n\nNNClassifier and NNClassifierModel\n\n\nNNClassifier\n and \nNNClassifierModel\nextends \nNNEstimator\n and \nNNModel\n and focus on \nclassification tasks, where both label column and prediction column are of Double type.\n\n\nNNImageReader\n\nNNImageReader loads image into Spark DataFrame.\n\n\nplease check our\n\nImageProcessing\n for detailed usage.",
            "title": "DataFrame and ML Pipeline"
        },
        {
            "location": "/ProgrammingGuide/nnframes/#overview",
            "text": "NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.  Highlights    Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.    Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.    In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.    Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).    Rich toolset for feature extraction and processing, including image, audio and texts.",
            "title": "Overview"
        },
        {
            "location": "/ProgrammingGuide/nnframes/#examples",
            "text": "The examples are included in the Analytics Zoo source code.   image classification: model inference using pre-trained Inception v1 model.\n     Scala version \n     Python version  image classification: transfer learning from pre-trained Inception v1 model.\n     Scala version \n     Python version",
            "title": "Examples:"
        },
        {
            "location": "/ProgrammingGuide/nnframes/#primary-apis",
            "text": "NNEstimator and NNModel  Analytics Zoo provides  NNEstimator  for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer \npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator  is a NNModel, which is a Spark ML Transformer.  please check our NNEstimator API  for detailed usage.  NNClassifier and NNClassifierModel  NNClassifier  and  NNClassifierModel extends  NNEstimator  and  NNModel  and focus on \nclassification tasks, where both label column and prediction column are of Double type.  NNImageReader \nNNImageReader loads image into Spark DataFrame.  please check our ImageProcessing  for detailed usage.",
            "title": "Primary APIs"
        },
        {
            "location": "/ProgrammingGuide/autograd/",
            "text": "Overview\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustracted below. (See more examples \nhere\n). Conceptually we use reverse mode together with the chain rule for automatic differentiation. \nVariable\n is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input \nvariables\n and roots are the output \nvariables\n.\n\n\nCustomLoss\n\n\n1.Define a custom function using \nautograd\n\n\nfrom zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)\n\n\n\n\n\n\nUse \nCustomLoss\n in \ncompile\n method.\n\n\n\n\n# You can pass the loss function directly into `loss`\nmodel.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)\n\n\n\n\n\n\nUse \nCustomLoss\n in \nnnframe\n pipeline.\n\n\n\n\n# 1) Create a CustomLoss object from function.\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\n# 2) Passing the CustomLoss object to NNClassifier.\nclassifier = NNClassifier(lrModel, loss, SeqToTensor([1000]))\n\n\n\n\n\n\nUse \nforward\n and \nbackward\n to evaluate a \nCustomLoss\n for debugging.\n\n\n\n\n# y_pred_shape=[2] is a shape without batch\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\nerror = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\ngrad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\n\n\n\n\nLambda layer\n\n\n1.Define custom function using \nautograd\n\n\nfrom zoo.pipeline.api.autograd import *\ndef add_one_func(x):\n   return x + 1.0\n\n\n\n\n2.Define model using Keras-style API and \ncustom \nLambda\n layer\n\n\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size\n\n\n\n\n\nConstruct variable computation without \nLambda\n layer\n\n\n\n\nThe returning type for each operation is a \nVariable\n, so you can connect those \nVariable\n together freely without using \nLambda\n. i.e \nDense[Float](3).from(input2)\n or \ninput1 + input2\n\n\nShape inference is supported as well, which means you can check the output shape of a \nVariable\n by calling \nget_output_shape()\n\n\n\n\nPython\n\n\nimport zoo.pipeline.api.autograd as auto\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\ninput = Input(shape=[2, 20]) # create a variable\ntime = TimeDistributed(layer=Dense(30))(input) # time is a variable\nt1 = time.index_select(1, 0) # t1 is a variable\nt2 = time.index_select(1, 1)\ndiff = auto.abs(t1 - t2)\nassert diff.get_output_shape() == (None, 30)\nassert diff.get_input_shape() == (None, 30)\nmodel = Model(input, diff)\ndata = np.random.uniform(0, 1, [10, 2, 20])\noutput = model.forward(data)\n\n\n\n\nScala\n- In respect of backward compatibility, the scala API is slightly different with the python API.\n- \nlayer.inputs(node)\n would return a node(backward compatibility).\n- \nlayer.from(variable)\n would return a variable.(You may want to use this style as it can support autograd.)\n\n\nimport com.intel.analytics.zoo.pipeline.api.autograd.Variable\nimport com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\n\nval input1 = Variable[Float](inputShape = Shape(3))\nval input2 = Variable[Float](inputShape = Shape(3))\nval diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2))\nval model = Model[Float](input = Array(input1, input2), output = diff)\nval inputValue = Tensor[Float](1, 3).randn()\n// In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table.\nval out = model.forward(T(inputValue, inputValue)).toTensor[Float]\n\n\n\n\nDefine a model using trainable Parameter\n\n\nBuild a \nLinear\n Model (Wx + b) by using trainable \nParameter\n which is equivalent to use \nDense\n layer.\n* Scala\n\n\nimport com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nval input = Variable[Float](Shape(3))\nval w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize\nval bias = Parameter[Float](Shape(2))\nval cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias\nval model = Model[Float](input = input, output = cDense)\n\n\n\n\n\n\n\nPython\n\n\n\n\nfrom zoo.pipeline.api.autograd import *\nfrom zoo.pipeline.api.keras.models import *\ninput = Variable((3,))\nw = Parameter((2, 3)) # outputSize * inputSize\nbias = Parameter((2,))\ncDense = mm(input, w, axes = (1, 1)) + bias\nmodel = Model(input = input, output = cDense)",
            "title": "Autograd"
        },
        {
            "location": "/ProgrammingGuide/autograd/#overview",
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustracted below. (See more examples  here ). Conceptually we use reverse mode together with the chain rule for automatic differentiation.  Variable  is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input  variables  and roots are the output  variables .",
            "title": "Overview"
        },
        {
            "location": "/ProgrammingGuide/autograd/#customloss",
            "text": "1.Define a custom function using  autograd  from zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)   Use  CustomLoss  in  compile  method.   # You can pass the loss function directly into `loss`\nmodel.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)   Use  CustomLoss  in  nnframe  pipeline.   # 1) Create a CustomLoss object from function.\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\n# 2) Passing the CustomLoss object to NNClassifier.\nclassifier = NNClassifier(lrModel, loss, SeqToTensor([1000]))   Use  forward  and  backward  to evaluate a  CustomLoss  for debugging.   # y_pred_shape=[2] is a shape without batch\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\nerror = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\ngrad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))",
            "title": "CustomLoss"
        },
        {
            "location": "/ProgrammingGuide/autograd/#lambda-layer",
            "text": "1.Define custom function using  autograd  from zoo.pipeline.api.autograd import *\ndef add_one_func(x):\n   return x + 1.0  2.Define model using Keras-style API and  custom  Lambda  layer  from zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size",
            "title": "Lambda layer"
        },
        {
            "location": "/ProgrammingGuide/autograd/#construct-variable-computation-without-lambda-layer",
            "text": "The returning type for each operation is a  Variable , so you can connect those  Variable  together freely without using  Lambda . i.e  Dense[Float](3).from(input2)  or  input1 + input2  Shape inference is supported as well, which means you can check the output shape of a  Variable  by calling  get_output_shape()   Python  import zoo.pipeline.api.autograd as auto\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\ninput = Input(shape=[2, 20]) # create a variable\ntime = TimeDistributed(layer=Dense(30))(input) # time is a variable\nt1 = time.index_select(1, 0) # t1 is a variable\nt2 = time.index_select(1, 1)\ndiff = auto.abs(t1 - t2)\nassert diff.get_output_shape() == (None, 30)\nassert diff.get_input_shape() == (None, 30)\nmodel = Model(input, diff)\ndata = np.random.uniform(0, 1, [10, 2, 20])\noutput = model.forward(data)  Scala\n- In respect of backward compatibility, the scala API is slightly different with the python API.\n-  layer.inputs(node)  would return a node(backward compatibility).\n-  layer.from(variable)  would return a variable.(You may want to use this style as it can support autograd.)  import com.intel.analytics.zoo.pipeline.api.autograd.Variable\nimport com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\n\nval input1 = Variable[Float](inputShape = Shape(3))\nval input2 = Variable[Float](inputShape = Shape(3))\nval diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2))\nval model = Model[Float](input = Array(input1, input2), output = diff)\nval inputValue = Tensor[Float](1, 3).randn()\n// In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table.\nval out = model.forward(T(inputValue, inputValue)).toTensor[Float]",
            "title": "Construct variable computation without Lambda layer"
        },
        {
            "location": "/ProgrammingGuide/autograd/#define-a-model-using-trainable-parameter",
            "text": "Build a  Linear  Model (Wx + b) by using trainable  Parameter  which is equivalent to use  Dense  layer.\n* Scala  import com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nval input = Variable[Float](Shape(3))\nval w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize\nval bias = Parameter[Float](Shape(2))\nval cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias\nval model = Model[Float](input = input, output = cDense)   Python   from zoo.pipeline.api.autograd import *\nfrom zoo.pipeline.api.keras.models import *\ninput = Variable((3,))\nw = Parameter((2, 3)) # outputSize * inputSize\nbias = Parameter((2,))\ncDense = mm(input, w, axes = (1, 1)) + bias\nmodel = Model(input = input, output = cDense)",
            "title": "Define a model using trainable Parameter"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/",
            "text": "Overview\n\n\nAnalytics Zoo provides some useful utilities for transfer learning.\n\n\nLoading a pre-trained model\n\n\nWe can use the \nNet\n api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to \nNet API Guide\n\n\nRemove the last a few layers\n\n\nWhen a model is loaded using \nNet\n, we can use the \nnewGraph(output)\n api to define a Model with\nthe output specified by the parameter.\n\n\nFor example, \n\n\nIn scala:\n\n\nval inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output = \"pool5/drop_7x7_s1\")\n\n\n\n\n\nIn python:\n\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n\n\n\n\nThe returning model's output layer is \"pool5/drop_7x7_s1\".\n\n\nFreeze some layers\n\n\nIn transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the \nfreezeUpTo(endPoint)\n api to do that.\n\n\nFor example,\n\n\nIn scala:\n\n\ninception.freezeUpTo(\"pool4/3x3_s2\") // freeze layer pool4/3x3_s2 and the layers before it\n\n\n\n\nIn python:\n\n\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])\n\n\n\n\nThis will freeze all the layers from the input layer to \"pool4/3x3_s2\"\n\n\nExample\n\n\nFor a complete example, refer to the \nscala transfer learning example\n\nand \npython transfer learning example",
            "title": "Transfer Learning"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/#overview",
            "text": "Analytics Zoo provides some useful utilities for transfer learning.",
            "title": "Overview"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/#loading-a-pre-trained-model",
            "text": "We can use the  Net  api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to  Net API Guide",
            "title": "Loading a pre-trained model"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/#remove-the-last-a-few-layers",
            "text": "When a model is loaded using  Net , we can use the  newGraph(output)  api to define a Model with\nthe output specified by the parameter.  For example,   In scala:  val inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output = \"pool5/drop_7x7_s1\")  In python:  full_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])  The returning model's output layer is \"pool5/drop_7x7_s1\".",
            "title": "Remove the last a few layers"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/#freeze-some-layers",
            "text": "In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the  freezeUpTo(endPoint)  api to do that.  For example,  In scala:  inception.freezeUpTo(\"pool4/3x3_s2\") // freeze layer pool4/3x3_s2 and the layers before it  In python:  # freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])  This will freeze all the layers from the input layer to \"pool4/3x3_s2\"",
            "title": "Freeze some layers"
        },
        {
            "location": "/ProgrammingGuide/transferlearning/#example",
            "text": "For a complete example, refer to the  scala transfer learning example \nand  python transfer learning example",
            "title": "Example"
        },
        {
            "location": "/ProgrammingGuide/inference/",
            "text": "Inference Model is a package in Analytics Zoo aiming to provide high-level APIs to speed-up development. It allows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Inference Model provides Java, Scala and Python interfaces.\n\n\nHighlights\n\n\n\n\nEasy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\n\n\nSupport transformation of various input data type, thus supporting future prediction tasks.\n\n\nTransparently support the OpenVINO toolkit, which deliver a significant boost for inference speed (\nup to 19.9x\n).\n\n\n\n\nLoad and predict with pre-trained model\n\n\nBasic usage of Inference Model:\n\n\n\n\nDirectly use InferenceModel or write a subclass extends \nInferenceModel\n (\nAbstractInferenceModel\n in Java).\n\n\nLoad pre-trained models with corresponding \nload\n methods, e.g, \ndoLoadBigDL\n for Analytics Zoo, and \ndoLoadTensorflow\n for TensorFlow.\n\n\nDo prediction with \npredict\n method.\n\n\n\n\nSupported models:\n\n\n\n\nAnalytics Zoo Models\n\n\nCaffe Models\n\n\nTensorFlow Models\n\n\nOpenVINO models\n\n\n\n\nPredict input and output\n\n\n\n\npredictInput\n: JList[JList[JTensor]] or \nTensor\n for Scale and Java, Numpy for Python. Input data for prediction. \nJTensor\n is a 1D List, with Array[Int] shape.\n\n\npredictOutput\n: JList[JList[JTensor]] or \nTensor\n for Scale and Java, Numpy for Python. Prediction result.\n\n\n\n\nOpenVINO requirements:\n\n\nSystem requirements\n:\n\n\nUbuntu 18.04 LTS (64 bit)\nCentOS 7.4 (64 bit)\nmacOS 10.13, 10.14 (64 bit)\n\n\n\nPython requirements:\n\n\ntensorflow>=1.2.0\nnetworkx>=1.11\nnumpy>=1.12.0\nprotobuf==3.6.1\n\n\n\nJava\n\n\nWrite a subclass that extends \nAbstractInferenceModel\n, implement or override methods. Then, load model with corresponding \nload\n methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with \nloadBigDL\n, \nloadCaffe\n, \nloadOpenVINO\n and \nloadTensorflow\n), and do prediction with \npredict\n method. \n\n\nimport com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n    public ExtendedInferenceModel() {\n        super();\n    }\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\n// Load Analytics Zoo model\nmodel.loadBigDL(modelPath, weightPath);\n// Predict\nList<List<JTensor>> result = model.predict(inputList);\n\n\n\n\nScala\n\n\nNew an instance of \nInferenceModel\n, and load model with corresponding \nload\n methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with \ndoLoadBigDL\n, \ndoLoadCaffe\n, \ndoLoadOpenVINO\n and \ndoLoadTensorflow\n), then do prediction with \npredict\n method.\n\n\nimport com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nval model = new InferenceModel()\n// Load Analytics Zoo model\nmodel.doLoadBigDL(modelPath, weightPath)\n// Predict\nval result = model.doPredict(inputList)\n\n\n\n\nIn some cases, you may want to write a subclass that extends \nInferenceModel\n, implement or override methods. Then, load model with corresponding \nload\n methods, and do prediction with \npredict\n method.\n\n\nimport com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nclass ExtendedInferenceModel extends InferenceModel {\n\n}\n\nval model = new ExtendedInferenceModel()\n// Load Analytics Zoo model\nmodel.doLoadBigDL(modelPath, weightPath)\n// Predict\nval result = model.doPredict(inputList)\n\n\n\n\nPython\n\n\nNew an instance of \nInferenceModel\n, and load Zoo model with corresponding \nload\n methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with \nload_bigdl\n, \nload_caffe\n, \nload_openvino\n and \nload_tensorflow\n), then do prediction with \npredict\n method.\n\n\nfrom zoo.pipeline.inference import InferenceModel\n\nmodel = InferenceModel()\n# Load Analytics Zoo model\nmodel.load_bigdl(model_path, weight_path)\n# Predict\nresult = model.predict(input_list)\n\n\n\n\nIn some cases, you may want to write a subclass that extends \nInferenceModel\n, implement or override methods. Then, load model with corresponding \nload\n methods, and do prediction with \npredict\n method.\n\n\nfrom zoo.pipeline.inference import InferenceModel\n\nclass ExtendedInferenceModel(InferenceModel):\n\n    def __init__(self):\n        pass\n\nmodel = ExtendedInferenceModel()\n# Load Analytics Zoo model\nmodel.load_bigdl(model_path, weight_path)\n# Predict\nresult = model.predict(input_list)\n\n\n\n\nExamples\n\n\nWe provide examples based on InferenceModel.\n\n\nSee \nhere\n for the Java example.\n\n\nSee \nhere\n for the Scala example.",
            "title": "Model Serving"
        },
        {
            "location": "/ProgrammingGuide/inference/#load-and-predict-with-pre-trained-model",
            "text": "Basic usage of Inference Model:   Directly use InferenceModel or write a subclass extends  InferenceModel  ( AbstractInferenceModel  in Java).  Load pre-trained models with corresponding  load  methods, e.g,  doLoadBigDL  for Analytics Zoo, and  doLoadTensorflow  for TensorFlow.  Do prediction with  predict  method.   Supported models:   Analytics Zoo Models  Caffe Models  TensorFlow Models  OpenVINO models   Predict input and output   predictInput : JList[JList[JTensor]] or  Tensor  for Scale and Java, Numpy for Python. Input data for prediction.  JTensor  is a 1D List, with Array[Int] shape.  predictOutput : JList[JList[JTensor]] or  Tensor  for Scale and Java, Numpy for Python. Prediction result.   OpenVINO requirements:  System requirements :  Ubuntu 18.04 LTS (64 bit)\nCentOS 7.4 (64 bit)\nmacOS 10.13, 10.14 (64 bit)  Python requirements:  tensorflow>=1.2.0\nnetworkx>=1.11\nnumpy>=1.12.0\nprotobuf==3.6.1  Java  Write a subclass that extends  AbstractInferenceModel , implement or override methods. Then, load model with corresponding  load  methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with  loadBigDL ,  loadCaffe ,  loadOpenVINO  and  loadTensorflow ), and do prediction with  predict  method.   import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n    public ExtendedInferenceModel() {\n        super();\n    }\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\n// Load Analytics Zoo model\nmodel.loadBigDL(modelPath, weightPath);\n// Predict\nList<List<JTensor>> result = model.predict(inputList);  Scala  New an instance of  InferenceModel , and load model with corresponding  load  methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with  doLoadBigDL ,  doLoadCaffe ,  doLoadOpenVINO  and  doLoadTensorflow ), then do prediction with  predict  method.  import com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nval model = new InferenceModel()\n// Load Analytics Zoo model\nmodel.doLoadBigDL(modelPath, weightPath)\n// Predict\nval result = model.doPredict(inputList)  In some cases, you may want to write a subclass that extends  InferenceModel , implement or override methods. Then, load model with corresponding  load  methods, and do prediction with  predict  method.  import com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nclass ExtendedInferenceModel extends InferenceModel {\n\n}\n\nval model = new ExtendedInferenceModel()\n// Load Analytics Zoo model\nmodel.doLoadBigDL(modelPath, weightPath)\n// Predict\nval result = model.doPredict(inputList)  Python  New an instance of  InferenceModel , and load Zoo model with corresponding  load  methods (load Analytics Zoo, caffe, OpenVINO and TensorFlow model with  load_bigdl ,  load_caffe ,  load_openvino  and  load_tensorflow ), then do prediction with  predict  method.  from zoo.pipeline.inference import InferenceModel\n\nmodel = InferenceModel()\n# Load Analytics Zoo model\nmodel.load_bigdl(model_path, weight_path)\n# Predict\nresult = model.predict(input_list)  In some cases, you may want to write a subclass that extends  InferenceModel , implement or override methods. Then, load model with corresponding  load  methods, and do prediction with  predict  method.  from zoo.pipeline.inference import InferenceModel\n\nclass ExtendedInferenceModel(InferenceModel):\n\n    def __init__(self):\n        pass\n\nmodel = ExtendedInferenceModel()\n# Load Analytics Zoo model\nmodel.load_bigdl(model_path, weight_path)\n# Predict\nresult = model.predict(input_list)",
            "title": "Load and predict with pre-trained model"
        },
        {
            "location": "/ProgrammingGuide/inference/#examples",
            "text": "We provide examples based on InferenceModel.  See  here  for the Java example.  See  here  for the Scala example.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/",
            "text": "Analytics-Zoo provides a set APIs for running TensorFlow model on Spark in a distributed fashion.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nTFPark API\n\n\nTFPark is a set of high-level api modeling after tf.keras and tf.estimator to help user to train and evaluate TensorFlow\nmodels on Spark and BigDL. Users can define their model using \ntf.keras\n API or using \nmodel_fn\n similar to \ntf.estimator\n.\n\n\nTFDataset\n\n\nTFDatasets\n represents a distributed collection of elements (backed by a RDD) to be fed into a TensorFlow graph.\nTFDatasets can be created from numpy.ndarrays, an rdd of numpy.ndarrays as well as ImageSet, TextSet and FeatureSet.\nIt acts as an interface connecting RDD data to TensorFlow models.\n\n\nfrom zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=BATCH_SIZE)\n\n\n\n\nMore on TFDataset API \nAPI Guide\n\n\nKerasModel\n\n\nKerasModel enables user to use \ntf.keras\n API to define TensorFlow models and perform training or evaluation on top\nof Spark and BigDL in a distributed fashion.\n\n\n\n\nCreate a KerasModel\n\n\n\n\nfrom zoo.tfpark import KerasModel, TFDataset\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential(\n    [tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n     tf.keras.layers.Dense(64, activation='relu'),\n     tf.keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nkeras_model = KerasModel(model)\n\n\n\n\n\n\n\nPerform training on TFDataset and save model\n\n\n\n\nkeras_model.fit(training_dataset, epochs=max_epoch)\n\nmodel.save_weights(\"/tmp/model.h5\")\n\n\n\n\n\n\n\nLoading saved model and preform evaluation or inference\n\n\n\n\nmodel.load_weights(\"/tmp/model.h5\")\n\nevaluation_results = model.evaluate(eval_dataset)\n\npredictions = model.predict(pred_dataset)\n\n\n\n\nMore on KerasModel API \nAPI Guide\n\n\nTFEstimator\n\n\nTFEstimator wraps a model defined by \nmodel_fn\n. The \nmodel_fn\n is almost identical to TensorFlow's \nmodel_fn\n\nexcept users are required to use ZooOptimizer, which takes a \ntf.train.Optimzer\n as input, to derive a train_op.\n\n\n\n\nDefine a \nmodel_fn\n and create a TFEstimator. Note that \nZooOptimizer\n must be used.\n\n\n\n\nimport tensorflow as tf\nfrom zoo.tfpark import TFEstimator, ZooOptimizer\ndef model_fn(features, labels, mode):\n\n    hidden = tf.layers.dense(features, 32, activation=tf.nn.relu)\n\n    logits = tf.layers.dense(hidden, 10)\n\n    if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(\n            tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n        train_op = ZooOptimizer(tf.train.AdamOptimizer()).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, train_op=train_op, predictions=logits, loss=loss)\n    else:\n        return tf.estimator.EstimatorSpec(mode, predictions=logits)\nestimator = TFEstimator.from_model_fn(model_fn, model_dir=\"/tmp/estimator\")\n\n\n\n\nOr use a pre-made Estimator from TensorFlow and create a TFEstimator. Note that \nZooOptimizer\n must be used.\n\n\nimport tensorflow as tf\nlinear = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n                                           optimizer=ZooOptimizer(tf.train.FtrlOptimizer(0.2)))\nestimator = TFEstimator(linear)\n\n\n\n\n\n\nDefine a input_fn.\n\n\n\n\nimport tensorflow as tf\nsc = init_nncontext()\ndef input_fn(mode):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        training_rdd = get_data_rdd(\"train\", sc)\n        dataset = TFDataset.from_rdd(training_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     labels=(tf.int32, []),\n                                     batch_size=320)\n    elif mode == tf.estimator.ModeKeys.EVAL:\n        validation_rdd = get_data_rdd(\"validation\", sc)\n        dataset = TFDataset.from_rdd(testing_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     labels=(tf.int32, []),\n                                     batch_size=320)\n    else:\n        testing_rdd = get_data_rdd(\"test\", sc)\n        dataset = TFDataset.from_rdd(testing_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     batch_per_thread=80)\n    return dataset\n\n\n\n\n\n\nPerform training, evaluation or inference\n\n\n\n\nestimator.train(input_fn, steps=10000)\nevaluation_result = estimator.evaluate(input_fn, [\"acc\"])\npredictions = estimator.predict(input_fn)\n\n\n\n\nMore on TFEstimator API \nAPI Guide\n\n\nLow level API\n\n\nConcepts\n\n\n\n\n\n\nTFOptimizer\n is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. It takes the user specified \nloss\n (a TensorFlow scalar tensor) as\nan argument and runs stochastic gradient descent using the given \noptimMethod\n on all the \nVariables\n that\ncontribute to this loss.\n\n\n\n\n\n\nTFPredictor\n takes a list of user specified TensorFlow tensors as the model outputs, and feed all the\nelements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the\nmodel prediction for the corresponding input elements.\n\n\n\n\n\n\nTraining\n\n\n1.Data wrangling and analysis using PySpark\n\n\nfrom zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=BATCH_SIZE)\n\n\n\n\n2.Deep learning model development using TensorFlow\n\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nsqueezed_labels = tf.squeeze(labels)\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels))\n\n\n\n\nYou can also construct your model using Keras provided by Tensorflow.\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\n\n\n\n3.Distributed training on Spark and BigDL\n\n\nfrom zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.set_train_summary(TrainSummary(\"/tmp/az_lenet\", \"lenet\"))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nFor Keras model:\n\n\nfrom zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset)\noptimizer.set_train_summary(TrainSummary(\"/tmp/az_lenet\", \"lenet\"))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\n4.Save the variable to checkpoint\n\n\nsaver = tf.train.Saver()\nsaver.save(optimizer.sess, \"/tmp/lenet/\")\n\n\n\n\nFor Keras model, you can also Keras' \nsave_weights\n api.\n\n\nmodel.save_weights(\"/tmp/keras.h5\")\n\n\n\n\nInference\n\n\n1.Data processing using PySpark\n\n\nfrom zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntesting_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(testing_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             batch_per_thread=4)\n\n\n\n\n2.Reconstruct the model for inference and load the checkpoint\n\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \"/tmp/lenet\")\n\n\n\n\nAs before, you can also construct and restore your model using Keras provided by Tensorflow.\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.load_weights(\"/tmp/mnist_keras.h5\")\n\n\n\n\n\n3.Run predictions\n\n\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()\n\n\n\n\nFor keras model:\n\n\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()\n\n\n\n\nRelationship to TFNet\n\n\nTFNet\n is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors).\nIt implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers\nto construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API. \n\n\nYou can think of \nTFDatasets\n, \nTFOptimizer\n, \nTFPredictor\n as a set API for training/testing TensorFlow models\non Spark/BigDL, while \nTFNet\n as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph.\n\n\nFor more information on TFNet, please refer to the \nAPI Guide",
            "title": "TFPark Overview"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#tfpark-api",
            "text": "TFPark is a set of high-level api modeling after tf.keras and tf.estimator to help user to train and evaluate TensorFlow\nmodels on Spark and BigDL. Users can define their model using  tf.keras  API or using  model_fn  similar to  tf.estimator .",
            "title": "TFPark API"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#tfdataset",
            "text": "TFDatasets  represents a distributed collection of elements (backed by a RDD) to be fed into a TensorFlow graph.\nTFDatasets can be created from numpy.ndarrays, an rdd of numpy.ndarrays as well as ImageSet, TextSet and FeatureSet.\nIt acts as an interface connecting RDD data to TensorFlow models.  from zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=BATCH_SIZE)  More on TFDataset API  API Guide",
            "title": "TFDataset"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#kerasmodel",
            "text": "KerasModel enables user to use  tf.keras  API to define TensorFlow models and perform training or evaluation on top\nof Spark and BigDL in a distributed fashion.   Create a KerasModel   from zoo.tfpark import KerasModel, TFDataset\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential(\n    [tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n     tf.keras.layers.Dense(64, activation='relu'),\n     tf.keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nkeras_model = KerasModel(model)   Perform training on TFDataset and save model   keras_model.fit(training_dataset, epochs=max_epoch)\n\nmodel.save_weights(\"/tmp/model.h5\")   Loading saved model and preform evaluation or inference   model.load_weights(\"/tmp/model.h5\")\n\nevaluation_results = model.evaluate(eval_dataset)\n\npredictions = model.predict(pred_dataset)  More on KerasModel API  API Guide",
            "title": "KerasModel"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#tfestimator",
            "text": "TFEstimator wraps a model defined by  model_fn . The  model_fn  is almost identical to TensorFlow's  model_fn \nexcept users are required to use ZooOptimizer, which takes a  tf.train.Optimzer  as input, to derive a train_op.   Define a  model_fn  and create a TFEstimator. Note that  ZooOptimizer  must be used.   import tensorflow as tf\nfrom zoo.tfpark import TFEstimator, ZooOptimizer\ndef model_fn(features, labels, mode):\n\n    hidden = tf.layers.dense(features, 32, activation=tf.nn.relu)\n\n    logits = tf.layers.dense(hidden, 10)\n\n    if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(\n            tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n        train_op = ZooOptimizer(tf.train.AdamOptimizer()).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, train_op=train_op, predictions=logits, loss=loss)\n    else:\n        return tf.estimator.EstimatorSpec(mode, predictions=logits)\nestimator = TFEstimator.from_model_fn(model_fn, model_dir=\"/tmp/estimator\")  Or use a pre-made Estimator from TensorFlow and create a TFEstimator. Note that  ZooOptimizer  must be used.  import tensorflow as tf\nlinear = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n                                           optimizer=ZooOptimizer(tf.train.FtrlOptimizer(0.2)))\nestimator = TFEstimator(linear)   Define a input_fn.   import tensorflow as tf\nsc = init_nncontext()\ndef input_fn(mode):\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        training_rdd = get_data_rdd(\"train\", sc)\n        dataset = TFDataset.from_rdd(training_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     labels=(tf.int32, []),\n                                     batch_size=320)\n    elif mode == tf.estimator.ModeKeys.EVAL:\n        validation_rdd = get_data_rdd(\"validation\", sc)\n        dataset = TFDataset.from_rdd(testing_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     labels=(tf.int32, []),\n                                     batch_size=320)\n    else:\n        testing_rdd = get_data_rdd(\"test\", sc)\n        dataset = TFDataset.from_rdd(testing_rdd,\n                                     features=(tf.float32, [28, 28, 1]),\n                                     batch_per_thread=80)\n    return dataset   Perform training, evaluation or inference   estimator.train(input_fn, steps=10000)\nevaluation_result = estimator.evaluate(input_fn, [\"acc\"])\npredictions = estimator.predict(input_fn)  More on TFEstimator API  API Guide",
            "title": "TFEstimator"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#low-level-api",
            "text": "",
            "title": "Low level API"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#concepts",
            "text": "TFOptimizer  is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. It takes the user specified  loss  (a TensorFlow scalar tensor) as\nan argument and runs stochastic gradient descent using the given  optimMethod  on all the  Variables  that\ncontribute to this loss.    TFPredictor  takes a list of user specified TensorFlow tensors as the model outputs, and feed all the\nelements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the\nmodel prediction for the corresponding input elements.",
            "title": "Concepts"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#training",
            "text": "1.Data wrangling and analysis using PySpark  from zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=BATCH_SIZE)  2.Deep learning model development using TensorFlow  import tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nsqueezed_labels = tf.squeeze(labels)\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels))  You can also construct your model using Keras provided by Tensorflow.  from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])  3.Distributed training on Spark and BigDL  from zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.set_train_summary(TrainSummary(\"/tmp/az_lenet\", \"lenet\"))\noptimizer.optimize(end_trigger=MaxEpoch(5))  For Keras model:  from zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset)\noptimizer.set_train_summary(TrainSummary(\"/tmp/az_lenet\", \"lenet\"))\noptimizer.optimize(end_trigger=MaxEpoch(5))  4.Save the variable to checkpoint  saver = tf.train.Saver()\nsaver.save(optimizer.sess, \"/tmp/lenet/\")  For Keras model, you can also Keras'  save_weights  api.  model.save_weights(\"/tmp/keras.h5\")",
            "title": "Training"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#inference",
            "text": "1.Data processing using PySpark  from zoo import init_nncontext\nfrom zoo.tfpark import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntesting_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(testing_rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             batch_per_thread=4)  2.Reconstruct the model for inference and load the checkpoint  import tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \"/tmp/lenet\")  As before, you can also construct and restore your model using Keras provided by Tensorflow.  from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.load_weights(\"/tmp/mnist_keras.h5\")  3.Run predictions  predictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()  For keras model:  predictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()",
            "title": "Inference"
        },
        {
            "location": "/ProgrammingGuide/TFPark/tensorflow/#relationship-to-tfnet",
            "text": "TFNet  is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors).\nIt implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers\nto construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API.   You can think of  TFDatasets ,  TFOptimizer ,  TFPredictor  as a set API for training/testing TensorFlow models\non Spark/BigDL, while  TFNet  as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph.  For more information on TFNet, please refer to the  API Guide",
            "title": "Relationship to TFNet"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/",
            "text": "TFDataset\n\n\nIntroduction\n\n\nTFDatasets\n is the main entrance point in TFPark for importing and manipulating data.\nIt represents a distributed collection of elements (backed by a RDD) to be fed into a\nTensorFlow graph for training, evaluation or inference. It provides a rich set of tools\nto import data from various data sources and work as a unified interface to interact with\nother components of TFPark.\n\n\nThis guide will walk you through some common cases of importing data and you can find detailed description\nof TFDataset's API in \nAnalytics-Zoo API Guide\n.\n\n\nBasics\n\n\nTFDataset\n's job is to take in dataset, distribute the data across the Spark cluster and transform each data\nrecord into the format that is compatible with TFPark.\n\n\nHere are a few common features that every TFDataset share:\n\n\n\n\n\n\nTFDataset\n will automatically stack consecutive records into batches. The \nbatch_size\n argument (for training)\nor \nbatch_per_thread\n argument (for inference or evaluation) should be set when creating TFDataset.\nThe \nbatch_size\n here is used for training and it means the total batch size in distributed training.\nIn other words, it equals to the total number of records processed in one iteration in the\nwhole cluster. \nbatch_size\n should be a multiple of the total number of cores that is allocated for this Spark application\nso that we can distributed the workload evenly across the cluster. You may need to adjust your other training\nhyper-parameters when \nbatch_size\n is changed. \nbatch_per_thread\n is used for inference or evaluation\nand it means the number of records process in one iteration in one partition. \nbatch_per_thread\n is argument for tuning\nperformance and it does not affect the correctness or accuracy of the prediction or evaluation. Too small \nbatch_per_thread\n\nmight slow down the prediction/evaluation.\n\n\n\n\n\n\nFor training, \nTFDataset\n can optionally takes a validation data source for validation at the the end of each epoch.\nThe validation data source should has the same structure of the main data source used for training.\n\n\n\n\n\n\nimport numpy as np\nfrom zoo.tfpark import TFDataset\nfeature_data = np.random.randn(100, 28, 28, 1)\nlabel_data = np.random.randint(0, 10, size=(100,))\nval_feature_data = np.random.randn(100, 28, 28, 1)\nval_label_data = np.random.randint(0, 10, size=(100,))\ndataset = TFDataset.from_ndarrays((feature_data, label_data), batch_size=32, val_tensors=(val_feature_data, val_label_data))\n\n\n\n\nWorking with in-memory ndarray\n\n\nIf your input data is quite small, the simplest way to create \nTFDataset\n to convert them to ndarrays and use\n\nTFDataset.from_ndarrays()\n\n\nE.g.\n\n\nimport numpy as np\nfrom zoo.tfpark import TFDataset\nfeature_data = np.random.randn(100, 28, 28, 1)\nlabel_data = np.random.randint(0, 10, size=(100,))\ndataset = TFDataset.from_ndarrays((feature_data, label_data), batch_size=32)\n\n\n\n\nWorking with data files including (csv files, text files and TFRecord files)\n\n\nTFDataset support reading the records in tf.data.Dataset, so you can use tf.data.Dataset to read and process your data\nfiles and pass it to TFDataset. TFDataset will automatically ship the dataset to different Spark executors, shard the\ndata and batch the records for further consumption.\n\n\nIf you data files is already in HDFS, you should configure you dataset with the path with the following pattern\n\n\"hdfs://namenode:port/path/to/file.txt\"\n and TFDataset will directly access that file in HDFS in each executor.\n\nHDFS_HDFS_HOME\n environment may needs to be set to the location where hadoop is installed for both Spark driver\nand Spark executor. More information on the environment variable can be found \nhere\n.\n\n\nIf you data files are in local file system, you can either upload it to a HDFS cluster and use the above approach or\ncopy all the data files on each executor in exact the same location.\n\n\nMore information on \ntf.data.Dataset\n can be found \nhere\n.\n\n\nE.g.\n\n\nds = tf.data.TextLineDataset(\"hdfs://path/to/data.csv\")\nds = ds.map(lambda line: tf.parse_csv(line, COLUMNS))\nds = ds.map(lamdda data: extract_features_labels(data))\ndataset = TFDataset.from_tf_data_dataset(dataset, batch_size=32)\n\n\n\n\nWorking with Analytics Zoo Feature Engineering tools\n\n\nAnalytics Zoo provides a rich set of tools to build complex data engineering pipelines on top Spark, including\n\nImageSet\n, \nTextSet\n and \nFeatureSet\n. TFPark also support using those tools for manipulating data. Specifically,\nyou can use \nTFDataset.from_image_set\n, \nTFDataset.from_text_set\n and \nTFDataset.from_feature_set\n for importing\ndata pipeline written in those tools. Details for these api can be found in \nAnalytics-Zoo API Guide\n.\nMore information on Analytics Zoo's Feature Engineering tools can be found \nhere\n.\n\n\nWorking with RDD or Spark DataFrame data\n\n\nIf the about approach does not match your use cases, you can always transform your data into RDD or DataFrame using\nSpark's data processing capability.\n\n\nFor rdd, we assume each record contains a tuple of numpy.ndarrays or a tuple of list/dict of numpy.ndarrays. The first\nelement of the tuple, will be interpreted as feature and the second (optional) will be interpreted as label. Each record\nshould has the same structure. Details for these api can be found in \nAnalytics-Zoo API Guide\n.\n\n\ne.g.\n\n\nimage_rdd = sc.parallelize(np.random.randn(100, 28, 28, 1))\nlabels_rdd = sc.parallelize(np.random.randint(0, 10, size=(100,)))\nrdd = image_rdd.zip(labels_rdd)\ndataset = TFDataset.from_rdd(rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=32)\n\n\n\n\nFor dataframe, you should which columns are features and which columns are labels (optional). And currently only numerical\ntypes and vectors are supported. Details for these api can be found in \nAnalytics-Zoo API Guide\n.\n\n\ne.g.\n\n\nrdd = self.sc.range(0, 1000)\ndf = rdd.map(lambda x: (DenseVector(np.random.rand(20).astype(np.float)),\n                                x % 10)).toDF([\"feature\", \"label\"])\ndataset = TFDataset.from_dataframe(train_df,\n                                   feature_cols=[\"feature\"],\n                                   labels_cols=[\"label\"],\n                                   batch_size=32)",
            "title": "How To Import Data"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#tfdataset",
            "text": "",
            "title": "TFDataset"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#introduction",
            "text": "TFDatasets  is the main entrance point in TFPark for importing and manipulating data.\nIt represents a distributed collection of elements (backed by a RDD) to be fed into a\nTensorFlow graph for training, evaluation or inference. It provides a rich set of tools\nto import data from various data sources and work as a unified interface to interact with\nother components of TFPark.  This guide will walk you through some common cases of importing data and you can find detailed description\nof TFDataset's API in  Analytics-Zoo API Guide .",
            "title": "Introduction"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#basics",
            "text": "TFDataset 's job is to take in dataset, distribute the data across the Spark cluster and transform each data\nrecord into the format that is compatible with TFPark.  Here are a few common features that every TFDataset share:    TFDataset  will automatically stack consecutive records into batches. The  batch_size  argument (for training)\nor  batch_per_thread  argument (for inference or evaluation) should be set when creating TFDataset.\nThe  batch_size  here is used for training and it means the total batch size in distributed training.\nIn other words, it equals to the total number of records processed in one iteration in the\nwhole cluster.  batch_size  should be a multiple of the total number of cores that is allocated for this Spark application\nso that we can distributed the workload evenly across the cluster. You may need to adjust your other training\nhyper-parameters when  batch_size  is changed.  batch_per_thread  is used for inference or evaluation\nand it means the number of records process in one iteration in one partition.  batch_per_thread  is argument for tuning\nperformance and it does not affect the correctness or accuracy of the prediction or evaluation. Too small  batch_per_thread \nmight slow down the prediction/evaluation.    For training,  TFDataset  can optionally takes a validation data source for validation at the the end of each epoch.\nThe validation data source should has the same structure of the main data source used for training.    import numpy as np\nfrom zoo.tfpark import TFDataset\nfeature_data = np.random.randn(100, 28, 28, 1)\nlabel_data = np.random.randint(0, 10, size=(100,))\nval_feature_data = np.random.randn(100, 28, 28, 1)\nval_label_data = np.random.randint(0, 10, size=(100,))\ndataset = TFDataset.from_ndarrays((feature_data, label_data), batch_size=32, val_tensors=(val_feature_data, val_label_data))",
            "title": "Basics"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#working-with-in-memory-ndarray",
            "text": "If your input data is quite small, the simplest way to create  TFDataset  to convert them to ndarrays and use TFDataset.from_ndarrays()  E.g.  import numpy as np\nfrom zoo.tfpark import TFDataset\nfeature_data = np.random.randn(100, 28, 28, 1)\nlabel_data = np.random.randint(0, 10, size=(100,))\ndataset = TFDataset.from_ndarrays((feature_data, label_data), batch_size=32)",
            "title": "Working with in-memory ndarray"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#working-with-data-files-including-csv-files-text-files-and-tfrecord-files",
            "text": "TFDataset support reading the records in tf.data.Dataset, so you can use tf.data.Dataset to read and process your data\nfiles and pass it to TFDataset. TFDataset will automatically ship the dataset to different Spark executors, shard the\ndata and batch the records for further consumption.  If you data files is already in HDFS, you should configure you dataset with the path with the following pattern \"hdfs://namenode:port/path/to/file.txt\"  and TFDataset will directly access that file in HDFS in each executor. HDFS_HDFS_HOME  environment may needs to be set to the location where hadoop is installed for both Spark driver\nand Spark executor. More information on the environment variable can be found  here .  If you data files are in local file system, you can either upload it to a HDFS cluster and use the above approach or\ncopy all the data files on each executor in exact the same location.  More information on  tf.data.Dataset  can be found  here .  E.g.  ds = tf.data.TextLineDataset(\"hdfs://path/to/data.csv\")\nds = ds.map(lambda line: tf.parse_csv(line, COLUMNS))\nds = ds.map(lamdda data: extract_features_labels(data))\ndataset = TFDataset.from_tf_data_dataset(dataset, batch_size=32)",
            "title": "Working with data files including (csv files, text files and TFRecord files)"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#working-with-analytics-zoo-feature-engineering-tools",
            "text": "Analytics Zoo provides a rich set of tools to build complex data engineering pipelines on top Spark, including ImageSet ,  TextSet  and  FeatureSet . TFPark also support using those tools for manipulating data. Specifically,\nyou can use  TFDataset.from_image_set ,  TFDataset.from_text_set  and  TFDataset.from_feature_set  for importing\ndata pipeline written in those tools. Details for these api can be found in  Analytics-Zoo API Guide .\nMore information on Analytics Zoo's Feature Engineering tools can be found  here .",
            "title": "Working with Analytics Zoo Feature Engineering tools"
        },
        {
            "location": "/ProgrammingGuide/TFPark/how-to-import-data/#working-with-rdd-or-spark-dataframe-data",
            "text": "If the about approach does not match your use cases, you can always transform your data into RDD or DataFrame using\nSpark's data processing capability.  For rdd, we assume each record contains a tuple of numpy.ndarrays or a tuple of list/dict of numpy.ndarrays. The first\nelement of the tuple, will be interpreted as feature and the second (optional) will be interpreted as label. Each record\nshould has the same structure. Details for these api can be found in  Analytics-Zoo API Guide .  e.g.  image_rdd = sc.parallelize(np.random.randn(100, 28, 28, 1))\nlabels_rdd = sc.parallelize(np.random.randint(0, 10, size=(100,)))\nrdd = image_rdd.zip(labels_rdd)\ndataset = TFDataset.from_rdd(rdd,\n                             features=(tf.float32, [28, 28, 1]),\n                             labels=(tf.int32, []),\n                             batch_size=32)  For dataframe, you should which columns are features and which columns are labels (optional). And currently only numerical\ntypes and vectors are supported. Details for these api can be found in  Analytics-Zoo API Guide .  e.g.  rdd = self.sc.range(0, 1000)\ndf = rdd.map(lambda x: (DenseVector(np.random.rand(20).astype(np.float)),\n                                x % 10)).toDF([\"feature\", \"label\"])\ndataset = TFDataset.from_dataframe(train_df,\n                                   feature_cols=[\"feature\"],\n                                   labels_cols=[\"label\"],\n                                   batch_size=32)",
            "title": "Working with RDD or Spark DataFrame data"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/",
            "text": "There are a number of built-in \ncompiled\n text models in Analytics Zoo TFPark for Natural Language Processing (NLP) tasks based on \nKerasModel\n.\n\n\nSee \nthis page\n for more details about how to construct built-in models for intent extraction, named entity extraction and pos tagging. etc.\n\n\nIn this page, we show the general steps how to train and evaluate an \nNER\n model in a distributed fashion and use this model for distributed inference.\nFor other models, the steps are more or less quite similar.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\n\n\nModel Construction\n\n\nYou can easily construct a model for named entity recognition using the following API.\n\n\nfrom zoo.tfpark.text.keras import NER\n\nmodel = NER(num_entities, word_vocab_size, char_vocab_size, word_length)\n\n\n\n\n\n\nData Preparation\n\n\nThe NER model has two inputs: word indices and character indices.\n\n\nThus, each raw text record needs to go through word-wise tokenization, character-wise segmentation and alignment to the same target length for preprocessing.\n\n\nIf you are using numpy arrays, then the input \nx\n should be a list of two numpy arrays:\n\n\n\n\nx_words\n of shape (batch, sequence_length) for word indices\n\n\nx_chars\n of shape (batch, sequence_length, word_length) for character indices.\n\n\nx = [x_words, x_char]\n\n\n\n\nIf there are labels (for training and evaluation), \ny\n should be another numpy array of shape (batch, sequence_length, word_length) for entity tags.\n\n\nAlternatively, you can construct a \nTFDataSet\n directly if you are dealing with RDD.\nEach record in TFDataSet should contain word indices, character indices and labels (if any) as well.\n\n\n\n\nModel Training\n\n\nYou can easily call \nfit\n to train the NER model in a distributed fashion. You don't need to specify \ny\n if \nx\n is already a TFDataSet.\n\n\nmodel.fit(x, y, batch_size, epochs, distributed=True)\n\n\n\n\n\n\nModel Evaluation\n\n\nYou can easily call \nevaluate\n to evaluate the NER model in a distributed fashion. You don't need to specify \ny\n if \nx\n is already a TFDataSet.\n\n\nresult = model.evaluate(x, y, distributed=True)\n\n\n\n\n\n\nModel Save and Load\n\n\nAfter training, you can save the \nNER\n model to a single HDF5 file.\n\n\nmodel.save_model(path)\n\n\n\n\nFor inference, you can load a directly trained \nNER\n model (with weights) from HDF5 file.\n\n\nfrom zoo.tfpark.text.keras import NER\n\nmodel = NER.load_model(path)\n\n\n\n\n\n\nModel Inference\n\n\nYou can easily call \npredict\n to use the trained NER model for distributed inference. Note that you don't necessarily need labels for prediction.\n\n\npredictions = model.predict(x, distributed=True)",
            "title": "Text Models"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#model-construction",
            "text": "You can easily construct a model for named entity recognition using the following API.  from zoo.tfpark.text.keras import NER\n\nmodel = NER(num_entities, word_vocab_size, char_vocab_size, word_length)",
            "title": "Model Construction"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#data-preparation",
            "text": "The NER model has two inputs: word indices and character indices.  Thus, each raw text record needs to go through word-wise tokenization, character-wise segmentation and alignment to the same target length for preprocessing.  If you are using numpy arrays, then the input  x  should be a list of two numpy arrays:   x_words  of shape (batch, sequence_length) for word indices  x_chars  of shape (batch, sequence_length, word_length) for character indices.  x = [x_words, x_char]   If there are labels (for training and evaluation),  y  should be another numpy array of shape (batch, sequence_length, word_length) for entity tags.  Alternatively, you can construct a  TFDataSet  directly if you are dealing with RDD.\nEach record in TFDataSet should contain word indices, character indices and labels (if any) as well.",
            "title": "Data Preparation"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#model-training",
            "text": "You can easily call  fit  to train the NER model in a distributed fashion. You don't need to specify  y  if  x  is already a TFDataSet.  model.fit(x, y, batch_size, epochs, distributed=True)",
            "title": "Model Training"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#model-evaluation",
            "text": "You can easily call  evaluate  to evaluate the NER model in a distributed fashion. You don't need to specify  y  if  x  is already a TFDataSet.  result = model.evaluate(x, y, distributed=True)",
            "title": "Model Evaluation"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#model-save-and-load",
            "text": "After training, you can save the  NER  model to a single HDF5 file.  model.save_model(path)  For inference, you can load a directly trained  NER  model (with weights) from HDF5 file.  from zoo.tfpark.text.keras import NER\n\nmodel = NER.load_model(path)",
            "title": "Model Save and Load"
        },
        {
            "location": "/ProgrammingGuide/TFPark/text-models/#model-inference",
            "text": "You can easily call  predict  to use the trained NER model for distributed inference. Note that you don't necessarily need labels for prediction.  predictions = model.predict(x, distributed=True)",
            "title": "Model Inference"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/",
            "text": "Analytics Zoo provides a built-in BERTClassifier in TFPark for Natural Language Processing (NLP) classification tasks based on \nTFEstimator\n and BERT.\n\n\nBidirectional Encoder Representations from Transformers (BERT) is Google's state-of-the-art pre-trained NLP model.\nYou may refer to \nhere\n for more details.\n\n\nBERTClassifier is a pre-built TFEstimator that takes the hidden state of the first token to do classification.\n\n\nIn this page, we show the general steps how to train and evaluate an \nBERTClassifier\n in a distributed fashion and use this estimator for distributed inference.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\n\n\nBERTClassifier Construction\n\n\nYou can easily construct an estimator for classification based on BERT using the following API.\n\n\nfrom zoo.tfpark.text.estimator import BERTClassifier\n\nestimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint, optimizer=tf.train.AdamOptimizer(learning_rate), model_dir=\"/tmp/bert\")\n\n\n\n\n\n\nData Preparation\n\n\nBERT has three inputs of the same sequence length: input_ids, input_mask and token_type_ids. \n\n\nThe preprocessing steps should follow BERT's conventions. You may refer to BERT TensorFlow \nrun_classifier example\n for more details.\n\n\nTo construct the input function for BERTClassifier, you can use the following API:\n\n\nfrom zoo.tfpark.text.estimator import bert_input_fn\n\ninput_fn = bert_input_fn(rdd, max_seq_length, batch_size)\n\n\n\n\n\n\nFor training and evaluation, each element in rdd should be a tuple: (feature dict, label). Label is supposed to be an integer.\n\n\nFor prediction, each element in rdd should be a feature dict.\n\n\nThe keys of feature dict should be \ninput_ids\n, \ninput_mask\n and \ntoken_type_ids\n and the values should be the corresponding preprocessed results of max_seq_length for a record.\n\n\n\n\n\n\nEstimator Training\n\n\nYou can easily call \ntrain\n to train the BERTClassifier in a distributed fashion.\n\n\nestimator.train(train_input_fn, steps)\n\n\n\n\nYou can find the trained checkpoints saved under \nmodel_dir\n, which is specified when you initiate BERTClassifier.\n\n\n\n\nEstimator Evaluation\n\n\nYou can easily call \nevaluate\n to evaluate the BERTClassifier in a distributed fashion using top1 accuracy.\n\n\nresult = estimator.evaluate(eval_input_fn, eval_methods=[\"acc\"])\n\n\n\n\n\n\nEstimator Inference\n\n\nYou can easily call \npredict\n to use the trained BERTClassifier for distributed inference.\n\n\npredictions_rdd = estimator.predict(test_input_fn)",
            "title": "BERT Classifier"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/#bertclassifier-construction",
            "text": "You can easily construct an estimator for classification based on BERT using the following API.  from zoo.tfpark.text.estimator import BERTClassifier\n\nestimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint, optimizer=tf.train.AdamOptimizer(learning_rate), model_dir=\"/tmp/bert\")",
            "title": "BERTClassifier Construction"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/#data-preparation",
            "text": "BERT has three inputs of the same sequence length: input_ids, input_mask and token_type_ids.   The preprocessing steps should follow BERT's conventions. You may refer to BERT TensorFlow  run_classifier example  for more details.  To construct the input function for BERTClassifier, you can use the following API:  from zoo.tfpark.text.estimator import bert_input_fn\n\ninput_fn = bert_input_fn(rdd, max_seq_length, batch_size)   For training and evaluation, each element in rdd should be a tuple: (feature dict, label). Label is supposed to be an integer.  For prediction, each element in rdd should be a feature dict.  The keys of feature dict should be  input_ids ,  input_mask  and  token_type_ids  and the values should be the corresponding preprocessed results of max_seq_length for a record.",
            "title": "Data Preparation"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/#estimator-training",
            "text": "You can easily call  train  to train the BERTClassifier in a distributed fashion.  estimator.train(train_input_fn, steps)  You can find the trained checkpoints saved under  model_dir , which is specified when you initiate BERTClassifier.",
            "title": "Estimator Training"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/#estimator-evaluation",
            "text": "You can easily call  evaluate  to evaluate the BERTClassifier in a distributed fashion using top1 accuracy.  result = estimator.evaluate(eval_input_fn, eval_methods=[\"acc\"])",
            "title": "Estimator Evaluation"
        },
        {
            "location": "/ProgrammingGuide/TFPark/bert-classifier/#estimator-inference",
            "text": "You can easily call  predict  to use the trained BERTClassifier for distributed inference.  predictions_rdd = estimator.predict(test_input_fn)",
            "title": "Estimator Inference"
        },
        {
            "location": "/ProgrammingGuide/pytorch/",
            "text": "Analytics-Zoo supports distributed Pytorch training and inference on on Apache Spark. User can\ndefine their model and loss function with Pytorch API, and run it in a distributed environment\nwith the wrapper layers provided by Analytics Zoo.\n\n\nSystem Requirement\n\n\nPytorch version: 1.5.0 or above\n\ntorchvision: 0.6.0 or above\n\ncloudpickle: 1.6.0\n\njep: 3.9.0\n\nPython: 3.7\n\n\nPytorch API\n\n\nA few wrappers are defined in Analytics Zoo for Pytorch:\n\n\n\n\nTorchModel: TorchModel is a wrapper class for Pytorch model.\nUser may create a TorchModel by providing a Pytorch model, e.g.\n\n\n\n\nfrom zoo.pipeline.api.torch import TorchModel\nimport torchvision\nzoo_model = TorchModel.from_pytorch(torchvision.models.resnet18(pretrained=True))\n\n\n\n\nThe above line creates TorchModel wrapping a ResNet model, and user can use the TorchModel for\ntraining or inference with Analytics Zoo.\n\n\n\n\nTorchLoss: TorchLoss is a wrapper for loss functions defined by Pytorch.\nUser may create a TorchLoss from a Pytorch Criterion, \n\n\n\n\nimport torch\nfrom zoo.pipeline.api.torch import TorchLoss\n\naz_criterion = TorchLoss.from_pytorch(torch.nn.MSELoss())\n\n\n\n\nor from a custom loss function, which takes input and label as parameters\n\n\nimport torch\nfrom zoo.pipeline.api.torch import TorchLoss\n\ncriterion = torch.nn.MSELoss()\n\n# this loss function is calculating loss for a multi-output model\ndef lossFunc(input, label):\n    loss1 = criterion(input[0], label[0])\n    loss2 = criterion(input[1], label[1])\n    loss = loss1 + 0.4 * loss2\n    return loss\n\naz_criterion = TorchLoss.from_pytorch(lossFunc)\n\n\n\n\n\n\nTorchOptim: TorchOptim wraps a torch optimizer for distributed training.\n\n\n\n\nfrom zoo.pipeline.api.torch import TorchOptim\nimport torch\n\nmodel = torchvision.models.resnet18(pretrained=True))\nadam = torch.optim.Adam(model.parameters())\nzoo_optimizer = TorchOptim.from_pytorch(adam)\n\n\n\n\nExamples\n\n\nHere we provide a simple end to end example, where we use TorchModel and TorchLoss to\ntrain a simple model with Spark DataFrame.\n\n\n#\n# Copyright 2018 Analytics Zoo Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nimport torch\nimport torch.nn as nn\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.torch import TorchModel, TorchLoss, TorchOptim\nfrom zoo.pipeline.nnframes import *\n\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.sql import SparkSession\n\n\n# define model with Pytorch\nclass SimpleTorchModel(nn.Module):\n    def __init__(self):\n        super(SimpleTorchModel, self).__init__()\n        self.dense1 = nn.Linear(2, 4)\n        self.dense2 = nn.Linear(4, 1)\n\n    def forward(self, x):\n        x = self.dense1(x)\n        x = torch.sigmoid(self.dense2(x))\n        return x\n\nif __name__ == '__main__':\n    sc = init_spark_on_local(cores=1)\n    spark = SparkSession \\\n        .builder \\\n        .getOrCreate()\n\n    df = spark.createDataFrame(\n        [(Vectors.dense([2.0, 1.0]), 1.0),\n         (Vectors.dense([1.0, 2.0]), 0.0),\n         (Vectors.dense([2.0, 1.0]), 1.0),\n         (Vectors.dense([1.0, 2.0]), 0.0)],\n        [\"features\", \"label\"])\n\n    torch_model = SimpleTorchModel()\n    torch_criterion = nn.MSELoss()\n    torch_optimizer = torch.optim.Adam(torch_model.parameters())\n\n    az_model = TorchModel.from_pytorch(torch_model)\n    az_criterion = TorchLoss.from_pytorch(torch_criterion)\n    az_optimizer = TorchOptim.from_pytorch(torch_optimizer)\n\n    classifier = NNClassifier(az_model, az_criterion) \\\n        .setBatchSize(4) \\\n        .setOptimMethod(az_optimizer) \\\n        .setLearningRate(0.01) \\\n        .setMaxEpoch(10)\n\n    nnClassifierModel = classifier.fit(df)\n\n    print(\"After training: \")\n    res = nnClassifierModel.transform(df)\n    res.show(10, False)\n\n\n\n\n\nYou can simply use \npython\n to execute the script above. We expects to see the output like:\n\n\n+---------+-----+----------+\n|features |label|prediction|\n+---------+-----+----------+\n|[2.0,1.0]|1.0  |1.0       |\n|[1.0,2.0]|0.0  |0.0       |\n|[2.0,1.0]|1.0  |1.0       |\n|[1.0,2.0]|0.0  |0.0       |\n+---------+-----+----------+\n\n\n\n\nFAQ\n\n\n\n\n\n\nDoes analytics-zoo's distributed pytorch support training or inference?\n\nAnalytics-Zoo support both training and inference.\n\n\n\n\n\n\nHow to prepare the environment?\n\nWe recommend you to use \nAnaconda\n to prepare the enviroments, especially if you want to run on a yarn cluster(yarn-client mode only). \n\n\n\n\n\n\nconda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[torch]\n\n\n\n\nNote that the extra dependencies (including BigDL, torch, torchvision, jep, cloudpickle, conda-pack) will be installed by specifying [torch].  \n\n\n\n\n\n\nHow to determine how many resources do you use in analytics-zoo's distributed mode?\n\nIf you are running your jobs on yarn cluster, you can use \ninit_spark_on_yarn\n from package \nzoo.common.nncontext\n to request cores and memorys from resource manager.\n\nIf you are running your jobs on Spark standalone cluster, you can use \ninit_spark_standalone\n from package \nzoo.common.nncontext\n to request resources from Spark master.\n\nIf you are running your jobs on spark local mode(single-node, pseudo-distributed), you can use \ninit_spark_on_local\n from package \nzoo.common.nncontext\n to declare how many cores and memorys.\n\n\n\n\n\n\nSupported torch and torchvision version?\n\nWe support torch 1.5.x and 1.6.x, torchvision's version should match torch's version.  \n\n\n\n\n\n\nHow to migrate training from pytorch to AZ?\n\nHere is a simple example migrate \npytorch mnist example\n to \nanalytics-zoo distributed pytorch mnist example\n.",
            "title": "PyTorch"
        },
        {
            "location": "/ProgrammingGuide/pytorch/#system-requirement",
            "text": "Pytorch version: 1.5.0 or above \ntorchvision: 0.6.0 or above \ncloudpickle: 1.6.0 \njep: 3.9.0 \nPython: 3.7",
            "title": "System Requirement"
        },
        {
            "location": "/ProgrammingGuide/pytorch/#pytorch-api",
            "text": "A few wrappers are defined in Analytics Zoo for Pytorch:   TorchModel: TorchModel is a wrapper class for Pytorch model.\nUser may create a TorchModel by providing a Pytorch model, e.g.   from zoo.pipeline.api.torch import TorchModel\nimport torchvision\nzoo_model = TorchModel.from_pytorch(torchvision.models.resnet18(pretrained=True))  The above line creates TorchModel wrapping a ResNet model, and user can use the TorchModel for\ntraining or inference with Analytics Zoo.   TorchLoss: TorchLoss is a wrapper for loss functions defined by Pytorch.\nUser may create a TorchLoss from a Pytorch Criterion,    import torch\nfrom zoo.pipeline.api.torch import TorchLoss\n\naz_criterion = TorchLoss.from_pytorch(torch.nn.MSELoss())  or from a custom loss function, which takes input and label as parameters  import torch\nfrom zoo.pipeline.api.torch import TorchLoss\n\ncriterion = torch.nn.MSELoss()\n\n# this loss function is calculating loss for a multi-output model\ndef lossFunc(input, label):\n    loss1 = criterion(input[0], label[0])\n    loss2 = criterion(input[1], label[1])\n    loss = loss1 + 0.4 * loss2\n    return loss\n\naz_criterion = TorchLoss.from_pytorch(lossFunc)   TorchOptim: TorchOptim wraps a torch optimizer for distributed training.   from zoo.pipeline.api.torch import TorchOptim\nimport torch\n\nmodel = torchvision.models.resnet18(pretrained=True))\nadam = torch.optim.Adam(model.parameters())\nzoo_optimizer = TorchOptim.from_pytorch(adam)",
            "title": "Pytorch API"
        },
        {
            "location": "/ProgrammingGuide/pytorch/#examples",
            "text": "Here we provide a simple end to end example, where we use TorchModel and TorchLoss to\ntrain a simple model with Spark DataFrame.  #\n# Copyright 2018 Analytics Zoo Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nimport torch\nimport torch.nn as nn\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.torch import TorchModel, TorchLoss, TorchOptim\nfrom zoo.pipeline.nnframes import *\n\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.sql import SparkSession\n\n\n# define model with Pytorch\nclass SimpleTorchModel(nn.Module):\n    def __init__(self):\n        super(SimpleTorchModel, self).__init__()\n        self.dense1 = nn.Linear(2, 4)\n        self.dense2 = nn.Linear(4, 1)\n\n    def forward(self, x):\n        x = self.dense1(x)\n        x = torch.sigmoid(self.dense2(x))\n        return x\n\nif __name__ == '__main__':\n    sc = init_spark_on_local(cores=1)\n    spark = SparkSession \\\n        .builder \\\n        .getOrCreate()\n\n    df = spark.createDataFrame(\n        [(Vectors.dense([2.0, 1.0]), 1.0),\n         (Vectors.dense([1.0, 2.0]), 0.0),\n         (Vectors.dense([2.0, 1.0]), 1.0),\n         (Vectors.dense([1.0, 2.0]), 0.0)],\n        [\"features\", \"label\"])\n\n    torch_model = SimpleTorchModel()\n    torch_criterion = nn.MSELoss()\n    torch_optimizer = torch.optim.Adam(torch_model.parameters())\n\n    az_model = TorchModel.from_pytorch(torch_model)\n    az_criterion = TorchLoss.from_pytorch(torch_criterion)\n    az_optimizer = TorchOptim.from_pytorch(torch_optimizer)\n\n    classifier = NNClassifier(az_model, az_criterion) \\\n        .setBatchSize(4) \\\n        .setOptimMethod(az_optimizer) \\\n        .setLearningRate(0.01) \\\n        .setMaxEpoch(10)\n\n    nnClassifierModel = classifier.fit(df)\n\n    print(\"After training: \")\n    res = nnClassifierModel.transform(df)\n    res.show(10, False)  You can simply use  python  to execute the script above. We expects to see the output like:  +---------+-----+----------+\n|features |label|prediction|\n+---------+-----+----------+\n|[2.0,1.0]|1.0  |1.0       |\n|[1.0,2.0]|0.0  |0.0       |\n|[2.0,1.0]|1.0  |1.0       |\n|[1.0,2.0]|0.0  |0.0       |\n+---------+-----+----------+",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/pytorch/#faq",
            "text": "Does analytics-zoo's distributed pytorch support training or inference? \nAnalytics-Zoo support both training and inference.    How to prepare the environment? \nWe recommend you to use  Anaconda  to prepare the enviroments, especially if you want to run on a yarn cluster(yarn-client mode only).     conda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[torch]  Note that the extra dependencies (including BigDL, torch, torchvision, jep, cloudpickle, conda-pack) will be installed by specifying [torch].      How to determine how many resources do you use in analytics-zoo's distributed mode? \nIf you are running your jobs on yarn cluster, you can use  init_spark_on_yarn  from package  zoo.common.nncontext  to request cores and memorys from resource manager. \nIf you are running your jobs on Spark standalone cluster, you can use  init_spark_standalone  from package  zoo.common.nncontext  to request resources from Spark master. \nIf you are running your jobs on spark local mode(single-node, pseudo-distributed), you can use  init_spark_on_local  from package  zoo.common.nncontext  to declare how many cores and memorys.    Supported torch and torchvision version? \nWe support torch 1.5.x and 1.6.x, torchvision's version should match torch's version.      How to migrate training from pytorch to AZ? \nHere is a simple example migrate  pytorch mnist example  to  analytics-zoo distributed pytorch mnist example .",
            "title": "FAQ"
        },
        {
            "location": "/ProgrammingGuide/rayonspark/",
            "text": "Introduction\n\n\nRay\n is a distributed framework for emerging AI applications open-sourced by \nUC Berkeley RISELab\n. \nIt implements a unified interface, distributed scheduler, and distributed and fault-tolerant store to address the new and demanding systems requirements for advanced AI technologies. \n\n\nRay allows users to easily and efficiently to run many emerging AI applications, such as deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc.\n\n\nAnalytics Zoo provides a mechanism to deploy Python dependencies and Ray services automatically\nacross yarn cluster, meaning python users would be able to run \nanalytics-zoo\n or \nray\n\nin a pythonic way on yarn without \nspark-submit\n or installing analytics-zoo or ray across all cluster nodes.\n\n\n\n\nSteps to run RayOnSpark\n\n\nNOTE:\n We have been tested on Ray 0.8.4 and you are highly recommended to use this Ray version.\n\n\n1) Install \nConda\n in your environment.\n\n\n2) Create a new conda environment (with name \"zoo\" for example):\n\n\nconda create -n zoo python=3.6\nsource activate zoo\n\n\n\n\n3) Install analytics-zoo in the created conda environment:\n\n\npip install analytics-zoo[ray]\n\n\n\n\nNote that the essential dependencies (including \nray==0.8.4\n, \npsutil\n, \naiohttp\n, \nsetproctitle\n, \npyarrow==0.17.0\n) will be installed by specifying the extras key \n[ray]\n when you pip install analytics-zoo.\n\n\n4) Download JDK8 and set the environment variable: JAVA_HOME (recommended).\n\n\nYou can also install JDK via conda without setting the JAVA_HOME manually:\n\n\nconda install -c anaconda openjdk=8.0.152\n\n\n5) Start \npython\n and then execute the following example.\n\n\n\n\nCreate a SparkContext on yarn, only \nyarn-client mode\n is supported for now:\n\n\n\n\nfrom zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")\n\n\n\n\n\n\n[Optional] If you don't have a yarn cluster, this can also be tested locally by creating a SparkContext\nwith \ninit_spark_on_local\n:\n\n\n\n\nfrom zoo import init_spark_on_local\n\nsc = init_spark_on_local(cores=4)\n\n\n\n\n\n\n\n\nOnce the SparkContext is created, we can write more logic here such as training an Analytics Zoo model\nor launching ray on Spark.\n\n\n\n\n\n\nRun the following simple example to launch a ray cluster on top of the SparkContext configurations and verify if RayOnSpark can work smoothly.\n\n\n\n\n\n\nimport ray\nfrom zoo.ray import RayContext\n\nray_ctx = RayContext(sc=sc, object_store_memory=\"5g\")\nray_ctx.init()\n\n@ray.remote\nclass Counter(object):\n      def __init__(self):\n          self.n = 0\n\n      def increment(self):\n          self.n += 1\n          return self.n\n\n\ncounters = [Counter.remote() for i in range(5)]\nprint(ray.get([c.increment.remote() for c in counters]))\n\nray_ctx.stop()\nsc.stop()\n\n\n\n\n\n\nFAQ\n\n\n\n\nIf you encounter the following error when initiating RayOnSpark, especially when you are using Spark standalone cluster:\n\n\n\n\nThis system supports the C.UTF-8 locale which is recommended. You might be able to resolve your issue by exporting the following environment variables:\n\n    export LC_ALL=C.UTF-8\n    export LANG=C.UTF-8\n\n\n\n\nAdd the environment variables when initiating RayContext would resolve the issue:\n\n\nray_ctx = RayContext(sc=sc, object_store_memory=\"5g\", env={\"LANG\": \"C.UTF-8\", \"LC_ALL\": \"C.UTF-8\"})",
            "title": "RayOnSpark"
        },
        {
            "location": "/ProgrammingGuide/rayonspark/#introduction",
            "text": "Ray  is a distributed framework for emerging AI applications open-sourced by  UC Berkeley RISELab . \nIt implements a unified interface, distributed scheduler, and distributed and fault-tolerant store to address the new and demanding systems requirements for advanced AI technologies.   Ray allows users to easily and efficiently to run many emerging AI applications, such as deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc.  Analytics Zoo provides a mechanism to deploy Python dependencies and Ray services automatically\nacross yarn cluster, meaning python users would be able to run  analytics-zoo  or  ray \nin a pythonic way on yarn without  spark-submit  or installing analytics-zoo or ray across all cluster nodes.",
            "title": "Introduction"
        },
        {
            "location": "/ProgrammingGuide/rayonspark/#steps-to-run-rayonspark",
            "text": "NOTE:  We have been tested on Ray 0.8.4 and you are highly recommended to use this Ray version.  1) Install  Conda  in your environment.  2) Create a new conda environment (with name \"zoo\" for example):  conda create -n zoo python=3.6\nsource activate zoo  3) Install analytics-zoo in the created conda environment:  pip install analytics-zoo[ray]  Note that the essential dependencies (including  ray==0.8.4 ,  psutil ,  aiohttp ,  setproctitle ,  pyarrow==0.17.0 ) will be installed by specifying the extras key  [ray]  when you pip install analytics-zoo.  4) Download JDK8 and set the environment variable: JAVA_HOME (recommended).  You can also install JDK via conda without setting the JAVA_HOME manually:  conda install -c anaconda openjdk=8.0.152  5) Start  python  and then execute the following example.   Create a SparkContext on yarn, only  yarn-client mode  is supported for now:   from zoo import init_spark_on_yarn\n\nsc = init_spark_on_yarn(\n    hadoop_conf=\"path to the yarn configuration folder\",\n    conda_name=\"zoo\", # The name of the created conda-env\n    num_executor=2,\n    executor_cores=4,\n    executor_memory=\"8g\",\n    driver_memory=\"2g\",\n    driver_cores=4,\n    extra_executor_memory_for_ray=\"10g\")   [Optional] If you don't have a yarn cluster, this can also be tested locally by creating a SparkContext\nwith  init_spark_on_local :   from zoo import init_spark_on_local\n\nsc = init_spark_on_local(cores=4)    Once the SparkContext is created, we can write more logic here such as training an Analytics Zoo model\nor launching ray on Spark.    Run the following simple example to launch a ray cluster on top of the SparkContext configurations and verify if RayOnSpark can work smoothly.    import ray\nfrom zoo.ray import RayContext\n\nray_ctx = RayContext(sc=sc, object_store_memory=\"5g\")\nray_ctx.init()\n\n@ray.remote\nclass Counter(object):\n      def __init__(self):\n          self.n = 0\n\n      def increment(self):\n          self.n += 1\n          return self.n\n\n\ncounters = [Counter.remote() for i in range(5)]\nprint(ray.get([c.increment.remote() for c in counters]))\n\nray_ctx.stop()\nsc.stop()",
            "title": "Steps to run RayOnSpark"
        },
        {
            "location": "/ProgrammingGuide/rayonspark/#faq",
            "text": "If you encounter the following error when initiating RayOnSpark, especially when you are using Spark standalone cluster:   This system supports the C.UTF-8 locale which is recommended. You might be able to resolve your issue by exporting the following environment variables:\n\n    export LC_ALL=C.UTF-8\n    export LANG=C.UTF-8  Add the environment variables when initiating RayContext would resolve the issue:  ray_ctx = RayContext(sc=sc, object_store_memory=\"5g\", env={\"LANG\": \"C.UTF-8\", \"LC_ALL\": \"C.UTF-8\"})",
            "title": "FAQ"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/",
            "text": "Programming Guide\n\n\nAnalytics Zoo Cluster Serving\u00a0is a lightweight distributed, real-time serving solution that supports a wide range of deep learning models (such as TensorFlow, PyTorch, Caffe, BigDL and OpenVINO models). It provides a simple pub/sub API, so that the users can easily send their inference requests to the input queue (using a simple Python API);\u00a0Cluster Serving\u00a0will then automatically manage the scale-out and real-time model inference across a large cluster (using distributed streaming frameworks such as Apache Spark Streaming, Apache Flink, etc.) \n\n\nThe overall architecture of Analytics Zoo Cluster Serving solution is illustrated as below: \n\n\n\n\nThis page contains the guide for you to run Analytics Zoo Cluster Serving, including following:\n\n\n\n\n\n\nQuick Start\n\n\n\n\n\n\nWorkflow Overview\n \n\n\n\n\n\n\nDeploy Your Own Cluster Serving\n\n\n\n\n\n\nInstallation\n\n\n\n\n\n\nConfiguration\n \n\n\n\n\n\n\nLaunching Service\n\n\n\n\n\n\nModel inference\n\n\n\n\n\n\nOptional Operations\n\n\n\n\n\n\nUpdate Model or Configurations\n\n\n\n\n\n\nLogs and Visualization\n\n\n\n\n\n\n\n\n\n\nQuick Start\n\n\nThis section provides a quick start example for you to run Analytics Zoo Cluster Serving. To simplify the example, we use docker to run Cluster Serving. If you do not have docker installed, \ninstall docker\n first. The quick start example contains all the necessary components so the first time users can get it up and running within minutes:\n\n\n\n\nA docker image for Analytics Zoo Cluster Serving (with all dependencies installed)\n\n\nA sample configuration file\n\n\nA sample trained TensorFlow model, and sample data for inference\n\n\nA sample Python client program\n\n\n\n\nUse one command to run Cluster Serving container. (We provide quick start model in older version of docker image, for newest version, please refer to following sections and we remove the model to reduce the docker image size).\n\n\ndocker run --name cluster-serving -itd --net=host intelanalytics/zoo-cluster-serving:0.9.0\n\n\n\n\nLog into the container using \ndocker exec -it cluster-serving bash\n, go to Cluster Serving working directory by \ncd cluster-serving\n.\n\n\nYou can see prepared TensorFlow frozen ResNet50 model in \nresources/model\n directory with following structure.\n\n\ncluster-serving | \n               -- | model\n                 -- frozen_graph.pb\n                 -- graph_meta.json\n\n\n\n\nModify \nconfig.yaml\n and add following to \nfilter:\n config\n\n\ndata:\n  shape: [3,224,224]\n  filter: topN(1)\n\n\n\n\nThis will tell the shape of input image is [3,224,224] and rank Top-1 result of the model output.\n\n\nStart Cluster Serving using \ncluster-serving-start\n. \n\n\nRun python program \npython3 image_classification_and_object_detection_quick_start.py -i resources/test_image\n to push data into queue and get inference result. \n\n\nThen you can see the inference output in console. \n\n\nimage: fish1.jpeg, classification-result:class: 5's prob: 0.18204997\nimage: dog1.jpeg, classification-result:class: 267's prob: 0.27166227\nimage: cat1.jpeg, classification-result:class: 292's prob: 0.32633427\n\n\n\n\nWow! You made it!\n\n\nNote that the Cluster Serving quick start example will run on your local node only. Check the \nDeploy Your Own Cluster Serving\n section for how to configure and run Cluster Serving in a distributed fashion.\n\n\nFor more details, refer to following sections.\n\n\nWorkflow Overview\n\n\nThe figure below illustrates the simple 3-step \"Prepare-Launch-Inference\" workflow for Cluster Serving.\n\n\n\n\n1. Install and prepare Cluster Serving environment on a local node:\n\n\n\n\nCopy a previously trained model to the local node; currently TensorFlow, PyTorch, Caffe, BigDL and OpenVINO models are supported.\n\n\nInstall Analytics Zoo on the local node (e.g., using a single pip install command)\n\n\nConfigure Cluster Server on the local node, including the file path to the trained model and the address of the cluster (such as Apache Hadoop YARN cluster, K8s cluster, etc.).\nPlease note that you only need to deploy the Cluster Serving solution on a single local node, and NO modifications are needed for the (YARN or K8s) cluster. \n\n\n\n\n2. Launch the Cluster Serving service\n\n\nYou can launch the Cluster Serving service by running the startup script on the local node. Under the hood, Cluster Serving will automatically deploy the trained model and serve the model inference requests across the cluster in a distributed fashion. You may monitor its runtime status (such as inference throughput) using TensorBoard. \n\n\n3. Distributed, real-time (streaming) inference\n\n\nCluster Serving provides a simple pub/sub API to the users, so that you can easily send the inference requests to an input queue (currently Redis Streams is used) using a simple Python API.\n\n\nCluster Serving will then read the requests from the Redis stream, run the distributed real-time inference across the cluster (using Flink), and return the results back through Redis. As a result, you may get the inference results again using a simple Python API.\n\n\nDeploy your Own Cluster Serving\n\n\n1. Installation\n\n\nIt is recommended to install Cluster Serving by pulling the pre-built Docker image to your local node, which have packaged all the required dependencies. Alternatively, you may also manually install Cluster Serving (through either pip or direct downloading), Redis on the local node.\n\n\nDocker\n\n\ndocker pull intelanalytics/zoo-cluster-serving\n\n\n\n\nthen, (or directly run \ndocker run\n, it will pull the image if it does not exist)\n\n\ndocker run --name cluster-serving -itd --net=host intelanalytics/zoo-cluster-serving:0.9.0\n\n\n\n\nLog into the container\n\n\ndocker exec -it cluster-serving bash\n\n\n\n\ncd ./cluster-serving\n, you can see all the environments are prepared.\n\n\nYarn user\n\n\nFor Yarn user using docker, start Flink on Yarn inside the container. The other operations are the same.\n\n\nManual installation\n\n\nRequirements\n\n\nNon-Docker users need to install \nFlink 1.10.0+\n, 1.10.0 by default, \nRedis 5.0.0+\n, 5.0.5 by default.\n\n\nAfter preparing dependencies above, make sure the environment variable \n$FLINK_HOME\n (/path/to/flink-FLINK_VERSION-bin), \n$REDIS_HOME\n(/path/to/redis-REDIS_VERSION) is set before following steps. \n\n\nInstall Cluster Serving by download release\n\n\nFor users who need to deploy and start Cluster Serving, download Cluster Serving zip \nanalytics-zoo-xxx-cluster-serving-all.zip\n from \nhere\n and unzip it, then run \nsource cluster-serving-setup.sh\n.\nFor users who need to do inference, aka. predict data only, download Analytics Zoo python zip \nanalytics-zoo-xxx-cluster-serving-python.zip\n from \nhere\n and run \nexport PYTHONPATH=$PYTHONPATH:/path/to/zip\n to add this zip to \nPYTHONPATH\n environment variable.\n\n\nInstall Cluster Serving by pip\n\n\nDownload package from \nhere\n, run following command to install Cluster Serving\n\n\npip install analytics_zoo_serving-*.whl\n\n\n\n\nFor users who need to deploy and start Cluster Serving, run \ncluster-serving-init\n to download and prepare dependencies.\n\n\nFor users who need to do inference, aka. predict data only, the environment is ready.\n\n\n2. Configuration\n\n\nHow to Config\n\n\nAfter \nInstallation\n, you will see a config file \nconfig.yaml\n in your current working directory. This file contains all the configurations that you can customize for your Cluster Serving. See an example of \nconfig.yaml\n below.\n\n\n## Analytics Zoo Cluster Serving Config Example\n\nmodel:\n  # model path must be set\n  path: /opt/work/model\nparams:\n  # default, 4\n  core_num:  \n\n\n\n\nPreparing Model\n\n\nCurrently Analytics Zoo Cluster Serving supports TensorFlow, OpenVINO, PyTorch, BigDL, Caffe models. Supported types are listed below.\n\n\nYou need to put your model file into a directory with layout like following according to model type, note that only one model is allowed in your directory. Then, set in \nconfig.yaml\n file with \nmodel:path:/path/to/dir\n.\n\n\nTensorflow*\n\n\nTensorflow SavedModel***\n\n\n|-- model\n   |-- saved_model.pb\n   |-- variables\n       |-- variables.data-00000-of-00001\n       |-- variables.index\n\n\n\n\nTensorflow Frozen Graph\n\n\n|-- model\n   |-- frozen_graph.pb\n   |-- graph_meta.json\n\n\n\n\nTensorflow Checkpoint\n\nPlease refer to \nfreeze checkpoint example\n\n\nPytorch\n\n\n|-- model\n   |-- xx.pt\n\n\n\n\nRunning Pytorch model needs extra dependency and config. Refer to \nhere\n to install dependencies, and set environment variable \n$PYTHONHOME\n to your python, e.g. python could be run by \n$PYTHONHOME/bin/python\n and library is at \n$PYTHONHOME/lib/\n.\n\n\nOpenVINO\n\n\n|-- model\n   |-- xx.xml\n   |-- xx.bin\n\n\n\n\nBigDL\n\n\n|--model\n   |-- xx.model\n\n\n\n\nCaffe\n\n\n|-- model\n   |-- xx.prototxt\n   |-- xx.caffemodel\n\n\n\n\nData Configuration\n\n\nThe field \ndata\n contains your input data configuration.\n\n\n\n\nsrc: the queue you subscribe for your input data, e.g. default config of Redis on local machine is \nlocalhost:6379\n. Note that please use the host address in your network instead of localhost or 127.0.0.1 when you run serving in cluster, and make sure other nodes in cluster could also recognize this address.\n\n\nshape: the shape of your input data. e.g. [[1],[3,224,224],[3]], if your model contains only one input, brackets could be omitted.\n\n\nfilter: the post-processing of pipeline, could be none. Except none, currently supported filters are,\n\n\n\n\nTop-N, e.g. \ntopN(1)\n represents Top-1 result is kept and returned with index. User should follow this schema \ntopN(n)\n. Noted if the top-N number is larger than model output size of the the final layer, it would just return all the outputs.\n\n\nOther Configuration\n\n\nThe field \nparams\n contains your inference parameter configuration.\n\n\n\n\ncore_number: the \nbatch size\n you use for model inference, usually the core number of your machine is recommended. Thus you could just provide your machine core number at this field. We recommend this value to be not smaller than 4 and not larger than 512. In general, using larger batch size means higher throughput, but also increase the latency between batches accordingly.\n\n\n\n\n3. Launching Service\n\n\nThis section is about how to start and stop Cluster Serving. \n\n\nStart\n\n\nYou can use following command to start Cluster Serving.\n\n\ncluster-serving-start\n\n\n\n\nUse \ncluster-serving-start -p 5\n to start Cluster Serving with Flink parallelism 5.\n\n\nUse \ncluster-serving-start -c config_path\n to path config path \nconfig_path\n to Cluster Serving manually.\n\n\nStop\n\n\nYou can use Flink UI in \nlocalhost:8081\n by default, to cancel your Cluster Serving job.\n\n\nShut Down\n\n\nYou can use following command to shutdown Cluster Serving. This operation will stop all running services related to Cluster Serving. Note that your data in Redis will be removed when you shutdown. \n\n\ncluster-serving-shutdown\n\n\n\n\nIf you are using Docker, you could also run \ndocker rm\n to shutdown Cluster Serving.\n\n\nHTTP Server (for sync API only)\n\n\nIf you want to use sync API for inference, you should start a provided HTTP server first. User can submit HTTP requests to the HTTP server through RESTful APIs. The HTTP server will parse the input requests and pub them to Redis input queues, then retrieve the output results and render them as json results in HTTP responses.\n\n\nPrepare\n\n\nUser can download a analytics-zoo-${VERSION}-http.jar from the Nexus Repository with GAVP: \n\n\n<groupId>com.intel.analytics.zoo</groupId>\n<artifactId>analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}</artifactId>\n<version>${ZOO_VERSION}</version>\n\n\n\n\nUser can also build from the source code:\n\n\nmvn clean package -P spark_2.4+ -Dmaven.test.skip=true\n\n\n\n\nStart the HTTP Server\n\n\nUser can start the HTTP server with following command.\n\n\njava -jar analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ZOO_VERSION}-http.jar\n\n\n\n\nAnd check the status of the HTTP server with:\n\n\ncurl  http://${BINDED_HOST_IP}:${BINDED_HOST_PORT}/\n\n\n\n\nIf you get a response like \"welcome to analytics zoo web serving frontend\", that means the HTTP server is started successfully.\n\n\nStart options\n\n\nUser can pass options to the HTTP server when start it:\n\n\njava -jar analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ZOO_VERSION}-http.jar --redisHost=\"172.16.0.109\"\n\n\n\n\nAll the supported parameter are listed here:\n* \ninterface\n: the binded server interface, default is \"0.0.0.0\"\n* \nport\n: the binded server port, default is 10020\n* \nredisHost\n: the host IP of redis server, default is \"localhost\"\n* \nredisPort\n: the host port of redis server, default is 6379\n* \nredisInputQueue\n: the input queue of redis server, default is \"serving_stream\"\n* \nredisOutputQueue\n: the output queue of redis server, default is \"result:\" \n* \nparallelism\n: the parallelism of requests processing, default is 1000\n* \ntimeWindow\n: the timeWindow wait to pub inputs to redis, default is 0\n* \ncountWindow\n: the timeWindow wait to ub inputs to redis, default is 56\n* \ntokenBucketEnabled\n: the switch to enable/disable RateLimiter, default is false\n* \ntokensPerSecond\n: the rate of permits per second, default is 100\n* \ntokenAcquireTimeout\n: acquires a permit from this RateLimiter if it can be obtained without exceeding the specified timeout(ms), default is 100\n\n\nUser can adjust these options to tune the performance of the HTTP server.\n\n\n4. Model Inference\n\n\nWe support Python API and HTTP RESTful API for conducting inference with Data Pipeline in Cluster Serving. \n\n\nPython API\n\n\nFor Python API, the requirements of python packages are \nopencv-python\n(for raw image only), \npyyaml\n, \nredis\n. You can use \nInputQueue\n and \nOutputQueue\n to connect to data pipeline by providing the pipeline url, e.g. \nmy_input_queue = InputQueue(host, port)\n and \nmy_output_queue = OutputQueue(host, port)\n. If parameters are not provided, default url \nlocalhost:6379\n would be used.\n\n\nWe provide some basic usages here, for more details, please see \nAPI Guide\n.\n\n\nAsync API\n\n\nAsync API provide method to enqueue data, the method would not block and user can query the data anytime afterwards.\n\n\nTo input data to queue, you need a \nInputQueue\n instance, and using \nenqueue\n method, for each input, give a key correspond to your model or give arbitrary key if your model does not care about it.\n\n\nTo enqueue an image\n\n\nfrom zoo.serving.client import InputQueue\ninput_api = InputQueue()\ninput_api.enqueue('my-image1', user_define_key={\"path: 'path/to/image1'})\n\n\n\n\nTo enqueue an instance containing 1 image and 2 ndarray\n\n\nfrom zoo.serving.client import InputQueue\nimport numpy as np\ninput_api = InputQueue()\nt1 = np.array([1,2])\nt2 = np.array([[1,2], [3,4]])\ninput_api.enqueue('my-instance', img={\"path\": 'path/to/image'}, tensor1=t1, tensor2=t2)\n\n\n\n\nThere are 4 types of inputs in total, string, image, tensor, sparse tensor, which could represents nearly all types of models. For more details of usage, go to \nAPI Guide\n\n\nTo get data from queue, you need a \nOutputQueue\n instance, and using \nquery\n or \ndequeue\n method. The \nquery\n method takes image uri as parameter and returns the corresponding result. The \ndequeue\n method takes no parameter and just returns all results and also delete them in data queue. See following example.\n\n\nfrom zoo.serving.client import OutputQueue\noutput_api = OutputQueue()\nimg1_result = output_api.query('img1')\nall_result = output_api.dequeue() # the output queue is empty after this code\n\n\n\n\nConsider the code above,\n\n\nimg1_result = output_api.query('img1')\n\n\n\n\nSync API\n\n\nSync API provide method to predict data, the method would block until the result is available.\n\n\nUser need to create a \nInputQueue\n instance with \nsync=True\n and \nfrontend_url=frontend_server_url\n argument.\n\n\nfrom zoo.serving.client import InputQueue\ninput_api = InputQueue(sync=True, frontend_url=frontend_server_url)\nresponse = input_api.predict(request_json_string)\nprint(response.text)\n\n\n\n\nexample of \nrequest_json_string\n is\n\n\n'{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }]\n}'\n\n\n\n\nThis API is also a python support of \nRestful API\n section, so for more details of input format, refer to it.\n\n\nRESTful API\n\n\nThis part describes API endpoints and end-to-end examples on usage. \nThe requests and responses are in JSON format. The composition of them depends on the requests type or verb. See the APIs for details.\nIn case of error, all APIs will return a JSON object in the response body with error as key and the error message as the value:\n\n\n{\n  \"error\": <error message string>\n}\n\n\n\n\nPredict API\n\n\nURL\n\n\nPOST http://host:port/predict\n\n\n\n\nRequest Example for images as inputs:\n\n\ncurl -d \\\n'{\n  \"instances\": [\n    {\n      \"image\": \"/9j/4AAQSkZJRgABAQEASABIAAD/7RcEUGhvdG9za...\"\n    },   \n    {\n      \"image\": \"/9j/4AAQSkZJRgABAQEASABIAAD/7RcEUGhvdG9za...\"\n    }\n  ]\n}' \\\n-X POST http://host:port/predict\n\n\n\n\nResponse Example\n\n\n{\n  \"predictions\": [\n    \"{value=[[903,0.1306194]]}\",    \n    \"{value=[[903,0.1306194]]}\"\n  ]\n}\n\n\n\n\nRequest Example for tensor as inputs:\n\n\ncurl -d \\\n'{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }, {\n    \"ids\" : [ 100.0, 88.0 ]\n  } ]\n}' \\\n-X POST http://host:port/predict\n\n\n\n\nResponse Example\n\n\n{\n  \"predictions\": [\n    \"{value=[[1,0.6427843]]}\",\n    \"{value=[[1,0.6427842]]}\"\n  ]\n}\n\n\n\n\nAnother request example for composition of scalars and tensors.\n\n\ncurl -d \\\n '{\n  \"instances\" : [ {\n    \"intScalar\" : 12345,\n    \"floatScalar\" : 3.14159,\n    \"stringScalar\" : \"hello, world. hello, arrow.\",\n    \"intTensor\" : [ 7756, 9549, 1094, 9808, 4959, 3831, 3926, 6578, 1870, 1741 ],\n    \"floatTensor\" : [ 0.6804766, 0.30136853, 0.17394465, 0.44770062, 0.20275897, 0.32762378, 0.45966738, 0.30405098, 0.62053126, 0.7037923 ],\n    \"stringTensor\" : [ \"come\", \"on\", \"united\" ],\n    \"intTensor2\" : [ [ 1, 2 ], [ 3, 4 ], [ 5, 6 ] ],\n    \"floatTensor2\" : [ [ [ 0.2, 0.3 ], [ 0.5, 0.6 ] ], [ [ 0.2, 0.3 ], [ 0.5, 0.6 ] ] ],\n    \"stringTensor2\" : [ [ [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ], [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ] ], [ [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ], [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ] ] ]\n  }]\n}' \\\n-X POST http://host:port/predict\n\n\n\n\nAnother request example for composition of sparse and dense tensors.\n\n\ncurl -d \\\n'{\n  \"instances\" : [ {\n    \"sparseTensor\" : {\n      \"shape\" : [ 100, 10000, 10 ],\n      \"data\" : [ 0.2, 0.5, 3.45, 6.78 ],\n      \"indices\" : [ [ 1, 1, 1 ], [ 2, 2, 2 ], [ 3, 3, 3 ], [ 4, 4, 4 ] ]\n    },\n    \"intTensor2\" : [ [ 1, 2 ], [ 3, 4 ], [ 5, 6 ] ]\n  }]\n}' \\\n-X POST http://host:port/predict\n\n\n\n\nMetrics API\n\n\nURL\n\n\nGET http://host:port/metrics\n\n\n\n\nResponse example:\n\n\n[\n  {\n    name: \"zoo.serving.redis.get\",\n    count: 810,\n    meanRate: 12.627772820651845,\n    min: 0,\n    max: 25,\n    mean: 0.9687099303718213,\n    median: 0.928579,\n    stdDev: 0.8150031623593447,\n    _75thPercentile: 1.000047,\n    _95thPercentile: 1.141443,\n    _98thPercentile: 1.268665,\n    _99thPercentile: 1.608387,\n    _999thPercentile: 25.874584\n  }\n]\n\n\n\n\nOptional Operations\n\n\nUpdate Model or Configurations\n\n\nTo update your model, you could replace your model file in your model directory, and restart Cluster Serving by \ncluster-serving-restart\n. Note that you could also change your configurations in \nconfig.yaml\n and restart serving.\n\n\nLogs and Visualization\n\n\nLogs\n\n\nTo see log, please refer to Flink UI \nlocalhost:8081\n by default.\n\n\nVisualization\n\n\nTo visualize Cluster Serving performance, go to your flink job UI, default \nlocalhost:8081\n, and go to Cluster Serving job -> metrics. Add \nnumRecordsOut\n to see total record number and \nnumRecordsOutPerSecond\n to see throughput.\n\n\nSee example of visualization:",
            "title": "Cluster Serving"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#programming-guide",
            "text": "Analytics Zoo Cluster Serving\u00a0is a lightweight distributed, real-time serving solution that supports a wide range of deep learning models (such as TensorFlow, PyTorch, Caffe, BigDL and OpenVINO models). It provides a simple pub/sub API, so that the users can easily send their inference requests to the input queue (using a simple Python API);\u00a0Cluster Serving\u00a0will then automatically manage the scale-out and real-time model inference across a large cluster (using distributed streaming frameworks such as Apache Spark Streaming, Apache Flink, etc.)   The overall architecture of Analytics Zoo Cluster Serving solution is illustrated as below:    This page contains the guide for you to run Analytics Zoo Cluster Serving, including following:    Quick Start    Workflow Overview      Deploy Your Own Cluster Serving    Installation    Configuration      Launching Service    Model inference    Optional Operations    Update Model or Configurations    Logs and Visualization",
            "title": "Programming Guide"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#quick-start",
            "text": "This section provides a quick start example for you to run Analytics Zoo Cluster Serving. To simplify the example, we use docker to run Cluster Serving. If you do not have docker installed,  install docker  first. The quick start example contains all the necessary components so the first time users can get it up and running within minutes:   A docker image for Analytics Zoo Cluster Serving (with all dependencies installed)  A sample configuration file  A sample trained TensorFlow model, and sample data for inference  A sample Python client program   Use one command to run Cluster Serving container. (We provide quick start model in older version of docker image, for newest version, please refer to following sections and we remove the model to reduce the docker image size).  docker run --name cluster-serving -itd --net=host intelanalytics/zoo-cluster-serving:0.9.0  Log into the container using  docker exec -it cluster-serving bash , go to Cluster Serving working directory by  cd cluster-serving .  You can see prepared TensorFlow frozen ResNet50 model in  resources/model  directory with following structure.  cluster-serving | \n               -- | model\n                 -- frozen_graph.pb\n                 -- graph_meta.json  Modify  config.yaml  and add following to  filter:  config  data:\n  shape: [3,224,224]\n  filter: topN(1)  This will tell the shape of input image is [3,224,224] and rank Top-1 result of the model output.  Start Cluster Serving using  cluster-serving-start .   Run python program  python3 image_classification_and_object_detection_quick_start.py -i resources/test_image  to push data into queue and get inference result.   Then you can see the inference output in console.   image: fish1.jpeg, classification-result:class: 5's prob: 0.18204997\nimage: dog1.jpeg, classification-result:class: 267's prob: 0.27166227\nimage: cat1.jpeg, classification-result:class: 292's prob: 0.32633427  Wow! You made it!  Note that the Cluster Serving quick start example will run on your local node only. Check the  Deploy Your Own Cluster Serving  section for how to configure and run Cluster Serving in a distributed fashion.  For more details, refer to following sections.",
            "title": "Quick Start"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#workflow-overview",
            "text": "The figure below illustrates the simple 3-step \"Prepare-Launch-Inference\" workflow for Cluster Serving.",
            "title": "Workflow Overview"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#1-install-and-prepare-cluster-serving-environment-on-a-local-node",
            "text": "Copy a previously trained model to the local node; currently TensorFlow, PyTorch, Caffe, BigDL and OpenVINO models are supported.  Install Analytics Zoo on the local node (e.g., using a single pip install command)  Configure Cluster Server on the local node, including the file path to the trained model and the address of the cluster (such as Apache Hadoop YARN cluster, K8s cluster, etc.).\nPlease note that you only need to deploy the Cluster Serving solution on a single local node, and NO modifications are needed for the (YARN or K8s) cluster.",
            "title": "1. Install and prepare Cluster Serving environment on a local node:"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#2-launch-the-cluster-serving-service",
            "text": "You can launch the Cluster Serving service by running the startup script on the local node. Under the hood, Cluster Serving will automatically deploy the trained model and serve the model inference requests across the cluster in a distributed fashion. You may monitor its runtime status (such as inference throughput) using TensorBoard.",
            "title": "2. Launch the Cluster Serving service"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#3-distributed-real-time-streaming-inference",
            "text": "Cluster Serving provides a simple pub/sub API to the users, so that you can easily send the inference requests to an input queue (currently Redis Streams is used) using a simple Python API.  Cluster Serving will then read the requests from the Redis stream, run the distributed real-time inference across the cluster (using Flink), and return the results back through Redis. As a result, you may get the inference results again using a simple Python API.",
            "title": "3. Distributed, real-time (streaming) inference"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#deploy-your-own-cluster-serving",
            "text": "",
            "title": "Deploy your Own Cluster Serving"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#1-installation",
            "text": "It is recommended to install Cluster Serving by pulling the pre-built Docker image to your local node, which have packaged all the required dependencies. Alternatively, you may also manually install Cluster Serving (through either pip or direct downloading), Redis on the local node.",
            "title": "1. Installation"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#docker",
            "text": "docker pull intelanalytics/zoo-cluster-serving  then, (or directly run  docker run , it will pull the image if it does not exist)  docker run --name cluster-serving -itd --net=host intelanalytics/zoo-cluster-serving:0.9.0  Log into the container  docker exec -it cluster-serving bash  cd ./cluster-serving , you can see all the environments are prepared.",
            "title": "Docker"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#yarn-user",
            "text": "For Yarn user using docker, start Flink on Yarn inside the container. The other operations are the same.",
            "title": "Yarn user"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#manual-installation",
            "text": "",
            "title": "Manual installation"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#requirements",
            "text": "Non-Docker users need to install  Flink 1.10.0+ , 1.10.0 by default,  Redis 5.0.0+ , 5.0.5 by default.  After preparing dependencies above, make sure the environment variable  $FLINK_HOME  (/path/to/flink-FLINK_VERSION-bin),  $REDIS_HOME (/path/to/redis-REDIS_VERSION) is set before following steps.",
            "title": "Requirements"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#install-cluster-serving-by-download-release",
            "text": "For users who need to deploy and start Cluster Serving, download Cluster Serving zip  analytics-zoo-xxx-cluster-serving-all.zip  from  here  and unzip it, then run  source cluster-serving-setup.sh .\nFor users who need to do inference, aka. predict data only, download Analytics Zoo python zip  analytics-zoo-xxx-cluster-serving-python.zip  from  here  and run  export PYTHONPATH=$PYTHONPATH:/path/to/zip  to add this zip to  PYTHONPATH  environment variable.",
            "title": "Install Cluster Serving by download release"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#install-cluster-serving-by-pip",
            "text": "Download package from  here , run following command to install Cluster Serving  pip install analytics_zoo_serving-*.whl  For users who need to deploy and start Cluster Serving, run  cluster-serving-init  to download and prepare dependencies.  For users who need to do inference, aka. predict data only, the environment is ready.",
            "title": "Install Cluster Serving by pip"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#2-configuration",
            "text": "",
            "title": "2. Configuration"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#how-to-config",
            "text": "After  Installation , you will see a config file  config.yaml  in your current working directory. This file contains all the configurations that you can customize for your Cluster Serving. See an example of  config.yaml  below.  ## Analytics Zoo Cluster Serving Config Example\n\nmodel:\n  # model path must be set\n  path: /opt/work/model\nparams:\n  # default, 4\n  core_num:",
            "title": "How to Config"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#preparing-model",
            "text": "Currently Analytics Zoo Cluster Serving supports TensorFlow, OpenVINO, PyTorch, BigDL, Caffe models. Supported types are listed below.  You need to put your model file into a directory with layout like following according to model type, note that only one model is allowed in your directory. Then, set in  config.yaml  file with  model:path:/path/to/dir .  Tensorflow*  Tensorflow SavedModel***  |-- model\n   |-- saved_model.pb\n   |-- variables\n       |-- variables.data-00000-of-00001\n       |-- variables.index  Tensorflow Frozen Graph  |-- model\n   |-- frozen_graph.pb\n   |-- graph_meta.json  Tensorflow Checkpoint \nPlease refer to  freeze checkpoint example  Pytorch  |-- model\n   |-- xx.pt  Running Pytorch model needs extra dependency and config. Refer to  here  to install dependencies, and set environment variable  $PYTHONHOME  to your python, e.g. python could be run by  $PYTHONHOME/bin/python  and library is at  $PYTHONHOME/lib/ .  OpenVINO  |-- model\n   |-- xx.xml\n   |-- xx.bin  BigDL  |--model\n   |-- xx.model  Caffe  |-- model\n   |-- xx.prototxt\n   |-- xx.caffemodel",
            "title": "Preparing Model"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#data-configuration",
            "text": "The field  data  contains your input data configuration.   src: the queue you subscribe for your input data, e.g. default config of Redis on local machine is  localhost:6379 . Note that please use the host address in your network instead of localhost or 127.0.0.1 when you run serving in cluster, and make sure other nodes in cluster could also recognize this address.  shape: the shape of your input data. e.g. [[1],[3,224,224],[3]], if your model contains only one input, brackets could be omitted.  filter: the post-processing of pipeline, could be none. Except none, currently supported filters are,   Top-N, e.g.  topN(1)  represents Top-1 result is kept and returned with index. User should follow this schema  topN(n) . Noted if the top-N number is larger than model output size of the the final layer, it would just return all the outputs.",
            "title": "Data Configuration"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#other-configuration",
            "text": "The field  params  contains your inference parameter configuration.   core_number: the  batch size  you use for model inference, usually the core number of your machine is recommended. Thus you could just provide your machine core number at this field. We recommend this value to be not smaller than 4 and not larger than 512. In general, using larger batch size means higher throughput, but also increase the latency between batches accordingly.",
            "title": "Other Configuration"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#3-launching-service",
            "text": "This section is about how to start and stop Cluster Serving.",
            "title": "3. Launching Service"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#start",
            "text": "You can use following command to start Cluster Serving.  cluster-serving-start  Use  cluster-serving-start -p 5  to start Cluster Serving with Flink parallelism 5.  Use  cluster-serving-start -c config_path  to path config path  config_path  to Cluster Serving manually.",
            "title": "Start"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#stop",
            "text": "You can use Flink UI in  localhost:8081  by default, to cancel your Cluster Serving job.",
            "title": "Stop"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#shut-down",
            "text": "You can use following command to shutdown Cluster Serving. This operation will stop all running services related to Cluster Serving. Note that your data in Redis will be removed when you shutdown.   cluster-serving-shutdown  If you are using Docker, you could also run  docker rm  to shutdown Cluster Serving.",
            "title": "Shut Down"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#http-server-for-sync-api-only",
            "text": "If you want to use sync API for inference, you should start a provided HTTP server first. User can submit HTTP requests to the HTTP server through RESTful APIs. The HTTP server will parse the input requests and pub them to Redis input queues, then retrieve the output results and render them as json results in HTTP responses.",
            "title": "HTTP Server (for sync API only)"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#prepare",
            "text": "User can download a analytics-zoo-${VERSION}-http.jar from the Nexus Repository with GAVP:   <groupId>com.intel.analytics.zoo</groupId>\n<artifactId>analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}</artifactId>\n<version>${ZOO_VERSION}</version>  User can also build from the source code:  mvn clean package -P spark_2.4+ -Dmaven.test.skip=true",
            "title": "Prepare"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#start-the-http-server",
            "text": "User can start the HTTP server with following command.  java -jar analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ZOO_VERSION}-http.jar  And check the status of the HTTP server with:  curl  http://${BINDED_HOST_IP}:${BINDED_HOST_PORT}/  If you get a response like \"welcome to analytics zoo web serving frontend\", that means the HTTP server is started successfully.",
            "title": "Start the HTTP Server"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#start-options",
            "text": "User can pass options to the HTTP server when start it:  java -jar analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ZOO_VERSION}-http.jar --redisHost=\"172.16.0.109\"  All the supported parameter are listed here:\n*  interface : the binded server interface, default is \"0.0.0.0\"\n*  port : the binded server port, default is 10020\n*  redisHost : the host IP of redis server, default is \"localhost\"\n*  redisPort : the host port of redis server, default is 6379\n*  redisInputQueue : the input queue of redis server, default is \"serving_stream\"\n*  redisOutputQueue : the output queue of redis server, default is \"result:\" \n*  parallelism : the parallelism of requests processing, default is 1000\n*  timeWindow : the timeWindow wait to pub inputs to redis, default is 0\n*  countWindow : the timeWindow wait to ub inputs to redis, default is 56\n*  tokenBucketEnabled : the switch to enable/disable RateLimiter, default is false\n*  tokensPerSecond : the rate of permits per second, default is 100\n*  tokenAcquireTimeout : acquires a permit from this RateLimiter if it can be obtained without exceeding the specified timeout(ms), default is 100  User can adjust these options to tune the performance of the HTTP server.",
            "title": "Start options"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#4-model-inference",
            "text": "We support Python API and HTTP RESTful API for conducting inference with Data Pipeline in Cluster Serving.",
            "title": "4. Model Inference"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#python-api",
            "text": "For Python API, the requirements of python packages are  opencv-python (for raw image only),  pyyaml ,  redis . You can use  InputQueue  and  OutputQueue  to connect to data pipeline by providing the pipeline url, e.g.  my_input_queue = InputQueue(host, port)  and  my_output_queue = OutputQueue(host, port) . If parameters are not provided, default url  localhost:6379  would be used.  We provide some basic usages here, for more details, please see  API Guide .",
            "title": "Python API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#async-api",
            "text": "Async API provide method to enqueue data, the method would not block and user can query the data anytime afterwards.  To input data to queue, you need a  InputQueue  instance, and using  enqueue  method, for each input, give a key correspond to your model or give arbitrary key if your model does not care about it.  To enqueue an image  from zoo.serving.client import InputQueue\ninput_api = InputQueue()\ninput_api.enqueue('my-image1', user_define_key={\"path: 'path/to/image1'})  To enqueue an instance containing 1 image and 2 ndarray  from zoo.serving.client import InputQueue\nimport numpy as np\ninput_api = InputQueue()\nt1 = np.array([1,2])\nt2 = np.array([[1,2], [3,4]])\ninput_api.enqueue('my-instance', img={\"path\": 'path/to/image'}, tensor1=t1, tensor2=t2)  There are 4 types of inputs in total, string, image, tensor, sparse tensor, which could represents nearly all types of models. For more details of usage, go to  API Guide  To get data from queue, you need a  OutputQueue  instance, and using  query  or  dequeue  method. The  query  method takes image uri as parameter and returns the corresponding result. The  dequeue  method takes no parameter and just returns all results and also delete them in data queue. See following example.  from zoo.serving.client import OutputQueue\noutput_api = OutputQueue()\nimg1_result = output_api.query('img1')\nall_result = output_api.dequeue() # the output queue is empty after this code  Consider the code above,  img1_result = output_api.query('img1')",
            "title": "Async API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#sync-api",
            "text": "Sync API provide method to predict data, the method would block until the result is available.  User need to create a  InputQueue  instance with  sync=True  and  frontend_url=frontend_server_url  argument.  from zoo.serving.client import InputQueue\ninput_api = InputQueue(sync=True, frontend_url=frontend_server_url)\nresponse = input_api.predict(request_json_string)\nprint(response.text)  example of  request_json_string  is  '{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }]\n}'  This API is also a python support of  Restful API  section, so for more details of input format, refer to it.",
            "title": "Sync API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#restful-api",
            "text": "This part describes API endpoints and end-to-end examples on usage. \nThe requests and responses are in JSON format. The composition of them depends on the requests type or verb. See the APIs for details.\nIn case of error, all APIs will return a JSON object in the response body with error as key and the error message as the value:  {\n  \"error\": <error message string>\n}",
            "title": "RESTful API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#predict-api",
            "text": "URL  POST http://host:port/predict  Request Example for images as inputs:  curl -d \\\n'{\n  \"instances\": [\n    {\n      \"image\": \"/9j/4AAQSkZJRgABAQEASABIAAD/7RcEUGhvdG9za...\"\n    },   \n    {\n      \"image\": \"/9j/4AAQSkZJRgABAQEASABIAAD/7RcEUGhvdG9za...\"\n    }\n  ]\n}' \\\n-X POST http://host:port/predict  Response Example  {\n  \"predictions\": [\n    \"{value=[[903,0.1306194]]}\",    \n    \"{value=[[903,0.1306194]]}\"\n  ]\n}  Request Example for tensor as inputs:  curl -d \\\n'{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }, {\n    \"ids\" : [ 100.0, 88.0 ]\n  } ]\n}' \\\n-X POST http://host:port/predict  Response Example  {\n  \"predictions\": [\n    \"{value=[[1,0.6427843]]}\",\n    \"{value=[[1,0.6427842]]}\"\n  ]\n}  Another request example for composition of scalars and tensors.  curl -d \\\n '{\n  \"instances\" : [ {\n    \"intScalar\" : 12345,\n    \"floatScalar\" : 3.14159,\n    \"stringScalar\" : \"hello, world. hello, arrow.\",\n    \"intTensor\" : [ 7756, 9549, 1094, 9808, 4959, 3831, 3926, 6578, 1870, 1741 ],\n    \"floatTensor\" : [ 0.6804766, 0.30136853, 0.17394465, 0.44770062, 0.20275897, 0.32762378, 0.45966738, 0.30405098, 0.62053126, 0.7037923 ],\n    \"stringTensor\" : [ \"come\", \"on\", \"united\" ],\n    \"intTensor2\" : [ [ 1, 2 ], [ 3, 4 ], [ 5, 6 ] ],\n    \"floatTensor2\" : [ [ [ 0.2, 0.3 ], [ 0.5, 0.6 ] ], [ [ 0.2, 0.3 ], [ 0.5, 0.6 ] ] ],\n    \"stringTensor2\" : [ [ [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ], [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ] ], [ [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ], [ [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ], [ \"come\", \"on\", \"united\" ] ] ] ]\n  }]\n}' \\\n-X POST http://host:port/predict  Another request example for composition of sparse and dense tensors.  curl -d \\\n'{\n  \"instances\" : [ {\n    \"sparseTensor\" : {\n      \"shape\" : [ 100, 10000, 10 ],\n      \"data\" : [ 0.2, 0.5, 3.45, 6.78 ],\n      \"indices\" : [ [ 1, 1, 1 ], [ 2, 2, 2 ], [ 3, 3, 3 ], [ 4, 4, 4 ] ]\n    },\n    \"intTensor2\" : [ [ 1, 2 ], [ 3, 4 ], [ 5, 6 ] ]\n  }]\n}' \\\n-X POST http://host:port/predict",
            "title": "Predict API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#metrics-api",
            "text": "URL  GET http://host:port/metrics  Response example:  [\n  {\n    name: \"zoo.serving.redis.get\",\n    count: 810,\n    meanRate: 12.627772820651845,\n    min: 0,\n    max: 25,\n    mean: 0.9687099303718213,\n    median: 0.928579,\n    stdDev: 0.8150031623593447,\n    _75thPercentile: 1.000047,\n    _95thPercentile: 1.141443,\n    _98thPercentile: 1.268665,\n    _99thPercentile: 1.608387,\n    _999thPercentile: 25.874584\n  }\n]",
            "title": "Metrics API"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#optional-operations",
            "text": "",
            "title": "Optional Operations"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#update-model-or-configurations",
            "text": "To update your model, you could replace your model file in your model directory, and restart Cluster Serving by  cluster-serving-restart . Note that you could also change your configurations in  config.yaml  and restart serving.",
            "title": "Update Model or Configurations"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#logs-and-visualization",
            "text": "",
            "title": "Logs and Visualization"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#logs",
            "text": "To see log, please refer to Flink UI  localhost:8081  by default.",
            "title": "Logs"
        },
        {
            "location": "/ClusterServingGuide/ProgrammingGuide/#visualization",
            "text": "To visualize Cluster Serving performance, go to your flink job UI, default  localhost:8081 , and go to Cluster Serving job -> metrics. Add  numRecordsOut  to see total record number and  numRecordsOutPerSecond  to see throughput.  See example of visualization:",
            "title": "Visualization"
        },
        {
            "location": "/ProgrammingGuide/AutoML/overview/",
            "text": "AutoML Framework Overview\n\n\nThere are four essential components in the AutoML framework, i.e. FeatureTransformer, Model, SearchEngine, and Pipeline. \n\n\nA FeatureTransformer (inherited from \nBaseFeatureTransformer\n class) defines the feature engineering process, which usually includes a chain of operations like feature generation, feature transformations and selection. A Model (inherited from \nBaseModel\n class) usually defines an optimizable model (e.g. AlexNet or LeNet), and a fitting function using an optimization algorithm (e.g. SGD, Adam, etc.). A Model may also include the procedure of model/algorithm selection. \n\n\nDuring training, a SearchEngine (inherited from \nSearchEngine\n class) searches for the best set of hyper parameters for both FeatureTransformer and Model and control the actual model fitting process. A Pipeline (inherited from \nPipeline\n class) is a convenient utility that integrates FeatureTransformer and Model into an end2end data processing pipeline. A Pipeline can be easily saved to file and loaded for reuse later elsewhere. \n\n\nA typical training workflow with AutoML looks like below: \n\n\n\n\nA FeatureTransformer and A Model are instantiated. A SearchEngine is then instantiated and configured with the FeatureTransformer and Model, along with search presets, specifying how parameters are searched, the reward metric, and etc. \n\n\nThe SearchEngine runs the search procedure. It will generate several trials at a time and distribute the trials in a cluster. Each trail runs feature engineering and the model fitting process with a different combination of hyper parameters and obtain the target metric. It may take a while if the search presets generate many trails or model fitting takes a long time.\n\n\nAfter all trials completed, the best configuration and fitted model are retrieved according to the target metric. They are used to generate the result FeatureTransformer and Model, which are in turn used to compose a Pipeline.  The Pipeline can then be saved to file and loaded later for inference and resume/incremental training.",
            "title": "Overview"
        },
        {
            "location": "/ProgrammingGuide/AutoML/overview/#automl-framework-overview",
            "text": "There are four essential components in the AutoML framework, i.e. FeatureTransformer, Model, SearchEngine, and Pipeline.   A FeatureTransformer (inherited from  BaseFeatureTransformer  class) defines the feature engineering process, which usually includes a chain of operations like feature generation, feature transformations and selection. A Model (inherited from  BaseModel  class) usually defines an optimizable model (e.g. AlexNet or LeNet), and a fitting function using an optimization algorithm (e.g. SGD, Adam, etc.). A Model may also include the procedure of model/algorithm selection.   During training, a SearchEngine (inherited from  SearchEngine  class) searches for the best set of hyper parameters for both FeatureTransformer and Model and control the actual model fitting process. A Pipeline (inherited from  Pipeline  class) is a convenient utility that integrates FeatureTransformer and Model into an end2end data processing pipeline. A Pipeline can be easily saved to file and loaded for reuse later elsewhere.   A typical training workflow with AutoML looks like below:    A FeatureTransformer and A Model are instantiated. A SearchEngine is then instantiated and configured with the FeatureTransformer and Model, along with search presets, specifying how parameters are searched, the reward metric, and etc.   The SearchEngine runs the search procedure. It will generate several trials at a time and distribute the trials in a cluster. Each trail runs feature engineering and the model fitting process with a different combination of hyper parameters and obtain the target metric. It may take a while if the search presets generate many trails or model fitting takes a long time.  After all trials completed, the best configuration and fitted model are retrieved according to the target metric. They are used to generate the result FeatureTransformer and Model, which are in turn used to compose a Pipeline.  The Pipeline can then be saved to file and loaded later for inference and resume/incremental training.",
            "title": "AutoML Framework Overview"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/",
            "text": "Automated Time Series Prediction\n\n\nTraining a model using \nTimeSequencePredictor\n\n\nTimeSequencePredictor\n can be used to train a model on historical time sequence data and predict future sequences. Note that: \n\n  * We require input time series data to be uniformly sampled in timeline. Missing data points will lead to errors or unreliable prediction result. \n\n\n0. Prepare environment\n\n\nWe recommend you to use \nAnaconda\n to prepare the environments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).\n\n\nconda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above\n\n\n\n\n1. Before training, init RayOnSpark.\n\n\n\n\nRun ray on spark local mode, Example\n\n\n\n\nfrom zoo import init_spark_on_local\nfrom zoo.ray import RayContext\nsc = init_spark_on_local(cores=4)\nray_ctx = RayContext(sc=sc)\nray_ctx.init()\n\n\n\n\n\n\nrun ray on yarn cluster, Example  \n\n\n\n\nfrom zoo import init_spark_on_yarn\nfrom zoo.ray import RayContext\nslave_num = 2\nsc = init_spark_on_yarn(\n        hadoop_conf=args.hadoop_conf,\n        conda_name=\"ray36\",\n        num_executor=slave_num,\n        executor_cores=4,\n        executor_memory=\"8g \",\n        driver_memory=\"2g\",\n        driver_cores=4,\n        extra_executor_memory_for_ray=\"10g\")\nray_ctx = RayContext(sc=sc, object_store_memory=\"5g\")\nray_ctx.init()\n\n\n\n\n2. Create a \nTimeSequencePredictor\n\n\n\n\ndt_col\n and \ntarget_col\n are datetime cols and target column in the input dataframe \n\n\nfuture_seq_len\n is how many data points ahead to predict. \n\n\n\n\nfrom zoo.automl.regression.time_sequence_predictor import TimeSequencePredictor\ntsp = TimeSequencePredictor(dt_col=\"datetime\", target_col=\"value\", extra_features_col=None, future_seq_len=1)\n\n\n\n\n3. Train on historical time sequence.\n\n\n\n\nrecipe\n contains parameters to control the search space, stop criteria and number of samples (e.g. for random search strategy, how many samples are taken from the search space). Some recipe with large number of samples may lead to a large trial pool and take very long time to finish. Current avaiable recipes are: \nSmokeRecipe\n, \nRandomRecipe\n, \nGridRandomRecipe\n and \nBayesRecipe\n. \nSmokeRecipe\n is a very simple Recipe for smoke test that runs one epoch and one iteration with only 1 random sample. Other recipes all have arguments \nnum_random_samples\n and \nlook_back\n. \nnum_random_samples\n is used to control the number of samples. Note that for GridRandomRecipe, the actual number of trials generated will be 2*\nnum_samples\n, as it needs to do a grid search from 2 possble values for every random sample. \nlook_back\n is the length of sequence you want to look back. The default values is 1. You can either put a tuple of (min_len, max_len) or a single int to control the look back sequence length search space. \nBayesRecipe\n use bayesian-optimization package to perform sequential model-based hyperparameter optimization.\n\n\nfit\n returns a \nPipeline\n object (see next section for details). \n\n\nNow we don't support resume training - i.e. calling \nfit\n multiple times retrains on the input data from scratch. \n\n\ninput train dataframe look like below: \n\n\n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n\n\n\n\n2019-06-07\n\n\n2.3\n\n\n\n\n\n\n\n\npipeline = tsp.fit(train_df, metric=\"mean_squared_error\", recipe=RandomRecipe(num_samples=1))\n\n\n\n\n4. After training finished, stop RayOnSpark\n\n\nray_ctx.stop()\n\n\n\n\nSaving and Loading a \nTimeSequencePipeline\n\n\n\n\nSave the \nPipeline\n object to a file\n\n\n\n\npipeline.save(\"/tmp/saved_pipeline/my.ppl\")\n\n\n\n\n\n\nLoad the \nPipeline\n object from a file \n\n\n\n\nfrom zoo.automl.pipeline.time_sequence import load_ts_pipeline\n\npipeline = load_ts_pipeline(\"/tmp/saved_pipeline/my.ppl\")\n\n\n\n\nPrediction and Evaluation using \nTimeSequencePipeline\n\n\nA \nTimeSequencePipeline\n contains a chain of feature transformers and models, which does end-to-end time sequence prediction on input data. \nTimeSequencePipeline\n can be saved and loaded for future deployment.      \n\n\n\n\nPrediction using \nPipeline\n object\n\n\n\n\nOutput dataframe look likes below (assume predict n values forward). col \ndatetime\n is the starting timestamp.  \n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue_0\n\n\nvalue_1\n\n\n...\n\n\nvalue_{n-1}\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n2.8\n\n\n...\n\n\n4.4\n\n\n\n\n\n\n\n\nresult_df = pipeline.predict(test_df)\n\n\n\n\n\n\nEvaluation using \nPipeline\n object\n\n\n\n\n#evaluate with MSE and R2 metrics\nmse, rs = pipeline.evaluate(test_df, metrics=[\"mse\", \"rs\"])\n\n\n\n\n\n\nIncremental training using \nPipeline\n object\n\n\n\n\n#fit with new data and train for 5 epochs\npipeline.fit(new_train_df,epoch_num=5)",
            "title": "Time Series Forecasting"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#automated-time-series-prediction",
            "text": "",
            "title": "Automated Time Series Prediction"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#training-a-model-using-timesequencepredictor",
            "text": "TimeSequencePredictor  can be used to train a model on historical time sequence data and predict future sequences. Note that:  \n  * We require input time series data to be uniformly sampled in timeline. Missing data points will lead to errors or unreliable prediction result.",
            "title": "Training a model using TimeSequencePredictor"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#0-prepare-environment",
            "text": "We recommend you to use  Anaconda  to prepare the environments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).  conda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above",
            "title": "0. Prepare environment"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#1-before-training-init-rayonspark",
            "text": "Run ray on spark local mode, Example   from zoo import init_spark_on_local\nfrom zoo.ray import RayContext\nsc = init_spark_on_local(cores=4)\nray_ctx = RayContext(sc=sc)\nray_ctx.init()   run ray on yarn cluster, Example     from zoo import init_spark_on_yarn\nfrom zoo.ray import RayContext\nslave_num = 2\nsc = init_spark_on_yarn(\n        hadoop_conf=args.hadoop_conf,\n        conda_name=\"ray36\",\n        num_executor=slave_num,\n        executor_cores=4,\n        executor_memory=\"8g \",\n        driver_memory=\"2g\",\n        driver_cores=4,\n        extra_executor_memory_for_ray=\"10g\")\nray_ctx = RayContext(sc=sc, object_store_memory=\"5g\")\nray_ctx.init()",
            "title": "1. Before training, init RayOnSpark."
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#2-create-a-timesequencepredictor",
            "text": "dt_col  and  target_col  are datetime cols and target column in the input dataframe   future_seq_len  is how many data points ahead to predict.    from zoo.automl.regression.time_sequence_predictor import TimeSequencePredictor\ntsp = TimeSequencePredictor(dt_col=\"datetime\", target_col=\"value\", extra_features_col=None, future_seq_len=1)",
            "title": "2. Create a TimeSequencePredictor"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#3-train-on-historical-time-sequence",
            "text": "recipe  contains parameters to control the search space, stop criteria and number of samples (e.g. for random search strategy, how many samples are taken from the search space). Some recipe with large number of samples may lead to a large trial pool and take very long time to finish. Current avaiable recipes are:  SmokeRecipe ,  RandomRecipe ,  GridRandomRecipe  and  BayesRecipe .  SmokeRecipe  is a very simple Recipe for smoke test that runs one epoch and one iteration with only 1 random sample. Other recipes all have arguments  num_random_samples  and  look_back .  num_random_samples  is used to control the number of samples. Note that for GridRandomRecipe, the actual number of trials generated will be 2* num_samples , as it needs to do a grid search from 2 possble values for every random sample.  look_back  is the length of sequence you want to look back. The default values is 1. You can either put a tuple of (min_len, max_len) or a single int to control the look back sequence length search space.  BayesRecipe  use bayesian-optimization package to perform sequential model-based hyperparameter optimization.  fit  returns a  Pipeline  object (see next section for details).   Now we don't support resume training - i.e. calling  fit  multiple times retrains on the input data from scratch.   input train dataframe look like below:       datetime  value      2019-06-06  1.2    2019-06-07  2.3     pipeline = tsp.fit(train_df, metric=\"mean_squared_error\", recipe=RandomRecipe(num_samples=1))",
            "title": "3. Train on historical time sequence."
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#4-after-training-finished-stop-rayonspark",
            "text": "ray_ctx.stop()",
            "title": "4. After training finished, stop RayOnSpark"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#saving-and-loading-a-timesequencepipeline",
            "text": "Save the  Pipeline  object to a file   pipeline.save(\"/tmp/saved_pipeline/my.ppl\")   Load the  Pipeline  object from a file    from zoo.automl.pipeline.time_sequence import load_ts_pipeline\n\npipeline = load_ts_pipeline(\"/tmp/saved_pipeline/my.ppl\")",
            "title": "Saving and Loading a TimeSequencePipeline"
        },
        {
            "location": "/ProgrammingGuide/AutoML/forecasting/#prediction-and-evaluation-using-timesequencepipeline",
            "text": "A  TimeSequencePipeline  contains a chain of feature transformers and models, which does end-to-end time sequence prediction on input data.  TimeSequencePipeline  can be saved and loaded for future deployment.         Prediction using  Pipeline  object   Output dataframe look likes below (assume predict n values forward). col  datetime  is the starting timestamp.       datetime  value_0  value_1  ...  value_{n-1}      2019-06-06  1.2  2.8  ...  4.4     result_df = pipeline.predict(test_df)   Evaluation using  Pipeline  object   #evaluate with MSE and R2 metrics\nmse, rs = pipeline.evaluate(test_df, metrics=[\"mse\", \"rs\"])   Incremental training using  Pipeline  object   #fit with new data and train for 5 epochs\npipeline.fit(new_train_df,epoch_num=5)",
            "title": "Prediction and Evaluation using TimeSequencePipeline"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/",
            "text": "Visualization\n\n\nAutoML visualization Overview\n\n\nAutoML visualization provides two kinds of visualization.\n\n\n\n\nDuring the searching process, the visualizations of each trail are shown and updated every 30 seconds.\n\n\nAfter the searching process, a leaderboard of each trail's configs and metrics is shown.\n\n\n\n\nNote that: AutoML visualization is based on tensorboard and tensorboardx. They should be installed properly before the training starts.\n\n\nScalar view\n\n\nBefore training, start the tensorboard server through\n\n\ntensorboard --logdir=<logs_dir>/<job_name>/\n\n\n\n\nlogs_dir\n is the log directory you set for your predictor(e.g. \nTimeSequencePredictor\n in Automated Time Series Prediction). It is default to \"/home/\\<username>/zoo_automl_logs\", where \nusername\n is your login username. \njob_name\n is the name parameter you set for your predictor.\n\n\nThe data in SCALARS tag will be updated every 30 seconds for users to see the training progress.\n\n\n\n\nLeaderboard view\n\n\nAfter training, start the tensorboard server through\n\n\ntensorboard --logdir=<logs_dir>/<job_name>_leaderboard/\n\n\n\n\nwhere \nlogs_dir\n and \njob_name\n are the same as stated in \nScalar view\n.\n\n\nA leaderboard of each trail's configs and metrics is shown in the HPARAMS tag.\n\n\n\n\nUse visualization in Jupyter Notebook\n\n\nYou can enable a tensorboard view in jupyter notebook by the following code\n\n\n%load_ext tensorboard\n# for scalar view\n%tensorboard --logdir <logs_dir>/<job_name>/\n# for leaderboard view\n%tensorboard --logdir <logs_dir>/<job_name>_leaderboard/",
            "title": "Visualization"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/#visualization",
            "text": "",
            "title": "Visualization"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/#automl-visualization-overview",
            "text": "AutoML visualization provides two kinds of visualization.   During the searching process, the visualizations of each trail are shown and updated every 30 seconds.  After the searching process, a leaderboard of each trail's configs and metrics is shown.   Note that: AutoML visualization is based on tensorboard and tensorboardx. They should be installed properly before the training starts.",
            "title": "AutoML visualization Overview"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/#scalar-view",
            "text": "Before training, start the tensorboard server through  tensorboard --logdir=<logs_dir>/<job_name>/  logs_dir  is the log directory you set for your predictor(e.g.  TimeSequencePredictor  in Automated Time Series Prediction). It is default to \"/home/\\<username>/zoo_automl_logs\", where  username  is your login username.  job_name  is the name parameter you set for your predictor.  The data in SCALARS tag will be updated every 30 seconds for users to see the training progress.",
            "title": "Scalar view"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/#leaderboard-view",
            "text": "After training, start the tensorboard server through  tensorboard --logdir=<logs_dir>/<job_name>_leaderboard/  where  logs_dir  and  job_name  are the same as stated in  Scalar view .  A leaderboard of each trail's configs and metrics is shown in the HPARAMS tag.",
            "title": "Leaderboard view"
        },
        {
            "location": "/ProgrammingGuide/AutoML/visualization/#use-visualization-in-jupyter-notebook",
            "text": "You can enable a tensorboard view in jupyter notebook by the following code  %load_ext tensorboard\n# for scalar view\n%tensorboard --logdir <logs_dir>/<job_name>/\n# for leaderboard view\n%tensorboard --logdir <logs_dir>/<job_name>_leaderboard/",
            "title": "Use visualization in Jupyter Notebook"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/",
            "text": "Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nAnalytics Zoo can process image data as Spark Data Frame.\n\nNNImageReader\n is the primary DataFrame-based image loading interface to read images into DataFrame.\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext(\"app\")\nval imageDF1 = NNImageReader.readImages(\"/tmp\", sc)\nval imageDF2 = NNImageReader.readImages(\"/tmp/*.jpg\", sc)\nval imageDF3 = NNImageReader.readImages(\"/tmp/a.jpg, /tmp/b.jpg\", sc)\n\n\n\n\n\nPython:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext(\"app\")\nimageDF1 = NNImageReader.readImages(\"/tmp\", sc)\nimageDF2 = NNImageReader.readImages(\"/tmp/*.jpg\", sc)\nimageDF3 = NNImageReader.readImages(\"/tmp/a.jpg, /tmp/b.jpg\", sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\"origin\", StringType, true) ::\n      StructField(\"height\", IntegerType, false) ::\n      StructField(\"width\", IntegerType, false) ::\n      StructField(\"nChannels\", IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\"mode\", IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\"data\", BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.\n\n\nLoad to ImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\n// create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\"/tmp/image/\")\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\"/tmp/image/\", sc, 2)\n\n\n\n\nPython example:\n\n\n# create LocalImageSet from an image folder\nlocal_image_frame2 = ImageSet.read(\"/tmp/image/\")\n\n# create DistributedImageSet from an image folder\ndistributed_image_frame = ImageSet.read(\"/tmp/image/\", sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo has many pre-defined image processing transformers built on top of OpenCV:\n\n\n\n\nImageBrightness\n: Adjust the image brightness.\n\n\nImageHue\n: Adjust the image hue.\n\n\nImageSaturation\n: Adjust the image Saturation.\n\n\nImageContrast\n: Adjust the image Contrast.\n\n\nImageChannelOrder\n: Random change the channel order of an image\n\n\nImageColorJitter\n: Random adjust brightness, contrast, hue, saturation\n\n\nImageResize\n: Resize image\n\n\nImageAspectScale\n: Resize the image, keep the aspect ratio. scale according to the short edge\n\n\nImageRandomAspectScale\n: Resize the image by randomly choosing a scale\n\n\nImageChannelNormalize\n: Image channel normalize\n\n\nImagePixelNormalizer\n: Pixel level normalizer\n\n\nImageCenterCrop\n: Crop a \ncropWidth\n x \ncropHeight\n patch from center of image.\n\n\nImageRandomCrop\n: Random crop a \ncropWidth\n x \ncropHeight\n patch from an image.\n\n\nImageFixedCrop\n: Crop a fixed area of image\n\n\nImageDetectionCrop\n: Crop from object detections, each image should has a tensor detection,\n\n\nImageExpand\n: Expand image, fill the blank part with the meanR, meanG, meanB\n\n\nImageFiller\n: Fill part of image with certain pixel value\n\n\nImageHFlip\n: Flip the image horizontally\n\n\nImageRandomPreprocessing\n: It is a wrapper for transformers to control the transform probability\n\n\nImageBytesToMat\n: Transform byte array(original image file in byte) to OpenCVMat\n\n\nImageMatToFloats\n: Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n\n\nImageMatToTensor\n: Transform opencv mat to tensor, note that in this transformer, the mat is released.\n\n\nImageSetToSample\n: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.\n\n\n\n\nMore examples can be found \nhere\n\n\nYou can also define your own Transformer by extending \nImageProcessing\n,\nand override the function \ntransformMat\n to do the actual transformation to \nImageFeature\n.\n\n\nBuild Image Transformation Pipeline\n\n\nYou can easily build the image transformation pipeline by chaining transformers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -> ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n             ImageChannelNormalize(123, 117, 104) ->\n             ImageMatToTensor[Float]() ->\n             ImageSetToSample[Float]()\n\n\n\n\nIn the above example, the transformations will perform sequentially.\n\n\nAssume you have an ImageSet containing original bytes array,\n\n\n\n\n\n\nImageBytesToMat\n will transform the bytes array to \nOpenCVMat\n.\n\n\n\n\n\n\nImageColorJitter\n, \nImageExpand\n, \nImageResize\n, \nImageHFlip\n and \nImageChannelNormalize\n will transform over \nOpenCVMat\n,\nnote that \nOpenCVMat\n is overwrite by default.\n\n\n\n\n\n\nImageMatToTensor\n transform \nOpenCVMat\n to \nTensor\n, and \nOpenCVMat\n is released in this step.\n\n\n\n\n\n\nImageSetToSample\n transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.\n\n\n\n\n\n\nPython example:\n\n\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.feature.common import ChainedPreprocessing\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])\n\n\n\n\nImage Train\n\n\nTrain with Image DataFrame\n\n\nYou can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call \nfit\n method to let Analytics Zoo train the model\n\n\nFor detail APIs, please refer to: \nNNFrames\n\n\nScala example:\n\n\nval batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -> ImageResize(256, 256) ->\n                                   ImageCenterCrop(224, 224) ->\n                                   ImageChannelNormalize(123, 117, 104) ->\n                                   ImageMatToTensor() ->\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\"image\")\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n\n\n\n\nPython example:\n\n\nbatchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\"image\")\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\n\n\nTrain with ImageSet\n\n\nYou can train Zoo Keras model with ImageSet. Just call \nfit\n method to let Analytics Zoo train the model.\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\"train keras\")\nimg_path=\"/tmp/image\"\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\"/tmp/bigdl_inception-v1_imagenet_0.4.0.model\"\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])\n\ninputNode = Input(name=\"input\", shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\n\n\n\n\nImage Predict\n\n\nPredict with Image DataFrame\n\n\nAfter training with \nNNEstimator/NNCLassifier\n, you'll get a trained \nNNModel/NNClassifierModel\n . You can call \ntransform\n to predict Image DataFrame with this \nNNModel/NNClassifierModel\n . Or you can load pre-trained \nAnalytics-Zoo/BigDL/Caffe/Torch/Tensorflow\n  model and create \nNNModel/NNClassifierModel\n with this model. Then call to \ntransform\n to Image DataFrame.\n\n\nAfter prediction, there is a new column \nprediction\n in the prediction image dataframe.\n\n\nScala example:\n\n\nval batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -> ImageResize(256, 256) ->\n                                   ImageCenterCrop(224, 224) ->\n                                   ImageChannelNormalize(123, 117, 104) ->\n                                   ImageMatToTensor() ->\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\"image\")\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n// predict with trained model\nval predictions = trainedModel.transform(testDf)\npredictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)\n\n// predict with loaded pre-trained model\nval model = Module.loadModule[Float](modelPath)\nval dlmodel = NNClassifierModel(model, featureTransformer)\n        .setBatchSize(batchsize)\n        .setFeaturesCol(\"image\")\n        .setPredictionCol(\"prediction\") \nval resultDF = dlmodel.transform(testDf)\n\n\n\n\nPython example:\n\n\nbatchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n    ImageCenterCrop(224, 224),\n    ImageChannelNormalize(123, 117, 104),\n    ImageMatToTensor(),\n    ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\"image\")\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n# predict with trained model\npredictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)\n\n# predict with loaded pre-trained model\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)\n\n\n\n\nPredict with ImageSet\n\n\nAfter training Zoo Keras model, you can call \npredict\n to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nPredict with trained Zoo Keras Model\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\"train keras\")\nimg_path=\"/tmp/image\"\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\"/tmp/bigdl_inception-v1_imagenet_0.4.0.model\"\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])\n\ninputNode = Input(name=\"input\", shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()\n\n\n\n\nPredict with loaded Model\n\n\nYou can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nFor details, you can check guide of \nimage classificaion\n or \nobject detection\n\n\n3D Image Support\n\n\nFor 3D images, we can support above operations based on ImageSet. For details, please refer to \nimage API guide\n\n\nCaching Images in Persistent Memory\n\n\nHere is a scala \nexample\n to train Inception V1 with ImageNet-2012 dataset. If you set the option \nmemoryType\n to \nPMEM\n, the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide \nhere\n on how to set up the system environment.\n\n\nIn the InceptionV1 example, we use an new dataset called \nFeatureSet\n to cache the data. Only scala API is currently available.\n\n\nScala example:\n\n\n val rawData = readFromSeqFiles(path, sc, classNumber)\n val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM)\n\n\n\n\nreadFromSeqFiles\n read the Sequence File into \nRDD[ByteRecord]\n, then \nFeatureSet.rdd(rawData, memoryType = PMEM)\n will cache the data to Intel Optane DC Persistent Memory.",
            "title": "Working with Images"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-image",
            "text": "Analytics Zoo provides APIs to read image to different formats:",
            "title": "Load Image"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-data-frame",
            "text": "Analytics Zoo can process image data as Spark Data Frame. NNImageReader  is the primary DataFrame-based image loading interface to read images into DataFrame.  Scala example:  import com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext(\"app\")\nval imageDF1 = NNImageReader.readImages(\"/tmp\", sc)\nval imageDF2 = NNImageReader.readImages(\"/tmp/*.jpg\", sc)\nval imageDF3 = NNImageReader.readImages(\"/tmp/a.jpg, /tmp/b.jpg\", sc)  Python:  from zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext(\"app\")\nimageDF1 = NNImageReader.readImages(\"/tmp\", sc)\nimageDF2 = NNImageReader.readImages(\"/tmp/*.jpg\", sc)\nimageDF3 = NNImageReader.readImages(\"/tmp/a.jpg, /tmp/b.jpg\", sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField(\"origin\", StringType, true) ::\n      StructField(\"height\", IntegerType, false) ::\n      StructField(\"width\", IntegerType, false) ::\n      StructField(\"nChannels\", IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\"mode\", IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\"data\", BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .",
            "title": "Load to Data Frame"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-imageset",
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  // create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\"/tmp/image/\")\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\"/tmp/image/\", sc, 2)  Python example:  # create LocalImageSet from an image folder\nlocal_image_frame2 = ImageSet.read(\"/tmp/image/\")\n\n# create DistributedImageSet from an image folder\ndistributed_image_frame = ImageSet.read(\"/tmp/image/\", sc, 2)",
            "title": "Load to ImageSet"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-transformer",
            "text": "Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV:   ImageBrightness : Adjust the image brightness.  ImageHue : Adjust the image hue.  ImageSaturation : Adjust the image Saturation.  ImageContrast : Adjust the image Contrast.  ImageChannelOrder : Random change the channel order of an image  ImageColorJitter : Random adjust brightness, contrast, hue, saturation  ImageResize : Resize image  ImageAspectScale : Resize the image, keep the aspect ratio. scale according to the short edge  ImageRandomAspectScale : Resize the image by randomly choosing a scale  ImageChannelNormalize : Image channel normalize  ImagePixelNormalizer : Pixel level normalizer  ImageCenterCrop : Crop a  cropWidth  x  cropHeight  patch from center of image.  ImageRandomCrop : Random crop a  cropWidth  x  cropHeight  patch from an image.  ImageFixedCrop : Crop a fixed area of image  ImageDetectionCrop : Crop from object detections, each image should has a tensor detection,  ImageExpand : Expand image, fill the blank part with the meanR, meanG, meanB  ImageFiller : Fill part of image with certain pixel value  ImageHFlip : Flip the image horizontally  ImageRandomPreprocessing : It is a wrapper for transformers to control the transform probability  ImageBytesToMat : Transform byte array(original image file in byte) to OpenCVMat  ImageMatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released.  ImageMatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released.  ImageSetToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.   More examples can be found  here  You can also define your own Transformer by extending  ImageProcessing ,\nand override the function  transformMat  to do the actual transformation to  ImageFeature .",
            "title": "Image Transformer"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#build-image-transformation-pipeline",
            "text": "You can easily build the image transformation pipeline by chaining transformers.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -> ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n             ImageChannelNormalize(123, 117, 104) ->\n             ImageMatToTensor[Float]() ->\n             ImageSetToSample[Float]()  In the above example, the transformations will perform sequentially.  Assume you have an ImageSet containing original bytes array,    ImageBytesToMat  will transform the bytes array to  OpenCVMat .    ImageColorJitter ,  ImageExpand ,  ImageResize ,  ImageHFlip  and  ImageChannelNormalize  will transform over  OpenCVMat ,\nnote that  OpenCVMat  is overwrite by default.    ImageMatToTensor  transform  OpenCVMat  to  Tensor , and  OpenCVMat  is released in this step.    ImageSetToSample  transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.    Python example:  from zoo.feature.image.imagePreprocessing import *\nfrom zoo.feature.common import ChainedPreprocessing\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])",
            "title": "Build Image Transformation Pipeline"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-train",
            "text": "",
            "title": "Image Train"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-image-dataframe",
            "text": "You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call  fit  method to let Analytics Zoo train the model  For detail APIs, please refer to:  NNFrames  Scala example:  val batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -> ImageResize(256, 256) ->\n                                   ImageCenterCrop(224, 224) ->\n                                   ImageChannelNormalize(123, 117, 104) ->\n                                   ImageMatToTensor() ->\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\"image\")\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)  Python example:  batchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\"image\")\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)",
            "title": "Train with Image DataFrame"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-imageset",
            "text": "You can train Zoo Keras model with ImageSet. Just call  fit  method to let Analytics Zoo train the model.  Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\"train keras\")\nimg_path=\"/tmp/image\"\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\"/tmp/bigdl_inception-v1_imagenet_0.4.0.model\"\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])\n\ninputNode = Input(name=\"input\", shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)",
            "title": "Train with ImageSet"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-predict",
            "text": "",
            "title": "Image Predict"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-image-dataframe",
            "text": "After training with  NNEstimator/NNCLassifier , you'll get a trained  NNModel/NNClassifierModel  . You can call  transform  to predict Image DataFrame with this  NNModel/NNClassifierModel  . Or you can load pre-trained  Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow   model and create  NNModel/NNClassifierModel  with this model. Then call to  transform  to Image DataFrame.  After prediction, there is a new column  prediction  in the prediction image dataframe.  Scala example:  val batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -> ImageResize(256, 256) ->\n                                   ImageCenterCrop(224, 224) ->\n                                   ImageChannelNormalize(123, 117, 104) ->\n                                   ImageMatToTensor() ->\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\"image\")\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n// predict with trained model\nval predictions = trainedModel.transform(testDf)\npredictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)\n\n// predict with loaded pre-trained model\nval model = Module.loadModule[Float](modelPath)\nval dlmodel = NNClassifierModel(model, featureTransformer)\n        .setBatchSize(batchsize)\n        .setFeaturesCol(\"image\")\n        .setPredictionCol(\"prediction\") \nval resultDF = dlmodel.transform(testDf)  Python example:  batchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n    ImageCenterCrop(224, 224),\n    ImageChannelNormalize(123, 117, 104),\n    ImageMatToTensor(),\n    ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\"image\")\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n# predict with trained model\npredictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)\n\n# predict with loaded pre-trained model\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)",
            "title": "Predict with Image DataFrame"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-imageset",
            "text": "After training Zoo Keras model, you can call  predict  to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.",
            "title": "Predict with ImageSet"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-zoo-keras-model",
            "text": "Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\"train keras\")\nimg_path=\"/tmp/image\"\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\"/tmp/bigdl_inception-v1_imagenet_0.4.0.model\"\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\"pool4/3x3_s2\"])\n\ninputNode = Input(name=\"input\", shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()",
            "title": "Predict with trained Zoo Keras Model"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-model",
            "text": "You can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.  For details, you can check guide of  image classificaion  or  object detection",
            "title": "Predict with loaded Model"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#3d-image-support",
            "text": "For 3D images, we can support above operations based on ImageSet. For details, please refer to  image API guide",
            "title": "3D Image Support"
        },
        {
            "location": "/ProgrammingGuide/workingwithimages/#caching-images-in-persistent-memory",
            "text": "Here is a scala  example  to train Inception V1 with ImageNet-2012 dataset. If you set the option  memoryType  to  PMEM , the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide  here  on how to set up the system environment.  In the InceptionV1 example, we use an new dataset called  FeatureSet  to cache the data. Only scala API is currently available.  Scala example:   val rawData = readFromSeqFiles(path, sc, classNumber)\n val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM)  readFromSeqFiles  read the Sequence File into  RDD[ByteRecord] , then  FeatureSet.rdd(rawData, memoryType = PMEM)  will cache the data to Intel Optane DC Persistent Memory.",
            "title": "Caching Images in Persistent Memory"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/",
            "text": "Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline,\nincluding text loading, pre-processing, training and inference, etc.\n\n\n\n\nTextSet\n\n\nTextSet\n is a collection of TextFeatures where each \nTextFeature\n keeps information of a single text record.\n\n\nTextSet\n can either be a \nDistributedTextSet\n consisting of text RDD or a \nLocalTextSet\n consisting of text array.\n\n\n\n\nRead texts as TextSet\n\n\nRead texts from a directory\n\n\nRead texts with labels from a directory.\n\n\nUnder this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.\n\n\nScala\n\n\ntextSet = TextSet.read(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from csv file\n\n\nRead texts with id from csv file.\n\n\nEach record is supposed to contain id(String) and text(String) in order.\n\n\nNote that the csv file should be without header.\n\n\nScala\n\n\ntextSet = TextSet.readCSV(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_csv(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from parquet file\n\n\nRead texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.\n\n\nScala\n\n\ntextSet = TextSet.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.\n\n\n\n\n\n\nBuild Text Transformation Pipeline\n\n\nYou can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to \nhere\n for more details.\n\n\nScala Example\n\n\ntransformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample()\n\n\n\n\nPython Example\n\n\ntransformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample()\n\n\n\n\n\n\nText Training\n\n\nAfter doing text transformation, you can directly feed the transformed TextSet into the model for training.\n\n\nScala\n\n\nmodel.fit(transformedTextSet, batchSize, nbEpoch)\n\n\n\n\nPython\n\n\nmodel.fit(transformed_text_set, batch_size, nb_epoch)\n\n\n\n\n\n\nWord Index Save and Load\n\n\nSave word index\n\n\nAfter training the model, you can save the word index correspondence to text file, which can be used for future inference. Each separate line will be \"word id\".\n\n\nFor LocalTextSet, save txt to a local file system.\n\n\nFor DistributedTextSet, save txt to a local or distributed file system (such as HDFS).\n\n\nScala\n\n\ntransformedTextSet.saveWordIndex(path)\n\n\n\n\nPython\n\n\ntransformed_text_set.save_word_index(path)\n\n\n\n\nLoad word index\n\n\nDuring text prediction, you can load the saved word index back, so that the prediction TextSet uses exactly the same word index as the training process. Each separate line should be \"word id\".\n\n\nFor LocalTextSet, load txt to a local file system.\n\n\nFor DistributedTextSet, load txt to a local or distributed file system (such as HDFS).\n\n\nScala\n\n\ntextSet.loadWordIndex(path)\n\n\n\n\nPython\n\n\ntext_set.load_word_index(path)\n\n\n\n\n\n\nText Prediction\n\n\nGiven a raw TextSet to do prediction, you need to first load the saved word index back as instructed \nabove\n and go through the same transformation\nprocess as what you did in your training. Note that here you do not need to specify any argument when calling \nword2idx\n in the preprocessing pipeline as now you are using exactly\nthe loaded word index.\n\n\nThen you can directly feed the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature.\n\n\nScala\n\n\npredictionTextSet = model.predict(transformedTextSet)\n\n\n\n\nPython\n\n\nprediction_text_set = model.predict(transformed_text_set)\n\n\n\n\n\n\nExamples\n\n\nYou can refer to our TextClassification example for TextSet transformation, training and inference.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.",
            "title": "Working with Texts"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#textset",
            "text": "TextSet  is a collection of TextFeatures where each  TextFeature  keeps information of a single text record.  TextSet  can either be a  DistributedTextSet  consisting of text RDD or a  LocalTextSet  consisting of text array.",
            "title": "TextSet"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-as-textset",
            "text": "",
            "title": "Read texts as TextSet"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-a-directory",
            "text": "Read texts with labels from a directory.  Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.  Scala  textSet = TextSet.read(path, sc = null, minPartitions = 1)   path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read(path, sc=None, min_partitions=1)   path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.",
            "title": "Read texts from a directory"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-csv-file",
            "text": "Read texts with id from csv file.  Each record is supposed to contain id(String) and text(String) in order.  Note that the csv file should be without header.  Scala  textSet = TextSet.readCSV(path, sc = null, minPartitions = 1)   path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read_csv(path, sc=None, min_partitions=1)   path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.",
            "title": "Read texts from csv file"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-parquet-file",
            "text": "Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.  Scala  textSet = TextSet.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  text_set = TextSet.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.",
            "title": "Read texts from parquet file"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#build-text-transformation-pipeline",
            "text": "You can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to  here  for more details.  Scala Example  transformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample()  Python Example  transformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample()",
            "title": "Build Text Transformation Pipeline"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#text-training",
            "text": "After doing text transformation, you can directly feed the transformed TextSet into the model for training.  Scala  model.fit(transformedTextSet, batchSize, nbEpoch)  Python  model.fit(transformed_text_set, batch_size, nb_epoch)",
            "title": "Text Training"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#word-index-save-and-load",
            "text": "",
            "title": "Word Index Save and Load"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#save-word-index",
            "text": "After training the model, you can save the word index correspondence to text file, which can be used for future inference. Each separate line will be \"word id\".  For LocalTextSet, save txt to a local file system.  For DistributedTextSet, save txt to a local or distributed file system (such as HDFS).  Scala  transformedTextSet.saveWordIndex(path)  Python  transformed_text_set.save_word_index(path)",
            "title": "Save word index"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#load-word-index",
            "text": "During text prediction, you can load the saved word index back, so that the prediction TextSet uses exactly the same word index as the training process. Each separate line should be \"word id\".  For LocalTextSet, load txt to a local file system.  For DistributedTextSet, load txt to a local or distributed file system (such as HDFS).  Scala  textSet.loadWordIndex(path)  Python  text_set.load_word_index(path)",
            "title": "Load word index"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#text-prediction",
            "text": "Given a raw TextSet to do prediction, you need to first load the saved word index back as instructed  above  and go through the same transformation\nprocess as what you did in your training. Note that here you do not need to specify any argument when calling  word2idx  in the preprocessing pipeline as now you are using exactly\nthe loaded word index.  Then you can directly feed the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature.  Scala  predictionTextSet = model.predict(transformedTextSet)  Python  prediction_text_set = model.predict(transformed_text_set)",
            "title": "Text Prediction"
        },
        {
            "location": "/ProgrammingGuide/workingwithtexts/#examples",
            "text": "You can refer to our TextClassification example for TextSet transformation, training and inference.  See  here  for the Scala example.  See  here  for the Python example.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/object-detection/",
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Apache Spark, Apache Storm or Apache Flink.\n\n\nObject Detection examples\n\n\nAnalytics Zoo provides two typical kind of pre-trained Object Detection models : \nSSD\n and \nFaster-RCNN\n on dataset \nPASCAL\n and \nCOCO\n. For the usage of these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nNote: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set \nimageCodec\n when loading images \nImageSet.read\n. See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples\n\n\nUsers can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) ->\n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) ->\n                         MatToTensor() -> ImageFrameToSample()\nval output = model.predictImageset(data)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nDownload link\n\n\nPASCAL VOC models\n\n\n\n\nSSD 300x300 MobileNet\n\n\nSSD 300x300 VGG\n\n\nSSD 300x300 VGG Quantize\n\n\nSSD 512x512 VGG\n\n\nSSD 512x512 VGG Quantize\n\n\nFaster-RCNN VGG\n\n\nFaster-RCNN VGG Compress\n\n\nFaster-RCNN VGG Compress Quantize\n\n\nFaster-RCNN PvaNet\n\n\nFaster-RCNN PvaNet Compress\n\n\nFaster-RCNN PvaNet Compress Quantize\n\n\n\n\nCOCO models\n\n\n\n\nSSD 300x300 VGG\n\n\nSSD 300x300 VGG Quantize\n\n\nSSD 512x512 VGG\n\n\nSSD 512x512 VGG Quantize",
            "title": "Object Detection API"
        },
        {
            "location": "/ProgrammingGuide/object-detection/#object-detection-examples",
            "text": "Analytics Zoo provides two typical kind of pre-trained Object Detection models :  SSD  and  Faster-RCNN  on dataset  PASCAL  and  COCO . For the usage of these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)  For preprocessors for Object Detection models, please check  Object Detection Config  Note: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set  imageCodec  when loading images  ImageSet.read . See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples  Users can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) ->\n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) ->\n                         MatToTensor() -> ImageFrameToSample()\nval output = model.predictImageset(data)  Python  Python example  It's very easy to apply the model for inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)  For preprocessors for Object Detection models, please check  Object Detection Config",
            "title": "Object Detection examples"
        },
        {
            "location": "/ProgrammingGuide/object-detection/#download-link",
            "text": "PASCAL VOC models   SSD 300x300 MobileNet  SSD 300x300 VGG  SSD 300x300 VGG Quantize  SSD 512x512 VGG  SSD 512x512 VGG Quantize  Faster-RCNN VGG  Faster-RCNN VGG Compress  Faster-RCNN VGG Compress Quantize  Faster-RCNN PvaNet  Faster-RCNN PvaNet Compress  Faster-RCNN PvaNet Compress Quantize   COCO models   SSD 300x300 VGG  SSD 300x300 VGG Quantize  SSD 512x512 VGG  SSD 512x512 VGG Quantize",
            "title": "Download link"
        },
        {
            "location": "/ProgrammingGuide/image-classification/",
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nImage Classification examples\n\n\nAnalytics Zoo provides several typical kind of pre-trained Image Classfication models : \nAlexnet\n, \nInception-V1\n, \nVGG\n, \nResnet\n, \nDensenet\n, \nMobilenet\n, \nSqueezenet\n models. To use these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n        ImageChannelNormalize(123, 117, 104) ->\n        ImageMatToTensor[Float]() ->\n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Image Classification models, please check \nImage Classification Config\n\n\nDownload link\n\n\n\n\nAlexnet\n\n\nAlexnet Quantize\n\n\nInception-V1\n\n\nInception-V1 Quantize\n\n\nInception-V3\n\n\nInception-V3 Quantize\n\n\nVGG-16\n\n\nVGG-16 Quantize\n\n\nVGG-19\n\n\nVGG-19 Quantize\n\n\nResnet-50\n\n\nResnet-50 Quantize\n\n\nResnet-50 Int8\n\n\nDensenet-161\n\n\nDensenet-161 Quantize\n\n\nMobilenet\n\n\nMobilenet-V2\n\n\nMobilenet-V2 Quantize\n\n\nSqueezenet\n\n\nSqueezenet Quantize",
            "title": "Image Classification API"
        },
        {
            "location": "/ProgrammingGuide/image-classification/#image-classification-examples",
            "text": "Analytics Zoo provides several typical kind of pre-trained Image Classfication models :  Alexnet ,  Inception-V1 ,  VGG ,  Resnet ,  Densenet ,  Mobilenet ,  Squeezenet  models. To use these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)  User can also define his own configuration to do the inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n        ImageChannelNormalize(123, 117, 104) ->\n        ImageMatToTensor[Float]() ->\n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)  Python  Python example  It's very easy to apply the model for inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)  For preprocessors for Image Classification models, please check  Image Classification Config",
            "title": "Image Classification examples"
        },
        {
            "location": "/ProgrammingGuide/image-classification/#download-link",
            "text": "Alexnet  Alexnet Quantize  Inception-V1  Inception-V1 Quantize  Inception-V3  Inception-V3 Quantize  VGG-16  VGG-16 Quantize  VGG-19  VGG-19 Quantize  Resnet-50  Resnet-50 Quantize  Resnet-50 Int8  Densenet-161  Densenet-161 Quantize  Mobilenet  Mobilenet-V2  Mobilenet-V2 Quantize  Squeezenet  Squeezenet Quantize",
            "title": "Download link"
        },
        {
            "location": "/ProgrammingGuide/text-classification/",
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\n\n\nHighlights\n\n\n\n\nEasy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer.\n\n\nThe encoders we support include CNN, LSTM and GRU.\n\n\n\n\n\n\nBuild a TextClassifier model\n\n\nYou can call the following API in Scala and Python respectively to create a \nTextClassifier\n with \npre-trained GloVe word embeddings as the first layer\n.\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \"cnn\", encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\nembeddingFile\n The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\"cnn\", encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\nembedding_file\n The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\n\n\nTrain a TextClassifier model\n\n\nAfter building the model, we can call compile and fit to train it (with validation).\n\n\nFor training and validation data, you can first read files as \nTextSet\n (see \nhere\n) and then do preprocessing (see \nhere\n).\n\n\nScala\n\n\nmodel.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy()))\nmodel.fit(trainSet, batchSize, nbEpoch, validateSet)\n\n\n\n\nPython\n\n\nmodel.compile(optimizer=Adagrad(learning_rate, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\nmodel.fit(train_set, batch_size, nb_epoch, validate_set)\n\n\n\n\n\n\nDo prediction\n\n\nAfter training the model, it can be used to predict probability distributions.\n\n\nScala\n\n\nval predictSet = textClassifier.predict(validateSet)\n\n\n\n\nPython\n\n\npredict_set = text_classifier.predict(validate_set)\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.",
            "title": "Text Classification API"
        },
        {
            "location": "/ProgrammingGuide/text-classification/#build-a-textclassifier-model",
            "text": "You can call the following API in Scala and Python respectively to create a  TextClassifier  with  pre-trained GloVe word embeddings as the first layer .  Scala  val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \"cnn\", encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  embeddingFile  The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex  Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   Python  text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\"cnn\", encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  embedding_file  The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index  Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.",
            "title": "Build a TextClassifier model"
        },
        {
            "location": "/ProgrammingGuide/text-classification/#train-a-textclassifier-model",
            "text": "After building the model, we can call compile and fit to train it (with validation).  For training and validation data, you can first read files as  TextSet  (see  here ) and then do preprocessing (see  here ).  Scala  model.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy()))\nmodel.fit(trainSet, batchSize, nbEpoch, validateSet)  Python  model.compile(optimizer=Adagrad(learning_rate, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\nmodel.fit(train_set, batch_size, nb_epoch, validate_set)",
            "title": "Train a TextClassifier model"
        },
        {
            "location": "/ProgrammingGuide/text-classification/#do-prediction",
            "text": "After training the model, it can be used to predict probability distributions.  Scala  val predictSet = textClassifier.predict(validateSet)  Python  predict_set = text_classifier.predict(validate_set)",
            "title": "Do prediction"
        },
        {
            "location": "/ProgrammingGuide/text-classification/#examples",
            "text": "We provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  See  here  for the Scala example.  See  here  for the Python example.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/recommendation/",
            "text": "Analytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model. \n\n\nHighlights\n\n\n\n\nEasy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer.\n\n\nRecommenders can handle either explict or implicit feedback, given corresponding features.\n\n\nIt provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items).\n\n\n\n\nThe examples/notebooks are included in the Analytics Zoo source code.\n\n\n\n\nWide and Deep Learning Model.\n    \nScala example\n\n    \nPython notebook\n\n\nNCF.\n    \nScala example\n\n    \nPython notebook\n\n\nSession Recommender model.\n    \nScala example\n\n\n\n\n\n\nWide and Deep\n\n\nScala\n\n\nBuild a WND model for recommendation. \n\n\nval wideAndDeep = WideAndDeep(modelType = \"wide_n_deep\", numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\nCompile and train a WND model.\n\n\nwideAndDeep.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n                    loss = SparseCategoricalCrossEntropy[Float](),\n                    metrics = List(new Top1Accuracy[Float]()))\nwideAndDeep.fit(trainRdds, batchSize, nbEpoch, validationRdds)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n.\n\n\nPython\n\n\nCompile and train a WND model.\n\n\nwide_n_deep = WideAndDeep(class_num, column_info, model_type=\"wide_n_deep\", hidden_layers=(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer \n\n\nwide_n_deep.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6),\n                    loss= \"sparse_categorical_crossentropy\",\n                    metrics=['accuracy'])\nwide_n_deep.fit(train_rdd, nb_epoch, batch_size, val_rdd)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nScala\n\n\nBuild a NCF model for recommendation. \n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\nCompile and train a NCF model\n\n\nncf.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n            loss = SparseCategoricalCrossEntropy[Float](),\n            metrics = List(new Top1Accuracy[Float]()))\nncf.fit(trainRdds, batchSize, nbEpoch, validationRdds)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a NCF model for recommendation. \n\n\nncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\nCompile and train a NCF model\n\n\nncf.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6),\n            loss= \"sparse_categorical_crossentropy\",\n            metrics=['accuracy'])\nncf.fit(train_rdd, nb_epoch, batch_size, val_rdd)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.\n\n\n\n\nSession Recommender Model\n\n\nScala\n\n\nBuild a Session Recommender model for recommendation. \n\n\nval sessionRecommender = SessionRecommender(itemCount, itemEmbed, sessionLength, includeHistory, mlpHiddenLayers, historyLength)\n\nCompile and train a Session Recommender model\n```scala\nsessionRecommender.compile(optimizer = new RMSprop[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n                           loss = SparseCategoricalCrossEntropy[Float](),\n                           metrics = List(new Top1Accuracy[Float]()))\nsessionRecommender.fit(trainRdds, batchSize, nbEpoch, validationRdds)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval results = sessionRecommender.predict(testRdd)\nval recommendations = model.recommendForSession(testRdd, 3, false)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a Session Recommender model for recommendation. \n\n\nsession_recommender=SessionRecommender(item_count, item_embed, rnn_hidden_layers=[40, 20], session_length=10, include_history=True, mlp_hidden_layers=[40, 20], history_length=5)\n\n\n\n\nCompile and train a NCF model\n\n\nsession_recommender.compile(optimizer= RMSprop(learningrate = 1e-3, learningrate_decay=1e-6),\n                            loss= \"sparse_categorical_crossentropy\",\n                            metrics=['top5Accuracy'])\nsession_recommender.fit(train, batch_size=4, nb_epoch=1, validation_data=test)\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nresults1 = session_recommender.predict(test)\nrecommendations1 = session_recommender.recommend_for_session(rdd, 3, zero_based_label=False)",
            "title": "Recommendation API"
        },
        {
            "location": "/ProgrammingGuide/recommendation/#wide-and-deep",
            "text": "Scala  Build a WND model for recommendation.   val wideAndDeep = WideAndDeep(modelType = \"wide_n_deep\", numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))  Compile and train a WND model.  wideAndDeep.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n                    loss = SparseCategoricalCrossEntropy[Float](),\n                    metrics = List(new Top1Accuracy[Float]()))\nwideAndDeep.fit(trainRdds, batchSize, nbEpoch, validationRdds)  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example .  Python  Compile and train a WND model.  wide_n_deep = WideAndDeep(class_num, column_info, model_type=\"wide_n_deep\", hidden_layers=(40, 20, 10))  Train a WND model using BigDL Optimizer   wide_n_deep.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6),\n                    loss= \"sparse_categorical_crossentropy\",\n                    metrics=['accuracy'])\nwide_n_deep.fit(train_rdd, nb_epoch, batch_size, val_rdd)  Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .",
            "title": "Wide and Deep"
        },
        {
            "location": "/ProgrammingGuide/recommendation/#neural-network-based-collaborative-filtering",
            "text": "Scala  Build a NCF model for recommendation.   val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)  Compile and train a NCF model  ncf.compile(optimizer = new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n            loss = SparseCategoricalCrossEntropy[Float](),\n            metrics = List(new Top1Accuracy[Float]()))\nncf.fit(trainRdds, batchSize, nbEpoch, validationRdds)  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example  Python  Build a NCF model for recommendation.   ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)  Compile and train a NCF model  ncf.compile(optimizer= Adam(learningrate = 1e-3, learningrate_decay=1e-6),\n            loss= \"sparse_categorical_crossentropy\",\n            metrics=['accuracy'])\nncf.fit(train_rdd, nb_epoch, batch_size, val_rdd)  Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .",
            "title": "Neural network-based Collaborative Filtering"
        },
        {
            "location": "/ProgrammingGuide/recommendation/#session-recommender-model",
            "text": "Scala  Build a Session Recommender model for recommendation.   val sessionRecommender = SessionRecommender(itemCount, itemEmbed, sessionLength, includeHistory, mlpHiddenLayers, historyLength)\n\nCompile and train a Session Recommender model\n```scala\nsessionRecommender.compile(optimizer = new RMSprop[Float](learningRate = 1e-2,learningRateDecay = 1e-5),\n                           loss = SparseCategoricalCrossEntropy[Float](),\n                           metrics = List(new Top1Accuracy[Float]()))\nsessionRecommender.fit(trainRdds, batchSize, nbEpoch, validationRdds)  Predict and recommend items(users) for users(items) with given features.  val results = sessionRecommender.predict(testRdd)\nval recommendations = model.recommendForSession(testRdd, 3, false)  See more details in our Recommender API  and  Scala example  Python  Build a Session Recommender model for recommendation.   session_recommender=SessionRecommender(item_count, item_embed, rnn_hidden_layers=[40, 20], session_length=10, include_history=True, mlp_hidden_layers=[40, 20], history_length=5)  Compile and train a NCF model  session_recommender.compile(optimizer= RMSprop(learningrate = 1e-3, learningrate_decay=1e-6),\n                            loss= \"sparse_categorical_crossentropy\",\n                            metrics=['top5Accuracy'])\nsession_recommender.fit(train, batch_size=4, nb_epoch=1, validation_data=test)  Predict and recommend items(users) for users(items) with given features.  results1 = session_recommender.predict(test)\nrecommendations1 = session_recommender.recommend_for_session(rdd, 3, zero_based_label=False)",
            "title": "Session Recommender Model"
        },
        {
            "location": "/ProgrammingGuide/anomaly-detection/",
            "text": "Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. \nA sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions.  \n\n\nHightlights\n\n\n\n\nKeras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training.\n\n\nModels are defined base on LSTM.\n\n\n\n\n\n\nBuild an AnomalyDetction model\n\n\nYou can call the following API in Scala and Python respectively to create an \nAnomalyDetrctor\n model\n\n\nScala\n\n\nimport com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)\n\n\n\n\n\n\nfeatureShape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhiddenLayers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nPython\n\n\nfrom zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])\n\n\n\n\n\n\nfeature_shape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhidden_layers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nTrain an AnomalyDetector model\n\n\nAfter building the model, we can compile and train it using RDD of \nSample\n.\n\n\nNote that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples.\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.optim._\n\nmodel.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9),\n      loss = MeanSquaredError[Float]())\nmodel.fit(trainRdd, batchSize = 1024, nbEpoch = 20)\n\n\n\n\nPython\n\n\nmodel.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(train, batch_size = 1024, nb_epoch = 20)\n\n\n\n\n\n\nDo prediction to detect anomalies\n\n\nAfter training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top \nanomalySize\n data points are anomalies).\n\n\nScala\n\n\nval yPredict = model.predict(testRdd).map(x => x.toTensor.toArray()(0))\nval yTruth: RDD[Float] = testRdd.map(x => x.label.toArray()(0))\nval anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20)\n\n\n\n\nPython\n\n\ny_predict = model.predict(test).map(lambda x: float(x[0]))\ny_test = test.map(lambda x: float(x.label.to_ndarray()[0]))\nanomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20)\n\n\n\n\n\n\nExamples\n\n\nWe provide examples to train the AnomalyDetector model and detect possible anomalies using data of \nNYC taxi passengers\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.\n\n\nSee a \nPython notebook\n for defining and training a model using simple Keras layers, and more details.",
            "title": "Anomaly Detection API"
        },
        {
            "location": "/ProgrammingGuide/anomaly-detection/#build-an-anomalydetction-model",
            "text": "You can call the following API in Scala and Python respectively to create an  AnomalyDetrctor  model  Scala  import com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)   featureShape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hiddenLayers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.   Python  from zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])   feature_shape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hidden_layers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.",
            "title": "Build an AnomalyDetction model"
        },
        {
            "location": "/ProgrammingGuide/anomaly-detection/#train-an-anomalydetector-model",
            "text": "After building the model, we can compile and train it using RDD of  Sample .  Note that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples.  Scala  import com.intel.analytics.bigdl.optim._\n\nmodel.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9),\n      loss = MeanSquaredError[Float]())\nmodel.fit(trainRdd, batchSize = 1024, nbEpoch = 20)  Python  model.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(train, batch_size = 1024, nb_epoch = 20)",
            "title": "Train an AnomalyDetector model"
        },
        {
            "location": "/ProgrammingGuide/anomaly-detection/#do-prediction-to-detect-anomalies",
            "text": "After training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top  anomalySize  data points are anomalies).  Scala  val yPredict = model.predict(testRdd).map(x => x.toTensor.toArray()(0))\nval yTruth: RDD[Float] = testRdd.map(x => x.label.toArray()(0))\nval anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20)  Python  y_predict = model.predict(test).map(lambda x: float(x[0]))\ny_test = test.map(lambda x: float(x.label.to_ndarray()[0]))\nanomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20)",
            "title": "Do prediction to detect anomalies"
        },
        {
            "location": "/ProgrammingGuide/anomaly-detection/#examples",
            "text": "We provide examples to train the AnomalyDetector model and detect possible anomalies using data of  NYC taxi passengers  See  here  for the Scala example.  See  here  for the Python example.  See a  Python notebook  for defining and training a model using simple Keras layers, and more details.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/text-matching/",
            "text": "Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering).\nMore text matching models will be supported in the future.\n\n\nHighlights\n\n\n\n\nEasy-to-use Keras-Style defined model which provides compile and fit methods for training. Alternatively, it could be fed into NNFrames or BigDL Optimizer.\n\n\nThe model can be used for both ranking and classification tasks.\n\n\n\n\n\n\nBuild a KNRM Model\n\n\nKernel-pooling Neural Ranking Model with RBF kernel. See \nhere\n for more details.\n\n\nYou can call the following API in Scala and Python respectively to create a \nKNRM\n with \npre-trained GloVe word embeddings\n.\n\n\nScala\n\n\nval knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \"ranking\")\n\n\n\n\n\n\ntext1Length\n: Sequence length of text1 (query).\n\n\ntext2Length\n: Sequence length of text2 (doc).\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainEmbed\n: Boolean. Whether to train the embedding layer or not. Default is true.\n\n\nkernelNum\n: Integer > 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexactSigma\n: Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntargetMode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nPython\n\n\nknrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\"ranking\")\n\n\n\n\n\n\ntext1_length\n: Sequence length of text1 (query).\n\n\ntext2_length\n: Sequence length of text2 (doc).\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrain_embed\n: Boolean. Whether to train the embedding layer or not. Default is True.\n\n\nkernel_num\n: Int > 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexact_sigma\n: Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntarget_mode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\n\n\nPairwise training\n\n\nFor ranking, the model can be trained pairwisely with the following steps:\n\n\n\n\nRead train relations. See \nhere\n for more details.\n\n\nRead text1 and text2 corpus as TextSet. See \nhere\n for more details.\n\n\nPreprocess text1 and text2 corpus. See \nhere\n for more details.\n\n\nGenerate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1.\nDuring the training process, we intend to optimize the margin loss within each pair.\nWe provide the following API to generate a \nTextSet\n for pairwise training:\n\n\n\n\nScala\n\n\nval trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or array of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling \ntokenize\n, \nword2idx\n \n  and \nshapeSequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nPython\n\n\ntrain_set = TextSet.from_relation_pairs(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or list of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling \ntokenize\n, \nword2idx\n \n  and \nshape_sequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nCall compile and fit to train the model:\n\n\nScala\n\n\nval model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length)))\nmodel.compile(optimizer = new SGD(learningRate), loss = RankHinge())\nmodel.fit(trainSet, batchSize, nbEpoch)\n\n\n\n\nPython\n\n\nmodel = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length)))\nmodel.compile(optimizer=SGD(learning_rate), loss='rank_hinge')\nmodel.fit(train_set, batch_size, nb_epoch)\n\n\n\n\n\n\nListwise evaluation\n\n\nGiven text1 and a list of text2 candidates, we provide metrics \nNDCG\n and \nMAP\n to listwisely evaluate a ranking model with the following steps:\n\n\n\n\nRead validation relations. See \nhere\n for more details.\n\n\nRead text1 and text2 corpus as TextSet. See \nhere\n for more details.\n\n\nPreprocess text1 and text2 corpus same as the training phase. See \nhere\n for more details.\n\n\nGenerate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1.\nWe provide the following API to generate a \nTextSet\n for listwise evaluation:\n\n\n\n\nScala\n\n\nval validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or array of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling \ntokenize\n, \nword2idx\n \nand \nshapeSequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nPython\n\n\nvalidate_set = TextSet.from_relation_lists(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or list of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling \ntokenize\n, \nword2idx\n \nand \nshape_sequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nCall evaluateNDCG or evaluateMAP to evaluate the model:\n\n\nScala\n\n\nknrm.evaluateNDCG(validateSet, k, threshold = 0.0)\nknrm.evaluateMAP(validateSet, threshold = 0.0)\n\n\n\n\nPython\n\n\nknrm.evaluate_ndcg(validate_set, k, threshold=0.0)\nknrm.evaluate_map(validate_set, threshold=0.0)\n\n\n\n\n\n\nk\n: Positive integer. Rank position in NDCG.\n\n\nthreshold\n: If label > threshold, then it will be considered as a positive record. Default is 0.0.\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.",
            "title": "Text Matching API"
        },
        {
            "location": "/ProgrammingGuide/text-matching/#build-a-knrm-model",
            "text": "Kernel-pooling Neural Ranking Model with RBF kernel. See  here  for more details.  You can call the following API in Scala and Python respectively to create a  KNRM  with  pre-trained GloVe word embeddings .  Scala  val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \"ranking\")   text1Length : Sequence length of text1 (query).  text2Length : Sequence length of text2 (doc).  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true.  kernelNum : Integer > 1. The number of kernels to use. Default is 21.  sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   Python  knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\"ranking\")   text1_length : Sequence length of text1 (query).  text2_length : Sequence length of text2 (doc).  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  train_embed : Boolean. Whether to train the embedding layer or not. Default is True.  kernel_num : Int > 1. The number of kernels to use. Default is 21.  sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.",
            "title": "Build a KNRM Model"
        },
        {
            "location": "/ProgrammingGuide/text-matching/#pairwise-training",
            "text": "For ranking, the model can be trained pairwisely with the following steps:   Read train relations. See  here  for more details.  Read text1 and text2 corpus as TextSet. See  here  for more details.  Preprocess text1 and text2 corpus. See  here  for more details.  Generate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1.\nDuring the training process, we intend to optimize the margin loss within each pair.\nWe provide the following API to generate a  TextSet  for pairwise training:   Scala  val trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2)   relations : RDD or array of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling  tokenize ,  word2idx  \n  and  shapeSequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.   Python  train_set = TextSet.from_relation_pairs(relations, corpus1, corpus2)   relations : RDD or list of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling  tokenize ,  word2idx  \n  and  shape_sequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.   Call compile and fit to train the model:  Scala  val model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length)))\nmodel.compile(optimizer = new SGD(learningRate), loss = RankHinge())\nmodel.fit(trainSet, batchSize, nbEpoch)  Python  model = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length)))\nmodel.compile(optimizer=SGD(learning_rate), loss='rank_hinge')\nmodel.fit(train_set, batch_size, nb_epoch)",
            "title": "Pairwise training"
        },
        {
            "location": "/ProgrammingGuide/text-matching/#listwise-evaluation",
            "text": "Given text1 and a list of text2 candidates, we provide metrics  NDCG  and  MAP  to listwisely evaluate a ranking model with the following steps:   Read validation relations. See  here  for more details.  Read text1 and text2 corpus as TextSet. See  here  for more details.  Preprocess text1 and text2 corpus same as the training phase. See  here  for more details.  Generate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1.\nWe provide the following API to generate a  TextSet  for listwise evaluation:   Scala  val validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2)   relations : RDD or array of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling  tokenize ,  word2idx  \nand  shapeSequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.   Python  validate_set = TextSet.from_relation_lists(relations, corpus1, corpus2)   relations : RDD or list of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling  tokenize ,  word2idx  \nand  shape_sequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.   Call evaluateNDCG or evaluateMAP to evaluate the model:  Scala  knrm.evaluateNDCG(validateSet, k, threshold = 0.0)\nknrm.evaluateMAP(validateSet, threshold = 0.0)  Python  knrm.evaluate_ndcg(validate_set, k, threshold=0.0)\nknrm.evaluate_map(validate_set, threshold=0.0)   k : Positive integer. Rank position in NDCG.  threshold : If label > threshold, then it will be considered as a positive record. Default is 0.0.",
            "title": "Listwise evaluation"
        },
        {
            "location": "/ProgrammingGuide/text-matching/#examples",
            "text": "We provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking.  See  here  for the Scala example.  See  here  for the Python example.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/seq2seq/",
            "text": "Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more.\n\n\nHighlights\n\n\n\n\nEasy-to-use models, could be fed into NNFrames or BigDL Optimizer for training.\n\n\nSupport SimpleRNN, LSTM and GRU.\n\n\nSupport transform encoder states before fed into decoder\n\n\n\n\n\n\nBuild a Seq2seq model\n\n\nYou can call the following API in Scala and Python respectively to create a \nSeq2seq\n.\n\n\nScala\n\n\nval encoder = RNNEncoder[Float](rnnType=\"lstm\", numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval decoder = RNNDecoder[Float](rnnType=\"lstm\", numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval bridge = Bridge[Float](bridgeType=\"dense\", decoderHiddenSize=3)\nval model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge)\n\n\n\n\n\n\nrnnType\n: currently support \"simplernn | lstm | gru\"\n\n\nnumLayer\n: number of layers\n\n\nhiddenSize\n: hidden size\n\n\nembedding\n: embedding layer\n\n\nbridgeType\n: currently only support \"dense | densenonlinear\"\n\n\ninput_shape\n: shape of encoder input\n\n\noutput_shape\n: shape of decoder input\n\n\n\n\nPython\n\n\nencoder = RNNEncoder.initialize(rnn_tpye=\"LSTM\", nlayers=1, hidden_size=4)\ndecoder = RNNDecoder.initialize(rnn_tpye=\"LSTM\", nlayers=1, hidden_size=4)\nbridge = Bridge.initialize(bridge_type=\"dense\", decoder_hidden_size=4)\nseq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge)\n\n\n\n\n\n\nrnn_type\n: currently support \"simplernn | lstm | gru\"\n\n\nnlayers\n: number of layers\n\n\nhidden_size\n: hidden size\n\n\nbridge_type\n: currently only support \"dense | densenonlinear\"\n\n\ninput_shape\n: shape of encoder input\n\n\noutput_shape\n: shape of decoder input\n\n\n\n\n\n\nTrain a Seq2seq model\n\n\nAfter building the model, we can use BigDL Optimizer to train it (with validation) using RDD of \nSample\n.\n\nfeature\n is expected to be a sequence(eg. batch x seqLen x feature) and \nlabel\n is also a sequence(eg. batch x seqLen x feature).\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ZooClassNLLCriterion}\n\nval optimizer = Optimizer(\nmodel,\ntrainSet,\nTimeDistributedMaskCriterion(\n  ZooClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n),\nbatchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()\n\n\n\n\nAlso we can use \nSeq2seq.fit\n api to train the model.\n\n\nmodel.compile(\noptimizer = optimMethod,\nloss = TimeDistributedMaskCriterion(\n  ZooClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n))\n\nmodel.fit(\n  trainSet, batchSize = param.batchSize,\n  nbEpoch = 20)\n\n\n\n\nPython\n\n\nfrom bigdl.optim.optimizer import *\n\noptimizer = Optimizer(\n    model=seq2seq,\n    training_rdd=train_rdd,\n    criterion=TimeDistributedMaskCriterion(ZooClassNLLCriterion()),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    trigger=EveryEpoch())\n\n\n\n\nAlso we can use \nSeq2seq.fit\n api to train the model.\n\n\nmodel.compile(optimizer, loss, metrics)\n\nmodel.fit(x, batch_size=32, nb_epoch=10, validation_data=None)\n\n\n\n\n\n\nDo prediction\n\n\nPredict output with given input\n\nScala\n\n\nval result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput)\n\n\n\n\n\n\ninput\n: a sequence of data feed into encoder, eg: batch x seqLen x featureSize\n\n\nstartSign\n: a tensor which represents start and is fed into decoder\n\n\nmaxSeqLen\n: max sequence length for final output\n\n\nstopSign\n: a tensor that indicates model should stop infer further if current output is the same with stopSign\n\n\nbuildOutput\n: Feeding model output to buildOutput to generate final result\n\n\n\n\nPython\n\n\nresult = model.infer(input, start_sign, max_seq_len, stop_sign, build_output)\n\n\n\n\n\n\ninput\n: a sequence of data feed into encoder, eg: batch x seqLen x featureSize\n\n\nstart_sign\n: a ndarray which represents start and is fed into decoder\n\n\nmax_seq_len\n: max sequence length for final output\n\n\nstop_sign\n: a ndarray that indicates model should stop infer further if current output is the same with stopSign\n\n\nbuild_output\n: Feeding model output to buildOutput to generate final result\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction.\n\n\nSee \nhere\n for the Scala example.",
            "title": "Sequence to Sequence API"
        },
        {
            "location": "/ProgrammingGuide/seq2seq/#build-a-seq2seq-model",
            "text": "You can call the following API in Scala and Python respectively to create a  Seq2seq .  Scala  val encoder = RNNEncoder[Float](rnnType=\"lstm\", numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval decoder = RNNDecoder[Float](rnnType=\"lstm\", numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval bridge = Bridge[Float](bridgeType=\"dense\", decoderHiddenSize=3)\nval model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge)   rnnType : currently support \"simplernn | lstm | gru\"  numLayer : number of layers  hiddenSize : hidden size  embedding : embedding layer  bridgeType : currently only support \"dense | densenonlinear\"  input_shape : shape of encoder input  output_shape : shape of decoder input   Python  encoder = RNNEncoder.initialize(rnn_tpye=\"LSTM\", nlayers=1, hidden_size=4)\ndecoder = RNNDecoder.initialize(rnn_tpye=\"LSTM\", nlayers=1, hidden_size=4)\nbridge = Bridge.initialize(bridge_type=\"dense\", decoder_hidden_size=4)\nseq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge)   rnn_type : currently support \"simplernn | lstm | gru\"  nlayers : number of layers  hidden_size : hidden size  bridge_type : currently only support \"dense | densenonlinear\"  input_shape : shape of encoder input  output_shape : shape of decoder input",
            "title": "Build a Seq2seq model"
        },
        {
            "location": "/ProgrammingGuide/seq2seq/#train-a-seq2seq-model",
            "text": "After building the model, we can use BigDL Optimizer to train it (with validation) using RDD of  Sample . feature  is expected to be a sequence(eg. batch x seqLen x feature) and  label  is also a sequence(eg. batch x seqLen x feature).  Scala  import com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ZooClassNLLCriterion}\n\nval optimizer = Optimizer(\nmodel,\ntrainSet,\nTimeDistributedMaskCriterion(\n  ZooClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n),\nbatchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()  Also we can use  Seq2seq.fit  api to train the model.  model.compile(\noptimizer = optimMethod,\nloss = TimeDistributedMaskCriterion(\n  ZooClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n))\n\nmodel.fit(\n  trainSet, batchSize = param.batchSize,\n  nbEpoch = 20)  Python  from bigdl.optim.optimizer import *\n\noptimizer = Optimizer(\n    model=seq2seq,\n    training_rdd=train_rdd,\n    criterion=TimeDistributedMaskCriterion(ZooClassNLLCriterion()),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    trigger=EveryEpoch())  Also we can use  Seq2seq.fit  api to train the model.  model.compile(optimizer, loss, metrics)\n\nmodel.fit(x, batch_size=32, nb_epoch=10, validation_data=None)",
            "title": "Train a Seq2seq model"
        },
        {
            "location": "/ProgrammingGuide/seq2seq/#do-prediction",
            "text": "Predict output with given input Scala  val result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput)   input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize  startSign : a tensor which represents start and is fed into decoder  maxSeqLen : max sequence length for final output  stopSign : a tensor that indicates model should stop infer further if current output is the same with stopSign  buildOutput : Feeding model output to buildOutput to generate final result   Python  result = model.infer(input, start_sign, max_seq_len, stop_sign, build_output)   input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize  start_sign : a ndarray which represents start and is fed into decoder  max_seq_len : max sequence length for final output  stop_sign : a ndarray that indicates model should stop infer further if current output is the same with stopSign  build_output : Feeding model output to buildOutput to generate final result",
            "title": "Do prediction"
        },
        {
            "location": "/ProgrammingGuide/seq2seq/#examples",
            "text": "We provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction.  See  here  for the Scala example.",
            "title": "Examples"
        },
        {
            "location": "/ProgrammingGuide/visualization/",
            "text": "Generating Summary\n\n\nTo enable visualization support, you need first properly configure to collect statistics summary in different stages of training. It should be done before the training starts. See examples below: \n\n\nGenerating summary in NNEstimator\n\n\nscala\n\n\nval estimator = NNEstimator(...)\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\nestimator.setTrainSummary(trainSummary)\nestimator.setValidationSummary(validationSummary)\n...\nval nnModel = estimator.fit(...)\n\n\n\n\npython\n\n\nfrom bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nestimator = NNEstimator(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\nestimator.set_train_summary(train_summary)\nestimator.set_val_summary(val_summary)\n...\nnnModel = estimator.fit(...)\n\n\n\n\nGenerating summary in Keras API\n\n\nscala\n\n\nval model = [...new keras model]\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nmodel.setTensorBoard(logdir, appName)\n...\nmodel.fit(...)\n\n\n\n\npython\n\n\nmodel = [...new keras model]\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\nmodel.set_tensorboard(log_dir, app_name)\n...\nmodel.fit(...)\n\n\n\n\nGenerating summary in KerasModel\n\n\npython\n\n\nimport tensorflow as tf\nfrom zoo.tfpark import KerasModel\nfrom bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nmodel = [...new keras model]\nmodel = KerasModel(model, model_dir=\"mylogdir\")\n...\nmodel.fit(...)\n\n\n\n\nGenerating summary in TFEstimator\n\n\npython\n\n\nfrom zoo.tfpark.estimator import TFEstimator\n\nestimator = TFEstimator.from_model_fn(..., model_dir=\"mylogdir\")\n...\nestimator.train(...)\n\n\n\n\nNotice\n:  \n\n\nIf logdir is relative path, like \nlogdir/inpcetion_log\n, the log will be stored in your local file system;  \n\n\nIf logdir is absolute path started with \n/\n, like \n/user/logdir/inpcetion_log\n, the log will be stored in your local file system;  \n\n\nIf logdir is URI started with \nhdfs://[host:port]/\n, like \nhdfs://172.168.0.101:8020/user/logdir/inpcetion_log\n, the log will be stored to HDFS;  \n\n\n\n\nVisualizing training with TensorBoard\n\n\nWith the summary info generated, we can then use \nTensorBoard\n to visualize the behaviors of the training program.  \n\n\nInstalling TensorBoard\n\n\nPrerequisites:\n\n\n\n\nPython version: 3.6 or 3.7\n\n\nPip version >= 9.0.1\n\n\nTensorFlow 1.13.1\n\n\n\n\nLaunching TensorBoard\n\n\nLoading from local directory\n\n\nYou can launch TensorBoard using the command below:\n\n\ntensorboard --logdir=[logdir path]\n\n\n\n\nAfter that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006\n\n\nLoading from HDFS\n\n\nIf the logdir is a HDFS folder, you need to configure the HDFS environment before running \ntensorboard\n.\n\nPrerequisites:\n1. JDK >= 1.8, Orcale JDK recommended \n2. Hadoop >= 2.7\n\n\nSet env before running \ntensorboard\n:\n\n\nexport JAVA_HOME=[your java home path]\nexport HADOOP_HOME=[your hadoop home path]\nsource ${HADOOP_HOME}/libexec/hadoop-config.sh\nexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${JAVA_HOME}/jre/lib/amd64/server\n\n\n\n\nIf the Hadoop cluster is in secure mode, also set the environment variable \nKRB5CCNAME\n:\n\n\nexport KRB5CCNAME={Path of Kerberos ticket cache file}\n\n\n\n\nRun tensorboard, for example:\n\n\nCLASSPATH=$(${HADOOP_HOME}/bin/hadoop classpath --glob) tensorboard --logdir=hdfs://[ip:port]/[hdfs path]\n\n\n\n\nVisualizations in TensorBoard\n\n\nWithin the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):\n\n\n\nAnd \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):\n\n\n\n\nAs getting DISTRIBUTIONS and HISTOGRAMS may affect the training performance, so we don't enable this option by default. For example you want to fetch this parameters every 20 iteartions, you should call \ntrainSummary.setSummaryTrigger(\"Parameters\", Trigger.severalIteration(20))\n(\nset_summary_trigger\n in python API) before calling \nsetTrainSummary\n.\n\n\n\n\nRetrieving summary from build-in API\n\n\nYou can use provided API to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.\n\n\nPlease note this approach does not work for KerasModel and TFEstimator.\n\n\n\n\nExample: Reading summary info in NNestimator\n \n\n\n\n\nscala\n\n\nval estimator = NNEstimator(...)\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\nestimator.setTrainSummary(trainSummary)\nestimator.setValidationSummary(validationSummary)\n...\nval nnModel = estimator.fit(...)\nval trainLoss = trainSummary.readScalar(\"Loss\")\nval valLoss = validationSummary.readScalar(\"Loss\")\n\n\n\n\npython\n\n\nfrom bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nestimator = NNEstimator(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\nestimator.set_train_summary(train_summary)\nestimator.set_val_summary(val_summary)\n...\ntrain_loss = np.array(train_summary.read_scalar('Loss'))\nval_loss = np.array(val_summary.read_scalar('Loss'))\n\n\n\n\n\n\nExample: Reading summary info in keras API\n\n\n\n\nscala\n\n\nval trainLoss = model.getTrainSummary(\"loss\")\nval valLoss = model.getValidationSummary(\"loss\")\n\n\n\n\npython\n\n\ntrain_loss = model.get_train_summary('loss')\nval_loss = model.get_validation_summary('loss')\n\n\n\n\nIf your training job has finished and existed, but a new program wants retrieving summary with \nreadScalar\n(\nread_scalar\n in python) API. \nYou can re-create the TrainingSummary and ValidationSummary with the same \nlogDir\n and \nappName\n in your new job. \n\n\n\n\nVisualizing training with Jupyter notebook\n\n\nIf you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline. \n\n\nFirst, retrieve the summaries as instructed in \nRetrieve Summary\n. The retrieved summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:  \n\n\nPlease note this approach does not work for KerasModel and TFEstimator.\n\n\n\n\nExample: Plot the train/validation loss in Jupyter\n\n\n\n\n#retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar(\"Loss\"))\nval_loss  = np.array(val_summary.read_scalar(\"Loss\"))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();",
            "title": "Visualization"
        },
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary",
            "text": "To enable visualization support, you need first properly configure to collect statistics summary in different stages of training. It should be done before the training starts. See examples below:",
            "title": "Generating Summary"
        },
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-in-nnestimator",
            "text": "scala  val estimator = NNEstimator(...)\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\nestimator.setTrainSummary(trainSummary)\nestimator.setValidationSummary(validationSummary)\n...\nval nnModel = estimator.fit(...)  python  from bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nestimator = NNEstimator(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\nestimator.set_train_summary(train_summary)\nestimator.set_val_summary(val_summary)\n...\nnnModel = estimator.fit(...)",
            "title": "Generating summary in NNEstimator"
        },
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-in-keras-api",
            "text": "scala  val model = [...new keras model]\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nmodel.setTensorBoard(logdir, appName)\n...\nmodel.fit(...)  python  model = [...new keras model]\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\nmodel.set_tensorboard(log_dir, app_name)\n...\nmodel.fit(...)",
            "title": "Generating summary in Keras API"
        },
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-in-kerasmodel",
            "text": "python  import tensorflow as tf\nfrom zoo.tfpark import KerasModel\nfrom bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nmodel = [...new keras model]\nmodel = KerasModel(model, model_dir=\"mylogdir\")\n...\nmodel.fit(...)",
            "title": "Generating summary in KerasModel"
        },
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-in-tfestimator",
            "text": "python  from zoo.tfpark.estimator import TFEstimator\n\nestimator = TFEstimator.from_model_fn(..., model_dir=\"mylogdir\")\n...\nestimator.train(...)  Notice :    If logdir is relative path, like  logdir/inpcetion_log , the log will be stored in your local file system;    If logdir is absolute path started with  / , like  /user/logdir/inpcetion_log , the log will be stored in your local file system;    If logdir is URI started with  hdfs://[host:port]/ , like  hdfs://172.168.0.101:8020/user/logdir/inpcetion_log , the log will be stored to HDFS;",
            "title": "Generating summary in TFEstimator"
        },
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-tensorboard",
            "text": "With the summary info generated, we can then use  TensorBoard  to visualize the behaviors of the training program.",
            "title": "Visualizing training with TensorBoard"
        },
        {
            "location": "/ProgrammingGuide/visualization/#installing-tensorboard",
            "text": "Prerequisites:   Python version: 3.6 or 3.7  Pip version >= 9.0.1  TensorFlow 1.13.1",
            "title": "Installing TensorBoard"
        },
        {
            "location": "/ProgrammingGuide/visualization/#launching-tensorboard",
            "text": "",
            "title": "Launching TensorBoard"
        },
        {
            "location": "/ProgrammingGuide/visualization/#loading-from-local-directory",
            "text": "You can launch TensorBoard using the command below:  tensorboard --logdir=[logdir path]  After that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006",
            "title": "Loading from local directory"
        },
        {
            "location": "/ProgrammingGuide/visualization/#loading-from-hdfs",
            "text": "If the logdir is a HDFS folder, you need to configure the HDFS environment before running  tensorboard . \nPrerequisites:\n1. JDK >= 1.8, Orcale JDK recommended \n2. Hadoop >= 2.7  Set env before running  tensorboard :  export JAVA_HOME=[your java home path]\nexport HADOOP_HOME=[your hadoop home path]\nsource ${HADOOP_HOME}/libexec/hadoop-config.sh\nexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${JAVA_HOME}/jre/lib/amd64/server  If the Hadoop cluster is in secure mode, also set the environment variable  KRB5CCNAME :  export KRB5CCNAME={Path of Kerberos ticket cache file}  Run tensorboard, for example:  CLASSPATH=$(${HADOOP_HOME}/bin/hadoop classpath --glob) tensorboard --logdir=hdfs://[ip:port]/[hdfs path]",
            "title": "Loading from HDFS"
        },
        {
            "location": "/ProgrammingGuide/visualization/#visualizations-in-tensorboard",
            "text": "Within the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):  And \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):  \nAs getting DISTRIBUTIONS and HISTOGRAMS may affect the training performance, so we don't enable this option by default. For example you want to fetch this parameters every 20 iteartions, you should call  trainSummary.setSummaryTrigger(\"Parameters\", Trigger.severalIteration(20)) ( set_summary_trigger  in python API) before calling  setTrainSummary .",
            "title": "Visualizations in TensorBoard"
        },
        {
            "location": "/ProgrammingGuide/visualization/#retrieving-summary-from-build-in-api",
            "text": "You can use provided API to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.  Please note this approach does not work for KerasModel and TFEstimator.   Example: Reading summary info in NNestimator     scala  val estimator = NNEstimator(...)\n...\nval logdir = \"mylogdir\"\nval appName = \"myapp\"\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\nestimator.setTrainSummary(trainSummary)\nestimator.setValidationSummary(validationSummary)\n...\nval nnModel = estimator.fit(...)\nval trainLoss = trainSummary.readScalar(\"Loss\")\nval valLoss = validationSummary.readScalar(\"Loss\")  python  from bigdl.optim.optimizer import TrainSummary, ValidationSummary\n\nestimator = NNEstimator(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\nestimator.set_train_summary(train_summary)\nestimator.set_val_summary(val_summary)\n...\ntrain_loss = np.array(train_summary.read_scalar('Loss'))\nval_loss = np.array(val_summary.read_scalar('Loss'))   Example: Reading summary info in keras API   scala  val trainLoss = model.getTrainSummary(\"loss\")\nval valLoss = model.getValidationSummary(\"loss\")  python  train_loss = model.get_train_summary('loss')\nval_loss = model.get_validation_summary('loss')  If your training job has finished and existed, but a new program wants retrieving summary with  readScalar ( read_scalar  in python) API. \nYou can re-create the TrainingSummary and ValidationSummary with the same  logDir  and  appName  in your new job.",
            "title": "Retrieving summary from build-in API"
        },
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-jupyter-notebook",
            "text": "If you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline.   First, retrieve the summaries as instructed in  Retrieve Summary . The retrieved summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:    Please note this approach does not work for KerasModel and TFEstimator.   Example: Plot the train/validation loss in Jupyter   #retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar(\"Loss\"))\nval_loss  = np.array(val_summary.read_scalar(\"Loss\"))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();",
            "title": "Visualizing training with Jupyter notebook"
        },
        {
            "location": "/ProgrammingGuide/usercases-overview/",
            "text": "Analytics Zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in \nanalytics-zoo/apps\n.\n\n\n\n\n\n\nAnomaly Detection\n demostrates using LSTM network to detect anomalies in time series data.\n\n\n\n\n\n\nFraud Detection\n demostrates using feed-forward neural network to detect frauds in credit card transactions data. \n\n\n\n\n\n\nImage Augmentation\n demostrates how to do image augmentation for vision projects. \n\n\n\n\n\n\nObject Detection\n demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos. \n\n\n\n\n\n\nRecommendation demonstrates how to use Analytics Zoo Recommendation APIs (i.e. \nNeural Collaborative Filtering\n, \nWide and Deep\n) to do recommendation on data with explicit feedback. \n\n\n\n\n\n\nSentiment Analysis\n demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU, Bi-LSTM).  \n\n\n\n\n\n\nVariational AutoEncoder\n demostrates how to use variational autoencoder to generate faces and digital numbers.",
            "title": "Reference Use Cases"
        },
        {
            "location": "/ProgrammingGuide/run-on-dataproc/",
            "text": "Deploy Analytics Zoo with BigDL on Dataproc\n\n\nBefore using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc \n(you may refer to \nhttps://cloud.google.com/sdk/docs/how-to\n \nfor more instructions). \nNow you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/) \n\ngcloud\n command-line tool.\n\n\nNote:\n The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]).\n So at the time of writing you should download and place the updated version of this script somewhere accessible for you \n (into your own Google Storage bucket, for example) and set appropriate location for \n--initialization-actions\n.\n\n\nYou can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed \nin it.\n\n\nBy default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8).\nSo you must specify to download Analytics Zoo instead (which includes BigDL) with: \nbigdl-download-url\n \nproperty in metadata:\n\n\ngcloud dataproc clusters create <CLUSTER_NAME> \\\n    --image-version 1.3 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip'\n\n\n\n\nTo download a different version of Zoo or one targeted to a different version of Spark/Scala, \nfind the download URL from the \nAnalytics Zoo releases page\n \nor \nmaven repository\n, \nand set the metadata key \"bigdl-download-url\" \n.\n\n\nMore information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl\n\n\nOnce the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.\n\n\nCloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,\n\n\ngcloud compute --project <PROJECT_ID> ssh --zone <ZONE> <CLUSTER_NAME>\n\n\n\n\nGoogle cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).\n\n\nYou should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. \nNow you can run jobs with Zoo and BigDL on Google Dataproc \nas usual with \ngcloud dataproc jobs submit spark\n.",
            "title": "Run on Google Cloud Dataproc"
        },
        {
            "location": "/ProgrammingGuide/run-on-dataproc/#deploy-analytics-zoo-with-bigdl-on-dataproc",
            "text": "Before using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc \n(you may refer to  https://cloud.google.com/sdk/docs/how-to  \nfor more instructions). \nNow you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/)  gcloud  command-line tool.  Note:\n The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]).\n So at the time of writing you should download and place the updated version of this script somewhere accessible for you \n (into your own Google Storage bucket, for example) and set appropriate location for  --initialization-actions .  You can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed \nin it.  By default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8).\nSo you must specify to download Analytics Zoo instead (which includes BigDL) with:  bigdl-download-url  \nproperty in metadata:  gcloud dataproc clusters create <CLUSTER_NAME> \\\n    --image-version 1.3 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip'  To download a different version of Zoo or one targeted to a different version of Spark/Scala, \nfind the download URL from the  Analytics Zoo releases page  \nor  maven repository , \nand set the metadata key \"bigdl-download-url\" \n.  More information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl  Once the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.  Cloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,  gcloud compute --project <PROJECT_ID> ssh --zone <ZONE> <CLUSTER_NAME>  Google cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).  You should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. \nNow you can run jobs with Zoo and BigDL on Google Dataproc \nas usual with  gcloud dataproc jobs submit spark .",
            "title": "Deploy Analytics Zoo with BigDL on Dataproc"
        },
        {
            "location": "/ProgrammingGuide/run-notebook-colab/",
            "text": "With \nGoogle Colaboratory\n, we can easily set up and run code in the cloud. This page illustrates the steps to install Analytics Zoo and run notebooks on colaboratory.\n\n\nFirst, create or load a notebook file in colaboratory. Then, prepare the environment. You only need to install JDK and Analytics Zoo. As installing analytics-zoo from pip will automatically install pyspark, you are recommended not to install pyspark by yourself.\n\n\nPrepare Environment\n\n\nInstall Java 8\n\n\nRun the command on the colaboratory file to install jdk 1.8:\n\n\n# Install jdk8\n!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n# Set jdk environment path which enables you to run Pyspark in your Colab environment.\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n\n\n\n\nInstall Analytics Zoo from pip\n\n\nYou can add the following command on your colab file to install the analytics-zoo via pip easily:\n\n\n# Install latest release version of analytics-zoo \n# Installing analytics-zoo from pip will automatically install pyspark, bigdl, and their dependencies.\n!pip install analytics-zoo\n\n\n\n\nBegin your code\n\n\nCall \ninit_nncontext()\n that will create a SparkContext with optimized performance configurations.\n\n\nfrom zoo.common.nncontext import*\n\nsc = init_nncontext()\n\n\n\n\nOutput on Colaboratory:\n\n\nPrepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\nAdding /usr/local/lib/python3.6/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.7.0-jar-with-dependencies.jar to BIGDL_JARS\nPrepending /usr/local/lib/python3.6/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n\n\n\n\nRun Github Notebook on colaboratory\n\n\nIf you would like to open Analytics Zoo Notebook in a GitHub repo directly, the only thing you need to do is:\n\n\n\n\n\n\nOpen the Notebook file on GitHub in a browser (So the URL ends in \n.ipynb\n).\n\n\n\n\n\n\nChange the URL from \nhttps://github.com/full_path_to_the_notebook\n to \nhttps://colab.research.google.com/github/full_path_to_the_notebook\n\n\n\n\n\n\nFor example, change the URL of Analytics Zoo tutorial \nhttps://github.com/intel-analytics/zoo-tutorials/blob/master/keras/2.1-a-first-look-at-a-neural-network.ipynb\n \n  to \nhttps://colab.research.google.com/github/intel-analytics/zoo-tutorials/blob/master/keras/2.1-a-first-look-at-a-neural-network.ipynb\n.\n\n\nThen, prepare the environment of Java8 and Analytics Zoo as described \nabove\n at the beginning of the colab notebook. If you would like to save the changes, you can make a copy to drive and run it within the instructions.\n\n\nNote\n\n\nAs Colab engine provides your application with some built-in Python libraries, you should check if the library versions are compatible with your application. You may refer this \ndocument\n to specify the python library version that Analytics Zoo supports.",
            "title": "Run on Google Colab"
        },
        {
            "location": "/ProgrammingGuide/run-notebook-colab/#prepare-environment",
            "text": "Install Java 8  Run the command on the colaboratory file to install jdk 1.8:  # Install jdk8\n!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n# Set jdk environment path which enables you to run Pyspark in your Colab environment.\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java  Install Analytics Zoo from pip  You can add the following command on your colab file to install the analytics-zoo via pip easily:  # Install latest release version of analytics-zoo \n# Installing analytics-zoo from pip will automatically install pyspark, bigdl, and their dependencies.\n!pip install analytics-zoo  Begin your code  Call  init_nncontext()  that will create a SparkContext with optimized performance configurations.  from zoo.common.nncontext import*\n\nsc = init_nncontext()  Output on Colaboratory:  Prepending /usr/local/lib/python3.6/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\nAdding /usr/local/lib/python3.6/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.7.0-jar-with-dependencies.jar to BIGDL_JARS\nPrepending /usr/local/lib/python3.6/dist-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path",
            "title": "Prepare Environment"
        },
        {
            "location": "/ProgrammingGuide/run-notebook-colab/#run-github-notebook-on-colaboratory",
            "text": "If you would like to open Analytics Zoo Notebook in a GitHub repo directly, the only thing you need to do is:    Open the Notebook file on GitHub in a browser (So the URL ends in  .ipynb ).    Change the URL from  https://github.com/full_path_to_the_notebook  to  https://colab.research.google.com/github/full_path_to_the_notebook    For example, change the URL of Analytics Zoo tutorial  https://github.com/intel-analytics/zoo-tutorials/blob/master/keras/2.1-a-first-look-at-a-neural-network.ipynb  \n  to  https://colab.research.google.com/github/intel-analytics/zoo-tutorials/blob/master/keras/2.1-a-first-look-at-a-neural-network.ipynb .  Then, prepare the environment of Java8 and Analytics Zoo as described  above  at the beginning of the colab notebook. If you would like to save the changes, you can make a copy to drive and run it within the instructions.  Note  As Colab engine provides your application with some built-in Python libraries, you should check if the library versions are compatible with your application. You may refer this  document  to specify the python library version that Analytics Zoo supports.",
            "title": "Run Github Notebook on colaboratory"
        },
        {
            "location": "/ProgrammingGuide/AnalyticsZoo-on-Databricks/",
            "text": "Databricks\n is a fast Apache Spark based big data analysis platform. Analytics Zoo program can run easily on Databricks spark cluster for distributed training or inference. This guide will introduce how to prepare Analytics Zoo environment as well as starting an Analytics Zoo notebook on Databricks.\n\n\n\n\nPrerequisites\n\n\nInstalling Analytics Zoo libraries\n\n\nSetting Spark configuration\n\n\nRunning Analytics Zoo notebook on Databricks\n\n\n\n\nPrerequisites\n\n\nBefore you start this guide, make sure a Databricks workspace is ready and a cluster is created using the Databricks UI.\n\n\n\n\nCreate either \nAWS Databricks\n  workspace or \nAzure Databricks\n workspace.\n\n\nCreate Databricks \nclusters\n using the UI. Choose Databricks runtime version. This guide is tested on Runtime 5.5 LTS (includes Apache Spark 2.4.3, Scala 2.11).\n\n\n\n\nInstalling Analytics Zoo libraries\n\n\n1.In the left pane, click \nClusters\n and select your cluster. \n\n\n \n\n\n2.Install Analytics Zoo python environment using PyPI. Click \nLibraries > Install New > PyPI\n. Text \"analytics-zoo\" library.\n\n\n \n\n\n3.Install Analytics Zoo prebuilt jar package. Click \nLibraries > Install New > Upload > Jar\n. Download Analytics Zoo prebuilt release package from the \nRelease Page\n. Please note that you should choose the same spark version of package as your Databricks runtime version. Unzip it. Find jar named \"analytics-zoo-bigdl_\n-spark_\n-jar-with-dependencies.jar\" in the lib directory. Drop the jar on Databricks.\n\n\n \n\n\n4.Make sure the jar file and analytics-zoo (with PyPI) are installed on all clusters. In \nLibraries\n tab of your cluster, check installed libraries and click \u201cInstall automatically on all clusters\u201d option in \nAdmin Settings\n.\n\n\n\n\nSetting Spark configuration\n\n\nOn the cluster configuration page, click the \nAdvanced Options\n toggle. Click the \nSpark\n tab. You can provide custom \nSpark configuration properties\n in a cluster configuration. Please set it according to your cluster resource and program needs.  \n\n\n\n\nSee below for an example of Spark config setting needed by Analytics Zoo. Here it sets 1 core and 6g memory per executor and driver. Note that \"spark.cores.max\" needs to be properly set below.\n\n\nspark.shuffle.reduceLocality.enabled false\nspark.serializer org.apache.spark.serializer.JavaSerializer\nspark.shuffle.blockTransferService nio\nspark.databricks.delta.preview.enabled true\nspark.executor.cores 1\nspark.executor.memory 6g\nspark.speculation false\nspark.driver.memory 6g\nspark.scheduler.minRegisteredResourcesRatio 1.0\nspark.cores.max 4\nspark.driver.cores 1\n\n\n\n\nRunning Analytics Zoo notebook on Databricks\n\n\nOpen a new notebook. First call \ninit_nncontext()\n at the beginning of your code. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine. \n\n\nfrom zoo.common.nncontext import*\nsc = init_nncontext()\n\n\n\n\nOutput on Databricks:\n\n\nPrepending /databricks/python/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\nAdding /databricks/python/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.9.1-spark_2.4.3-0.6.0-jar-with-dependencies.jar to BIGDL_JARS\nPrepending /databricks/python/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n\n\n\n\nIf you would like to run a completed Analytics Zoo notebook, you can import an Analytics Zoo notebook from a URL directly. Click \nworkspace > Import\n.\n\n\n\n\nFor example, you may import a simple \nAnalytics Zoo tutorials notebook\n.\n\n\n\n\nNote the above notebook runs on Spark local default; to make it run on Databricks cluster, please change the first Python cell in the notebook to:\n\n\nfrom zoo.common.nncontext import*\nsc = init_nncontext()",
            "title": "Run on Databricks"
        },
        {
            "location": "/ProgrammingGuide/AnalyticsZoo-on-Databricks/#prerequisites",
            "text": "Before you start this guide, make sure a Databricks workspace is ready and a cluster is created using the Databricks UI.   Create either  AWS Databricks   workspace or  Azure Databricks  workspace.  Create Databricks  clusters  using the UI. Choose Databricks runtime version. This guide is tested on Runtime 5.5 LTS (includes Apache Spark 2.4.3, Scala 2.11).",
            "title": "Prerequisites"
        },
        {
            "location": "/ProgrammingGuide/AnalyticsZoo-on-Databricks/#installing-analytics-zoo-libraries",
            "text": "1.In the left pane, click  Clusters  and select your cluster.      2.Install Analytics Zoo python environment using PyPI. Click  Libraries > Install New > PyPI . Text \"analytics-zoo\" library.     3.Install Analytics Zoo prebuilt jar package. Click  Libraries > Install New > Upload > Jar . Download Analytics Zoo prebuilt release package from the  Release Page . Please note that you should choose the same spark version of package as your Databricks runtime version. Unzip it. Find jar named \"analytics-zoo-bigdl_ -spark_ -jar-with-dependencies.jar\" in the lib directory. Drop the jar on Databricks.     4.Make sure the jar file and analytics-zoo (with PyPI) are installed on all clusters. In  Libraries  tab of your cluster, check installed libraries and click \u201cInstall automatically on all clusters\u201d option in  Admin Settings .",
            "title": "Installing Analytics Zoo libraries"
        },
        {
            "location": "/ProgrammingGuide/AnalyticsZoo-on-Databricks/#setting-spark-configuration",
            "text": "On the cluster configuration page, click the  Advanced Options  toggle. Click the  Spark  tab. You can provide custom  Spark configuration properties  in a cluster configuration. Please set it according to your cluster resource and program needs.     See below for an example of Spark config setting needed by Analytics Zoo. Here it sets 1 core and 6g memory per executor and driver. Note that \"spark.cores.max\" needs to be properly set below.  spark.shuffle.reduceLocality.enabled false\nspark.serializer org.apache.spark.serializer.JavaSerializer\nspark.shuffle.blockTransferService nio\nspark.databricks.delta.preview.enabled true\nspark.executor.cores 1\nspark.executor.memory 6g\nspark.speculation false\nspark.driver.memory 6g\nspark.scheduler.minRegisteredResourcesRatio 1.0\nspark.cores.max 4\nspark.driver.cores 1",
            "title": "Setting Spark configuration"
        },
        {
            "location": "/ProgrammingGuide/AnalyticsZoo-on-Databricks/#running-analytics-zoo-notebook-on-databricks",
            "text": "Open a new notebook. First call  init_nncontext()  at the beginning of your code. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.   from zoo.common.nncontext import*\nsc = init_nncontext()  Output on Databricks:  Prepending /databricks/python/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\nAdding /databricks/python/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.9.1-spark_2.4.3-0.6.0-jar-with-dependencies.jar to BIGDL_JARS\nPrepending /databricks/python/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path  If you would like to run a completed Analytics Zoo notebook, you can import an Analytics Zoo notebook from a URL directly. Click  workspace > Import .   For example, you may import a simple  Analytics Zoo tutorials notebook .   Note the above notebook runs on Spark local default; to make it run on Databricks cluster, please change the first Python cell in the notebook to:  from zoo.common.nncontext import*\nsc = init_nncontext()",
            "title": "Running Analytics Zoo notebook on Databricks"
        },
        {
            "location": "/ProgrammingGuide/k8s/",
            "text": "Analytics Zoo hyperzoo image has been built to easily run applications on Kubernetes cluster. The details of pre-installed packages and usage of the image will be introduced in this page.\n\n\n\n\nLaunch pre-built hyperzoo image\n\n\nRun Analytics Zoo examples on k8s\n\n\nRun Analytics Zoo Jupyter Notebooks on remote Spark cluster or k8s\n\n\nLaunch Analytics Zoo cluster serving\n\n\n\n\nLaunch pre-built hyperzoo image\n\n\nPrerequisites\n\n\n\n\nRunnable docker environment has been set up.\n\n\nA running Kubernetes cluster is prepared. Also make sure the permission of  \nkubectl\n  to create, list and delete pod.\n\n\n\n\nLaunch pre-built hyperzoo k8s image\n\n\n\n\nPull an Analytics Zoo hyperzoo image from \ndockerhub\n:\n\n\n\n\nsudo docker pull intelanalytics/hyper-zoo:latest\n\n\n\n\n\n\nSpeed up pulling image by adding mirrors\n\n\n\n\nTo speed up pulling the image from dockerhub in China, add a registry's mirror. For Linux OS (CentOS, Ubuntu etc), if the docker version is higher than 1.12, config the docker daemon. Edit \n/etc/docker/daemon.json\n and add the registry-mirrors key and value:\n\n\n{\n  \"registry-mirrors\": [\"https://<my-docker-mirror-host>\"]\n}\n\n\n\n\nFor example, add the ustc mirror in China.\n\n\n{\n  \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]\n}\n\n\n\n\nFlush changes and restart docker\uff1a\n\n\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n\n\n\n\nIf your docker version is between 1.8 and 1.11, find the docker configuration which location depends on the operation system. Edit and add \nDOCKER_OPTS=\"--registry-mirror=https://<my-docker-mirror-host>\"\n. Restart docker \nsudo service docker restart\n.\n\n\nIf you would like to speed up pulling this image on MacOS or Windows, find the docker setting and config registry-mirrors section by specifying mirror host. Restart docker. \n\n\nThen pull the image. It will be faster.\n\n\nsudo docker pull intelanalytics/hyper-zoo:latest\n\n\n\n\n\n\nLaunch a k8s client container:\n\n\n\n\nPlease note the two different containers: \nclient container\n is for user to submit zoo jobs from here, since it contains all the required env and libs except hadoop/k8s configs; executor container is not need to create manually, which is scheduled by k8s at runtime.\n\n\nsudo docker run -itd --net=host \\\n    -v /etc/kubernetes:/etc/kubernetes \\\n    -v /root/.kube:/root/.kube \\\n    intelanalytics/hyper-zoo:latest bash\n\n\n\n\nNote. To launch the client container, \n-v /etc/kubernetes:/etc/kubernetes:\n and \n-v /root/.kube:/root/.kube\n are required to specify the path of kube config and installation.\n\n\nTo specify more argument, use:\n\n\nsudo docker run -itd --net=host \\\n    -v /etc/kubernetes:/etc/kubernetes \\\n    -v /root/.kube:/root/.kube \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    -e RUNTIME_SPARK_MASTER=k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> \\\n    -e RUNTIME_K8S_SERVICE_ACCOUNT=account \\\n    -e RUNTIME_K8S_SPARK_IMAGE=intelanalytics/hyper-zoo:latest \\\n    -e RUNTIME_PERSISTENT_VOLUME_CLAIM=myvolumeclaim \\\n    -e RUNTIME_DRIVER_HOST=x.x.x.x \\\n    -e RUNTIME_DRIVER_PORT=54321 \\\n    -e RUNTIME_EXECUTOR_INSTANCES=1 \\\n    -e RUNTIME_EXECUTOR_CORES=4 \\\n    -e RUNTIME_EXECUTOR_MEMORY=20g \\\n    -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\\n    -e RUNTIME_DRIVER_CORES=4 \\\n    -e RUNTIME_DRIVER_MEMORY=10g \\\n    intelanalytics/hyper-zoo:latest bash \n\n\n\n\n\n\nNotebookPort value 12345 is a user specified port number.\n\n\nNotebookToken value \"your-token\" is a user specified string.\n\n\nhttp_proxy is to specify http proxy.\n\n\nhttps_proxy is to specify https proxy.\n\n\nRUNTIME_SPARK_MASTER is to specify spark master, which should be \nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n or \nspark://<spark-master-host>:<spark-master-port>\n. \n\n\nRUNTIME_K8S_SERVICE_ACCOUNT is service account for driver pod. Please refer to k8s \nRBAC\n.\n\n\nRUNTIME_K8S_SPARK_IMAGE is the k8s image.\n\n\nRUNTIME_PERSISTENT_VOLUME_CLAIM is to specify volume mount. We are supposed to use volume mount to store or receive data. Get ready with \nKubernetes Volumes\n.\n\n\nRUNTIME_DRIVER_HOST is to specify driver localhost (only required when submit jobs as kubernetes client mode). \n\n\nRUNTIME_DRIVER_PORT is to specify port number (only required when submit jobs as kubernetes client mode).\n\n\nOther environment variables are for spark configuration setting. The default values in this image are listed above. Replace the values as you need.\n\n\n\n\nOnce the container is created, launch the container by:\n\n\nsudo docker exec -it <containerID> bash\n\n\n\n\nThen you may see it shows:\n\n\nroot@[hostname]:/opt/spark/work-dir# \n\n\n\n\n/opt/spark/work-dir\n is the spark work path. \n\n\nNote: The \n/opt\n directory contains:\n\n\n\n\ndownload-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.\n\n\nstart-notebook-spark.sh is used for starting the jupyter notebook on standard spark cluster. \n\n\nstart-notebook-k8s.sh is used for starting the jupyter notebook on k8s cluster.\n\n\nanalytics-zoo-x.x-SNAPSHOT is \nANALYTICS_ZOO_HOME\n, which is the home of Analytics Zoo distribution.\n\n\nanalytics-zoo-examples directory contains downloaded python example code.\n\n\njdk is the jdk home.\n\n\nspark is the spark home.\n\n\nredis is the redis home.\n\n\n\n\nRun Analytics Zoo examples on k8s\n\n\nLaunch an Analytics Zoo python example on k8s\n\n\nHere is a sample for submitting the python \nanomalydetection\n example on cluster mode.\n\n\n${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip,/opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  file:///opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --input_dir /zoo/data/nyc_taxi.csv\n\n\n\n\nOptions:\n\n\n\n\n--master: the spark mater, must be a URL with the format \nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n. \n\n\n--deploy-mode: submit application in cluster mode or client mode.\n\n\n--name: the Spark application name.\n\n\n--conf: require to specify k8s service account, container image to use for the Spark application, driver volumes name and path, label of pods, spark driver and executor configuration, etc.\n  check the argument settings in your environment and refer to the \nspark configuration page\n and \nspark on k8s configuration page\n for more details.\n\n\n--properties-file: the customized conf properties.\n\n\n--py-files: the extra python packages is needed.\n\n\nfile://: local file path of the python example file in the client container.\n\n\n--input_dir: input data path of the anomaly detection example. The data path is the mounted filesystem of the host. Refer to more details by \nKubernetes Volumes\n.\n\n\n\n\nLaunch an Analytics Zoo scala example on k8s\n\n\nHere is a sample for submitting the scala \nanomalydetection\n example on cluster mode\n\n\n${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --class com.intel.analytics.zoo.examples.anomalydetection.AnomalyDetection \\\n  ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip \\\n  --inputDir /zoo/data\n\n\n\n\nOptions:\n\n\n\n\n--master: the spark mater, must be a URL with the format \nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n. \n\n\n--deploy-mode: submit application in cluster mode or client mode.\n\n\n--name: the Spark application name.\n\n\n--conf: require to specify k8s service account, container image to use for the Spark application, driver volumes name and path, label of pods, spark driver and executor configuration, etc.\n  check the argument settings in your environment and refer to the \nspark configuration page\n and \nspark on k8s configuration page\n for more details.\n\n\n--properties-file: the customized conf properties.\n\n\n--py-files: the extra python packages is needed.\n\n\n--class: scala example class name.\n\n\n--input_dir: input data path of the anomaly detection example. The data path is the mounted filesystem of the host. Refer to more details by \nKubernetes Volumes\n.\n\n\n\n\nAccess logs to check result and clear pods\n\n\nWhen application is running, it\u2019s possible to stream logs on the driver pod:\n\n\n$ kubectl logs <spark-driver-pod>\n\n\n\n\nTo check pod status or to get some basic information around pod using:\n\n\n$ kubectl describe pod <spark-driver-pod>\n\n\n\n\nYou can also check other pods using the similar way.\n\n\nAfter finishing running the application, deleting the driver pod:\n\n\n$ kubectl delete <spark-driver-pod>\n\n\n\n\nOr clean up the entire spark application by pod label:\n\n\n$ kubectl delete pod -l <pod label>\n\n\n\n\nRun Analytics Zoo Jupyter Notebooks on remote Spark cluster or k8s\n\n\nWhen started a Docker container with specified argument RUNTIME_SPARK_MASTER=\nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n or RUNTIME_SPARK_MASTER=\nspark://<spark-master-host>:<spark-master-port>\n, the container will submit jobs to k8s cluster or spark cluster if you use $RUNTIME_SPARK_MASTER as url of spark master.\n\n\nYou may also need to specify NotebookPort=\n<your-port>\n and NotebookToken=\n<your-token>\n to start Jupyter Notebook on the specified port and bind to 0.0.0.0.\n\n\nTo start the Jupyter notebooks on remote spark cluster, please use RUNTIME_SPARK_MASTER=\nspark://<spark-master-host>:<spark-master-port>\n, and attach the client container with command: \u201cdocker exec -it \n<container-id>\n  bash\u201d, then run the shell script: \u201c/opt/start-notebook-spark.sh\u201d, this will start a Jupyter notebook instance on local container, and each tutorial in it will be submitted to the specified spark cluster. User can access the notebook with url \nhttp://<local-ip>:<your-port>\n in a preferred browser, and also need to input required  token with \n<your-token>\n to browse and run the tutorials of Analytics Zoo. Each tutorial will run driver part code in local container and run executor part code on spark cluster.\n\n\nTo start the Jupyter notebooks on Kubernetes cluster, please use RUNTIME_SPARK_MASTER=\nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n, and attach the client container with command: \u201cdocker exec -it \n<container-id>\n  bash\u201d, then run the shell script: \u201c/opt/start-notebook-k8s.sh\u201d, this will start a Jupyter notebook instance on local container, and each tutorial in it will be submitted to the specified kubernetes cluster. User can access the notebook with url \nhttp://<local-ip>:<your-port>\n in a preferred browser, and also need to input required  token with \n<your-token>\n to browse and run the tutorials of Analytics Zoo. Each tutorial will run driver part code in local container and run executor part code in dynamic allocated spark executor pods on k8s cluster. \n\n\nLaunch Analytics Zoo cluster serving\n\n\nTo run Analytics Zoo cluster serving in hyper-zoo client container and submit the streaming job on K8S cluster, you may need to specify arguments RUNTIME_SPARK_MASTER=\nk8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>\n, and you may also need to mount volume from host to container to load model and data files.\n\n\nYou can leverage an existing Redis instance/cluster, or you can start one in the client container:\n\n\n${REDIS_HOME}/src/redis-server ${REDIS_HOME}/redis.conf > ${REDIS_HOME}/redis.log &\n\n\n\n\nAnd you can check the running logs of redis:\n\n\ncat ${REDIS_HOME}/redis.log\n\n\n\n\nBefore starting the cluster serving job, please also modify the config.yaml to configure correct path of the model and redis host url, etc.\n\n\nnano /opt/cluster-serving/config.yaml\n\n\n\n\nAfter that, you can start the cluster-serving job and submit the streaming job on K8S cluster:\n\n\n${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip,/opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar:/opt/cluster-serving/spark-redis-2.4.0-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar:/opt/cluster-serving/spark-redis-2.4.0-jar-with-dependencies.jar \\\n  --conf \"spark.executor.extraJavaOptions=-Dbigdl.engineType=mklblas\" \\\n  --conf \"spark.driver.extraJavaOptions=-Dbigdl.engineType=mklblas\" \\\n  --class com.intel.analytics.zoo.serving.ClusterServing \\\n  local:/opt/analytics-zoo-0.8.0-SNAPSHOT/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.0-SNAPSHOT-jar-with-dependencies.jar",
            "title": "Run on Kubernetes cluster"
        },
        {
            "location": "/ProgrammingGuide/k8s/#launch-pre-built-hyperzoo-image",
            "text": "Prerequisites   Runnable docker environment has been set up.  A running Kubernetes cluster is prepared. Also make sure the permission of   kubectl   to create, list and delete pod.   Launch pre-built hyperzoo k8s image   Pull an Analytics Zoo hyperzoo image from  dockerhub :   sudo docker pull intelanalytics/hyper-zoo:latest   Speed up pulling image by adding mirrors   To speed up pulling the image from dockerhub in China, add a registry's mirror. For Linux OS (CentOS, Ubuntu etc), if the docker version is higher than 1.12, config the docker daemon. Edit  /etc/docker/daemon.json  and add the registry-mirrors key and value:  {\n  \"registry-mirrors\": [\"https://<my-docker-mirror-host>\"]\n}  For example, add the ustc mirror in China.  {\n  \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]\n}  Flush changes and restart docker\uff1a  sudo systemctl daemon-reload\nsudo systemctl restart docker  If your docker version is between 1.8 and 1.11, find the docker configuration which location depends on the operation system. Edit and add  DOCKER_OPTS=\"--registry-mirror=https://<my-docker-mirror-host>\" . Restart docker  sudo service docker restart .  If you would like to speed up pulling this image on MacOS or Windows, find the docker setting and config registry-mirrors section by specifying mirror host. Restart docker.   Then pull the image. It will be faster.  sudo docker pull intelanalytics/hyper-zoo:latest   Launch a k8s client container:   Please note the two different containers:  client container  is for user to submit zoo jobs from here, since it contains all the required env and libs except hadoop/k8s configs; executor container is not need to create manually, which is scheduled by k8s at runtime.  sudo docker run -itd --net=host \\\n    -v /etc/kubernetes:/etc/kubernetes \\\n    -v /root/.kube:/root/.kube \\\n    intelanalytics/hyper-zoo:latest bash  Note. To launch the client container,  -v /etc/kubernetes:/etc/kubernetes:  and  -v /root/.kube:/root/.kube  are required to specify the path of kube config and installation.  To specify more argument, use:  sudo docker run -itd --net=host \\\n    -v /etc/kubernetes:/etc/kubernetes \\\n    -v /root/.kube:/root/.kube \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\"your-token\" \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    -e RUNTIME_SPARK_MASTER=k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> \\\n    -e RUNTIME_K8S_SERVICE_ACCOUNT=account \\\n    -e RUNTIME_K8S_SPARK_IMAGE=intelanalytics/hyper-zoo:latest \\\n    -e RUNTIME_PERSISTENT_VOLUME_CLAIM=myvolumeclaim \\\n    -e RUNTIME_DRIVER_HOST=x.x.x.x \\\n    -e RUNTIME_DRIVER_PORT=54321 \\\n    -e RUNTIME_EXECUTOR_INSTANCES=1 \\\n    -e RUNTIME_EXECUTOR_CORES=4 \\\n    -e RUNTIME_EXECUTOR_MEMORY=20g \\\n    -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\\n    -e RUNTIME_DRIVER_CORES=4 \\\n    -e RUNTIME_DRIVER_MEMORY=10g \\\n    intelanalytics/hyper-zoo:latest bash    NotebookPort value 12345 is a user specified port number.  NotebookToken value \"your-token\" is a user specified string.  http_proxy is to specify http proxy.  https_proxy is to specify https proxy.  RUNTIME_SPARK_MASTER is to specify spark master, which should be  k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>  or  spark://<spark-master-host>:<spark-master-port> .   RUNTIME_K8S_SERVICE_ACCOUNT is service account for driver pod. Please refer to k8s  RBAC .  RUNTIME_K8S_SPARK_IMAGE is the k8s image.  RUNTIME_PERSISTENT_VOLUME_CLAIM is to specify volume mount. We are supposed to use volume mount to store or receive data. Get ready with  Kubernetes Volumes .  RUNTIME_DRIVER_HOST is to specify driver localhost (only required when submit jobs as kubernetes client mode).   RUNTIME_DRIVER_PORT is to specify port number (only required when submit jobs as kubernetes client mode).  Other environment variables are for spark configuration setting. The default values in this image are listed above. Replace the values as you need.   Once the container is created, launch the container by:  sudo docker exec -it <containerID> bash  Then you may see it shows:  root@[hostname]:/opt/spark/work-dir#   /opt/spark/work-dir  is the spark work path.   Note: The  /opt  directory contains:   download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.  start-notebook-spark.sh is used for starting the jupyter notebook on standard spark cluster.   start-notebook-k8s.sh is used for starting the jupyter notebook on k8s cluster.  analytics-zoo-x.x-SNAPSHOT is  ANALYTICS_ZOO_HOME , which is the home of Analytics Zoo distribution.  analytics-zoo-examples directory contains downloaded python example code.  jdk is the jdk home.  spark is the spark home.  redis is the redis home.",
            "title": "Launch pre-built hyperzoo image"
        },
        {
            "location": "/ProgrammingGuide/k8s/#run-analytics-zoo-examples-on-k8s",
            "text": "Launch an Analytics Zoo python example on k8s  Here is a sample for submitting the python  anomalydetection  example on cluster mode.  ${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip,/opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  file:///opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --input_dir /zoo/data/nyc_taxi.csv  Options:   --master: the spark mater, must be a URL with the format  k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> .   --deploy-mode: submit application in cluster mode or client mode.  --name: the Spark application name.  --conf: require to specify k8s service account, container image to use for the Spark application, driver volumes name and path, label of pods, spark driver and executor configuration, etc.\n  check the argument settings in your environment and refer to the  spark configuration page  and  spark on k8s configuration page  for more details.  --properties-file: the customized conf properties.  --py-files: the extra python packages is needed.  file://: local file path of the python example file in the client container.  --input_dir: input data path of the anomaly detection example. The data path is the mounted filesystem of the host. Refer to more details by  Kubernetes Volumes .   Launch an Analytics Zoo scala example on k8s  Here is a sample for submitting the scala  anomalydetection  example on cluster mode  ${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar \\\n  --class com.intel.analytics.zoo.examples.anomalydetection.AnomalyDetection \\\n  ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip \\\n  --inputDir /zoo/data  Options:   --master: the spark mater, must be a URL with the format  k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> .   --deploy-mode: submit application in cluster mode or client mode.  --name: the Spark application name.  --conf: require to specify k8s service account, container image to use for the Spark application, driver volumes name and path, label of pods, spark driver and executor configuration, etc.\n  check the argument settings in your environment and refer to the  spark configuration page  and  spark on k8s configuration page  for more details.  --properties-file: the customized conf properties.  --py-files: the extra python packages is needed.  --class: scala example class name.  --input_dir: input data path of the anomaly detection example. The data path is the mounted filesystem of the host. Refer to more details by  Kubernetes Volumes .   Access logs to check result and clear pods  When application is running, it\u2019s possible to stream logs on the driver pod:  $ kubectl logs <spark-driver-pod>  To check pod status or to get some basic information around pod using:  $ kubectl describe pod <spark-driver-pod>  You can also check other pods using the similar way.  After finishing running the application, deleting the driver pod:  $ kubectl delete <spark-driver-pod>  Or clean up the entire spark application by pod label:  $ kubectl delete pod -l <pod label>",
            "title": "Run Analytics Zoo examples on k8s"
        },
        {
            "location": "/ProgrammingGuide/k8s/#run-analytics-zoo-jupyter-notebooks-on-remote-spark-cluster-or-k8s",
            "text": "When started a Docker container with specified argument RUNTIME_SPARK_MASTER= k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port>  or RUNTIME_SPARK_MASTER= spark://<spark-master-host>:<spark-master-port> , the container will submit jobs to k8s cluster or spark cluster if you use $RUNTIME_SPARK_MASTER as url of spark master.  You may also need to specify NotebookPort= <your-port>  and NotebookToken= <your-token>  to start Jupyter Notebook on the specified port and bind to 0.0.0.0.  To start the Jupyter notebooks on remote spark cluster, please use RUNTIME_SPARK_MASTER= spark://<spark-master-host>:<spark-master-port> , and attach the client container with command: \u201cdocker exec -it  <container-id>   bash\u201d, then run the shell script: \u201c/opt/start-notebook-spark.sh\u201d, this will start a Jupyter notebook instance on local container, and each tutorial in it will be submitted to the specified spark cluster. User can access the notebook with url  http://<local-ip>:<your-port>  in a preferred browser, and also need to input required  token with  <your-token>  to browse and run the tutorials of Analytics Zoo. Each tutorial will run driver part code in local container and run executor part code on spark cluster.  To start the Jupyter notebooks on Kubernetes cluster, please use RUNTIME_SPARK_MASTER= k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> , and attach the client container with command: \u201cdocker exec -it  <container-id>   bash\u201d, then run the shell script: \u201c/opt/start-notebook-k8s.sh\u201d, this will start a Jupyter notebook instance on local container, and each tutorial in it will be submitted to the specified kubernetes cluster. User can access the notebook with url  http://<local-ip>:<your-port>  in a preferred browser, and also need to input required  token with  <your-token>  to browse and run the tutorials of Analytics Zoo. Each tutorial will run driver part code in local container and run executor part code in dynamic allocated spark executor pods on k8s cluster.",
            "title": "Run Analytics Zoo Jupyter Notebooks on remote Spark cluster or k8s"
        },
        {
            "location": "/ProgrammingGuide/k8s/#launch-analytics-zoo-cluster-serving",
            "text": "To run Analytics Zoo cluster serving in hyper-zoo client container and submit the streaming job on K8S cluster, you may need to specify arguments RUNTIME_SPARK_MASTER= k8s://https://<k8s-apiserver-host>:<k8s-apiserver-port> , and you may also need to mount volume from host to container to load model and data files.  You can leverage an existing Redis instance/cluster, or you can start one in the client container:  ${REDIS_HOME}/src/redis-server ${REDIS_HOME}/redis.conf > ${REDIS_HOME}/redis.log &  And you can check the running logs of redis:  cat ${REDIS_HOME}/redis.log  Before starting the cluster serving job, please also modify the config.yaml to configure correct path of the model and redis host url, etc.  nano /opt/cluster-serving/config.yaml  After that, you can start the cluster-serving job and submit the streaming job on K8S cluster:  ${SPARK_HOME}/bin/spark-submit \\\n  --master ${RUNTIME_SPARK_MASTER} \\\n  --deploy-mode cluster \\\n  --conf spark.kubernetes.authenticate.driver.serviceAccountName=${RUNTIME_K8S_SERVICE_ACCOUNT} \\\n  --name analytics-zoo \\\n  --conf spark.kubernetes.container.image=${RUNTIME_K8S_SPARK_IMAGE} \\\n  --conf spark.executor.instances=${RUNTIME_EXECUTOR_INSTANCES} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.options.claimName=${RUNTIME_PERSISTENT_VOLUME_CLAIM} \\\n  --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.${RUNTIME_PERSISTENT_VOLUME_CLAIM}.mount.path=/zoo \\\n  --conf spark.kubernetes.driver.label.<your-label>=true \\\n  --conf spark.kubernetes.executor.label.<your-label>=true \\\n  --executor-cores ${RUNTIME_EXECUTOR_CORES} \\\n  --executor-memory ${RUNTIME_EXECUTOR_MEMORY} \\\n  --total-executor-cores ${RUNTIME_TOTAL_EXECUTOR_CORES} \\\n  --driver-cores ${RUNTIME_DRIVER_CORES} \\\n  --driver-memory ${RUNTIME_DRIVER_MEMORY} \\\n  --properties-file ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf \\\n  --py-files ${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-python-api.zip,/opt/analytics-zoo-examples/python/anomalydetection/anomaly_detection.py \\\n  --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \\\n  --conf spark.sql.catalogImplementation='in-memory' \\\n  --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar:/opt/cluster-serving/spark-redis-2.4.0-jar-with-dependencies.jar \\\n  --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-bigdl_${BIGDL_VERSION}-spark_${SPARK_VERSION}-${ANALYTICS_ZOO_VERSION}-jar-with-dependencies.jar:/opt/cluster-serving/spark-redis-2.4.0-jar-with-dependencies.jar \\\n  --conf \"spark.executor.extraJavaOptions=-Dbigdl.engineType=mklblas\" \\\n  --conf \"spark.driver.extraJavaOptions=-Dbigdl.engineType=mklblas\" \\\n  --class com.intel.analytics.zoo.serving.ClusterServing \\\n  local:/opt/analytics-zoo-0.8.0-SNAPSHOT/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.0-SNAPSHOT-jar-with-dependencies.jar",
            "title": "Launch Analytics Zoo cluster serving"
        },
        {
            "location": "/wp-bigdl/",
            "text": "BigDL: A Distributed Deep Learning Framework for Big Data\n\n\nJason (Jinquan) Dai\n1\n, Yiheng Wang\n1\n, Xin Qiu\n1\n, Ding Ding\n1\n, Yao Zhang\n2 \u01c2\n, Yanzhang Wang\n1\n, Xianyan Jia\n2 \u01c2\n, Cherry (Li) Zhang\n1\n, Yan Wan\n3 \u01c2\n, Zhichao Li\n1\n, Jiao Wang\n1\n, Shengsheng Huang\n1\n, Zhongyuan Wu\n1\n, Yang Wang\n1\n, Yuhao Yang\n1\n, Bowen She\n1\n, Dongjie Shi\n1\n, Qi Lu\n1\n, Kai Huang\n1\n, Guoqiong Song\n1\n\n\n1\nIntel Corporation,    \n2\nTencent Inc.,    \n3\nAlibaba Group\n\n\n\u01c2\nWork was done when the author worked at Intel\n\n\n\n\nAbstract\n\n\nIn this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an \nAllReduce\n like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.\n\n\n1. Introduction\n\n\nRecent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:\n\n\n\n\n\n\nData scale drives deep learning process.\n Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).\n\n\n\n\n\n\nReal-world deep learning applications are complex big data pipelines,\n which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].\n\n\n\n\n\n\nDeep learning is increasingly adopted by the big data and data science community.\n Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.\n\n\n\n\n\n\nWe have developed \nBigDL\n [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.\n\n\nBigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms.\n\n\n2. Programming Model\n\n\nBigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.\n\n\n1    spark = SparkContext(appName=\"text_classifier\", \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile(\"hdfs://...\")\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   optimizer.set_train_summary(summary = TrainSummary(\u2026))\n25   trained_model =optimizer.optimize()\n26   //model prediction\n27   test_rdd = \u2026\n28   prediction_rdd = trained_model.predict(test_rdd)\n\n\n\n\nFigure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.\n\n\n2.1. Spark\n\n\nSpark provides the \nResilient Distributed Dataset\n (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like \nmap, filter and reduce.\n Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.\n\n\n2.2. Data transformation\n\n\nSpark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector. \n\n\n\n\n\n\nN-dimensional array:\n In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by \nnumpy.ndarry\n [22] and \nBigDL.Tensor\n (similar to \nTorch.Tensor\n [23]) for BigDL Python and Scala/Java APIs respectively.\n\n\n\n\n\n\nSample:\n Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more \nN-dimensional arrays.\n For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of \nSamples,\n which will later be used by BigDL model training.\n\n\n\n\n\n\n2.3. Model Construction\n\n\nSimilar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as \nReLu, Spatial Convolution and LSTM\n). BigDL then uses the semantics of the layers for model evaluation (\nforward\n) and gradient computation (\nbackward\n). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.\n\n\n2.4. Model training\n\n\nThe transformed input data (RDD of Samples) and the constructed model can then be passed over to the \nOptimizer\n in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in \nFigure 1.\n\n\n\n\n\n\nOptimizer:\n In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as \nSGD, AdaGrad [24], Adam [25], etc.\n).\n\n\n\n\n\n\nVisualization:\n To make it easy for users to understand the behaviors of model training, the \noptimizer\n in BigDL can be configured to produce a \nTrainSummary\n that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27].\n\n\n\n\n\n\n2.5. Model Inference\n\n\nBigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1. \n\n\n\n\nModelBroadcast:\n BigDL provides the \nModelBroadcast\n abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation (\npredict\n) in BigDL uses \nModelBroadcast\n to cache a single copy of the model on each machine (by leveraging the \nbroadcast\n [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.\n\n\n\n\n2.6. Spark DataFrame and ML Pipeline\n\n\nBesides RDD, Spark provides a high level \nDataFrame\n abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like \nfilter\n and \njoin\n for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML \n(machine learning) pipeline\n [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its \nDLModel\n and \nDLEstimator\n abstractions). \n\n\n3. Execution Model\n\n\nSimilar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items). \n\n\n \n\n\nFigure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.\n\n\nOn the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).\n\n\n3.1. Data-parallel training\n\n\nTo train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.\n\n\nfor (i <- 1 to N) {\n  //\"model forward-backward\" job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local Sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  //\"parameter synchronization\" job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}\n\n\n\n\nFigure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.\n\n\nAs described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional \nzip\n operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4.\n\n\n \n\n\nFigure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.\n\n\n3.2. Parameter synchronization\n\n\nParameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the \nparameter server\n [33][34][35] architecture or \nAllReduce\n [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.\n\n\nIn BigDL, we have adapted the primitives available in Spark (e.g., \nshuffle, broadcast, in-memory cache\n, etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).\n\n\n \n\n\nFigure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.\n\n\n\n\n\n\nA Spark job has \nN\n tasks, each of which is assigned a unique Id ranging from \n1\n to \nN\n in BigDL. After each task in the \u201c\nmodel forward-backward\n\u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into \nN\n partitions, as shown in Figure 5.\n\n\n\n\n\n\nNext, another \u201c\nparameter synchronization\n\u201d job is launched; each task \nn\n in the \u201c\nparameter synchronization\n\u201d job is responsible for managing the n\nth\n partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n\nth\n partition of the gradients (from all the tasks of the previous \u201c\nmodel forward-backward\n\u201d job) are first \nshuffled\n to task \nn\n, which then aggregates (sums) these gradients, and applies the updates to the n\nth\n partition of the weights (using the specific \noptimization method\n), as illustrated in Figure 5.\n\n\n\n\n\n\n \n\n\nFigure 6. The \u201cparameter synchronization\u201d Spark job, manages the n\nth\n partition of the parameters (similar to a parameter server).\n\n\n\n\n\n\nAfter that, each task \nn\n in the \u201c\nparameter synchronization\n\u201d job \nbroadcasts\n the n\nth\n partition of the updated weights; consequently, tasks in the \u201c\nmodel forward-backward\n\u201d job of the next iteration can read the latest value of all the weights before the next training step begins.\n\n\n\n\n\n\nThe \nshuffle\n and \ntask-side broadcast\n operations described above are implemented on top of the distributed \nin-memory\n storage in Spark: both the shuffled \ngradients\n and broadcasted \nweights\n are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.\n\n\n\n\n\n\nBy implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7. \n\n\n \n\n\nFigure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).\n\n\n3.3. Task scheduling\n\n\nWhile BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization.\n\n\nIn contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above). \n\n\nTo scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by \nDrizzle\n [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8.\n\n\n \n\n\nFigure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39].\n\n\n3.4. Model quantization\n\n\nQuantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.\n\n\nBigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.\n\n\nMath.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte\n\n\n\n\nFigure 9. Equation for quantizing 32-bit floating point to 8-bit integer.\n\n\nUnlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10.\n\n\n\n\nFigure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40].\n\n\n3.5. Local execution\n\n\nIn addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.\n\n\n4. Applications\n\n\nSince its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL.\n\n\n4.1. Model Inference: image feature extraction\n\n\nJD.com [41] is one of the largest online retailers in the world. It has built an end-to-end \nobject detection and image feature extraction\n pipeline on top of Spark and BigDL[42], as illustrated in Figure 11.\n\n\n \n\n\nFigure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42].\n\n\n\n\n\n\nThe pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including \nresizing\n, \nnormalization\n, and \nbatching\n) in a distributed fashion using Spark.\n\n\n\n\n\n\nAfter that, it uses BigDL to load a \nSSD\n [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.\n\n\n\n\n\n\nIt then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including \nresizing\n and \nbatching\n).\n\n\n\n\n\n\nFinally it uses BigDL to load a \nDeepBit\n [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).\n\n\n\n\n\n\nThe entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12.\n\n\n \n\n\nFigure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).\n\n\n4.2. Distributed training: precipitation nowcasting\n\n\nCray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting (\npredicting short-term precipitation\n) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13). \n\n\n \n\n\nFigure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL.\n\n\n\n\n\n\nThe application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of \nNumPy ndarrays\n.\n\n\n\n\n\n\nIt then trains a \nsequence-to-sequence\n model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output.\n\n\n\n\n\n\nAfter the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.\n\n\n\n\n\n\n \n\n\nFigure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37]\n\n\n4.3. Transfer learning: image-similarity based house recommendations\n\n\nMLSListings Inc. is a large \nMultiple Listing Service\n (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15.\n\n\n \n\n\nFigure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47]\n\n\nTo compute the \nsemantic similarity\n for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo.\n\n\nTo compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage.\n\n\nAt \nmodel serving\n time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the \n\u201cSimilar Houses\u201d\n section of the webpage in Figure 16.\n\n\n \n\n\nFigure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47]\n\n\n5.Related Work\n\n\nExisting big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model.\n\n\nExisting deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark.\n\n\nRecently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark). \n\n\n6. Summary\n\n\nWe have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training. \n\n\nBigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.\n\n\n7. Acknowledgement\n\n\nWe gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project.\n\n\n8. Reference\n\n\n[1] Caffe. \nhttp://caffe.berkeleyvision.org\n\n\n[2] Torch. \nhttp://torch.ch\n\n\n[3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.\n\n\n[4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.\n\n\n[5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.\n\n\n[6] Apache Hadoop. \nhttp://hadoop.apache.org\n\n\n[7] Apache Spark. \nhttps://spark.apache.org\n\n\n[8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.\n\n\n[9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]\n\n\n[10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]\n\n\n[11] BigDL. \nhttps://github.com/intel-analytics/BigDL/\n\n\n[12] Keras. \nhttps://keras.io\n\n\n[13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.\n\n\n[14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.\n\n\n[15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.\n\n\n[16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.\n\n\n[17] Apache Storm. \nhttp://storm.apache.org\n\n\n[18] Apache Flink. \nhttps://flink.apache.org\n\n\n[19] Apache Kafka. \nhttps://kafka.apache.org\n\n\n[20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.\n\n\n[21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.\n\n\n[22] Numpy. \nhttp://www.numpy.org\n\n\n[23] Torch7. \nhttps://github.com/torch/torch7\n\n\n[24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.\n\n\n[25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.\n\n\n[26] M. Abadi, et al.\n\u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems.\n, 2016.\n\n\n[27] Project Jupyter. \nhttp://jupyter.org\n\n\n[28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.\n\n\n[29] SciKit-Learn. \nhttp://scikit-learn.org/stable/\n\n\n[30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.\n\n\n[31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.\n\n\n[32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.\n\n\n[33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.\n\n\n[34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.\n\n\n[35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.\n\n\n[36] Andrew Gibiansky. \nBringing HPC Techniques to Deep Learning\n\n\n[37] Alex Heye, et al. \nScalable Deep Learning with BigDL on the Urika-XC Software Suite\n\n\n[38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.\n\n\n[39] Shivaram Venkataraman, et al. \nAccelerating Deep Learning Training with BigDL and Drizzle on Apache Spark\n\n\n[40] Jason (Jinquan) Dai, et al. \nLeveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL\n\n\n[41] JD. \nhttps://en.wikipedia.org/wiki/JD.com\n\n\n[42] Jason (Jinquan) Dai, et al. \nBuilding Large-Scale Image Feature Extraction with BigDL at JD.com\n\n\n[43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.\n\n\n[44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.\n\n\n[45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014. \n\n\n[46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.\n\n\n[47] Jason (Jinquan) Dai, et al. \n\u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d\n\n\n[48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015.\n\n\n[49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.\n\n\n[50] Karen Simonyan, at al. \n\u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d\n, 2014.\n\n\n[51]    Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017.\n\n\n[52]    DJ4J. https://deeplearning4j.org/\n\n\n[53]    TensorFrames. https://github.com/databricks/tensorframes\n\n\n[54]    Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning\n\n\n[55]    CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark\n\n\n[56]    TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark\n\n\n[57]    Philipp Moritz, et al.  \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.",
            "title": "BigDL"
        },
        {
            "location": "/wp-bigdl/#bigdl-a-distributed-deep-learning-framework-for-big-data",
            "text": "Jason (Jinquan) Dai 1 , Yiheng Wang 1 , Xin Qiu 1 , Ding Ding 1 , Yao Zhang 2 \u01c2 , Yanzhang Wang 1 , Xianyan Jia 2 \u01c2 , Cherry (Li) Zhang 1 , Yan Wan 3 \u01c2 , Zhichao Li 1 , Jiao Wang 1 , Shengsheng Huang 1 , Zhongyuan Wu 1 , Yang Wang 1 , Yuhao Yang 1 , Bowen She 1 , Dongjie Shi 1 , Qi Lu 1 , Kai Huang 1 , Guoqiong Song 1  1 Intel Corporation,     2 Tencent Inc.,     3 Alibaba Group  \u01c2 Work was done when the author worked at Intel",
            "title": "BigDL: A Distributed Deep Learning Framework for Big Data"
        },
        {
            "location": "/wp-bigdl/#abstract",
            "text": "In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an  AllReduce  like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.",
            "title": "Abstract"
        },
        {
            "location": "/wp-bigdl/#1-introduction",
            "text": "Recent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:    Data scale drives deep learning process.  Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).    Real-world deep learning applications are complex big data pipelines,  which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].    Deep learning is increasingly adopted by the big data and data science community.  Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.    We have developed  BigDL  [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.  BigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms.",
            "title": "1. Introduction"
        },
        {
            "location": "/wp-bigdl/#2-programming-model",
            "text": "BigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.  1    spark = SparkContext(appName=\"text_classifier\", \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile(\"hdfs://...\")\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   optimizer.set_train_summary(summary = TrainSummary(\u2026))\n25   trained_model =optimizer.optimize()\n26   //model prediction\n27   test_rdd = \u2026\n28   prediction_rdd = trained_model.predict(test_rdd)  Figure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.",
            "title": "2. Programming Model"
        },
        {
            "location": "/wp-bigdl/#21-spark",
            "text": "Spark provides the  Resilient Distributed Dataset  (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like  map, filter and reduce.  Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.",
            "title": "2.1. Spark"
        },
        {
            "location": "/wp-bigdl/#22-data-transformation",
            "text": "Spark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector.     N-dimensional array:  In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by  numpy.ndarry  [22] and  BigDL.Tensor  (similar to  Torch.Tensor  [23]) for BigDL Python and Scala/Java APIs respectively.    Sample:  Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more  N-dimensional arrays.  For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of  Samples,  which will later be used by BigDL model training.",
            "title": "2.2. Data transformation"
        },
        {
            "location": "/wp-bigdl/#23-model-construction",
            "text": "Similar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as  ReLu, Spatial Convolution and LSTM ). BigDL then uses the semantics of the layers for model evaluation ( forward ) and gradient computation ( backward ). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.",
            "title": "2.3. Model Construction"
        },
        {
            "location": "/wp-bigdl/#24-model-training",
            "text": "The transformed input data (RDD of Samples) and the constructed model can then be passed over to the  Optimizer  in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in  Figure 1.    Optimizer:  In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as  SGD, AdaGrad [24], Adam [25], etc. ).    Visualization:  To make it easy for users to understand the behaviors of model training, the  optimizer  in BigDL can be configured to produce a  TrainSummary  that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27].",
            "title": "2.4. Model training"
        },
        {
            "location": "/wp-bigdl/#25-model-inference",
            "text": "BigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1.    ModelBroadcast:  BigDL provides the  ModelBroadcast  abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation ( predict ) in BigDL uses  ModelBroadcast  to cache a single copy of the model on each machine (by leveraging the  broadcast  [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.",
            "title": "2.5. Model Inference"
        },
        {
            "location": "/wp-bigdl/#26-spark-dataframe-and-ml-pipeline",
            "text": "Besides RDD, Spark provides a high level  DataFrame  abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like  filter  and  join  for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML  (machine learning) pipeline  [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its  DLModel  and  DLEstimator  abstractions).",
            "title": "2.6. Spark DataFrame and ML Pipeline"
        },
        {
            "location": "/wp-bigdl/#3-execution-model",
            "text": "Similar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items).      Figure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.  On the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).",
            "title": "3. Execution Model"
        },
        {
            "location": "/wp-bigdl/#31-data-parallel-training",
            "text": "To train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.  for (i <- 1 to N) {\n  //\"model forward-backward\" job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local Sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  //\"parameter synchronization\" job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}  Figure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.  As described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional  zip  operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4.     Figure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.",
            "title": "3.1. Data-parallel training"
        },
        {
            "location": "/wp-bigdl/#32-parameter-synchronization",
            "text": "Parameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the  parameter server  [33][34][35] architecture or  AllReduce  [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.  In BigDL, we have adapted the primitives available in Spark (e.g.,  shuffle, broadcast, in-memory cache , etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).     Figure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.    A Spark job has  N  tasks, each of which is assigned a unique Id ranging from  1  to  N  in BigDL. After each task in the \u201c model forward-backward \u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into  N  partitions, as shown in Figure 5.    Next, another \u201c parameter synchronization \u201d job is launched; each task  n  in the \u201c parameter synchronization \u201d job is responsible for managing the n th  partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n th  partition of the gradients (from all the tasks of the previous \u201c model forward-backward \u201d job) are first  shuffled  to task  n , which then aggregates (sums) these gradients, and applies the updates to the n th  partition of the weights (using the specific  optimization method ), as illustrated in Figure 5.       Figure 6. The \u201cparameter synchronization\u201d Spark job, manages the n th  partition of the parameters (similar to a parameter server).    After that, each task  n  in the \u201c parameter synchronization \u201d job  broadcasts  the n th  partition of the updated weights; consequently, tasks in the \u201c model forward-backward \u201d job of the next iteration can read the latest value of all the weights before the next training step begins.    The  shuffle  and  task-side broadcast  operations described above are implemented on top of the distributed  in-memory  storage in Spark: both the shuffled  gradients  and broadcasted  weights  are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.    By implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7.      Figure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).",
            "title": "3.2. Parameter synchronization"
        },
        {
            "location": "/wp-bigdl/#33-task-scheduling",
            "text": "While BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization.  In contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above).   To scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by  Drizzle  [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8.     Figure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39].",
            "title": "3.3. Task scheduling"
        },
        {
            "location": "/wp-bigdl/#34-model-quantization",
            "text": "Quantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.  BigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.  Math.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte  Figure 9. Equation for quantizing 32-bit floating point to 8-bit integer.  Unlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10.   Figure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40].",
            "title": "3.4. Model quantization"
        },
        {
            "location": "/wp-bigdl/#35-local-execution",
            "text": "In addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.",
            "title": "3.5. Local execution"
        },
        {
            "location": "/wp-bigdl/#4-applications",
            "text": "Since its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL.",
            "title": "4. Applications"
        },
        {
            "location": "/wp-bigdl/#41-model-inference-image-feature-extraction",
            "text": "JD.com [41] is one of the largest online retailers in the world. It has built an end-to-end  object detection and image feature extraction  pipeline on top of Spark and BigDL[42], as illustrated in Figure 11.     Figure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42].    The pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including  resizing ,  normalization , and  batching ) in a distributed fashion using Spark.    After that, it uses BigDL to load a  SSD  [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.    It then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including  resizing  and  batching ).    Finally it uses BigDL to load a  DeepBit  [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).    The entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12.     Figure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).",
            "title": "4.1. Model Inference: image feature extraction"
        },
        {
            "location": "/wp-bigdl/#42-distributed-training-precipitation-nowcasting",
            "text": "Cray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting ( predicting short-term precipitation ) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13).      Figure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL.    The application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of  NumPy ndarrays .    It then trains a  sequence-to-sequence  model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output.    After the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.       Figure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37]",
            "title": "4.2. Distributed training: precipitation nowcasting"
        },
        {
            "location": "/wp-bigdl/#43-transfer-learning-image-similarity-based-house-recommendations",
            "text": "MLSListings Inc. is a large  Multiple Listing Service  (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15.     Figure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47]  To compute the  semantic similarity  for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo.  To compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage.  At  model serving  time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the  \u201cSimilar Houses\u201d  section of the webpage in Figure 16.     Figure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47]",
            "title": "4.3. Transfer learning: image-similarity based house recommendations"
        },
        {
            "location": "/wp-bigdl/#5related-work",
            "text": "Existing big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model.  Existing deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark.  Recently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark).",
            "title": "5.Related Work"
        },
        {
            "location": "/wp-bigdl/#6-summary",
            "text": "We have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training.   BigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.",
            "title": "6. Summary"
        },
        {
            "location": "/wp-bigdl/#7-acknowledgement",
            "text": "We gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project.",
            "title": "7. Acknowledgement"
        },
        {
            "location": "/wp-bigdl/#8-reference",
            "text": "[1] Caffe.  http://caffe.berkeleyvision.org  [2] Torch.  http://torch.ch  [3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.  [4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.  [5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.  [6] Apache Hadoop.  http://hadoop.apache.org  [7] Apache Spark.  https://spark.apache.org  [8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.  [9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]  [10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]  [11] BigDL.  https://github.com/intel-analytics/BigDL/  [12] Keras.  https://keras.io  [13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.  [14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.  [15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.  [16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.  [17] Apache Storm.  http://storm.apache.org  [18] Apache Flink.  https://flink.apache.org  [19] Apache Kafka.  https://kafka.apache.org  [20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.  [21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.  [22] Numpy.  http://www.numpy.org  [23] Torch7.  https://github.com/torch/torch7  [24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.  [25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.  [26] M. Abadi, et al. \u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems. , 2016.  [27] Project Jupyter.  http://jupyter.org  [28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.  [29] SciKit-Learn.  http://scikit-learn.org/stable/  [30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.  [31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.  [32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.  [33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.  [34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.  [35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.  [36] Andrew Gibiansky.  Bringing HPC Techniques to Deep Learning  [37] Alex Heye, et al.  Scalable Deep Learning with BigDL on the Urika-XC Software Suite  [38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.  [39] Shivaram Venkataraman, et al.  Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark  [40] Jason (Jinquan) Dai, et al.  Leveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL  [41] JD.  https://en.wikipedia.org/wiki/JD.com  [42] Jason (Jinquan) Dai, et al.  Building Large-Scale Image Feature Extraction with BigDL at JD.com  [43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.  [44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.  [45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014.   [46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.  [47] Jason (Jinquan) Dai, et al.  \u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d  [48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015.  [49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.  [50] Karen Simonyan, at al.  \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d , 2014.  [51]    Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017.  [52]    DJ4J. https://deeplearning4j.org/  [53]    TensorFrames. https://github.com/databricks/tensorframes  [54]    Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning  [55]    CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark  [56]    TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark  [57]    Philipp Moritz, et al.  \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.",
            "title": "8. Reference"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/",
            "text": "NNEstimator\n\n\nScala:\n\n\nval estimator = NNEstimator(model, criterion)\n\n\n\n\nPython:\n\n\nestimator = NNEstimator(model, criterion)\n\n\n\n\nNNEstimator\n extends \norg.apache.spark.ml.Estimator\n and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.\n\n\nNNEstimator\n supports different feature and label data types through \nPreprocessing\n.\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe \nPreprocessing\n to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL \nSample\n. \n\n\nEach\nPreprocessing\n conducts a data conversion step in the preprocessing phase, multiple\n\nPreprocessing\n can be combined into a \nChainedPreprocessing\n. Some pre-defined \n\nPreprocessing\n for popular data types like Image, Array or Vector are provided in package\n\ncom.intel.analytics.zoo.feature\n, while user can also develop customized \nPreprocessing\n.\n\n\nNNEstimator and NNClassifier also supports setting the caching level for the training data.\nOptions are \"DRAM\", \"PMEM\" or \"DISK_AND_DRAM\". If DISK_AND_DRAM(numSlice) is used, only 1/numSlice\ndata will be loaded into memory during training time. By default, DRAM mode is used and all data\nare cached in memory.\n\n\nBy default, \nSeqToTensor\n is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the \nPreprocessing\n allows \nNNEstimator\n to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\n\n\nMore concrete examples are available in package \ncom.intel.analytics.zoo.examples.nnframes\n\n\nNNEstimator\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNEstimator(model, criterion)\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   \nPreprocessing\n. \nNNEstimator\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL \nSample\n and send to model for\n   training.\n\n\n2.\n \nNNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). \nNNEstimator\n\n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n\n\n3.\n \nNNEstimator(model, criterion, featureSize: Array[Array[Int]], labelSize: Array[Int])\n\n\nThis is the interface for multi-input model. It takes model, criterion, featureSize(Array of\n   Int Array) and labelSize(Array of Int). \nNNEstimator\n\n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n\n\n4.\n \nNNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion, featurePreprocessing and labelPreprocessing.  \nNNEstimator\n\n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNEstimator\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample according to user-specified Preprocessing.\n\n\nScala Example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF(\"features\", \"label\")\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\"features\", ArrayType(DoubleType(), False), False),\n    StructField(\"label\", ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40) \\\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)\n\n\n\n\nExample with multi-inputs Model.\n\nThis example trains a model with 3 inputs. And users can\nuse VectorAssembler from Spark MLlib to combine different fields. With the specified sizes for\neach model input, NNEstiamtor and NNClassifer will split the input features data and send\ntensors to corresponding inputs.\n\n\nsparkConf = init_spark_conf().setAppName(\"testNNClassifer\").setMaster('local[1]')\nsc = init_nncontext(sparkConf)\nspark = SparkSession\\\n    .builder\\\n    .getOrCreate()\n\ndf = spark.createDataFrame(\n    [(1, 35, 109.0, Vectors.dense([2.0, 5.0, 0.5, 0.5]), 1.0),\n     (2, 58, 2998.0, Vectors.dense([4.0, 10.0, 0.5, 0.5]), 2.0),\n     (3, 18, 123.0, Vectors.dense([3.0, 15.0, 0.5, 0.5]), 1.0)],\n    [\"user\", \"age\", \"income\", \"history\", \"label\"])\n\nassembler = VectorAssembler(\n    inputCols=[\"user\", \"age\", \"income\", \"history\"],\n    outputCol=\"features\")\n\ndf = assembler.transform(df)\n\nx1 = ZLayer.Input(shape=(1,))\nx2 = ZLayer.Input(shape=(2,))\nx3 = ZLayer.Input(shape=(2, 2,))\n\nuser_embedding = ZLayer.Embedding(5, 10)(x1)\nflatten = ZLayer.Flatten()(user_embedding)\ndense1 = ZLayer.Dense(2)(x2)\ngru = ZLayer.LSTM(4, input_shape=(2, 2))(x3)\n\nmerged = ZLayer.merge([flatten, dense1, gru], mode=\"concat\")\nzy = ZLayer.Dense(2)(merged)\n\nzmodel = ZModel([x1, x2, x3], zy)\ncriterion = ZooClassNLLCriterion()\nclassifier = NNClassifier(zmodel, criterion, [[1], [2], [2, 2]]) \\\n    .setOptimMethod(Adam()) \\\n    .setLearningRate(0.1)\\\n    .setBatchSize(2) \\\n    .setMaxEpoch(10)\n\nnnClassifierModel = classifier.fit(df)\nprint(nnClassifierModel.getBatchSize())\nres = nnClassifierModel.transform(df).collect()\n\n\n\n\n\n\n\nNNModel\n\n\nScala:\n\n\nval nnModel = NNModel(bigDLModel)\n\n\n\n\nPython:\n\n\nnn_model = NNModel(bigDLModel)\n\n\n\n\nNNModel\n extends Spark's ML\n\nTransformer\n. User can invoke\n\nfit\n in \nNNEstimator\n to get a \nNNModel\n, or directly compose a \nNNModel\n from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for \nDataFrame\n(DataSet)\n. \n\n\nNNModel\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNModel(model)\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNModel\n will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n\n\n2.\n \nNNModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size. User can also set featureSize as\n   Array[Array[Int]] for multi-inputs model.\n\n\n3.\n \nNNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNModel\n will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNModel\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nNNClassifier\n\n\nScala:\n\n\nval classifer =  NNClassifer(model, criterion)\n\n\n\n\nPython:\n\n\nclassifier = NNClassifer(model, criterion)\n\n\n\n\nNNClassifier\n is a specialized \nNNEstimator\n that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted \nNNClassifierModel\n will have the prediction column of \nDoubleType.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\n\n\nNNClassifier\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNClassifier(model, criterion)\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   Preprocessing. \nNNClassifier\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n\n\n2.\n \nNNClassifier(model, criterion, featureSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int). \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size. \nScalarToTensor\n is used to convert the label column.\n   User can also set featureSize as Array[Array[Int]] for multi-inputs model.\n\n\n3.\n \nNNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion and featurePreprocessing.  \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifier\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample with user-specified Preprocessing.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF(\"features\", \"label\")\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ZooClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\"features\", ArrayType(DoubleType(), False), False),\n    StructField(\"label\", ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\n\n\n\n\nNNClassifierModel\n\n\nScala:\n\n\nval nnClassifierModel = NNClassifierModel(model, featureSize)\n\n\n\n\nPython:\n\n\nnn_classifier_model = NNClassifierModel(model)\n\n\n\n\nNNClassifierModel is a specialized \nNNModel\n for classification tasks.\nBoth label and prediction column will have the datatype of Double.\n\n\nNNClassifierModel\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNClassifierModel(model)\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNClassifierModel\n will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n\n\n2.\n \nNNClassifierModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNClassifierModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size. User can also set featureSize as\n   Array[Array[Int]] for multi-inputs model.\n\n\n3.\n \nNNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNClassifierModel\n will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifierModel\n\nsupports: \nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nHyperparameter setting\n\n\nPrior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or\n\nNNEstimator\n/\nNNClassifier\n will use the default value.\n\n\nContinue the codes above, NNEstimator and NNClassifier can be set in the same way.\n\n\nScala:\n\n\n//for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n\n\n\n\nPython:\n\n\n# for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n\n\n\n\n\nPrepare the data and start the training process\n\n\nNNEstimator/NNCLassifer supports training with Spark's\n\nDataFrame/DataSet\n\n\nSuppose \ndf\n is the training data, simple call \nfit\n method and let Analytics Zoo train the model\nfor you.\n\n\nScala:\n\n\n//get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)\n\n\n\n\nPython:\n\n\n# get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)\n\n\n\n\nUser may also set validation DataFrame and validation frequency through \nsetValidation\n method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard. See \nVisualization\n for the details.\n\n\nMake prediction on chosen data\n\n\nSince \nNNModel\n/\nNNClassifierModel\n inherits from Spark's \nTransformer\n abstract class, simply call \n\ntransform\n method on \nNNModel\n/\nNNClassifierModel\n to make prediction.\n\n\nScala:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nPython:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nFor the complete examples of NNFrames, please refer to:\n\nScala examples\n\n\nPython examples\n\n\nNNImageReader\n\n\nNNImageReader\n is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.\n\n\nScala:\n\n\nval imageDF = NNImageReader.readImages(imageDirectory, sc)\n\n\n\n\nPython:\n\n\nimage_frame = NNImageReader.readImages(image_path, self.sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\nval byteSchema = StructType(\n  StructField(\"origin\", StringType, true) ::\n    StructField(\"height\", IntegerType, false) ::\n    StructField(\"width\", IntegerType, false) ::\n    StructField(\"nChannels\", IntegerType, false) ::\n    // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n    StructField(\"mode\", IntegerType, false) ::\n    // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n    StructField(\"data\", BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.",
            "title": "NNFrames"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnestimator",
            "text": "Scala:  val estimator = NNEstimator(model, criterion)  Python:  estimator = NNEstimator(model, criterion)  NNEstimator  extends  org.apache.spark.ml.Estimator  and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.  NNEstimator  supports different feature and label data types through  Preprocessing .\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe  Preprocessing  to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL  Sample .   Each Preprocessing  conducts a data conversion step in the preprocessing phase, multiple Preprocessing  can be combined into a  ChainedPreprocessing . Some pre-defined  Preprocessing  for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized  Preprocessing .  NNEstimator and NNClassifier also supports setting the caching level for the training data.\nOptions are \"DRAM\", \"PMEM\" or \"DISK_AND_DRAM\". If DISK_AND_DRAM(numSlice) is used, only 1/numSlice\ndata will be loaded into memory during training time. By default, DRAM mode is used and all data\nare cached in memory.  By default,  SeqToTensor  is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the  Preprocessing  allows  NNEstimator  to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.  More concrete examples are available in package  com.intel.analytics.zoo.examples.nnframes  NNEstimator  can be created with various parameters for different scenarios.  1.   NNEstimator(model, criterion)  Takes only model and criterion and use  SeqToTensor  as feature and label\n    Preprocessing .  NNEstimator  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL  Sample  and send to model for\n   training.  2.   NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])  Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int).  NNEstimator \n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.  3.   NNEstimator(model, criterion, featureSize: Array[Array[Int]], labelSize: Array[Int])  This is the interface for multi-input model. It takes model, criterion, featureSize(Array of\n   Int Array) and labelSize(Array of Int).  NNEstimator \n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.  4.   NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion, featurePreprocessing and labelPreprocessing.   NNEstimator \n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNEstimator  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample according to user-specified Preprocessing.  Scala Example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF(\"features\", \"label\")\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\"features\", ArrayType(DoubleType(), False), False),\n    StructField(\"label\", ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40) \\\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)  Example with multi-inputs Model. \nThis example trains a model with 3 inputs. And users can\nuse VectorAssembler from Spark MLlib to combine different fields. With the specified sizes for\neach model input, NNEstiamtor and NNClassifer will split the input features data and send\ntensors to corresponding inputs.  sparkConf = init_spark_conf().setAppName(\"testNNClassifer\").setMaster('local[1]')\nsc = init_nncontext(sparkConf)\nspark = SparkSession\\\n    .builder\\\n    .getOrCreate()\n\ndf = spark.createDataFrame(\n    [(1, 35, 109.0, Vectors.dense([2.0, 5.0, 0.5, 0.5]), 1.0),\n     (2, 58, 2998.0, Vectors.dense([4.0, 10.0, 0.5, 0.5]), 2.0),\n     (3, 18, 123.0, Vectors.dense([3.0, 15.0, 0.5, 0.5]), 1.0)],\n    [\"user\", \"age\", \"income\", \"history\", \"label\"])\n\nassembler = VectorAssembler(\n    inputCols=[\"user\", \"age\", \"income\", \"history\"],\n    outputCol=\"features\")\n\ndf = assembler.transform(df)\n\nx1 = ZLayer.Input(shape=(1,))\nx2 = ZLayer.Input(shape=(2,))\nx3 = ZLayer.Input(shape=(2, 2,))\n\nuser_embedding = ZLayer.Embedding(5, 10)(x1)\nflatten = ZLayer.Flatten()(user_embedding)\ndense1 = ZLayer.Dense(2)(x2)\ngru = ZLayer.LSTM(4, input_shape=(2, 2))(x3)\n\nmerged = ZLayer.merge([flatten, dense1, gru], mode=\"concat\")\nzy = ZLayer.Dense(2)(merged)\n\nzmodel = ZModel([x1, x2, x3], zy)\ncriterion = ZooClassNLLCriterion()\nclassifier = NNClassifier(zmodel, criterion, [[1], [2], [2, 2]]) \\\n    .setOptimMethod(Adam()) \\\n    .setLearningRate(0.1)\\\n    .setBatchSize(2) \\\n    .setMaxEpoch(10)\n\nnnClassifierModel = classifier.fit(df)\nprint(nnClassifierModel.getBatchSize())\nres = nnClassifierModel.transform(df).collect()",
            "title": "NNEstimator"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnmodel",
            "text": "Scala:  val nnModel = NNModel(bigDLModel)  Python:  nn_model = NNModel(bigDLModel)  NNModel  extends Spark's ML Transformer . User can invoke fit  in  NNEstimator  to get a  NNModel , or directly compose a  NNModel  from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for  DataFrame\n(DataSet) .   NNModel  can be created with various parameters for different scenarios.  1.   NNModel(model)  Takes only model and use  SeqToTensor  as feature Preprocessing.  NNModel  will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.  2.   NNModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size. User can also set featureSize as\n   Array[Array[Int]] for multi-inputs model.  3.   NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNModel  will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNModel  supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.",
            "title": "NNModel"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifier",
            "text": "Scala:  val classifer =  NNClassifer(model, criterion)  Python:  classifier = NNClassifer(model, criterion)  NNClassifier  is a specialized  NNEstimator  that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted  NNClassifierModel  will have the prediction column of \nDoubleType.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient   NNClassifier  can be created with various parameters for different scenarios.  1.   NNClassifier(model, criterion)  Takes only model and criterion and use  SeqToTensor  as feature and label\n   Preprocessing.  NNClassifier  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.  2.   NNClassifier(model, criterion, featureSize: Array[Int])  Takes model, criterion, featureSize(Array of Int).  NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size.  ScalarToTensor  is used to convert the label column.\n   User can also set featureSize as Array[Array[Int]] for multi-inputs model.  3.   NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion and featurePreprocessing.   NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifier  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample with user-specified Preprocessing.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF(\"features\", \"label\")\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ZooClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\"features\", ArrayType(DoubleType(), False), False),\n    StructField(\"label\", ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)",
            "title": "NNClassifier"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifiermodel",
            "text": "Scala:  val nnClassifierModel = NNClassifierModel(model, featureSize)  Python:  nn_classifier_model = NNClassifierModel(model)  NNClassifierModel is a specialized  NNModel  for classification tasks.\nBoth label and prediction column will have the datatype of Double.  NNClassifierModel  can be created with various parameters for different scenarios.  1.   NNClassifierModel(model)  Takes only model and use  SeqToTensor  as feature Preprocessing.  NNClassifierModel  will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.  2.   NNClassifierModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNClassifierModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size. User can also set featureSize as\n   Array[Array[Int]] for multi-inputs model.  3.   NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNClassifierModel  will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifierModel \nsupports:  setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.",
            "title": "NNClassifierModel"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#hyperparameter-setting",
            "text": "Prior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier  will use the default value.  Continue the codes above, NNEstimator and NNClassifier can be set in the same way.  Scala:  //for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())  Python:  # for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())",
            "title": "Hyperparameter setting"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#prepare-the-data-and-start-the-training-process",
            "text": "NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet  Suppose  df  is the training data, simple call  fit  method and let Analytics Zoo train the model\nfor you.  Scala:  //get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)  Python:  # get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)  User may also set validation DataFrame and validation frequency through  setValidation  method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard. See  Visualization  for the details.",
            "title": "Prepare the data and start the training process"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#make-prediction-on-chosen-data",
            "text": "Since  NNModel / NNClassifierModel  inherits from Spark's  Transformer  abstract class, simply call  transform  method on  NNModel / NNClassifierModel  to make prediction.  Scala:  nnModel.transform(df).show(false)  Python:  nnModel.transform(df).show(false)  For the complete examples of NNFrames, please refer to: Scala examples  Python examples",
            "title": "Make prediction on chosen data"
        },
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnimagereader",
            "text": "NNImageReader  is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.  Scala:  val imageDF = NNImageReader.readImages(imageDirectory, sc)  Python:  image_frame = NNImageReader.readImages(image_path, self.sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.  val byteSchema = StructType(\n  StructField(\"origin\", StringType, true) ::\n    StructField(\"height\", IntegerType, false) ::\n    StructField(\"width\", IntegerType, false) ::\n    StructField(\"nChannels\", IntegerType, false) ::\n    // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n    StructField(\"mode\", IntegerType, false) ::\n    // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n    StructField(\"data\", BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .",
            "title": "NNImageReader"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/",
            "text": "mean\n\n\nMean of a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepDims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeepDims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nmean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nmean(x, axis=0, keepDims=False):\n\n\n\n\nabs\n\n\nElement-wise absolute value.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nabs(x: Variable[T])\n\n\n\n\nPython example\n\n\nabs(x):\n\n\n\n\nsum\n\n\nSum of the values in a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepDims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeepDims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nsum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nsum(x, axis=0, keepDims=False):\n\n\n\n\nclip\n\n\nElement-wise value clipping.\n- \nx\n A \nVariable\n.\n- \nmin\n Double\n- \nmax\n Double\n\n\nScala example\n\n\nclip(x: Variable[T], min: Double, max: Double)\n\n\n\n\nPython example\n\n\nclip(x, min, max)\n\n\n\n\nsquare\n\n\nElement-wise square.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsquare(x: Variable[T])\n\n\n\n\nPython example\n\n\nsquare(x):\n\n\n\n\nsqrt\n\n\nElement-wise square root.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsqrt(x: Variable[T])\n\n\n\n\nPython example\n\n\nsqrt(x):\n\n\n\n\nmaximum\n\n\nElement-wise maximum of two \nVariables\n.\n- \nx\n A \nVariable\n.\n- \ny\n A \nVariable\n or Double.\n\n\nScala example\n\n\nmaximum(x: Variable[T], y: Variable[T])\n\n\n\n\nPython example\n\n\nmaximum(x, y):\n\n\n\n\nlog\n\n\nElement-wise log.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nlog(x: Variable[T])\n\n\n\n\nPython example\n\n\nlog(x):\n\n\n\n\nexp\n\n\nElement-wise exponential.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nexp(x: Variable[T])\n\n\n\n\nPython example\n\n\nexp(x):\n\n\n\n\npow\n\n\nElement-wise exponentiation.\n- \nx\n A \nVariable\n.\n- \na\n Double.   \n\n\nScala example\n\n\npow(x: Variable[T])\n\n\n\n\nPython example\n\n\npow(x):\n\n\n\n\nsoftsign\n\n\nSoftsign of a \nVariable\n.\n\n\nScala example\n\n\nsoftsign(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftsign(x):\n\n\n\n\nsoftplus\n\n\nSoftplus of a \nVariable\n.\n\n\nScala example\n\n\nsoftplus(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftplus(x):\n\n\n\n\nstack\n\n\nStacks a list of rank \nR\n tensors into a rank \nR+1\n tensor.\n   You should start from 1 as dim 0 is for batch.\n   - inputs: List of variables (tensors)\n   - axis: xis along which to perform stacking.\n\n\nScala example\n\n\ndef stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1)\n\n\n\n\nPython example\n\n\ndef stack(inputs, axis=1)\n\n\n\n\nexpand_dims\n\n\nAdds a 1-sized dimension at index \"axis\".\n\n\nScala example\n\n\ndef expandDims[T: ClassTag](x: Variable[T], axis: Int)\n\n\n\n\nPython example\n\n\nexpand_dims(x, axis)\n\n\n\n\ncontiguous\n\n\nTurn the output and grad to be contiguous for the input Variable\n\n\nScala example\n\n\ndef contiguous[T: ClassTag](input: Variable[T])\n\n\n\n\nPython example\n\n\ndef contiguous(x)\n\n\n\n\nmm\n\n\nModule to perform matrix multiplication on two mini-batch inputs, producing a mini-batch.\n- \nx\n A variable.\n- \ny\n A variable.\n- \naxes\n Axes along which to perform multiplication.\n\n\nScala example\n\n\ndef mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int])\n\n\n\n\nPython example\n\n\ndef mm(x, y, axes)\n\n\n\n\nbatch_dot\n\n\nOperator that computes a dot product between samples in two tensors.\n- \nx\n Shape should only be [batch, xx]\n- \ny\n Shape should only be [batch, xx]\n- \naxes\n Integer or tuple of integers, axis or axes along which to take the dot product.\n- \nnormalize\n Whether to L2-normalize samples along the\n              dot product axis before taking the dot product.\n              If set to True, then the output of the dot product\n              is the cosine proximity between the two samples.\n\n\nScala example\n\n\ndef batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false)\n\n\n\n\nPython example\n\n\ndef batch_dot(x, y, axes=1, normalize=False)\n\n\n\n\nl2_normalize\n\n\nNormalizes a tensor wrt the L2 norm alongside the specified axis.\n- \nx\n A variable.\n- \naxis\n Axis along which to perform normalization.\n\n\nScala example\n\n\ndef l2Normalize[T: ClassTag](x: Variable[T], axis: Int)\n\n\n\n\nPython example\n\n\ndef l2_normalize(x, axis)",
            "title": "Autograd-Math"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#mean",
            "text": "Mean of a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepDims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keepDims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  mean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  mean(x, axis=0, keepDims=False):",
            "title": "mean"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#abs",
            "text": "Element-wise absolute value.\n-  x  A  Variable .  Scala example  abs(x: Variable[T])  Python example  abs(x):",
            "title": "abs"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#sum",
            "text": "Sum of the values in a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepDims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keepDims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  sum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  sum(x, axis=0, keepDims=False):",
            "title": "sum"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#clip",
            "text": "Element-wise value clipping.\n-  x  A  Variable .\n-  min  Double\n-  max  Double  Scala example  clip(x: Variable[T], min: Double, max: Double)  Python example  clip(x, min, max)",
            "title": "clip"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#square",
            "text": "Element-wise square.\n-  x  A  Variable .  Scala example  square(x: Variable[T])  Python example  square(x):",
            "title": "square"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#sqrt",
            "text": "Element-wise square root.\n-  x  A  Variable .  Scala example  sqrt(x: Variable[T])  Python example  sqrt(x):",
            "title": "sqrt"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#maximum",
            "text": "Element-wise maximum of two  Variables .\n-  x  A  Variable .\n-  y  A  Variable  or Double.  Scala example  maximum(x: Variable[T], y: Variable[T])  Python example  maximum(x, y):",
            "title": "maximum"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#log",
            "text": "Element-wise log.\n-  x  A  Variable .  Scala example  log(x: Variable[T])  Python example  log(x):",
            "title": "log"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#exp",
            "text": "Element-wise exponential.\n-  x  A  Variable .  Scala example  exp(x: Variable[T])  Python example  exp(x):",
            "title": "exp"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#pow",
            "text": "Element-wise exponentiation.\n-  x  A  Variable .\n-  a  Double.     Scala example  pow(x: Variable[T])  Python example  pow(x):",
            "title": "pow"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#softsign",
            "text": "Softsign of a  Variable .  Scala example  softsign(x: Variable[T])  Python example  softsign(x):",
            "title": "softsign"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#softplus",
            "text": "Softplus of a  Variable .  Scala example  softplus(x: Variable[T])  Python example  softplus(x):",
            "title": "softplus"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#stack",
            "text": "Stacks a list of rank  R  tensors into a rank  R+1  tensor.\n   You should start from 1 as dim 0 is for batch.\n   - inputs: List of variables (tensors)\n   - axis: xis along which to perform stacking.  Scala example  def stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1)  Python example  def stack(inputs, axis=1)",
            "title": "stack"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#expand_dims",
            "text": "Adds a 1-sized dimension at index \"axis\".  Scala example  def expandDims[T: ClassTag](x: Variable[T], axis: Int)  Python example  expand_dims(x, axis)",
            "title": "expand_dims"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#contiguous",
            "text": "Turn the output and grad to be contiguous for the input Variable  Scala example  def contiguous[T: ClassTag](input: Variable[T])  Python example  def contiguous(x)",
            "title": "contiguous"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#mm",
            "text": "Module to perform matrix multiplication on two mini-batch inputs, producing a mini-batch.\n-  x  A variable.\n-  y  A variable.\n-  axes  Axes along which to perform multiplication.  Scala example  def mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int])  Python example  def mm(x, y, axes)",
            "title": "mm"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#batch_dot",
            "text": "Operator that computes a dot product between samples in two tensors.\n-  x  Shape should only be [batch, xx]\n-  y  Shape should only be [batch, xx]\n-  axes  Integer or tuple of integers, axis or axes along which to take the dot product.\n-  normalize  Whether to L2-normalize samples along the\n              dot product axis before taking the dot product.\n              If set to True, then the output of the dot product\n              is the cosine proximity between the two samples.  Scala example  def batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false)  Python example  def batch_dot(x, y, axes=1, normalize=False)",
            "title": "batch_dot"
        },
        {
            "location": "/APIGuide/PipelineAPI/math/#l2_normalize",
            "text": "Normalizes a tensor wrt the L2 norm alongside the specified axis.\n-  x  A variable.\n-  axis  Axis along which to perform normalization.  Scala example  def l2Normalize[T: ClassTag](x: Variable[T], axis: Int)  Python example  def l2_normalize(x, axis)",
            "title": "l2_normalize"
        },
        {
            "location": "/APIGuide/PipelineAPI/variable/",
            "text": "Basic operators: \n+ - * /\n\n\nThose are supported as element-wise operation.\n\n\nScala example\n\n\nx + 1.0\nx + y\n\n\n\n\nPython example\n\n\nx + 1.0\nx + y\n\n\n\n\nsqueeze\n\n\nDelete the singleton dimension(s).\n   The batch dimension needs to be unchanged.\n   For example, if input has size (2, 1, 3, 4, 1):\n   - squeeze(dim = 1) will give output size (2, 3, 4, 1)\n   - squeeze(dims = null) will give output size (2, 3, 4)\n\n\nScala example\n\n\nx.squeeze(1)\n\n\n\n\nPython example\n\n\nx.squeeze(1)\n\n\n\n\nslice\n\n\nSlice the input with the number of dimensions not being reduced.\nThe batch dimension needs to be unchanged.\n- dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension.\n     -1 means the last dimension of the input.\n- startIndex Non-negative integer. The start index on the given dimension. 0-based index.\n- length The length to be sliced. Default is 1.\n\n\nFor example, \nif input is:\n1 2 3\n4 5 6\n- slice(1, 1, 2) will give output\n2 3\n5 6\n- slice(1, 2, -1) will give output\n3\n6\n\n\nScala example\n\n\nx.slice(1, 1, 2)\n\n\n\n\nPython example\n\n\nx.slice(1, 1, 2)\n\n\n\n\nindex_select\n\n\nSelect an index of the input in the given dim and return the subset part.\n The batch dimension needs to be unchanged.\n The selected dim would be remove after this operation.\n - dim: The dimension to select. 0-based index. Cannot select the batch dimension.\n                 -1 means the last dimension of the input.\n - index: The index of the dimension to be selected. 0-based index.\n                -1 means the last dimension of the input.\n\n\nFor example, if input is:\n           1 2 3\n           4 5 6\n - Select(1, 1) will give output [2 5]\n - Select(1, -1) will give output [3 6]\n\n\nScala example\n\n\nx.select(1, 1)\n\n\n\n\nPython example\n\n\nx.select(1, 1)",
            "title": "Autograd-Variable"
        },
        {
            "location": "/APIGuide/PipelineAPI/variable/#basic-operators-",
            "text": "Those are supported as element-wise operation.  Scala example  x + 1.0\nx + y  Python example  x + 1.0\nx + y",
            "title": "Basic operators: + - * /"
        },
        {
            "location": "/APIGuide/PipelineAPI/variable/#squeeze",
            "text": "Delete the singleton dimension(s).\n   The batch dimension needs to be unchanged.\n   For example, if input has size (2, 1, 3, 4, 1):\n   - squeeze(dim = 1) will give output size (2, 3, 4, 1)\n   - squeeze(dims = null) will give output size (2, 3, 4)  Scala example  x.squeeze(1)  Python example  x.squeeze(1)",
            "title": "squeeze"
        },
        {
            "location": "/APIGuide/PipelineAPI/variable/#slice",
            "text": "Slice the input with the number of dimensions not being reduced.\nThe batch dimension needs to be unchanged.\n- dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension.\n     -1 means the last dimension of the input.\n- startIndex Non-negative integer. The start index on the given dimension. 0-based index.\n- length The length to be sliced. Default is 1.  For example, \nif input is:\n1 2 3\n4 5 6\n- slice(1, 1, 2) will give output\n2 3\n5 6\n- slice(1, 2, -1) will give output\n3\n6  Scala example  x.slice(1, 1, 2)  Python example  x.slice(1, 1, 2)",
            "title": "slice"
        },
        {
            "location": "/APIGuide/PipelineAPI/variable/#index_select",
            "text": "Select an index of the input in the given dim and return the subset part.\n The batch dimension needs to be unchanged.\n The selected dim would be remove after this operation.\n - dim: The dimension to select. 0-based index. Cannot select the batch dimension.\n                 -1 means the last dimension of the input.\n - index: The index of the dimension to be selected. 0-based index.\n                -1 means the last dimension of the input.  For example, if input is:\n           1 2 3\n           4 5 6\n - Select(1, 1) will give output [2 5]\n - Select(1, -1) will give output [3 6]  Scala example  x.select(1, 1)  Python example  x.select(1, 1)",
            "title": "index_select"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/",
            "text": "Net\n\n\nLoad Analytics Zoo Model\n\n\nUse \nNet.load\n(in Scala) or \nNet.load\n (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.  \nNet\n (Scala) or \nNet\n(Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.\n\n\nScala example\n\n\nval model = Net.load(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nval model = Net.load(\"hdfs://...\") //load from hdfs\nval model = Net.load(\"s3://...\") //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.load(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nmodel = Net.load(\"hdfs://...\") //load from hdfs\nmodel = Net.load(\"s3://...\") //load from s3\n\n\n\n\nLoad BigDL Model\n\n\nScala example\n\n\nval model = Net.loadBigDL(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nval model = Net.loadBigDL(\"hdfs://...\") //load from hdfs\nval model = Net.loadBigDL(\"s3://...\") //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadBigDL(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nmodel = Net.loadBigDL(\"hdfs://...\") //load from hdfs\nmodel = Net.loadBigDL(\"s3://...\") //load from s3\n\n\n\n\nLoad Torch Model\n\n\nScala example\n\n\nval model = Net.loadTorch(\"/tmp/torch_model\") //load from local fs\nval model = Net.loadTorch(\"hdfs://...\") //load from hdfs\nval model = Net.loadTorch(\"s3://...\") //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadTorch(\"/tmp/torch_model\") //load from local fs\nmodel = Net.loadTorch(\"hdfs://...\") //load from hdfs\nmodel = Net.loadTorch(\"s3://...\") //load from s3\n\n\n\n\nLoad Caffe Model\n\n\nScala example\n\n\nval model = Net.loadCaffe(\"/tmp/def/path\", \"/tmp/model/path\") //load from local fs\nval model = Net.loadCaffe(\"hdfs://def/path\", \"hdfs://model/path\") //load from hdfs\nval model = Net.loadCaffe(\"s3://def/path\", \"s3://model/path\") //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadCaffe(\"/tmp/def/path\", \"/tmp/model/path\") //load from local fs\nmodel = Net.loadCaffe(\"hdfs://def/path\", \"hdfs://model/path\") //load from hdfs\nmodel = Net.loadCaffe(\"s3://def/path\", \"s3://model/path\") //load from s3\n\n\n\n\nTFNet\n\n\nTFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel.\n\n\nTFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model.\nWhen used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient\nfrom TFNet is set to zero.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nExport TensorFlow model to frozen inference graph\n\n\nAnalytics-zoo provides a useful utility function, \nexport_tf\n, to export a TensorFlow model\nto frozen inference graph.\n\n\nFor example:\n\n\nPython:\n\n\nimport tensorflow as tf\nfrom nets import inception\nslim = tf.contrib.slim\n\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3))\n\nwith slim.arg_scope(inception.inception_v1_arg_scope()):\n    logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \"/tmp/models/inception_v1.ckpt\")\n\nfrom zoo.util.tf import export_tf\nexport_tf(sess, \"/tmp/models/tfnet\", inputs=[images], outputs=[logits])\n\n\n\n\nIn the above code, the \nexport_tf\n utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names. \n\n\nCreating a TFNet\n\n\nAfter we have export the TensorFlow model, we can easily create a TFNet.\n\n\nScala:\n\n\nval m = TFNet(\"/tmp/models/tfnet\")\n\n\n\n\nPython:\n\n\nm = TFNet.from_export_folder(\"/tmp/models/tfnet\")\n\n\n\n\nPlease refer to \nTFNet Object Detection Example (Scala)\n\nor \nTFNet Object Detection Example (Python)\n and\nthe \nImage Classification Using TFNet Notebook\n for more information.",
            "title": "Net"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#net",
            "text": "",
            "title": "Net"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#load-analytics-zoo-model",
            "text": "Use  Net.load (in Scala) or  Net.load  (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.   Net  (Scala) or  Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.  Scala example  val model = Net.load(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nval model = Net.load(\"hdfs://...\") //load from hdfs\nval model = Net.load(\"s3://...\") //load from s3  Python example  model = Net.load(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nmodel = Net.load(\"hdfs://...\") //load from hdfs\nmodel = Net.load(\"s3://...\") //load from s3",
            "title": "Load Analytics Zoo Model"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#load-bigdl-model",
            "text": "Scala example  val model = Net.loadBigDL(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nval model = Net.loadBigDL(\"hdfs://...\") //load from hdfs\nval model = Net.loadBigDL(\"s3://...\") //load from s3  Python example  model = Net.loadBigDL(\"/tmp/model.def\", \"/tmp/model.weights\") //load from local fs\nmodel = Net.loadBigDL(\"hdfs://...\") //load from hdfs\nmodel = Net.loadBigDL(\"s3://...\") //load from s3",
            "title": "Load BigDL Model"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#load-torch-model",
            "text": "Scala example  val model = Net.loadTorch(\"/tmp/torch_model\") //load from local fs\nval model = Net.loadTorch(\"hdfs://...\") //load from hdfs\nval model = Net.loadTorch(\"s3://...\") //load from s3  Python example  model = Net.loadTorch(\"/tmp/torch_model\") //load from local fs\nmodel = Net.loadTorch(\"hdfs://...\") //load from hdfs\nmodel = Net.loadTorch(\"s3://...\") //load from s3",
            "title": "Load Torch Model"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#load-caffe-model",
            "text": "Scala example  val model = Net.loadCaffe(\"/tmp/def/path\", \"/tmp/model/path\") //load from local fs\nval model = Net.loadCaffe(\"hdfs://def/path\", \"hdfs://model/path\") //load from hdfs\nval model = Net.loadCaffe(\"s3://def/path\", \"s3://model/path\") //load from s3  Python example  model = Net.loadCaffe(\"/tmp/def/path\", \"/tmp/model/path\") //load from local fs\nmodel = Net.loadCaffe(\"hdfs://def/path\", \"hdfs://model/path\") //load from hdfs\nmodel = Net.loadCaffe(\"s3://def/path\", \"s3://model/path\") //load from s3",
            "title": "Load Caffe Model"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#tfnet",
            "text": "TFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel.  TFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model.\nWhen used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient\nfrom TFNet is set to zero.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .",
            "title": "TFNet"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#export-tensorflow-model-to-frozen-inference-graph",
            "text": "Analytics-zoo provides a useful utility function,  export_tf , to export a TensorFlow model\nto frozen inference graph.  For example:  Python:  import tensorflow as tf\nfrom nets import inception\nslim = tf.contrib.slim\n\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3))\n\nwith slim.arg_scope(inception.inception_v1_arg_scope()):\n    logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \"/tmp/models/inception_v1.ckpt\")\n\nfrom zoo.util.tf import export_tf\nexport_tf(sess, \"/tmp/models/tfnet\", inputs=[images], outputs=[logits])  In the above code, the  export_tf  utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names.",
            "title": "Export TensorFlow model to frozen inference graph"
        },
        {
            "location": "/APIGuide/PipelineAPI/net/#creating-a-tfnet",
            "text": "After we have export the TensorFlow model, we can easily create a TFNet.  Scala:  val m = TFNet(\"/tmp/models/tfnet\")  Python:  m = TFNet.from_export_folder(\"/tmp/models/tfnet\")  Please refer to  TFNet Object Detection Example (Scala) \nor  TFNet Object Detection Example (Python)  and\nthe  Image Classification Using TFNet Notebook  for more information.",
            "title": "Creating a TFNet"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/",
            "text": "Inference Model is a package in Analytics Zoo aiming to provide high-level APIs to speed-up development. It allows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). Inference Model provides Java, Scala and Python interfaces.\n\n\nHighlights\n\n\n\n\nEasy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\n\n\nSupport transformation of various input data type, thus supporting future prediction tasks.\n\n\nTransparently support the OpenVINO toolkit, which deliver a significant boost for inference speed (\nup to 19.9x\n).\n\n\n\n\nBasic usage of Inference Model:\n\n\n\n\nDirectly use InferenceModel or write a subclass extends \nInferenceModel\n (\nAbstractInferenceModel\n in Java).\n\n\nLoad pre-trained models with corresponding \nload\n methods, e.g, \ndoLoadBigDL\n for Analytics Zoo, and \ndoLoadTensorflow\n for TensorFlow.\n\n\nDo prediction with \npredict\n method.\n\n\n\n\nOpenVINO requirements:\n\n\nSystem requirements\n:\n\n\nUbuntu 16.04.3 LTS or higher (64 bit)\nCentOS 7.6 or higher (64 bit)\nmacOS 10.14 or higher (64 bit)\n\n\n\nPython requirements:\n\n\ntensorflow>=1.2.0,<2.0.0\nnetworkx>=1.11\nnumpy>=1.12.0\ndefusedxml>=0.5.0\ntest-generator>=0.1.1\n\n\n\nSupported models:\n\n\n\n\nAnalytics Zoo Models\n\n\nCaffe Models\n\n\nTensorFlow Models\n\n\nOpenVINO models\n\n\n\n\nLoad pre-trained model\n\n\nLoad pre-trained Analytics Zoo model\n\n\nLoad Analytics Zoo model with corresponding \nload\n methods (\nload\n for Java and Python, \ndoLoad\n for Scala).\n\n\nJava\n\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadBigDL(modelPath, weightPath);\n\n\n\n\nScala\n\n\nval model = new InferenceModel()\nmodel.doLoadBigDL(modelPath, weightPath)\n\n\n\n\nPython\n\n\nmodel = InferenceModel()\nmodel.load_bigdl(modelPath, weightPath)\n\n\n\n\n\n\nmodelPath\n: String. Path of pre-trained model.\n\n\nweightPath\n: String. Path of pre-trained model weight. Default is \nnull\n.\n\n\n\n\nLoad pre-trained Caffe model\n\n\nLoad Caffe model with \nloadCaffe\n methods (\nloadCaffe\n for Java, \ndoLoadCaffe\n for Scala and \nload_caffe\n Python).\n\n\nJava\n\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadCaffe(modelPath, weightPath);\n\n\n\n\nScala\n\n\nval model = new InferenceModel()\nmodel.doLoadCaffe(modelPath, weightPath)\n\n\n\n\nPython\n\n\nmodel = InferenceModel()\nmodel.load_caffe(modelPath, weightPath)\n\n\n\n\n\n\nmodelPath\n: String. Path of pre-trained model.\n\n\nweightPath\n: String. Path of pre-trained model weight.\n\n\n\n\nLoad pre-trained TensorFlow model\n\n\nLoad model into \nTFNet\n with corresponding \nloadTensorflow\n methods (\nloadTensorflow\n for Java, \ndoLoadTensorflow\n for Scala and \nload_tensorflow\n for Python)\n\n\nWe provide \nloadTensorflow\n with the following parameters:\n\n\n\n\nmodelPath\n: String. Path of pre-trained model.\n\n\nmodelType\n: String. Type of pre-trained model file.\n\n\nInputs\n: Array[String]. The inputs of the model.\n\n\nOutputs\n: Array[String]. The outputs of the model.\n\n\nintraOpParallelismThreads\n: Int. The number of intraOpParallelismThreads.\n\n\ninterOpParallelismThreads\n: Int. The number of interOpParallelismThreads.\n\n\nusePerSessionThreads\n: Boolean. Whether to perSessionThreads\n\n\n\n\nNote that we prepare several implementations with less parameters based on this method, e.g., \nloadTensorflow(modelPath, modelType)\n for frozenModel.\n\n\nJava\n\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadTensorflow(modelPath, modelType);\n\n\n\n\nScala\n\n\nval model = new InferenceModel()\nmodel.doLoadTensorflow(modelPath, modelType)\n\n\n\n\nPython\n\n\nmodel = InferenceModel()\nmodel.load_tensorflow(modelPath, modelType)\n\n\n\n\nLoad OpenVINO model\n\n\nLoad OpenVINO model with \nloadOpenVINO\n methods (\nloadOpenVINO\n for Java, \ndoLoadOpenVINO\n for Scala and \nload_openvino\n Python).\n\n\nJava\n\n\npublic class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadOpenVINO(modelPath, weightPath);\n\n\n\n\nScala\n\n\nval model = new InferenceModel()\nmodel.doLoadOpenVINO(modelPath, weightPath)\n\n\n\n\nPython\n\n\nmodel = InferenceModel()\nmodel.load_openvino(modelPath, weightPath)\n\n\n\n\n\n\nmodelPath\n: String. Path of pre-trained OpenVINO model.\n\n\nweightPath\n: String. Path of pre-trained OpenVINO model weight.\n\n\n\n\nPredict with loaded model\n\n\nAfter loading pre-trained models with load methods, we can make prediction with unified \npredict\n method.\n\n\n\n\npredictInput\n: JList[JList[JTensor]] or \nTensor\n for Scale and Java, Numpy for Python. Input data for prediction. \nJTensor\n is a 1D List, with Array[Int] shape.\n\n\npredictOutput\n: JList[JList[JTensor]] or \nTensor\n for Scale and Java, Numpy for Python. Prediction result.\n\n\n\n\nDo prediction with \npredict\n methods (\npredict\n for Java and Python, \ndoPredict\n for Scala).\n\n\nJava\n\n\nList<List<JTensor>> predictOutput = model.predict(predictInput);\n\n\n\n\nScala\n\n\nval predictOutput = model.doPredict(predictInput)\n\n\n\n\nPython\n\n\npredict_output = model.predict(predict_input)",
            "title": "Inference"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#load-pre-trained-model",
            "text": "",
            "title": "Load pre-trained model"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#load-pre-trained-analytics-zoo-model",
            "text": "Load Analytics Zoo model with corresponding  load  methods ( load  for Java and Python,  doLoad  for Scala).  Java  public class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadBigDL(modelPath, weightPath);  Scala  val model = new InferenceModel()\nmodel.doLoadBigDL(modelPath, weightPath)  Python  model = InferenceModel()\nmodel.load_bigdl(modelPath, weightPath)   modelPath : String. Path of pre-trained model.  weightPath : String. Path of pre-trained model weight. Default is  null .",
            "title": "Load pre-trained Analytics Zoo model"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#load-pre-trained-caffe-model",
            "text": "Load Caffe model with  loadCaffe  methods ( loadCaffe  for Java,  doLoadCaffe  for Scala and  load_caffe  Python).  Java  public class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadCaffe(modelPath, weightPath);  Scala  val model = new InferenceModel()\nmodel.doLoadCaffe(modelPath, weightPath)  Python  model = InferenceModel()\nmodel.load_caffe(modelPath, weightPath)   modelPath : String. Path of pre-trained model.  weightPath : String. Path of pre-trained model weight.",
            "title": "Load pre-trained Caffe model"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#load-pre-trained-tensorflow-model",
            "text": "Load model into  TFNet  with corresponding  loadTensorflow  methods ( loadTensorflow  for Java,  doLoadTensorflow  for Scala and  load_tensorflow  for Python)  We provide  loadTensorflow  with the following parameters:   modelPath : String. Path of pre-trained model.  modelType : String. Type of pre-trained model file.  Inputs : Array[String]. The inputs of the model.  Outputs : Array[String]. The outputs of the model.  intraOpParallelismThreads : Int. The number of intraOpParallelismThreads.  interOpParallelismThreads : Int. The number of interOpParallelismThreads.  usePerSessionThreads : Boolean. Whether to perSessionThreads   Note that we prepare several implementations with less parameters based on this method, e.g.,  loadTensorflow(modelPath, modelType)  for frozenModel.  Java  public class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadTensorflow(modelPath, modelType);  Scala  val model = new InferenceModel()\nmodel.doLoadTensorflow(modelPath, modelType)  Python  model = InferenceModel()\nmodel.load_tensorflow(modelPath, modelType)",
            "title": "Load pre-trained TensorFlow model"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#load-openvino-model",
            "text": "Load OpenVINO model with  loadOpenVINO  methods ( loadOpenVINO  for Java,  doLoadOpenVINO  for Scala and  load_openvino  Python).  Java  public class ExtendedInferenceModel extends AbstractInferenceModel {\n}\nExtendedInferenceModel model = new ExtendedInferenceModel();\nmodel.loadOpenVINO(modelPath, weightPath);  Scala  val model = new InferenceModel()\nmodel.doLoadOpenVINO(modelPath, weightPath)  Python  model = InferenceModel()\nmodel.load_openvino(modelPath, weightPath)   modelPath : String. Path of pre-trained OpenVINO model.  weightPath : String. Path of pre-trained OpenVINO model weight.",
            "title": "Load OpenVINO model"
        },
        {
            "location": "/APIGuide/PipelineAPI/inference/#predict-with-loaded-model",
            "text": "After loading pre-trained models with load methods, we can make prediction with unified  predict  method.   predictInput : JList[JList[JTensor]] or  Tensor  for Scale and Java, Numpy for Python. Input data for prediction.  JTensor  is a 1D List, with Array[Int] shape.  predictOutput : JList[JList[JTensor]] or  Tensor  for Scale and Java, Numpy for Python. Prediction result.   Do prediction with  predict  methods ( predict  for Java and Python,  doPredict  for Scala).  Java  List<List<JTensor>> predictOutput = model.predict(predictInput);  Scala  val predictOutput = model.doPredict(predictInput)  Python  predict_output = model.predict(predict_input)",
            "title": "Predict with loaded model"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/",
            "text": "Estimator\n\n\nEstimator\n supports the training and evaluation of BigDL models, Keras-like models and PyTorch models. It wraps a model, and provide a uniform training, evaluation, or prediction operation on both localhost and distributed spark environment.\n\n\nCreating an Estimator\n\n\nIn summary, you need to supply three parameters to create an Estimator: 1)a model, 2) optimMethod\n(s), 3) model directory, as shown below:\n\n\nScala:\n\n\nval estimator = Estimator[T: ClassTag](\n      model: Module[T], \n      optimMethods: Map[String, OptimMethod[T]] = Map(), \n      modelDir: Option[String] = None)\n\n\n\n\nT\n: the numeric type(Float/Double).\n\n\nmodel\n: the model will be optimized.\n\n\noptimMethods\n: the methods to optimize the model. Submodule names and optimMethod pairs.\n\n\nmodelDir\n(Optional): model checkpoint directory, and related summary directory.\n\n\nval estimator = Estimator[T: ClassTag](\n      model: Module[T],\n      optimMethod: OptimMethod[T],\n      modelDir: Option[String] = None)\n\n\n\n\n\nT\n: the numeric type(Float/Double).\n\n\nmodel\n: the model will be optimized.\n\n\noptimMethod\n: the method to optimize the model.\n\n\nmodelDir\n(Optional): model checkpoint directory, and related summary directory.\n\n\nPython:\n\n\nestimator = Estimator(model, optim_methods, model_dir)\n\n\n\n\n\nmodel\n: the model will be optimized.\n\n\noptim_methods\n: the methods to optimize the model. Both single optimMethod and Dict(submodule \nname, optimMethod) are supported.\n\n\nmodel_dir\n(Optional): model checkpoint directory, and related summary directory.\n\n\nTraining\n\n\nTrain the model with provided trainSet and criterion. The training will end when the endTrigger is \ntriggered. During the training, if the checkPointTrigger is defined and triggered, the model will be saved to modelDir. And if validationSet and validationMethod are defined, the model will be evaluated at the checkpoint.\n\n\nScala:\n\n\nestimator.train(trainSet: FeatureSet[MiniBatch[T]],\n            criterion: Criterion[T],\n            endTrigger: Option[Trigger] = None,\n            checkPointTrigger: Option[Trigger] = None,\n            validationSet: FeatureSet[MiniBatch[T]] = null,\n            validationMethod: Array[ValidationMethod[T]] = null)\n\n\n\n\ntrainSet\n: training dataset in type of FeatureSet[MiniBatch].\n\n\ncriterion\n: loss function.\n\n\nendTrigger\n: when to finish the training.\n\n\ncheckPointTrigger\n: how often to save a checkpoint and evaluate the model.\n\n\nvalidationSet\n: validation dataset in type of FeatureSet[MiniBatch].\n\n\nvalidationMethod\n: a set of validationMethod.\n\n\nPython:\n\n\nTrain Samples\n\n\nestimator.train(train_set, criterion, end_trigger, checkpoint_trigger,\n              validation_set, validation_method, batch_size)\n\n\n\n\ntrain_set\n: training dataset in type of FeatureSet[Sample[T]].\n\n\ncriterion\n: loss function.\n\n\nend_trigger\n: when to finish the training.\n\n\ncheckpoint_trigger\n: how often to save a checkpoint and evaluate the model.\n\n\nvalidation_set\n: validation dataset in type of FeatureSet[Sample[T]].\n\n\nvalidation_method\n: a set of validationMethod.\n\n\nbatch_size\n: mini batch size.\n\n\nTrain ImageFeatures\n\n\nestimator.train_imagefeature(self, train_set, criterion, end_trigger, checkpoint_trigger,\n                           validation_set, validation_method, batch_size)\n\n\n\n\ntrain_set\n: training dataset in type of FeatureSet[ImageFeature].\n\n\ncriterion\n: loss function.\n\n\nend_trigger\n: when to finish the training.\n\n\ncheckpoint_trigger\n: how often to save a checkpoint and evaluate the model.\n\n\nvalidation_set\n: validation dataset in type of FeatureSet[ImageFeature].\n\n\nvalidation_method\n: a set of validationMethod.\n\n\nbatch_size\n: mini batch size.\n\n\nEvaluation\n\n\nEvaluate the model on the validationSet with the validationMethods.\n\n\nScala:\n\n\nestimator.evaluate(validationSet: FeatureSet[MiniBatch[T]],\n                   validationMethod: Array[ValidationMethod[T]])\n\n\n\n\nvalidationSet\n: validation dataset in type of FeatureSet.\n\n\nvalidationMethod\n: a set of validationMethod.\n\n\nPython:\n\n\nEvaluate Samples\n\n\nestimator.evaluate(validation_set, validation_method, batch_size)\n\n\n\n\nvalidation_set\n: validation dataset in type of FeatureSet[Sample[T]].\n\n\nvalidation_method\n: a set of validationMethod.\n\n\nbatch_size\n: mini batch size.\n\n\nTrain ImageFeatures\n\n\nestimator.evaluate_imagefeature(validation_set, validation_method, batch_size)\n\n\n\n\nvalidation_set\n: validation dataset in type of FeatureSet[ImageFeature].\n\n\nvalidation_method\n: a set of validationMethod.\n\n\nbatch_size\n: mini batch size.\n\n\nOther Important API\n\n\nsetConstantGradientClipping\n\n\nSet constant gradient clipping during the training process. In order to take effect, it needs to \nbe called before fit.\n\n\nScala:\n\n\nestimator.setConstantGradientClipping(min: Double, max: Double)\n\n\n\n\nmin\n: The minimum value to clip by. Double.\n\n\nmax\n: The maximum value to clip by. Double.\n\n\nPython:\n\n\nestimator.set_constant_gradient_clipping(min, max)\n\n\n\n\nmin\n: The minimum value to clip by. Double.\n\n\nmax\n: The maximum value to clip by. Double.\n\n\nsetGradientClippingByL2Norm\n\n\nSet clip gradient to a maximum L2-Norm during the training process. In order to take effect, it \nneeds to be called before fit.\n\n\nScala:\n\n\nestimator.setGradientClippingByL2Norm(clipNorm: Double)\n\n\n\n\nclipNorm\n: Gradient L2-Norm threshold. Double.\n\n\nPython:\n\n\nestimator.set_l2_norm_gradient_clipping(clip_norm)\n\n\n\n\nclip_norm\n: Gradient L2-Norm threshold. Double.\n\n\nclearGradientClipping\n\n\nClear gradient clipping parameters. In this case, gradient clipping will not be applied. In order\n to take effect, it needs to be called before fit.\n\n\nScala:\n\n \nscala\n estimator.clearGradientClipping()\n\n\nPython:\n\n \npython\nestimator.clear_gradient_clipping()\n\n\nExamples\n\n\nPlease refer to \nInception(Scala)\n or \nInception(Python)\n for \nmore information",
            "title": "Estimator"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#estimator",
            "text": "Estimator  supports the training and evaluation of BigDL models, Keras-like models and PyTorch models. It wraps a model, and provide a uniform training, evaluation, or prediction operation on both localhost and distributed spark environment.",
            "title": "Estimator"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#creating-an-estimator",
            "text": "In summary, you need to supply three parameters to create an Estimator: 1)a model, 2) optimMethod\n(s), 3) model directory, as shown below:  Scala:  val estimator = Estimator[T: ClassTag](\n      model: Module[T], \n      optimMethods: Map[String, OptimMethod[T]] = Map(), \n      modelDir: Option[String] = None)  T : the numeric type(Float/Double).  model : the model will be optimized.  optimMethods : the methods to optimize the model. Submodule names and optimMethod pairs.  modelDir (Optional): model checkpoint directory, and related summary directory.  val estimator = Estimator[T: ClassTag](\n      model: Module[T],\n      optimMethod: OptimMethod[T],\n      modelDir: Option[String] = None)  T : the numeric type(Float/Double).  model : the model will be optimized.  optimMethod : the method to optimize the model.  modelDir (Optional): model checkpoint directory, and related summary directory.  Python:  estimator = Estimator(model, optim_methods, model_dir)  model : the model will be optimized.  optim_methods : the methods to optimize the model. Both single optimMethod and Dict(submodule \nname, optimMethod) are supported.  model_dir (Optional): model checkpoint directory, and related summary directory.",
            "title": "Creating an Estimator"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#training",
            "text": "Train the model with provided trainSet and criterion. The training will end when the endTrigger is \ntriggered. During the training, if the checkPointTrigger is defined and triggered, the model will be saved to modelDir. And if validationSet and validationMethod are defined, the model will be evaluated at the checkpoint.  Scala:  estimator.train(trainSet: FeatureSet[MiniBatch[T]],\n            criterion: Criterion[T],\n            endTrigger: Option[Trigger] = None,\n            checkPointTrigger: Option[Trigger] = None,\n            validationSet: FeatureSet[MiniBatch[T]] = null,\n            validationMethod: Array[ValidationMethod[T]] = null)  trainSet : training dataset in type of FeatureSet[MiniBatch].  criterion : loss function.  endTrigger : when to finish the training.  checkPointTrigger : how often to save a checkpoint and evaluate the model.  validationSet : validation dataset in type of FeatureSet[MiniBatch].  validationMethod : a set of validationMethod.  Python:",
            "title": "Training"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#train-samples",
            "text": "estimator.train(train_set, criterion, end_trigger, checkpoint_trigger,\n              validation_set, validation_method, batch_size)  train_set : training dataset in type of FeatureSet[Sample[T]].  criterion : loss function.  end_trigger : when to finish the training.  checkpoint_trigger : how often to save a checkpoint and evaluate the model.  validation_set : validation dataset in type of FeatureSet[Sample[T]].  validation_method : a set of validationMethod.  batch_size : mini batch size.",
            "title": "Train Samples"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#train-imagefeatures",
            "text": "estimator.train_imagefeature(self, train_set, criterion, end_trigger, checkpoint_trigger,\n                           validation_set, validation_method, batch_size)  train_set : training dataset in type of FeatureSet[ImageFeature].  criterion : loss function.  end_trigger : when to finish the training.  checkpoint_trigger : how often to save a checkpoint and evaluate the model.  validation_set : validation dataset in type of FeatureSet[ImageFeature].  validation_method : a set of validationMethod.  batch_size : mini batch size.",
            "title": "Train ImageFeatures"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#evaluation",
            "text": "Evaluate the model on the validationSet with the validationMethods.  Scala:  estimator.evaluate(validationSet: FeatureSet[MiniBatch[T]],\n                   validationMethod: Array[ValidationMethod[T]])  validationSet : validation dataset in type of FeatureSet.  validationMethod : a set of validationMethod.  Python:",
            "title": "Evaluation"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#evaluate-samples",
            "text": "estimator.evaluate(validation_set, validation_method, batch_size)  validation_set : validation dataset in type of FeatureSet[Sample[T]].  validation_method : a set of validationMethod.  batch_size : mini batch size.",
            "title": "Evaluate Samples"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#train-imagefeatures_1",
            "text": "estimator.evaluate_imagefeature(validation_set, validation_method, batch_size)  validation_set : validation dataset in type of FeatureSet[ImageFeature].  validation_method : a set of validationMethod.  batch_size : mini batch size.",
            "title": "Train ImageFeatures"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#other-important-api",
            "text": "",
            "title": "Other Important API"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#setconstantgradientclipping",
            "text": "Set constant gradient clipping during the training process. In order to take effect, it needs to \nbe called before fit.  Scala:  estimator.setConstantGradientClipping(min: Double, max: Double)  min : The minimum value to clip by. Double.  max : The maximum value to clip by. Double.  Python:  estimator.set_constant_gradient_clipping(min, max)  min : The minimum value to clip by. Double.  max : The maximum value to clip by. Double.",
            "title": "setConstantGradientClipping"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#setgradientclippingbyl2norm",
            "text": "Set clip gradient to a maximum L2-Norm during the training process. In order to take effect, it \nneeds to be called before fit.  Scala:  estimator.setGradientClippingByL2Norm(clipNorm: Double)  clipNorm : Gradient L2-Norm threshold. Double.  Python:  estimator.set_l2_norm_gradient_clipping(clip_norm)  clip_norm : Gradient L2-Norm threshold. Double.",
            "title": "setGradientClippingByL2Norm"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#cleargradientclipping",
            "text": "Clear gradient clipping parameters. In this case, gradient clipping will not be applied. In order\n to take effect, it needs to be called before fit.  Scala: \n  scala\n estimator.clearGradientClipping()  Python: \n  python\nestimator.clear_gradient_clipping()",
            "title": "clearGradientClipping"
        },
        {
            "location": "/APIGuide/PipelineAPI/estimator/#examples",
            "text": "Please refer to  Inception(Scala)  or  Inception(Python)  for \nmore information",
            "title": "Examples"
        },
        {
            "location": "/APIGuide/TFPark/model/",
            "text": "KerasModel\n\n\nKerasModel enables user to use \ntf.keras\n API to define TensorFlow models and perform training or evaluation on top\nof Spark and BigDL in a distributed fashion.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nfrom zoo.tfpark import KerasModel, TFDataset\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential(\n    [tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n     tf.keras.layers.Dense(64, activation='relu'),\n     tf.keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nkeras_model = KerasModel(model)\n\n\n\n\nMethods\n\n\n__init__\n\n\nKerasModel(model)\n\n\n\n\nArguments\n\n\n\n\nmodel\n: a compiled keras model defined using \ntf.keras\n\n\n\n\nfit\n\n\nfit(x=None, y = None, batch_size=None, epochs=1, validation_data=None, distributed=False)\n\n\n\n\nArguments\n\n\n\n\n\n\nx\n: Input data. It could be:\n\n\n - a TFDataset object\n - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).\n - A dict mapping input names to the corresponding array/tensors, if the model has named inputs.\n\n\n\n\n\n\n\ny\n: Target data. Like the input data \nx\n,\n         It should be consistent with \nx\n (you cannot have Numpy inputs and\n         tensor targets, or inversely). If \nx\n is a TFDataset, \ny\n should\n         not be specified (since targets will be obtained from \nx\n).\n\n\n\n\n\n\nbatch_size\n: Integer or \nNone\n.\n                  Number of samples per gradient update.\n                  If \nx\n is a TFDataset, you do not need to specify batch_size.\n\n\n\n\n\n\nepochs\n: Integer. Number of epochs to train the model.\n              An epoch is an iteration over the entire \nx\n and \ny\n\n              data provided.\n\n\n\n\n\n\nvalidation_data\n: validation_data: Data on which to evaluate\n                       the loss and any model metrics at the end of each epoch.\n                       The model will not be trained on this data.\n                       \nvalidation_data\n could be:\n                          - tuple \n(x_val, y_val)\n of Numpy arrays or tensors\n\n\n\n\n\n\ndistributed\n: Boolean. Whether to do prediction in distributed mode or local mode.\n                   Default is True. In local mode, x must be a Numpy array.\n\n\n\n\n\n\nevaluate\n\n\nevaluate(x=None, y=None, bath_per_thread=None, distributed=False)\n\n\n\n\nArguments\n\n\n\n\nx\n: Input data. It could be:\n    - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,\n    if the model has named inputs.\n\n\n\n\n\ny\n: Target data. Like the input data \nx\n,\n     It should be consistent with \nx\n (you cannot have Numpy inputs and\n     tensor targets, or inversely). If \nx\n is a TFDataset, \ny\n should\n     not be specified (since targets will be obtained from \nx\n).\n\n\nbatch_per_thread\n:\n      The default value is 1.\n      When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n      When distributed is False the total batch size is batch_per_thread * numOfCores.\n\n\ndistributed\n: Boolean. Whether to do prediction in distributed mode or local mode.\n               Default is True. In local mode, x must be a Numpy array.\n\n\n\n\n\n\n\n\npredict\n\n\npredict(x, batch_per_thread=None, distributed=False):\n\n\n\n\nArguments\n\n\n\n\nx\n: Input data. It could be:\n    - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,\n\n\n\n\n\nbatch_per_thread\n:\n      The default value is 1.\n      When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n      When distributed is False the total batch size is batch_per_thread * numOfCores.\n\n\ndistributed\n: Boolean. Whether to do prediction in distributed mode or local mode.\n                Default is True. In local mode, x must be a Numpy array.",
            "title": "KerasModel"
        },
        {
            "location": "/APIGuide/TFPark/model/#kerasmodel",
            "text": "KerasModel enables user to use  tf.keras  API to define TensorFlow models and perform training or evaluation on top\nof Spark and BigDL in a distributed fashion.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .   from zoo.tfpark import KerasModel, TFDataset\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential(\n    [tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n     tf.keras.layers.Dense(64, activation='relu'),\n     tf.keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nkeras_model = KerasModel(model)",
            "title": "KerasModel"
        },
        {
            "location": "/APIGuide/TFPark/model/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/TFPark/model/#__init__",
            "text": "KerasModel(model)",
            "title": "__init__"
        },
        {
            "location": "/APIGuide/TFPark/model/#arguments",
            "text": "model : a compiled keras model defined using  tf.keras",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/model/#fit",
            "text": "fit(x=None, y = None, batch_size=None, epochs=1, validation_data=None, distributed=False)",
            "title": "fit"
        },
        {
            "location": "/APIGuide/TFPark/model/#arguments_1",
            "text": "x : Input data. It could be:   - a TFDataset object\n - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).\n - A dict mapping input names to the corresponding array/tensors, if the model has named inputs.    y : Target data. Like the input data  x ,\n         It should be consistent with  x  (you cannot have Numpy inputs and\n         tensor targets, or inversely). If  x  is a TFDataset,  y  should\n         not be specified (since targets will be obtained from  x ).    batch_size : Integer or  None .\n                  Number of samples per gradient update.\n                  If  x  is a TFDataset, you do not need to specify batch_size.    epochs : Integer. Number of epochs to train the model.\n              An epoch is an iteration over the entire  x  and  y \n              data provided.    validation_data : validation_data: Data on which to evaluate\n                       the loss and any model metrics at the end of each epoch.\n                       The model will not be trained on this data.\n                        validation_data  could be:\n                          - tuple  (x_val, y_val)  of Numpy arrays or tensors    distributed : Boolean. Whether to do prediction in distributed mode or local mode.\n                   Default is True. In local mode, x must be a Numpy array.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/model/#evaluate",
            "text": "evaluate(x=None, y=None, bath_per_thread=None, distributed=False)",
            "title": "evaluate"
        },
        {
            "location": "/APIGuide/TFPark/model/#arguments_2",
            "text": "x : Input data. It could be:     - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,\n    if the model has named inputs.   y : Target data. Like the input data  x ,\n     It should be consistent with  x  (you cannot have Numpy inputs and\n     tensor targets, or inversely). If  x  is a TFDataset,  y  should\n     not be specified (since targets will be obtained from  x ).  batch_per_thread :\n      The default value is 1.\n      When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n      When distributed is False the total batch size is batch_per_thread * numOfCores.  distributed : Boolean. Whether to do prediction in distributed mode or local mode.\n               Default is True. In local mode, x must be a Numpy array.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/model/#predict",
            "text": "predict(x, batch_per_thread=None, distributed=False):",
            "title": "predict"
        },
        {
            "location": "/APIGuide/TFPark/model/#arguments_3",
            "text": "x : Input data. It could be:     - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,   batch_per_thread :\n      The default value is 1.\n      When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n      When distributed is False the total batch size is batch_per_thread * numOfCores.  distributed : Boolean. Whether to do prediction in distributed mode or local mode.\n                Default is True. In local mode, x must be a Numpy array.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/estimator/",
            "text": "TFEstimator\n\n\nTFEstimator wraps a model defined by \nmodel_fn\n. The \nmodel_fn\n is almost identical to TensorFlow's \nmodel_fn\n\nexcept users are required to use ZooOptimizer, which takes a \ntf.train.Optimzer\n as input, to derive a train_op.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nCreate a TFEstimator from a model_fn\n:\n\n\nimport tensorflow as tf\nfrom zoo.tfpark import TFEstimator, ZooOptimizer\ndef model_fn(features, labels, mode):\n\n    hidden = tf.layers.dense(features, 32, activation=tf.nn.relu)\n\n    logits = tf.layers.dense(hidden, 10)\n\n    if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(\n            tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n        train_op = ZooOptimizer(tf.train.AdamOptimizer()).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, train_op=train_op, predictions=logits, loss=loss)\n    else:\n        return tf.estimator.EstimatorSpec(mode, predictions=logits)\n\nestimator = TFEstimator.from_model_fn(model_fn, model_dir=\"/tmp/estimator\")\n\n\n\n\nCreate a TFEstimator from a pre-made estimator\n:\n\n\nimport tensorflow as tf\nlinear = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n                                           optimizer=ZooOptimizer(tf.train.FtrlOptimizer(0.2)))\nestimator = TFEstimator(linear)\n\n\n\n\nMethods\n\n\n__init__\n\n\nCreate a TFEstimator from a tf.estimator.Estimator\n\n\nTFEstimator(estimator)\n\n\n\n\nfrom_model_fn\n\n\nCreate a TFEstimator from a model_fn\n\n\nTFEstimator.from_model_fn(model_fn, model_dir=None, config=None, params=None, warm_start_from=None)\n\n\n\n\nArguments\n\n\n\n\nmodel_fn\n: Model function. Follows the signature:\n    * Args:\n\n        * `features`: This is the first item returned from the `input_fn`\n            passed to `train`, `evaluate`, and `predict`. This should be a\n            single `tf.Tensor` or `dict` of same.\n        * `labels`: This is the second item returned from the `input_fn`\n            passed to `train`, `evaluate`, and `predict`. This should be a\n            single `tf.Tensor` or `dict` of same (for multi-head models).\n            If mode is `tf.estimator.ModeKeys.PREDICT`, `labels=None` will\n            be passed. If the `model_fn`'s signature does not accept\n            `mode`, the `model_fn` must still be able to handle\n            `labels=None`.\n        * `mode`: Optional. Specifies if this training, evaluation or\n            prediction. See `tf.estimator.ModeKeys`.\n        * `params`: Optional `dict` of hyperparameters.  Will receive what\n            is passed to Estimator in `params` parameter. This allows\n            to configure Estimators from hyper parameter tuning.\n        * `config`: Optional `estimator.RunConfig` object. Will receive what\n            is passed to Estimator as its `config` parameter, or a default\n            value. Allows setting up things in your `model_fn` based on\n            configuration such as `num_ps_replicas`, or `model_dir`.\n\n    * Returns:\n        `tf.estimator.EstimatorSpec`\n    For the train_op in tf.estimator.EstimatorSpec, it derive from and only from\n                `zoo.tfpark.ZooOptimizer`\n\n\n\n\n\nmodel_dir\n: Directory to save model parameters, graph and etc. This can\n        also be used to load checkpoints from the directory into an estimator to\n        continue training a previously saved model. If \nPathLike\n object, the\n        path will be resolved. If \nNone\n, the model_dir in \nconfig\n will be used\n        if set. If both are set, they must be same. If both are \nNone\n, a\n        temporary directory will be used.\n\n\nconfig\n: \nestimator.RunConfig\n configuration object.\n\n\nparams\n: \ndict\n of hyper parameters that will be passed into \nmodel_fn\n.\n          Keys are names of parameters, values are basic python types.\n\n\nwarm_start_from\n: Optional string filepath to a checkpoint or SavedModel to\n                   warm-start from, or a \ntf.estimator.WarmStartSettings\n\n                   object to fully configure warm-starting.  If the string\n                   filepath is provided instead of a\n                   \ntf.estimator.WarmStartSettings\n, then all variables are\n                   warm-started, and it is assumed that vocabularies\n                   and \ntf.Tensor\n names are unchanged.\n\n\n\n\n\n\n\n\ntrain\n\n\ntrain(input_fn, steps=None)\n\n\n\n\nArguments\n\n\n\n\ninput_fn\n: A function that constructs the input data for evaluation. The\n            function should construct and return one of the following:\n    * A `TFDataset` object, each elements of which is a tuple `(features, labels)`.\n    * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple\n    `(features, labels)` with same constraints as below.\n    * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary\n    of string feature name to `Tensor` and `labels` is a `Tensor` or a\n    dictionary of string label name to `Tensor`. Both `features` and\n    `labels` are consumed by `model_fn`. They should satisfy the expectation\n    of `model_fn` from inputs.\n\n\n\n\n\nsteps\n: Number of steps for which to train the model.\n\n\n\n\n\n\n\n\nevaluate\n\n\nevaluate(input_fn, eval_methods, steps=None, checkpoint_path=None)\n\n\n\n\nArguments\n\n\n\n\ninput_fn\n: A function that constructs the input data for evaluation. The\n            function should construct and return one of the following:\n    * A `TFDataset` object, each elements of which is a tuple `(features, labels)`.\n    * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple\n    `(features, labels)` with same constraints as below.\n    * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary\n    of string feature name to `Tensor` and `labels` is a `Tensor` or a\n    dictionary of string label name to `Tensor`. Both `features` and\n    `labels` are consumed by `model_fn`. They should satisfy the expectation\n    of `model_fn` from inputs.\n\n\n\n\n\neval_methods\n: a list of strings to specify the evaluation metrics to\n                be used in this model\n\n\nsteps\n: Number of steps for which to evaluate model.\n\n\ncheckpoint_path\n: Path of a specific checkpoint to evaluate. If \nNone\n, the\n        latest checkpoint in \nmodel_dir\n is used.  If there are no checkpoints\n        in \nmodel_dir\n, evaluation is run with newly initialized \nVariables\n\n        instead of ones restored from checkpoint.\n\n\n\n\n\n\n\n\npredict\n\n\npredict(input_fn, checkpoint_path=None)\n\n\n\n\nArguments\n\n\n\n\n\n\ninput_fn\n: A function that constructs the features.\n\n\n      * A `TFDataset` object, each elements of which is a tuple `(features, None)`.\n      * A `tf.data.Dataset` object: Outputs of `Dataset` object must have\n        same constraints as below.\n      * features: A `tf.Tensor` or a dictionary of string feature name to\n        `Tensor`. features are consumed by `model_fn`. They should satisfy\n        the expectation of `model_fn` from inputs.\n      * A tuple, in which case the first item is extracted as features.\n\n\n\n\n\n\n\ncheckpoint_path\n: Path of a specific checkpoint to predict. If \nNone\n, the\n            latest checkpoint in \nmodel_dir\n is used.  If there are no checkpoints\n            in \nmodel_dir\n, prediction is run with newly initialized \nVariables\n\n            instead of ones restored from checkpoint.",
            "title": "TFEstimator"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#tfestimator",
            "text": "TFEstimator wraps a model defined by  model_fn . The  model_fn  is almost identical to TensorFlow's  model_fn \nexcept users are required to use ZooOptimizer, which takes a  tf.train.Optimzer  as input, to derive a train_op.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .   Create a TFEstimator from a model_fn :  import tensorflow as tf\nfrom zoo.tfpark import TFEstimator, ZooOptimizer\ndef model_fn(features, labels, mode):\n\n    hidden = tf.layers.dense(features, 32, activation=tf.nn.relu)\n\n    logits = tf.layers.dense(hidden, 10)\n\n    if mode == tf.estimator.ModeKeys.EVAL or mode == tf.estimator.ModeKeys.TRAIN:\n        loss = tf.reduce_mean(\n            tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n        train_op = ZooOptimizer(tf.train.AdamOptimizer()).minimize(loss)\n        return tf.estimator.EstimatorSpec(mode, train_op=train_op, predictions=logits, loss=loss)\n    else:\n        return tf.estimator.EstimatorSpec(mode, predictions=logits)\n\nestimator = TFEstimator.from_model_fn(model_fn, model_dir=\"/tmp/estimator\")  Create a TFEstimator from a pre-made estimator :  import tensorflow as tf\nlinear = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n                                           optimizer=ZooOptimizer(tf.train.FtrlOptimizer(0.2)))\nestimator = TFEstimator(linear)",
            "title": "TFEstimator"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#__init__",
            "text": "Create a TFEstimator from a tf.estimator.Estimator  TFEstimator(estimator)",
            "title": "__init__"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#from_model_fn",
            "text": "Create a TFEstimator from a model_fn  TFEstimator.from_model_fn(model_fn, model_dir=None, config=None, params=None, warm_start_from=None)",
            "title": "from_model_fn"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#arguments",
            "text": "model_fn : Model function. Follows the signature:     * Args:\n\n        * `features`: This is the first item returned from the `input_fn`\n            passed to `train`, `evaluate`, and `predict`. This should be a\n            single `tf.Tensor` or `dict` of same.\n        * `labels`: This is the second item returned from the `input_fn`\n            passed to `train`, `evaluate`, and `predict`. This should be a\n            single `tf.Tensor` or `dict` of same (for multi-head models).\n            If mode is `tf.estimator.ModeKeys.PREDICT`, `labels=None` will\n            be passed. If the `model_fn`'s signature does not accept\n            `mode`, the `model_fn` must still be able to handle\n            `labels=None`.\n        * `mode`: Optional. Specifies if this training, evaluation or\n            prediction. See `tf.estimator.ModeKeys`.\n        * `params`: Optional `dict` of hyperparameters.  Will receive what\n            is passed to Estimator in `params` parameter. This allows\n            to configure Estimators from hyper parameter tuning.\n        * `config`: Optional `estimator.RunConfig` object. Will receive what\n            is passed to Estimator as its `config` parameter, or a default\n            value. Allows setting up things in your `model_fn` based on\n            configuration such as `num_ps_replicas`, or `model_dir`.\n\n    * Returns:\n        `tf.estimator.EstimatorSpec`\n    For the train_op in tf.estimator.EstimatorSpec, it derive from and only from\n                `zoo.tfpark.ZooOptimizer`   model_dir : Directory to save model parameters, graph and etc. This can\n        also be used to load checkpoints from the directory into an estimator to\n        continue training a previously saved model. If  PathLike  object, the\n        path will be resolved. If  None , the model_dir in  config  will be used\n        if set. If both are set, they must be same. If both are  None , a\n        temporary directory will be used.  config :  estimator.RunConfig  configuration object.  params :  dict  of hyper parameters that will be passed into  model_fn .\n          Keys are names of parameters, values are basic python types.  warm_start_from : Optional string filepath to a checkpoint or SavedModel to\n                   warm-start from, or a  tf.estimator.WarmStartSettings \n                   object to fully configure warm-starting.  If the string\n                   filepath is provided instead of a\n                    tf.estimator.WarmStartSettings , then all variables are\n                   warm-started, and it is assumed that vocabularies\n                   and  tf.Tensor  names are unchanged.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#train",
            "text": "train(input_fn, steps=None)",
            "title": "train"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#arguments_1",
            "text": "input_fn : A function that constructs the input data for evaluation. The\n            function should construct and return one of the following:     * A `TFDataset` object, each elements of which is a tuple `(features, labels)`.\n    * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple\n    `(features, labels)` with same constraints as below.\n    * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary\n    of string feature name to `Tensor` and `labels` is a `Tensor` or a\n    dictionary of string label name to `Tensor`. Both `features` and\n    `labels` are consumed by `model_fn`. They should satisfy the expectation\n    of `model_fn` from inputs.   steps : Number of steps for which to train the model.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#evaluate",
            "text": "evaluate(input_fn, eval_methods, steps=None, checkpoint_path=None)",
            "title": "evaluate"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#arguments_2",
            "text": "input_fn : A function that constructs the input data for evaluation. The\n            function should construct and return one of the following:     * A `TFDataset` object, each elements of which is a tuple `(features, labels)`.\n    * A `tf.data.Dataset` object: Outputs of `Dataset` object must be a tuple\n    `(features, labels)` with same constraints as below.\n    * A tuple `(features, labels)`: Where `features` is a `tf.Tensor` or a dictionary\n    of string feature name to `Tensor` and `labels` is a `Tensor` or a\n    dictionary of string label name to `Tensor`. Both `features` and\n    `labels` are consumed by `model_fn`. They should satisfy the expectation\n    of `model_fn` from inputs.   eval_methods : a list of strings to specify the evaluation metrics to\n                be used in this model  steps : Number of steps for which to evaluate model.  checkpoint_path : Path of a specific checkpoint to evaluate. If  None , the\n        latest checkpoint in  model_dir  is used.  If there are no checkpoints\n        in  model_dir , evaluation is run with newly initialized  Variables \n        instead of ones restored from checkpoint.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#predict",
            "text": "predict(input_fn, checkpoint_path=None)",
            "title": "predict"
        },
        {
            "location": "/APIGuide/TFPark/estimator/#arguments_3",
            "text": "input_fn : A function that constructs the features.        * A `TFDataset` object, each elements of which is a tuple `(features, None)`.\n      * A `tf.data.Dataset` object: Outputs of `Dataset` object must have\n        same constraints as below.\n      * features: A `tf.Tensor` or a dictionary of string feature name to\n        `Tensor`. features are consumed by `model_fn`. They should satisfy\n        the expectation of `model_fn` from inputs.\n      * A tuple, in which case the first item is extracted as features.    checkpoint_path : Path of a specific checkpoint to predict. If  None , the\n            latest checkpoint in  model_dir  is used.  If there are no checkpoints\n            in  model_dir , prediction is run with newly initialized  Variables \n            instead of ones restored from checkpoint.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/",
            "text": "TFOptimizer\n\n\nTFOptimizer is used for optimizing a TensorFlow model with respect to its training variables\non Spark/BigDL.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nCreate a TFOptimizer\n:\n\n\nimport tensorflow as tf\nfrom zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import *\nloss = ...\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nFor Keras model:\n\n\nfrom zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import *\nfrom tensorflow.keras.models import Model\n\nmodel = Model(inputs=..., outputs=...)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\noptimizer = TFOptimizer.from_keras(model, dataset)\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nMethods\n\n\nfrom_loss (factory method)\n\n\nCreate a TFOptimizer from a TensorFlow loss tensor.\nThe loss tensor must come from a TensorFlow graph that only takes TFDataset.tensors and\nthe tensors in \ntensor_with_value\n as inputs.\n\n\nfrom_loss(loss, optim_method, session=None, val_outputs=None,\n                  val_labels=None, val_method=None,\n                  clip_norm=None, clip_value=None, metrics=None,\n                  tensor_with_value=None, **kwargs)\n\n\n\n\nArguments\n\n\n\n\nloss\n: The loss tensor of the TensorFlow model, should be a scalar.\n            The loss tensor must come from a TensorFlow graph that only takes TFDataset.tensors and\n            the tensors in \ntensor_with_value\n as inputs.\n\n\noptim_method\n: the optimization method to be used, such as bigdl.optim.optimizer.Adam\n\n\nsession\n: the current TensorFlow Session, if you want to used a pre-trained model,\n             you should use the Session to load the pre-trained variables and pass it to TFOptimizer.\n\n\nval_outputs\n: the validation output TensorFlow tensor to be used by val_methods\n\n\nval_labels\n: the validation label TensorFlow tensor to be used by val_methods\n\n\nval_method\n: the BigDL val_method(s) to be used.\n\n\nclip_norm\n: float >= 0. Gradients will be clipped when their L2 norm exceeds\n               this value.\n\n\nclip_value\n: float >= 0. Gradients will be clipped when their absolute value\n                exceeds this value.\n\n\nmetrics\n: a dictionary. The key should be a string representing the metric's name\n             and the value should be the corresponding TensorFlow tensor, which should be a scalar.\n\n\ntensor_with_value\n: a dictionary. The key is TensorFlow tensor, usually a\n                      placeholder, the value of the dictionary is a tuple of two elements. The first one of\n                      the tuple is the value to feed to the tensor in training phase and the second one\n                      is the value to feed to the tensor in validation phase.\n\n\n\n\nfrom_keras (factory method)\n\n\nCreate a TFOptimizer from a tensorflow.keras model. The model must be compiled.\n\n\nfrom_keras(keras_model, dataset, optim_method=None, **kwargs)\n\n\n\n\nArguments\n\n\n\n\nkeras_model\n: the tensorflow.keras model, which must be compiled.\n\n\ndataset\n: a \nTFDataset\n\n\noptim_method\n: the optimization method to be used, such as bigdl.optim.optimizer.Adam\n\n\n\n\nset_train_summary\n\n\nset_train_summary(summary)\n\n\n\n\nArguments\n\n\n\n\nsummary\n: The train summary to be set. A TrainSummary object contains information\n               necessary for the optimizer to know how often the logs are recorded,\n               where to store the logs and how to retrieve them, etc. For details,\n               refer to the docs of \nTrainSummary\n.\n\n\n\n\nset_val_summary\n\n\nset_val_summary(summary)\n\n\n\n\nArguments\n\n\n\n\nsummary\n: The validation summary to be set. A ValidationSummary object contains information\n               necessary for the optimizer to know how often the logs are recorded,\n               where to store the logs and how to retrieve them, etc. For details,\n               refer to the docs of \nValidationSummary\n.\n\n\n\n\nset_constant_gradient_clipping\n\n\nset_constant_gradient_clipping(min_value, max_value)\n\n\n\n\nArguments\n\n\n\n\nmin_value\n: the minimum value to clip by\n\n\nmax_value\n: the maxmimum value to clip by\n\n\n\n\nset_gradient_clipping_by_l2_norm\n\n\nset_gradient_clipping_by_l2_norm(self, clip_norm)\n\n\n\n\nArguments\n\n\n\n\nclip_norm\n: gradient L2-Norm threshold\n\n\n\n\noptimize\n\n\noptimize(self, end_trigger=None)\n\n\n\n\nArguments\n\n\n\n\nend_trigger\n: BigDL's \nTrigger\n to indicate when to stop the training. If none, defaults to\n                   train for one epoch.",
            "title": "TFOptimizer"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#tfoptimizer",
            "text": "TFOptimizer is used for optimizing a TensorFlow model with respect to its training variables\non Spark/BigDL.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .   Create a TFOptimizer :  import tensorflow as tf\nfrom zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import *\nloss = ...\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.optimize(end_trigger=MaxEpoch(5))  For Keras model:  from zoo.tfpark import TFOptimizer\nfrom bigdl.optim.optimizer import *\nfrom tensorflow.keras.models import Model\n\nmodel = Model(inputs=..., outputs=...)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\noptimizer = TFOptimizer.from_keras(model, dataset)\noptimizer.optimize(end_trigger=MaxEpoch(5))",
            "title": "TFOptimizer"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#from_loss-factory-method",
            "text": "Create a TFOptimizer from a TensorFlow loss tensor.\nThe loss tensor must come from a TensorFlow graph that only takes TFDataset.tensors and\nthe tensors in  tensor_with_value  as inputs.  from_loss(loss, optim_method, session=None, val_outputs=None,\n                  val_labels=None, val_method=None,\n                  clip_norm=None, clip_value=None, metrics=None,\n                  tensor_with_value=None, **kwargs)",
            "title": "from_loss (factory method)"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments",
            "text": "loss : The loss tensor of the TensorFlow model, should be a scalar.\n            The loss tensor must come from a TensorFlow graph that only takes TFDataset.tensors and\n            the tensors in  tensor_with_value  as inputs.  optim_method : the optimization method to be used, such as bigdl.optim.optimizer.Adam  session : the current TensorFlow Session, if you want to used a pre-trained model,\n             you should use the Session to load the pre-trained variables and pass it to TFOptimizer.  val_outputs : the validation output TensorFlow tensor to be used by val_methods  val_labels : the validation label TensorFlow tensor to be used by val_methods  val_method : the BigDL val_method(s) to be used.  clip_norm : float >= 0. Gradients will be clipped when their L2 norm exceeds\n               this value.  clip_value : float >= 0. Gradients will be clipped when their absolute value\n                exceeds this value.  metrics : a dictionary. The key should be a string representing the metric's name\n             and the value should be the corresponding TensorFlow tensor, which should be a scalar.  tensor_with_value : a dictionary. The key is TensorFlow tensor, usually a\n                      placeholder, the value of the dictionary is a tuple of two elements. The first one of\n                      the tuple is the value to feed to the tensor in training phase and the second one\n                      is the value to feed to the tensor in validation phase.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#from_keras-factory-method",
            "text": "Create a TFOptimizer from a tensorflow.keras model. The model must be compiled.  from_keras(keras_model, dataset, optim_method=None, **kwargs)",
            "title": "from_keras (factory method)"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_1",
            "text": "keras_model : the tensorflow.keras model, which must be compiled.  dataset : a  TFDataset  optim_method : the optimization method to be used, such as bigdl.optim.optimizer.Adam",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#set_train_summary",
            "text": "set_train_summary(summary)",
            "title": "set_train_summary"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_2",
            "text": "summary : The train summary to be set. A TrainSummary object contains information\n               necessary for the optimizer to know how often the logs are recorded,\n               where to store the logs and how to retrieve them, etc. For details,\n               refer to the docs of  TrainSummary .",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#set_val_summary",
            "text": "set_val_summary(summary)",
            "title": "set_val_summary"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_3",
            "text": "summary : The validation summary to be set. A ValidationSummary object contains information\n               necessary for the optimizer to know how often the logs are recorded,\n               where to store the logs and how to retrieve them, etc. For details,\n               refer to the docs of  ValidationSummary .",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#set_constant_gradient_clipping",
            "text": "set_constant_gradient_clipping(min_value, max_value)",
            "title": "set_constant_gradient_clipping"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_4",
            "text": "min_value : the minimum value to clip by  max_value : the maxmimum value to clip by",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#set_gradient_clipping_by_l2_norm",
            "text": "set_gradient_clipping_by_l2_norm(self, clip_norm)",
            "title": "set_gradient_clipping_by_l2_norm"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_5",
            "text": "clip_norm : gradient L2-Norm threshold",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#optimize",
            "text": "optimize(self, end_trigger=None)",
            "title": "optimize"
        },
        {
            "location": "/APIGuide/TFPark/tf-optimizer/#arguments_6",
            "text": "end_trigger : BigDL's  Trigger  to indicate when to stop the training. If none, defaults to\n                   train for one epoch.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/TFPark/tf-pred/",
            "text": "TFPredictor\n\n\nTFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in\n TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the\n model prediction for the corresponding input elements.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nPython\n\n\nlogist = ...\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()\n\n\n\n\nFor Keras model:\n\n\nmodel = Model(inputs=..., outputs=...)\nmodel.load_weights(\"/tmp/mnist_keras.h5\")\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()",
            "title": "TFPredictor"
        },
        {
            "location": "/APIGuide/TFPark/tf-pred/#tfpredictor",
            "text": "TFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in\n TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the\n model prediction for the corresponding input elements.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .   Python  logist = ...\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()  For Keras model:  model = Model(inputs=..., outputs=...)\nmodel.load_weights(\"/tmp/mnist_keras.h5\")\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()",
            "title": "TFPredictor"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/",
            "text": "TFDataset\n\n\nTFDatset represents a distributed collection of elements to be feed into TensorFlow graph.\nTFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing\nthe tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the\nTFOptimizer or TFPredictor.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nMethods\n\n\nfrom_rdd\n\n\nCreate a TFDataset from a rdd.\n\n\nFor training and evaluation, both \nfeatures\n and \nlabels\n arguments should be specified.\nThe element of the rdd should be a tuple of two, (features, labels), each has the\nsame structure of numpy.ndarrays of the argument \nfeatures\n, \nlabels\n.\n\n\nE.g. if \nfeatures\n is [(tf.float32, [10]), (tf.float32, [20])],\nand \nlabels\n is {\"label1\":(tf.float32, [10]), \"label2\": (tf.float32, [20])}\nthen a valid element of the rdd could be\n\n\n    (\n    [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))],\n     {\"label1\": np.zeros(dtype=float, shape=(10,)),\n      \"label2\":np.zeros(dtype=float, shape=(10,))))}\n    )\n\n\n\nIf \nlabels\n is not specified,\nthen the above element should be changed to\n\n\n    [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))]\n\n\n\nFor inference, \nlabels\n can be not specified.\nThe element of the rdd should be some ndarrays of the same structure of the \nfeatures\n\nargument.\n\n\nA note on the legacy api: if you are using \nnames\n, \nshapes\n, \ntypes\n arguments,\neach element of the rdd should be a list of numpy.ndarray.\n\n\nPython\n\n\nfrom_rdd(rdd, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_rdd=None)\n\n\n\n\nArguments\n\n\n\n\nrdd\n: a rdd containing the numpy.ndarrays to be used \n           for training/evaluation/inference\n\n\n\n\nfeatures\n: the structure of input features, should one the following:\n\n\n\n\na tuple (dtype, shape), e.g. (tf.float32, [28, 28, 1]) \n\n\na list of such tuple [(dtype1, shape1), (dtype2, shape2)],\n                 e.g. [(tf.float32, [10]), (tf.float32, [20])],\n\n\na dict of such tuple, mapping string names to tuple {\"name\": (dtype, shape},\n                 e.g. {\"input1\":(tf.float32, [10]), \"input2\": (tf.float32, [20])}\n\n\n\n\n\n\n\n\nlabels\n: the structure of input labels, format is the same as features\n\n\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nval_rdd\n: validation data with the same structure of rdd\n\n\n\n\nfrom_string_rdd\n\n\nCreate a TFDataset from a RDD of strings. Each element in the RDD should be a single string.\nThe returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor\nis tf.string, and the shape is (None,). The returning don't have label_tensors. If the\ndataset is used for training, the label should be encoded in the string.\n\n\nPython\n\n\nfrom_string_rdd(string_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_string_rdd=None)\n\n\n\n\nArguments\n\n\n\n\nstring_rdd\n: the RDD of strings\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_string_rdd\n: the RDD of strings to be used in validation\n\n\n\n\nfrom_bytes_rdd\n\n\nCreate a TFDataset from a RDD of bytes. Each element is the RDD should be a bytes object.\nThe returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor\nis tf.string, and the shape is (None,). The returning don't have label_tensors. If the\ndataset is used for training, the label should be encoded in the bytes.\n\n\nPython\n\n\nfrom_bytes_rdd(bytes_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_bytes_rdd=None)\n\n\n\n\nArguments\n\n\n\n\nbytes_rdd\n: the RDD of bytes\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_string_rdd\n: the RDD of bytes to be used in validation\n\n\n\n\nfrom_ndarrays\n\n\nCreate a TFDataset from a nested structure of numpy ndarrays. Each element\nin the resulting TFDataset has the same structure of the argument tensors and\nis created by indexing on the first dimension of each ndarray in the tensors\nargument.\n\n\nThis method is equivalent to sc.parallize the tensors and call TFDataset.from_rdd\n\n\nPython\n\n\nfrom_ndarrays(tensors, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_tensors=None)\n\n\n\n\nArguments\n\n\n\n\ntensors\n: the numpy ndarrays\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nval_tensors\n: the numpy ndarrays used for validation during training\n\n\n\n\nfrom_image_set\n\n\nCreate a TFDataset from a ImagetSet. Each ImageFeature in the ImageSet should\nalready has the \"sample\" field, i.e. the result of ImageSetToSample transformer\n\n\nPython\n\n\nfrom_image_set(image_set, image, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)\n\n\n\n\nArguments\n\n\n\n\nimage_set\n: the ImageSet used to create this TFDataset\n\n\nimage\n: a tuple of two, the first element is the type of image, the second element\n        is the shape of this element, i.e. (tf.float32, [224, 224, 3]))\n\n\nlabel\n: a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1]))\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_image_set\n: the ImageSet used for validation during training\n\n\n\n\nfrom_text_set\n\n\nCreate a TFDataset from a TextSet. The TextSet must be transformed to Sample, i.e.\nthe result of TextFeatureToSample transformer.\n\n\nPython\n\n\nfrom_text_set(text_set, text, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)\n\n\n\n\nArguments\n\n\n\n\ntext_set\n: the TextSet used to create this TFDataset\n\n\ntext\n: a tuple of two, the first element is the type of this input feature,\n        the second element is the shape of this element, i.e. (tf.float32, [10, 100, 4])).\n        text can also be nested structure of this tuple of two.\n\n\nlabel\n: a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of\n        this tuple of two.\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_image_set\n: The TextSet used for validation during training\n\n\n\n\nfrom_feature_set\n\n\nCreate a TFDataset from a FeatureSet. Currently, the element in this Feature set must be a\nImageFeature that has a sample field, i.e. the result of ImageSetToSample transformer\n\n\nPython\n\n\nfrom_feature_set(dataset, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None)\n\n\n\n\nArguments\n\n\n\n\ndataset\n: the feature set used to create this TFDataset\n\n\nfeatures\n: a tuple of two, the first element is the type of this input feature,\n        the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])).\n        text can also be nested structure of this tuple of two.\n\n\nlabels\n: a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of\n        this tuple of two.\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_dataset\n: The FeatureSet used for validation during training\n\n\n\n\nfrom_tf_data_dataset\n\n\nCreate a TFDataset from a tf.data.Dataset.\n\n\nThe recommended way to create the dataset is to reading files in a shared file\nsystem (e.g. HDFS) that is accessible from every executor of this Spark Application.\n\n\nIf the dataset is created by reading files in the local file system, then the\nfiles must exist in every executor in the exact same path. The path should be\nabsolute path and relative path is not supported.\n\n\nA few kinds of dataset is not supported for now:\n1. dataset created from tf.data.Dataset.from_generators\n2. dataset with Dataset.batch operation.\n3. dataset with Dataset.repeat operation\n4. dataset contains tf.py_func, tf.py_function or tf.numpy_function\n\n\nPython\n\n\nfrom_tf_data_dataset(dataset, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None)\n\n\n\n\nArguments\n\n\n\n\ndataset\n: the tf.data.Dataset\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_dataset\n: the dataset used for validation\n\n\n\n\nfrom_dataframe\n\n\nCreate a TFDataset from a pyspark.sql.DataFrame.\n\n\nPython\n\n\nfrom_dataframe(df, feature_cols, labels_cols=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_df=None)\n\n\n\n\nArguments\n\n\n\n\ndf\n: the DataFrame for the dataset\n\n\nfeature_cols\n: a list of string, indicating which columns are used as features.\n                    Currently supported types are FloatType, DoubleType, IntegerType,\n                    LongType, ArrayType (value should be numbers), DenseVector\n                    and SparseVector. For ArrayType, DenseVector and SparseVector,\n                    the element of the same column are assume to have the same size. \n\n\nlabel_cols\n: a list of string, indicating which columns are used as labels.\n                    Currently supported types are FloatType, DoubleType, IntegerType,\n                    LongType, ArrayType (value should be numbers), DenseVector\n                    and SparseVector. For ArrayType, DenseVector and SparseVector,\n                    the element of the same column are assume to have the same size.\n\n\nbatch_size\n: the batch size, used for training, should be a multiple of\n        total core num\n\n\nbatch_per_thread\n: the batch size for each thread, used for inference or evaluation\n\n\nhard_code_batch_size\n: whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.\n\n\nvalidation_df\n: the DataFrame used for validation",
            "title": "TFDataset"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#tfdataset",
            "text": "TFDatset represents a distributed collection of elements to be feed into TensorFlow graph.\nTFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing\nthe tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the\nTFOptimizer or TFPredictor.  Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .",
            "title": "TFDataset"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_rdd",
            "text": "Create a TFDataset from a rdd.  For training and evaluation, both  features  and  labels  arguments should be specified.\nThe element of the rdd should be a tuple of two, (features, labels), each has the\nsame structure of numpy.ndarrays of the argument  features ,  labels .  E.g. if  features  is [(tf.float32, [10]), (tf.float32, [20])],\nand  labels  is {\"label1\":(tf.float32, [10]), \"label2\": (tf.float32, [20])}\nthen a valid element of the rdd could be      (\n    [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))],\n     {\"label1\": np.zeros(dtype=float, shape=(10,)),\n      \"label2\":np.zeros(dtype=float, shape=(10,))))}\n    )  If  labels  is not specified,\nthen the above element should be changed to      [np.zeros(dtype=float, shape=(10,), np.zeros(dtype=float, shape=(10,)))]  For inference,  labels  can be not specified.\nThe element of the rdd should be some ndarrays of the same structure of the  features \nargument.  A note on the legacy api: if you are using  names ,  shapes ,  types  arguments,\neach element of the rdd should be a list of numpy.ndarray.  Python  from_rdd(rdd, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_rdd=None)  Arguments   rdd : a rdd containing the numpy.ndarrays to be used \n           for training/evaluation/inference   features : the structure of input features, should one the following:   a tuple (dtype, shape), e.g. (tf.float32, [28, 28, 1])   a list of such tuple [(dtype1, shape1), (dtype2, shape2)],\n                 e.g. [(tf.float32, [10]), (tf.float32, [20])],  a dict of such tuple, mapping string names to tuple {\"name\": (dtype, shape},\n                 e.g. {\"input1\":(tf.float32, [10]), \"input2\": (tf.float32, [20])}     labels : the structure of input labels, format is the same as features   batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  val_rdd : validation data with the same structure of rdd",
            "title": "from_rdd"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_string_rdd",
            "text": "Create a TFDataset from a RDD of strings. Each element in the RDD should be a single string.\nThe returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor\nis tf.string, and the shape is (None,). The returning don't have label_tensors. If the\ndataset is used for training, the label should be encoded in the string.  Python  from_string_rdd(string_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_string_rdd=None)  Arguments   string_rdd : the RDD of strings  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_string_rdd : the RDD of strings to be used in validation",
            "title": "from_string_rdd"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_bytes_rdd",
            "text": "Create a TFDataset from a RDD of bytes. Each element is the RDD should be a bytes object.\nThe returning TFDataset's feature_tensors has only one Tensor. the type of the Tensor\nis tf.string, and the shape is (None,). The returning don't have label_tensors. If the\ndataset is used for training, the label should be encoded in the bytes.  Python  from_bytes_rdd(bytes_rdd, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_bytes_rdd=None)  Arguments   bytes_rdd : the RDD of bytes  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_string_rdd : the RDD of bytes to be used in validation",
            "title": "from_bytes_rdd"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_ndarrays",
            "text": "Create a TFDataset from a nested structure of numpy ndarrays. Each element\nin the resulting TFDataset has the same structure of the argument tensors and\nis created by indexing on the first dimension of each ndarray in the tensors\nargument.  This method is equivalent to sc.parallize the tensors and call TFDataset.from_rdd  Python  from_ndarrays(tensors, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, val_tensors=None)  Arguments   tensors : the numpy ndarrays  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  val_tensors : the numpy ndarrays used for validation during training",
            "title": "from_ndarrays"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_image_set",
            "text": "Create a TFDataset from a ImagetSet. Each ImageFeature in the ImageSet should\nalready has the \"sample\" field, i.e. the result of ImageSetToSample transformer  Python  from_image_set(image_set, image, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)  Arguments   image_set : the ImageSet used to create this TFDataset  image : a tuple of two, the first element is the type of image, the second element\n        is the shape of this element, i.e. (tf.float32, [224, 224, 3]))  label : a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1]))  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_image_set : the ImageSet used for validation during training",
            "title": "from_image_set"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_text_set",
            "text": "Create a TFDataset from a TextSet. The TextSet must be transformed to Sample, i.e.\nthe result of TextFeatureToSample transformer.  Python  from_text_set(text_set, text, label=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_image_set=None)  Arguments   text_set : the TextSet used to create this TFDataset  text : a tuple of two, the first element is the type of this input feature,\n        the second element is the shape of this element, i.e. (tf.float32, [10, 100, 4])).\n        text can also be nested structure of this tuple of two.  label : a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of\n        this tuple of two.  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_image_set : The TextSet used for validation during training",
            "title": "from_text_set"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_feature_set",
            "text": "Create a TFDataset from a FeatureSet. Currently, the element in this Feature set must be a\nImageFeature that has a sample field, i.e. the result of ImageSetToSample transformer  Python  from_feature_set(dataset, features, labels=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None)  Arguments   dataset : the feature set used to create this TFDataset  features : a tuple of two, the first element is the type of this input feature,\n        the second element is the shape of this element, i.e. (tf.float32, [224, 224, 3])).\n        text can also be nested structure of this tuple of two.  labels : a tuple of two, the first element is the type of label, the second element\n        is the shape of this element, i.e. (tf.int32, [1])). label can also be nested structure of\n        this tuple of two.  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_dataset : The FeatureSet used for validation during training",
            "title": "from_feature_set"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_tf_data_dataset",
            "text": "Create a TFDataset from a tf.data.Dataset.  The recommended way to create the dataset is to reading files in a shared file\nsystem (e.g. HDFS) that is accessible from every executor of this Spark Application.  If the dataset is created by reading files in the local file system, then the\nfiles must exist in every executor in the exact same path. The path should be\nabsolute path and relative path is not supported.  A few kinds of dataset is not supported for now:\n1. dataset created from tf.data.Dataset.from_generators\n2. dataset with Dataset.batch operation.\n3. dataset with Dataset.repeat operation\n4. dataset contains tf.py_func, tf.py_function or tf.numpy_function  Python  from_tf_data_dataset(dataset, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_dataset=None)  Arguments   dataset : the tf.data.Dataset  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_dataset : the dataset used for validation",
            "title": "from_tf_data_dataset"
        },
        {
            "location": "/APIGuide/TFPark/tf-dataset/#from_dataframe",
            "text": "Create a TFDataset from a pyspark.sql.DataFrame.  Python  from_dataframe(df, feature_cols, labels_cols=None, batch_size=-1, batch_per_thread=-1, hard_code_batch_size=False, validation_df=None)  Arguments   df : the DataFrame for the dataset  feature_cols : a list of string, indicating which columns are used as features.\n                    Currently supported types are FloatType, DoubleType, IntegerType,\n                    LongType, ArrayType (value should be numbers), DenseVector\n                    and SparseVector. For ArrayType, DenseVector and SparseVector,\n                    the element of the same column are assume to have the same size.   label_cols : a list of string, indicating which columns are used as labels.\n                    Currently supported types are FloatType, DoubleType, IntegerType,\n                    LongType, ArrayType (value should be numbers), DenseVector\n                    and SparseVector. For ArrayType, DenseVector and SparseVector,\n                    the element of the same column are assume to have the same size.  batch_size : the batch size, used for training, should be a multiple of\n        total core num  batch_per_thread : the batch size for each thread, used for inference or evaluation  hard_code_batch_size : whether to hard code the batch_size into tensorflow graph,\n        if True, the static size of the first dimension of the resulting tensors is\n        batch_size/total_core_num (training) or batch_per_thread for inference; if False,\n        it is None.  validation_df : the DataFrame used for validation",
            "title": "from_dataframe"
        },
        {
            "location": "/APIGuide/TFPark/gan-estimator/",
            "text": "Analytics-Zoo provides a GANEstimator to support training GAN like models.\nCurrently we support standard unconditional/conditional GAN and other GAN types will be supported in the future.\n\n\n\n\nGANEstimator\n\n\nPython\n\n\nGANEstimator(generator_fn,\n             discriminator_fn,\n             generator_loss_fn,\n             discriminator_loss_fn,\n             generator_optimizer,\n             discriminator_optimizer,\n             generator_steps=1,\n             discriminator_steps=1,\n             model_dir=None,\n    )\n\n\n\n\nArguments\n\n\n\n\ngenerator_fn\n: a python function that defines the generator. It should takes a single noise tensor (unconditional)\na tuple of tensors in which the first element represents noise and the second label (conditional) and return the\ngenerated data.  \n\n\ndiscriminator_fn\n: a python function that defines the discriminator. The discriminator_fn should have two inputs.\nThe first input should be the real data or generated data. The inputs to generator will also be passed too discriminator\nas the second input.\n\n\ngenerator_loss_fn\n: the loss function on the generator. It should take the output of discriminator on generated data\nand return the loss for generator.\n\n\ndiscriminator_loss_fn\n: the loss function on the discriminator. The discriminator_loss_fn should have two inputs. The\nfirst input is the output of discriminator on generated data and the second input is the output of discriminator on real data.\n\n\ngenerator_optimizer\n: the optimizer to optimize generator, should be an instance of tf.train.Optimizer\n\n\ndiscriminator_optimizer\n: the optimizer to optimizer discriminator, should be an instance of tf.train.Optimizer\n\n\ngenerator_steps\n: the number of consecutive steps to run generator in each round\n\n\ndiscriminator_steps\n: the number of consecutive steps to run discriminator in each round\n\n\n\n\ntrain\n\n\nestimator.train(input_fn=input_fn, end_trigger=MaxIteration(100))\n\n\n\n\nArguments\n\n\n\n\ninput_fn\n: a python function that takes zero arguments and return a TFDataset. Each record in the TFDataset should\na tuple. The first element of the tuple is generator inputs, and the second element of the tuple should be real data.\n\n\nend_trigger\n: BigDL's \nTrigger\n to indicate when to stop the training. If none, defaults to\ntrain for one epoch.",
            "title": "GANEstimator"
        },
        {
            "location": "/APIGuide/TFPark/gan-estimator/#ganestimator",
            "text": "Python  GANEstimator(generator_fn,\n             discriminator_fn,\n             generator_loss_fn,\n             discriminator_loss_fn,\n             generator_optimizer,\n             discriminator_optimizer,\n             generator_steps=1,\n             discriminator_steps=1,\n             model_dir=None,\n    )  Arguments   generator_fn : a python function that defines the generator. It should takes a single noise tensor (unconditional)\na tuple of tensors in which the first element represents noise and the second label (conditional) and return the\ngenerated data.    discriminator_fn : a python function that defines the discriminator. The discriminator_fn should have two inputs.\nThe first input should be the real data or generated data. The inputs to generator will also be passed too discriminator\nas the second input.  generator_loss_fn : the loss function on the generator. It should take the output of discriminator on generated data\nand return the loss for generator.  discriminator_loss_fn : the loss function on the discriminator. The discriminator_loss_fn should have two inputs. The\nfirst input is the output of discriminator on generated data and the second input is the output of discriminator on real data.  generator_optimizer : the optimizer to optimize generator, should be an instance of tf.train.Optimizer  discriminator_optimizer : the optimizer to optimizer discriminator, should be an instance of tf.train.Optimizer  generator_steps : the number of consecutive steps to run generator in each round  discriminator_steps : the number of consecutive steps to run discriminator in each round",
            "title": "GANEstimator"
        },
        {
            "location": "/APIGuide/TFPark/gan-estimator/#train",
            "text": "estimator.train(input_fn=input_fn, end_trigger=MaxIteration(100))  Arguments   input_fn : a python function that takes zero arguments and return a TFDataset. Each record in the TFDataset should\na tuple. The first element of the tuple is generator inputs, and the second element of the tuple should be real data.  end_trigger : BigDL's  Trigger  to indicate when to stop the training. If none, defaults to\ntrain for one epoch.",
            "title": "train"
        },
        {
            "location": "/APIGuide/TFPark/text-models/",
            "text": "There are a number of built-in \ncompiled\n text models in Analytics Zoo TFPark for Natural Language Processing (NLP) tasks based on \nKerasModel\n.\n\n\nAfter constructing a text model, you can directly call \nfit\n, \nevaluate\n or \npredict\n \nin a distributed fashion. \nSee \nhere\n for more instructions.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\n\n\nIntent Extraction\n\n\nThis is a multi-task model used for joint intent extraction and slot filling.\n\n\nThis model has two inputs:\n\n\n\n\nword indices of shape (batch, sequence_length)\n\n\ncharacter indices of shape (batch, sequence_length, word_length)\n\n\n\n\nThis model has two outputs:\n\n\n\n\nintent labels of shape (batch, num_intents)\n\n\nentity tags of shape (batch, sequence_length, num_entities)\n\n\n\n\nfrom zoo.tfpark.text.keras import IntentEntity\n\nmodel = IntentEntity(num_intents, num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, char_lstm_dim=30, tagger_lstm_dim=100, dropout=0.2, optimizer=None)\n\n\n\n\n\n\nnum_intents\n: Positive int. The number of intent classes to be classified.\n\n\nnum_entities\n: Positive int. The number of slot labels to be classified.\n\n\nword_vocab_size\n: Positive int. The size of the word dictionary.\n\n\nchar_vocab_size\n: Positive int. The size of the character dictionary.\n\n\nword_length\n: Positive int. The max word length in characters. Default is 12.\n\n\nword_emb_dim\n: Positive int. The dimension of word embeddings. Default is 100.\n\n\nchar_emb_dim\n: Positive int. The dimension of character embeddings. Default is 30.\n\n\nchar_lstm_dim\n: Positive int. The hidden size of character feature Bi-LSTM layer. Default is 30.\n\n\ntagger_lstm_dim\n: Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100.\n\n\ndropout\n: Dropout rate. Default is 0.2.\n\n\noptimizer\n: Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer().\n\n\n\n\nModel Save and Load\n\n\nSave the \nIntentEntity\n model to a single HDF5 file.\n\n\nmodel.save_model(path)\n\n\n\n\nLoad an existing \nIntentEntity\n model (with weights) from HDF5 file.\n\n\nfrom zoo.tfpark.text.keras import IntentEntity\n\nmodel = IntentEntity.load_model(path)\n\n\n\n\n\n\nNamed Entity Recognition\n\n\nThis model is used for named entity recognition using Bidirectional LSTM with\nConditional Random Field (CRF) sequence classifier.\n\n\nThis model has two inputs:\n\n\n\n\nword indices of shape (batch, sequence_length)\n\n\ncharacter indices of shape (batch, sequence_length, word_length)\n\n\n\n\nThis model outputs entity tags of shape (batch, sequence_length, num_entities).\n\n\nfrom zoo.tfpark.text.keras import NER\n\nmodel = NER(num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, tagger_lstm_dim=100, dropout=0.5, crf_mode='reg', optimizer=None)\n\n\n\n\n\n\nnum_entities\n: Positive int. The number of entity labels to be classified.\n\n\nword_vocab_size\n: Positive int. The size of the word dictionary.\n\n\nchar_vocab_size\n: Positive int. The size of the character dictionary.\n\n\nword_length\n: Positive int. The max word length in characters. Default is 12.\n\n\nword_emb_dim\n: Positive int. The dimension of word embeddings. Default is 100.\n\n\nchar_emb_dim\n: Positive int. The dimension of character embeddings. Default is 30.\n\n\ntagger_lstm_dim\n: Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100.\n\n\ndropout\n: Dropout rate. Default is 0.5.\n\n\ncrf_mode\n: String. CRF operation mode. Either 'reg' or 'pad'. Default is 'reg'. \n                     'reg' for regular full sequence learning (all sequences have equal length). \n                     'pad' for supplied sequence lengths (useful for padded sequences). \n                     For 'pad' mode, a third input for sequence_length (batch, 1) is needed.\n\n\noptimizer\n: Optimizer to train the model. If not specified, it will by default to be tf.keras.optimizers.Adam(0.001, clipnorm=5.).\n\n\n\n\nModel Save and Load\n\n\nSave the \nNER\n model to a single HDF5 file.\n\n\nmodel.save_model(path)\n\n\n\n\nLoad an existing \nNER\n model (with weights) from HDF5 file.\n\n\nfrom zoo.tfpark.text.keras import NER\n\nmodel = NER.load_model(path)\n\n\n\n\n\n\nPOS Tagging\n\n\nThis model is used as Part-Of-Speech(POS)-tagger and chunker for sentence tagging, which contains three\nBidirectional LSTM layers.\n\n\nThis model can have one or two input(s):\n\n\n\n\nword indices of shape (batch, sequence_length)\n\n\ncharacter indices of shape (batch, sequence_length, word_length) (if char_vocab_size is not None)\n\n\n\n\nThis model has two outputs:\n\n\n\n\npos tags of shape (batch, sequence_length, num_pos_labels)\n\n\nchunk tags of shape (batch, sequence_length, num_chunk_labels)\n\n\n\n\nfrom zoo.tfpark.text.keras import SequenceTagger\n\nmodel = NER(num_pos_labels, num_chunk_labels, word_vocab_size, char_vocab_size=None, word_length=12, feature_size=100, dropout=0.2, classifier='softmax', optimizer=None)\n\n\n\n\n\n\nnum_pos_labels\n: Positive int. The number of pos labels to be classified.\n\n\nnum_chunk_labels\n: Positive int. The number of chunk labels to be classified.\n\n\nword_vocab_size\n: Positive int. The size of the word dictionary.\n\n\nchar_vocab_size\n: Positive int. The size of the character dictionary.\nDefault is None and in this case only one input, namely word indices is expected.\n\n\nword_length\n: Positive int. The max word length in characters. Default is 12.\n\n\nfeature_size\n: Positive int. The size of Embedding and Bi-LSTM layers. Default is 100.\n\n\ndropout\n: Dropout rate. Default is 0.5.\n\n\nclassifier\n: String. The classification layer used for tagging chunks. \nEither 'softmax' or 'crf' (Conditional Random Field). Default is 'softmax'.\n\n\noptimizer\n: Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer().\n\n\n\n\nModel Save and Load\n\n\nSave the \nSequenceTagger\n model to a single HDF5 file.\n\n\nmodel.save_model(path)\n\n\n\n\nLoad an existing \nSequenceTagger\n model (with weights) from HDF5 file.\n\n\nfrom zoo.tfpark.text.keras import SequenceTagger\n\nmodel = SequenceTagger.load_model(path)",
            "title": "Text Models"
        },
        {
            "location": "/APIGuide/TFPark/text-models/#intent-extraction",
            "text": "This is a multi-task model used for joint intent extraction and slot filling.  This model has two inputs:   word indices of shape (batch, sequence_length)  character indices of shape (batch, sequence_length, word_length)   This model has two outputs:   intent labels of shape (batch, num_intents)  entity tags of shape (batch, sequence_length, num_entities)   from zoo.tfpark.text.keras import IntentEntity\n\nmodel = IntentEntity(num_intents, num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, char_lstm_dim=30, tagger_lstm_dim=100, dropout=0.2, optimizer=None)   num_intents : Positive int. The number of intent classes to be classified.  num_entities : Positive int. The number of slot labels to be classified.  word_vocab_size : Positive int. The size of the word dictionary.  char_vocab_size : Positive int. The size of the character dictionary.  word_length : Positive int. The max word length in characters. Default is 12.  word_emb_dim : Positive int. The dimension of word embeddings. Default is 100.  char_emb_dim : Positive int. The dimension of character embeddings. Default is 30.  char_lstm_dim : Positive int. The hidden size of character feature Bi-LSTM layer. Default is 30.  tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100.  dropout : Dropout rate. Default is 0.2.  optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer().   Model Save and Load  Save the  IntentEntity  model to a single HDF5 file.  model.save_model(path)  Load an existing  IntentEntity  model (with weights) from HDF5 file.  from zoo.tfpark.text.keras import IntentEntity\n\nmodel = IntentEntity.load_model(path)",
            "title": "Intent Extraction"
        },
        {
            "location": "/APIGuide/TFPark/text-models/#named-entity-recognition",
            "text": "This model is used for named entity recognition using Bidirectional LSTM with\nConditional Random Field (CRF) sequence classifier.  This model has two inputs:   word indices of shape (batch, sequence_length)  character indices of shape (batch, sequence_length, word_length)   This model outputs entity tags of shape (batch, sequence_length, num_entities).  from zoo.tfpark.text.keras import NER\n\nmodel = NER(num_entities, word_vocab_size, char_vocab_size, word_length=12, word_emb_dim=100, char_emb_dim=30, tagger_lstm_dim=100, dropout=0.5, crf_mode='reg', optimizer=None)   num_entities : Positive int. The number of entity labels to be classified.  word_vocab_size : Positive int. The size of the word dictionary.  char_vocab_size : Positive int. The size of the character dictionary.  word_length : Positive int. The max word length in characters. Default is 12.  word_emb_dim : Positive int. The dimension of word embeddings. Default is 100.  char_emb_dim : Positive int. The dimension of character embeddings. Default is 30.  tagger_lstm_dim : Positive int. The hidden size of tagger Bi-LSTM layers. Default is 100.  dropout : Dropout rate. Default is 0.5.  crf_mode : String. CRF operation mode. Either 'reg' or 'pad'. Default is 'reg'. \n                     'reg' for regular full sequence learning (all sequences have equal length). \n                     'pad' for supplied sequence lengths (useful for padded sequences). \n                     For 'pad' mode, a third input for sequence_length (batch, 1) is needed.  optimizer : Optimizer to train the model. If not specified, it will by default to be tf.keras.optimizers.Adam(0.001, clipnorm=5.).   Model Save and Load  Save the  NER  model to a single HDF5 file.  model.save_model(path)  Load an existing  NER  model (with weights) from HDF5 file.  from zoo.tfpark.text.keras import NER\n\nmodel = NER.load_model(path)",
            "title": "Named Entity Recognition"
        },
        {
            "location": "/APIGuide/TFPark/text-models/#pos-tagging",
            "text": "This model is used as Part-Of-Speech(POS)-tagger and chunker for sentence tagging, which contains three\nBidirectional LSTM layers.  This model can have one or two input(s):   word indices of shape (batch, sequence_length)  character indices of shape (batch, sequence_length, word_length) (if char_vocab_size is not None)   This model has two outputs:   pos tags of shape (batch, sequence_length, num_pos_labels)  chunk tags of shape (batch, sequence_length, num_chunk_labels)   from zoo.tfpark.text.keras import SequenceTagger\n\nmodel = NER(num_pos_labels, num_chunk_labels, word_vocab_size, char_vocab_size=None, word_length=12, feature_size=100, dropout=0.2, classifier='softmax', optimizer=None)   num_pos_labels : Positive int. The number of pos labels to be classified.  num_chunk_labels : Positive int. The number of chunk labels to be classified.  word_vocab_size : Positive int. The size of the word dictionary.  char_vocab_size : Positive int. The size of the character dictionary.\nDefault is None and in this case only one input, namely word indices is expected.  word_length : Positive int. The max word length in characters. Default is 12.  feature_size : Positive int. The size of Embedding and Bi-LSTM layers. Default is 100.  dropout : Dropout rate. Default is 0.5.  classifier : String. The classification layer used for tagging chunks. \nEither 'softmax' or 'crf' (Conditional Random Field). Default is 'softmax'.  optimizer : Optimizer to train the model. If not specified, it will by default to be tf.train.AdamOptimizer().   Model Save and Load  Save the  SequenceTagger  model to a single HDF5 file.  model.save_model(path)  Load an existing  SequenceTagger  model (with weights) from HDF5 file.  from zoo.tfpark.text.keras import SequenceTagger\n\nmodel = SequenceTagger.load_model(path)",
            "title": "POS Tagging"
        },
        {
            "location": "/APIGuide/TFPark/bert-classifier/",
            "text": "Analytics Zoo provides a built-in BERTClassifier in TFPark for Natural Language Processing (NLP) classification tasks based on \nTFEstimator\n and BERT.\n\n\nBidirectional Encoder Representations from Transformers (BERT) is Google's state-of-the-art pre-trained NLP model.\nYou may refer to \nhere\n for more details.\n\n\nBERTClassifier is a pre-built TFEstimator that takes the hidden state of the first token to do classification.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\nAfter constructing a BERTClassifier, you can directly call \ntrain\n, \nevaluate\n or \npredict\n \nin a distributed fashion. \nSee \nhere\n for more instructions.\n\n\nfrom zoo.tfpark.text.estimator import BERTClassifier\n\nestimator = BERTClassifier(num_classes, bert_config_file, init_checkpoint=None, use_one_hot_embeddings=False, optimizer=None, model_dir=None)\n\n\n\n\n\n\nnum_classes\n: Positive int. The number of classes to be classified.\n\n\nbert_config_file\n: The path to the json file for BERT configurations.\n\n\ninit_checkpoint\n: The path to the initial checkpoint of the pre-trained BERT model if any. Default is None.\n\n\nuse_one_hot_embeddings\n: Boolean. Whether to use one-hot for word embeddings. Default is False.\n\n\noptimizer\n: The optimizer used to train the estimator. It can either be an instance of \ntf.train.Optimizer or the corresponding string representation. Default is None if no training is involved.\n\n\nmodel_dir\n: The output directory for model checkpoints to be written if any. Default is None.",
            "title": "BERT Classifier"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/",
            "text": "API Guide\n\n\nPython\n\n\nclass InputQueue\n\n\nThe class \nInput\n defines methods allowing you to input data into Cluster Serving \nInput Pipeline\n.\n\n\ninit\n\n\nview source\n\n\n__init__(host=None, port=None, sync=False, frontend_url=None)\n\n\n\n\nsets up a connection with configuration in your Cluster Serving \nconfiguration file\n \nconfig.yaml\n.\n\n\nreturn\n: None\n\n\nenqueue\n\n\nview source\n\n\nenqueue(uri, data*)\n\n\n\n\nputs key-value pair into data pipeline, if your model has key regulation, pass corresponded key. Otherwise, give the key any name you want.\n\n\nreturn\n: None\n\n\nuri\n: a string, unique identification of your image\n\n\ndata\n: key-value pair of your data.\n\n\nThere are 4 types of inputs in total, string, image, tensor, sparse tensor. See following example to enqueue specific type of data.\n\nExample\n\nImport the dependency and create an instance of \nInputQueue\n\n\nfrom zoo.serving.client import InputQueue\ninput_api = InputQueue()\n\n\n\n\nTo enqueue a list of string, pass a list of str objects, list of str type input is usually used in Tensorflow models.\n\n\ninput_api.enqueue('my-string-input', user_define_key=['hello', 'world'])\n\n\n\n\nTo enqueue an image, you could pass either image path or base64 encoded image bytes, the type of your parameter is identified by key of dict, see example below. If you pass image path, \ncv2\n package is required. (Could be installed by \npip install opencv-python\n)\n\n\nTo pass image path, use key \npath\n\n\nimage_path = \"path/to/image\"\ninput_api.enqueue('my-image1', user_define_key={\"path\": image_path})\n\n\n\n\nTo pass base64 encoded image bytes, use key \nb64\n\n\nimage_bytes = \"base64_encoded_bytes\"\ninput_api.enqueue('my-image1', user_define_key={\"b64\": image_bytes})\n\n\n\n\nTo enqueue a tensor or sparse tensor, \nnumpy\n package is required. (Would be installed while you installed Analytics Zoo, if not, could be installed by \npip install numpy\n)\n\n\nTo enqueue a tensor, pass a ndarray object.\n\n\nimport numpy as np\ninput_api.enqueue('my-tensor1', a=np.array([1,2]))\n\n\n\n\nTo enqueue a sparse tensor pass a list of ndarray object, normally sparse tensor is only used if your model specifies the input as sparse tensor. The list should have size of 3, where the 1st element is a 2-D ndarray, representing the indices of values, the 2nd element is a 1-D ndarray, representing the values corresponded with the indices, the 3rd element is a 1-D ndarray representing the shape of the sparse tensor.\n\n\nA sparse tensor of shape (5,10), with 3 elements at position (0, 0), (1, 2), (4, 5), having value 101, 102, 103, visualized as following,\n\n\n101. 0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   102. 0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   103. 0.   0.   0.   0\n\n\n\n\ncould be represented as following list.\n\n\nindices = np.array([[0, 1, 4], [0, 2, 5]])\nvalues = np.array([101, 102, 103])\nshape = np.array([5, 10])\ntensor = [indices, values, shape]\n\n\n\n\nand enqueue it by\n\n\ninput_api.enqueue(\"my-sparse-tensor\", input=tensor)\n\n\n\n\nTo enqueue an instance containing several images, tensors and sparse tensors.\n\n\nimport numpy as np\ninput_api.enqueue('my-instance', \n    img1={\"path: 'path/to/image1'},\n    img2={\"path: 'path/to/image2'},\n    tensor1=np.array([1,2]), \n    tensor2=np.array([[1,3],[2,3]])\n    sparse_tensor=[np.array([[0, 1, 4], [0, 2, 5]]),\n                   np.array([101, 102, 103])\n                   np.array([5, 10])]\n)\n\n\n\n\npredict\n\n\nview source\n\n\npredict(request_str)\n\n\n\n\nreturn\n: Numpy ndarray\n\n\nExample\n\n\nfrom zoo.serving.client import InputQueue\ninput_api = InputQueue(sync=True, frontend_url=frontend_server_url)\nrequest_json_string='''{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }]\n}'''\nresponse = input_api.predict(request_json_string)\nprint(response.text)\n\n\n\n\nclass OutputQueue\n\n\nThe class \nOutput\n defines methods allowing you to get result from Cluster Serving \nOutput Pipeline\n.\n\n\ninit\n\n\nview source\n\n\n__init__()\n\n\n\n\nsets up a connection with configuration in your Cluster Serving \nconfiguration file\n \nconfig.yaml\n.\n\n\nquery\n\n\nview source\n\n\nquery(uri)\n\n\n\n\nquery result in output Pipeline by key \nuri\n\n\nreturn\n: Numpy ndarray\n\n\nFormat: \n\n\n{\n    \"class_1\": \"probability_1\",\n    \"class_2\": \"probability_2\",\n    ...,\n    \"class_n\": \"probability_n\"\n}\n\n\n\n\nwhere \nn\n is \ntop_n\n in your serving config, the result is sorted by output probability.\n\n\nExample\n\n\nfrom zoo.serving.client import OutputQueue\nimport json\noutput_api = OutputQueue()\nd = output_api.query('my-image') \n\ntmp_dict = json.loads(d)\nfor class_idx in tmp_dict.keys():\n    output += \"class: \" + class_idx + \"'s prob: \" + tmp_dict[class_idx]\nprint(output)\n\n\n\n\ndequeue\n\n\nview source\n\n\ndequeue()\n\n\n\n\ngets all result of your model prediction and dequeue them from OutputQueue\n\n\nreturn\n: dict(), with keys the \nuri\n of your \nenqueue\n, string type, and values the output of your prediction, Numpy ndarray\n\n\nFormat: \n\n\n{\n  \"image1\": {\n      \"class_1\": \"probability_1\",\n      \"class_2\": \"probability_2\",\n      ...,\n      \"class_n\": \"probability_n\"\n  }, \n  \"image2\": {\n      \"class_1\": \"probability_1\",\n      \"class_2\": \"probability_2\",\n      ...,\n      \"class_n\": \"probability_n\"\n  }\n  ...\n}\n\n\n\n\nwhere \nn\n is \ntop_n\n in your serving config, the result is sorted by output probability.\n\n\nExample\n\n\nfrom zoo.serving.client import OutputQueue\nimport json\noutput_api = OutputQueue()\nd = output_api.dequeue()\n\nfor k in d.keys():\n    output = \"image: \" + k + \", classification-result:\"\n    tmp_dict = json.loads(result[k])\n    for class_idx in tmp_dict.keys():\n        output += \"class: \" + class_idx + \"'s prob: \" + tmp_dict[class_idx]\n    print(output)",
            "title": "Cluster Serving"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#api-guide",
            "text": "",
            "title": "API Guide"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#class-inputqueue",
            "text": "The class  Input  defines methods allowing you to input data into Cluster Serving  Input Pipeline .",
            "title": "class InputQueue"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#init",
            "text": "view source  __init__(host=None, port=None, sync=False, frontend_url=None)  sets up a connection with configuration in your Cluster Serving  configuration file   config.yaml .  return : None",
            "title": "init"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#enqueue",
            "text": "view source  enqueue(uri, data*)  puts key-value pair into data pipeline, if your model has key regulation, pass corresponded key. Otherwise, give the key any name you want.  return : None  uri : a string, unique identification of your image  data : key-value pair of your data.  There are 4 types of inputs in total, string, image, tensor, sparse tensor. See following example to enqueue specific type of data. Example \nImport the dependency and create an instance of  InputQueue  from zoo.serving.client import InputQueue\ninput_api = InputQueue()  To enqueue a list of string, pass a list of str objects, list of str type input is usually used in Tensorflow models.  input_api.enqueue('my-string-input', user_define_key=['hello', 'world'])  To enqueue an image, you could pass either image path or base64 encoded image bytes, the type of your parameter is identified by key of dict, see example below. If you pass image path,  cv2  package is required. (Could be installed by  pip install opencv-python )  To pass image path, use key  path  image_path = \"path/to/image\"\ninput_api.enqueue('my-image1', user_define_key={\"path\": image_path})  To pass base64 encoded image bytes, use key  b64  image_bytes = \"base64_encoded_bytes\"\ninput_api.enqueue('my-image1', user_define_key={\"b64\": image_bytes})  To enqueue a tensor or sparse tensor,  numpy  package is required. (Would be installed while you installed Analytics Zoo, if not, could be installed by  pip install numpy )  To enqueue a tensor, pass a ndarray object.  import numpy as np\ninput_api.enqueue('my-tensor1', a=np.array([1,2]))  To enqueue a sparse tensor pass a list of ndarray object, normally sparse tensor is only used if your model specifies the input as sparse tensor. The list should have size of 3, where the 1st element is a 2-D ndarray, representing the indices of values, the 2nd element is a 1-D ndarray, representing the values corresponded with the indices, the 3rd element is a 1-D ndarray representing the shape of the sparse tensor.  A sparse tensor of shape (5,10), with 3 elements at position (0, 0), (1, 2), (4, 5), having value 101, 102, 103, visualized as following,  101. 0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   102. 0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   0.   0.   0.   0.   0\n0.   0.   0.   0.   0.   103. 0.   0.   0.   0  could be represented as following list.  indices = np.array([[0, 1, 4], [0, 2, 5]])\nvalues = np.array([101, 102, 103])\nshape = np.array([5, 10])\ntensor = [indices, values, shape]  and enqueue it by  input_api.enqueue(\"my-sparse-tensor\", input=tensor)  To enqueue an instance containing several images, tensors and sparse tensors.  import numpy as np\ninput_api.enqueue('my-instance', \n    img1={\"path: 'path/to/image1'},\n    img2={\"path: 'path/to/image2'},\n    tensor1=np.array([1,2]), \n    tensor2=np.array([[1,3],[2,3]])\n    sparse_tensor=[np.array([[0, 1, 4], [0, 2, 5]]),\n                   np.array([101, 102, 103])\n                   np.array([5, 10])]\n)",
            "title": "enqueue"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#predict",
            "text": "view source  predict(request_str)  return : Numpy ndarray  Example  from zoo.serving.client import InputQueue\ninput_api = InputQueue(sync=True, frontend_url=frontend_server_url)\nrequest_json_string='''{\n  \"instances\" : [ {\n    \"ids\" : [ 100.0, 88.0 ]\n  }]\n}'''\nresponse = input_api.predict(request_json_string)\nprint(response.text)",
            "title": "predict"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#class-outputqueue",
            "text": "The class  Output  defines methods allowing you to get result from Cluster Serving  Output Pipeline .",
            "title": "class OutputQueue"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#init_1",
            "text": "view source  __init__()  sets up a connection with configuration in your Cluster Serving  configuration file   config.yaml .",
            "title": "init"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#query",
            "text": "view source  query(uri)  query result in output Pipeline by key  uri  return : Numpy ndarray  Format:   {\n    \"class_1\": \"probability_1\",\n    \"class_2\": \"probability_2\",\n    ...,\n    \"class_n\": \"probability_n\"\n}  where  n  is  top_n  in your serving config, the result is sorted by output probability.  Example  from zoo.serving.client import OutputQueue\nimport json\noutput_api = OutputQueue()\nd = output_api.query('my-image') \n\ntmp_dict = json.loads(d)\nfor class_idx in tmp_dict.keys():\n    output += \"class: \" + class_idx + \"'s prob: \" + tmp_dict[class_idx]\nprint(output)",
            "title": "query"
        },
        {
            "location": "/ClusterServingGuide/APIGuide/#dequeue",
            "text": "view source  dequeue()  gets all result of your model prediction and dequeue them from OutputQueue  return : dict(), with keys the  uri  of your  enqueue , string type, and values the output of your prediction, Numpy ndarray  Format:   {\n  \"image1\": {\n      \"class_1\": \"probability_1\",\n      \"class_2\": \"probability_2\",\n      ...,\n      \"class_n\": \"probability_n\"\n  }, \n  \"image2\": {\n      \"class_1\": \"probability_1\",\n      \"class_2\": \"probability_2\",\n      ...,\n      \"class_n\": \"probability_n\"\n  }\n  ...\n}  where  n  is  top_n  in your serving config, the result is sorted by output probability.  Example  from zoo.serving.client import OutputQueue\nimport json\noutput_api = OutputQueue()\nd = output_api.dequeue()\n\nfor k in d.keys():\n    output = \"image: \" + k + \", classification-result:\"\n    tmp_dict = json.loads(result[k])\n    for class_idx in tmp_dict.keys():\n        output += \"class: \" + class_idx + \"'s prob: \" + tmp_dict[class_idx]\n    print(output)",
            "title": "dequeue"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/",
            "text": "TimeSequencePredictor\n\n\nTimeSequencePredictor\n can be used to train a pipeline (including feature engineering and model) for \nautomated time series forecasting in a distributed way. AutoML is applied for searching the best \nset of features as well as model hyper-parameters.\n\n\nMethods\n\n\n__init__\n\n\ntsp = TimeSequencePredictor(name=\"automl\",\n                            logs_dir=\"~/zoo_automl_logs\",\n                            future_seq_len=1,\n                            dt_col=\"datetime\",\n                            target_col=\"value\",\n                            extra_features_col=None,\n                            drop_missing=True,\n                            search_alg=None,\n                            search_alg_params=None,\n                            scheduler=None,\n                            scheduler_params=None,)\n\n\n\n\nArguments\n\n\n\n\n\n\nname\n: Name of the experiment.\n\n\n\n\n\n\nlogs_dir\n: Where the automl tune logs file located.\n\n\n\n\n\n\nfuture_seq_len\n: Integer. The future sequence length to be predicted. The default value is 1.\n\n\n\n\n\n\ndt_col\n: The name of datetime column of the input data frame.\n\n\n\n\n\n\ntarget_col\n: The name of target column to be predicted of the input data frame.\n\n\n\n\n\n\nextra_features_col\n: The name of extra features column that needs for prediction of the input data frame.\n\n\n\n\n\n\ndrop_missing\n: Boolean. Whether to drop missing values of the input data frame.\n\n\n\n\n\n\nsearch_alg\n: Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.\n\n\n\n\n\n\nsearch_alg_params\n: Optional(Dict). params of search_alg.\n\n\n\n\n\n\nscheduler\n: Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".\n\n\n\n\n\n\nscheduler_params\n: Optional(Dict). Necessary params of scheduler.\n\n\n\n\n\n\nfit\n\n\nTrain a pipeline for time series forecasting. It will return a \nTimeSequencePipeline\n object.\n\n\ntsp.fit(self,\n        input_df,\n        validation_df=None,\n        metric=\"mse\",\n        recipe=SmokeRecipe(),\n        mc=False,\n        resources_per_trial={\"cpu\": 2},\n        )\n\n\n\n\nArguments\n\n\n\n\n\n\ninput_df\n: Input time series data frame. It could look like:\n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue\n\n\n...\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n...\n\n\n\n\n\n\n2019-06-07\n\n\n2.3\n\n\n...\n\n\n\n\n\n\n\n\n\n\n\n\nvalidation_df\n: validation data frame. It should have the same columns with \ninput_df\n.\n\n\n\n\n\n\nmetric\n: String. Metric used for train and validation. Available values are \"mean_squared_error\" or \"mean_absolute_error\".\n\n\n\n\n\n\nrecipe\n: A Recipe object. Various recipes covers different search space and stopping criteria. Default is \nSmokeRecipe\n. \n              Available recipes are \nSmokeRecipe\n, \nRandomRecipe\n, \nGridRandomRecipe\n and \nBayesRecipe\n.\n\n\n\n\n\n\nresources_per_trial\n: Machine resources to allocate per trial, e.g. \n{\"cpu\": 64, \"gpu\": 8}\n.",
            "title": "TimeSequencePredictor"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#timesequencepredictor",
            "text": "TimeSequencePredictor  can be used to train a pipeline (including feature engineering and model) for \nautomated time series forecasting in a distributed way. AutoML is applied for searching the best \nset of features as well as model hyper-parameters.",
            "title": "TimeSequencePredictor"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#__init__",
            "text": "tsp = TimeSequencePredictor(name=\"automl\",\n                            logs_dir=\"~/zoo_automl_logs\",\n                            future_seq_len=1,\n                            dt_col=\"datetime\",\n                            target_col=\"value\",\n                            extra_features_col=None,\n                            drop_missing=True,\n                            search_alg=None,\n                            search_alg_params=None,\n                            scheduler=None,\n                            scheduler_params=None,)",
            "title": "__init__"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#arguments",
            "text": "name : Name of the experiment.    logs_dir : Where the automl tune logs file located.    future_seq_len : Integer. The future sequence length to be predicted. The default value is 1.    dt_col : The name of datetime column of the input data frame.    target_col : The name of target column to be predicted of the input data frame.    extra_features_col : The name of extra features column that needs for prediction of the input data frame.    drop_missing : Boolean. Whether to drop missing values of the input data frame.    search_alg : Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.    search_alg_params : Optional(Dict). params of search_alg.    scheduler : Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".    scheduler_params : Optional(Dict). Necessary params of scheduler.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#fit",
            "text": "Train a pipeline for time series forecasting. It will return a  TimeSequencePipeline  object.  tsp.fit(self,\n        input_df,\n        validation_df=None,\n        metric=\"mse\",\n        recipe=SmokeRecipe(),\n        mc=False,\n        resources_per_trial={\"cpu\": 2},\n        )",
            "title": "fit"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-predictor/#arguments_1",
            "text": "input_df : Input time series data frame. It could look like:     datetime  value  ...      2019-06-06  1.2  ...    2019-06-07  2.3  ...       validation_df : validation data frame. It should have the same columns with  input_df .    metric : String. Metric used for train and validation. Available values are \"mean_squared_error\" or \"mean_absolute_error\".    recipe : A Recipe object. Various recipes covers different search space and stopping criteria. Default is  SmokeRecipe . \n              Available recipes are  SmokeRecipe ,  RandomRecipe ,  GridRandomRecipe  and  BayesRecipe .    resources_per_trial : Machine resources to allocate per trial, e.g.  {\"cpu\": 64, \"gpu\": 8} .",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/recipe/",
            "text": "Recipe\n\n\nYou can use \nRecipe\n to choose some presets for the \nTimeSequencePredictor\n fitting process by passing to the \nrecipe\n field in the \nfit\n method.\n\n\nSmokeRecipe\n\n\nA very simple Recipe for smoke test that runs one epoch and one iteration with only 1 random sample.\n\n\nSmokeRecipe()\n\n\n\n\nLSTMRandomGridRecipe\n\n\nA recipe mixing random and grid using LSTM Model only\n\n\nLSTMGridRandomRecipe(num_rand_samples=1,epochs=5,training_iteration=10,look_back=2,lstm_1_units=[16, 32, 64, 128],lstm_2_units=[16, 32, 64], batch_size=[32, 64])\n\n\n\n\nArguments\n\n\n\n\n:param lstm_1_units: random search candidates for num of lstm_1_units\n\n\n:param lstm_2_units: grid search candidates for num of lstm_1_units\n\n\n:param batch_size: grid search candidates for batch size\n\n\n:param num_rand_samples: number of hyper-param configurations sampled randomly\n\n\n:param look_back: the length to look back, either a tuple with 2 int values,\n          which is in format is (min len, max len), or a single int, which is\n          a fixed length to look back.\n\n\n:param training_iteration: no. of iterations for training (n epochs) in trials\n\n\n:param epochs: no. of epochs to train in each iteration\n\n\n\n\nMTNetRandomGridRecipe\n\n\nA recipe mixing random and grid using MTNet Model only\n\n\nMTNetGridRandomRecipe(num_rand_samples=1,\n                 epochs=5,\n                 training_iteration=10,\n                 time_step=[3, 4],\n                 long_num=[3, 4],\n                 cnn_height=[2, 3],\n                 cnn_hid_size=[32, 50, 100],\n                 ar_size=[2, 3],\n                 batch_size=[32, 64])\n\n\n\n\nArguments\n\n\n\n\n:param num_rand_samples: number of hyper-param configurations sampled randomly\n\n\n:param training_iteration: no. of iterations for training (n epochs) in trials\n\n\n:param epochs: no. of epochs to train in each iteration\n\n\n:param time_step: random search candidates for model param \"time_step\"\n\n\n:param long_num: random search candidates for model param \"long_num\"\n\n\n:param ar_size: random search candidates for model param \"ar_size\"\n\n\n:param batch_size: grid search candidates for batch size\n\n\n:param cnn_height: random search candidates for model param \"cnn_height\"\n\n\n:param cnn_hid_size: random search candidates for model param \"cnn_hid_size\"\n\n\n\n\nRandomRecipe\n\n\nPure random sample Recipe. Often used as baseline.\n\n\nRandomRecipe(num_rand_samples=1, look_back=2)\n\n\n\n\nArguments\n\n\n\n\n\n\nnum_rand_samples\n: number of hyper-param configurations sampled randomly.\n\n\n\n\n\n\nlook_back\n: The length to look back. It could be\n\n\n\n\nA single int, which is a fixed length to look back. Note that the look back value should be larger than 1 to take the series information into account.\n\n\nA tuple with 2 int values, which is in format is (min len, max len). The \nmin len\n value should also be larger than 1.\n\n\n\n\n\n\n\n\nGridRandomRecipe\n\n\nA recipe involves both grid search and random search. The arguments are the same with \nRandomRecipe\n.\n\n\nGridRandomRecipe(num_rand_samples=1, look_back=2)\n\n\n\n\nBayesRecipe\n\n\nA recipe to search with Bayes Optimization. You need to pre-install \nbayesian-optimization\n before using the recipe.\n\n\nBayesRecipe(num_samples=1, look_back=2)",
            "title": "Recipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#recipe",
            "text": "You can use  Recipe  to choose some presets for the  TimeSequencePredictor  fitting process by passing to the  recipe  field in the  fit  method.",
            "title": "Recipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#smokerecipe",
            "text": "A very simple Recipe for smoke test that runs one epoch and one iteration with only 1 random sample.  SmokeRecipe()",
            "title": "SmokeRecipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#lstmrandomgridrecipe",
            "text": "A recipe mixing random and grid using LSTM Model only  LSTMGridRandomRecipe(num_rand_samples=1,epochs=5,training_iteration=10,look_back=2,lstm_1_units=[16, 32, 64, 128],lstm_2_units=[16, 32, 64], batch_size=[32, 64])",
            "title": "LSTMRandomGridRecipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#arguments",
            "text": ":param lstm_1_units: random search candidates for num of lstm_1_units  :param lstm_2_units: grid search candidates for num of lstm_1_units  :param batch_size: grid search candidates for batch size  :param num_rand_samples: number of hyper-param configurations sampled randomly  :param look_back: the length to look back, either a tuple with 2 int values,\n          which is in format is (min len, max len), or a single int, which is\n          a fixed length to look back.  :param training_iteration: no. of iterations for training (n epochs) in trials  :param epochs: no. of epochs to train in each iteration",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#mtnetrandomgridrecipe",
            "text": "A recipe mixing random and grid using MTNet Model only  MTNetGridRandomRecipe(num_rand_samples=1,\n                 epochs=5,\n                 training_iteration=10,\n                 time_step=[3, 4],\n                 long_num=[3, 4],\n                 cnn_height=[2, 3],\n                 cnn_hid_size=[32, 50, 100],\n                 ar_size=[2, 3],\n                 batch_size=[32, 64])",
            "title": "MTNetRandomGridRecipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#arguments_1",
            "text": ":param num_rand_samples: number of hyper-param configurations sampled randomly  :param training_iteration: no. of iterations for training (n epochs) in trials  :param epochs: no. of epochs to train in each iteration  :param time_step: random search candidates for model param \"time_step\"  :param long_num: random search candidates for model param \"long_num\"  :param ar_size: random search candidates for model param \"ar_size\"  :param batch_size: grid search candidates for batch size  :param cnn_height: random search candidates for model param \"cnn_height\"  :param cnn_hid_size: random search candidates for model param \"cnn_hid_size\"",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#randomrecipe",
            "text": "Pure random sample Recipe. Often used as baseline.  RandomRecipe(num_rand_samples=1, look_back=2)",
            "title": "RandomRecipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#arguments_2",
            "text": "num_rand_samples : number of hyper-param configurations sampled randomly.    look_back : The length to look back. It could be   A single int, which is a fixed length to look back. Note that the look back value should be larger than 1 to take the series information into account.  A tuple with 2 int values, which is in format is (min len, max len). The  min len  value should also be larger than 1.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#gridrandomrecipe",
            "text": "A recipe involves both grid search and random search. The arguments are the same with  RandomRecipe .  GridRandomRecipe(num_rand_samples=1, look_back=2)",
            "title": "GridRandomRecipe"
        },
        {
            "location": "/APIGuide/AutoML/recipe/#bayesrecipe",
            "text": "A recipe to search with Bayes Optimization. You need to pre-install  bayesian-optimization  before using the recipe.  BayesRecipe(num_samples=1, look_back=2)",
            "title": "BayesRecipe"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/",
            "text": "TimeSequencePipeline\n\n\nTimeSequencePipeline\n integrates feature engineering and time sequence model into a data analysis pipeline.\nYou can get an \nTimeSequencePipeline\n object after calling \nTimeSequencePredictor.fit()\n or \nload_ts_pipeline\n.\n\n\nMethods\n\n\nload_ts_pipeline\n\n\nts_pipeline = load_ts_pipeline(file)\n\n\n\n\nArguments\n\n\n\n\nfile\n: saved ts pipeline file.\n\n\n\n\ndescribe\n\n\nSince you may get your \nts_pipeline\n from a saved file which is a result pipeline of \nTimeSeqencePredictor\n. You can use\n\ndescribe\n method to get the initialization info for the \nTimeSeqencePredictor\n, including \nfuture_seq_len\n, \ndt_col\n, \ntarget_col\n, \nextra_features_col\n, \ndrop_missing\n.\n\n\nts_pipeline.describe()\n\n\n\n\nfit\n\n\nUsed for incremental fitting. Note that \nfit\n in \nTimeSequencePipeline\n doesn`t run in distributed mode.\n\n\nts_pipeline.fit(input_df, validation_df=None, mc=False, epoch_num=20)\n\n\n\n\nArguments\n\n\n\n\n\n\ninput_df\n: Input time series data frame. It should have the same datetime column, target column, \n                extra features columns (if there are) name with the names you got from \nts_pipeline.describe()\n. \n\n\n\n\n\n\nvalidation_df\n: The validation data frame. It should have the same columns with \ninput_df\n.\n\n\n\n\n\n\nmc\n: Boolean. Whether to use Monte Carlo Dropout to predict with uncertainty. Default is False.\n          You can refer to the paper \nhere\n for more details about Monte Carlo Dropout. \n\n\n\n\n\n\nepoch_num\n: Integer. Number of epochs to run incremental fitting.\n\n\n\n\n\n\nevaluate\n\n\nts_pipeline.evaluate(input_df,\n                     metrics=[\"mse\"],\n                     multioutput=`raw_values`)\n\n\n\n\nArguments\n\n\n\n\n\n\ninput_df\n: Input data frame. It should have the same column names as the data frame you used to train your \nTimeSequencePredictor\n. \n                And you can get the information with \npipeline.describe()\n \n\n\n\n\n\n\nmetrics\n: The metrics you want to use for evaluation. The available metrics are \n               \nme\n, \nmae\n, \nmse\n, \nrmse\n, \nmsle\n, \nr2\n, \nmpe\n, \nmape\n, \nmspe\n, \nsmape\n, \nmdape\n and \nsmdape\n.\n\n\n\n\n\n\nmultioutput\n: string in [\nraw_values\n, \nuniform_average\n]\n\n\n        - `raw_values` : Returns a full set of errors.\n        - `uniform_average` : Errors of all outputs are averaged with uniform weight.\n\n\n\n\n\n\n\npredict\n\n\nts_pipeline.predict(input_df)\n\n\n\n\nArguments\n\n\n\n\ninput_df\n: Input data frame to do prediction.It should have the same column names as the data frame you used to train your \nTimeSequencePredictor\n. \n                And you can get the information with \npipeline.describe()\n \n    - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,\n\n\n\n\n\n\n\nsave\n\n\nts_pipeline.save(ppl_file=\"my.ppl\")\n\n\n\n\nArguments\n\n\n\n\nppl_file\n: The file name you want to save your pipeline.\n\n\n\n\nconfig_save\n\n\nts_pipeline.config_save(config_file==\"my.json\")\n\n\n\n\nArguments\n\n\n\n\nconfig_file\n: The config file name that you want to save all the pipeline configs in.",
            "title": "TimeSequencePipeline"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#timesequencepipeline",
            "text": "TimeSequencePipeline  integrates feature engineering and time sequence model into a data analysis pipeline.\nYou can get an  TimeSequencePipeline  object after calling  TimeSequencePredictor.fit()  or  load_ts_pipeline .",
            "title": "TimeSequencePipeline"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#load_ts_pipeline",
            "text": "ts_pipeline = load_ts_pipeline(file)",
            "title": "load_ts_pipeline"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments",
            "text": "file : saved ts pipeline file.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#describe",
            "text": "Since you may get your  ts_pipeline  from a saved file which is a result pipeline of  TimeSeqencePredictor . You can use describe  method to get the initialization info for the  TimeSeqencePredictor , including  future_seq_len ,  dt_col ,  target_col ,  extra_features_col ,  drop_missing .  ts_pipeline.describe()",
            "title": "describe"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#fit",
            "text": "Used for incremental fitting. Note that  fit  in  TimeSequencePipeline  doesn`t run in distributed mode.  ts_pipeline.fit(input_df, validation_df=None, mc=False, epoch_num=20)",
            "title": "fit"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments_1",
            "text": "input_df : Input time series data frame. It should have the same datetime column, target column, \n                extra features columns (if there are) name with the names you got from  ts_pipeline.describe() .     validation_df : The validation data frame. It should have the same columns with  input_df .    mc : Boolean. Whether to use Monte Carlo Dropout to predict with uncertainty. Default is False.\n          You can refer to the paper  here  for more details about Monte Carlo Dropout.     epoch_num : Integer. Number of epochs to run incremental fitting.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#evaluate",
            "text": "ts_pipeline.evaluate(input_df,\n                     metrics=[\"mse\"],\n                     multioutput=`raw_values`)",
            "title": "evaluate"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments_2",
            "text": "input_df : Input data frame. It should have the same column names as the data frame you used to train your  TimeSequencePredictor . \n                And you can get the information with  pipeline.describe()      metrics : The metrics you want to use for evaluation. The available metrics are \n                me ,  mae ,  mse ,  rmse ,  msle ,  r2 ,  mpe ,  mape ,  mspe ,  smape ,  mdape  and  smdape .    multioutput : string in [ raw_values ,  uniform_average ]          - `raw_values` : Returns a full set of errors.\n        - `uniform_average` : Errors of all outputs are averaged with uniform weight.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#predict",
            "text": "ts_pipeline.predict(input_df)",
            "title": "predict"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments_3",
            "text": "input_df : Input data frame to do prediction.It should have the same column names as the data frame you used to train your  TimeSequencePredictor . \n                And you can get the information with  pipeline.describe()       - a TFDataset object\n    - A Numpy array (or array-like), or a list of arrays\n       (in case the model has multiple inputs).\n    - A dict mapping input names to the corresponding array/tensors,",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#save",
            "text": "ts_pipeline.save(ppl_file=\"my.ppl\")",
            "title": "save"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments_4",
            "text": "ppl_file : The file name you want to save your pipeline.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#config_save",
            "text": "ts_pipeline.config_save(config_file==\"my.json\")",
            "title": "config_save"
        },
        {
            "location": "/APIGuide/AutoML/time-sequence-pipeline/#arguments_5",
            "text": "config_file : The config file name that you want to save all the pipeline configs in.",
            "title": "Arguments"
        },
        {
            "location": "/APIGuide/FeatureEngineering/featureset/",
            "text": "A FeatureSet can be used to represent an input pipeline as a collection of elements which is used in the model optimization process. You can use FeatureSet to switch the memory type between \nDRAM\n, \nDISK_AND_DRAM(numSlice)\n \nand \nPMEM\n in consideration of the hardware optimization.\n* \nDRAM\n is the default mode which would cached the training data in main memory.\n* \nDISK_AND_DRAM(numSlice)\n mode will cache training data in disk, and only hold 1/numSlice of data in main memory. After going through the 1/numSlice, we will release the current cache, and load another 1/numSlice into memory.\n* \nPMEM\n mode would try to cache the training data in persistent memory rather than main memory. You should install the Intel Optane DC Persistent Memory hardware to AD mode before switching to this option. \n\n\nScala example:\n\n\nIn scala, user can create a DRAM or DISK_AND_DRAM FeatureSet from any RDD. \nBut PMEM FeatureSet only support RDD of ByteRecord, Sample or ImageFeature.\n\n\nimport com.intel.analytics.zoo.feature.FeatureSet\nimport com.intel.analytics.zoo.feature.pmem.{DRAM, DISK_AND_DRAM, PMEM}\n// DRAM featureSet\nval dramSet = FeatureSet.rdd(rawRDD, memoryType = DRAM)\n// DISK_AND_DRAM featureSet\nval diskSet = FeatureSet.rdd(rawRDD, memoryType = DISK_AND_DRAM(10))\n// PMEM featureSet\nval pmemSet = FeatureSet.rdd(rawRDD, memoryType = PMEM)\n// Add your transformer: featureSet -> feature transformer -> batch and sample transformer\nval dataSet = ...\n\n\n\n\nTake a look at \nInceptionV1 example scala version\n for more details.\n\n\nPython example:\nIn python, user can create FeatureSet from RDD, ImageSet, and ImageFrame.\n\n\nfrom zoo.feature.common import FeatureSet\ndramSet = FeatureSet.rdd(rawRDD, memory_type = \"DRAM\")\n# DISK_AND_DRAM featureSet\ndiskSet = FeatureSet.rdd(rawRDD, memoryType = \"10\")\n#PMEM featureSet\npmemSet = FeatureSet.rdd(rawRDD, memoryType = \"PMEM\")\n#Add your transformer: featureSet -> feature transformer -> batch and sample transformer\ndataSet = ...\n\n\n\n\nTake a look at \nInceptionV1 example python version\n for more details.",
            "title": "FeatureSet"
        },
        {
            "location": "/APIGuide/FeatureEngineering/relation/",
            "text": "A Relation represents the relationship between two items.\n\n\nScala/Python\n\n\nrelation = Relation(id1, id2, label)\n\n\n\n\n\n\nid1\n: String. The id of one item.\n\n\nid2\n: String. The id of the other item.\n\n\nlabel\n: Integer. The label between the two items. By convention you can use 0 if they are unrelated and a positive integer if they are related.\n\n\n\n\nA RelationPair is made up of two relations of the same id1, namely:\n\n\n\n\nRelation(id1, id2Positive, label>0) (A positive Relation)\n\n\nRelation(id1, id2Negative, label=0) (A negative Relation)\n\n\n\n\n\n\nRead Relations\n\n\nFrom csv or txt file\n\n\nEach record is supposed to contain id1, id2 and label described above in the exact order.\n\n\nFor csv file, it should be without header.\n\n\nFor txt file, each line should contain one record with fields separated by comma.\n\n\nScala\n\n\nrelationsRDD = Relations.read(path, sc, minPartitions = 1)\nrelationsArray = Relations.read(path)\n\n\n\n\n\n\npath\n: The path to the relations file, which can either be a local or distributed file system (such as HDFS) path (in this case sc needs to be specified).\n\n\nsc\n: An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation.\n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.\n\n\n\n\nPython\n\n\nrelations_rdd = Relations.read(path, sc, min_partitions = 1)\nrelations_list = Relations.read(path)\n\n\n\n\n\n\npath\n: The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).\n\n\nsc\n: An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation.\n\n\nmin_partitions\n: Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.\n\n\n\n\nFrom parquet file\n\n\nRead relations from parquet file exactly with the schema in Relation. Return RDD of Relation.\n\n\nScala\n\n\nrelationsRDD = Relations.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\nrelations_rdd = Relations.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.",
            "title": "Relation"
        },
        {
            "location": "/APIGuide/FeatureEngineering/relation/#read-relations",
            "text": "From csv or txt file  Each record is supposed to contain id1, id2 and label described above in the exact order.  For csv file, it should be without header.  For txt file, each line should contain one record with fields separated by comma.  Scala  relationsRDD = Relations.read(path, sc, minPartitions = 1)\nrelationsArray = Relations.read(path)   path : The path to the relations file, which can either be a local or distributed file system (such as HDFS) path (in this case sc needs to be specified).  sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation.  minPartitions : Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.   Python  relations_rdd = Relations.read(path, sc, min_partitions = 1)\nrelations_list = Relations.read(path)   path : The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).  sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation.  min_partitions : Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.   From parquet file  Read relations from parquet file exactly with the schema in Relation. Return RDD of Relation.  Scala  relationsRDD = Relations.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  relations_rdd = Relations.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.",
            "title": "Read Relations"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/",
            "text": "Analytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nScala:\n\n\npackage com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame\n}\n\n\n\n\nRead the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.\n\n\n\n\npath: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).\n\n\nsc: SparkContext to be used.\n\n\nminPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead\n\n\nresizeH: height after resize, by default is -1 which will not resize the image\n\n\nresizeW: width after resize, by default is -1 which will not resize the image\n\n\n\n\nPython:\n\n\nclass zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type=\"float\")\n\n\n\n\nImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala APIs:\n\n\nobject com.intel.analytics.zoo.feature.image.ImageSet\n\n\n\n\ndef array(data: Array[ImageFeature]): LocalImageSet\n\n\n\n\nCreate LocalImageSet from array of ImeageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\ndef rdd(data: RDD[ImageFeature]): DistributedImageSet\n\n\n\n\nCreate DistributedImageSet from rdd of ImageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\ndef read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\nresizeH: height after resize, by default is -1 which will not resize the image\n\n\nresizeW: width after resize, by default is -1 which will not resize the image\n\n\n\n\nExample:\n\n\n// create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\"/tmp/image/\")\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\"/tmp/image/\", sc, 2)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.ImageSet\n\n\n\n\nread(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type=\"float\")\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nmin_partitions: A suggestion value of the minimal splitting number for input data.\n\n\nresize_height height after resize, by default is -1 which will not resize the image\n\n\nresize_width width after resize, by default is -1 which will not resize the image\n\n\n\n\nPython example:\n\n\n# create LocalImageSet from an image folder\nlocal_image_set2 = ImageSet.read(\"/tmp/image/\")\n\n# create DistributedImageSet from an image folder\ndistributed_image_set = ImageSet.read(\"/tmp/image/\", sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. \n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndeltaLow: low bound of brightness parameter\n\n\ndeltaHigh: high bound of brightness parameter\n\n\n\n\nExample:\n\n\nval transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type=\"float\")\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndelta_low: low bound of brightness parameter\n\n\ndelta_high: high bound of brightness parameter\n\n\n\n\nExample:\n\n\ntransformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)\n\n\n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBytesToMat\n\ndef apply(byteKey: String = ImageFeature.bytes,\n          imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat\n\n\n\n\nTransform byte array(original image file in byte) to OpenCVMat\n\n\n\n\nbyteKey: key that maps byte array. Default value is ImageFeature.bytes\n\n\nimageCodec: specifying the color type of a loaded image, same as in OpenCV.imread.\n              1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.\n              2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one\n              3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one\n              4. >0 Return a 3-channel color image.\n              Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel.\n              5. =0 Return a grayscale image.\n              6. <0 Return the loaded image as is (with alpha channel).\n              Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED.\n\n\n\n\nExample:\n\n\nval imageSet = ImageSet.read(path, sc)\nimageSet -> ImageBytesToMat()\n\n\n\n\n3D Image Support\n\n\nCreate ImageSet for 3D Images\n\n\nFor 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python).\n\n\nScala example:\n\n\nval image = ImageFeature3D(tensor)\n\n// create local imageset for 3D images\nval arr = Array[ImageFeature](image)\nval localImageSet = ImageSet.array(arr)\n\n// create distributed imageset for 3D images\nval rdd = sc.parallelize(Seq[ImageFeature](image))\nval imageSet = ImageSet.rdd(rdd)\n\n\n\n\nPython example:\n\n\n\n# get image numpy array\nimg_np =\n\n# create local imageset for 3D images\nlocal_imageset = LocalImageSet(image_list=[img_np])\n\n# create distributed imageset for 3D images\nrdd = sc.parallelize([img_np])\ndist_imageSet = DistributedImageSet(image_rdd=rdd)\n\n\n\n\n3D Image Transformers\n\n\nAnalytics zoo also provides several image transformers for 3D Images.\nThe usage is similar as 2D image transformers. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet.\n\n\nCurrently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation.\n\n\nCrop transformers\n\n\nCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.Crop3D\n\n// create Crop3D transformer\nval cropper = Crop3D(start, patchSize)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size.\n   * start: start point array(depth, height, width) for cropping\n   * patchSize: patch size array(depth, height, width)\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import Crop3D\n\ncrop = Crop3D(start, patch_size)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\nstart: start point list[]depth, height, width] for cropping\n\n\npatch_size: patch size list[]depth, height, width]\n\n\n\n\nRandomCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.RandomCrop3D\n\n// create Crop3D transformer\nval cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a random patch from an 3D image with specified patch size. The patch size should be less than the image size.\n* cropDepth: depth after crop\n* cropHeight: height after crop\n* cropWidth: width after crop\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import RandomCrop3D\n\ncrop = RandomCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\ncrop_depth: depth after crop\n\n\ncrop_height: height after crop\n\n\ncrop_width: width after crop\n\n\n\n\nCenterCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.CenterCrop3D\n\n// create Crop3D transformer\nval cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a \ncropDepth\n x \ncropWidth\n x \ncropHeight\n patch from center of image. The patch size should be less than the image size.\n* cropDepth: depth after crop\n* cropHeight: height after crop\n* cropWidth: width after crop\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import CenterCrop3D\n\ncrop = CenterCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\ncrop_depth: depth after crop\n\n\ncrop_height: height after crop\n\n\ncrop_width: width after crop\n\n\n\n\nRotation\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.Rotate3D\n\n// create Crop3D transformer\nval rotAngles = Array[Double](yaw, pitch, roll)\nval rot = Rotate3D(rotAngles)\nval outputImageSet = imageset.transform(rot)\n\n\n\n\nRotate a 3D image with specified angles.\n* rotationAngles: the angles for rotation.\n   Which are the yaw(a counterclockwise rotation angle about the z-axis),\n   pitch(a counterclockwise rotation angle about the y-axis),\n   and roll(a counterclockwise rotation angle about the x-axis).\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import Rotate3D\n\nrot = Rotate3D(rotation_angles)\ntransformed_image = rot(image_set)\n\n\n\n\nAffine Transformation\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.AffineTransform3D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// create Crop3D transformer\nval matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4)\nval matTensor = Tensor[Double](matArray, Array[Int](3, 3))\nval trans = Tensor[Double](3)\ntrans(1) = 0\ntrans(2) = 1.8\ntrans(3) = 1.1\nval aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode = \"clamp\", padVal = 0)\nval outputImageSet = imageset.transform(aff)\n\n\n\n\nAffine transformer implements affine transformation on a given tensor.\nTo avoid defects in resampling, the mapping is from destination to source.\ndst(z,y,x) = src(f(z),f(y),f(x)) where f: dst -> src\n\n\n\n\nmat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src.\n\n\ntranslation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis.\n\n\nclampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image.\n\n\npadVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.\n\n\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import AffineTransform3D\n\naffine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val)\ntransformed_image = affine(image_set)\n\n\n\n\n\n\naffine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src.\n\n\ntranslation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis.\n\n\nclamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image.\n\n\npad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.",
            "title": "Image"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-image",
            "text": "Analytics Zoo provides APIs to read image to different formats:",
            "title": "Load Image"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-to-data-frame",
            "text": "Scala:  package com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame\n}  Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.   path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).  sc: SparkContext to be used.  minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead  resizeH: height after resize, by default is -1 which will not resize the image  resizeW: width after resize, by default is -1 which will not resize the image   Python:  class zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type=\"float\")",
            "title": "Load to Data Frame"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#imageset",
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala APIs:  object com.intel.analytics.zoo.feature.image.ImageSet  def array(data: Array[ImageFeature]): LocalImageSet  Create LocalImageSet from array of ImeageFeature   data: array of ImageFeature   def rdd(data: RDD[ImageFeature]): DistributedImageSet  Create DistributedImageSet from rdd of ImageFeature   data: array of ImageFeature   def read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.  resizeH: height after resize, by default is -1 which will not resize the image  resizeW: width after resize, by default is -1 which will not resize the image   Example:  // create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\"/tmp/image/\")\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\"/tmp/image/\", sc, 2)  Python APIs:  class zoo.feature.image.ImageSet  read(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type=\"float\")  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  min_partitions: A suggestion value of the minimal splitting number for input data.  resize_height height after resize, by default is -1 which will not resize the image  resize_width width after resize, by default is -1 which will not resize the image   Python example:  # create LocalImageSet from an image folder\nlocal_image_set2 = ImageSet.read(\"/tmp/image/\")\n\n# create DistributedImageSet from an image folder\ndistributed_image_set = ImageSet.read(\"/tmp/image/\", sc, 2)",
            "title": "ImageSet"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#image-transformer",
            "text": "Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call  transform  with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training.   Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness  Adjust the image brightness.   deltaLow: low bound of brightness parameter  deltaHigh: high bound of brightness parameter   Example:  val transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)  Python APIs:  class zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type=\"float\")  Adjust the image brightness.   delta_low: low bound of brightness parameter  delta_high: high bound of brightness parameter   Example:  transformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)  Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBytesToMat\n\ndef apply(byteKey: String = ImageFeature.bytes,\n          imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat  Transform byte array(original image file in byte) to OpenCVMat   byteKey: key that maps byte array. Default value is ImageFeature.bytes  imageCodec: specifying the color type of a loaded image, same as in OpenCV.imread.\n              1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.\n              2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one\n              3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one\n              4. >0 Return a 3-channel color image.\n              Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel.\n              5. =0 Return a grayscale image.\n              6. <0 Return the loaded image as is (with alpha channel).\n              Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED.   Example:  val imageSet = ImageSet.read(path, sc)\nimageSet -> ImageBytesToMat()",
            "title": "Image Transformer"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#3d-image-support",
            "text": "",
            "title": "3D Image Support"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#create-imageset-for-3d-images",
            "text": "For 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python).  Scala example:  val image = ImageFeature3D(tensor)\n\n// create local imageset for 3D images\nval arr = Array[ImageFeature](image)\nval localImageSet = ImageSet.array(arr)\n\n// create distributed imageset for 3D images\nval rdd = sc.parallelize(Seq[ImageFeature](image))\nval imageSet = ImageSet.rdd(rdd)  Python example:  \n# get image numpy array\nimg_np =\n\n# create local imageset for 3D images\nlocal_imageset = LocalImageSet(image_list=[img_np])\n\n# create distributed imageset for 3D images\nrdd = sc.parallelize([img_np])\ndist_imageSet = DistributedImageSet(image_rdd=rdd)",
            "title": "Create ImageSet for 3D Images"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#3d-image-transformers",
            "text": "Analytics zoo also provides several image transformers for 3D Images.\nThe usage is similar as 2D image transformers. After create these transformers, call  transform  with ImageSet to get transformed ImageSet.  Currently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation.",
            "title": "3D Image Transformers"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#crop-transformers",
            "text": "",
            "title": "Crop transformers"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#crop3d",
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.Crop3D\n\n// create Crop3D transformer\nval cropper = Crop3D(start, patchSize)\nval outputImageSet = imageset.transform(cropper)  Crop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size.\n   * start: start point array(depth, height, width) for cropping\n   * patchSize: patch size array(depth, height, width)  Python:  from zoo.feature.image3d.transformation import Crop3D\n\ncrop = Crop3D(start, patch_size)\ntransformed_image = crop(image_set)   start: start point list[]depth, height, width] for cropping  patch_size: patch size list[]depth, height, width]",
            "title": "Crop3D"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#randomcrop3d",
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.RandomCrop3D\n\n// create Crop3D transformer\nval cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)  Crop a random patch from an 3D image with specified patch size. The patch size should be less than the image size.\n* cropDepth: depth after crop\n* cropHeight: height after crop\n* cropWidth: width after crop  Python:  from zoo.feature.image3d.transformation import RandomCrop3D\n\ncrop = RandomCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)   crop_depth: depth after crop  crop_height: height after crop  crop_width: width after crop",
            "title": "RandomCrop3D"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#centercrop3d",
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.CenterCrop3D\n\n// create Crop3D transformer\nval cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)  Crop a  cropDepth  x  cropWidth  x  cropHeight  patch from center of image. The patch size should be less than the image size.\n* cropDepth: depth after crop\n* cropHeight: height after crop\n* cropWidth: width after crop  Python:  from zoo.feature.image3d.transformation import CenterCrop3D\n\ncrop = CenterCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)   crop_depth: depth after crop  crop_height: height after crop  crop_width: width after crop",
            "title": "CenterCrop3D"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#rotation",
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.Rotate3D\n\n// create Crop3D transformer\nval rotAngles = Array[Double](yaw, pitch, roll)\nval rot = Rotate3D(rotAngles)\nval outputImageSet = imageset.transform(rot)  Rotate a 3D image with specified angles.\n* rotationAngles: the angles for rotation.\n   Which are the yaw(a counterclockwise rotation angle about the z-axis),\n   pitch(a counterclockwise rotation angle about the y-axis),\n   and roll(a counterclockwise rotation angle about the x-axis).  Python:  from zoo.feature.image3d.transformation import Rotate3D\n\nrot = Rotate3D(rotation_angles)\ntransformed_image = rot(image_set)",
            "title": "Rotation"
        },
        {
            "location": "/APIGuide/FeatureEngineering/image/#affine-transformation",
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.AffineTransform3D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// create Crop3D transformer\nval matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4)\nval matTensor = Tensor[Double](matArray, Array[Int](3, 3))\nval trans = Tensor[Double](3)\ntrans(1) = 0\ntrans(2) = 1.8\ntrans(3) = 1.1\nval aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode = \"clamp\", padVal = 0)\nval outputImageSet = imageset.transform(aff)  Affine transformer implements affine transformation on a given tensor.\nTo avoid defects in resampling, the mapping is from destination to source.\ndst(z,y,x) = src(f(z),f(y),f(x)) where f: dst -> src   mat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src.  translation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis.  clampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image.  padVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.   Python:  from zoo.feature.image3d.transformation import AffineTransform3D\n\naffine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val)\ntransformed_image = affine(image_set)   affine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src.  translation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis.  clamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image.  pad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.",
            "title": "Affine Transformation"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/",
            "text": "Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline,\nincluding text loading, pre-processing, training and inference, etc.\n\n\n\n\nTextSet\n\n\nTextSet\n is a collection of TextFeatures where each \nTextFeature\n keeps information of a single text record.\n\n\nTextSet\n can either be a \nDistributedTextSet\n consisting of text RDD or a \nLocalTextSet\n consisting of text array.\n\n\n\n\nRead texts as TextSet\n\n\nRead texts from a directory\n\n\nRead texts with labels from a directory.\n\n\nUnder this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.\n\n\nScala\n\n\ntextSet = TextSet.read(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from csv file\n\n\nRead texts with id from csv file.\n\n\nEach record is supposed to contain id(String) and text(String) in order.\n\n\nNote that the csv file should be without header.\n\n\nScala\n\n\ntextSet = TextSet.readCSV(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_csv(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from parquet file\n\n\nRead texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.\n\n\nScala\n\n\ntextSet = TextSet.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.\n\n\n\n\n\n\nTextSet Transformations\n\n\nAnalytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference:\n\n\nTokenization\n\n\nDo tokenization on original text.\n\n\nScala\n\n\ntransformedTextSet = textSet.tokenize()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.tokenize()\n\n\n\n\nNormalization\n\n\nRemoves all dirty (non English alphabet) characters from tokens and converts words to lower case. \nNeed to tokenize first.\n\n\nScala\n\n\ntransformedTextSet = textSet.normalize()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.normalize()\n\n\n\n\nWord To Index\n\n\nMap word tokens to indices.\n\n\nImportant:\n Take care that this method behaves a bit differently for training and inference.\n\n\nTraining\n\n\nDuring the training, you need to generate a new word index correspondence according to the texts\nyou are dealing with. Thus this method will first do the vocabulary generation and then\nconvert words to indices based on the generated vocabulary.\n\n\nThe following arguments pose some constraints when generating the vocabulary.\nIn the result vocabulary, index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order. \n\n\nHere we adopt the convention that index 0 will be reserved for unknown words.\nNeed to tokenize first.\n\n\nAfter word2idx, you can get the generated word index vocabulary by calling \ngetWordIndex\n (Scala) or \nget_word_index()\n (Python) of the transformed TextSet.\n\n\nAlso, you can call \nsaveWordIndex(path)\n (Scala) \nsave_word_index(path)\n (Python) to \nsave\n this word index vocabulary to be used in\nfuture training.\n\n\nInference\n\n\nDuring the inference, you are supposed to use exactly the same word index correspondence as in the\ntraining stage instead of generating a new one. Need to tokenize first.\n\n\nThus please be aware that you do not need to specify any of the below arguments.\n\n\nYou need to call \nloadWordIndex(path)\n (Scala) or \nload_word_index(path)\n (Python) beforehand for word index \nloading\n.\n\n\nScala\n\n\ntransformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null)\n\n\n\n\n\n\nremoveTopN\n: Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.\n\n\nmaxWordsNum\n: Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer.\n\n\nminFreq\n: Positive integer. Only those words with frequency >= minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered.\n\n\nexistingMap\n: Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. \nIf not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words.\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None)\n\n\n\n\n\n\nremove_topN\n: Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.\n\n\nmax_words_num\n: Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int.\n\n\nmin_freq\n: Positive int. Only those words with frequency >= min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered.\n\n\nexisting_map\n: Existing dictionary of word index if any. Default is None and in this case a new dictionary with index starting from 1 will be generated. \nIf not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words.\n\n\n\n\nSequence Shaping\n\n\nShape the sequence of indices to a fixed length. \nNeed to word2idx first.\n\n\nScala\n\n\ntransformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0)\n\n\n\n\n\n\nlen\n: Positive integer. The target length.\n\n\ntruncMode\n: Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. \nIf 'TruncMode.pre', the sequence will be truncated from the beginning. \nIf 'TruncMode.post', the sequence will be truncated from the end. \nDefault is 'TruncMode.post'.\n\n\npadElement\n: Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.shape_sequence(len, trunc_mode=\"pre\", pad_element=0)\n\n\n\n\n\n\nlen\n: Positive int. The target length.\n\n\ntrunc_mode\n: String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. \nIf 'pre', the sequence will be truncated from the beginning. \nIf 'post', the sequence will be truncated from the end. \nDefault is 'post'.\n\n\npad_element\n: Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.\n\n\n\n\nBigDL Sample Generation\n\n\nTransform indices and label (if any) to a BigDL \nSample\n. \nNeed to word2idx first.\n\n\nScala\n\n\ntransformedTextSet = textSet.generateSample()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.generate_sample()\n\n\n\n\n\n\nWordEmbedding\n\n\nThis is a special Embedding layer that directly loads pre-trained word vectors as weights, \nwhich turns non-negative integers (indices) into dense vectors of fixed size.\n\n\nCurrently only GloVe embedding is supported for this layer.\n\n\nThe input of this layer should be 2D.\n\n\nScala\n\n\nembedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)\n\n\n\n\n\n\nembeddingFile\n: The path to the word embedding file. Currently \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not. Only false is supported for now.\n\n\ninputLength\n: Positive integer. The sequence length of each input.\n\n\n\n\nPython\n\n\nembedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None)\n\n\n\n\n\n\nembedding_file\n The path to the word embedding file. Currently \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not. Only False is supported for now.\n\n\ninputLength\n: Positive int. The sequence length of each input.",
            "title": "Text"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#textset",
            "text": "TextSet  is a collection of TextFeatures where each  TextFeature  keeps information of a single text record.  TextSet  can either be a  DistributedTextSet  consisting of text RDD or a  LocalTextSet  consisting of text array.",
            "title": "TextSet"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-as-textset",
            "text": "",
            "title": "Read texts as TextSet"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-a-directory",
            "text": "Read texts with labels from a directory.  Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.  Scala  textSet = TextSet.read(path, sc = null, minPartitions = 1)   path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read(path, sc=None, min_partitions=1)   path : String. Folder path to texts. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.",
            "title": "Read texts from a directory"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-csv-file",
            "text": "Read texts with id from csv file.  Each record is supposed to contain id(String) and text(String) in order.  Note that the csv file should be without header.  Scala  textSet = TextSet.readCSV(path, sc = null, minPartitions = 1)   path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read_csv(path, sc=None, min_partitions=1)   path : String. The path to the csv file. Local or distributed file system (such as HDFS) are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.",
            "title": "Read texts from csv file"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-parquet-file",
            "text": "Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.  Scala  textSet = TextSet.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  text_set = TextSet.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.",
            "title": "Read texts from parquet file"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#textset-transformations",
            "text": "Analytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference:",
            "title": "TextSet Transformations"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#tokenization",
            "text": "Do tokenization on original text.  Scala  transformedTextSet = textSet.tokenize()  Python  transformed_text_set = text_set.tokenize()",
            "title": "Tokenization"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#normalization",
            "text": "Removes all dirty (non English alphabet) characters from tokens and converts words to lower case. \nNeed to tokenize first.  Scala  transformedTextSet = textSet.normalize()  Python  transformed_text_set = text_set.normalize()",
            "title": "Normalization"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#word-to-index",
            "text": "Map word tokens to indices.  Important:  Take care that this method behaves a bit differently for training and inference.  Training  During the training, you need to generate a new word index correspondence according to the texts\nyou are dealing with. Thus this method will first do the vocabulary generation and then\nconvert words to indices based on the generated vocabulary.  The following arguments pose some constraints when generating the vocabulary.\nIn the result vocabulary, index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order.   Here we adopt the convention that index 0 will be reserved for unknown words.\nNeed to tokenize first.  After word2idx, you can get the generated word index vocabulary by calling  getWordIndex  (Scala) or  get_word_index()  (Python) of the transformed TextSet.  Also, you can call  saveWordIndex(path)  (Scala)  save_word_index(path)  (Python) to  save  this word index vocabulary to be used in\nfuture training.  Inference  During the inference, you are supposed to use exactly the same word index correspondence as in the\ntraining stage instead of generating a new one. Need to tokenize first.  Thus please be aware that you do not need to specify any of the below arguments.  You need to call  loadWordIndex(path)  (Scala) or  load_word_index(path)  (Python) beforehand for word index  loading .  Scala  transformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null)   removeTopN : Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.  maxWordsNum : Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer.  minFreq : Positive integer. Only those words with frequency >= minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered.  existingMap : Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. \nIf not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words.   Python  transformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None)   remove_topN : Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.  max_words_num : Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int.  min_freq : Positive int. Only those words with frequency >= min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered.  existing_map : Existing dictionary of word index if any. Default is None and in this case a new dictionary with index starting from 1 will be generated. \nIf not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words.",
            "title": "Word To Index"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#sequence-shaping",
            "text": "Shape the sequence of indices to a fixed length. \nNeed to word2idx first.  Scala  transformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0)   len : Positive integer. The target length.  truncMode : Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. \nIf 'TruncMode.pre', the sequence will be truncated from the beginning. \nIf 'TruncMode.post', the sequence will be truncated from the end. \nDefault is 'TruncMode.post'.  padElement : Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.   Python  transformed_text_set = text_set.shape_sequence(len, trunc_mode=\"pre\", pad_element=0)   len : Positive int. The target length.  trunc_mode : String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. \nIf 'pre', the sequence will be truncated from the beginning. \nIf 'post', the sequence will be truncated from the end. \nDefault is 'post'.  pad_element : Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.",
            "title": "Sequence Shaping"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#bigdl-sample-generation",
            "text": "Transform indices and label (if any) to a BigDL  Sample . \nNeed to word2idx first.  Scala  transformedTextSet = textSet.generateSample()  Python  transformed_text_set = text_set.generate_sample()",
            "title": "BigDL Sample Generation"
        },
        {
            "location": "/APIGuide/FeatureEngineering/text/#wordembedding",
            "text": "This is a special Embedding layer that directly loads pre-trained word vectors as weights, \nwhich turns non-negative integers (indices) into dense vectors of fixed size.  Currently only GloVe embedding is supported for this layer.  The input of this layer should be 2D.  Scala  embedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)   embeddingFile : The path to the word embedding file. Currently  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now.  inputLength : Positive integer. The sequence length of each input.   Python  embedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None)   embedding_file  The path to the word embedding file. Currently  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index  Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  trainable : To configure whether the weights of this layer will be updated or not. Only False is supported for now.  inputLength : Positive int. The sequence length of each input.",
            "title": "WordEmbedding"
        },
        {
            "location": "/APIGuide/Models/object-detection/",
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink.\n\n\nModel Load\n\n\nUse \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float](\"/tmp/zoo.model\") //load from local fs\nval model = ObjectDetector.loadModel(\"hdfs://...\") //load from hdfs\nval model = ObjectDetector.loadModel(\"s3://...\") //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model(\"/tmp/zoo.model\") //load from local fs\nmodel = ObjectDetector.load_model(\"hdfs://...\") //load from hdfs\nmodel = ObjectDetector.load_model(\"s3://...\") //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.\n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageSet before model inference\n\n\npostProcessor: postprocessor of ImageSet after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n                     ImageChannelNormalize(123, 117, 104) ->\n                     ImageMatToTensor[Float]() ->\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\"float\")\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)\n\n\n\n\nPredict with loaded object detection model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this prediction\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\"/tmp/image\"\nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel(\"/tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model\")\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  prediction\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)",
            "title": "Object Detection"
        },
        {
            "location": "/APIGuide/Models/object-detection/#model-load",
            "text": "Use  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float](\"/tmp/zoo.model\") //load from local fs\nval model = ObjectDetector.loadModel(\"hdfs://...\") //load from hdfs\nval model = ObjectDetector.loadModel(\"s3://...\") //load from s3  Python example  from zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model(\"/tmp/zoo.model\") //load from local fs\nmodel = ObjectDetector.load_model(\"hdfs://...\") //load from hdfs\nmodel = ObjectDetector.load_model(\"s3://...\") //load from s3",
            "title": "Model Load"
        },
        {
            "location": "/APIGuide/Models/object-detection/#creat-image-configuration",
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.  Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageSet before model inference  postProcessor: postprocessor of ImageSet after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n                     ImageChannelNormalize(123, 117, 104) ->\n                     ImageMatToTensor[Float]() ->\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\"float\")   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)",
            "title": "Creat image configuration"
        },
        {
            "location": "/APIGuide/Models/object-detection/#predict-with-loaded-object-detection-model",
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this prediction   Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\"/tmp/image\"\nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel(\"/tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model\")\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  prediction   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)",
            "title": "Predict with loaded object detection model"
        },
        {
            "location": "/APIGuide/Models/image-classification/",
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nModel Load\n\n\nUse \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.  \nModule\n (Scala) or \nModel\n(Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float](\"/tmp/model.zoo\", \"/tmp/model.bin\") //load from local fs\nval model = ImageClassifier.loadModel(\"hdfs://...\") //load from hdfs\nval model = ImageClassifier.loadModel(\"s3://...\") //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model(\"/tmp/...model\", \"/tmp/model.bin\") //load from local fs\nmodel = ImageClassifier.load_model(\"hdfs://...\") //load from hdfs\nmodel = ImageClassifier.load_model(\"s3://...\") //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. \n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageFrame before model inference\n\n\npostProcessor: postprocessor of ImageFrame after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n                     ImageChannelNormalize(123, 117, 104) ->\n                     ImageMatToTensor[Float]() ->\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\"float\")\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing) \n\n\n\n\nPredict with loaded image classification model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  predcition\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\"/tmp/image\"\nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel(\"/tmp/analytics-zoo_inception-v1_imagenet_0.1.0\") \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this predcition\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)",
            "title": "Image Classification"
        },
        {
            "location": "/APIGuide/Models/image-classification/#model-load",
            "text": "Use  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.   Module  (Scala) or  Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float](\"/tmp/model.zoo\", \"/tmp/model.bin\") //load from local fs\nval model = ImageClassifier.loadModel(\"hdfs://...\") //load from hdfs\nval model = ImageClassifier.loadModel(\"s3://...\") //load from s3  Python example  from zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model(\"/tmp/...model\", \"/tmp/model.bin\") //load from local fs\nmodel = ImageClassifier.load_model(\"hdfs://...\") //load from hdfs\nmodel = ImageClassifier.load_model(\"s3://...\") //load from s3",
            "title": "Model Load"
        },
        {
            "location": "/APIGuide/Models/image-classification/#creat-image-configuration",
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.   Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageFrame before model inference  postProcessor: postprocessor of ImageFrame after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-> ImageCenterCrop(224, 224) ->\n                     ImageChannelNormalize(123, 117, 104) ->\n                     ImageMatToTensor[Float]() ->\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\"float\")   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)",
            "title": "Creat image configuration"
        },
        {
            "location": "/APIGuide/Models/image-classification/#predict-with-loaded-image-classification-model",
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  predcition   Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\"/tmp/image\"\nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel(\"/tmp/analytics-zoo_inception-v1_imagenet_0.1.0\") \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this predcition   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)",
            "title": "Predict with loaded image classification model"
        },
        {
            "location": "/APIGuide/Models/text-classification/",
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\nThe model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\n\n\nBuild a TextClassifier Model\n\n\nYou can call the following API in Scala and Python respectively to create a \nTextClassifier\n with \npre-trained GloVe word embeddings as the first layer\n.\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \"cnn\", encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nSee \nhere\n for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\"cnn\", encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\nSee \nhere\n for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\n\n\nSave Model\n\n\nAfter building and training a TextClassifier model, you can save it for future use.\n\n\nScala\n\n\ntextClassifier.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\ntext_classifier.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load a TextClassifier model (with weights) saved \nabove\n:\n\n\nScala\n\n\nTextClassifier.loadModel(path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nTextClassifier.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.",
            "title": "Text Classification"
        },
        {
            "location": "/APIGuide/Models/text-classification/#build-a-textclassifier-model",
            "text": "You can call the following API in Scala and Python respectively to create a  TextClassifier  with  pre-trained GloVe word embeddings as the first layer .  Scala  val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \"cnn\", encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   See  here  for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  Python  text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\"cnn\", encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.   See  here  for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.",
            "title": "Build a TextClassifier Model"
        },
        {
            "location": "/APIGuide/Models/text-classification/#save-model",
            "text": "After building and training a TextClassifier model, you can save it for future use.  Scala  textClassifier.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  text_classifier.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.",
            "title": "Save Model"
        },
        {
            "location": "/APIGuide/Models/text-classification/#load-model",
            "text": "To load a TextClassifier model (with weights) saved  above :  Scala  TextClassifier.loadModel(path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  TextClassifier.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.",
            "title": "Load Model"
        },
        {
            "location": "/APIGuide/Models/recommendation/",
            "text": "Analytics Zoo provides three Recommenders, including Wide and Deep (WND) model, Neural network-based Collaborative Filtering (NCF) model and Session Recommender model. Easy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer.\n\n\nWND and NCF recommenders can handle either explict or implicit feedback, given corresponding features.\n\n\nWe also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See \nhere\n for more details.\n\n\n\n\nWide and Deep\n\n\nWide and Deep Learning Model, proposed by \nGoogle, 2016\n, is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.\n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval wideAndDeep = WideAndDeep(modelType = \"wide_n_deep\", numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\n\n\nmodelType\n: String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\ncolumnInfo\n An instance of \nColumnFeatureInfo\n.\n\n\nhiddenLayers\n: Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).\n\n\n\n\nSee \nhere\n for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nwide_and_deep = WideAndDeep(class_num, column_info, model_type=\"wide_n_deep\", hidden_layers=(40, 20, 10))\n\n\n\n\n\n\nclass_num\n: The number of classes. Positive int.\n\n\ncolumn_info\n: An instance of \nColumnFeatureInfo\n.\n\n\nmodel_type\n: String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.\n\n\nhidden_layers\n: Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).\n\n\n\n\nSee \nhere\n for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nNCF (\nHe, 2015\n) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. \nincludeMF\n(Boolean) is provided for users to build a \nNeuralCF\n model with or without matrix factorization. \n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\n\n\nuserCount\n: The number of users. Positive integer.\n\n\nitemCount\n: The number of items. Positive integer.\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\nuserEmbed\n: Units of user embedding. Positive integer. Default is 20.\n\n\nitemEmbed\n: Units of item embedding. Positive integer. Default is 20.\n\n\nhiddenLayers\n: Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).\n\n\nincludeMF\n: Whether to include Matrix Factorization. Boolean. Default is true.\n\n\nmfEmbed\n: Units of matrix factorization embedding. Positive integer. Default is 20.\n\n\n\n\nSee \nhere\n for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\n\n\nuser_count\n: The number of users. Positive int.\n\n\nitem_count\n: The number of classes. Positive int.\n\n\nclass_num:\n The number of classes. Positive int.\n\n\nuser_embed\n: Units of user embedding. Positive int. Default is 20.\n\n\nitem_embed\n: itemEmbed Units of item embedding. Positive int. Default is 20.\n\n\nhidden_layers\n: Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).\n\n\ninclude_mf\n: Whether to include Matrix Factorization. Boolean. Default is True.\n\n\nmf_embed\n: Units of matrix factorization embedding. Positive int. Default is 20.\n\n\n\n\nSee \nhere\n for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nSession Recommender\n\n\nSession Recommender (\nHidasi, 2015\n) uses an RNN-based approach for session-based recommendations. The model is enhanced in NetEase (\nWu, 2016\n) by adding multiple layers to model users' purchase history. In Analytics Zoo, \nincludeHistory\n(Boolean) is provided for users to build a \nSessionRecommender\n model with or without history. \n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval sessionRecommender = SessionRecommender(itemCount, itemEmbed, sessionLength, includeHistory, mlpHiddenLayers, historyLength)\n\n\n\n\n\n\nitemCount\nL: The number of distinct items. Positive integer.\n\n\nitemEmbed\n: The output size of embedding layer. Positive integer.\n\n\nmlpHiddenLayers\n: Units of hidden layers for the mlp model. Array of positive integers.\n\n\nsessionLength\n: The max number of items in the sequence of a session\n\n\nrnnHiddenLayers\n: Units of hidden layers for the mlp model. Array of positive integers.\n\n\nincludeHistory\n: Whether to include purchase history. Boolean. Default is true.\n\n\nhistoryLength\n: The max number of items in the sequence of historical purchase\n\n\n\n\nSee \nhere\n for the Scala example that trains the SessionRecommender model on an ecommerce dataset provided by OfficeDepot and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nsession_recommender=SessionRecommender(item_count, item_embed, rnn_hidden_layers=[40, 20], session_length=10, include_history=True, mlp_hidden_layers=[40, 20], history_length=5)\n\n\n\n\n\n\nitem_ount\n: The number of distinct items. Positive integer.\n\n\nitem_embed\n: The output size of embedding layer. Positive integer.\n*\nrnn_hidden_layers\n: Units of hidden layers for the mlp model. Array of positive integers.\n\n\nsession_length\n: The max number of items in the sequence of a session\n\n\ninclude_history\n: Whether to include purchase history. Boolean. Default is true.\n\n\nmlp_hidden_layers\n: Units of hidden layers for the mlp model. Array of positive integers.\n\n\nhistory_length\n: The max number of items in the sequence of historical purchase\n\n\n\n\n\n\nPrediction and Recommendation\n\n\nPredict for user-item pairs\n\n\nGive prediction for each pair of user and item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\npredictUserItemPair(featureRdd)\n\n\n\n\nPython\n\n\npredict_user_item_pair(feature_rdd)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\n\n\nRecommend for users\n\n\nRecommend a number of items for each user. Return RDD of \nUserItemPrediction\n. Only works for WND and NCF.\n\n\nScala\n\n\nrecommendForUser(featureRdd, maxItems)\n\n\n\n\nPython\n\n\nrecommend_for_user(feature_rdd, max_items)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxItems\n: The number of items to be recommended to each user. Positive integer.\n\n\n\n\nRecommend for items\n\n\nRecommend a number of users for each item. Return RDD of \nUserItemPrediction\n. Only works for WND and NCF.\n\n\nScala\n\n\nrecommendForItem(featureRdd, maxUsers)\n\n\n\n\nPython\n\n\nrecommend_for_item(feature_rdd, max_users)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxUsers\n: The number of users to be recommended to each item. Positive integer.\n\n\n\n\nRecommend for sessions\n\n\nRecommend a number of items for each sequence. Return corresponding recommendations, each of which contains a sequence of(item, probability). Only works for Session Recommender\n\n\nScala\n\n\nrecommendForSession(sessions, maxItems, zeroBasedLabel)\n\n\n\n\nPython\n\n\nrecommend_for_session(sessions, max_items, zero_based_label)\n\n\n\n\nParameters:\n\n\n\n\nsessions\n: RDD or Array of samples.\n\n\nmaxItems\n: Number of items to be recommended to each user. Positive integer.\n\n\nzeroBasedLabel\n: True if data starts from 0, False if data starts from 1\n\n\n\n\n\n\nModel Save\n\n\nAfter building and training a WideAndDeep or NeuralCF model, you can save it for future use.\n\n\nScala\n\n\nwideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)\n\nsessionRecommender.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nwide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)\n\nsession_recommender.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nModel Load\n\n\nTo load a WideAndDeep or NeuralCF model (with weights) saved \nabove\n:\n\n\nScala\n\n\nWideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)\n\nSessionRecommender.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nWideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)\n\nSessionRecommender.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.\n\n\n\n\n\n\nUserItemFeature\n\n\nRepresent records of user-item with features.\n\n\nEach record should contain the following fields:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitem_id\n: Positive integer.\n\n\nsample\n: \nSample\n which consists of feature(s) and label(s).\n\n\n\n\nScala\n\n\nUserItemFeature(userId, itemId, sample)\n\n\n\n\nPython\n\n\nUserItemFeature(user_id, item_id, sample)\n\n\n\n\n\n\nUserItemPrediction\n\n\nRepresent the prediction results of user-item pairs.\n\n\nEach prediction record will contain the following information:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitemId\n: Positive integer.\n\n\nprediction\n: The prediction (rating) for the user on the item.\n\n\nprobability\n: The probability for the prediction.\n\n\n\n\nScala\n\n\nUserItemPrediction(userId, itemId, prediction, probability)\n\n\n\n\nPython\n\n\nUserItemPrediction(user_id, item_id, prediction, probability)\n\n\n\n\n\n\nColumnFeatureInfo\n\n\nAn instance of \nColumnFeatureInfo\n contains the same data information shared by the \nWideAndDeep\n model and its feature generation part.\n\n\nYou can choose to include the following information for feature engineering and the \nWideAndDeep\n model:\n\n\n\n\nwideBaseCols\n: Data of \nwideBaseCols\n together with \nwideCrossCols\n will be fed into the wide model.\n\n\nwideBaseDims\n: Dimensions of \nwideBaseCols\n. The dimensions of the data in \nwideBaseCols\n should be within the range of \nwideBaseDims\n.\n\n\nwideCrossCols\n: Data of \nwideCrossCols\n will be fed into the wide model.\n\n\nwideCrossDims\n: Dimensions of \nwideCrossCols\n. The dimensions of the data in \nwideCrossCols\n should be within the range of \nwideCrossDims\n.\n\n\nindicatorCols\n: Data of \nindicatorCols\n will be fed into the deep model as multi-hot vectors. \n\n\nindicatorDims\n: Dimensions of \nindicatorCols\n. The dimensions of the data in \nindicatorCols\n should be within the range of \nindicatorDims\n.\n\n\nembedCols\n: Data of \nembedCols\n will be fed into the deep model as embeddings.\n\n\nembedInDims\n: Input dimension of the data in \nembedCols\n. The dimensions of the data in \nembedCols\n should be within the range of \nembedInDims\n.\n\n\nembedOutDims\n: The dimensions of embeddings for \nembedCols\n.\n\n\ncontinuousCols\n: Data of \ncontinuousCols\n will be treated as continuous values for the deep model.\n\n\nlabel\n: The name of the 'label' column. String. Default is \"label\".\n\n\n\n\nRemark:\n\n\nFields that involve \nCols\n should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.\n\n\nFields that involve \nDims\n should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.\n\n\nIf any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).\n\n\nScala\n\n\nColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label = \"label\")\n\n\n\n\nPython\n\n\nColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label=\"label\")",
            "title": "Recommendation"
        },
        {
            "location": "/APIGuide/Models/recommendation/#wide-and-deep",
            "text": "Wide and Deep Learning Model, proposed by  Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.  After training the model, users can use the model to  do prediction and recommendation .  Scala  val wideAndDeep = WideAndDeep(modelType = \"wide_n_deep\", numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))   modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".  numClasses : The number of classes. Positive integer.  columnInfo  An instance of  ColumnFeatureInfo .  hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).   See  here  for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  wide_and_deep = WideAndDeep(class_num, column_info, model_type=\"wide_n_deep\", hidden_layers=(40, 20, 10))   class_num : The number of classes. Positive int.  column_info : An instance of  ColumnFeatureInfo .  model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.  hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).   See  here  for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.",
            "title": "Wide and Deep"
        },
        {
            "location": "/APIGuide/Models/recommendation/#neural-network-based-collaborative-filtering",
            "text": "NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework.  includeMF (Boolean) is provided for users to build a  NeuralCF  model with or without matrix factorization.   After training the model, users can use the model to  do prediction and recommendation .  Scala  val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)   userCount : The number of users. Positive integer.  itemCount : The number of items. Positive integer.  numClasses : The number of classes. Positive integer.  userEmbed : Units of user embedding. Positive integer. Default is 20.  itemEmbed : Units of item embedding. Positive integer. Default is 20.  hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).  includeMF : Whether to include Matrix Factorization. Boolean. Default is true.  mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20.   See  here  for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  ncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)   user_count : The number of users. Positive int.  item_count : The number of classes. Positive int.  class_num:  The number of classes. Positive int.  user_embed : Units of user embedding. Positive int. Default is 20.  item_embed : itemEmbed Units of item embedding. Positive int. Default is 20.  hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).  include_mf : Whether to include Matrix Factorization. Boolean. Default is True.  mf_embed : Units of matrix factorization embedding. Positive int. Default is 20.   See  here  for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.",
            "title": "Neural network-based Collaborative Filtering"
        },
        {
            "location": "/APIGuide/Models/recommendation/#session-recommender",
            "text": "Session Recommender ( Hidasi, 2015 ) uses an RNN-based approach for session-based recommendations. The model is enhanced in NetEase ( Wu, 2016 ) by adding multiple layers to model users' purchase history. In Analytics Zoo,  includeHistory (Boolean) is provided for users to build a  SessionRecommender  model with or without history.   After training the model, users can use the model to  do prediction and recommendation .  Scala  val sessionRecommender = SessionRecommender(itemCount, itemEmbed, sessionLength, includeHistory, mlpHiddenLayers, historyLength)   itemCount L: The number of distinct items. Positive integer.  itemEmbed : The output size of embedding layer. Positive integer.  mlpHiddenLayers : Units of hidden layers for the mlp model. Array of positive integers.  sessionLength : The max number of items in the sequence of a session  rnnHiddenLayers : Units of hidden layers for the mlp model. Array of positive integers.  includeHistory : Whether to include purchase history. Boolean. Default is true.  historyLength : The max number of items in the sequence of historical purchase   See  here  for the Scala example that trains the SessionRecommender model on an ecommerce dataset provided by OfficeDepot and uses the model to do prediction and recommendation.  Python  session_recommender=SessionRecommender(item_count, item_embed, rnn_hidden_layers=[40, 20], session_length=10, include_history=True, mlp_hidden_layers=[40, 20], history_length=5)   item_ount : The number of distinct items. Positive integer.  item_embed : The output size of embedding layer. Positive integer.\n* rnn_hidden_layers : Units of hidden layers for the mlp model. Array of positive integers.  session_length : The max number of items in the sequence of a session  include_history : Whether to include purchase history. Boolean. Default is true.  mlp_hidden_layers : Units of hidden layers for the mlp model. Array of positive integers.  history_length : The max number of items in the sequence of historical purchase",
            "title": "Session Recommender"
        },
        {
            "location": "/APIGuide/Models/recommendation/#prediction-and-recommendation",
            "text": "Predict for user-item pairs  Give prediction for each pair of user and item. Return RDD of  UserItemPrediction .  Scala  predictUserItemPair(featureRdd)  Python  predict_user_item_pair(feature_rdd)  Parameters:   featureRdd : RDD of  UserItemFeature .   Recommend for users  Recommend a number of items for each user. Return RDD of  UserItemPrediction . Only works for WND and NCF.  Scala  recommendForUser(featureRdd, maxItems)  Python  recommend_for_user(feature_rdd, max_items)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxItems : The number of items to be recommended to each user. Positive integer.   Recommend for items  Recommend a number of users for each item. Return RDD of  UserItemPrediction . Only works for WND and NCF.  Scala  recommendForItem(featureRdd, maxUsers)  Python  recommend_for_item(feature_rdd, max_users)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxUsers : The number of users to be recommended to each item. Positive integer.   Recommend for sessions  Recommend a number of items for each sequence. Return corresponding recommendations, each of which contains a sequence of(item, probability). Only works for Session Recommender  Scala  recommendForSession(sessions, maxItems, zeroBasedLabel)  Python  recommend_for_session(sessions, max_items, zero_based_label)  Parameters:   sessions : RDD or Array of samples.  maxItems : Number of items to be recommended to each user. Positive integer.  zeroBasedLabel : True if data starts from 0, False if data starts from 1",
            "title": "Prediction and Recommendation"
        },
        {
            "location": "/APIGuide/Models/recommendation/#model-save",
            "text": "After building and training a WideAndDeep or NeuralCF model, you can save it for future use.  Scala  wideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)\n\nsessionRecommender.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  wide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)\n\nsession_recommender.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.",
            "title": "Model Save"
        },
        {
            "location": "/APIGuide/Models/recommendation/#model-load",
            "text": "To load a WideAndDeep or NeuralCF model (with weights) saved  above :  Scala  WideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)\n\nSessionRecommender.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  WideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)\n\nSessionRecommender.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.",
            "title": "Model Load"
        },
        {
            "location": "/APIGuide/Models/recommendation/#useritemfeature",
            "text": "Represent records of user-item with features.  Each record should contain the following fields:   userId : Positive integer.  item_id : Positive integer.  sample :  Sample  which consists of feature(s) and label(s).   Scala  UserItemFeature(userId, itemId, sample)  Python  UserItemFeature(user_id, item_id, sample)",
            "title": "UserItemFeature"
        },
        {
            "location": "/APIGuide/Models/recommendation/#useritemprediction",
            "text": "Represent the prediction results of user-item pairs.  Each prediction record will contain the following information:   userId : Positive integer.  itemId : Positive integer.  prediction : The prediction (rating) for the user on the item.  probability : The probability for the prediction.   Scala  UserItemPrediction(userId, itemId, prediction, probability)  Python  UserItemPrediction(user_id, item_id, prediction, probability)",
            "title": "UserItemPrediction"
        },
        {
            "location": "/APIGuide/Models/recommendation/#columnfeatureinfo",
            "text": "An instance of  ColumnFeatureInfo  contains the same data information shared by the  WideAndDeep  model and its feature generation part.  You can choose to include the following information for feature engineering and the  WideAndDeep  model:   wideBaseCols : Data of  wideBaseCols  together with  wideCrossCols  will be fed into the wide model.  wideBaseDims : Dimensions of  wideBaseCols . The dimensions of the data in  wideBaseCols  should be within the range of  wideBaseDims .  wideCrossCols : Data of  wideCrossCols  will be fed into the wide model.  wideCrossDims : Dimensions of  wideCrossCols . The dimensions of the data in  wideCrossCols  should be within the range of  wideCrossDims .  indicatorCols : Data of  indicatorCols  will be fed into the deep model as multi-hot vectors.   indicatorDims : Dimensions of  indicatorCols . The dimensions of the data in  indicatorCols  should be within the range of  indicatorDims .  embedCols : Data of  embedCols  will be fed into the deep model as embeddings.  embedInDims : Input dimension of the data in  embedCols . The dimensions of the data in  embedCols  should be within the range of  embedInDims .  embedOutDims : The dimensions of embeddings for  embedCols .  continuousCols : Data of  continuousCols  will be treated as continuous values for the deep model.  label : The name of the 'label' column. String. Default is \"label\".   Remark:  Fields that involve  Cols  should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.  Fields that involve  Dims  should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.  If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).  Scala  ColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label = \"label\")  Python  ColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label=\"label\")",
            "title": "ColumnFeatureInfo"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/",
            "text": "Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. \nA sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions.  \n\n\nHightlights\n\n\n\n\nKeras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training.\n\n\nModels are defined base on LSTM.\n\n\n\n\n\n\nBuild an AnomalyDetction model\n\n\nYou can call the following API in Scala and Python respectively to create an \nAnomalyDetrctor\n model\n\n\nScala\n\n\nimport com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)\n\n\n\n\n\n\nfeatureShape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhiddenLayers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nPython\n\n\nfrom zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])\n\n\n\n\n\n\nfeature_shape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhidden_layers\n Units of hidden layers of LSTM.\n\n\ndropouts\n      Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nUnroll features\n\n\nTo prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length.\n\n\nScala\n\n\nval unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep)\n\n\n\n\n\n\ndataRdd\n       RDD[Array]. data to be unrolled, it holds original time series features\n\n\nunrollLength\n  Int. the length of precious values to predict future value.\n\n\npredictStep\n   Int. How many time steps to predict future value, default is 1.\n\n\n\n\nPython\n\n\nunrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step)\n\n\n\n\n\n\ndata_rdd\n       RDD[Array]. data to be unrolled, it holds original time series features\n\n\nunroll_length\n  Int. The length of precious values to predict future value.\n\n\npredict_step\n   Int. How many time steps to predict future value, default is 1.\n\n\n\n\n\n\nDetect anomalies\n\n\nAfter training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top \nanomalySize\n data points are anomalies).\n\n\nScala\n\n\nval anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize)\n\n\n\n\n\n\nyTruth\n      RDD of float or double values. Truth to be compared. \n\n\nyPredict\n    RDD of float or double values. Predictions.\n\n\nanomalySize\n Int. The size to be considered as anomalies.\n\n\n\n\nPython\n``\n\n\nanomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size)\n\n\n\n\n\n\ny_truth\n      RDD of float or double values. Truth to be compared. \n\n\ny_predict\n    RDD of float or double values. Predictions.\n\n\nanomaly_size\n Int. The size to be considered as anomalies.\n\n\n\n\n\n\nSave Model\n\n\nAfter building and training an AnomalyDetector model, you can save it for future use.\n\n\nScala\n\n\nmodel.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nmodel.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load an AnomalyDetector model (with weights) saved \nabove\n:\n\n\nScala\n\n\nAnomalyDetector.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nAnomalyDetector.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.",
            "title": "Anomaly Detection"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/#build-an-anomalydetction-model",
            "text": "You can call the following API in Scala and Python respectively to create an  AnomalyDetrctor  model  Scala  import com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)   featureShape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hiddenLayers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.   Python  from zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])   feature_shape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hidden_layers  Units of hidden layers of LSTM.  dropouts       Fraction of the input units to drop out. Float between 0 and 1.",
            "title": "Build an AnomalyDetction model"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/#unroll-features",
            "text": "To prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length.  Scala  val unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep)   dataRdd        RDD[Array]. data to be unrolled, it holds original time series features  unrollLength   Int. the length of precious values to predict future value.  predictStep    Int. How many time steps to predict future value, default is 1.   Python  unrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step)   data_rdd        RDD[Array]. data to be unrolled, it holds original time series features  unroll_length   Int. The length of precious values to predict future value.  predict_step    Int. How many time steps to predict future value, default is 1.",
            "title": "Unroll features"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/#detect-anomalies",
            "text": "After training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top  anomalySize  data points are anomalies).  Scala  val anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize)   yTruth       RDD of float or double values. Truth to be compared.   yPredict     RDD of float or double values. Predictions.  anomalySize  Int. The size to be considered as anomalies.   Python ``  anomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size)   y_truth       RDD of float or double values. Truth to be compared.   y_predict     RDD of float or double values. Predictions.  anomaly_size  Int. The size to be considered as anomalies.",
            "title": "Detect anomalies"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/#save-model",
            "text": "After building and training an AnomalyDetector model, you can save it for future use.  Scala  model.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  model.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.",
            "title": "Save Model"
        },
        {
            "location": "/APIGuide/Models/anomaly-detection/#load-model",
            "text": "To load an AnomalyDetector model (with weights) saved  above :  Scala  AnomalyDetector.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  AnomalyDetector.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.",
            "title": "Load Model"
        },
        {
            "location": "/APIGuide/Models/text-matching/",
            "text": "Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering).\nFor training, you can use Keras-Style API methods or alternatively feed the model into NNFrames and BigDL Optimizer.\nMore text matching models will be supported in the future.\n\n\n\n\nBuild a KNRM Model\n\n\nKernel-pooling Neural Ranking Model with RBF kernel. See \nhere\n for more details.\n\n\nYou can call the following API in Scala and Python respectively to create a \nKNRM\n with \npre-trained GloVe word embeddings\n.\n\n\nScala\n\n\nval knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \"ranking\")\n\n\n\n\n\n\ntext1Length\n: Sequence length of text1 (query).\n\n\ntext2Length\n: Sequence length of text2 (doc).\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainEmbed\n: Boolean. Whether to train the embedding layer or not. Default is true.\n\n\nkernelNum\n: Integer > 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexactSigma\n: Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntargetMode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nSee \nhere\n for the Scala example that trains a KNRM model on WikiQA dataset.\n\n\nPython\n\n\nknrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\"ranking\")\n\n\n\n\n\n\ntext1_length\n: Sequence length of text1 (query).\n\n\ntext2_length\n: Sequence length of text2 (doc).\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrain_embed\n: Boolean. Whether to train the embedding layer or not. Default is True.\n\n\nkernel_num\n: Int > 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexact_sigma\n: Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntarget_mode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nSee \nhere\n for the Python example that trains a KNRM model on WikiQA dataset.\n\n\n\n\nSave Model\n\n\nAfter building and training a KNRM model, you can save it for future use.\n\n\nScala\n\n\nknrm.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nknrm.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load a KNRM model (with weights) saved \nabove\n:\n\n\nScala\n\n\nKNRM.loadModel(path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nKNRM.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.",
            "title": "Text Matching"
        },
        {
            "location": "/APIGuide/Models/text-matching/#build-a-knrm-model",
            "text": "Kernel-pooling Neural Ranking Model with RBF kernel. See  here  for more details.  You can call the following API in Scala and Python respectively to create a  KNRM  with  pre-trained GloVe word embeddings .  Scala  val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \"ranking\")   text1Length : Sequence length of text1 (query).  text2Length : Sequence length of text2 (doc).  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true.  kernelNum : Integer > 1. The number of kernels to use. Default is 21.  sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   See  here  for the Scala example that trains a KNRM model on WikiQA dataset.  Python  knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\"ranking\")   text1_length : Sequence length of text1 (query).  text2_length : Sequence length of text2 (doc).  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  train_embed : Boolean. Whether to train the embedding layer or not. Default is True.  kernel_num : Int > 1. The number of kernels to use. Default is 21.  sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   See  here  for the Python example that trains a KNRM model on WikiQA dataset.",
            "title": "Build a KNRM Model"
        },
        {
            "location": "/APIGuide/Models/text-matching/#save-model",
            "text": "After building and training a KNRM model, you can save it for future use.  Scala  knrm.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  knrm.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.",
            "title": "Save Model"
        },
        {
            "location": "/APIGuide/Models/text-matching/#load-model",
            "text": "To load a KNRM model (with weights) saved  above :  Scala  KNRM.loadModel(path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  KNRM.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.",
            "title": "Load Model"
        },
        {
            "location": "/APIGuide/Models/seq2seq/",
            "text": "Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more.\nThe model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\n\n\nBuild a Seq2seq Model\n\n\nBefore build Seq2seq Model, you need build \nEncoder\n, \nDecoder\n. And \nBridge\n if you want to do some transformation before passing encoder states to decoder.\n\n\nBuild an Encoder\n\n\nCurrently we only support \nRNNEncoder\n which enables you to put RNN layers into encoder.\nYou can call the following API in Scala and Python respectively to create a \nRNNEncoder\n.\n\n\nScala\n\n\nval encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding)\n\n\n\n\n\n\nrnnType\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnumLayers\n number of layers used in encoder\n\n\nhiddenSize\n hidden size of encoder\n\n\nembedding\n embedding layer in encoder, default is \nnull\n\n\n\n\nYou can also define RNN layers yourself\n\n\nval encoder = RNNEncoder(rnns, embedding, inputShape)\n\n\n\n\n\n\nrnns\n rnn layers used for encoder, support stacked rnn layers\n\n\nembedding\n embedding layer in encoder, default is \nnull\n\n\n\n\nPython\n\n\nencoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding)\n\n\n\n\n\n\nrnn_type\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnlayers\n number of layers used in encoder\n\n\nhidden_size\n hidden size of encoder\n\n\nembedding\n embedding layer in encoder, default is \nNone\n\n\n\n\nOr\n\n\nencoder = RNNEncoder(rnns, embedding, input_shape)\n\n\n\n\n\n\nrnns\n rnn layers used for encoder, support stacked rnn layers\n\n\nembedding\n embedding layer in encoder, default is \nNone\n\n\n\n\nBuild a Decoder\n\n\nSimilar to Encoder, we only support \nRNNDecoder\n and API is pretty much the same with \nRNNEncoder\n\n\nScala\n\n\nval decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding)\n\n\n\n\n\n\nrnnType\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnumLayers\n number of layers used in decoder\n\n\nhiddenSize\n hidden size of decoder\n\n\nembedding\n embedding layer in decoder, default is \nnull\n\n\n\n\nYou can also define RNN layers yourself\n\n\nval decoder = RNNDecoder(rnns, embedding, inputShape)\n\n\n\n\n\n\nrnns\n rnn layers used for decoder, support stacked rnn layers\n\n\nembedding\n embedding layer in decoder, default is \nnull\n\n\n\n\nPython\n\n\nencoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding):\n\n\n\n\n\n\nrnn_type\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnlayers\n number of layers used in decoder\n\n\nhidden_size\n hidden size of decoder\n\n\nembedding\n embedding layer in decoder, default is \nNone\n\n\n\n\nOr\n\n\ndecoder = RNNDecoder(rnns, embedding, input_shape)\n\n\n\n\n\n\nrnns\n rnn layers used for decoder, support stacked rnn layers\n\n\nembedding\n embedding layer in decoder, default is \nNone\n\n\n\n\nBuild a Bridge\n\n\nBy default, encoder states are directly fed into decoder. In this case, you don't need build a \nBridge\n. But if you want to do some transformation before feed encoder states to decoder,\nplease use following API to create a \nBridge\n.\n\n\nScala\n\n\nval bridge = Bridge(bridgeType, decoderHiddenSize)\n\n\n\n\n\n\nbridgeType\n currently only support \"dense | densenonlinear\"\n\n\ndecoderHiddenSize\n hidden size of decoder\n\n\n\n\nYou can also specify various keras layers as a \nBridge\n\n\nval bridge = Bridge(bridge)\n\n\n\n\n\n\nbridge\n keras layers used to do the transformation\n\n\n\n\nPython\n\n\nbridge = Bridge.initialize(bridge_type, decoder_hidden_size)\n\n\n\n\n\n\nbridge_type\n: currently only support \"dense | densenonlinear\"\n\n\ndecoder_hidden_size\n: hidden size of decoder\n\n\n\n\nOr\n\n\nbridge = Bridge.initialize_from_keras_layer(bridge)\n\n\n\n\n\n\nbridge\n keras layers used to do the transformation\n\n\n\n\nBuild a Seq2seq\n\n\nScala\n\n\nval seq2seq = Seq2seq(encoder,\n    decoder,\n    inputShape,\n    outputShape,\n    bridge,\n    generator)\n\n\n\n\n\n\nencoder\n an encoder object\n\n\ndecoder\n a decoder object\n\n\ninputShape\n shape of encoder input, for variable length, please input -1\n\n\noutputShape\n shape of decoder input, for variable length, please input -1\n\n\nbridge\n connect encoder and decoder, you can input \nnull\n\n\ngenerator\n Feeding decoder output to generator to generate final result, \nnull\n is supported\n\n\n\n\nSee \nhere\n for the Scala example that trains the Seq2seq model and uses the model to do prediction.\n\n\nPython\n\n\nseq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge,\n                 generator)\n\n\n\n\n\n\nencoder\n an encoder object\n\n\ndecoder\n a decoder object\n\n\ninput_shape\n shape of encoder input, for variable length, please input -1\n\n\noutput_shape\n shape of decoder input, for variable length, please input -1\n\n\nbridge\n connect encoder and decoder, you can input \nnull\n\n\ngenerator\n Feeding decoder output to generator to generate final result, \nNone\n is supported",
            "title": "Sequence to Sequence"
        },
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-seq2seq-model",
            "text": "Before build Seq2seq Model, you need build  Encoder ,  Decoder . And  Bridge  if you want to do some transformation before passing encoder states to decoder.",
            "title": "Build a Seq2seq Model"
        },
        {
            "location": "/APIGuide/Models/seq2seq/#build-an-encoder",
            "text": "Currently we only support  RNNEncoder  which enables you to put RNN layers into encoder.\nYou can call the following API in Scala and Python respectively to create a  RNNEncoder .  Scala  val encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding)   rnnType  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  numLayers  number of layers used in encoder  hiddenSize  hidden size of encoder  embedding  embedding layer in encoder, default is  null   You can also define RNN layers yourself  val encoder = RNNEncoder(rnns, embedding, inputShape)   rnns  rnn layers used for encoder, support stacked rnn layers  embedding  embedding layer in encoder, default is  null   Python  encoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding)   rnn_type  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  nlayers  number of layers used in encoder  hidden_size  hidden size of encoder  embedding  embedding layer in encoder, default is  None   Or  encoder = RNNEncoder(rnns, embedding, input_shape)   rnns  rnn layers used for encoder, support stacked rnn layers  embedding  embedding layer in encoder, default is  None",
            "title": "Build an Encoder"
        },
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-decoder",
            "text": "Similar to Encoder, we only support  RNNDecoder  and API is pretty much the same with  RNNEncoder  Scala  val decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding)   rnnType  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  numLayers  number of layers used in decoder  hiddenSize  hidden size of decoder  embedding  embedding layer in decoder, default is  null   You can also define RNN layers yourself  val decoder = RNNDecoder(rnns, embedding, inputShape)   rnns  rnn layers used for decoder, support stacked rnn layers  embedding  embedding layer in decoder, default is  null   Python  encoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding):   rnn_type  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  nlayers  number of layers used in decoder  hidden_size  hidden size of decoder  embedding  embedding layer in decoder, default is  None   Or  decoder = RNNDecoder(rnns, embedding, input_shape)   rnns  rnn layers used for decoder, support stacked rnn layers  embedding  embedding layer in decoder, default is  None",
            "title": "Build a Decoder"
        },
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-bridge",
            "text": "By default, encoder states are directly fed into decoder. In this case, you don't need build a  Bridge . But if you want to do some transformation before feed encoder states to decoder,\nplease use following API to create a  Bridge .  Scala  val bridge = Bridge(bridgeType, decoderHiddenSize)   bridgeType  currently only support \"dense | densenonlinear\"  decoderHiddenSize  hidden size of decoder   You can also specify various keras layers as a  Bridge  val bridge = Bridge(bridge)   bridge  keras layers used to do the transformation   Python  bridge = Bridge.initialize(bridge_type, decoder_hidden_size)   bridge_type : currently only support \"dense | densenonlinear\"  decoder_hidden_size : hidden size of decoder   Or  bridge = Bridge.initialize_from_keras_layer(bridge)   bridge  keras layers used to do the transformation",
            "title": "Build a Bridge"
        },
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-seq2seq",
            "text": "Scala  val seq2seq = Seq2seq(encoder,\n    decoder,\n    inputShape,\n    outputShape,\n    bridge,\n    generator)   encoder  an encoder object  decoder  a decoder object  inputShape  shape of encoder input, for variable length, please input -1  outputShape  shape of decoder input, for variable length, please input -1  bridge  connect encoder and decoder, you can input  null  generator  Feeding decoder output to generator to generate final result,  null  is supported   See  here  for the Scala example that trains the Seq2seq model and uses the model to do prediction.  Python  seq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge,\n                 generator)   encoder  an encoder object  decoder  a decoder object  input_shape  shape of encoder input, for variable length, please input -1  output_shape  shape of decoder input, for variable length, please input -1  bridge  connect encoder and decoder, you can input  null  generator  Feeding decoder output to generator to generate final result,  None  is supported",
            "title": "Build a Seq2seq"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/",
            "text": "Introduction\n\n\nWe provide \nKeras-Style API\n based on \nKeras 1.2.2\n in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Python using the Keras-Style API, now one just need to import the following packages:\n\n\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\n\n\n\nOne of the highlighted features with regard to the Keras-Style API is \nshape inference\n. Users only need to specify the input shape (a shape tuple \nexcluding\n batch dimension, for example, \ninput_shape=(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\nget_input_shape()\n\n\n\n\nget_output_shape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a shape tuple. The first entry is \nNone\n representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.\n\n\n\n\nset_name(name)\n\n\n\n\n\n\nSet the name of the model. Can alternatively specify the argument \nname\n in the constructor when creating a model.\n\n\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation(\"relu\"))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nshape\n: A shape tuple indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or a list of input nodes.\n\n\noutput\n: An output node or a list of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nmerge(inputs, mode=\"sum\", concat_axis=-1) # This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcat_axis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nfrom zoo.pipeline.api.keras.models import Model\nfrom zoo.pipeline.api.keras.layers import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode=\"sum\")\n# create a graph container\nmodel = Model([input1, input2], output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the Keras-Style API.\n\n\nTo set the name of a layer, you can either call \nset_name(name)\n or alternatively specify the argument \nname\n in the constructor when creating a layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation=\"tanh\", name=\"conv1_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation=\"tanh\", name=\"conv2_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation=\"tanh\", name=\"fc1\"))\nmodel.add(Dense(10, activation=\"softmax\", name=\"fc2\"))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)\n\n\n\n\n\n\nKeras Code Support\n\n\nIf you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with:\n\n\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n\n\n\nand making modifications subject to the following limitations:\n\n\n\n\n\n\nThe Keras version we support and test is \nKeras 1.2.2\n with TensorFlow backend.\n\n\n\n\n\n\nThere exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See \nhere\n for the full list of unsupported layer arguments. \n\n\n\n\n\n\nThe default dim_ordering in Analytics Zoo is \nth\n (Channel First, channel_axis=1).\n\n\n\n\n\n\nKeras \nbackend\n related code needs to be deleted or refactored appropriately.\n\n\n\n\n\n\nCode involving Keras utility functions or loading weights from HDF5 files should be removed.\n\n\n\n\n\n\nRemark:\n We have tested for migrating Keras code definition of \nVGG16\n, \nVGG19\n, \nResNet50\n and \nInceptionV3\n into Analytics Zoo.",
            "title": "Python Guide"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#introduction",
            "text": "We provide  Keras-Style API  based on  Keras 1.2.2  in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.  To define a model in Python using the Keras-Style API, now one just need to import the following packages:  from zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *  One of the highlighted features with regard to the Keras-Style API is  shape inference . Users only need to specify the input shape (a shape tuple  excluding  batch dimension, for example,  input_shape=(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.",
            "title": "Introduction"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#define-a-model",
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  get_input_shape()  get_output_shape()   Return the input or output shape of a model, which is a shape tuple. The first entry is  None  representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.   set_name(name)   Set the name of the model. Can alternatively specify the argument  name  in the constructor when creating a model.",
            "title": "Define a model"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#sequential-api",
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation(\"relu\"))",
            "title": "Sequential API"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#functional-api",
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(shape=None, name=None)  Parameters:   shape : A shape tuple indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or a list of input nodes.  output : An output node or a list of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  merge(inputs, mode=\"sum\", concat_axis=-1) # This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concat_axis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  from zoo.pipeline.api.keras.models import Model\nfrom zoo.pipeline.api.keras.layers import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode=\"sum\")\n# create a graph container\nmodel = Model([input1, input2], output)",
            "title": "Functional API"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#layers",
            "text": "See  here  for all the available layers for the Keras-Style API.  To set the name of a layer, you can either call  set_name(name)  or alternatively specify the argument  name  in the constructor when creating a layer.",
            "title": "Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#lenet-example",
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation=\"tanh\", name=\"conv1_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation=\"tanh\", name=\"conv2_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation=\"tanh\", name=\"fc1\"))\nmodel.add(Dense(10, activation=\"softmax\", name=\"fc2\"))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)",
            "title": "LeNet Example"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#keras-code-support",
            "text": "If you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with:  from zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *  and making modifications subject to the following limitations:    The Keras version we support and test is  Keras 1.2.2  with TensorFlow backend.    There exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See  here  for the full list of unsupported layer arguments.     The default dim_ordering in Analytics Zoo is  th  (Channel First, channel_axis=1).    Keras  backend  related code needs to be deleted or refactored appropriately.    Code involving Keras utility functions or loading weights from HDF5 files should be removed.    Remark:  We have tested for migrating Keras code definition of  VGG16 ,  VGG19 ,  ResNet50  and  InceptionV3  into Analytics Zoo.",
            "title": "Keras Code Support"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/",
            "text": "Introduction\n\n\nWe provide \nKeras-Style API\n based on \nKeras 1.2.2\n in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Scala using the Keras-Style API, now one just need to import the following packages:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\n\n\n\nOne of the highlighted features with regard to the new API is \nshape inference\n. Users only need to specify the input shape (a \nShape\n object \nexcluding\n batch dimension, for example, \ninputShape=Shape(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nShape\n\n\nInput and output shapes of a model in the Keras-Style API are described by the \nShape\n object in Scala, which can be classified into \nSingleShape\n and \nMultiShape\n.\n\n\nSingleShape\n is just a list of Int indicating shape dimensions while \nMultiShape\n is essentially a list of \nShape\n.\n\n\nExample code to create a shape:\n\n\n// create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))\n\n\n\n\nYou can use method \ntoSingle()\n to cast a \nShape\n to a \nSingleShape\n. Similarly, use \ntoMulti()\n to cast a \nShape\n to a \nMultiShape\n.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\ngetInputShape()\n\n\n\n\ngetOutputShape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a \nShape\n object. For \nSingleShape\n, the first entry is \n-1\n representing the batch dimension. For a model with multiple inputs or outputs, it will return a \nMultiShape\n.\n\n\n\n\nsetName(name)\n\n\n\n\n\n\nSet the name of the model.\n\n\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](32, inputShape = Shape(128)))\nmodel.add(Activation[Float](\"relu\"))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(inputShape = null, name = null)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: A \nShape\n object indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or an array of input nodes.\n\n\noutput\n: An output node or an array of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\n\nmerge(inputs, mode = \"sum\", concatAxis = -1) // This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input}\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.bigdl.utils.Shape\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode = \"sum\")\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the Keras-Style API.\n\n\nTo set the name of a layer, call the method \nsetName(name)\n of the layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation = \"tanh\").setName(\"conv1_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation = \"tanh\").setName(\"conv2_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation = \"tanh\").setName(\"fc1\"))\nmodel.add(Dense(10, activation = \"softmax\").setName(\"fc2\"))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)",
            "title": "Scala Guide"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#introduction",
            "text": "We provide  Keras-Style API  based on  Keras 1.2.2  in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.  To define a model in Scala using the Keras-Style API, now one just need to import the following packages:  import com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape  One of the highlighted features with regard to the new API is  shape inference . Users only need to specify the input shape (a  Shape  object  excluding  batch dimension, for example,  inputShape=Shape(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.",
            "title": "Introduction"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#shape",
            "text": "Input and output shapes of a model in the Keras-Style API are described by the  Shape  object in Scala, which can be classified into  SingleShape  and  MultiShape .  SingleShape  is just a list of Int indicating shape dimensions while  MultiShape  is essentially a list of  Shape .  Example code to create a shape:  // create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))  You can use method  toSingle()  to cast a  Shape  to a  SingleShape . Similarly, use  toMulti()  to cast a  Shape  to a  MultiShape .",
            "title": "Shape"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#define-a-model",
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  getInputShape()  getOutputShape()   Return the input or output shape of a model, which is a  Shape  object. For  SingleShape , the first entry is  -1  representing the batch dimension. For a model with multiple inputs or outputs, it will return a  MultiShape .   setName(name)   Set the name of the model.",
            "title": "Define a model"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#sequential-api",
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](32, inputShape = Shape(128)))\nmodel.add(Activation[Float](\"relu\"))",
            "title": "Sequential API"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#functional-api",
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(inputShape = null, name = null)  Parameters:   inputShape : A  Shape  object indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or an array of input nodes.  output : An output node or an array of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\n\nmerge(inputs, mode = \"sum\", concatAxis = -1) // This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input}\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.bigdl.utils.Shape\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode = \"sum\")\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)",
            "title": "Functional API"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#layers",
            "text": "See  here  for all the available layers for the Keras-Style API.  To set the name of a layer, call the method  setName(name)  of the layer.",
            "title": "Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#lenet-example",
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation = \"tanh\").setName(\"conv1_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation = \"tanh\").setName(\"conv2_5x5\"))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation = \"tanh\").setName(\"fc1\"))\nmodel.add(Dense(10, activation = \"softmax\").setName(\"fc2\"))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)",
            "title": "LeNet Example"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/",
            "text": "Activation\n\n\nSimple activation function to be applied to the output.\n\n\nScala:\n\n\nActivation(activation, inputShape = null)\n\n\n\n\nPython:\n\n\nActivation(activation, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: Name of the activation function as string. See \nhere\n for available activation strings.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Activation\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation[Float](\"tanh\", inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Activation\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Activation(\"tanh\", input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]\n\n\n\n\nOutput is\n\n\n[[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]\n\n\n\n\nNote that the following two pieces of code will be equivalent:\n\n\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\n\n\n\n\nmodel.add(Dense(32, activation=\"relu\"))\n\n\n\n\n\n\nAvailable Activations\n\n\n\n\nelu\n\n\nrrelu\n\n\nrelu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input.\n\n\nselu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information).\n\n\ntanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.\n\n\nhardtanh\n\n\nsigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.\n\n\nhard_sigmoid\n\n\nsoftmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\n            elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\n            Softmax is defined as:\nf_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift)\n\n            where \nshift = max_i(x_i)\n.\n\n\nsoftplus : Apply the SoftPlus function to an n-dimensional input tensor.\n\n\nsoftsign : SoftSign applies SoftSign function to the input tensor\n\n\nexponential : Exponential (base e) activation function.\n\n\nlinear : Linear (i.e. identity) activation function.\n\n\n\n\n\n\nELU\n\n\nApplies exponential linear unit (\nELU\n), which parameter a varies the convergence value of the exponential function below zero:\n\n\nELU\n is defined as:\n\n\nf(x) = max(0, x) + min(0, alpha * (exp(x) - 1))\n\n\n\n\nThe output dimension is always equal to input dimension.\n\n\nFor reference see \nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n.\n\n\nScala:\n\n\nELU(alpha = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nm = ELU(alpha=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Double, scale for the negative factor. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](1.2, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.3208098      -0.3994111      1.5678865       -0.5417255      -0.72367394\n-0.16772668     -0.28669843     1.0305564       0.15613572      0.29151332\n-1.1018531      -0.32264477     -1.4345981      -0.4781121      -2.1548445\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4647158      -0.64999336     0.97413754\n1.0128744       -0.3654132      0.15322192      1.048261        0.9095614\n-0.6602698      0.2848114       -0.35451657     -1.3011501      0.7933063\n-1.5871915      -0.9177772      0.4741297       0.34224162      -2.7270272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8796972      -0.3951421      1.5678865       -0.5019077      -0.61803937\n-0.18529809     -0.29911432     1.0305564       0.15613572      0.29151332\n-0.8012943      -0.33092272     -0.9141467      -0.4560568      -1.0608946\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4460236      -0.5735409      0.97413754\n1.0128744       -0.36730814     0.15322192      1.048261        0.9095614\n-0.57994574     0.2848114       -0.358185       -0.8733378      0.7933063\n-0.9546011      -0.720713       0.4741297       0.34224162      -1.1215038\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(1.2, input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075],\n        [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956],\n        [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748],\n        [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108],\n        [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063],\n        [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432  ],\n        [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]])\n\n\n\n\nOutput is\n\n\narray([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076],\n        [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957],\n        [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748],\n        [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ],\n        [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066],\n        [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432  ],\n        [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]],\n      dtype=float32)\n\n\n\n\n\n\nRReLU\n\n\nApplies the randomized leaky rectified linear unit element-wise to the input.\n\n\nf(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).\n\n\nIn the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u).\n\n\nIn the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2.\n\n\nIf l == u, a RReLU essentially becomes a LeakyReLU.\n\n\nRegardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.\n\n\nFor reference, see \nEmpirical Evaluation of Rectified Activations in Convolutional Network\n.\n\n\nScala:\n\n\nRReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null)\n\n\n\n\nPython:\n\n\nRReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlower\n: Lower boundary of the uniform random distribution. Default is 1.0/8.\n\n\nupper\n: Upper boundary of the uniform random distribution. Default is 1.0/3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RReLU[Float](inputShape = Shape(1, 4)))\nval input = Tensor[Float](1, 1, 4).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import RReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RReLU(input_shape = (1, 4)))\ninput = np.random.random([1, 1, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]])\n\n\n\n\nOuput is:\n\n\narray([[[0.421039  , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32)\n\n\n\n\n\n\nHardTanh\n\n\nApplies the hard tanh function element-wise to the input.\n\n\nf(x) = maxValue, if x > maxValue\n\n\nf(x) = minValue, if x < minValue\n\n\nf(x) = x, otherwise\n\n\nScala:\n\n\nHardTanh(minValue = -1, maxValue = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nHardTanh(min_value=-1, max_value=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nminValue\n: The minimum threshold value. Default is -1.\n\n\nmaxValue\n: The maximum threshold value. Default is 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8396661       -2.096241       -0.36010137     -1.97987\n-0.20326108     1.5972694       -1.4166505      -0.3369559\n-0.22637285     -1.1021988      1.0707928       -1.5014135\n\n(2,.,.) =\n-0.24511681     -1.1103313      -0.7901563      -1.0394055\n-0.033373486    0.22657289      -0.7928737      1.5241393\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5     -1.0    -0.36010137     -1.0\n-0.20326108     0.5     -1.0    -0.3369559\n-0.22637285     -1.0    0.5     -1.0\n\n(2,.,.) =\n-0.24511681     -1.0    -0.7901563      -1.0\n-0.033373486    0.22657289      -0.7928737      0.5\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import HardTanh\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(HardTanh(-1, 0.5, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.38707977, 0.94085094, 0.50552125, 0.42818523],\n  [0.5544486 , 0.36521357, 0.42551631, 0.93228245],\n  [0.29155494, 0.61710319, 0.93137551, 0.05688166]],\n\n [[0.75222706, 0.36454257, 0.83076327, 0.82004643],\n  [0.29213453, 0.71532663, 0.99556398, 0.57001469],\n  [0.58088671, 0.32646428, 0.60736   , 0.14861018]]]\n\n\n\n\nOutput is\n\n\n[[[0.38707978, 0.5       , 0.5       , 0.42818522],\n  [0.5       , 0.36521357, 0.4255163 , 0.5       ],\n  [0.29155496, 0.5       , 0.5       , 0.05688166]],\n\n [[0.5       , 0.36454257, 0.5       , 0.5       ],\n  [0.29213452, 0.5       , 0.5       , 0.5       ],\n  [0.5       , 0.3264643 , 0.5       , 0.14861017]]]",
            "title": "Activation"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#activation",
            "text": "Simple activation function to be applied to the output.  Scala:  Activation(activation, inputShape = null)  Python:  Activation(activation, input_shape=None, name=None)  Parameters:   activation : Name of the activation function as string. See  here  for available activation strings.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Activation\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation[Float](\"tanh\", inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Activation\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Activation(\"tanh\", input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]  Output is  [[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]  Note that the following two pieces of code will be equivalent:  model.add(Dense(32))\nmodel.add(Activation('relu'))  model.add(Dense(32, activation=\"relu\"))",
            "title": "Activation"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#available-activations",
            "text": "elu  rrelu  relu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input.  selu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information).  tanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.  hardtanh  sigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.  hard_sigmoid  softmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\n            elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\n            Softmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift) \n            where  shift = max_i(x_i) .  softplus : Apply the SoftPlus function to an n-dimensional input tensor.  softsign : SoftSign applies SoftSign function to the input tensor  exponential : Exponential (base e) activation function.  linear : Linear (i.e. identity) activation function.",
            "title": "Available Activations"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#elu",
            "text": "Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero:  ELU  is defined as:  f(x) = max(0, x) + min(0, alpha * (exp(x) - 1))  The output dimension is always equal to input dimension.  For reference see  Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) .  Scala:  ELU(alpha = 1.0, inputShape = null)  Python:  m = ELU(alpha=1.0, input_shape=None, name=None)  Parameters:   alpha : Double, scale for the negative factor. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](1.2, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.3208098      -0.3994111      1.5678865       -0.5417255      -0.72367394\n-0.16772668     -0.28669843     1.0305564       0.15613572      0.29151332\n-1.1018531      -0.32264477     -1.4345981      -0.4781121      -2.1548445\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4647158      -0.64999336     0.97413754\n1.0128744       -0.3654132      0.15322192      1.048261        0.9095614\n-0.6602698      0.2848114       -0.35451657     -1.3011501      0.7933063\n-1.5871915      -0.9177772      0.4741297       0.34224162      -2.7270272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8796972      -0.3951421      1.5678865       -0.5019077      -0.61803937\n-0.18529809     -0.29911432     1.0305564       0.15613572      0.29151332\n-0.8012943      -0.33092272     -0.9141467      -0.4560568      -1.0608946\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4460236      -0.5735409      0.97413754\n1.0128744       -0.36730814     0.15322192      1.048261        0.9095614\n-0.57994574     0.2848114       -0.358185       -0.8733378      0.7933063\n-0.9546011      -0.720713       0.4741297       0.34224162      -1.1215038\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(1.2, input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)  Input is:  array([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075],\n        [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956],\n        [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748],\n        [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108],\n        [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063],\n        [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432  ],\n        [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]])  Output is  array([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076],\n        [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957],\n        [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748],\n        [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ],\n        [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066],\n        [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432  ],\n        [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]],\n      dtype=float32)",
            "title": "ELU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#rrelu",
            "text": "Applies the randomized leaky rectified linear unit element-wise to the input.  f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).  In the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u).  In the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2.  If l == u, a RReLU essentially becomes a LeakyReLU.  Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.  For reference, see  Empirical Evaluation of Rectified Activations in Convolutional Network .  Scala:  RReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null)  Python:  RReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None)  Parameters:   lower : Lower boundary of the uniform random distribution. Default is 1.0/8.  upper : Upper boundary of the uniform random distribution. Default is 1.0/3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RReLU[Float](inputShape = Shape(1, 4)))\nval input = Tensor[Float](1, 1, 4).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import RReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RReLU(input_shape = (1, 4)))\ninput = np.random.random([1, 1, 4])\noutput = model.forward(input)  Input is:  array([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]])  Ouput is:  array([[[0.421039  , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32)",
            "title": "RReLU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#hardtanh",
            "text": "Applies the hard tanh function element-wise to the input.  f(x) = maxValue, if x > maxValue  f(x) = minValue, if x < minValue  f(x) = x, otherwise  Scala:  HardTanh(minValue = -1, maxValue = 1, inputShape = null)  Python:  HardTanh(min_value=-1, max_value=1, input_shape=None, name=None)  Parameters:   minValue : The minimum threshold value. Default is -1.  maxValue : The maximum threshold value. Default is 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8396661       -2.096241       -0.36010137     -1.97987\n-0.20326108     1.5972694       -1.4166505      -0.3369559\n-0.22637285     -1.1021988      1.0707928       -1.5014135\n\n(2,.,.) =\n-0.24511681     -1.1103313      -0.7901563      -1.0394055\n-0.033373486    0.22657289      -0.7928737      1.5241393\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5     -1.0    -0.36010137     -1.0\n-0.20326108     0.5     -1.0    -0.3369559\n-0.22637285     -1.0    0.5     -1.0\n\n(2,.,.) =\n-0.24511681     -1.0    -0.7901563      -1.0\n-0.033373486    0.22657289      -0.7928737      0.5\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import HardTanh\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(HardTanh(-1, 0.5, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.38707977, 0.94085094, 0.50552125, 0.42818523],\n  [0.5544486 , 0.36521357, 0.42551631, 0.93228245],\n  [0.29155494, 0.61710319, 0.93137551, 0.05688166]],\n\n [[0.75222706, 0.36454257, 0.83076327, 0.82004643],\n  [0.29213453, 0.71532663, 0.99556398, 0.57001469],\n  [0.58088671, 0.32646428, 0.60736   , 0.14861018]]]  Output is  [[[0.38707978, 0.5       , 0.5       , 0.42818522],\n  [0.5       , 0.36521357, 0.4255163 , 0.5       ],\n  [0.29155496, 0.5       , 0.5       , 0.05688166]],\n\n [[0.5       , 0.36454257, 0.5       , 0.5       ],\n  [0.29213452, 0.5       , 0.5       , 0.5       ],\n  [0.5       , 0.3264643 , 0.5       , 0.14861017]]]",
            "title": "HardTanh"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/initialization/",
            "text": "",
            "title": "Initialization"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/",
            "text": "Masking\n\n\nUse a mask value to skip timesteps for a sequence.\n\n\nScala:\n\n\nMasking(maskValue = 0.0, inputShape = null)\n\n\n\n\nPython:\n\n\nMasking(mask_value=0.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nmaskValue\n: Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Masking\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.31542103 0.20640659 0.22282763]\n [0.99352167 0.90135718 0.24504717]]\n\n\n\n\nOutput is\n\n\n[[0.31542102 0.2064066  0.22282763]\n [0.9935217  0.9013572  0.24504717]]\n\n\n\n\n\n\nSparseDense\n\n\nSparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:\nfirstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward\ngradient to next layer in the backpropagation by default, as the gradInput of SparseDense is\nuseless and very big in most cases.\n\n\nBut, considering model like Wide&Deep, we provide backwardStart and backwardLength to backward\npart of the gradient to next layer.\n\n\nThe most common input is 2D.\n\n\nScala:\n\n\nSparseDense(outputDim, init = \"glorot_uniform\", activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nSparseDense(output_dim, init=\"glorot_uniform\", activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of the output dimension.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. Default is null.\n\n\nwRegularizer\n: An instance of [Regularizer], applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of [Regularizer], applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\nbackwardStart\n: Backward start index, counting from 1.\n\n\nbackwardLength\n: Backward length.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4))\nlayer.build(Shape(-1, 2, 4))\nval input = Tensor[Float](Array(2, 4)).rand()\ninput.setValue(1, 1, 1f)\ninput.setValue(2, 3, 3f)\nval sparseInput = Tensor.sparse(input)\nval output = layer.forward(sparseInput)\n\n\n\n\nInput is:\n\n\ninput: \n(0, 0) : 1.0\n(0, 1) : 0.2992794\n(0, 2) : 0.11227019\n(0, 3) : 0.722947\n(1, 0) : 0.6147614\n(1, 1) : 0.4288646\n(1, 2) : 3.0\n(1, 3) : 0.7749917\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: \n0.053516    0.33429605  0.22587383  -0.8998945  0.24308181  \n0.76745665  -1.614114   0.5381658   -2.2226436  -0.15573677 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseDense\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseDense(output_dim=2, input_shape=(3, 4)))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\nJTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float\n\n\n\n\nOutput is\n\n\n[[ 1.57136     2.29596   ]\n [ 0.5791738  -1.6598101 ]\n [ 2.331141   -0.84687066]]\n ```\n\n## **SoftShrink**\nApplies the soft shrinkage function element-wise to the input.\n\nWhen you use this layer as the first layer of a model, you need to provide\nthe argument inputShape (a Single Shape, does not include the batch dimension).\n\nRemark: This layer is from Torch and wrapped in Keras style.\n\n\n**Scala:**\n```scala\nSoftShrink(value = 0.5, inputShape = null)\n\n\n\n\nPython:\n\n\nSoftShrink(value = 0.5, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nvalue\n: value The threshold value. Default is 0.5.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.36938807 0.023556225 -1.1655436  -0.34449077\n0.9444338   -0.086538695    -1.0425501  1.364976\n-1.2563878  -0.1842559  0.43428117  1.0756494\n\n(1,2,.,.) =\n-0.19888283 1.251872    0.114836805 -0.6208773\n0.0051822234    -0.8998633  0.06937465  -0.3929931\n-0.1058129  0.6945743   -0.40083578 -0.6252444\n\n(2,1,.,.) =\n-0.9899709  -0.77926594 -0.15497442 -0.15031165\n-0.6028622  0.86623466  -2.1543107  0.41970536\n-0.8215522  0.3014275   -0.32184362 0.14445356\n\n(2,2,.,.) =\n0.74701905  0.10044397  -0.40519297 0.03822808\n0.30726334  0.27862388  1.731753    0.032177072\n-1.3476961  -0.2294767  0.99794704  0.7398458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0 0.0 -0.56554353 0.0\n0.34443378  0.0 -0.44255006 0.764976\n-0.6563878  0.0 0.0 0.47564936\n\n(1,2,.,.) =\n0.0 0.6518719   0.0 -0.020877302\n0.0 -0.29986328 0.0 0.0\n0.0 0.09457427  0.0 -0.025244355\n\n(2,1,.,.) =\n-0.3899709  -0.17926592 0.0 0.0\n-0.0028621554   0.26623464  -1.5543107  0.0\n-0.2215522  0.0 0.0 0.0\n\n(2,2,.,.) =\n0.14701903  0.0 0.0 0.0\n0.0 0.0 1.131753    0.0\n-0.74769604 0.0 0.397947    0.13984579\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SoftShrink\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SoftShrink(0.6, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[ 0.43421006,  0.28394451,  0.15221226,  0.47268966],\n         [ 0.22426224,  0.24855662,  0.790498  ,  0.67767582],\n         [ 0.14879562,  0.56077882,  0.61470262,  0.94875862]],\n\n        [[ 0.72404932,  0.89780875,  0.08456734,  0.01303937],\n         [ 0.25023568,  0.45392504,  0.587254  ,  0.51164461],\n         [ 0.12277567,  0.05571182,  0.17076456,  0.71660884]]],\n\n\n       [[[ 0.06369975,  0.85395557,  0.35752425,  0.606633  ],\n         [ 0.67640252,  0.86861737,  0.18040722,  0.55467108],\n         [ 0.24102058,  0.37580645,  0.81601612,  0.56513788]],\n\n        [[ 0.8461435 ,  0.65668365,  0.17969807,  0.51602926],\n         [ 0.86191073,  0.34245714,  0.62795207,  0.36706125],\n         [ 0.80344028,  0.81056003,  0.80959083,  0.15366483]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.19049799,  0.07767582],\n         [ 0.        ,  0.        ,  0.01470262,  0.34875858]],\n\n        [[ 0.12404931,  0.29780871,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.1166088 ]]],\n\n\n       [[[ 0.        ,  0.25395554,  0.        ,  0.00663298],\n         [ 0.07640249,  0.26861733,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.21601611,  0.        ]],\n\n        [[ 0.24614346,  0.05668366,  0.        ,  0.        ],\n         [ 0.26191074,  0.        ,  0.02795208,  0.        ],\n         [ 0.20344025,  0.21056002,  0.20959079,  0.        ]]]], dtype=float32)\n\n ```\n\n---\n## **Reshape**\nReshapes an output to a certain shape.\n\nSupports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).\n\n**Scala:**\n```scala\nReshape(targetShape, inputShape = null)\n\n\n\n\nPython:\n\n\nReshape(target_shape, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntargetShape\n: The target shape that you desire to have. Batch dimension should be excluded.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Reshape\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]\n\n\n\n\nOutput is\n\n\n[[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]\n\n\n\n\n\n\nMerge\n\n\nUsed to merge a list of inputs into a single output, following some merge mode.\n\n\nMerge must have at least two input layers.\n\n\nScala:\n\n\nMerge(layers = null, mode = \"sum\", concatAxis = -1, inputShape = null)\n\n\n\n\nPython:\n\n\nMerge(layers=None, mode=\"sum\", concat_axis=-1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlayers\n: A list of layer instances. Must be more than one layer.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode = \"sum\")\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -> input1, 2 -> input2)\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Merge, InputLayer\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n   [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n   [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n  [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n   [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n   [0.56138318, 0.68165639, 0.10644523, 0.51860127]]],\n\n [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n   [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n   [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n  [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n   [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n   [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]]\n\n\n\n\nOutput is\n\n\n[[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]\n\n\n\n\n\n\nMaxoutDense\n\n\nA dense maxout layer that takes the element-wise maximum of linear layers.\n\n\nThis allows the layer to learn a convex, piecewise linear activation function over the inputs.\n\n\nThe input of this layer should be 2D.\n\n\nScala:\n\n\nMaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of output dimension.\n\n\nnbFeature\n: Number of Dense layers to use internally. Integer. Default is 4.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxoutDense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]\n\n\n\n\nOutput is\n\n\n[[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]\n\n\n\n\n\n\nSqueeze\n\n\nDelete the singleton dimension(s). The batch dimension needs to be unchanged.\n\n\nFor example, if input has size (2, 1, 3, 4, 1):\n\n\nSqueeze(1) will give output size (2, 3, 4, 1),\n\n\nSqueeze() will give output size (2, 3, 4)\n\n\nScala:\n\n\nSqueeze(dims = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSqueeze(dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndims\n: The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32)))\nval input = Tensor[Float](1, 1, 1, 32).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Squeeze\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Squeeze(1, input_shape=(1, 1, 32)))\ninput = np.random.random([1, 1, 1, 32])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281,\n    0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763,\n    0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269,\n    0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821,\n    0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 ,\n    0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729,\n    0.89774196, 0.77838838]]]]\n\n\n\n\nOutput is\n\n\n[[[0.20585343, 0.470117  , 0.14553176, 0.939156  , 0.5723428 ,\n   0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763,\n   0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 ,\n   0.48919672, 0.284064  , 0.20962799, 0.8807176 , 0.45501822,\n   0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 ,\n   0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 ,\n   0.897742  , 0.7783884 ]]]\n\n\n\n\n\n\nBinaryThreshold\n\n\nThreshold the input.\n\n\nIf an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1.\n\n\nScala:\n\n\nBinaryThreshold(value = 1e-6, inputShape = null)\n\n\n\n\nPython:\n\n\nBinaryThreshold(value=1e-6, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nvalue\n: The threshold value to compare with. Default is 1e-6.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1907398      -0.18995096     -2.0344417      -1.3789974\n-1.8801064      -0.74757665     -0.4339697      0.0058485097\n0.7012256       -0.6363152      2.0156987       -0.5512639\n\n(1,2,.,.) =\n-0.5251603      0.082127444     0.29550993      1.6357868\n-1.3828015      -0.11842779     0.3316966       -0.14360528\n0.21216457      -0.117370956    -0.12934707     -0.35854268\n\n(2,1,.,.) =\n-0.9071151      -2.8566089      -0.4796377      -0.915065\n-0.8439908      -0.25404388     -0.39926198     -0.15191565\n-1.0496653      -0.403675       -1.3591816      0.5311797\n\n(2,2,.,.) =\n0.53509855      -0.08892822     1.2196561       -0.62759316\n-0.47476718     -0.43337926     -0.10406987     1.4035174\n-1.7120812      1.1328355       0.9219375       1.3813454\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n1.0     0.0     1.0     0.0\n\n(1,2,.,.) =\n0.0     1.0     1.0     1.0\n0.0     0.0     1.0     0.0\n1.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n\n(2,2,.,.) =\n1.0     0.0     1.0     0.0\n0.0     0.0     0.0     1.0\n0.0     1.0     1.0     1.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import BinaryThreshold\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(BinaryThreshold(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767],\n         [0.72650405, 0.53096719, 0.66346109, 0.0589329 ],\n         [0.12994731, 0.92181174, 0.43129874, 0.97306968]],\n\n        [[0.3031087 , 0.20339982, 0.69034712, 0.40191   ],\n         [0.57517034, 0.30159448, 0.4801747 , 0.75175084],\n         [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]],\n\n\n       [[[0.46102959, 0.33029002, 0.69340103, 0.32885719],\n         [0.84405147, 0.03421879, 0.68242578, 0.03560338],\n         [0.12244515, 0.3610654 , 0.01312785, 0.84485178]],\n\n        [[0.73472287, 0.75707757, 0.77070527, 0.40863145],\n         [0.01137898, 0.82896826, 0.1498069 , 0.22309423],\n         [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]])\n\n\n\n\nOutput is\n\n\narray([[[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]],\n\n\n       [[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]]], dtype=float32)\n\n\n\n\n\n\nSqrt\n\n\nApplies an element-wise square root operation to the input.\n\n\nScala:\n\n\nSqrt(inputShape = null)\n\n\n\n\nPython:\n\n\nSqrt(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Sqrt[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6950394       0.5234307       1.7375475\n0.25833175      0.02685826      -0.6046901\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8336902       0.7234851       1.3181607\n0.50826347      0.16388491      NaN\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Sqrt\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Sqrt(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.2484558 , 0.65280218, 0.35286984],\n [0.19616094, 0.30966802, 0.82148169]]\n\n\n\n\nOutput is\n\n\n[[0.4984534 , 0.80796176, 0.5940285 ],\n [0.4429006 , 0.55647826, 0.9063563 ]]\n\n\n\n\n\n\nMul\n\n\nMultiply a single scalar factor to the incoming data\n\n\nScala:\n\n\nMul(inputShape = null)\n\n\n\n\nPython:\n\n\nMul(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Mul\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Mul[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2316265  -2.008802 -1.3908259  -0.61135375\n-0.48992255 0.1786112 0.18872596  0.49621895\n-0.6931602  -0.919745 -0.09019699 -0.41218707\n\n(2,.,.) =\n-0.3135355  -0.4385771  -0.3317269  1.0412029\n-0.8859662  0.17758773  -0.73779273 -0.4445366\n0.3921595 1.6923207 0.014470488 0.4044164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.59036994 -0.9629025  -0.6666808  -0.29304734\n-0.2348403  0.0856158 0.09046422  0.23785843\n-0.33226058 -0.44087213 -0.043235175  -0.19757845\n\n(2,.,.) =\n-0.15029064 -0.21022828 -0.15901053 0.49909195\n-0.42468053 0.0851252 -0.3536548  -0.21308492\n0.18797839  0.81119984  0.006936308 0.19385365\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Mul\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Mul(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.22607292,  0.59806062,  0.19428923,  0.22928606],\n        [ 0.13804536,  0.1615547 ,  0.52824658,  0.52794904],\n        [ 0.4049169 ,  0.94109084,  0.58158453,  0.78368633]],\n\n       [[ 0.86233305,  0.47995805,  0.80430949,  0.9931171 ],\n        [ 0.35179631,  0.33615276,  0.87756877,  0.73560288],\n        [ 0.29775703,  0.11404466,  0.77695536,  0.97580018]]])\n\n\n\n\nOutput is\n\n\narray([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998],\n        [-0.13730718, -0.1606908 , -0.52542186, -0.52512592],\n        [-0.40275168, -0.93605846, -0.57847458, -0.77949566]],\n\n       [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ],\n        [-0.34991512, -0.33435524, -0.87287611, -0.73166931],\n        [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32)\n\n\n\n\n\n\nMulConstant\n\n\nMultiply the input by a (non-learnable) scalar constant.\n\n\nScala:\n\n\nMulConstant(constant, inputShape = null)\n\n\n\n\nPython:\n\n\nMulConstant(constant, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nconstant\n: The scalar constant to be multiplied.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MulConstant[Float](2.2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.16873977     1.0812985       1.0942211       -0.67091423\n1.0086882       0.5915831       0.26184535      -1.361431\n1.5616825       -0.037591368    1.2794676       1.0692137\n\n(2,.,.) =\n0.29868057      -0.23266982     -0.7679556      -2.209848\n-0.13954644     -0.1368473      -0.54510623     1.8397199\n-0.58691734     -0.56410027     -1.5567777      0.050648995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.3712275      2.3788567       2.4072864       -1.4760114\n2.219114        1.3014828       0.57605976      -2.9951482\n3.4357016       -0.08270101     2.8148286       2.3522704\n\n(2,.,.) =\n0.6570973       -0.5118736      -1.6895024      -4.8616657\n-0.3070022      -0.30106407     -1.1992338      4.047384\n-1.2912182      -1.2410206      -3.424911       0.11142779\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MulConstant\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MulConstant(2.2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.39874191, 0.66634984, 0.23907766, 0.31587494],\n  [0.78842014, 0.93057835, 0.80739529, 0.71541279],\n  [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]],\n\n [[0.60142458, 0.41221671, 0.00890549, 0.32069845],\n  [0.51122554, 0.76280426, 0.87579418, 0.17182832],\n  [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]]\n\n\n\n\nOutput is\n\n\n[[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ],\n  [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ],\n  [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]],\n\n [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ],\n  [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234],\n  [1.19093   , 0.43591645, 2.0356452 , 1.2356553 ]]]\n\n\n\n\n\n\nScale\n\n\nScale is the combination of CMul and CAdd.\n\n\nComputes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input.\n\n\nSimilarly, perform an expanded bias and perform an element-wise add.\n\n\nScala:\n\n\nScale(size, inputShape = null)\n\n\n\n\nPython:\n\n\nScale(size, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Size of the weight and bias.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Scale\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nvar array = Array(1, 2)\nmodel.add(Scale[Float](array, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006399727    -0.06412822     -0.2334789\n0.31029955      1.6557469       1.9614618\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.09936619      0.57585865      0.20324506\n0.38537437      -0.8598822      -1.0186496\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Scale\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Scale((2, 1), input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.7242994 , 0.77888884, 0.71470432],\n [0.03058471, 0.00602764, 0.57513629]]\n\n\n\n\nOutput is\n\n\n[[1.0946966 , 1.1255064 , 1.0892813 ],\n [0.58151895, 0.5909191 , 0.37307182]]\n\n\n\n\n\n\nLog\n\n\nApplies a log transformation to the input.\n\n\nScala:\n\n\nLog(inputShape = null)\n\n\n\n\nPython:\n\n\nLog(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Log\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Log[Float](inputShape = Shape(2, 4, 4)))\nval input = Tensor[Float](1, 2, 4, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.38405678      -0.5502389      -0.383079       -0.988537\n-0.6294056      -0.7838047      0.8747865       -1.0659786\n-2.2445498      -0.5488076      -0.42898977     0.6916364\n1.6542299       -0.9966279      -0.38244298     1.6954672\n\n(1,2,.,.) =\n0.43478605      -0.6678534      1.9530942       -0.5209587\n0.12899925      0.20572199      2.0359943       0.55223215\n0.65247816      0.8792108       -0.38860792     0.48663738\n-1.0084358      0.31141177      0.69208467      0.48385203\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.95696485     NaN     NaN     NaN\nNaN     NaN     -0.13377543     NaN\nNaN     NaN     NaN     -0.36869493\n0.5033356       NaN     NaN     0.5279584\n\n(1,2,.,.) =\n-0.83290124     NaN     0.6694149       NaN\n-2.0479486      -1.5812296      0.7109843       -0.5937868\n-0.4269776      -0.12873057     NaN     -0.720236\nNaN     -1.1666392      -0.36804697     -0.72597617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Log\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Log(input_shape=(2, 4, 4)))\ninput = np.random.random([1, 2, 4, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453],\n   [0.46529477, 0.81511804, 0.24435558, 0.45003562],\n   [0.15170845, 0.35157662, 0.0925214 , 0.63852947],\n   [0.27817508, 0.42572846, 0.44363004, 0.03536394]],\n\n  [[0.65027784, 0.00429838, 0.07434429, 0.18653305],\n   [0.19659183, 0.66647529, 0.77821197, 0.65894478],\n   [0.28212032, 0.52307663, 0.09589939, 0.71547588],\n   [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032],\n   [-0.76508415, -0.20442237, -1.4091308 , -0.79842854],\n   [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742],\n   [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]],\n\n  [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ],\n   [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554],\n   [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743],\n   [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]]\n\n\n\n\n\n\nIdentity\n\n\nIdentity just return the input to output.\n\n\nIt's useful in same parallel container to get an origin input.\n\n\nScala:\n\n\nIdentity(inputShape = null)\n\n\n\n\nPython:\n\n\nIdentity(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Identity\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Identity[Float](inputShape = Shape(4, 4)))\nval input = Tensor[Float](3, 4, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Identity\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Identity(input_shape=(4, 4)))\ninput = np.random.random([3, 4, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.36751123, 0.92287101, 0.73894405, 0.33699379],\n  [0.69405782, 0.9653215 , 0.2617223 , 0.68205229],\n  [0.71455325, 0.99419333, 0.90886495, 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921154, 0.26803146]],\n\n  [[0.35898357, 0.72067882, 0.13236563, 0.71935521],\n   [0.30865626, 0.71098844, 0.86718946, 0.12531168],\n   [0.84916882, 0.84221518, 0.52186664, 0.87239729],\n   [0.50637899, 0.10890469, 0.86832705, 0.93581179]],\n\n  [[0.19640105, 0.09341008, 0.12043328, 0.09261859],\n   [0.66019486, 0.07251262, 0.80929761, 0.39094486],\n   [0.63027391, 0.39537796, 0.55578905, 0.53933265],\n   [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]]\n\n\n\n\nOutput is\n\n\n[[[0.36751124, 0.922871  , 0.73894405, 0.33699378],\n  [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ],\n  [0.71455324, 0.9941933 , 0.908865  , 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921156, 0.26803148]],\n\n [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ],\n  [0.30865628, 0.71098846, 0.86718947, 0.12531169],\n  [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ],\n  [0.506379  , 0.10890469, 0.868327  , 0.9358118 ]],\n\n [[0.19640104, 0.09341008, 0.12043328, 0.09261858],\n  [0.6601949 , 0.07251262, 0.8092976 , 0.39094487],\n  [0.63027394, 0.39537796, 0.55578905, 0.5393326 ],\n  [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]]\n\n\n\n\n\n\nSelect\n\n\nSelect an index of the input in the given dim and return the subset part.\n\n\nThe batch dimension needs to be unchanged.\n\n\nFor example, if input is:\n\n\n[[1, 2, 3], \n [4, 5, 6]]\n\n\nSelect(1, 1) will give output [2 5]\n\n\nSelect(1, -1) will give output [3 6]\n\n\nScala:\n\n\nSelect(dim, index, inputShape = null)\n\n\n\n\nPython:\n\n\nSelect(dim, index, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndim\n: The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input.\n\n\nindex\n: The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Select\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3)))\nval input = Tensor[Float](1, 3, 1, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.67646945     -0.5485965      -0.11103154\n(1,2,.,.) =\n-0.13488655     0.43843046      -0.04482145\n(1,3,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Select\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Select(1, 2, input_shape=(3, 1, 3)))\ninput = np.random.random([1, 3, 1, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.53306099, 0.95147881, 0.15222129]],\n        [[0.89604861, 0.90160974, 0.5230576 ]],\n        [[0.70779386, 0.14438568, 0.37601195]]]])\n\n\n\n\nOutput is:\n\n\narray([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32)\n\n\n\n\n\n\nDense\n\n\nA densely-connected NN layer.\n\n\nThe most common input is 2D.\n\n\nScala:\n\n\nDense(outputDim, init = \"glorot_uniform\", activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nDense(output_dim, init=\"glorot_uniform\", activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of the output dimension.\n\n\ninit\n: Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method.\n\n\nactivation\n: Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](5, activation = \"relu\", inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4289935       -1.7659454      -0.08306135     -1.0153456\n1.0191492       0.37392816      1.3076705       -0.19495767\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5421522       0.49008092      0.0     0.0     0.0\n0.07940009      0.0     0.12953377      0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Dense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(5, activation=\"relu\", input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[0.64593485, 0.67393322, 0.72505368, 0.04654095],\n       [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]])\n\n\n\n\nOutput is\n\n\narray([[0.        , 0.        , 1.2698183 , 0.        , 0.10656227],\n       [0.        , 0.        , 0.6236721 , 0.00299606, 0.29664695]],\n      dtype=float32)\n\n\n\n\n\n\nNegative\n\n\nComputes the negative value of each element of the input.\n\n\nScala:\n\n\nNegative(inputShape = null)\n\n\n\n\nPython:\n\n\nNegative(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Negative\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Negative[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.031705        -0.5723963      1.998631\n-0.32908052     2.4069138       -2.4111257\n(2,.,.) =\n0.5355049       -1.4404331      -0.38116863\n-0.45641592     -1.1485358      0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.031705       0.5723963       -1.998631\n0.32908052      -2.4069138      2.4111257\n(2,.,.) =\n-0.5355049      1.4404331       0.38116863\n0.45641592      1.1485358       -0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Negative\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Negative(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.39261261, 0.03164615, 0.32179116],\n        [0.11969367, 0.61610712, 0.42573733]],\n       [[0.36794656, 0.90912174, 0.540356  ],\n        [0.42667627, 0.04154093, 0.84692964]]])\n\n\n\n\nOutput is\n\n\narray([[[-0.3926126 , -0.03164615, -0.32179114],\n        [-0.11969367, -0.6161071 , -0.42573732]],\n       [[-0.36794657, -0.90912175, -0.540356  ],\n        [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32)\n\n\n\n\n\n\nCAdd\n\n\nThis layer has a bias with given size.\n\n\nThe bias will be added element-wise to the input.\n\n\nIf the element number of the bias matches the input, a simple element-wise addition will be done.\n\n\nOr the bias will be expanded to the same size of the input.\n\n\nThe expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised).\n\n\nScala:\n\n\nCAdd(size, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nCAdd(size, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: the size of the bias\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.2183351       0.32434112      0.89350265\n0.3348259       0.78677046      0.24054797\n(2,.,.) =\n0.9945844       0.72363794      0.7737936\n0.05522544      0.3517818       0.7417069\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1358028       0.6956667       1.0837181\n0.6767027       0.7955346       0.5063505\n(2,.,.) =\n0.9120521       1.0949634       0.96400905\n0.3971022       0.36054593      1.0075095\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import CAdd\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(CAdd([2, 1], input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.4122004 , 0.73289359, 0.11500016],\n        [0.26974491, 0.32166632, 0.91408442]],\n       [[0.66824327, 0.80271314, 0.75981145],\n        [0.39271431, 0.07312566, 0.4966805 ]]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.06560206,  0.38629526, -0.23159817],\n        [ 0.44287407,  0.4947955 ,  1.0872136 ]],\n       [[ 0.32164496,  0.45611483,  0.41321313],\n        [ 0.56584346,  0.24625483,  0.6698097 ]]], dtype=float32)\n\n\n\n\n\n\nRepeatVector\n\n\nRepeats the input n times.\n\n\nThe input of this layer should be 2D, i.e. (num_samples, features).\nThe output of thi layer should be 3D, i.e. (num_samples, n, features).\n\n\nScala:\n\n\nRepeatVector(n, inputShape = null)\n\n\n\n\nPython:\n\n\nRepeatVector(n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nn\n: Repetition factor. Integer.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector[Float](4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.31839952 -0.3495366  0.542486\n-0.54981124 -0.8428188  0.8225184\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n\n(2,.,.) =\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import RepeatVector\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[ 0.90715922,  0.54594769,  0.53952404],\n       [ 0.08989831,  0.07265549,  0.45830114]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402]],\n\n       [[ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116]]], dtype=float32)\n\n\n\n\n\n\nGaussianSampler\n\n\nTakes {mean, log_variance} as input and samples from the Gaussian distribution.\n\n\nScala:\n\n\nGaussianSampler(inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianSampler(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler\nimport com.intel.analytics.bigdl.utils.{Shape, MultiShape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval shape1 = Shape(2, 3)\nval shape2 = Shape(2, 3)\nmodel.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2))))\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -> input1, 2 -> input2)\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: (1,.,.) =\n           0.9996127    0.8964211       0.7424038\n           0.40628982   0.37035564      0.20108517\n\n           (2,.,.) =\n           0.6974727    0.60202897      0.1535999\n           0.012422224  0.5993025       0.96206\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n        1: (1,.,.) =\n           0.21060324   0.576583        0.21633287\n           0.1484059    0.2730577       0.25317845\n\n           (2,.,.) =\n           0.58513683   0.58095694      0.18811373\n           0.7029449    0.41235915      0.44636542\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5258198       1.9536011       -1.8591263\n-1.0618867      -0.751225       0.35412917\n\n(2,.,.) =\n1.3334517       -0.60312974     0.7324476\n0.09502721      0.8094909       0.44807082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GaussianSampler\n\nmodel = Sequential()\nmodel.add(GaussianSampler(input_shape=[(3,),(3,)]))\ninput1 = np.random.random([2, 3])\ninput2 = np.random.random([2, 3])\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.79941342, 0.87462822, 0.9516901 ],\n  [0.20111287, 0.54634077, 0.83614511]], \n\n [[0.31886989, 0.22829382, 0.84355419],\n  [0.51186641, 0.28043938, 0.29440057]]]\n\n\n\n\nOutput is\n\n\n[[ 0.71405387  2.2944303  -0.41778684]\n [ 0.84234     2.3337283  -0.18952972]]\n\n\n\n\n\n\nExp\n\n\nApplies element-wise exp to the input.\n\n\nWhen you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nExp(inputShape = null)\n\n\n\n\nPython:\n\n\nExp(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Exp\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Exp[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.5841372      -0.13795324     -2.144475       0.09272669\n1.055668        -1.2310301      1.2145554       -0.6073714\n0.9296467       0.2923885       1.3364213       0.1652137\n\n(1,2,.,.) =\n0.2099718       -0.3856573      -0.92586        -0.5317779\n0.6618383       -0.9677452      -1.5014665      -0.35464883\n2.045924        -0.317644       -1.812726       0.95438373\n\n(2,1,.,.) =\n-0.4536791      -0.34785584     1.6424289       -0.07981159\n-0.8022624      -0.4211059      0.3461831       1.9598864\n-0.84695745     -0.6115283      0.7729755       2.3077402\n\n(2,2,.,.) =\n-0.08438411     -0.908458       0.6688936       -0.7292123\n-0.26337254     0.55425745      -0.14925817     -0.010179609\n-0.62562865     -1.0517743      -0.23839666     -1.144982\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.20512469      0.8711394       0.11712951      1.0971619\n2.8738942       0.29199165      3.3687959       0.544781\n2.533614        1.3396233       3.8054006       1.1796452\n\n(1,2,.,.) =\n1.2336433       0.6800035       0.39619055      0.5875594\n1.9383523       0.37993878      0.22280318      0.7014197\n7.7363033       0.7278619       0.16320862      2.5970695\n\n(2,1,.,.) =\n0.63528657      0.70620066      5.167706        0.92329025\n0.44831353      0.6563206       1.4136615       7.0985208\n0.42871734      0.5425211       2.1662023       10.051684\n\n(2,2,.,.) =\n0.9190782       0.4031454       1.9520763       0.48228875\n0.76845556      1.740648        0.8613467       0.98987204\n0.53492504      0.34931743      0.7878901       0.31822965\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Exp\n\nmodel = Sequential()\nmodel.add(Exp(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.93104587 0.94000338 0.84870765 0.98645553]\n   [0.83708846 0.33375541 0.50119834 0.24879265]\n   [0.51966475 0.84514791 0.15496452 0.61538968]]\n\n  [[0.57250337 0.42520832 0.94850757 0.54317573]\n   [0.64228691 0.9904079  0.01008592 0.51365217]\n   [0.78640595 0.7717037  0.51277595 0.24245034]]]\n\n\n [[[0.82184752 0.92537331 0.20632728 0.47539445]\n   [0.44604637 0.1507692  0.5437313  0.2074501 ]\n   [0.93661363 0.93962609 0.29230559 0.74850958]]\n\n  [[0.11659768 0.76177132 0.33194573 0.20695088]\n   [0.49636212 0.85987328 0.49767861 0.96774006]\n   [0.67669121 0.15542122 0.69981032 0.3349874 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[2.5371614 2.5599902 2.3366253 2.6817122]\n   [2.3096325 1.3962016 1.6506982 1.2824761]\n   [1.6814638 2.3283222 1.1676165 1.8503776]]\n\n  [[1.7726992 1.5299091 2.5818534 1.721465 ]\n   [1.9008229 2.6923325 1.010137  1.6713842]\n   [2.1954916 2.163449  1.6699204 1.2743679]]]\n\n\n [[[2.2746985 2.52281   1.2291554 1.6086487]\n   [1.5621239 1.1627283 1.7224218 1.2305363]\n   [2.551327  2.5590243 1.3395122 2.1138473]]\n\n  [[1.1236672 2.1420672 1.3936772 1.2299222]\n   [1.6427343 2.3628614 1.6448984 2.6319895]\n   [1.9673574 1.16815   2.0133708 1.3979228]]]]\n\n\n\n\n\n\nSquare\n\n\nApplies an element-wise square operation to the input.\n\n\nWhen you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nSquare(inputShape = null)\n\n\n\n\nPython:\n\n\nSquare(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Square\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Square[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.108013034    1.8879265       1.2232096       -1.5076439\n1.4895755       -0.37966672     -0.34892964     0.15224025\n-0.9296686      -1.1523775      0.14153497      -0.26954007\n\n(1,2,.,.) =\n-1.0875931      2.190617        -0.6903083      1.0039362\n-0.1275677      -1.1096588      0.37359753      -0.17367937\n0.23349741      0.14639114      -0.2330162      0.5343827\n\n(2,1,.,.) =\n0.3222191       0.21463287      -1.0157064      -0.22627507\n1.1714277       0.43371263      1.069315        0.5122436\n0.1958086       -1.4601041      2.5394423       -0.470833\n\n(2,2,.,.) =\n-0.38708544     -0.951611       -0.37234613     0.26813275\n1.9477026       0.32779223      -1.2308712      -2.2376378\n0.19652915      0.3304719       -1.7674786      -0.86961496\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.011666816     3.5642662       1.4962418       2.2729902\n2.218835        0.14414681      0.1217519       0.023177093\n0.86428374      1.3279738       0.020032147     0.07265185\n\n(1,2,.,.) =\n1.1828587       4.7988033       0.47652552      1.0078878\n0.016273517     1.2313428       0.13957511      0.030164523\n0.05452104      0.021430366     0.054296546     0.28556487\n\n(2,1,.,.) =\n0.10382515      0.046067268     1.0316595       0.05120041\n1.3722429       0.18810664      1.1434345       0.26239353\n0.038341008     2.131904        6.448767        0.22168371\n\n(2,2,.,.) =\n0.14983514      0.9055635       0.13864164      0.07189517\n3.7935455       0.10744774      1.5150439       5.007023\n0.038623706     0.109211676     3.1239805       0.7562302\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Square\n\nmodel = Sequential()\nmodel.add(Square(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.8708819  0.2698243  0.55854849 0.71699472]\n   [0.66647234 0.72310216 0.8082119  0.66566951]\n   [0.6714764  0.61394108 0.35063125 0.60473593]]\n\n  [[0.37993365 0.64222557 0.96762005 0.18931697]\n   [0.00529722 0.99133455 0.09786619 0.28988077]\n   [0.60052911 0.83712995 0.59847519 0.54361243]]]\n\n\n [[[0.32832672 0.83316023 0.41272485 0.01963383]\n   [0.89593955 0.73433713 0.67529323 0.69711912]\n   [0.81251711 0.56755577 0.31958151 0.09795917]]\n\n  [[0.46465895 0.22818875 0.31505317 0.41912166]\n   [0.87865447 0.3799063  0.091204   0.68144165]\n   [0.88274284 0.70479132 0.32074672 0.71771481]]]]\n\n\n\n\nOutput is\n\n\n[[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01]\n   [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01]\n   [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]]\n\n  [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02]\n   [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02]\n   [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]]\n\n\n [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04]\n   [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01]\n   [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]]\n\n  [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01]\n   [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01]\n   [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]]\n\n\n\n\n\n\nPower\n\n\nApplies an element-wise power operation with scale and shift to the input.\n\n\nf(x) = (shift + scale * x)^power^\n\n\nPower(power, scale = 1, shift = 0, inputShape = null)\n\n\n\n\nPython:\n\n\nPower(power, scale=1, shift=0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npower\n: The exponent\n\n\nscale\n: The scale parameter. Default is 1.\n\n\nshift\n: The shift parameter. Default is 0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Power\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Power[Float](2, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.24691099      0.7588585       0.5785183\n0.10356348      0.2252714       0.3129436\n\n(2,.,.) =\n0.6277785       0.75136995      0.044648796\n0.46396527      0.9793776       0.92727077\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.060965035     0.5758662       0.3346834\n0.010725395     0.050747205     0.0979337\n\n(2,.,.) =\n0.39410582      0.5645568       0.001993515\n0.21526377      0.95918053      0.8598311\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Power\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Power(2, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.5300817 , 0.18128031, 0.19534253],\n        [0.28380639, 0.78365165, 0.6893    ]],\n\n       [[0.05574091, 0.400077  , 0.77051193],\n        [0.033559  , 0.61051396, 0.13970227]]])\n\n\n\n\nOutput is\n\n\narray([[[0.2809866 , 0.03286255, 0.03815871],\n        [0.08054607, 0.61410993, 0.4751345 ]],\n\n       [[0.00310705, 0.16006161, 0.5936886 ],\n        [0.00112621, 0.37272733, 0.01951673]]], dtype=float32)\n\n\n\n\n\n\nAddConstant\n\n\nAdd a (non-learnable) scalar constant to the input.\n\n\nAddConstant(constant, inputShape = null)\n\n\n\n\nPython:\n\n\nAddConstant(constant, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nconstant\n: The scalar constant to be added.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AddConstant[Float](1, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5658301       0.3508225       0.4012322\n0.1941942       0.18934165      0.6909284\n\n(2,.,.) =\n0.5985211       0.5485885       0.778548\n0.16745302      0.10363362      0.92185616\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5658301       1.3508224       1.4012322\n1.1941942       1.1893417       1.6909285\n\n(2,.,.) =\n1.5985211       1.5485885       1.778548\n1.167453        1.1036336       1.9218562\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import AddConstant\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(AddConstant(1, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.71730919, 0.07752598, 0.10448237],\n        [0.52319608, 0.38668494, 0.19588814]],\n\n       [[0.15496092, 0.48405899, 0.41441248],\n        [0.13792111, 0.7523953 , 0.55991187]]])\n\n\n\n\nOutput is\n\n\narray([[[1.7173092, 1.077526 , 1.1044824],\n        [1.5231961, 1.3866849, 1.1958882]],\n\n       [[1.1549609, 1.484059 , 1.4144125],\n        [1.1379211, 1.7523953, 1.5599118]]], dtype=float32)\n\n\n\n\n\n\nNarrow\n\n\nNarrow the input with the number of dimensions not being reduced.\n\n\nThe batch dimension needs to be unchanged.\n\n\nFor example, if input is:\n\n\n[[1 2 3],\n [4 5 6]]\n\n\nNarrow(1, 1, 2) will give output\n\n\n[[2 3],\n [5 6]]\n\n\nNarrow(1, 2, -1) will give output\n\n\n[3,\n 6]\n\n\nNarrow(dim, offset, length = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nNarrow(dim, offset, length=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndim\n: The dimension to narrow. 0-based index. Cannot narrow the batch dimension. \n         -1 means the last dimension of the input.\n\n\noffset\n: Non-negative integer. The start index on the given dimension. 0-based index.\n\n\nlength\n: The length to narrow. Default is 1.\n            Can use a negative length such as -1 in the case where input size is unknown.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.13770224      0.63719153      0.7776689       0.46612367\n0.9026256       0.11982094      0.8282868       0.05095969\n0.889799        0.6386537       0.35438475      0.298043\n\n(1,2,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.63957494      0.1921936       0.7749439       0.19744827\n0.91683346      0.16140814      0.9753973       0.8161283\n0.8481694       0.8802563       0.1233245       0.5732614\n\n(2,2,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Narrow\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Narrow(1, 1, input_shape=(2, 3, 4)))\ninput = np.random.rand(2, 2, 3, 4)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923],\n         [0.28316902, 0.3004414 , 0.40298034, 0.37476436],\n         [0.18825825, 0.38979411, 0.32963262, 0.37783457]],\n\n        [[0.14824117, 0.43532988, 0.57077087, 0.91535978],\n         [0.46375725, 0.90511296, 0.18859044, 0.92820822],\n         [0.13675737, 0.48270908, 0.04260755, 0.97255687]]],\n       [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529],\n         [0.07472717, 0.5715716 , 0.57029986, 0.26475783],\n         [0.56757079, 0.27602746, 0.45799196, 0.74420842]],\n\n        [[0.89048761, 0.08280716, 0.99030481, 0.35956427],\n         [0.70802689, 0.14425212, 0.08320864, 0.82271697],\n         [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ],\n         [0.46375725, 0.905113  , 0.18859044, 0.92820823],\n         [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]],\n\n       [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427],\n         [0.7080269 , 0.14425212, 0.08320864, 0.82271695],\n         [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]],\n      dtype=float32)\n\n\n\n\n\n\nPermute\n\n\nPermutes the dimensions of the input according to a given pattern.\n\n\nUseful for connecting RNNs and convnets together.\n\n\nPermute(dims, inputShape = null)\n\n\n\n\nPython:\n\n\nPermute(dims, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndims\n: Int array. Permutation pattern, does not include the batch dimension.\n          Indexing starts at 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Permute\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.31086245      0.21210302      0.35112163\n\n(1,2,.,.) =\n0.61466074      0.50173014      0.8759959\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.24063066      0.502274        0.9114748\n(2,2,.,.) =\n0.93335986      0.25173688      0.88615775\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.61466074      0.50173014      0.8759959\n\n(1,2,.,.) =\n0.31086245      0.21210302      0.35112163\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.93335986      0.25173688      0.88615775\n(2,2,.,.) =\n0.24063066      0.502274        0.9114748\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Permute\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Permute((2, 1, 3), input_shape=(2, 2, 3)))\ninput = np.random.rand(2, 2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.14016896, 0.7275626 , 0.79087092],\n         [0.57259566, 0.97387138, 0.70001999]],\n\n        [[0.9232002 , 0.07644555, 0.24705828],\n         [0.17257354, 0.93951155, 0.46183983]]],\n       [[[0.79432476, 0.64299062, 0.33959594],\n         [0.58608318, 0.338014  , 0.92602687]],\n\n        [[0.32638575, 0.69032582, 0.25168083],\n         [0.46813027, 0.95118373, 0.13145026]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.14016896, 0.7275626 , 0.7908709 ],\n         [0.9232002 , 0.07644555, 0.24705827]],\n\n        [[0.57259566, 0.97387135, 0.70002   ],\n         [0.17257354, 0.93951154, 0.46183982]]],\n       [[[0.79432476, 0.64299065, 0.33959594],\n         [0.32638577, 0.6903258 , 0.25168082]],\n        [[0.5860832 , 0.338014  , 0.9260269 ],\n         [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32)\n\n\n\n\n\n\nResizeBilinear\n\n\nResize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout.\n\n\nResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nResizeBilinear(output_height, output_width, align_corner=False, dim_ordering=\"th\", input_shape=(2, 3, 5, 7), name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputHeight\n: output height\n\n\noutputWidth\n: output width\n\n\nalignCorners\n: align corner or not\n\n\ndimOrdering\n: Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential()\nmodel.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5)))\nval input = Tensor[Float](2, 2, 3, 5).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.6991891       0.007127314     0.73871046      0.95916307      0.9433856\n0.41275907      0.37573513      0.99193203      0.06930728      0.5922364\n0.024281504     0.2592453       0.3898136       0.6635241       0.85888565\n\n(1,2,.,.) =\n0.38028112      0.43709648      0.62538666      0.8468501       0.6445014\n0.45252413      0.48801896      0.59471387      0.013207023     0.3567462\n0.85187584      0.49279585      0.7973665       0.81287366      0.07852263\n\n(2,1,.,.) =\n0.1452374       0.6140467       0.36384684      0.066476084     0.96101314\n0.54862195      0.66091377      0.86857307      0.6844842       0.7368217\n0.25342992      0.71737933      0.12789607      0.21691357      0.7543404\n\n(2,2,.,.) =\n0.79176855      0.1204049       0.58971256      0.115073755     0.10459962\n0.5225398       0.742363        0.7612815       0.9881919       0.13359445\n0.9026869       0.13972941      0.92064524      0.9435532       0.5502235\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of...\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.6991891       0.4948494       0.9539039\n0.21852028      0.5664119       0.48613077\n\n(1,2,.,.) =\n0.38028112      0.56262326      0.7794005\n0.6522  0.6274959       0.34790504\n\n(2,1,.,.) =\n0.1452374       0.4472468       0.36465502\n0.40102595      0.5618719       0.54899293\n\n(2,2,.,.) =\n0.79176855      0.43327665      0.111582376\n0.71261334      0.70765764      0.75788474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import ResizeBilinear\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5)))\ninput = np.random.rand(2, 2, 3, 5, 5)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189],\n         [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155],\n         [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]],\n\n        [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775],\n         [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264],\n         [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]],\n\n\n       [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452],\n         [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ],\n         [0.608378  , 0.10531177, 0.78000335, 0.51679768, 0.65067605]],\n\n        [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255],\n         [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493],\n         [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.43790358, 0.61913717, 0.2543214 ],\n         [0.6172875 , 0.52657175, 0.3151154 ]],\n\n        [[0.329656  , 0.13861606, 0.20514478],\n         [0.46164483, 0.541788  , 0.5311798 ]]],\n\n\n       [[[0.09462238, 0.57138187, 0.8545758 ],\n         [0.7116966 , 0.5389645 , 0.48184   ]],\n\n        [[0.12074634, 0.6571231 , 0.752728  ],\n         [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)",
            "title": "Core Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#masking",
            "text": "Use a mask value to skip timesteps for a sequence.  Scala:  Masking(maskValue = 0.0, inputShape = null)  Python:  Masking(mask_value=0.0, input_shape=None, name=None)  Parameters:   maskValue : Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Masking\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.31542103 0.20640659 0.22282763]\n [0.99352167 0.90135718 0.24504717]]  Output is  [[0.31542102 0.2064066  0.22282763]\n [0.9935217  0.9013572  0.24504717]]",
            "title": "Masking"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#sparsedense",
            "text": "SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:\nfirstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward\ngradient to next layer in the backpropagation by default, as the gradInput of SparseDense is\nuseless and very big in most cases.  But, considering model like Wide&Deep, we provide backwardStart and backwardLength to backward\npart of the gradient to next layer.  The most common input is 2D.  Scala:  SparseDense(outputDim, init = \"glorot_uniform\", activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null)  Python:  SparseDense(output_dim, init=\"glorot_uniform\", activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None)  Parameters:   outputDim : The size of the output dimension.  init : String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. Default is null.  wRegularizer : An instance of [Regularizer], applied to the input weights matrices. Default is null.  bRegularizer : An instance of [Regularizer], applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  backwardStart : Backward start index, counting from 1.  backwardLength : Backward length.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4))\nlayer.build(Shape(-1, 2, 4))\nval input = Tensor[Float](Array(2, 4)).rand()\ninput.setValue(1, 1, 1f)\ninput.setValue(2, 3, 3f)\nval sparseInput = Tensor.sparse(input)\nval output = layer.forward(sparseInput)  Input is:  input: \n(0, 0) : 1.0\n(0, 1) : 0.2992794\n(0, 2) : 0.11227019\n(0, 3) : 0.722947\n(1, 0) : 0.6147614\n(1, 1) : 0.4288646\n(1, 2) : 3.0\n(1, 3) : 0.7749917\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]  Output is:  output: \n0.053516    0.33429605  0.22587383  -0.8998945  0.24308181  \n0.76745665  -1.614114   0.5381658   -2.2226436  -0.15573677 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseDense\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseDense(output_dim=2, input_shape=(3, 4)))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)  Input is:  JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float  Output is  [[ 1.57136     2.29596   ]\n [ 0.5791738  -1.6598101 ]\n [ 2.331141   -0.84687066]]\n ```\n\n## **SoftShrink**\nApplies the soft shrinkage function element-wise to the input.\n\nWhen you use this layer as the first layer of a model, you need to provide\nthe argument inputShape (a Single Shape, does not include the batch dimension).\n\nRemark: This layer is from Torch and wrapped in Keras style.\n\n\n**Scala:**\n```scala\nSoftShrink(value = 0.5, inputShape = null)  Python:  SoftShrink(value = 0.5, input_shape=None, name=None)  Parameters:   value : value The threshold value. Default is 0.5.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.36938807 0.023556225 -1.1655436  -0.34449077\n0.9444338   -0.086538695    -1.0425501  1.364976\n-1.2563878  -0.1842559  0.43428117  1.0756494\n\n(1,2,.,.) =\n-0.19888283 1.251872    0.114836805 -0.6208773\n0.0051822234    -0.8998633  0.06937465  -0.3929931\n-0.1058129  0.6945743   -0.40083578 -0.6252444\n\n(2,1,.,.) =\n-0.9899709  -0.77926594 -0.15497442 -0.15031165\n-0.6028622  0.86623466  -2.1543107  0.41970536\n-0.8215522  0.3014275   -0.32184362 0.14445356\n\n(2,2,.,.) =\n0.74701905  0.10044397  -0.40519297 0.03822808\n0.30726334  0.27862388  1.731753    0.032177072\n-1.3476961  -0.2294767  0.99794704  0.7398458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0 0.0 -0.56554353 0.0\n0.34443378  0.0 -0.44255006 0.764976\n-0.6563878  0.0 0.0 0.47564936\n\n(1,2,.,.) =\n0.0 0.6518719   0.0 -0.020877302\n0.0 -0.29986328 0.0 0.0\n0.0 0.09457427  0.0 -0.025244355\n\n(2,1,.,.) =\n-0.3899709  -0.17926592 0.0 0.0\n-0.0028621554   0.26623464  -1.5543107  0.0\n-0.2215522  0.0 0.0 0.0\n\n(2,2,.,.) =\n0.14701903  0.0 0.0 0.0\n0.0 0.0 1.131753    0.0\n-0.74769604 0.0 0.397947    0.13984579\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SoftShrink\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SoftShrink(0.6, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[ 0.43421006,  0.28394451,  0.15221226,  0.47268966],\n         [ 0.22426224,  0.24855662,  0.790498  ,  0.67767582],\n         [ 0.14879562,  0.56077882,  0.61470262,  0.94875862]],\n\n        [[ 0.72404932,  0.89780875,  0.08456734,  0.01303937],\n         [ 0.25023568,  0.45392504,  0.587254  ,  0.51164461],\n         [ 0.12277567,  0.05571182,  0.17076456,  0.71660884]]],\n\n\n       [[[ 0.06369975,  0.85395557,  0.35752425,  0.606633  ],\n         [ 0.67640252,  0.86861737,  0.18040722,  0.55467108],\n         [ 0.24102058,  0.37580645,  0.81601612,  0.56513788]],\n\n        [[ 0.8461435 ,  0.65668365,  0.17969807,  0.51602926],\n         [ 0.86191073,  0.34245714,  0.62795207,  0.36706125],\n         [ 0.80344028,  0.81056003,  0.80959083,  0.15366483]]]])  Output is  array([[[[ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.19049799,  0.07767582],\n         [ 0.        ,  0.        ,  0.01470262,  0.34875858]],\n\n        [[ 0.12404931,  0.29780871,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.1166088 ]]],\n\n\n       [[[ 0.        ,  0.25395554,  0.        ,  0.00663298],\n         [ 0.07640249,  0.26861733,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.21601611,  0.        ]],\n\n        [[ 0.24614346,  0.05668366,  0.        ,  0.        ],\n         [ 0.26191074,  0.        ,  0.02795208,  0.        ],\n         [ 0.20344025,  0.21056002,  0.20959079,  0.        ]]]], dtype=float32)\n\n ```\n\n---\n## **Reshape**\nReshapes an output to a certain shape.\n\nSupports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).\n\n**Scala:**\n```scala\nReshape(targetShape, inputShape = null)  Python:  Reshape(target_shape, input_shape=None, name=None)  Parameters:   targetShape : The target shape that you desire to have. Batch dimension should be excluded.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Reshape\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]  Output is  [[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]",
            "title": "SparseDense"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#merge",
            "text": "Used to merge a list of inputs into a single output, following some merge mode.  Merge must have at least two input layers.  Scala:  Merge(layers = null, mode = \"sum\", concatAxis = -1, inputShape = null)  Python:  Merge(layers=None, mode=\"sum\", concat_axis=-1, input_shape=None, name=None)  Parameters:   layers : A list of layer instances. Must be more than one layer.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode = \"sum\")\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -> input1, 2 -> input2)\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Merge, InputLayer\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)  Input is:  [[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n   [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n   [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n  [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n   [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n   [0.56138318, 0.68165639, 0.10644523, 0.51860127]]],\n\n [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n   [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n   [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n  [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n   [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n   [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]]  Output is  [[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]",
            "title": "Merge"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#maxoutdense",
            "text": "A dense maxout layer that takes the element-wise maximum of linear layers.  This allows the layer to learn a convex, piecewise linear activation function over the inputs.  The input of this layer should be 2D.  Scala:  MaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  MaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of output dimension.  nbFeature : Number of Dense layers to use internally. Integer. Default is 4.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxoutDense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]  Output is  [[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]",
            "title": "MaxoutDense"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#squeeze",
            "text": "Delete the singleton dimension(s). The batch dimension needs to be unchanged.  For example, if input has size (2, 1, 3, 4, 1):  Squeeze(1) will give output size (2, 3, 4, 1),  Squeeze() will give output size (2, 3, 4)  Scala:  Squeeze(dims = null, inputShape = null)  Python:  Squeeze(dim=None, input_shape=None, name=None)  Parameters:   dims : The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32)))\nval input = Tensor[Float](1, 1, 1, 32).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Squeeze\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Squeeze(1, input_shape=(1, 1, 32)))\ninput = np.random.random([1, 1, 1, 32])\noutput = model.forward(input)  Input is:  [[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281,\n    0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763,\n    0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269,\n    0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821,\n    0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 ,\n    0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729,\n    0.89774196, 0.77838838]]]]  Output is  [[[0.20585343, 0.470117  , 0.14553176, 0.939156  , 0.5723428 ,\n   0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763,\n   0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 ,\n   0.48919672, 0.284064  , 0.20962799, 0.8807176 , 0.45501822,\n   0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 ,\n   0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 ,\n   0.897742  , 0.7783884 ]]]",
            "title": "Squeeze"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#binarythreshold",
            "text": "Threshold the input.  If an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1.  Scala:  BinaryThreshold(value = 1e-6, inputShape = null)  Python:  BinaryThreshold(value=1e-6, input_shape=None, name=None)  Parameters:   value : The threshold value to compare with. Default is 1e-6.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1907398      -0.18995096     -2.0344417      -1.3789974\n-1.8801064      -0.74757665     -0.4339697      0.0058485097\n0.7012256       -0.6363152      2.0156987       -0.5512639\n\n(1,2,.,.) =\n-0.5251603      0.082127444     0.29550993      1.6357868\n-1.3828015      -0.11842779     0.3316966       -0.14360528\n0.21216457      -0.117370956    -0.12934707     -0.35854268\n\n(2,1,.,.) =\n-0.9071151      -2.8566089      -0.4796377      -0.915065\n-0.8439908      -0.25404388     -0.39926198     -0.15191565\n-1.0496653      -0.403675       -1.3591816      0.5311797\n\n(2,2,.,.) =\n0.53509855      -0.08892822     1.2196561       -0.62759316\n-0.47476718     -0.43337926     -0.10406987     1.4035174\n-1.7120812      1.1328355       0.9219375       1.3813454\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n1.0     0.0     1.0     0.0\n\n(1,2,.,.) =\n0.0     1.0     1.0     1.0\n0.0     0.0     1.0     0.0\n1.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n\n(2,2,.,.) =\n1.0     0.0     1.0     0.0\n0.0     0.0     0.0     1.0\n0.0     1.0     1.0     1.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import BinaryThreshold\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(BinaryThreshold(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767],\n         [0.72650405, 0.53096719, 0.66346109, 0.0589329 ],\n         [0.12994731, 0.92181174, 0.43129874, 0.97306968]],\n\n        [[0.3031087 , 0.20339982, 0.69034712, 0.40191   ],\n         [0.57517034, 0.30159448, 0.4801747 , 0.75175084],\n         [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]],\n\n\n       [[[0.46102959, 0.33029002, 0.69340103, 0.32885719],\n         [0.84405147, 0.03421879, 0.68242578, 0.03560338],\n         [0.12244515, 0.3610654 , 0.01312785, 0.84485178]],\n\n        [[0.73472287, 0.75707757, 0.77070527, 0.40863145],\n         [0.01137898, 0.82896826, 0.1498069 , 0.22309423],\n         [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]])  Output is  array([[[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]],\n\n\n       [[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]]], dtype=float32)",
            "title": "BinaryThreshold"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#sqrt",
            "text": "Applies an element-wise square root operation to the input.  Scala:  Sqrt(inputShape = null)  Python:  Sqrt(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Sqrt[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6950394       0.5234307       1.7375475\n0.25833175      0.02685826      -0.6046901\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8336902       0.7234851       1.3181607\n0.50826347      0.16388491      NaN\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Sqrt\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Sqrt(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.2484558 , 0.65280218, 0.35286984],\n [0.19616094, 0.30966802, 0.82148169]]  Output is  [[0.4984534 , 0.80796176, 0.5940285 ],\n [0.4429006 , 0.55647826, 0.9063563 ]]",
            "title": "Sqrt"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#mul",
            "text": "Multiply a single scalar factor to the incoming data  Scala:  Mul(inputShape = null)  Python:  Mul(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Mul\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Mul[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2316265  -2.008802 -1.3908259  -0.61135375\n-0.48992255 0.1786112 0.18872596  0.49621895\n-0.6931602  -0.919745 -0.09019699 -0.41218707\n\n(2,.,.) =\n-0.3135355  -0.4385771  -0.3317269  1.0412029\n-0.8859662  0.17758773  -0.73779273 -0.4445366\n0.3921595 1.6923207 0.014470488 0.4044164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.59036994 -0.9629025  -0.6666808  -0.29304734\n-0.2348403  0.0856158 0.09046422  0.23785843\n-0.33226058 -0.44087213 -0.043235175  -0.19757845\n\n(2,.,.) =\n-0.15029064 -0.21022828 -0.15901053 0.49909195\n-0.42468053 0.0851252 -0.3536548  -0.21308492\n0.18797839  0.81119984  0.006936308 0.19385365\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Mul\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Mul(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.22607292,  0.59806062,  0.19428923,  0.22928606],\n        [ 0.13804536,  0.1615547 ,  0.52824658,  0.52794904],\n        [ 0.4049169 ,  0.94109084,  0.58158453,  0.78368633]],\n\n       [[ 0.86233305,  0.47995805,  0.80430949,  0.9931171 ],\n        [ 0.35179631,  0.33615276,  0.87756877,  0.73560288],\n        [ 0.29775703,  0.11404466,  0.77695536,  0.97580018]]])  Output is  array([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998],\n        [-0.13730718, -0.1606908 , -0.52542186, -0.52512592],\n        [-0.40275168, -0.93605846, -0.57847458, -0.77949566]],\n\n       [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ],\n        [-0.34991512, -0.33435524, -0.87287611, -0.73166931],\n        [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32)",
            "title": "Mul"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#mulconstant",
            "text": "Multiply the input by a (non-learnable) scalar constant.  Scala:  MulConstant(constant, inputShape = null)  Python:  MulConstant(constant, input_shape=None, name=None)  Parameters:   constant : The scalar constant to be multiplied.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MulConstant[Float](2.2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.16873977     1.0812985       1.0942211       -0.67091423\n1.0086882       0.5915831       0.26184535      -1.361431\n1.5616825       -0.037591368    1.2794676       1.0692137\n\n(2,.,.) =\n0.29868057      -0.23266982     -0.7679556      -2.209848\n-0.13954644     -0.1368473      -0.54510623     1.8397199\n-0.58691734     -0.56410027     -1.5567777      0.050648995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.3712275      2.3788567       2.4072864       -1.4760114\n2.219114        1.3014828       0.57605976      -2.9951482\n3.4357016       -0.08270101     2.8148286       2.3522704\n\n(2,.,.) =\n0.6570973       -0.5118736      -1.6895024      -4.8616657\n-0.3070022      -0.30106407     -1.1992338      4.047384\n-1.2912182      -1.2410206      -3.424911       0.11142779\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MulConstant\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MulConstant(2.2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.39874191, 0.66634984, 0.23907766, 0.31587494],\n  [0.78842014, 0.93057835, 0.80739529, 0.71541279],\n  [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]],\n\n [[0.60142458, 0.41221671, 0.00890549, 0.32069845],\n  [0.51122554, 0.76280426, 0.87579418, 0.17182832],\n  [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]]  Output is  [[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ],\n  [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ],\n  [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]],\n\n [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ],\n  [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234],\n  [1.19093   , 0.43591645, 2.0356452 , 1.2356553 ]]]",
            "title": "MulConstant"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#scale",
            "text": "Scale is the combination of CMul and CAdd.  Computes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input.  Similarly, perform an expanded bias and perform an element-wise add.  Scala:  Scale(size, inputShape = null)  Python:  Scale(size, input_shape=None, name=None)  Parameters:   size : Size of the weight and bias.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Scale\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nvar array = Array(1, 2)\nmodel.add(Scale[Float](array, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006399727    -0.06412822     -0.2334789\n0.31029955      1.6557469       1.9614618\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.09936619      0.57585865      0.20324506\n0.38537437      -0.8598822      -1.0186496\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Scale\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Scale((2, 1), input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.7242994 , 0.77888884, 0.71470432],\n [0.03058471, 0.00602764, 0.57513629]]  Output is  [[1.0946966 , 1.1255064 , 1.0892813 ],\n [0.58151895, 0.5909191 , 0.37307182]]",
            "title": "Scale"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#log",
            "text": "Applies a log transformation to the input.  Scala:  Log(inputShape = null)  Python:  Log(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Log\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Log[Float](inputShape = Shape(2, 4, 4)))\nval input = Tensor[Float](1, 2, 4, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.38405678      -0.5502389      -0.383079       -0.988537\n-0.6294056      -0.7838047      0.8747865       -1.0659786\n-2.2445498      -0.5488076      -0.42898977     0.6916364\n1.6542299       -0.9966279      -0.38244298     1.6954672\n\n(1,2,.,.) =\n0.43478605      -0.6678534      1.9530942       -0.5209587\n0.12899925      0.20572199      2.0359943       0.55223215\n0.65247816      0.8792108       -0.38860792     0.48663738\n-1.0084358      0.31141177      0.69208467      0.48385203\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.95696485     NaN     NaN     NaN\nNaN     NaN     -0.13377543     NaN\nNaN     NaN     NaN     -0.36869493\n0.5033356       NaN     NaN     0.5279584\n\n(1,2,.,.) =\n-0.83290124     NaN     0.6694149       NaN\n-2.0479486      -1.5812296      0.7109843       -0.5937868\n-0.4269776      -0.12873057     NaN     -0.720236\nNaN     -1.1666392      -0.36804697     -0.72597617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Log\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Log(input_shape=(2, 4, 4)))\ninput = np.random.random([1, 2, 4, 4])\noutput = model.forward(input)  Input is:  [[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453],\n   [0.46529477, 0.81511804, 0.24435558, 0.45003562],\n   [0.15170845, 0.35157662, 0.0925214 , 0.63852947],\n   [0.27817508, 0.42572846, 0.44363004, 0.03536394]],\n\n  [[0.65027784, 0.00429838, 0.07434429, 0.18653305],\n   [0.19659183, 0.66647529, 0.77821197, 0.65894478],\n   [0.28212032, 0.52307663, 0.09589939, 0.71547588],\n   [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]]  Output is  [[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032],\n   [-0.76508415, -0.20442237, -1.4091308 , -0.79842854],\n   [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742],\n   [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]],\n\n  [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ],\n   [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554],\n   [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743],\n   [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]]",
            "title": "Log"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#identity",
            "text": "Identity just return the input to output.  It's useful in same parallel container to get an origin input.  Scala:  Identity(inputShape = null)  Python:  Identity(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Identity\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Identity[Float](inputShape = Shape(4, 4)))\nval input = Tensor[Float](3, 4, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Identity\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Identity(input_shape=(4, 4)))\ninput = np.random.random([3, 4, 4])\noutput = model.forward(input)  Input is:  [[[0.36751123, 0.92287101, 0.73894405, 0.33699379],\n  [0.69405782, 0.9653215 , 0.2617223 , 0.68205229],\n  [0.71455325, 0.99419333, 0.90886495, 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921154, 0.26803146]],\n\n  [[0.35898357, 0.72067882, 0.13236563, 0.71935521],\n   [0.30865626, 0.71098844, 0.86718946, 0.12531168],\n   [0.84916882, 0.84221518, 0.52186664, 0.87239729],\n   [0.50637899, 0.10890469, 0.86832705, 0.93581179]],\n\n  [[0.19640105, 0.09341008, 0.12043328, 0.09261859],\n   [0.66019486, 0.07251262, 0.80929761, 0.39094486],\n   [0.63027391, 0.39537796, 0.55578905, 0.53933265],\n   [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]]  Output is  [[[0.36751124, 0.922871  , 0.73894405, 0.33699378],\n  [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ],\n  [0.71455324, 0.9941933 , 0.908865  , 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921156, 0.26803148]],\n\n [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ],\n  [0.30865628, 0.71098846, 0.86718947, 0.12531169],\n  [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ],\n  [0.506379  , 0.10890469, 0.868327  , 0.9358118 ]],\n\n [[0.19640104, 0.09341008, 0.12043328, 0.09261858],\n  [0.6601949 , 0.07251262, 0.8092976 , 0.39094487],\n  [0.63027394, 0.39537796, 0.55578905, 0.5393326 ],\n  [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]]",
            "title": "Identity"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#select",
            "text": "Select an index of the input in the given dim and return the subset part.  The batch dimension needs to be unchanged.  For example, if input is:  [[1, 2, 3], \n [4, 5, 6]]  Select(1, 1) will give output [2 5]  Select(1, -1) will give output [3 6]  Scala:  Select(dim, index, inputShape = null)  Python:  Select(dim, index, input_shape=None, name=None)  Parameters:   dim : The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input.  index : The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Select\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3)))\nval input = Tensor[Float](1, 3, 1, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.67646945     -0.5485965      -0.11103154\n(1,2,.,.) =\n-0.13488655     0.43843046      -0.04482145\n(1,3,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3]  Python example:  from zoo.pipeline.api.keras.layers import Select\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Select(1, 2, input_shape=(3, 1, 3)))\ninput = np.random.random([1, 3, 1, 3])\noutput = model.forward(input)  Input is:  array([[[[0.53306099, 0.95147881, 0.15222129]],\n        [[0.89604861, 0.90160974, 0.5230576 ]],\n        [[0.70779386, 0.14438568, 0.37601195]]]])  Output is:  array([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32)",
            "title": "Select"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#dense",
            "text": "A densely-connected NN layer.  The most common input is 2D.  Scala:  Dense(outputDim, init = \"glorot_uniform\", activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Dense(output_dim, init=\"glorot_uniform\", activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of the output dimension.  init : Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method.  activation : Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method.  wRegularizer : An instance of  Regularizer , applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](5, activation = \"relu\", inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4289935       -1.7659454      -0.08306135     -1.0153456\n1.0191492       0.37392816      1.3076705       -0.19495767\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5421522       0.49008092      0.0     0.0     0.0\n0.07940009      0.0     0.12953377      0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Dense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(5, activation=\"relu\", input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)  Input is:  array([[0.64593485, 0.67393322, 0.72505368, 0.04654095],\n       [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]])  Output is  array([[0.        , 0.        , 1.2698183 , 0.        , 0.10656227],\n       [0.        , 0.        , 0.6236721 , 0.00299606, 0.29664695]],\n      dtype=float32)",
            "title": "Dense"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#negative",
            "text": "Computes the negative value of each element of the input.  Scala:  Negative(inputShape = null)  Python:  Negative(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Negative\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Negative[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.031705        -0.5723963      1.998631\n-0.32908052     2.4069138       -2.4111257\n(2,.,.) =\n0.5355049       -1.4404331      -0.38116863\n-0.45641592     -1.1485358      0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.031705       0.5723963       -1.998631\n0.32908052      -2.4069138      2.4111257\n(2,.,.) =\n-0.5355049      1.4404331       0.38116863\n0.45641592      1.1485358       -0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Negative\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Negative(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.39261261, 0.03164615, 0.32179116],\n        [0.11969367, 0.61610712, 0.42573733]],\n       [[0.36794656, 0.90912174, 0.540356  ],\n        [0.42667627, 0.04154093, 0.84692964]]])  Output is  array([[[-0.3926126 , -0.03164615, -0.32179114],\n        [-0.11969367, -0.6161071 , -0.42573732]],\n       [[-0.36794657, -0.90912175, -0.540356  ],\n        [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32)",
            "title": "Negative"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#cadd",
            "text": "This layer has a bias with given size.  The bias will be added element-wise to the input.  If the element number of the bias matches the input, a simple element-wise addition will be done.  Or the bias will be expanded to the same size of the input.  The expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised).  Scala:  CAdd(size, bRegularizer = null, inputShape = null)  Python:  CAdd(size, b_regularizer=None, input_shape=None, name=None)  Parameters:   size : the size of the bias  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.2183351       0.32434112      0.89350265\n0.3348259       0.78677046      0.24054797\n(2,.,.) =\n0.9945844       0.72363794      0.7737936\n0.05522544      0.3517818       0.7417069\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1358028       0.6956667       1.0837181\n0.6767027       0.7955346       0.5063505\n(2,.,.) =\n0.9120521       1.0949634       0.96400905\n0.3971022       0.36054593      1.0075095\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import CAdd\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(CAdd([2, 1], input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.4122004 , 0.73289359, 0.11500016],\n        [0.26974491, 0.32166632, 0.91408442]],\n       [[0.66824327, 0.80271314, 0.75981145],\n        [0.39271431, 0.07312566, 0.4966805 ]]])  Output is  array([[[ 0.06560206,  0.38629526, -0.23159817],\n        [ 0.44287407,  0.4947955 ,  1.0872136 ]],\n       [[ 0.32164496,  0.45611483,  0.41321313],\n        [ 0.56584346,  0.24625483,  0.6698097 ]]], dtype=float32)",
            "title": "CAdd"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#repeatvector",
            "text": "Repeats the input n times.  The input of this layer should be 2D, i.e. (num_samples, features).\nThe output of thi layer should be 3D, i.e. (num_samples, n, features).  Scala:  RepeatVector(n, inputShape = null)  Python:  RepeatVector(n, input_shape=None, name=None)  Parameters:   n : Repetition factor. Integer.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector[Float](4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.31839952 -0.3495366  0.542486\n-0.54981124 -0.8428188  0.8225184\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n\n(2,.,.) =\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import RepeatVector\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  array([[ 0.90715922,  0.54594769,  0.53952404],\n       [ 0.08989831,  0.07265549,  0.45830114]])  Output is  array([[[ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402]],\n\n       [[ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116]]], dtype=float32)",
            "title": "RepeatVector"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#gaussiansampler",
            "text": "Takes {mean, log_variance} as input and samples from the Gaussian distribution.  Scala:  GaussianSampler(inputShape = null)  Python:  GaussianSampler(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler\nimport com.intel.analytics.bigdl.utils.{Shape, MultiShape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval shape1 = Shape(2, 3)\nval shape2 = Shape(2, 3)\nmodel.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2))))\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -> input1, 2 -> input2)\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.utils.Table =\n {\n        2: (1,.,.) =\n           0.9996127    0.8964211       0.7424038\n           0.40628982   0.37035564      0.20108517\n\n           (2,.,.) =\n           0.6974727    0.60202897      0.1535999\n           0.012422224  0.5993025       0.96206\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n        1: (1,.,.) =\n           0.21060324   0.576583        0.21633287\n           0.1484059    0.2730577       0.25317845\n\n           (2,.,.) =\n           0.58513683   0.58095694      0.18811373\n           0.7029449    0.41235915      0.44636542\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5258198       1.9536011       -1.8591263\n-1.0618867      -0.751225       0.35412917\n\n(2,.,.) =\n1.3334517       -0.60312974     0.7324476\n0.09502721      0.8094909       0.44807082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GaussianSampler\n\nmodel = Sequential()\nmodel.add(GaussianSampler(input_shape=[(3,),(3,)]))\ninput1 = np.random.random([2, 3])\ninput2 = np.random.random([2, 3])\ninput = [input1, input2]\noutput = model.forward(input)  Input is:  [[[0.79941342, 0.87462822, 0.9516901 ],\n  [0.20111287, 0.54634077, 0.83614511]], \n\n [[0.31886989, 0.22829382, 0.84355419],\n  [0.51186641, 0.28043938, 0.29440057]]]  Output is  [[ 0.71405387  2.2944303  -0.41778684]\n [ 0.84234     2.3337283  -0.18952972]]",
            "title": "GaussianSampler"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#exp",
            "text": "Applies element-wise exp to the input.  When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).  Scala:  Exp(inputShape = null)  Python:  Exp(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Exp\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Exp[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.5841372      -0.13795324     -2.144475       0.09272669\n1.055668        -1.2310301      1.2145554       -0.6073714\n0.9296467       0.2923885       1.3364213       0.1652137\n\n(1,2,.,.) =\n0.2099718       -0.3856573      -0.92586        -0.5317779\n0.6618383       -0.9677452      -1.5014665      -0.35464883\n2.045924        -0.317644       -1.812726       0.95438373\n\n(2,1,.,.) =\n-0.4536791      -0.34785584     1.6424289       -0.07981159\n-0.8022624      -0.4211059      0.3461831       1.9598864\n-0.84695745     -0.6115283      0.7729755       2.3077402\n\n(2,2,.,.) =\n-0.08438411     -0.908458       0.6688936       -0.7292123\n-0.26337254     0.55425745      -0.14925817     -0.010179609\n-0.62562865     -1.0517743      -0.23839666     -1.144982\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.20512469      0.8711394       0.11712951      1.0971619\n2.8738942       0.29199165      3.3687959       0.544781\n2.533614        1.3396233       3.8054006       1.1796452\n\n(1,2,.,.) =\n1.2336433       0.6800035       0.39619055      0.5875594\n1.9383523       0.37993878      0.22280318      0.7014197\n7.7363033       0.7278619       0.16320862      2.5970695\n\n(2,1,.,.) =\n0.63528657      0.70620066      5.167706        0.92329025\n0.44831353      0.6563206       1.4136615       7.0985208\n0.42871734      0.5425211       2.1662023       10.051684\n\n(2,2,.,.) =\n0.9190782       0.4031454       1.9520763       0.48228875\n0.76845556      1.740648        0.8613467       0.98987204\n0.53492504      0.34931743      0.7878901       0.31822965\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Exp\n\nmodel = Sequential()\nmodel.add(Exp(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.93104587 0.94000338 0.84870765 0.98645553]\n   [0.83708846 0.33375541 0.50119834 0.24879265]\n   [0.51966475 0.84514791 0.15496452 0.61538968]]\n\n  [[0.57250337 0.42520832 0.94850757 0.54317573]\n   [0.64228691 0.9904079  0.01008592 0.51365217]\n   [0.78640595 0.7717037  0.51277595 0.24245034]]]\n\n\n [[[0.82184752 0.92537331 0.20632728 0.47539445]\n   [0.44604637 0.1507692  0.5437313  0.2074501 ]\n   [0.93661363 0.93962609 0.29230559 0.74850958]]\n\n  [[0.11659768 0.76177132 0.33194573 0.20695088]\n   [0.49636212 0.85987328 0.49767861 0.96774006]\n   [0.67669121 0.15542122 0.69981032 0.3349874 ]]]]  Output is  [[[[2.5371614 2.5599902 2.3366253 2.6817122]\n   [2.3096325 1.3962016 1.6506982 1.2824761]\n   [1.6814638 2.3283222 1.1676165 1.8503776]]\n\n  [[1.7726992 1.5299091 2.5818534 1.721465 ]\n   [1.9008229 2.6923325 1.010137  1.6713842]\n   [2.1954916 2.163449  1.6699204 1.2743679]]]\n\n\n [[[2.2746985 2.52281   1.2291554 1.6086487]\n   [1.5621239 1.1627283 1.7224218 1.2305363]\n   [2.551327  2.5590243 1.3395122 2.1138473]]\n\n  [[1.1236672 2.1420672 1.3936772 1.2299222]\n   [1.6427343 2.3628614 1.6448984 2.6319895]\n   [1.9673574 1.16815   2.0133708 1.3979228]]]]",
            "title": "Exp"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#square",
            "text": "Applies an element-wise square operation to the input.  When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).  Scala:  Square(inputShape = null)  Python:  Square(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Square\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Square[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.108013034    1.8879265       1.2232096       -1.5076439\n1.4895755       -0.37966672     -0.34892964     0.15224025\n-0.9296686      -1.1523775      0.14153497      -0.26954007\n\n(1,2,.,.) =\n-1.0875931      2.190617        -0.6903083      1.0039362\n-0.1275677      -1.1096588      0.37359753      -0.17367937\n0.23349741      0.14639114      -0.2330162      0.5343827\n\n(2,1,.,.) =\n0.3222191       0.21463287      -1.0157064      -0.22627507\n1.1714277       0.43371263      1.069315        0.5122436\n0.1958086       -1.4601041      2.5394423       -0.470833\n\n(2,2,.,.) =\n-0.38708544     -0.951611       -0.37234613     0.26813275\n1.9477026       0.32779223      -1.2308712      -2.2376378\n0.19652915      0.3304719       -1.7674786      -0.86961496\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.011666816     3.5642662       1.4962418       2.2729902\n2.218835        0.14414681      0.1217519       0.023177093\n0.86428374      1.3279738       0.020032147     0.07265185\n\n(1,2,.,.) =\n1.1828587       4.7988033       0.47652552      1.0078878\n0.016273517     1.2313428       0.13957511      0.030164523\n0.05452104      0.021430366     0.054296546     0.28556487\n\n(2,1,.,.) =\n0.10382515      0.046067268     1.0316595       0.05120041\n1.3722429       0.18810664      1.1434345       0.26239353\n0.038341008     2.131904        6.448767        0.22168371\n\n(2,2,.,.) =\n0.14983514      0.9055635       0.13864164      0.07189517\n3.7935455       0.10744774      1.5150439       5.007023\n0.038623706     0.109211676     3.1239805       0.7562302\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Square\n\nmodel = Sequential()\nmodel.add(Square(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.8708819  0.2698243  0.55854849 0.71699472]\n   [0.66647234 0.72310216 0.8082119  0.66566951]\n   [0.6714764  0.61394108 0.35063125 0.60473593]]\n\n  [[0.37993365 0.64222557 0.96762005 0.18931697]\n   [0.00529722 0.99133455 0.09786619 0.28988077]\n   [0.60052911 0.83712995 0.59847519 0.54361243]]]\n\n\n [[[0.32832672 0.83316023 0.41272485 0.01963383]\n   [0.89593955 0.73433713 0.67529323 0.69711912]\n   [0.81251711 0.56755577 0.31958151 0.09795917]]\n\n  [[0.46465895 0.22818875 0.31505317 0.41912166]\n   [0.87865447 0.3799063  0.091204   0.68144165]\n   [0.88274284 0.70479132 0.32074672 0.71771481]]]]  Output is  [[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01]\n   [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01]\n   [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]]\n\n  [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02]\n   [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02]\n   [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]]\n\n\n [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04]\n   [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01]\n   [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]]\n\n  [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01]\n   [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01]\n   [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]]",
            "title": "Square"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#power",
            "text": "Applies an element-wise power operation with scale and shift to the input.  f(x) = (shift + scale * x)^power^  Power(power, scale = 1, shift = 0, inputShape = null)  Python:  Power(power, scale=1, shift=0, input_shape=None, name=None)  Parameters:   power : The exponent  scale : The scale parameter. Default is 1.  shift : The shift parameter. Default is 0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Power\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Power[Float](2, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.24691099      0.7588585       0.5785183\n0.10356348      0.2252714       0.3129436\n\n(2,.,.) =\n0.6277785       0.75136995      0.044648796\n0.46396527      0.9793776       0.92727077\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.060965035     0.5758662       0.3346834\n0.010725395     0.050747205     0.0979337\n\n(2,.,.) =\n0.39410582      0.5645568       0.001993515\n0.21526377      0.95918053      0.8598311\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Power\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Power(2, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.5300817 , 0.18128031, 0.19534253],\n        [0.28380639, 0.78365165, 0.6893    ]],\n\n       [[0.05574091, 0.400077  , 0.77051193],\n        [0.033559  , 0.61051396, 0.13970227]]])  Output is  array([[[0.2809866 , 0.03286255, 0.03815871],\n        [0.08054607, 0.61410993, 0.4751345 ]],\n\n       [[0.00310705, 0.16006161, 0.5936886 ],\n        [0.00112621, 0.37272733, 0.01951673]]], dtype=float32)",
            "title": "Power"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#addconstant",
            "text": "Add a (non-learnable) scalar constant to the input.  AddConstant(constant, inputShape = null)  Python:  AddConstant(constant, input_shape=None, name=None)  Parameters:   constant : The scalar constant to be added.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AddConstant[Float](1, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5658301       0.3508225       0.4012322\n0.1941942       0.18934165      0.6909284\n\n(2,.,.) =\n0.5985211       0.5485885       0.778548\n0.16745302      0.10363362      0.92185616\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5658301       1.3508224       1.4012322\n1.1941942       1.1893417       1.6909285\n\n(2,.,.) =\n1.5985211       1.5485885       1.778548\n1.167453        1.1036336       1.9218562\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import AddConstant\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(AddConstant(1, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.71730919, 0.07752598, 0.10448237],\n        [0.52319608, 0.38668494, 0.19588814]],\n\n       [[0.15496092, 0.48405899, 0.41441248],\n        [0.13792111, 0.7523953 , 0.55991187]]])  Output is  array([[[1.7173092, 1.077526 , 1.1044824],\n        [1.5231961, 1.3866849, 1.1958882]],\n\n       [[1.1549609, 1.484059 , 1.4144125],\n        [1.1379211, 1.7523953, 1.5599118]]], dtype=float32)",
            "title": "AddConstant"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#narrow",
            "text": "Narrow the input with the number of dimensions not being reduced.  The batch dimension needs to be unchanged.  For example, if input is:  [[1 2 3],\n [4 5 6]]  Narrow(1, 1, 2) will give output  [[2 3],\n [5 6]]  Narrow(1, 2, -1) will give output  [3,\n 6]  Narrow(dim, offset, length = 1, inputShape = null)  Python:  Narrow(dim, offset, length=1, input_shape=None, name=None)  Parameters:   dim : The dimension to narrow. 0-based index. Cannot narrow the batch dimension. \n         -1 means the last dimension of the input.  offset : Non-negative integer. The start index on the given dimension. 0-based index.  length : The length to narrow. Default is 1.\n            Can use a negative length such as -1 in the case where input size is unknown.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.13770224      0.63719153      0.7776689       0.46612367\n0.9026256       0.11982094      0.8282868       0.05095969\n0.889799        0.6386537       0.35438475      0.298043\n\n(1,2,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.63957494      0.1921936       0.7749439       0.19744827\n0.91683346      0.16140814      0.9753973       0.8161283\n0.8481694       0.8802563       0.1233245       0.5732614\n\n(2,2,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4]  Python example:  from zoo.pipeline.api.keras.layers import Narrow\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Narrow(1, 1, input_shape=(2, 3, 4)))\ninput = np.random.rand(2, 2, 3, 4)\noutput = model.forward(input)  Input is:  array([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923],\n         [0.28316902, 0.3004414 , 0.40298034, 0.37476436],\n         [0.18825825, 0.38979411, 0.32963262, 0.37783457]],\n\n        [[0.14824117, 0.43532988, 0.57077087, 0.91535978],\n         [0.46375725, 0.90511296, 0.18859044, 0.92820822],\n         [0.13675737, 0.48270908, 0.04260755, 0.97255687]]],\n       [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529],\n         [0.07472717, 0.5715716 , 0.57029986, 0.26475783],\n         [0.56757079, 0.27602746, 0.45799196, 0.74420842]],\n\n        [[0.89048761, 0.08280716, 0.99030481, 0.35956427],\n         [0.70802689, 0.14425212, 0.08320864, 0.82271697],\n         [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]])  Output is  array([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ],\n         [0.46375725, 0.905113  , 0.18859044, 0.92820823],\n         [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]],\n\n       [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427],\n         [0.7080269 , 0.14425212, 0.08320864, 0.82271695],\n         [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]],\n      dtype=float32)",
            "title": "Narrow"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#permute",
            "text": "Permutes the dimensions of the input according to a given pattern.  Useful for connecting RNNs and convnets together.  Permute(dims, inputShape = null)  Python:  Permute(dims, input_shape=None, name=None)  Parameters:   dims : Int array. Permutation pattern, does not include the batch dimension.\n          Indexing starts at 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Permute\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.31086245      0.21210302      0.35112163\n\n(1,2,.,.) =\n0.61466074      0.50173014      0.8759959\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.24063066      0.502274        0.9114748\n(2,2,.,.) =\n0.93335986      0.25173688      0.88615775\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.61466074      0.50173014      0.8759959\n\n(1,2,.,.) =\n0.31086245      0.21210302      0.35112163\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.93335986      0.25173688      0.88615775\n(2,2,.,.) =\n0.24063066      0.502274        0.9114748\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Permute\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Permute((2, 1, 3), input_shape=(2, 2, 3)))\ninput = np.random.rand(2, 2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[[0.14016896, 0.7275626 , 0.79087092],\n         [0.57259566, 0.97387138, 0.70001999]],\n\n        [[0.9232002 , 0.07644555, 0.24705828],\n         [0.17257354, 0.93951155, 0.46183983]]],\n       [[[0.79432476, 0.64299062, 0.33959594],\n         [0.58608318, 0.338014  , 0.92602687]],\n\n        [[0.32638575, 0.69032582, 0.25168083],\n         [0.46813027, 0.95118373, 0.13145026]]]])  Output is  array([[[[0.14016896, 0.7275626 , 0.7908709 ],\n         [0.9232002 , 0.07644555, 0.24705827]],\n\n        [[0.57259566, 0.97387135, 0.70002   ],\n         [0.17257354, 0.93951154, 0.46183982]]],\n       [[[0.79432476, 0.64299065, 0.33959594],\n         [0.32638577, 0.6903258 , 0.25168082]],\n        [[0.5860832 , 0.338014  , 0.9260269 ],\n         [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32)",
            "title": "Permute"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#resizebilinear",
            "text": "Resize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout.  ResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering = \"th\", inputShape = null)  Python:  ResizeBilinear(output_height, output_width, align_corner=False, dim_ordering=\"th\", input_shape=(2, 3, 5, 7), name=None)  Parameters:   outputHeight : output height  outputWidth : output width  alignCorners : align corner or not  dimOrdering : Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential()\nmodel.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5)))\nval input = Tensor[Float](2, 2, 3, 5).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.6991891       0.007127314     0.73871046      0.95916307      0.9433856\n0.41275907      0.37573513      0.99193203      0.06930728      0.5922364\n0.024281504     0.2592453       0.3898136       0.6635241       0.85888565\n\n(1,2,.,.) =\n0.38028112      0.43709648      0.62538666      0.8468501       0.6445014\n0.45252413      0.48801896      0.59471387      0.013207023     0.3567462\n0.85187584      0.49279585      0.7973665       0.81287366      0.07852263\n\n(2,1,.,.) =\n0.1452374       0.6140467       0.36384684      0.066476084     0.96101314\n0.54862195      0.66091377      0.86857307      0.6844842       0.7368217\n0.25342992      0.71737933      0.12789607      0.21691357      0.7543404\n\n(2,2,.,.) =\n0.79176855      0.1204049       0.58971256      0.115073755     0.10459962\n0.5225398       0.742363        0.7612815       0.9881919       0.13359445\n0.9026869       0.13972941      0.92064524      0.9435532       0.5502235\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of...  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.6991891       0.4948494       0.9539039\n0.21852028      0.5664119       0.48613077\n\n(1,2,.,.) =\n0.38028112      0.56262326      0.7794005\n0.6522  0.6274959       0.34790504\n\n(2,1,.,.) =\n0.1452374       0.4472468       0.36465502\n0.40102595      0.5618719       0.54899293\n\n(2,2,.,.) =\n0.79176855      0.43327665      0.111582376\n0.71261334      0.70765764      0.75788474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import ResizeBilinear\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5)))\ninput = np.random.rand(2, 2, 3, 5, 5)\noutput = model.forward(input)  Input is:  array([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189],\n         [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155],\n         [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]],\n\n        [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775],\n         [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264],\n         [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]],\n\n\n       [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452],\n         [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ],\n         [0.608378  , 0.10531177, 0.78000335, 0.51679768, 0.65067605]],\n\n        [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255],\n         [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493],\n         [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]])  Output is  array([[[[0.43790358, 0.61913717, 0.2543214 ],\n         [0.6172875 , 0.52657175, 0.3151154 ]],\n\n        [[0.329656  , 0.13861606, 0.20514478],\n         [0.46164483, 0.541788  , 0.5311798 ]]],\n\n\n       [[[0.09462238, 0.57138187, 0.8545758 ],\n         [0.7116966 , 0.5389645 , 0.48184   ]],\n\n        [[0.12074634, 0.6571231 , 0.752728  ],\n         [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)",
            "title": "ResizeBilinear"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/",
            "text": "LocallyConnected2D\n\n\nA Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input.\n\n\nThe input is 2D tensor with shape: (batch_size, channels, rows, cols).\n\n\nScala:\n\n\nLocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = \"valid\", subsample = (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode=\"valid\", subsample=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.71993834     0.018790463     0.08133635      0.35603827\n-1.1757486      1.8503827       -1.4548069      -0.6309117\n-0.53039306     -0.14174776     0.7653523       -0.1891388\n\n(1,2,.,.) =\n1.0949191       0.13689162      0.35839355      -0.14805469\n-2.5264592      -0.34186792     1.3190275       -0.11725446\n-0.48823252     -1.5305915      -1.0556486      1.792275\n\n(2,1,.,.) =\n0.92393816      0.83243525      0.22506136      0.6694662\n0.7662836       -0.23876576     -0.7719174      0.13114463\n0.042082224     1.2212821       -1.2496184      -0.18717249\n\n(2,2,.,.) =\n0.726698        0.42673108      0.0786712       -1.4069401\n-0.090565465    0.49527475      0.08590904      -0.51858175\n1.4575573       0.9669369       0.21832618      0.34654656\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.022375792     0.669761        -0.25723624\n0.99919814      0.93189466      0.8592935\n\n(1,2,.,.) =\n0.12613812      -1.0531536      0.8148589\n0.66276294      0.12609969      0.6590149\n\n(2,1,.,.) =\n-0.1259023      0.32203823      0.07248953\n-0.125191       -0.1285046      0.021367729\n\n(2,2,.,.) =\n-0.13560611     -0.038621478    -0.08420516\n-0.0021556932   -0.094522506    -0.08551059\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.75179142 0.10678918 0.92663152 0.2041142 ]\n   [0.03534582 0.13742629 0.94115987 0.17303432]\n   [0.91112368 0.19837546 0.45643767 0.16589123]]\n\n  [[0.22996923 0.22878544 0.75623624 0.7058976 ]\n   [0.14107232 0.49484648 0.71194356 0.53604538]\n   [0.46257205 0.46902871 0.48046811 0.83579709]]]\n\n\n [[[0.9397535  0.51814825 0.10492714 0.24623405]\n   [0.69800376 0.12353963 0.69536497 0.05159074]\n   [0.56722731 0.33348394 0.47648031 0.25398067]]\n\n  [[0.51018599 0.3416568  0.14112375 0.76505795]\n   [0.16242231 0.16735028 0.79000471 0.98701885]\n   [0.79852431 0.77458166 0.12551857 0.43866238]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 0.14901309 -0.11168094  0.28349853]\n   [ 0.21792562  0.49922782 -0.06560349]]\n\n  [[ 0.6176302  -0.4638375  -0.13387583]\n   [-0.04903107  0.07764787 -0.33653474]]]\n\n\n [[[ 0.24676235 -0.46874076  0.33973938]\n   [ 0.21408634  0.36619198  0.17972258]]\n\n  [[ 0.35941058 -0.23446569 -0.09271184]\n   [ 0.39490524 -0.00668371 -0.25355732]]]]\n\n\n\n\n\n\nConvolution1D\n\n\nApplies convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nYou can also use \nConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nConvolution1D(nbFilter, filterLength, init = \"glorot_uniform\", activation = null, borderMode = \"valid\", subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution1D(nb_filter, filter_length, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]\n\n\n\n\n\n\nConvolution2D\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n\n\nYou can also use \nConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D, i.e. (samples, channels, rows, cols).\nThe output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols).\n\n\nScala:\n\n\nConvolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, borderMode = \"valid\", subsample = (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D[Float](4, 2, 2, activation = \"relu\", inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8852683 -0.81495345 -1.2799169  0.9779215\n1.1456866 -0.10803124 -0.44350016 -1.7670554\n-0.9059258  -0.08115104 -0.888267 1.8203543\n\n(1,2,.,.) =\n-0.69458634 0.31331652  1.4600077 -0.93392456\n1.4808512 0.2082488 -0.008410408  0.013914147\n0.86024827  1.124567  0.28874534  -0.4866409\n\n(2,1,.,.) =\n-0.020653103  0.8077344 -0.9391865  0.2743323\n0.09707443  -0.1877453  2.3798819 1.71017\n0.14860597  0.8954743 2.0009918 1.0548053\n\n(2,2,.,.) =\n-0.06750481 -2.1010966  -0.51831937 -0.40519416\n1.2983296 1.9960507 0.31097296  -1.0400984\n-0.20703147 0.32478333  -0.5247251  1.2356688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.49652004  0.62284863  0.0\n1.2256577 0.11462581  0.761484\n\n(1,2,.,.) =\n0.0 0.0 1.6321466\n0.69082737  0.10713227  0.0\n\n(1,3,.,.) =\n0.0 0.0 1.0226117\n0.0 0.0 0.0\n\n(1,4,.,.) =\n0.017812707 0.044630717 0.0\n0.0 0.0 0.0\n\n(2,1,.,.) =\n0.0 0.79017955  0.0\n1.1551664 0.0 0.0\n\n(2,2,.,.) =\n0.0 0.0 0.0\n0.0 0.9762883 0.0\n\n(2,3,.,.) =\n0.0 0.0 0.0\n0.0 0.0 0.0\n\n(2,4,.,.) =\n0.0 0.0 0.1633394\n0.66279346  0.07180607  1.7188346\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[ 0.70766604,  0.56604946,  0.89172683,  0.35057259],\n         [ 0.89700606,  0.71675588,  0.92357667,  0.73319623],\n         [ 0.38198447,  0.66954234,  0.46397678,  0.81329758]],\n\n        [[ 0.86972625,  0.16386155,  0.73140259,  0.07359015],\n         [ 0.43441431,  0.16852341,  0.15025034,  0.34109183],\n         [ 0.89670592,  0.06335869,  0.72356566,  0.54245763]]],\n\n\n       [[[ 0.37727322,  0.14688331,  0.06249512,  0.29553298],\n         [ 0.50554043,  0.33364744,  0.95334248,  0.40551935],\n         [ 0.81317402,  0.59253283,  0.8249684 ,  0.80419637]],\n\n        [[ 0.71737738,  0.09376579,  0.3793706 ,  0.91432729],\n         [ 0.34433954,  0.74886398,  0.97859311,  0.9538775 ],\n         [ 0.45521369,  0.79446047,  0.35239537,  0.12803574]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.0732559 ,  0.70261478,  0.16962567],\n         [ 0.3641817 ,  0.56304729,  0.71597064]],\n\n        [[-0.5932048 , -0.04155506, -0.49025974],\n         [-0.57992101, -0.00230447, -0.33811107]],\n\n        [[ 0.13634545,  0.27157408, -0.01450583],\n         [ 0.34469086,  0.46334854,  0.55308509]],\n\n        [[-0.01247289,  0.69034004, -0.01554111],\n         [ 0.07790593,  0.09984782,  0.1278697 ]]],\n\n\n       [[[ 0.02547407,  0.64045584,  0.21886043],\n         [ 0.43482357,  0.45493811,  0.26216859]],\n\n        [[-0.39469361, -0.34455007, -0.2396858 ],\n         [-0.15447566, -0.35714447, -0.44134659]],\n\n        [[ 0.30956799,  0.9154281 ,  0.75450832],\n         [ 0.37207305,  0.55432665, -0.29964659]],\n\n        [[-0.48307419, -0.29406634, -0.29416537],\n         [ 0.0138942 ,  0.26592475,  0.38921899]]]], dtype=float32)\n\n\n\n\n\n\nAtrousConvolution2D\n\n\nApplies an atrous convolution operator for filtering windows of 2-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAtrousConvolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample=(1, 1), atrous_rate=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsample\n: Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).\n\n\natrousRate\n: Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D[Float](4, 2, 2, activation = \"relu\", inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]\n\n\n\n\n\n\nLocallyConnected1D\n\n\nLocally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nLocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected1D(nb_filter, filter_length, activation=None, border_mode=\"valid\", subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Dimensionality of the output.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Integer. Factor by which to subsample output.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LocallyConnected1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]\n\n\n\n\n\n\nUpSampling2D\n\n\nUpSampling layer for 2D inputs.\n\n\nRepeats the rows and columns of the data by the specified size.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nUpSampling2D(size = (2, 2), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling2D(size=(2, 2), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 2. UpSampling factors for rows and columns. Default is (2, 2).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) \n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import UpSampling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]\n\n\n\n\n\n\nUpSampling3D\n\n\nUpSampling layer for 3D inputs.\n\n\nRepeats the 1st, 2nd and 3rd dimensions of the data by the specified size.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nUpSampling3D(size = (2, 2, 2), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling3D(size=(2, 2, 2), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.05876646      0.8743367\n-0.15551122     0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n(1,1,2,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.01897243 0.87927954]\n-    [0.13656585 0.3003842 ]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]\n\n   [[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]]]]\n\n\n\n\n\n\nAtrousConvolution1D\n\n\nApplies an atrous convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAtrousConvolution1D(nbFilter, filterLength, init = \"glorot_uniform\", activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution1D(nb_filter, filter_length, init=\"glorot_uniform\", activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution kernels to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\natrousRate\n: Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18186663     -0.43034658     0.26391524      -1.4132749\n-0.17445838     1.3798479       0.1737039       1.152537\n0.27590567      0.009284354     -0.80261934     -0.9434588\n\n(2,.,.) =\n-0.20791245     0.21988653      0.8744776       0.2940677\n0.07080339      0.51823103      -0.46097854     -0.037812505\n0.35226902      0.79622966      0.011483789     0.88822025\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.026210725     1.2229221       0.45232815      -1.0826558      0.849349        0.086645454     0.041758537     0.3721839\n\n(2,.,.) =\n-0.14264873     0.060507685     -0.217965       0.42317814      0.17935039      -0.05465065     -0.6533742      -0.009769946\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.44706076 0.5902202  0.3784323  0.4098717 ]\n  [0.74646876 0.98997355 0.64164388 0.61591103]\n  [0.88695659 0.16591123 0.6575717  0.55897158]]\n\n [[0.51990872 0.82065542 0.18409799 0.99078291]\n  [0.03853884 0.0781884  0.82290244 0.99992993]\n  [0.02394716 0.10870804 0.17077537 0.77893951]]]\n\n\n\n\nOutput is\n\n\n[[[-0.09361145  0.48225394 -0.3777458  -0.84651476  0.3678655\n   -0.02871403  1.0220621   0.7548751 ]]\n\n [[-0.0299319   0.37761992 -0.08759689 -0.01757497 -0.01414538\n   -0.2547227   0.70025307  0.49045497]]]\n\n\n\n\n\n\nZeroPadding1D\n\n\nZero-padding layer for 1D input (e.g. temporal sequence).\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nZeroPadding1D(padding = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding1D(padding=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the padding dimension.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]\n\n\n\n\nOutput is\n\n\n[[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]\n\n\n\n\n\n\nZeroPadding3D\n\n\nZero-padding layer for 3D data (spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nZeroPadding3D(padding = (1, 1, 1), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding3D(padding=(1, 1, 1), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2)))\nval input = Tensor[Float](1, 1, 2, 1, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.59840345     -0.06308561\n\n(1,1,2,.,.) =\n0.48804763      0.2723002\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,2,.,.) =\n0.0     0.0     0.0     0.0\n0.0     -0.59840345     -0.06308561     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,3,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.48804763      0.2723002       0.0\n0.0     0.0     0.0     0.0\n\n(1,1,4,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2)))\ninput = np.random.random([1, 1, 2, 1, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.03167021, 0.15764403]],\n\n   [[0.26572586, 0.48872052]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.03167021, 0.15764403, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.26572585, 0.48872054, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]]]]]\n\n\n\n\n\n\nCropping1D\n\n\nCropping layer for 1D input (e.g. temporal sequence).\n\n\nIt crops along the time dimension (axis 1). \n\n\nThe input of this layer should be 3D, i.e. (batch, axis_to_crop, features).\nThe output of this layer should be 3D, i.e. (batch, cropped_axis, features).\n\n\nScala:\n\n\nCropping1D(cropping = (1, 1), inputShape = null)\n\n\n\n\nPython:\n\n\nCropping1D(cropping=(1, 1), input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.06297628  -0.8408224  0.21813048  -0.14371997\n0.9278932   0.069493145 -0.2900171  0.536517\n3.430168    -0.53643423 0.12677099  0.3572487\n\n(2,.,.) =\n1.493348    -1.1703341  -0.37385875 -0.239736\n0.33984247  -0.6005885  1.2722077   -0.5043763\n0.012092848 0.40293974  0.61356264  2.4283617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.9278932   0.069493145 -0.2900171  0.536517\n\n(2,.,.) =\n0.33984247  -0.6005885  1.2722077   -0.5043763\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Cropping1D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.12013423,  0.21359734,  0.92871231,  0.92152503],\n        [ 0.3649771 ,  0.39968689,  0.92007275,  0.16493056],\n        [ 0.11018303,  0.7591447 ,  0.35932136,  0.97727728]],\n\n       [[ 0.06645696,  0.21909036,  0.01219254,  0.46561466],\n        [ 0.64316144,  0.53577975,  0.38302965,  0.56807556],\n        [ 0.25223652,  0.23857826,  0.1884081 ,  0.42532243]]])\n\n\n\n\nOutput is:\n\n\narray([[[ 0.36497709,  0.3996869 ,  0.92007273,  0.16493057]],\n\n       [[ 0.64316142,  0.53577977,  0.38302964,  0.56807554]]], dtype=float32)\n\n\n\n\n\n\nCropping2D\n\n\nCropping layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nCropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nCropping2D(cropping=((0, 0), (0, 0)), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6840084      0.293568        0.045959193     0.91535753\n-0.49666363     -0.05026308     0.22163485      0.08330725\n0.36190453      -0.023894459    0.40037137      0.15155333\n\n(1,2,.,.) =\n1.0107938       0.05100493      -0.88689697     0.111396775\n0.065911256     -0.41727677     0.62742686      -0.5435138\n-1.0133605      0.7352207       -0.77922934     -0.36588958\n\n(2,1,.,.) =\n-0.6847248      0.8627568       -0.5600547      0.48514402\n-0.9261762      -0.34248486     -0.09243064     -0.13134436\n-0.23247129     1.2801572       -1.377833       -1.7608607\n\n(2,2,.,.) =\n1.1907105       0.30009162      -1.2604285      1.0099201\n-1.211673       -0.08809458     0.4386406       -0.6264226\n0.112140626     0.3690179       0.832656        1.3931179\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.293568        0.045959193     0.91535753\n-0.05026308     0.22163485      0.08330725\n\n(1,2,.,.) =\n0.05100493      -0.88689697     0.111396775\n-0.41727677     0.62742686      -0.5435138\n(2,1,.,.) =\n0.8627568       -0.5600547      0.48514402\n-0.34248486     -0.09243064     -0.13134436\n(2,2,.,.) =\n0.30009162      -1.2604285      1.0099201\n-0.08809458     0.4386406       -0.6264226\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Cropping2D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097],\n         [0.36859968, 0.44601991, 0.94679033, 0.93842937],\n         [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]],\n\n        [[0.32265899, 0.37304445, 0.09097587, 0.52496901],\n         [0.70275446, 0.10796127, 0.74849378, 0.99118752],\n         [0.34310691, 0.60435919, 0.22227177, 0.48464358]]],\n       [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216],\n         [0.48278365, 0.0968289 , 0.9465143 , 0.49814986],\n         [0.36140084, 0.98581155, 0.14834531, 0.71290525]],\n\n        [[0.8909849 , 0.66729728, 0.53332039, 0.83958965],\n         [0.3645429 , 0.40645471, 0.02596942, 0.80835778],\n         [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[0.78710294, 0.4518868 , 0.787381  ],\n         [0.44601992, 0.94679034, 0.93842936]],\n\n        [[0.37304446, 0.09097587, 0.524969  ],\n         [0.10796127, 0.7484938 , 0.9911875 ]]],\n       [[[0.6009071 , 0.09771059, 0.19654216],\n         [0.0968289 , 0.9465143 , 0.49814987]],\n\n        [[0.6672973 , 0.53332037, 0.83958966],\n         [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32)\n\n\n\n\n\n\nCropping3D\n\n\nCropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nCropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nCropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).\n\n\ndimOrdering\n: Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Cropping3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759],\n          [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911],\n          [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353],\n          [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]],\n\n         [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575],\n          [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304],\n          [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954],\n          [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]],\n\n         [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445],\n          [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542],\n          [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911],\n          [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]],\n\n        [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093],\n          [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295],\n          [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334],\n          [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]],\n\n         [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699],\n          [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744],\n          [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854],\n          [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]],\n\n         [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005],\n          [0.9700492 , 0.590918  , 0.88279087, 0.36807701, 0.48872168],\n          [0.847832  , 0.64009568, 0.97971251, 0.06989564, 0.80387185],\n          [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]],\n\n       [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475],\n          [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919],\n          [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606],\n          [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]],\n\n         [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397],\n          [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274],\n          [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272],\n          [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]],\n\n         [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231],\n          [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435],\n          [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504],\n          [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]],\n\n        [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ],\n          [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764],\n          [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024],\n          [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]],\n\n         [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993   ],\n          [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ],\n          [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089],\n          [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]],\n\n         [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002],\n          [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841],\n          [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372],\n          [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[[0.6530752 , 0.4779544 , 0.18358642],\n          [0.57958406, 0.7861404 , 0.12632357]]],\n\n        [[[0.8930068 , 0.8599061 , 0.38889495],\n          [0.4575138 , 0.1316247 , 0.04326183]]]],\n       [[[[0.68833065, 0.76978064, 0.14479478],\n          [0.03855975, 0.12752528, 0.9758718 ]]],\n\n        [[[0.6639144 , 0.49371347, 0.9227675 ],\n          [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32)\n\n\n\n\n\n\nZeroPadding2D\n\n\nZero-padding layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nZeroPadding2D(padding = (1, 1), dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding2D(padding=(1, 1), dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2227936       0.30803198      -1.3921114\n0.43359384      -0.038079295    -1.241585\n\n(1,2,.,.) =\n-1.1766883      -2.015887       -0.7110933\n-0.5415997      -0.50294536     -1.3715594\n(2,1,.,.) =\n0.10733734      1.3369694       0.037685163\n-1.2942516      0.2693859       0.6846867\n(2,2,.,.) =\n-1.4678168      0.21972063      0.40070927\n0.45242524      -0.03342953     -0.8016073\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     1.2227936       0.30803198      -1.3921114      0.0\n0.0     0.43359384      -0.038079295    -1.241585       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(1,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.1766883      -2.015887       -0.7110933      0.0\n0.0     -0.5415997      -0.50294536     -1.3715594      0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     0.10733734      1.3369694       0.037685163     0.0\n0.0     -1.2942516      0.2693859       0.6846867       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.4678168      0.21972063      0.40070927      0.0\n0.0     0.45242524      -0.03342953     -0.8016073      0.0\n0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.0544422 , 0.21723616, 0.69071413],\n         [0.68166784, 0.78673863, 0.63838101]],\n\n        [[0.43930351, 0.62153019, 0.5539688 ],\n         [0.79930636, 0.07007638, 0.13261168]]],\n       [[[0.21493318, 0.21060602, 0.12101637],\n         [0.90132665, 0.95799647, 0.09733214]],\n\n        [[0.21548934, 0.27369217, 0.06024094],\n         [0.85388521, 0.63911987, 0.34428558]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.0544422 , 0.21723616, 0.6907141 , 0.        ],\n         [0.        , 0.68166786, 0.78673863, 0.638381  , 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.43930352, 0.6215302 , 0.5539688 , 0.        ],\n         [0.        , 0.79930633, 0.07007638, 0.13261168, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n\n       [[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21493319, 0.21060602, 0.12101637, 0.        ],\n         [0.        , 0.90132666, 0.9579965 , 0.09733213, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21548934, 0.27369216, 0.06024094, 0.        ],\n         [0.        , 0.85388523, 0.63911986, 0.34428558, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]]],\n      dtype=float32)\n\n\n\n\n\n\nShareConvolution2D\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n\n\nYou can also use ShareConv2D as an alias of this layer.\n\n\nData format currently supported for this layer is DataFormat.NCHW (dimOrdering='th').\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nShareConvolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, subsample = (1, 1), padH = 0, padW = 0, \n                   propagateBack = true, dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nShareConvolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, subsample=(1, 1), pad_h=0, pad_w=0,\n                   propagate_back=True, dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: Initialization method for the weights of the layer. Default is Xavier.\n          You can also pass in corresponding string representations such as 'glorot_uniform'\n          or 'normal', etc. for simple init methods in the factory method.\n\n\nactivation\n: Activation function to use. Default is null.\n                You can also pass in corresponding string representations such as 'relu'\n                or 'sigmoid', etc. for simple activations in the factory method.\n\n\nsubsample\n: Int array of length 2 corresponding to the step of the convolution in the\n               height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\npadH\n: The additional zeros added to the height dimension. Default is 0.\n\n\npadW\n: The additional zeros added to the width dimension. Default is 0.\n\n\npropagateBack\n: Whether to propagate gradient back. Default is true.\n\n\ndimOrdering\n: Format of input data. Please use DataFormat.NCHW (dimOrdering='th').\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization),\n                  applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear).\n          Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.033261865     -0.5991786      1.7385886\n-0.56382173     0.4827164       -0.62269926\n\n(1,2,.,.) =\n-0.31000894     -0.05032834     -1.1754748\n2.594314        -1.0447274      -1.2348005\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.39924833\n\n(1,2,.,.) =\n-0.05582048\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import ShareConvolution2D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.94476901, 0.20822355, 0.12900894],\n         [0.07171242, 0.40400603, 0.87892258]],\n\n        [[0.40369527, 0.92786425, 0.17116734],\n         [0.73204729, 0.89770083, 0.86390069]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.1860767 ]],\n\n        [[-0.00958405]]]], dtype=float32)\n\n\n\n\n\n\nUpSampling1D\n\n\nUpSampling layer for 1D inputs.\n\n\nRepeats each temporal step 'length' times along the time axis.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nUpSampling1D(length = 2, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling1D(length=2, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlength\n: Integer. UpSampling factor. Default is 2.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling1D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(UpSampling1D(length=3, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.22908319, 0.6684591 , 0.12425427],\n        [0.02378978, 0.12953109, 0.70786959]],\n\n       [[0.40711686, 0.64417535, 0.92019981],\n        [0.28788481, 0.77902591, 0.93019748]]])\n\n\n\n\nOutput is\n\n\narray([[[0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ]],\n\n       [[0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)",
            "title": "Convolutional Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected2d",
            "text": "A Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input.  The input is 2D tensor with shape: (batch_size, channels, rows, cols).  Scala:  LocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = \"valid\", subsample = (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode=\"valid\", subsample=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.71993834     0.018790463     0.08133635      0.35603827\n-1.1757486      1.8503827       -1.4548069      -0.6309117\n-0.53039306     -0.14174776     0.7653523       -0.1891388\n\n(1,2,.,.) =\n1.0949191       0.13689162      0.35839355      -0.14805469\n-2.5264592      -0.34186792     1.3190275       -0.11725446\n-0.48823252     -1.5305915      -1.0556486      1.792275\n\n(2,1,.,.) =\n0.92393816      0.83243525      0.22506136      0.6694662\n0.7662836       -0.23876576     -0.7719174      0.13114463\n0.042082224     1.2212821       -1.2496184      -0.18717249\n\n(2,2,.,.) =\n0.726698        0.42673108      0.0786712       -1.4069401\n-0.090565465    0.49527475      0.08590904      -0.51858175\n1.4575573       0.9669369       0.21832618      0.34654656\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.022375792     0.669761        -0.25723624\n0.99919814      0.93189466      0.8592935\n\n(1,2,.,.) =\n0.12613812      -1.0531536      0.8148589\n0.66276294      0.12609969      0.6590149\n\n(2,1,.,.) =\n-0.1259023      0.32203823      0.07248953\n-0.125191       -0.1285046      0.021367729\n\n(2,2,.,.) =\n-0.13560611     -0.038621478    -0.08420516\n-0.0021556932   -0.094522506    -0.08551059\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.75179142 0.10678918 0.92663152 0.2041142 ]\n   [0.03534582 0.13742629 0.94115987 0.17303432]\n   [0.91112368 0.19837546 0.45643767 0.16589123]]\n\n  [[0.22996923 0.22878544 0.75623624 0.7058976 ]\n   [0.14107232 0.49484648 0.71194356 0.53604538]\n   [0.46257205 0.46902871 0.48046811 0.83579709]]]\n\n\n [[[0.9397535  0.51814825 0.10492714 0.24623405]\n   [0.69800376 0.12353963 0.69536497 0.05159074]\n   [0.56722731 0.33348394 0.47648031 0.25398067]]\n\n  [[0.51018599 0.3416568  0.14112375 0.76505795]\n   [0.16242231 0.16735028 0.79000471 0.98701885]\n   [0.79852431 0.77458166 0.12551857 0.43866238]]]]  Output is  [[[[ 0.14901309 -0.11168094  0.28349853]\n   [ 0.21792562  0.49922782 -0.06560349]]\n\n  [[ 0.6176302  -0.4638375  -0.13387583]\n   [-0.04903107  0.07764787 -0.33653474]]]\n\n\n [[[ 0.24676235 -0.46874076  0.33973938]\n   [ 0.21408634  0.36619198  0.17972258]]\n\n  [[ 0.35941058 -0.23446569 -0.09271184]\n   [ 0.39490524 -0.00668371 -0.25355732]]]]",
            "title": "LocallyConnected2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution1d",
            "text": "Applies convolution operator for filtering neighborhoods of 1-D inputs.  You can also use  Conv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  Convolution1D(nbFilter, filterLength, init = \"glorot_uniform\", activation = null, borderMode = \"valid\", subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution1D(nb_filter, filter_length, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]  Output is  [[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]",
            "title": "Convolution1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution2d",
            "text": "Applies a 2D convolution over an input image composed of several input planes.  You can also use  Conv2D  as an alias of this layer.  The input of this layer should be 4D, i.e. (samples, channels, rows, cols).\nThe output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols).  Scala:  Convolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, borderMode = \"valid\", subsample = (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D[Float](4, 2, 2, activation = \"relu\", inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8852683 -0.81495345 -1.2799169  0.9779215\n1.1456866 -0.10803124 -0.44350016 -1.7670554\n-0.9059258  -0.08115104 -0.888267 1.8203543\n\n(1,2,.,.) =\n-0.69458634 0.31331652  1.4600077 -0.93392456\n1.4808512 0.2082488 -0.008410408  0.013914147\n0.86024827  1.124567  0.28874534  -0.4866409\n\n(2,1,.,.) =\n-0.020653103  0.8077344 -0.9391865  0.2743323\n0.09707443  -0.1877453  2.3798819 1.71017\n0.14860597  0.8954743 2.0009918 1.0548053\n\n(2,2,.,.) =\n-0.06750481 -2.1010966  -0.51831937 -0.40519416\n1.2983296 1.9960507 0.31097296  -1.0400984\n-0.20703147 0.32478333  -0.5247251  1.2356688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.49652004  0.62284863  0.0\n1.2256577 0.11462581  0.761484\n\n(1,2,.,.) =\n0.0 0.0 1.6321466\n0.69082737  0.10713227  0.0\n\n(1,3,.,.) =\n0.0 0.0 1.0226117\n0.0 0.0 0.0\n\n(1,4,.,.) =\n0.017812707 0.044630717 0.0\n0.0 0.0 0.0\n\n(2,1,.,.) =\n0.0 0.79017955  0.0\n1.1551664 0.0 0.0\n\n(2,2,.,.) =\n0.0 0.0 0.0\n0.0 0.9762883 0.0\n\n(2,3,.,.) =\n0.0 0.0 0.0\n0.0 0.0 0.0\n\n(2,4,.,.) =\n0.0 0.0 0.1633394\n0.66279346  0.07180607  1.7188346\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[ 0.70766604,  0.56604946,  0.89172683,  0.35057259],\n         [ 0.89700606,  0.71675588,  0.92357667,  0.73319623],\n         [ 0.38198447,  0.66954234,  0.46397678,  0.81329758]],\n\n        [[ 0.86972625,  0.16386155,  0.73140259,  0.07359015],\n         [ 0.43441431,  0.16852341,  0.15025034,  0.34109183],\n         [ 0.89670592,  0.06335869,  0.72356566,  0.54245763]]],\n\n\n       [[[ 0.37727322,  0.14688331,  0.06249512,  0.29553298],\n         [ 0.50554043,  0.33364744,  0.95334248,  0.40551935],\n         [ 0.81317402,  0.59253283,  0.8249684 ,  0.80419637]],\n\n        [[ 0.71737738,  0.09376579,  0.3793706 ,  0.91432729],\n         [ 0.34433954,  0.74886398,  0.97859311,  0.9538775 ],\n         [ 0.45521369,  0.79446047,  0.35239537,  0.12803574]]]])  Output is  array([[[[ 0.0732559 ,  0.70261478,  0.16962567],\n         [ 0.3641817 ,  0.56304729,  0.71597064]],\n\n        [[-0.5932048 , -0.04155506, -0.49025974],\n         [-0.57992101, -0.00230447, -0.33811107]],\n\n        [[ 0.13634545,  0.27157408, -0.01450583],\n         [ 0.34469086,  0.46334854,  0.55308509]],\n\n        [[-0.01247289,  0.69034004, -0.01554111],\n         [ 0.07790593,  0.09984782,  0.1278697 ]]],\n\n\n       [[[ 0.02547407,  0.64045584,  0.21886043],\n         [ 0.43482357,  0.45493811,  0.26216859]],\n\n        [[-0.39469361, -0.34455007, -0.2396858 ],\n         [-0.15447566, -0.35714447, -0.44134659]],\n\n        [[ 0.30956799,  0.9154281 ,  0.75450832],\n         [ 0.37207305,  0.55432665, -0.29964659]],\n\n        [[-0.48307419, -0.29406634, -0.29416537],\n         [ 0.0138942 ,  0.26592475,  0.38921899]]]], dtype=float32)",
            "title": "Convolution2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution2d",
            "text": "Applies an atrous convolution operator for filtering windows of 2-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  AtrousConvolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, border_mode=\"valid\", subsample=(1, 1), atrous_rate=(1, 1), dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsample : Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).  atrousRate : Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D[Float](4, 2, 2, activation = \"relu\", inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]  Output is  [[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]",
            "title": "AtrousConvolution2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected1d",
            "text": "Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 3D.  Scala:  LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode=\"valid\", subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Dimensionality of the output.  filterLength : The extension (spatial or temporal) of each filter.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Integer. Factor by which to subsample output.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LocallyConnected1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]  Output is  [[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]",
            "title": "LocallyConnected1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling2d",
            "text": "UpSampling layer for 2D inputs.  Repeats the rows and columns of the data by the specified size.  The input of this layer should be 4D.  Scala:  UpSampling2D(size = (2, 2), dimOrdering = \"th\", inputShape = null)  Python:  UpSampling2D(size=(2, 2), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   size : Length 2. UpSampling factors for rows and columns. Default is (2, 2).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) \n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import UpSampling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]  Output is:  [[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]",
            "title": "UpSampling2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling3d",
            "text": "UpSampling layer for 3D inputs.  Repeats the 1st, 2nd and 3rd dimensions of the data by the specified size.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  The input of this layer should be 5D.  Scala:  UpSampling3D(size = (2, 2, 2), dimOrdering = \"th\", inputShape = null)  Python:  UpSampling3D(size=(2, 2, 2), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   size : Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.05876646      0.8743367\n-0.15551122     0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n(1,1,2,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.01897243 0.87927954]\n-    [0.13656585 0.3003842 ]]]]]  Output is  [[[[[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]\n\n   [[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]]]]",
            "title": "UpSampling3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution1d",
            "text": "Applies an atrous convolution operator for filtering neighborhoods of 1-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  AtrousConvolution1D(nbFilter, filterLength, init = \"glorot_uniform\", activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution1D(nb_filter, filter_length, init=\"glorot_uniform\", activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution kernels to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  atrousRate : Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18186663     -0.43034658     0.26391524      -1.4132749\n-0.17445838     1.3798479       0.1737039       1.152537\n0.27590567      0.009284354     -0.80261934     -0.9434588\n\n(2,.,.) =\n-0.20791245     0.21988653      0.8744776       0.2940677\n0.07080339      0.51823103      -0.46097854     -0.037812505\n0.35226902      0.79622966      0.011483789     0.88822025\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.026210725     1.2229221       0.45232815      -1.0826558      0.849349        0.086645454     0.041758537     0.3721839\n\n(2,.,.) =\n-0.14264873     0.060507685     -0.217965       0.42317814      0.17935039      -0.05465065     -0.6533742      -0.009769946\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.44706076 0.5902202  0.3784323  0.4098717 ]\n  [0.74646876 0.98997355 0.64164388 0.61591103]\n  [0.88695659 0.16591123 0.6575717  0.55897158]]\n\n [[0.51990872 0.82065542 0.18409799 0.99078291]\n  [0.03853884 0.0781884  0.82290244 0.99992993]\n  [0.02394716 0.10870804 0.17077537 0.77893951]]]  Output is  [[[-0.09361145  0.48225394 -0.3777458  -0.84651476  0.3678655\n   -0.02871403  1.0220621   0.7548751 ]]\n\n [[-0.0299319   0.37761992 -0.08759689 -0.01757497 -0.01414538\n   -0.2547227   0.70025307  0.49045497]]]",
            "title": "AtrousConvolution1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding1d",
            "text": "Zero-padding layer for 1D input (e.g. temporal sequence).  The input of this layer should be 3D.  Scala:  ZeroPadding1D(padding = 1, inputShape = null)  Python:  ZeroPadding1D(padding=1, input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the padding dimension.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]  Output is  [[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]",
            "title": "ZeroPadding1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding3d",
            "text": "Zero-padding layer for 3D data (spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  ZeroPadding3D(padding = (1, 1, 1), dimOrdering = \"th\", inputShape = null)  Python:  ZeroPadding3D(padding=(1, 1, 1), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   padding : Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2)))\nval input = Tensor[Float](1, 1, 2, 1, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.59840345     -0.06308561\n\n(1,1,2,.,.) =\n0.48804763      0.2723002\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,2,.,.) =\n0.0     0.0     0.0     0.0\n0.0     -0.59840345     -0.06308561     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,3,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.48804763      0.2723002       0.0\n0.0     0.0     0.0     0.0\n\n(1,1,4,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2)))\ninput = np.random.random([1, 1, 2, 1, 2])\noutput = model.forward(input)  Input is:  [[[[[0.03167021, 0.15764403]],\n\n   [[0.26572586, 0.48872052]]]]]  Output is  [[[[[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.03167021, 0.15764403, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.26572585, 0.48872054, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]]]]]",
            "title": "ZeroPadding3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping1d",
            "text": "Cropping layer for 1D input (e.g. temporal sequence).  It crops along the time dimension (axis 1).   The input of this layer should be 3D, i.e. (batch, axis_to_crop, features).\nThe output of this layer should be 3D, i.e. (batch, cropped_axis, features).  Scala:  Cropping1D(cropping = (1, 1), inputShape = null)  Python:  Cropping1D(cropping=(1, 1), input_shape=None, name=None)  Parameters:   cropping : Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.06297628  -0.8408224  0.21813048  -0.14371997\n0.9278932   0.069493145 -0.2900171  0.536517\n3.430168    -0.53643423 0.12677099  0.3572487\n\n(2,.,.) =\n1.493348    -1.1703341  -0.37385875 -0.239736\n0.33984247  -0.6005885  1.2722077   -0.5043763\n0.012092848 0.40293974  0.61356264  2.4283617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.9278932   0.069493145 -0.2900171  0.536517\n\n(2,.,.) =\n0.33984247  -0.6005885  1.2722077   -0.5043763\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]  Python example:  from zoo.pipeline.api.keras.layers import Cropping1D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.12013423,  0.21359734,  0.92871231,  0.92152503],\n        [ 0.3649771 ,  0.39968689,  0.92007275,  0.16493056],\n        [ 0.11018303,  0.7591447 ,  0.35932136,  0.97727728]],\n\n       [[ 0.06645696,  0.21909036,  0.01219254,  0.46561466],\n        [ 0.64316144,  0.53577975,  0.38302965,  0.56807556],\n        [ 0.25223652,  0.23857826,  0.1884081 ,  0.42532243]]])  Output is:  array([[[ 0.36497709,  0.3996869 ,  0.92007273,  0.16493057]],\n\n       [[ 0.64316142,  0.53577977,  0.38302964,  0.56807554]]], dtype=float32)",
            "title": "Cropping1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping2d",
            "text": "Cropping layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  Cropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = \"th\", inputShape = null)  Python:  Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6840084      0.293568        0.045959193     0.91535753\n-0.49666363     -0.05026308     0.22163485      0.08330725\n0.36190453      -0.023894459    0.40037137      0.15155333\n\n(1,2,.,.) =\n1.0107938       0.05100493      -0.88689697     0.111396775\n0.065911256     -0.41727677     0.62742686      -0.5435138\n-1.0133605      0.7352207       -0.77922934     -0.36588958\n\n(2,1,.,.) =\n-0.6847248      0.8627568       -0.5600547      0.48514402\n-0.9261762      -0.34248486     -0.09243064     -0.13134436\n-0.23247129     1.2801572       -1.377833       -1.7608607\n\n(2,2,.,.) =\n1.1907105       0.30009162      -1.2604285      1.0099201\n-1.211673       -0.08809458     0.4386406       -0.6264226\n0.112140626     0.3690179       0.832656        1.3931179\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.293568        0.045959193     0.91535753\n-0.05026308     0.22163485      0.08330725\n\n(1,2,.,.) =\n0.05100493      -0.88689697     0.111396775\n-0.41727677     0.62742686      -0.5435138\n(2,1,.,.) =\n0.8627568       -0.5600547      0.48514402\n-0.34248486     -0.09243064     -0.13134436\n(2,2,.,.) =\n0.30009162      -1.2604285      1.0099201\n-0.08809458     0.4386406       -0.6264226\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Cropping2D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097],\n         [0.36859968, 0.44601991, 0.94679033, 0.93842937],\n         [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]],\n\n        [[0.32265899, 0.37304445, 0.09097587, 0.52496901],\n         [0.70275446, 0.10796127, 0.74849378, 0.99118752],\n         [0.34310691, 0.60435919, 0.22227177, 0.48464358]]],\n       [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216],\n         [0.48278365, 0.0968289 , 0.9465143 , 0.49814986],\n         [0.36140084, 0.98581155, 0.14834531, 0.71290525]],\n\n        [[0.8909849 , 0.66729728, 0.53332039, 0.83958965],\n         [0.3645429 , 0.40645471, 0.02596942, 0.80835778],\n         [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]])  Output is:  array([[[[0.78710294, 0.4518868 , 0.787381  ],\n         [0.44601992, 0.94679034, 0.93842936]],\n\n        [[0.37304446, 0.09097587, 0.524969  ],\n         [0.10796127, 0.7484938 , 0.9911875 ]]],\n       [[[0.6009071 , 0.09771059, 0.19654216],\n         [0.0968289 , 0.9465143 , 0.49814987]],\n\n        [[0.6672973 , 0.53332037, 0.83958966],\n         [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32)",
            "title": "Cropping2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping3d",
            "text": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  Cropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = \"th\", inputShape = null)  Python:  Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).  dimOrdering : Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Cropping3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)  Input is:  array([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759],\n          [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911],\n          [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353],\n          [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]],\n\n         [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575],\n          [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304],\n          [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954],\n          [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]],\n\n         [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445],\n          [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542],\n          [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911],\n          [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]],\n\n        [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093],\n          [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295],\n          [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334],\n          [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]],\n\n         [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699],\n          [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744],\n          [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854],\n          [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]],\n\n         [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005],\n          [0.9700492 , 0.590918  , 0.88279087, 0.36807701, 0.48872168],\n          [0.847832  , 0.64009568, 0.97971251, 0.06989564, 0.80387185],\n          [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]],\n\n       [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475],\n          [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919],\n          [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606],\n          [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]],\n\n         [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397],\n          [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274],\n          [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272],\n          [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]],\n\n         [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231],\n          [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435],\n          [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504],\n          [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]],\n\n        [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ],\n          [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764],\n          [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024],\n          [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]],\n\n         [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993   ],\n          [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ],\n          [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089],\n          [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]],\n\n         [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002],\n          [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841],\n          [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372],\n          [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]])  Output is:  array([[[[[0.6530752 , 0.4779544 , 0.18358642],\n          [0.57958406, 0.7861404 , 0.12632357]]],\n\n        [[[0.8930068 , 0.8599061 , 0.38889495],\n          [0.4575138 , 0.1316247 , 0.04326183]]]],\n       [[[[0.68833065, 0.76978064, 0.14479478],\n          [0.03855975, 0.12752528, 0.9758718 ]]],\n\n        [[[0.6639144 , 0.49371347, 0.9227675 ],\n          [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32)",
            "title": "Cropping3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding2d",
            "text": "Zero-padding layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  ZeroPadding2D(padding = (1, 1), dimOrdering = \"th\", inputShape = null)  Python:  ZeroPadding2D(padding=(1, 1), dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2227936       0.30803198      -1.3921114\n0.43359384      -0.038079295    -1.241585\n\n(1,2,.,.) =\n-1.1766883      -2.015887       -0.7110933\n-0.5415997      -0.50294536     -1.3715594\n(2,1,.,.) =\n0.10733734      1.3369694       0.037685163\n-1.2942516      0.2693859       0.6846867\n(2,2,.,.) =\n-1.4678168      0.21972063      0.40070927\n0.45242524      -0.03342953     -0.8016073\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     1.2227936       0.30803198      -1.3921114      0.0\n0.0     0.43359384      -0.038079295    -1.241585       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(1,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.1766883      -2.015887       -0.7110933      0.0\n0.0     -0.5415997      -0.50294536     -1.3715594      0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     0.10733734      1.3369694       0.037685163     0.0\n0.0     -1.2942516      0.2693859       0.6846867       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.4678168      0.21972063      0.40070927      0.0\n0.0     0.45242524      -0.03342953     -0.8016073      0.0\n0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[[0.0544422 , 0.21723616, 0.69071413],\n         [0.68166784, 0.78673863, 0.63838101]],\n\n        [[0.43930351, 0.62153019, 0.5539688 ],\n         [0.79930636, 0.07007638, 0.13261168]]],\n       [[[0.21493318, 0.21060602, 0.12101637],\n         [0.90132665, 0.95799647, 0.09733214]],\n\n        [[0.21548934, 0.27369217, 0.06024094],\n         [0.85388521, 0.63911987, 0.34428558]]]])  Output is:  array([[[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.0544422 , 0.21723616, 0.6907141 , 0.        ],\n         [0.        , 0.68166786, 0.78673863, 0.638381  , 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.43930352, 0.6215302 , 0.5539688 , 0.        ],\n         [0.        , 0.79930633, 0.07007638, 0.13261168, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n\n       [[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21493319, 0.21060602, 0.12101637, 0.        ],\n         [0.        , 0.90132666, 0.9579965 , 0.09733213, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21548934, 0.27369216, 0.06024094, 0.        ],\n         [0.        , 0.85388523, 0.63911986, 0.34428558, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]]],\n      dtype=float32)",
            "title": "ZeroPadding2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#shareconvolution2d",
            "text": "Applies a 2D convolution over an input image composed of several input planes.  You can also use ShareConv2D as an alias of this layer.  Data format currently supported for this layer is DataFormat.NCHW (dimOrdering='th').  The input of this layer should be 4D.  Scala:  ShareConvolution2D(nbFilter, nbRow, nbCol, init = \"glorot_uniform\", activation = null, subsample = (1, 1), padH = 0, padW = 0, \n                   propagateBack = true, dimOrdering = \"th\", wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  ShareConvolution2D(nb_filter, nb_row, nb_col, init=\"glorot_uniform\", activation=None, subsample=(1, 1), pad_h=0, pad_w=0,\n                   propagate_back=True, dim_ordering=\"th\", W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : Initialization method for the weights of the layer. Default is Xavier.\n          You can also pass in corresponding string representations such as 'glorot_uniform'\n          or 'normal', etc. for simple init methods in the factory method.  activation : Activation function to use. Default is null.\n                You can also pass in corresponding string representations such as 'relu'\n                or 'sigmoid', etc. for simple activations in the factory method.  subsample : Int array of length 2 corresponding to the step of the convolution in the\n               height and width dimension. Also called strides elsewhere. Default is (1, 1).  padH : The additional zeros added to the height dimension. Default is 0.  padW : The additional zeros added to the width dimension. Default is 0.  propagateBack : Whether to propagate gradient back. Default is true.  dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th').  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization),\n                  applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear).\n          Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.033261865     -0.5991786      1.7385886\n-0.56382173     0.4827164       -0.62269926\n\n(1,2,.,.) =\n-0.31000894     -0.05032834     -1.1754748\n2.594314        -1.0447274      -1.2348005\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.39924833\n\n(1,2,.,.) =\n-0.05582048\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1]  Python example:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import ShareConvolution2D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[[0.94476901, 0.20822355, 0.12900894],\n         [0.07171242, 0.40400603, 0.87892258]],\n\n        [[0.40369527, 0.92786425, 0.17116734],\n         [0.73204729, 0.89770083, 0.86390069]]]])  Output is  array([[[[ 0.1860767 ]],\n\n        [[-0.00958405]]]], dtype=float32)",
            "title": "ShareConvolution2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling1d",
            "text": "UpSampling layer for 1D inputs.  Repeats each temporal step 'length' times along the time axis.  The input of this layer should be 3D.  Scala:  UpSampling1D(length = 2, inputShape = null)  Python:  UpSampling1D(length=2, input_shape=None, name=None)  Parameters:   length : Integer. UpSampling factor. Default is 2.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]  Python example:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling1D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(UpSampling1D(length=3, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.22908319, 0.6684591 , 0.12425427],\n        [0.02378978, 0.12953109, 0.70786959]],\n\n       [[0.40711686, 0.64417535, 0.92019981],\n        [0.28788481, 0.77902591, 0.93019748]]])  Output is  array([[[0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ]],\n\n       [[0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)",
            "title": "UpSampling1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/",
            "text": "MaxPooling1D\n\n\nMax pooling operation for temporal data.\n\n\nThe input is 3D tensor with shape:(batch_size, steps, feature_dim).\n\n\nScala:\n\n\nMaxPooling1D(poolLength = 2, stride = -1, borderMode = \"valid\", inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling1D(pool_length=2, stride=None, border_mode=\"valid\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which max pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2339195      -1.2134796      0.16991705      -0.10169973     -1.2464932\n0.37946555      0.29533234      -1.2552645      -2.6928735      -0.44519955\n0.98743796      -1.0912303      -0.13897413     1.0241779       -0.5951304\n-0.31459442     -0.088579334    -0.58336115     -0.6427486      -0.1447043\n\n(2,.,.) =\n0.14750746      0.07493488      -0.8554524      -1.6551514      0.16679412\n-0.82279974     0.25704315      0.09921734      -0.8135057      2.7640774\n-1.0111052      0.34388593      -0.7569789      1.0547938       1.6738676\n0.4396624       -1.0570261      0.061429325     1.1752373       -0.14648575\n\n(3,.,.) =\n-0.95818335     0.8790822       -0.99111855     -0.9717616      -0.39238095\n1.2533073       0.23365906      1.7784269       1.0600376       1.6816885\n0.7145845       0.4711851       -0.4465603      -0.77884597     0.484986\n0.42429695      -2.00715        0.6520644       1.3022201       -0.48169184\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.98743796      0.29533234      0.16991705      1.0241779       -0.44519955\n\n(2,.,.) =\n0.14750746      0.34388593      0.09921734      1.0547938       2.7640774\n\n(3,.,.) =\n1.2533073       0.8790822       1.7784269       1.0600376       1.6816885\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192]\n  [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637]\n  [0.24147633 0.2116796  0.54433489 0.22961905 0.88685975]\n  [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]]\n\n [[0.42306184 0.43404804 0.22141668 0.0316458  0.08445576]\n  [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813]\n  [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895]\n  [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]]\n\n [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853]\n  [0.9950283  0.55710408 0.70919634 0.52309929 0.14311439]\n  [0.25394468 0.41519219 0.8074057  0.05341861 0.98447171]\n  [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]]\n\n\n\n\nOutput is:\n\n\n[[[0.27837703 0.8728293  0.9429287  0.48428997 0.8868598 ]]\n\n [[0.9070284  0.43404803 0.52975726 0.43238723 0.50049895]]\n\n [[0.9950283  0.99869156 0.877897   0.6784016  0.98447174]]]\n\n\n\n\n\n\nMaxPooling2D\n\n\nMax pooling operation for spatial data.\n\n\nThe input is 4D tensor with shape:(batch_size, rows, cols, channels).\n\nScala:\n\n\nMaxPooling2D(poolSize = (2, 2), strides = null, borderMode = \"valid\", dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling2D(pool_size=(2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.02138003      -0.20666665     -0.93250555     0.41267508\n-0.40883347     0.4919021       0.7189889       1.3442185\n-0.08697278     -0.025719838    2.1126  0.69069535\n\n(1,2,.,.) =\n-0.1685801      -0.07843445     1.3499486       -0.5944459\n0.29377022      0.061167963     -0.60608864     -0.08283464\n0.03402891      -1.0627178      1.9463096       0.0011169242\n\n(2,1,.,.) =\n-1.4524128      1.3868454       2.3057284       1.574949\n-1.165581       0.79445213      -0.63500565     -0.17981622\n-0.98042095     -1.7876958      0.8024988       -0.90554804\n\n(2,2,.,.) =\n-1.6468426      1.1864686       -0.683854       -1.5643677\n2.8272789       -0.5537863      -0.563258       -0.01623243\n-0.31333938     0.03472893      -1.730748       -0.15463233\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput:\n(1,1,.,.) =\n0.4919021       1.3442185\n\n(1,2,.,.) =\n0.29377022      1.3499486\n\n(2,1,.,.) =\n1.3868454       2.3057284\n\n(2,2,.,.) =\n2.8272789       -0.01623243\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.58589442 0.94643201 0.24779969 0.55347075]\n   [0.50604116 0.69884915 0.81253572 0.58586743]\n   [0.94560389 0.11573268 0.12562681 0.63301697]]\n\n  [[0.11736968 0.75641404 0.19342809 0.37670404]\n   [0.55561582 0.54354621 0.9506264  0.65929266]\n   [0.72911388 0.00499644 0.24280364 0.28822998]]]\n\n\n [[[0.53249492 0.43969012 0.20407128 0.49541971]\n   [0.00369797 0.75294821 0.15204289 0.41394393]\n   [0.19416915 0.93034988 0.0358259  0.38001445]]\n\n  [[0.88946341 0.30646232 0.5347175  0.87568066]\n   [0.00439823 0.97792811 0.34842225 0.20433116]\n   [0.42777728 0.93583737 0.54341935 0.31203758]]]]\n\n\n\n\n\nOutput is:\n\n\n[[[[0.946432   0.8125357 ]]\n\n  [[0.75641406 0.95062643]]]\n\n\n [[[0.7529482  0.4954197 ]]\n\n  [[0.9779281  0.8756807 ]]]]\n\n\n\n\n\n\n\nAveragePooling3D\n\n\nApplies average pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\n\n\nScala:\n\n\nAveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.71569425     -0.39595184     -0.47607258\n-0.12621938     -0.66759187     0.86833215\n\n(1,1,2,.,.) =\n1.219894        -0.07514859     0.6606987\n0.073906526     -1.2547257      -0.49249622\n\n(1,2,1,.,.) =\n-1.0730773      0.2780401       -0.8603222\n-0.31499937     0.94786566      -1.6953986\n\n(1,2,2,.,.) =\n0.31038517      1.7660809       -0.9849316\n-1.5245554      0.24002236      0.473947\n\n(2,1,1,.,.) =\n-0.988634       -0.0028023662   -2.1534977\n0.58303267      0.72106487      0.22115333\n\n(2,1,2,.,.) =\n1.3964092       -0.59152335     -0.6552192\n2.0191588       -0.32599944     0.84014076\n\n(2,2,1,.,.) =\n1.4505147       -2.4253457      -0.37597662\n-0.7049585      1.3384854       -1.1081233\n\n(2,2,2,.,.) =\n-0.8498942      1.169977        0.78120154\n0.13814813      -0.7438999      -0.9272572\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n-0.24269137\n\n(1,2,1,.,.) =\n0.07872025\n\n(2,1,1,.,.) =\n0.3513383\n\n(2,2,1,.,.) =\n-0.078371644\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.95796698 0.76067104 0.47285625]\n    [0.90296063 0.64177821 0.23302549]]\n\n   [[0.37135542 0.38455108 0.66999497]\n    [0.06756778 0.16411331 0.39038159]]]\n\n\n  [[[0.9884323  0.97861344 0.69852249]\n    [0.53289779 0.51290587 0.54822396]]\n\n   [[0.77241923 0.06470524 0.00757586]\n    [0.65977832 0.31973607 0.7551191 ]]]]\n\n\n\n [[[[0.56819589 0.20398916 0.26409867]\n    [0.81165023 0.65269175 0.16519667]]\n\n   [[0.7350688  0.52442381 0.29116889]\n    [0.45458689 0.29734681 0.39667421]]]\n\n\n  [[[0.33577239 0.54035235 0.41285576]\n    [0.01023886 0.23677996 0.18901205]]\n\n   [[0.67638612 0.54170351 0.0068781 ]\n    [0.95769069 0.88558419 0.4262852 ]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.5313706 ]]]\n\n\n  [[[0.603686  ]]]]\n\n\n\n [[[[0.5309942 ]]]\n\n\n  [[[0.52306354]]]]]\n\n\n\n\n\n\n\nGlobalMaxPooling1D\n\n\nGlobal max pooling operation for temporal data.\n\n\nThe input is 3D with the shape:(batch_size, steps, features).\n\n\nScala:\n\n\nGlobalMaxPooling1D(inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling1D(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.2998451       2.1855159       -0.05535197\n-0.6448657      0.74119943      -0.8761581\n\n(2,.,.) =\n1.3994918       -1.5119147      -0.6625015\n1.803635        -2.2516544      -0.016894706\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2998451       2.1855159       -0.05535197\n1.803635        -1.5119147      -0.016894706\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.05589183 0.73674405 0.49270549]\n  [0.03348098 0.82000941 0.81752936]]\n\n [[0.97310222 0.8878789  0.72330625]\n  [0.86144601 0.88568162 0.47241316]]]\n\n\n\n\nOutput is:\n\n\n[[0.05589183 0.8200094  0.8175294 ]\n [0.9731022  0.8878789  0.72330624]]\n\n\n\n\n\n\nMaxPooling3D\n\n\nApplies max pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nMaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxPooling3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]\n\n\n\n\n\n\nGlobalMaxPooling2D\n\n\nGlobal max pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalMaxPooling2D(dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling2D(dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.12648843      0.15536028      1.3401515       -0.25693455\n0.6002777       0.6886729       -1.0650102      -0.22140503\n-0.7598008      0.8800106       -0.061039474    -1.3625065\n\n(1,2,.,.) =\n-0.37492484     -0.6727478      -0.12211597     1.3243467\n-0.72237        0.6942101       -1.455304       -0.23814173\n-0.38509718     -0.9179013      -0.99926376     0.18432678\n\n(2,1,.,.) =\n0.4457857       -0.36717635     -0.6653158      -1.9075912\n-0.49489713     -0.70543754     0.85306334      0.21031244\n0.08930698      0.046588574     0.9523686       -0.87959886\n\n(2,2,.,.) =\n-0.8523849      0.55808693      -1.5779148      1.312412\n-0.9923541      -0.562809       1.1512411       0.33178216\n1.056546        -2.0607772      -0.8233232      0.024466092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3401515       1.3243467\n0.9523686       1.312412\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.82189558 0.20668687 0.84669433 0.58740261]\n   [0.33005685 0.93836385 0.51005935 0.11894048]\n   [0.39757919 0.17126568 0.38237808 0.35911186]]\n\n  [[0.98544456 0.10949685 0.47642379 0.21039236]\n   [0.51058537 0.9625007  0.2519618  0.03186033]\n   [0.28042435 0.08481816 0.37535567 0.60848855]]]\n\n\n [[[0.34468892 0.48365864 0.01397789 0.16565704]\n   [0.91387839 0.78507728 0.0912983  0.06167101]\n   [0.49026863 0.17870698 0.43566122 0.79984653]]\n\n  [[0.15157888 0.07546447 0.47063241 0.46052913]\n   [0.92483801 0.51271677 0.45300461 0.40369727]\n   [0.94152848 0.61306339 0.43241425 0.88775481]]]]\n\n\n\n\nOutput is:\n\n\n[[0.93836385 0.98544455]\n- [0.9138784  0.9415285 ]]\n\n\n\n\n\n\nGlobalMaxPooling3D\n\n\nApplies global max pooling operation for 3D data.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\nThe output of this layer should be 2D, i.e. (batch_size, channels).\n\n\nScala:\n\n\nGlobalMaxPooling3D(dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling3D(dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.50938565  1.6374807   0.8158744\n-0.3293317  -0.17766304 0.9067782\n\n(1,1,2,.,.) =\n1.5450556   -1.0339675  0.056255028\n-0.8867852  -0.05401365 -0.9615863\n\n(1,2,1,.,.) =\n-0.98946816 0.21851462  -0.4431965\n-0.7591889  1.1842074   0.98533714\n\n(1,2,2,.,.) =\n-0.12944926 0.58315176  -1.5754528\n-0.93392104 -0.38259965 0.3566876\n\n(2,1,1,.,.) =\n-0.1219873  -0.06568    0.5519306\n0.32932717  1.4409258   0.68309426\n\n(2,1,2,.,.) =\n-1.4289209  0.47897565  -1.0722001\n-0.64675856 0.7097152   0.31949154\n\n(2,2,1,.,.) =\n-0.89986056 -0.13643691 0.69211197\n0.08849494  0.8695818   1.5527223\n\n(2,2,2,.,.) =\n1.3823601   0.36978078  0.10262361\n0.05734055  -0.41569084 0.009035309\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.6374807   1.1842074\n1.4409258   1.5527223\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[ 0.8402289  0.11503692 0.27831015]\n    [ 0.45756199 0.15043262 0.78778086]]\n\n   [[ 0.37076324 0.65032926 0.74508221]\n    [ 0.32223229 0.81980455 0.14822856]]]\n\n\n  [[[ 0.72858223 0.04609062 0.86802821]\n    [ 0.22619071 0.23091766 0.68856216]]\n\n   [[ 0.54321111 0.94913088 0.59588331]\n    [ 0.90821291 0.42860528 0.39355229]]]]\n\n\n\n [[[[ 0.06834657 0.41250882 0.55612858]\n    [ 0.72871084 0.59139003 0.83317638]]\n\n   [[ 0.99382906 0.24782635 0.27295274]\n    [ 0.65663701 0.7994264  0.73672449]]]\n\n\n  [[[ 0.11487664 0.74224294 0.39289158]\n    [ 0.34253228 0.47903629 0.66238715]]\n\n   [[ 0.13219379 0.12541975 0.93002441]\n    [ 0.58895306 0.38519765 0.27216034]]]]]\n\n\n\n\nOutput is:\n\n\n[[ 0.84022892  0.94913089]\n [ 0.99382907  0.93002439]]\n\n\n\n\n\n\nAveragePooling2D\n\n\nAverage pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAveragePooling2D(poolSize = (2, 2), strides = null, borderMode = \"valid\", dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling2D(pool_size=(2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]\n\n\n\n\n\n\nAveragePooling1D\n\n\nApplies average pooling operation for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAveragePooling1D(poolSize = 2, strides = -1, dimOrdering = \"valid\", inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling1D(pool_length=2, stride=None, border_mode=\"valid\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which average pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. Positive integer, or -1. 2 will halve the input.\n            If -1, it will default to poolLength. Default is -1, and in this case it will\n            be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n2.0454981       -0.9984553      -0.22548687\n-2.9674191      0.61953986      0.9267055\n\n(2,.,.) =\n0.2458116       -0.06563047     0.11032024\n0.29159164      1.0789983       0.6236742\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.4609605      -0.18945771     0.3506093\n\n(2,.,.) =\n0.2687016       0.50668395      0.36699724\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.27910133, 0.62511864, 0.11819567],\n        [0.60144333, 0.17082084, 0.32399398]],\n\n       [[0.44947572, 0.97199261, 0.95654852],\n        [0.72464095, 0.50742734, 0.09491157]]])\n\n\n\n\nOutput is:\n\n\narray([[[0.44027233, 0.39796975, 0.22109482]],\n\n       [[0.5870583 , 0.73971   , 0.52573   ]]], dtype=float32)\n\n\n\n\n\n\nGlobalAveragePooling2D\n\n\nApplies global average pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalAveragePooling2D(dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalAveragePooling2D(dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3)))\nval input = Tensor[Float](2, 2, 3, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3950379      0.23557353      -1.8424573\n0.07449951      0.6322816       0.8831866\n0.8229907       1.5395391       -0.84414214\n\n(1,2,.,.) =\n2.1792102       -1.0315448      -1.1207858\n-1.1498563      1.876386        -0.67528623\n0.54306036      0.7579748       0.09953801\n\n(2,1,.,.) =\n-0.5101911      -1.1826278      -0.5852779\n0.53600776      0.6960143       -2.8790317\n-0.4959711      -1.2831435      -0.09703717\n\n(2,2,.,.) =\n0.5213661       -0.4794566      -0.48301712\n0.3673898       -0.048692267    -0.043640807\n-0.60638505     -0.07805356     1.2334769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.011825972     0.16429958\n-0.64458424     0.04255416\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GlobalAveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 3)))\ninput = np.random.random([2, 2, 3, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.54771885, 0.53283909, 0.46927443],\n         [0.47621227, 0.76883995, 0.52303474],\n         [0.60008681, 0.60752329, 0.98198994]],\n\n        [[0.28667601, 0.47522264, 0.4943029 ],\n         [0.00561534, 0.39171735, 0.23420212],\n         [0.50868123, 0.40796681, 0.82682555]]],\n       [[[0.78836132, 0.58607316, 0.93814738],\n         [0.34578363, 0.32976447, 0.49251034],\n         [0.22992651, 0.04771577, 0.56071013]],\n\n        [[0.34291469, 0.13181605, 0.68202722],\n         [0.16404025, 0.54052442, 0.79312374],\n         [0.0254005 , 0.71477398, 0.94485338]]]])\n\n\n\n\nOutput is:\n\n\narray([[0.61194664, 0.40346777],\n       [0.47988808, 0.4821638 ]], dtype=float32)",
            "title": "Pooling Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling1d",
            "text": "Max pooling operation for temporal data.  The input is 3D tensor with shape:(batch_size, steps, feature_dim).  Scala:  MaxPooling1D(poolLength = 2, stride = -1, borderMode = \"valid\", inputShape = null)  Python:  MaxPooling1D(pool_length=2, stride=None, border_mode=\"valid\", input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which max pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2339195      -1.2134796      0.16991705      -0.10169973     -1.2464932\n0.37946555      0.29533234      -1.2552645      -2.6928735      -0.44519955\n0.98743796      -1.0912303      -0.13897413     1.0241779       -0.5951304\n-0.31459442     -0.088579334    -0.58336115     -0.6427486      -0.1447043\n\n(2,.,.) =\n0.14750746      0.07493488      -0.8554524      -1.6551514      0.16679412\n-0.82279974     0.25704315      0.09921734      -0.8135057      2.7640774\n-1.0111052      0.34388593      -0.7569789      1.0547938       1.6738676\n0.4396624       -1.0570261      0.061429325     1.1752373       -0.14648575\n\n(3,.,.) =\n-0.95818335     0.8790822       -0.99111855     -0.9717616      -0.39238095\n1.2533073       0.23365906      1.7784269       1.0600376       1.6816885\n0.7145845       0.4711851       -0.4465603      -0.77884597     0.484986\n0.42429695      -2.00715        0.6520644       1.3022201       -0.48169184\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.98743796      0.29533234      0.16991705      1.0241779       -0.44519955\n\n(2,.,.) =\n0.14750746      0.34388593      0.09921734      1.0547938       2.7640774\n\n(3,.,.) =\n1.2533073       0.8790822       1.7784269       1.0600376       1.6816885\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192]\n  [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637]\n  [0.24147633 0.2116796  0.54433489 0.22961905 0.88685975]\n  [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]]\n\n [[0.42306184 0.43404804 0.22141668 0.0316458  0.08445576]\n  [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813]\n  [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895]\n  [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]]\n\n [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853]\n  [0.9950283  0.55710408 0.70919634 0.52309929 0.14311439]\n  [0.25394468 0.41519219 0.8074057  0.05341861 0.98447171]\n  [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]]  Output is:  [[[0.27837703 0.8728293  0.9429287  0.48428997 0.8868598 ]]\n\n [[0.9070284  0.43404803 0.52975726 0.43238723 0.50049895]]\n\n [[0.9950283  0.99869156 0.877897   0.6784016  0.98447174]]]",
            "title": "MaxPooling1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling2d",
            "text": "Max pooling operation for spatial data.  The input is 4D tensor with shape:(batch_size, rows, cols, channels). Scala:  MaxPooling2D(poolSize = (2, 2), strides = null, borderMode = \"valid\", dimOrdering = \"th\", inputShape = null)  Python:  MaxPooling2D(pool_size=(2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.02138003      -0.20666665     -0.93250555     0.41267508\n-0.40883347     0.4919021       0.7189889       1.3442185\n-0.08697278     -0.025719838    2.1126  0.69069535\n\n(1,2,.,.) =\n-0.1685801      -0.07843445     1.3499486       -0.5944459\n0.29377022      0.061167963     -0.60608864     -0.08283464\n0.03402891      -1.0627178      1.9463096       0.0011169242\n\n(2,1,.,.) =\n-1.4524128      1.3868454       2.3057284       1.574949\n-1.165581       0.79445213      -0.63500565     -0.17981622\n-0.98042095     -1.7876958      0.8024988       -0.90554804\n\n(2,2,.,.) =\n-1.6468426      1.1864686       -0.683854       -1.5643677\n2.8272789       -0.5537863      -0.563258       -0.01623243\n-0.31333938     0.03472893      -1.730748       -0.15463233\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output:\n(1,1,.,.) =\n0.4919021       1.3442185\n\n(1,2,.,.) =\n0.29377022      1.3499486\n\n(2,1,.,.) =\n1.3868454       2.3057284\n\n(2,2,.,.) =\n2.8272789       -0.01623243\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.58589442 0.94643201 0.24779969 0.55347075]\n   [0.50604116 0.69884915 0.81253572 0.58586743]\n   [0.94560389 0.11573268 0.12562681 0.63301697]]\n\n  [[0.11736968 0.75641404 0.19342809 0.37670404]\n   [0.55561582 0.54354621 0.9506264  0.65929266]\n   [0.72911388 0.00499644 0.24280364 0.28822998]]]\n\n\n [[[0.53249492 0.43969012 0.20407128 0.49541971]\n   [0.00369797 0.75294821 0.15204289 0.41394393]\n   [0.19416915 0.93034988 0.0358259  0.38001445]]\n\n  [[0.88946341 0.30646232 0.5347175  0.87568066]\n   [0.00439823 0.97792811 0.34842225 0.20433116]\n   [0.42777728 0.93583737 0.54341935 0.31203758]]]]  Output is:  [[[[0.946432   0.8125357 ]]\n\n  [[0.75641406 0.95062643]]]\n\n\n [[[0.7529482  0.4954197 ]]\n\n  [[0.9779281  0.8756807 ]]]]",
            "title": "MaxPooling2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling3d",
            "text": "Applies average pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).  Scala:  AveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \"th\", inputShape = null)  Python:  AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.71569425     -0.39595184     -0.47607258\n-0.12621938     -0.66759187     0.86833215\n\n(1,1,2,.,.) =\n1.219894        -0.07514859     0.6606987\n0.073906526     -1.2547257      -0.49249622\n\n(1,2,1,.,.) =\n-1.0730773      0.2780401       -0.8603222\n-0.31499937     0.94786566      -1.6953986\n\n(1,2,2,.,.) =\n0.31038517      1.7660809       -0.9849316\n-1.5245554      0.24002236      0.473947\n\n(2,1,1,.,.) =\n-0.988634       -0.0028023662   -2.1534977\n0.58303267      0.72106487      0.22115333\n\n(2,1,2,.,.) =\n1.3964092       -0.59152335     -0.6552192\n2.0191588       -0.32599944     0.84014076\n\n(2,2,1,.,.) =\n1.4505147       -2.4253457      -0.37597662\n-0.7049585      1.3384854       -1.1081233\n\n(2,2,2,.,.) =\n-0.8498942      1.169977        0.78120154\n0.13814813      -0.7438999      -0.9272572\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n-0.24269137\n\n(1,2,1,.,.) =\n0.07872025\n\n(2,1,1,.,.) =\n0.3513383\n\n(2,2,1,.,.) =\n-0.078371644\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.95796698 0.76067104 0.47285625]\n    [0.90296063 0.64177821 0.23302549]]\n\n   [[0.37135542 0.38455108 0.66999497]\n    [0.06756778 0.16411331 0.39038159]]]\n\n\n  [[[0.9884323  0.97861344 0.69852249]\n    [0.53289779 0.51290587 0.54822396]]\n\n   [[0.77241923 0.06470524 0.00757586]\n    [0.65977832 0.31973607 0.7551191 ]]]]\n\n\n\n [[[[0.56819589 0.20398916 0.26409867]\n    [0.81165023 0.65269175 0.16519667]]\n\n   [[0.7350688  0.52442381 0.29116889]\n    [0.45458689 0.29734681 0.39667421]]]\n\n\n  [[[0.33577239 0.54035235 0.41285576]\n    [0.01023886 0.23677996 0.18901205]]\n\n   [[0.67638612 0.54170351 0.0068781 ]\n    [0.95769069 0.88558419 0.4262852 ]]]]]  Output is:  [[[[[0.5313706 ]]]\n\n\n  [[[0.603686  ]]]]\n\n\n\n [[[[0.5309942 ]]]\n\n\n  [[[0.52306354]]]]]",
            "title": "AveragePooling3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling1d",
            "text": "Global max pooling operation for temporal data.  The input is 3D with the shape:(batch_size, steps, features).  Scala:  GlobalMaxPooling1D(inputShape = null)  Python:  GlobalMaxPooling1D(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.2998451       2.1855159       -0.05535197\n-0.6448657      0.74119943      -0.8761581\n\n(2,.,.) =\n1.3994918       -1.5119147      -0.6625015\n1.803635        -2.2516544      -0.016894706\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2998451       2.1855159       -0.05535197\n1.803635        -1.5119147      -0.016894706\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.05589183 0.73674405 0.49270549]\n  [0.03348098 0.82000941 0.81752936]]\n\n [[0.97310222 0.8878789  0.72330625]\n  [0.86144601 0.88568162 0.47241316]]]  Output is:  [[0.05589183 0.8200094  0.8175294 ]\n [0.9731022  0.8878789  0.72330624]]",
            "title": "GlobalMaxPooling1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling3d",
            "text": "Applies max pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  MaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \"th\", inputShape = null)  Python:  MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxPooling3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]  Output is:  [[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]",
            "title": "MaxPooling3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling2d",
            "text": "Global max pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalMaxPooling2D(dimOrdering = \"th\", inputShape = null)  Python:  GlobalMaxPooling2D(dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.12648843      0.15536028      1.3401515       -0.25693455\n0.6002777       0.6886729       -1.0650102      -0.22140503\n-0.7598008      0.8800106       -0.061039474    -1.3625065\n\n(1,2,.,.) =\n-0.37492484     -0.6727478      -0.12211597     1.3243467\n-0.72237        0.6942101       -1.455304       -0.23814173\n-0.38509718     -0.9179013      -0.99926376     0.18432678\n\n(2,1,.,.) =\n0.4457857       -0.36717635     -0.6653158      -1.9075912\n-0.49489713     -0.70543754     0.85306334      0.21031244\n0.08930698      0.046588574     0.9523686       -0.87959886\n\n(2,2,.,.) =\n-0.8523849      0.55808693      -1.5779148      1.312412\n-0.9923541      -0.562809       1.1512411       0.33178216\n1.056546        -2.0607772      -0.8233232      0.024466092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3401515       1.3243467\n0.9523686       1.312412\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.82189558 0.20668687 0.84669433 0.58740261]\n   [0.33005685 0.93836385 0.51005935 0.11894048]\n   [0.39757919 0.17126568 0.38237808 0.35911186]]\n\n  [[0.98544456 0.10949685 0.47642379 0.21039236]\n   [0.51058537 0.9625007  0.2519618  0.03186033]\n   [0.28042435 0.08481816 0.37535567 0.60848855]]]\n\n\n [[[0.34468892 0.48365864 0.01397789 0.16565704]\n   [0.91387839 0.78507728 0.0912983  0.06167101]\n   [0.49026863 0.17870698 0.43566122 0.79984653]]\n\n  [[0.15157888 0.07546447 0.47063241 0.46052913]\n   [0.92483801 0.51271677 0.45300461 0.40369727]\n   [0.94152848 0.61306339 0.43241425 0.88775481]]]]  Output is:  [[0.93836385 0.98544455]\n- [0.9138784  0.9415285 ]]",
            "title": "GlobalMaxPooling2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling3d",
            "text": "Applies global max pooling operation for 3D data.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\nThe output of this layer should be 2D, i.e. (batch_size, channels).  Scala:  GlobalMaxPooling3D(dimOrdering = \"th\", inputShape = null)  Python:  GlobalMaxPooling3D(dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.50938565  1.6374807   0.8158744\n-0.3293317  -0.17766304 0.9067782\n\n(1,1,2,.,.) =\n1.5450556   -1.0339675  0.056255028\n-0.8867852  -0.05401365 -0.9615863\n\n(1,2,1,.,.) =\n-0.98946816 0.21851462  -0.4431965\n-0.7591889  1.1842074   0.98533714\n\n(1,2,2,.,.) =\n-0.12944926 0.58315176  -1.5754528\n-0.93392104 -0.38259965 0.3566876\n\n(2,1,1,.,.) =\n-0.1219873  -0.06568    0.5519306\n0.32932717  1.4409258   0.68309426\n\n(2,1,2,.,.) =\n-1.4289209  0.47897565  -1.0722001\n-0.64675856 0.7097152   0.31949154\n\n(2,2,1,.,.) =\n-0.89986056 -0.13643691 0.69211197\n0.08849494  0.8695818   1.5527223\n\n(2,2,2,.,.) =\n1.3823601   0.36978078  0.10262361\n0.05734055  -0.41569084 0.009035309\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.6374807   1.1842074\n1.4409258   1.5527223\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[ 0.8402289  0.11503692 0.27831015]\n    [ 0.45756199 0.15043262 0.78778086]]\n\n   [[ 0.37076324 0.65032926 0.74508221]\n    [ 0.32223229 0.81980455 0.14822856]]]\n\n\n  [[[ 0.72858223 0.04609062 0.86802821]\n    [ 0.22619071 0.23091766 0.68856216]]\n\n   [[ 0.54321111 0.94913088 0.59588331]\n    [ 0.90821291 0.42860528 0.39355229]]]]\n\n\n\n [[[[ 0.06834657 0.41250882 0.55612858]\n    [ 0.72871084 0.59139003 0.83317638]]\n\n   [[ 0.99382906 0.24782635 0.27295274]\n    [ 0.65663701 0.7994264  0.73672449]]]\n\n\n  [[[ 0.11487664 0.74224294 0.39289158]\n    [ 0.34253228 0.47903629 0.66238715]]\n\n   [[ 0.13219379 0.12541975 0.93002441]\n    [ 0.58895306 0.38519765 0.27216034]]]]]  Output is:  [[ 0.84022892  0.94913089]\n [ 0.99382907  0.93002439]]",
            "title": "GlobalMaxPooling3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling2d",
            "text": "Average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  AveragePooling2D(poolSize = (2, 2), strides = null, borderMode = \"valid\", dimOrdering = \"th\", inputShape = null)  Python:  AveragePooling2D(pool_size=(2, 2), strides=None, border_mode=\"valid\", dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]  Output is:  [[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]",
            "title": "AveragePooling2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling1d",
            "text": "Applies average pooling operation for temporal data.  The input of this layer should be 3D.  Scala:  AveragePooling1D(poolSize = 2, strides = -1, dimOrdering = \"valid\", inputShape = null)  Python:  AveragePooling1D(pool_length=2, stride=None, border_mode=\"valid\", input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which average pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. Positive integer, or -1. 2 will halve the input.\n            If -1, it will default to poolLength. Default is -1, and in this case it will\n            be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n2.0454981       -0.9984553      -0.22548687\n-2.9674191      0.61953986      0.9267055\n\n(2,.,.) =\n0.2458116       -0.06563047     0.11032024\n0.29159164      1.0789983       0.6236742\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.4609605      -0.18945771     0.3506093\n\n(2,.,.) =\n0.2687016       0.50668395      0.36699724\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.27910133, 0.62511864, 0.11819567],\n        [0.60144333, 0.17082084, 0.32399398]],\n\n       [[0.44947572, 0.97199261, 0.95654852],\n        [0.72464095, 0.50742734, 0.09491157]]])  Output is:  array([[[0.44027233, 0.39796975, 0.22109482]],\n\n       [[0.5870583 , 0.73971   , 0.52573   ]]], dtype=float32)",
            "title": "AveragePooling1D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling2d",
            "text": "Applies global average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalAveragePooling2D(dimOrdering = \"th\", inputShape = null)  Python:  GlobalAveragePooling2D(dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3)))\nval input = Tensor[Float](2, 2, 3, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3950379      0.23557353      -1.8424573\n0.07449951      0.6322816       0.8831866\n0.8229907       1.5395391       -0.84414214\n\n(1,2,.,.) =\n2.1792102       -1.0315448      -1.1207858\n-1.1498563      1.876386        -0.67528623\n0.54306036      0.7579748       0.09953801\n\n(2,1,.,.) =\n-0.5101911      -1.1826278      -0.5852779\n0.53600776      0.6960143       -2.8790317\n-0.4959711      -1.2831435      -0.09703717\n\n(2,2,.,.) =\n0.5213661       -0.4794566      -0.48301712\n0.3673898       -0.048692267    -0.043640807\n-0.60638505     -0.07805356     1.2334769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.011825972     0.16429958\n-0.64458424     0.04255416\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GlobalAveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 3)))\ninput = np.random.random([2, 2, 3, 3])\noutput = model.forward(input)  Input is:  array([[[[0.54771885, 0.53283909, 0.46927443],\n         [0.47621227, 0.76883995, 0.52303474],\n         [0.60008681, 0.60752329, 0.98198994]],\n\n        [[0.28667601, 0.47522264, 0.4943029 ],\n         [0.00561534, 0.39171735, 0.23420212],\n         [0.50868123, 0.40796681, 0.82682555]]],\n       [[[0.78836132, 0.58607316, 0.93814738],\n         [0.34578363, 0.32976447, 0.49251034],\n         [0.22992651, 0.04771577, 0.56071013]],\n\n        [[0.34291469, 0.13181605, 0.68202722],\n         [0.16404025, 0.54052442, 0.79312374],\n         [0.0254005 , 0.71477398, 0.94485338]]]])  Output is:  array([[0.61194664, 0.40346777],\n       [0.47988808, 0.4821638 ]], dtype=float32)",
            "title": "GlobalAveragePooling2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/",
            "text": "SimpleRNN\n\n\nA fully-connected recurrent neural network cell. The output is to be fed back to input.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nSimpleRNN(outputDim, activation = \"tanh\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSimpleRNN(output_dim, activation=\"tanh\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN[Float](8, activation = \"relu\", inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SimpleRNN\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation=\"relu\", input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]\n\n\n\n\nOutput is:\n\n\n[[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]\n\n\n\n\n\n\nLSTM\n\n\nLong Short Term Memory unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nLSTM(outputDim, activation = \"tanh\", innerActivation = \"hard_sigmoid\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nLSTM(output_dim, activation=\"tanh\", inner_activation=\"hard_sigmoid\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6857518   0.21570909  -0.019308459\n0.17754157  0.25172755  -1.189466\n\n(2,.,.) =\n0.23807438  1.6879119   -0.36335373\n0.9826865   0.49549296  0.8100107\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.13552098  -0.043483295    -0.10553853 0.19386405  0.18295142  0.037892513 -0.05510225 -0.2420117\n-0.04152686 -0.13908584 0.18151914  0.14170776  0.15598273  0.18968433  -0.042683482    -0.05782121\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LSTM\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.67619723,  0.5168176 ,  0.8093504 ],\n        [ 0.93787417,  0.53016934,  0.51934568]],\n\n       [[ 0.57334472,  0.40007739,  0.65670337],\n        [ 0.74457042,  0.15209156,  0.02015092]]])\n\n\n\n\nOutput is:\n\n\narray([[-0.01563799,  0.16000053, -0.20192699,  0.08859081, -0.14184587,\n         0.11160418,  0.19090165,  0.03475797],\n       [-0.02395577,  0.10148412, -0.13211192,  0.05772379, -0.16488783,\n         0.13513438,  0.15624164,  0.02866406]], dtype=float32)\n\n\n\n\n\n\nGRU\n\n\nGated Recurrent Unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nGRU(outputDim, activation = \"tanh\", innerActivation = \"hard_sigmoid\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nGRU(output_dim, activation=\"tanh\", inner_activation=\"hard_sigmoid\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GRU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GRU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]\n\n\n\n\nOutput is:\n\n\n[[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]\n\n\n\n\n\n\nHighway\n\n\nDensely connected highway network.\n\n\nHighway layers are a natural extension of LSTMs to feedforward networks.\n\n\nThe input of this layer should be 2D, i.e. (batch, input dim).\n\n\nScala:\n\n\nHighway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nHighway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Highway\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Highway\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Highway(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]\n\n\n\n\nOutput is:\n\n\n[[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]",
            "title": "Recurrent Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#simplernn",
            "text": "A fully-connected recurrent neural network cell. The output is to be fed back to input.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  SimpleRNN(outputDim, activation = \"tanh\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  SimpleRNN(output_dim, activation=\"tanh\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN[Float](8, activation = \"relu\", inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SimpleRNN\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation=\"relu\", input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]  Output is:  [[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]",
            "title": "SimpleRNN"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#lstm",
            "text": "Long Short Term Memory unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  LSTM(outputDim, activation = \"tanh\", innerActivation = \"hard_sigmoid\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  LSTM(output_dim, activation=\"tanh\", inner_activation=\"hard_sigmoid\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6857518   0.21570909  -0.019308459\n0.17754157  0.25172755  -1.189466\n\n(2,.,.) =\n0.23807438  1.6879119   -0.36335373\n0.9826865   0.49549296  0.8100107\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.13552098  -0.043483295    -0.10553853 0.19386405  0.18295142  0.037892513 -0.05510225 -0.2420117\n-0.04152686 -0.13908584 0.18151914  0.14170776  0.15598273  0.18968433  -0.042683482    -0.05782121\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LSTM\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[ 0.67619723,  0.5168176 ,  0.8093504 ],\n        [ 0.93787417,  0.53016934,  0.51934568]],\n\n       [[ 0.57334472,  0.40007739,  0.65670337],\n        [ 0.74457042,  0.15209156,  0.02015092]]])  Output is:  array([[-0.01563799,  0.16000053, -0.20192699,  0.08859081, -0.14184587,\n         0.11160418,  0.19090165,  0.03475797],\n       [-0.02395577,  0.10148412, -0.13211192,  0.05772379, -0.16488783,\n         0.13513438,  0.15624164,  0.02866406]], dtype=float32)",
            "title": "LSTM"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#gru",
            "text": "Gated Recurrent Unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  GRU(outputDim, activation = \"tanh\", innerActivation = \"hard_sigmoid\", returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  GRU(output_dim, activation=\"tanh\", inner_activation=\"hard_sigmoid\", return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.GRU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GRU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]  Output is:  [[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]",
            "title": "GRU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#highway",
            "text": "Densely connected highway network.  Highway layers are a natural extension of LSTMs to feedforward networks.  The input of this layer should be 2D, i.e. (batch, input dim).  Scala:  Highway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Highway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Highway\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Highway\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Highway(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]  Output is:  [[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]",
            "title": "Highway"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/",
            "text": "BatchNormalization\n\n\nBatch normalization layer.\n\n\nNormalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n\n\nIt is a feature-wise normalization, each feature map in the input will be normalized separately.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nBatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = \"zero\", gammaInit = \"one\", dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nBatchNormalization(epsilon=0.001, momentum=0.99, beta_init=\"zero\", gamma_init=\"one\", dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nepsilon\n: Fuzz parameter. Default is 0.001.\n\n\nmomentum\n: Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.\n\n\nbetaInit\n: Name of initialization function for shift parameter. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\ngammaInit\n: Name of initialization function for scale parameter. See \nhere\n for available initialization strings. Default is 'one'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.35774308      -0.0018262876   -1.0186636      -0.8283433\n0.1458402       -0.8954456      0.65028995      0.74481136\n0.46434486      -0.33841616     -0.2882468      0.27368018\n\n(1,2,.,.) =\n-0.85313565     -1.0957539      -0.7689828      1.7338694\n0.66673565      1.0302666       -1.0154791      0.9704916\n-1.518189       0.34307054      -0.8662138      0.53776205\n\n(2,1,.,.) =\n-1.5997988      0.4131082       -0.83005565     1.3930303\n1.061352        -0.6628746      0.8510218       -0.36472544\n1.4967325       -0.082105584    -1.2064567      0.5379558\n\n(2,2,.,.) =\n0.76886225      0.8283977       -2.815423       -1.1129401\n-0.76033413     -0.09757436     -1.1177903      0.057090428\n-1.1909146      1.3031846       1.8407855       2.2742975\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.42506456      -0.016198127    -1.2640586      -1.0304978\n0.16501783      -1.1128457      0.7840774       0.9000738\n0.55588603      -0.4292604      -0.3676927      0.32190278\n\n(1,2,.,.) =\n-0.66352594     -0.8604744      -0.59521383     1.4365083\n0.57024884      0.86534977      -0.7953103      0.8168265\n-1.2033914      0.30750957      -0.6741423      0.4655529\n\n(2,1,.,.) =\n-1.9772263      0.49300852      -1.0325992      1.6955665\n1.2885318       -0.827435       1.030415        -0.4615471\n1.8228296       -0.11471669     -1.4945178      0.6462212\n\n(2,2,.,.) =\n0.6531514       0.7014801       -2.2564375      -0.8744255\n-0.5881931      -0.050189503    -0.8783628      0.0753616\n-0.9377223      1.0868944       1.5232987       1.8752075\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.90728825 0.06248136 0.38908736 0.41036892]\n   [0.32752508 0.19828444 0.16125344 0.71703399]\n   [0.91384765 0.10565062 0.5159064  0.11213003]]\n\n  [[0.45955865 0.37912534 0.11220941 0.6227701 ]\n   [0.74682518 0.31436052 0.35600359 0.46670668]\n   [0.17039808 0.01137162 0.06768781 0.48850118]]]\n\n\n [[[0.41052004 0.51787735 0.22106962 0.72647921]\n   [0.69059405 0.22422016 0.55071537 0.33162262]\n   [0.92135018 0.81511106 0.76329409 0.30857876]]\n\n  [[0.02103797 0.62061211 0.06155861 0.48460782]\n   [0.95476727 0.66571869 0.53735588 0.09358965]\n   [0.32302843 0.29893286 0.56494356 0.14670565]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 1.5911555  -1.4893758  -0.2984292  -0.22082737]\n   [-0.52291185 -0.9941791  -1.1292102   0.8974061 ]\n   [ 1.6150738  -1.3319621   0.16400792 -1.3083354 ]]\n\n  [[ 0.3420891   0.02168216 -1.0415802   0.99224377]\n   [ 1.4864182  -0.2363091  -0.07042356  0.37056333]\n   [-0.809785   -1.4432687  -1.2189325   0.45738205]]]\n\n\n [[[-0.2202763   0.17119484 -0.91109455  0.9318476 ]\n   [ 0.8009946  -0.8996063   0.29093656 -0.5079704 ]\n   [ 1.6424314   1.2550375   1.0660906  -0.59199834]]\n\n  [[-1.4047626   0.98364717 -1.2433482   0.44187275]\n   [ 2.314758    1.1633297   0.6519953  -1.1157522 ]\n   [-0.20178048 -0.2977654   0.761891   -0.9041641 ]]]]\n\n\n\n\n\n\nLRN2D\n\n\nLocal Response Normalization between different feature maps.\n\n\nScala:\n\n\nLRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nLRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Double. The scaling parameter. Default is 0.0001.\n\n\nk\n: Double. A constant. Default is 1.0.\n\n\nbeta\n: Double. The exponent. Default is 0.75.\n\n\nn\n: The number of channels to sum over. Default is 5.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering = \"tf\", inputShape = Shape(3, 3, 3)))\nval input = Tensor[Float](2, 3, 3, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6331058      -1.1622255      -0.20002009\n0.031907756     1.4720777       0.36692062\n0.16142464      -0.87992615     1.9201758\n\n(1,2,.,.) =\n-1.0693451      -1.0901353      0.6909652\n0.13340907      1.0220904       -1.0232266\n-1.4288133      0.8749622       -0.07012164\n\n(1,3,.,.) =\n-0.04984741     -1.4627954      1.2438095\n1.5584376       -0.36223406     -0.862751\n-0.68516856     -0.0066024275   -0.55539906\n\n(2,1,.,.) =\n1.8261654       -0.39168724     0.4531422\n-0.09046966     0.61876625      0.4553172\n0.58150214      -2.6587567      0.46114618\n\n(2,2,.,.) =\n0.75011647      -2.220607       -1.4024881\n-0.5560173      0.19422908      -2.5069134\n-0.7417007      1.3029631       -0.660577\n\n(2,3,.,.) =\n-0.17827246     1.8794266       1.2124214\n0.5774041       0.25620413      0.6461205\n0.33391082      -0.532468       1.3129597\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.5884632      -1.0802679      -0.1859234\n0.02965645      1.3681923       0.34102687\n0.15005784      -0.81763095     1.7842402\n\n(1,2,.,.) =\n-0.9938776      -1.0131469      0.6422488\n0.12401139      0.94998133      -0.95103925\n-1.3279068      0.81316966      -0.065184206\n\n(1,3,.,.) =\n-0.046330474    -1.3593558      1.1558554\n1.4484164       -0.33663353     -0.8019933\n-0.63694555     -0.0061375294   -0.5163186\n\n(2,1,.,.) =\n1.6970686       -0.36398944     0.42125463\n-0.08410302     0.5752084       0.4232657\n0.54015917      -2.469669       0.4283661\n\n(2,2,.,.) =\n0.6969334       -2.0627165      -1.3028492\n-0.5168911      0.18043552      -2.32896\n-0.68936265     1.210961        -0.6139712\n\n(2,3,.,.) =\n-0.16566847     1.7462649       1.1265225\n0.53676987      0.23816296      0.60064477\n0.31041232      -0.49490157     1.2203434\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering=\"tf\", input_shape=(3, 3, 3)))\ninput = np.random.random([2, 3, 3, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.56356835, 0.57442602, 0.31515783],\n   [0.64858065, 0.45682821, 0.63889742],\n   [0.56114806, 0.32727298, 0.54948325]],\n\n  [[0.25249933, 0.27872938, 0.2341261 ],\n   [0.22254477, 0.0855324 , 0.95981825],\n   [0.55280765, 0.722852  , 0.95902286]],\n\n  [[0.65021279, 0.00722661, 0.64386904],\n   [0.36467587, 0.84466816, 0.05716471],\n   [0.16279813, 0.57831132, 0.52848513]]],\n\n\n [[[0.94372659, 0.32741784, 0.03196349],\n   [0.06181632, 0.8300082 , 0.36091632],\n   [0.4961609 , 0.5816011 , 0.95777095]],\n\n  [[0.12676416, 0.32625023, 0.58114797],\n   [0.05347868, 0.5303113 , 0.20170834],\n   [0.76583324, 0.39418884, 0.84815322]],\n\n  [[0.62523604, 0.56888912, 0.69009855],\n   [0.34074716, 0.05078519, 0.05212047],\n   [0.50672308, 0.30567418, 0.47902636]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.5238933 , 0.53398067, 0.2929779 ],\n   [0.602922  , 0.42464924, 0.59392124],\n   [0.52165645, 0.30423048, 0.5108133 ]],\n\n  [[0.23473667, 0.2591199 , 0.21765617],\n   [0.20689127, 0.07950803, 0.8922195 ],\n   [0.51387984, 0.6718813 , 0.89142925]],\n\n  [[0.604453  , 0.00671771, 0.59855634],\n   [0.3389953 , 0.7851862 , 0.05313992],\n   [0.15134202, 0.53759885, 0.49128178]]],\n\n\n [[[0.87725437, 0.30435583, 0.02971505],\n   [0.05746418, 0.77156085, 0.33550152],\n   [0.46123454, 0.54060525, 0.89028406]],\n\n  [[0.11784688, 0.30328864, 0.5402475 ],\n   [0.04971581, 0.4929952 , 0.1875149 ],\n   [0.7119114 , 0.36640498, 0.7884236 ]],\n\n  [[0.58121526, 0.5288076 , 0.64150494],\n   [0.31677726, 0.04721269, 0.04845466],\n   [0.4710655 , 0.28415698, 0.44531912]]]]\n\n\n\n\n\n\nWithinChannelLRN2D\n\n\nThe local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size).\n\n\nScala:\n\n\nWithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null)\n\n\n\n\nPython:\n\n\nWithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: The side length of the square region to sum over. Default is 5.\n\n\nalpha\n: The scaling parameter. Default is 1.0.\n\n\nbeta\n: The exponent. Default is 0.75.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](1, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.11547339     -0.52518076     0.22743009      0.24847448\n-0.72996384     1.5127875       1.285603        -0.8665928\n2.2911248       0.062601104     -0.07974513     -0.26207858\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.089576244    -0.39988548     0.17317083      0.21585277\n-0.5662553      1.1518734       0.97888964      -0.7528196\n1.7772957       0.047666013     -0.060719892    -0.22767082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import WithinChannelLRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WithinChannelLRN2D(input_shape=(3, 4)))\ninput = np.random.random([1, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.96982874, 0.80581477, 0.35435895, 0.45537825],\n  [0.61421818, 0.54708709, 0.86205409, 0.07374387],\n  [0.67227822, 0.25118575, 0.36258901, 0.28671433]]]\n\n\n\n\nOutput is\n\n\n[[[0.87259495, 0.71950066, 0.3164021 , 0.42620906],\n  [0.55263746, 0.48848635, 0.76971596, 0.06902022],\n  [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]",
            "title": "Normalization Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#batchnormalization",
            "text": "Batch normalization layer.  Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.  It is a feature-wise normalization, each feature map in the input will be normalized separately.  The input of this layer should be 4D.  Scala:  BatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = \"zero\", gammaInit = \"one\", dimOrdering = \"th\", inputShape = null)  Python:  BatchNormalization(epsilon=0.001, momentum=0.99, beta_init=\"zero\", gamma_init=\"one\", dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   epsilon : Fuzz parameter. Default is 0.001.  momentum : Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.  betaInit : Name of initialization function for shift parameter. See  here  for available initialization strings. Default is 'zero'.  gammaInit : Name of initialization function for scale parameter. See  here  for available initialization strings. Default is 'one'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.35774308      -0.0018262876   -1.0186636      -0.8283433\n0.1458402       -0.8954456      0.65028995      0.74481136\n0.46434486      -0.33841616     -0.2882468      0.27368018\n\n(1,2,.,.) =\n-0.85313565     -1.0957539      -0.7689828      1.7338694\n0.66673565      1.0302666       -1.0154791      0.9704916\n-1.518189       0.34307054      -0.8662138      0.53776205\n\n(2,1,.,.) =\n-1.5997988      0.4131082       -0.83005565     1.3930303\n1.061352        -0.6628746      0.8510218       -0.36472544\n1.4967325       -0.082105584    -1.2064567      0.5379558\n\n(2,2,.,.) =\n0.76886225      0.8283977       -2.815423       -1.1129401\n-0.76033413     -0.09757436     -1.1177903      0.057090428\n-1.1909146      1.3031846       1.8407855       2.2742975\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.42506456      -0.016198127    -1.2640586      -1.0304978\n0.16501783      -1.1128457      0.7840774       0.9000738\n0.55588603      -0.4292604      -0.3676927      0.32190278\n\n(1,2,.,.) =\n-0.66352594     -0.8604744      -0.59521383     1.4365083\n0.57024884      0.86534977      -0.7953103      0.8168265\n-1.2033914      0.30750957      -0.6741423      0.4655529\n\n(2,1,.,.) =\n-1.9772263      0.49300852      -1.0325992      1.6955665\n1.2885318       -0.827435       1.030415        -0.4615471\n1.8228296       -0.11471669     -1.4945178      0.6462212\n\n(2,2,.,.) =\n0.6531514       0.7014801       -2.2564375      -0.8744255\n-0.5881931      -0.050189503    -0.8783628      0.0753616\n-0.9377223      1.0868944       1.5232987       1.8752075\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.90728825 0.06248136 0.38908736 0.41036892]\n   [0.32752508 0.19828444 0.16125344 0.71703399]\n   [0.91384765 0.10565062 0.5159064  0.11213003]]\n\n  [[0.45955865 0.37912534 0.11220941 0.6227701 ]\n   [0.74682518 0.31436052 0.35600359 0.46670668]\n   [0.17039808 0.01137162 0.06768781 0.48850118]]]\n\n\n [[[0.41052004 0.51787735 0.22106962 0.72647921]\n   [0.69059405 0.22422016 0.55071537 0.33162262]\n   [0.92135018 0.81511106 0.76329409 0.30857876]]\n\n  [[0.02103797 0.62061211 0.06155861 0.48460782]\n   [0.95476727 0.66571869 0.53735588 0.09358965]\n   [0.32302843 0.29893286 0.56494356 0.14670565]]]]  Output is  [[[[ 1.5911555  -1.4893758  -0.2984292  -0.22082737]\n   [-0.52291185 -0.9941791  -1.1292102   0.8974061 ]\n   [ 1.6150738  -1.3319621   0.16400792 -1.3083354 ]]\n\n  [[ 0.3420891   0.02168216 -1.0415802   0.99224377]\n   [ 1.4864182  -0.2363091  -0.07042356  0.37056333]\n   [-0.809785   -1.4432687  -1.2189325   0.45738205]]]\n\n\n [[[-0.2202763   0.17119484 -0.91109455  0.9318476 ]\n   [ 0.8009946  -0.8996063   0.29093656 -0.5079704 ]\n   [ 1.6424314   1.2550375   1.0660906  -0.59199834]]\n\n  [[-1.4047626   0.98364717 -1.2433482   0.44187275]\n   [ 2.314758    1.1633297   0.6519953  -1.1157522 ]\n   [-0.20178048 -0.2977654   0.761891   -0.9041641 ]]]]",
            "title": "BatchNormalization"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#lrn2d",
            "text": "Local Response Normalization between different feature maps.  Scala:  LRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering = \"th\", inputShape = null)  Python:  LRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   alpha : Double. The scaling parameter. Default is 0.0001.  k : Double. A constant. Default is 1.0.  beta : Double. The exponent. Default is 0.75.  n : The number of channels to sum over. Default is 5.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering = \"tf\", inputShape = Shape(3, 3, 3)))\nval input = Tensor[Float](2, 3, 3, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6331058      -1.1622255      -0.20002009\n0.031907756     1.4720777       0.36692062\n0.16142464      -0.87992615     1.9201758\n\n(1,2,.,.) =\n-1.0693451      -1.0901353      0.6909652\n0.13340907      1.0220904       -1.0232266\n-1.4288133      0.8749622       -0.07012164\n\n(1,3,.,.) =\n-0.04984741     -1.4627954      1.2438095\n1.5584376       -0.36223406     -0.862751\n-0.68516856     -0.0066024275   -0.55539906\n\n(2,1,.,.) =\n1.8261654       -0.39168724     0.4531422\n-0.09046966     0.61876625      0.4553172\n0.58150214      -2.6587567      0.46114618\n\n(2,2,.,.) =\n0.75011647      -2.220607       -1.4024881\n-0.5560173      0.19422908      -2.5069134\n-0.7417007      1.3029631       -0.660577\n\n(2,3,.,.) =\n-0.17827246     1.8794266       1.2124214\n0.5774041       0.25620413      0.6461205\n0.33391082      -0.532468       1.3129597\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.5884632      -1.0802679      -0.1859234\n0.02965645      1.3681923       0.34102687\n0.15005784      -0.81763095     1.7842402\n\n(1,2,.,.) =\n-0.9938776      -1.0131469      0.6422488\n0.12401139      0.94998133      -0.95103925\n-1.3279068      0.81316966      -0.065184206\n\n(1,3,.,.) =\n-0.046330474    -1.3593558      1.1558554\n1.4484164       -0.33663353     -0.8019933\n-0.63694555     -0.0061375294   -0.5163186\n\n(2,1,.,.) =\n1.6970686       -0.36398944     0.42125463\n-0.08410302     0.5752084       0.4232657\n0.54015917      -2.469669       0.4283661\n\n(2,2,.,.) =\n0.6969334       -2.0627165      -1.3028492\n-0.5168911      0.18043552      -2.32896\n-0.68936265     1.210961        -0.6139712\n\n(2,3,.,.) =\n-0.16566847     1.7462649       1.1265225\n0.53676987      0.23816296      0.60064477\n0.31041232      -0.49490157     1.2203434\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering=\"tf\", input_shape=(3, 3, 3)))\ninput = np.random.random([2, 3, 3, 3])\noutput = model.forward(input)  Input is:  [[[[0.56356835, 0.57442602, 0.31515783],\n   [0.64858065, 0.45682821, 0.63889742],\n   [0.56114806, 0.32727298, 0.54948325]],\n\n  [[0.25249933, 0.27872938, 0.2341261 ],\n   [0.22254477, 0.0855324 , 0.95981825],\n   [0.55280765, 0.722852  , 0.95902286]],\n\n  [[0.65021279, 0.00722661, 0.64386904],\n   [0.36467587, 0.84466816, 0.05716471],\n   [0.16279813, 0.57831132, 0.52848513]]],\n\n\n [[[0.94372659, 0.32741784, 0.03196349],\n   [0.06181632, 0.8300082 , 0.36091632],\n   [0.4961609 , 0.5816011 , 0.95777095]],\n\n  [[0.12676416, 0.32625023, 0.58114797],\n   [0.05347868, 0.5303113 , 0.20170834],\n   [0.76583324, 0.39418884, 0.84815322]],\n\n  [[0.62523604, 0.56888912, 0.69009855],\n   [0.34074716, 0.05078519, 0.05212047],\n   [0.50672308, 0.30567418, 0.47902636]]]]  Output is  [[[[0.5238933 , 0.53398067, 0.2929779 ],\n   [0.602922  , 0.42464924, 0.59392124],\n   [0.52165645, 0.30423048, 0.5108133 ]],\n\n  [[0.23473667, 0.2591199 , 0.21765617],\n   [0.20689127, 0.07950803, 0.8922195 ],\n   [0.51387984, 0.6718813 , 0.89142925]],\n\n  [[0.604453  , 0.00671771, 0.59855634],\n   [0.3389953 , 0.7851862 , 0.05313992],\n   [0.15134202, 0.53759885, 0.49128178]]],\n\n\n [[[0.87725437, 0.30435583, 0.02971505],\n   [0.05746418, 0.77156085, 0.33550152],\n   [0.46123454, 0.54060525, 0.89028406]],\n\n  [[0.11784688, 0.30328864, 0.5402475 ],\n   [0.04971581, 0.4929952 , 0.1875149 ],\n   [0.7119114 , 0.36640498, 0.7884236 ]],\n\n  [[0.58121526, 0.5288076 , 0.64150494],\n   [0.31677726, 0.04721269, 0.04845466],\n   [0.4710655 , 0.28415698, 0.44531912]]]]",
            "title": "LRN2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#withinchannellrn2d",
            "text": "The local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size).  Scala:  WithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null)  Python:  WithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None)  Parameters:   size : The side length of the square region to sum over. Default is 5.  alpha : The scaling parameter. Default is 1.0.  beta : The exponent. Default is 0.75.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](1, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.11547339     -0.52518076     0.22743009      0.24847448\n-0.72996384     1.5127875       1.285603        -0.8665928\n2.2911248       0.062601104     -0.07974513     -0.26207858\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.089576244    -0.39988548     0.17317083      0.21585277\n-0.5662553      1.1518734       0.97888964      -0.7528196\n1.7772957       0.047666013     -0.060719892    -0.22767082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import WithinChannelLRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WithinChannelLRN2D(input_shape=(3, 4)))\ninput = np.random.random([1, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.96982874, 0.80581477, 0.35435895, 0.45537825],\n  [0.61421818, 0.54708709, 0.86205409, 0.07374387],\n  [0.67227822, 0.25118575, 0.36258901, 0.28671433]]]  Output is  [[[0.87259495, 0.71950066, 0.3164021 , 0.42620906],\n  [0.55263746, 0.48848635, 0.76971596, 0.06902022],\n  [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]",
            "title": "WithinChannelLRN2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/",
            "text": "SparseEmbedding\n\n\nSparseEmbedding is the sparse version of layer Embedding.\n\n\nThe input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors.\nIf the input is a SparseTensor, the values are positive integer ids,\nvalues in each row of this SparseTensor will be turned into a dense vector.\nIf the input is two SparseTensors, the first tensor should be the integer ids, just\nlike the SparseTensor input. And the second tensor is the corresponding\nweights of the integer ids.\n\n\nThis layer can only be used as the first layer in a model, you need to provide the argument\ninputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nSparseEmbedding(inputDim, outputDim, combiner = \"sum\", max_norm = -1.0, init = \"uniform\", wRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSparseEmbedding(input_dim, output_dim, combiner=\"sum\", max_norm=-1.0, init=\"uniform\", W_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputDim\n: Int > 0. Size of the vocabulary.\n\n\noutputDim\n: Int >= 0. Dimension of the dense embedding.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. Default is \"uniform\".\n\n\ncombiner\n: A string specifying the reduce type.\n              Currently \"mean\", \"sum\", \"sqrtn\" is supported.\n\n\nmaxNorm\n: If provided, each embedding is normalized to have l2 norm equal to\n               maxNorm before combining.\n\n\nwRegularizer\n: An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer.\n          If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4,\n  combiner = \"sum\", inputShape = Shape(10))\nlayer.build(Shape(-1, 10))\nval output = layer.forward(input)\n\n\n\n\nInput is:\n\n\ninput: \n(0, 0) : 2.0\n(0, 1) : 4.0\n(1, 0) : 1.0\n(2, 3) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]\n\n\n\n\nOutput is:\n\n\n-0.03674142 -0.01844017 -0.015794257    -0.045957662    \n-0.02645839 -0.024193227    -0.046255145    -0.047514524    \n-0.042759597    0.002117775 -0.041510757    1.9092667E-4    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, )))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\nJTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float\n\n\n\n\nOutput is\n\n\n[[ 0.00771878 -0.05676365  0.03861053  0.04300173]\n [-0.04647886 -0.03346863  0.04642192 -0.0145219 ]\n [ 0.03964841  0.0243053   0.04841208  0.04862341]]\n\n\n\n\n\n\nWordEmbedding\n\n\nEmbedding layer that directly loads pre-trained word vectors as weights.\n\n\nTurn non-negative integers (indices) into dense vectors of fixed size.\n\n\nCurrently only GloVe embedding is supported.\n\n\nThe input of this layer should be 2D.\n\n\nThis layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nWordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)\n\n\n\n\nPython:\n\n\nWordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nembeddingFile\n: The path to the embedding file.\n                   Currently the following GloVe files are supported:\n                   \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\"\n                   \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\".\n                   You can download them from: https://nlp.stanford.edu/projects/glove/.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer).\n               The index is supposed to start from 1 with 0 reserved for unknown words.\n               During the prediction, if you have words that are not in the wordIndex\n               for the training, you can map them to index 0.\n               Default is null. In this case, all the words in the embeddingFile will\n               be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not.\n               Only false is supported for now.\n\n\ninputLength\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = Sequential[Double]()\nmodel.add(WordEmbedding[Double](\"/path/to/glove.6B.50d.txt\", wordIndex = WordEmbedding.getWordIndex(\"/path/to/glove.6B.50d.txt\"), inputLength = 1))\nval input = Tensor(data = Array(0.418), shape = Array(1, 1))\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n0.418\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import WordEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WordEmbedding(\"/path/to/glove.6B.50d.txt\", word_index=WordEmbedding.get_word_index(\"/path/to/glove.6B.50d.txt\"), input_length=1))\ninput = np.random.random([1, 1])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[0.18575166]])\n\n\n\n\nOutput is\n\n\narray([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]]], dtype=float32)",
            "title": "Embedding Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/#sparseembedding",
            "text": "SparseEmbedding is the sparse version of layer Embedding.  The input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors.\nIf the input is a SparseTensor, the values are positive integer ids,\nvalues in each row of this SparseTensor will be turned into a dense vector.\nIf the input is two SparseTensors, the first tensor should be the integer ids, just\nlike the SparseTensor input. And the second tensor is the corresponding\nweights of the integer ids.  This layer can only be used as the first layer in a model, you need to provide the argument\ninputShape (a Single Shape, does not include the batch dimension).  Scala:  SparseEmbedding(inputDim, outputDim, combiner = \"sum\", max_norm = -1.0, init = \"uniform\", wRegularizer = null, inputShape = null)  Python:  SparseEmbedding(input_dim, output_dim, combiner=\"sum\", max_norm=-1.0, init=\"uniform\", W_regularizer=None, input_shape=None, name=None)  Parameters:   inputDim : Int > 0. Size of the vocabulary.  outputDim : Int >= 0. Dimension of the dense embedding.  init : String representation of the initialization method for the weights of the layer. Default is \"uniform\".  combiner : A string specifying the reduce type.\n              Currently \"mean\", \"sum\", \"sqrtn\" is supported.  maxNorm : If provided, each embedding is normalized to have l2 norm equal to\n               maxNorm before combining.  wRegularizer : An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer.\n          If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4,\n  combiner = \"sum\", inputShape = Shape(10))\nlayer.build(Shape(-1, 10))\nval output = layer.forward(input)  Input is:  input: \n(0, 0) : 2.0\n(0, 1) : 4.0\n(1, 0) : 1.0\n(2, 3) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]  Output is:  -0.03674142 -0.01844017 -0.015794257    -0.045957662    \n-0.02645839 -0.024193227    -0.046255145    -0.047514524    \n-0.042759597    0.002117775 -0.041510757    1.9092667E-4    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, )))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)  Input is:  JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float  Output is  [[ 0.00771878 -0.05676365  0.03861053  0.04300173]\n [-0.04647886 -0.03346863  0.04642192 -0.0145219 ]\n [ 0.03964841  0.0243053   0.04841208  0.04862341]]",
            "title": "SparseEmbedding"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/#wordembedding",
            "text": "Embedding layer that directly loads pre-trained word vectors as weights.  Turn non-negative integers (indices) into dense vectors of fixed size.  Currently only GloVe embedding is supported.  The input of this layer should be 2D.  This layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension).  Scala:  WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)  Python:  WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None)  Parameters:   embeddingFile : The path to the embedding file.\n                   Currently the following GloVe files are supported:\n                   \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\"\n                   \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\".\n                   You can download them from: https://nlp.stanford.edu/projects/glove/.  wordIndex : Map of word (String) and its corresponding index (integer).\n               The index is supposed to start from 1 with 0 reserved for unknown words.\n               During the prediction, if you have words that are not in the wordIndex\n               for the training, you can map them to index 0.\n               Default is null. In this case, all the words in the embeddingFile will\n               be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map.  trainable : To configure whether the weights of this layer will be updated or not.\n               Only false is supported for now.  inputLength : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = Sequential[Double]()\nmodel.add(WordEmbedding[Double](\"/path/to/glove.6B.50d.txt\", wordIndex = WordEmbedding.getWordIndex(\"/path/to/glove.6B.50d.txt\"), inputLength = 1))\nval input = Tensor(data = Array(0.418), shape = Array(1, 1))\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n0.418\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import WordEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WordEmbedding(\"/path/to/glove.6B.50d.txt\", word_index=WordEmbedding.get_word_index(\"/path/to/glove.6B.50d.txt\"), input_length=1))\ninput = np.random.random([1, 1])\noutput = model.forward(input)  Input is:  array([[0.18575166]])  Output is  array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]]], dtype=float32)",
            "title": "WordEmbedding"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/",
            "text": "SpatialDropout3D\n\n\nSpatial 3D version of Dropout.\n\n\nThis version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.\n\n\nThe input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3)\n\n\nScala:\n\n\nSpatialDropout3D(p = 0.5, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout3D(p=0.5, dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.5842006       -1.486708       -1.0261744\n-0.8227147      0.1386223       -0.46191332\n\n(1,1,2,.,.) =\n-0.7794714      0.52259976      1.5326598\n0.32597166      0.84018683      -0.24034925\n\n(1,2,1,.,.) =\n0.5037644       -0.42065156     1.1590574\n1.4855213       -1.4098096      0.5154563\n\n(1,2,2,.,.) =\n2.1119535       0.4159602       -0.33109334\n-1.9544226      0.014503485     -0.7715549\n\n(2,1,1,.,.) =\n1.1496683       0.20273614      -2.6363356\n-1.6820912      -1.1656585      -0.8387814\n\n(2,1,2,.,.) =\n-1.1125584      -1.9073812      0.78532314\n-1.0033096      -0.24038585     1.0534006\n\n(2,2,1,.,.) =\n0.46944886      -1.8767697      0.7275591\n0.36211884      0.34403932      -1.3721423\n\n(2,2,2,.,.) =\n0.37117565      -0.45195773     0.66517854\n0.3873176       -1.8218406      1.9105781\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     -0.0    -0.0\n-0.0    0.0     -0.0\n\n(1,1,2,.,.) =\n-0.0    0.0     0.0\n0.0     0.0     -0.0\n\n(1,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n(1,2,2,.,.) =\n0.0     0.0     -0.0\n-0.0    0.0     -0.0\n\n(2,1,1,.,.) =\n0.0     0.0     -0.0\n-0.0    -0.0    -0.0\n\n(2,1,2,.,.) =\n-0.0    -0.0    0.0\n-0.0    -0.0    0.0\n\n(2,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     0.0     -0.0\n\n(2,2,2,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.19861794 0.32822715]\n    [0.78735804 0.0586697 ]]\n\n   [[0.22181565 0.09894792]\n    [0.43668179 0.22321872]]]\n\n\n  [[[0.81122679 0.44084158]\n    [0.70199098 0.10383273]]\n\n   [[0.78102397 0.62514588]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.22229716 0.90939922]\n    [0.2453606  0.49500498]]\n\n   [[0.95518136 0.78983711]\n    [0.724247   0.62801332]]]\n\n\n  [[[0.89800761 0.5523274 ]\n    [0.83153558 0.58200981]]\n\n   [[0.84787731 0.16651971]\n    [0.22528241 0.68706778]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.19861795 0.32822713]\n    [0.78735805 0.0586697 ]]\n\n   [[0.22181565 0.09894791]\n    [0.43668178 0.22321871]]]\n\n\n  [[[0.8112268  0.4408416 ]\n    [0.70199096 0.10383273]]\n\n   [[0.781024   0.62514585]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.         0.        ]\n    [0.         0.        ]]\n\n   [[0.         0.        ]\n    [0.         0.        ]]]\n\n\n  [[[0.89800763 0.5523274 ]\n    [0.8315356  0.5820098 ]]\n\n   [[0.8478773  0.16651972]\n    [0.22528242 0.6870678 ]]]]]\n\n\n\n\n\n\nDropout\n\n\nApplies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.\n\n\nScala:\n\n\nDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout[Float](0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.5496527       0.34846303      1.8184849       -0.8750735\n-0.2907603      0.124056354     -0.5447822      -0.34512782\n1.003834        -0.27847317     -0.16524693     -0.12172801\n\n(2,.,.) =\n-0.50297844     -0.78188837     -1.5617784      -1.2353797\n-1.5052266      -1.6246556      0.5203618       1.144502\n-0.18044183     -0.032648038    -1.9599762      -0.6970337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n2.2137897       0.49780434      2.5978355       -1.250105\n0.0     0.17722337      0.0     0.0\n1.4340487       0.0     0.0     -0.17389716\n\n(2,.,.) =\n-0.71854067     -1.1169834      -2.231112       -1.7648282\n-2.1503239      -2.3209367      0.743374        1.635003\n-0.25777406     0.0     -2.799966       -0.99576247\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Dropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815],\n        [0.70987046, 0.11246564, 0.68062359, 0.48074257],\n        [0.61979472, 0.36682032, 0.08320745, 0.41117697]],\n\n       [[0.19616717, 0.18093539, 0.52080897, 0.73326568],\n        [0.72752776, 0.81963229, 0.05652756, 0.37253947],\n        [0.70200807, 0.27836313, 0.24421078, 0.58191582]]])\n\n\n\n\nOutput is\n\n\narray([[[1.1523907 , 0.7672588 , 0.        , 0.6953831 ],\n        [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ],\n        [0.        , 0.5240291 , 0.11886779, 0.58739567]],\n\n       [[0.2802388 , 0.        , 0.74401283, 1.0475224 ],\n        [1.0393254 , 1.1709033 , 0.08075366, 0.53219926],\n        [1.0028687 , 0.39766163, 0.        , 0.8313083 ]]], dtype=float32)\n\n\n\n\n\n\nGaussianDropout\n\n\nApply multiplicative 1-centered Gaussian noise.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8969221   2.454179    -0.26737544 0.86235714\n-0.61781764 -0.48739514 0.2337097   1.0086832\n1.7666794   -1.120229   -0.28245732 0.845279\n\n(2,.,.) =\n1.2763704   -0.3854067  0.0061038486    0.931373\n0.67848265  -3.098805   -0.1240183  0.36834922\n0.9772534   -0.639048   -0.078967154    1.4179249\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.8251847   4.3458977   -0.6353459  -0.10734326\n-0.4009521  -0.5479114  0.1226105   2.0534828\n-0.03313    -2.271632   0.122886114 -0.44396263\n\n(2,.,.) =\n0.45101312  -0.48233575 0.008046541 2.2945886\n1.3415622   -1.9070724  -0.1681036  0.60575134\n0.88338673  -1.4186113  -0.012104415    0.3102114\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianDropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.55167758,  0.07427833,  0.59777983,  0.86986969],\n        [ 0.53097779,  0.4174687 ,  0.58065922,  0.73479602],\n        [ 0.43731939,  0.64465237,  0.32946076,  0.59878638]],\n\n       [[ 0.26428987,  0.29575131,  0.36229906,  0.66938424],\n        [ 0.74325536,  0.08672916,  0.35460851,  0.00122828],\n        [ 0.27095285,  0.09442922,  0.02280022,  0.68735133]]])\n\n\n\n\nOutput is\n\n\narray([[[  1.29282939e+00,   7.24226162e-02,   5.17048061e-01,\n           8.93751144e-01],\n        [  5.48077464e-01,  -1.90222517e-01,   4.40389782e-01,\n           1.86340976e+00],\n        [  4.28632259e-01,   1.25118005e+00,   4.43376899e-01,\n           1.07255065e+00]],\n\n       [[ -4.06714790e-02,   9.10973027e-02,   1.28347218e+00,\n           1.03069496e+00],\n        [  2.37148595e+00,   3.56667452e-02,   1.25722930e-01,\n           1.17819163e-05],\n        [  3.79356921e-01,   8.55060294e-02,   3.33660096e-02,\n           3.40193957e-02]]], dtype=float32)\n\n\n\n\n\n\nSpatialDropout2D\n\n\nSpatial 2D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.\n\n\nThe input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last).\n\n\nScala:\n\n\nSpatialDropout2D(p = 0.5, dimOrdering = \"th\", inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout2D(p=0.5, dim_ordering=\"th\", input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.266674        -0.19261484     0.8210725       -0.22291088\n-0.38138267     1.7019615       1.1729054       0.59097356\n-0.50952524     -1.9868233      -0.17180282     -1.2743127\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     -0.0    0.0     -0.0\n-0.0    0.0     0.0     0.0\n-0.0    -0.0    -0.0    -0.0\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.45638721 0.87479404 0.28319946 0.85046252]\n   [0.90687581 0.29446766 0.23341603 0.92425726]\n   [0.51232495 0.83895807 0.90536451 0.41231943]]\n\n  [[0.00397271 0.28512243 0.32912336 0.27304027]\n   [0.97274043 0.92907157 0.25843125 0.201849  ]\n   [0.42783297 0.91400856 0.19290376 0.83749261]]]\n\n\n [[[0.03282751 0.60866148 0.47616452 0.4300911 ]\n   [0.75731354 0.34609462 0.66514783 0.18193801]\n   [0.6748754  0.94068849 0.38504096 0.66447561]]\n\n  [[0.61274329 0.56573389 0.21795374 0.45314279]\n   [0.2883045  0.22641016 0.83014439 0.21362862]\n   [0.33618578 0.47346473 0.96971251 0.2937416 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.45638722 0.87479407 0.28319946 0.8504625 ]\n   [0.9068758  0.29446766 0.23341602 0.9242573 ]\n   [0.5123249  0.8389581  0.9053645  0.41231942]]\n\n  [[0.00397271 0.28512242 0.32912338 0.27304026]\n   [0.9727404  0.92907155 0.25843126 0.201849  ]\n   [0.42783296 0.91400856 0.19290376 0.8374926 ]]]\n\n\n [[[0.03282751 0.6086615  0.47616452 0.4300911 ]\n   [0.75731355 0.3460946  0.66514784 0.18193801]\n   [0.6748754  0.9406885  0.38504097 0.6644756 ]]\n\n  [[0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]]]]\n\n\n\n\n\n\nGaussianNoise\n\n\nApply additive zero-centered Gaussian noise.\n\n\nThis is useful to mitigate overfitting (you could see it as a form of random data augmentation).\n\n\nGaussian Noise is a natural choice as corruption process for real valued inputs.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianNoise(sigma, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianNoise(sigma, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsigma\n: Standard deviation of the noise distribution.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.57896155     -0.19616802     1.7000706       -2.2136402\n0.2245884       -0.167104       0.08521592      -0.31111532\n-1.2676435      1.9858241       -0.27946314     -0.72280097\n\n(2,.,.) =\n1.263968        -0.1366611      0.7511876       -0.42096275\n-0.2524562      -2.082302       -1.3312799      0.035666652\n-1.6895409      -0.8562052      0.69322604      -0.080461726\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.25664312     0.1474515       2.066732        -1.5476861\n0.34144306      1.1049318       0.4146787       -0.15529981\n-1.3980585      2.0075183       0.09995845      -0.9865419\n\n(2,.,.) =\n0.8450401       0.0076646805    0.5062498       -0.5671178\n0.89790833      -2.1620805      -1.5945435      -0.74607164\n-1.7677919      -0.6946467      0.35671985      0.9388765\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianNoise\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.87836839, 0.29835789, 0.99199298, 0.61462649],\n        [0.24045628, 0.9334569 , 0.69817451, 0.80795268],\n        [0.82978091, 0.32160601, 0.97033687, 0.34726345]],\n\n       [[0.11581215, 0.2012782 , 0.89101947, 0.24642749],\n        [0.51231345, 0.47586449, 0.53419205, 0.71586367],\n        [0.88794988, 0.20960408, 0.46741968, 0.31609195]]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.9021132 ,  0.05798048,  0.9235187 ,  0.8105377 ],\n        [ 0.82122934,  0.87509984,  1.3449373 ,  0.115228  ],\n        [ 0.2612275 ,  0.02238336,  0.8971698 ,  0.3349191 ]],\n\n       [[-0.7950512 , -0.4547084 ,  1.6517348 ,  1.5761411 ],\n        [ 0.9232183 ,  0.33405185,  0.6043875 ,  0.54677534],\n        [ 1.4350419 , -1.4409285 , -0.31246042,  0.5502143 ]]],\n      dtype=float32)",
            "title": "Dropout Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout3d",
            "text": "Spatial 3D version of Dropout.  This version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.  The input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3)  Scala:  SpatialDropout3D(p = 0.5, dimOrdering = \"th\", inputShape = null)  Python:  SpatialDropout3D(p=0.5, dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.5842006       -1.486708       -1.0261744\n-0.8227147      0.1386223       -0.46191332\n\n(1,1,2,.,.) =\n-0.7794714      0.52259976      1.5326598\n0.32597166      0.84018683      -0.24034925\n\n(1,2,1,.,.) =\n0.5037644       -0.42065156     1.1590574\n1.4855213       -1.4098096      0.5154563\n\n(1,2,2,.,.) =\n2.1119535       0.4159602       -0.33109334\n-1.9544226      0.014503485     -0.7715549\n\n(2,1,1,.,.) =\n1.1496683       0.20273614      -2.6363356\n-1.6820912      -1.1656585      -0.8387814\n\n(2,1,2,.,.) =\n-1.1125584      -1.9073812      0.78532314\n-1.0033096      -0.24038585     1.0534006\n\n(2,2,1,.,.) =\n0.46944886      -1.8767697      0.7275591\n0.36211884      0.34403932      -1.3721423\n\n(2,2,2,.,.) =\n0.37117565      -0.45195773     0.66517854\n0.3873176       -1.8218406      1.9105781\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     -0.0    -0.0\n-0.0    0.0     -0.0\n\n(1,1,2,.,.) =\n-0.0    0.0     0.0\n0.0     0.0     -0.0\n\n(1,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n(1,2,2,.,.) =\n0.0     0.0     -0.0\n-0.0    0.0     -0.0\n\n(2,1,1,.,.) =\n0.0     0.0     -0.0\n-0.0    -0.0    -0.0\n\n(2,1,2,.,.) =\n-0.0    -0.0    0.0\n-0.0    -0.0    0.0\n\n(2,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     0.0     -0.0\n\n(2,2,2,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.19861794 0.32822715]\n    [0.78735804 0.0586697 ]]\n\n   [[0.22181565 0.09894792]\n    [0.43668179 0.22321872]]]\n\n\n  [[[0.81122679 0.44084158]\n    [0.70199098 0.10383273]]\n\n   [[0.78102397 0.62514588]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.22229716 0.90939922]\n    [0.2453606  0.49500498]]\n\n   [[0.95518136 0.78983711]\n    [0.724247   0.62801332]]]\n\n\n  [[[0.89800761 0.5523274 ]\n    [0.83153558 0.58200981]]\n\n   [[0.84787731 0.16651971]\n    [0.22528241 0.68706778]]]]]  Output is  [[[[[0.19861795 0.32822713]\n    [0.78735805 0.0586697 ]]\n\n   [[0.22181565 0.09894791]\n    [0.43668178 0.22321871]]]\n\n\n  [[[0.8112268  0.4408416 ]\n    [0.70199096 0.10383273]]\n\n   [[0.781024   0.62514585]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.         0.        ]\n    [0.         0.        ]]\n\n   [[0.         0.        ]\n    [0.         0.        ]]]\n\n\n  [[[0.89800763 0.5523274 ]\n    [0.8315356  0.5820098 ]]\n\n   [[0.8478773  0.16651972]\n    [0.22528242 0.6870678 ]]]]]",
            "title": "SpatialDropout3D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#dropout",
            "text": "Applies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.  Scala:  Dropout(p, inputShape = null)  Python:  Dropout(p, input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout[Float](0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.5496527       0.34846303      1.8184849       -0.8750735\n-0.2907603      0.124056354     -0.5447822      -0.34512782\n1.003834        -0.27847317     -0.16524693     -0.12172801\n\n(2,.,.) =\n-0.50297844     -0.78188837     -1.5617784      -1.2353797\n-1.5052266      -1.6246556      0.5203618       1.144502\n-0.18044183     -0.032648038    -1.9599762      -0.6970337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n2.2137897       0.49780434      2.5978355       -1.250105\n0.0     0.17722337      0.0     0.0\n1.4340487       0.0     0.0     -0.17389716\n\n(2,.,.) =\n-0.71854067     -1.1169834      -2.231112       -1.7648282\n-2.1503239      -2.3209367      0.743374        1.635003\n-0.25777406     0.0     -2.799966       -0.99576247\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Dropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815],\n        [0.70987046, 0.11246564, 0.68062359, 0.48074257],\n        [0.61979472, 0.36682032, 0.08320745, 0.41117697]],\n\n       [[0.19616717, 0.18093539, 0.52080897, 0.73326568],\n        [0.72752776, 0.81963229, 0.05652756, 0.37253947],\n        [0.70200807, 0.27836313, 0.24421078, 0.58191582]]])  Output is  array([[[1.1523907 , 0.7672588 , 0.        , 0.6953831 ],\n        [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ],\n        [0.        , 0.5240291 , 0.11886779, 0.58739567]],\n\n       [[0.2802388 , 0.        , 0.74401283, 1.0475224 ],\n        [1.0393254 , 1.1709033 , 0.08075366, 0.53219926],\n        [1.0028687 , 0.39766163, 0.        , 0.8313083 ]]], dtype=float32)",
            "title": "Dropout"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiandropout",
            "text": "Apply multiplicative 1-centered Gaussian noise.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianDropout(p, inputShape = null)  Python:  GaussianDropout(p, input_shape=None, name=None)  Parameters:   p : Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8969221   2.454179    -0.26737544 0.86235714\n-0.61781764 -0.48739514 0.2337097   1.0086832\n1.7666794   -1.120229   -0.28245732 0.845279\n\n(2,.,.) =\n1.2763704   -0.3854067  0.0061038486    0.931373\n0.67848265  -3.098805   -0.1240183  0.36834922\n0.9772534   -0.639048   -0.078967154    1.4179249\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.8251847   4.3458977   -0.6353459  -0.10734326\n-0.4009521  -0.5479114  0.1226105   2.0534828\n-0.03313    -2.271632   0.122886114 -0.44396263\n\n(2,.,.) =\n0.45101312  -0.48233575 0.008046541 2.2945886\n1.3415622   -1.9070724  -0.1681036  0.60575134\n0.88338673  -1.4186113  -0.012104415    0.3102114\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianDropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.55167758,  0.07427833,  0.59777983,  0.86986969],\n        [ 0.53097779,  0.4174687 ,  0.58065922,  0.73479602],\n        [ 0.43731939,  0.64465237,  0.32946076,  0.59878638]],\n\n       [[ 0.26428987,  0.29575131,  0.36229906,  0.66938424],\n        [ 0.74325536,  0.08672916,  0.35460851,  0.00122828],\n        [ 0.27095285,  0.09442922,  0.02280022,  0.68735133]]])  Output is  array([[[  1.29282939e+00,   7.24226162e-02,   5.17048061e-01,\n           8.93751144e-01],\n        [  5.48077464e-01,  -1.90222517e-01,   4.40389782e-01,\n           1.86340976e+00],\n        [  4.28632259e-01,   1.25118005e+00,   4.43376899e-01,\n           1.07255065e+00]],\n\n       [[ -4.06714790e-02,   9.10973027e-02,   1.28347218e+00,\n           1.03069496e+00],\n        [  2.37148595e+00,   3.56667452e-02,   1.25722930e-01,\n           1.17819163e-05],\n        [  3.79356921e-01,   8.55060294e-02,   3.33660096e-02,\n           3.40193957e-02]]], dtype=float32)",
            "title": "GaussianDropout"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout2d",
            "text": "Spatial 2D version of Dropout.  This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.  The input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last).  Scala:  SpatialDropout2D(p = 0.5, dimOrdering = \"th\", inputShape = null)  Python:  SpatialDropout2D(p=0.5, dim_ordering=\"th\", input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.266674        -0.19261484     0.8210725       -0.22291088\n-0.38138267     1.7019615       1.1729054       0.59097356\n-0.50952524     -1.9868233      -0.17180282     -1.2743127\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     -0.0    0.0     -0.0\n-0.0    0.0     0.0     0.0\n-0.0    -0.0    -0.0    -0.0\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.45638721 0.87479404 0.28319946 0.85046252]\n   [0.90687581 0.29446766 0.23341603 0.92425726]\n   [0.51232495 0.83895807 0.90536451 0.41231943]]\n\n  [[0.00397271 0.28512243 0.32912336 0.27304027]\n   [0.97274043 0.92907157 0.25843125 0.201849  ]\n   [0.42783297 0.91400856 0.19290376 0.83749261]]]\n\n\n [[[0.03282751 0.60866148 0.47616452 0.4300911 ]\n   [0.75731354 0.34609462 0.66514783 0.18193801]\n   [0.6748754  0.94068849 0.38504096 0.66447561]]\n\n  [[0.61274329 0.56573389 0.21795374 0.45314279]\n   [0.2883045  0.22641016 0.83014439 0.21362862]\n   [0.33618578 0.47346473 0.96971251 0.2937416 ]]]]  Output is  [[[[0.45638722 0.87479407 0.28319946 0.8504625 ]\n   [0.9068758  0.29446766 0.23341602 0.9242573 ]\n   [0.5123249  0.8389581  0.9053645  0.41231942]]\n\n  [[0.00397271 0.28512242 0.32912338 0.27304026]\n   [0.9727404  0.92907155 0.25843126 0.201849  ]\n   [0.42783296 0.91400856 0.19290376 0.8374926 ]]]\n\n\n [[[0.03282751 0.6086615  0.47616452 0.4300911 ]\n   [0.75731355 0.3460946  0.66514784 0.18193801]\n   [0.6748754  0.9406885  0.38504097 0.6644756 ]]\n\n  [[0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]]]]",
            "title": "SpatialDropout2D"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiannoise",
            "text": "Apply additive zero-centered Gaussian noise.  This is useful to mitigate overfitting (you could see it as a form of random data augmentation).  Gaussian Noise is a natural choice as corruption process for real valued inputs.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianNoise(sigma, inputShape = null)  Python:  GaussianNoise(sigma, input_shape=None, name=None)  Parameters:   sigma : Standard deviation of the noise distribution.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.57896155     -0.19616802     1.7000706       -2.2136402\n0.2245884       -0.167104       0.08521592      -0.31111532\n-1.2676435      1.9858241       -0.27946314     -0.72280097\n\n(2,.,.) =\n1.263968        -0.1366611      0.7511876       -0.42096275\n-0.2524562      -2.082302       -1.3312799      0.035666652\n-1.6895409      -0.8562052      0.69322604      -0.080461726\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.25664312     0.1474515       2.066732        -1.5476861\n0.34144306      1.1049318       0.4146787       -0.15529981\n-1.3980585      2.0075183       0.09995845      -0.9865419\n\n(2,.,.) =\n0.8450401       0.0076646805    0.5062498       -0.5671178\n0.89790833      -2.1620805      -1.5945435      -0.74607164\n-1.7677919      -0.6946467      0.35671985      0.9388765\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianNoise\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[0.87836839, 0.29835789, 0.99199298, 0.61462649],\n        [0.24045628, 0.9334569 , 0.69817451, 0.80795268],\n        [0.82978091, 0.32160601, 0.97033687, 0.34726345]],\n\n       [[0.11581215, 0.2012782 , 0.89101947, 0.24642749],\n        [0.51231345, 0.47586449, 0.53419205, 0.71586367],\n        [0.88794988, 0.20960408, 0.46741968, 0.31609195]]])  Output is  array([[[ 0.9021132 ,  0.05798048,  0.9235187 ,  0.8105377 ],\n        [ 0.82122934,  0.87509984,  1.3449373 ,  0.115228  ],\n        [ 0.2612275 ,  0.02238336,  0.8971698 ,  0.3349191 ]],\n\n       [[-0.7950512 , -0.4547084 ,  1.6517348 ,  1.5761411 ],\n        [ 0.9232183 ,  0.33405185,  0.6043875 ,  0.54677534],\n        [ 1.4350419 , -1.4409285 , -0.31246042,  0.5502143 ]]],\n      dtype=float32)",
            "title": "GaussianNoise"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/",
            "text": "PReLU\n\n\nApplies parametric ReLU, where parameter varies the slope of the negative part.\n\n\nIt follows: f(x) = max(0, x) + a * min(0, x)\n\n\nScala:\n\n\nPReLU(nOutputPlane = 0, inputShape = null)\n\n\n\n\nPython:\n\n\nPReLU(nOutputPlane=0, input_shape=None)\n\n\n\n\nParameters:\n\n\n\n\nnOutputPlane\n: Input map number. Default is 0,\n                  which means using PReLU in shared version and has only one parameter.\n\n\ninputShape\n:  A Single Shape, does not include the batch dimension.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(PReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.9026888      -1.0402212      1.3878769\n-0.17167428     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.2256722      -0.2600553      1.3878769\n-0.04291857     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import PReLU\n\nmodel = Sequential()\nmodel.add(PReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.61639702 0.08877075 0.93652509]\n [0.38800821 0.76286851 0.95777973]]\n\n\n\n\nOutput is\n\n\n[[0.616397   0.08877075 0.9365251 ]\n [0.3880082  0.7628685  0.9577797 ]]\n\n\n\n\n\n\nELU\n\n\nExponential Linear Unit.\n\n\nIt follows: f(x) =  alpha * (exp(x) - 1.) for x < 0, f(x) = x for x >= 0.\n\n\nScala:\n\n\nELU(alpha = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nELU(alpha=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Scale for the negative factor. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]\n\n\n\n\nOutput is\n\n\n[[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]\n\n\n\n\n\n\nSReLU\n\n\nS-shaped Rectified Linear Unit.\n\n\nIt follows: f(x) = t^r + a^r(x - t^r) for x >= t^r, f(x) = x for t^r > x > t^l, f(x) = t^l + a^l(x - t^l) for x <= t^l.\n\n\nScala:\n\n\nSReLU(tLeftInit = \"zero\", aLeftInit = \"glorot_uniform\", tRightInit = \"glorot_uniform\", aRightInit = \"one\", sharedAxes = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSReLU(t_left_init=\"zero\", a_left_init=\"glorot_uniform\", t_right_init=\"glorot_uniform\", a_right_init=\"one\", shared_axes=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntLeftInit\n: String representation of the initialization method for the left part intercept. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\naLeftInit\n: String representation of the initialization method for the left part slope. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\ntRightInit\n: String representation of ithe nitialization method for the right part intercept. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\naRightInit\n: String representation of the initialization method for the right part slope. See \nhere\n for available initialization strings. Default is 'one'.\n\n\nsharedAxes\n: The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]\n\n\n\n\nOutput is\n\n\n[[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]\n\n\n\n\n\n\nThresholdedReLU\n\n\nThresholded Rectified Linear Unit.\n\n\nIt follows: f(x) = x for x > theta, f(x) = 0 otherwise.\n\n\nScala:\n\n\nThresholdedReLU(theta = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nThresholdedReLU(theta=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntheta\n: Threshold location of activation. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ThresholdedReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]\n\n\n\n\nOutput is\n\n\n[[0.0   0.0   0.0]\n [0.0   0.0   0.0]]",
            "title": "Advanced Activations"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#prelu",
            "text": "Applies parametric ReLU, where parameter varies the slope of the negative part.  It follows: f(x) = max(0, x) + a * min(0, x)  Scala:  PReLU(nOutputPlane = 0, inputShape = null)  Python:  PReLU(nOutputPlane=0, input_shape=None)  Parameters:   nOutputPlane : Input map number. Default is 0,\n                  which means using PReLU in shared version and has only one parameter.  inputShape :  A Single Shape, does not include the batch dimension.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(PReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.9026888      -1.0402212      1.3878769\n-0.17167428     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.2256722      -0.2600553      1.3878769\n-0.04291857     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import PReLU\n\nmodel = Sequential()\nmodel.add(PReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.61639702 0.08877075 0.93652509]\n [0.38800821 0.76286851 0.95777973]]  Output is  [[0.616397   0.08877075 0.9365251 ]\n [0.3880082  0.7628685  0.9577797 ]]",
            "title": "PReLU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#elu",
            "text": "Exponential Linear Unit.  It follows: f(x) =  alpha * (exp(x) - 1.) for x < 0, f(x) = x for x >= 0.  Scala:  ELU(alpha = 1.0, inputShape = null)  Python:  ELU(alpha=1.0, input_shape=None, name=None)  Parameters:   alpha : Scale for the negative factor. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]  Output is  [[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]",
            "title": "ELU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#srelu",
            "text": "S-shaped Rectified Linear Unit.  It follows: f(x) = t^r + a^r(x - t^r) for x >= t^r, f(x) = x for t^r > x > t^l, f(x) = t^l + a^l(x - t^l) for x <= t^l.  Scala:  SReLU(tLeftInit = \"zero\", aLeftInit = \"glorot_uniform\", tRightInit = \"glorot_uniform\", aRightInit = \"one\", sharedAxes = null, inputShape = null)  Python:  SReLU(t_left_init=\"zero\", a_left_init=\"glorot_uniform\", t_right_init=\"glorot_uniform\", a_right_init=\"one\", shared_axes=None, input_shape=None, name=None)  Parameters:   tLeftInit : String representation of the initialization method for the left part intercept. See  here  for available initialization strings. Default is 'zero'.  aLeftInit : String representation of the initialization method for the left part slope. See  here  for available initialization strings. Default is 'glorot_uniform'.  tRightInit : String representation of ithe nitialization method for the right part intercept. See  here  for available initialization strings. Default is 'glorot_uniform'.  aRightInit : String representation of the initialization method for the right part slope. See  here  for available initialization strings. Default is 'one'.  sharedAxes : The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]  Output is  [[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]",
            "title": "SReLU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#thresholdedrelu",
            "text": "Thresholded Rectified Linear Unit.  It follows: f(x) = x for x > theta, f(x) = 0 otherwise.  Scala:  ThresholdedReLU(theta = 1.0, inputShape = null)  Python:  ThresholdedReLU(theta=1.0, input_shape=None, name=None)  Parameters:   theta : Threshold location of activation. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ThresholdedReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]  Output is  [[0.0   0.0   0.0]\n [0.0   0.0   0.0]]",
            "title": "ThresholdedReLU"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/",
            "text": "KerasLayerWrapper\n\n\nWrap a torch style layer to keras style layer.\n\n\nThis layer can be built multiple times.\n\n\nScala:\n\n\nKerasLayerWrapper(torchLayer, inputShape = null)\n\n\n\n\nPython:\n\n\nKerasLayerWrapper(torch_layer, input_shape=None)\n\n\n\n\nParameters:\n\n\n\n\ntorchLayer\n: a torch style layer.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.nn.Linear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20))\nmodel.add(dense)\nval input = Tensor[Float](2, 20).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.55278283      -0.5434559      -0.13098523     0.3069534       -0.12007129     0.031956512     -0.019634819    -0.09178751     -1.2957728      1.3516346      1.3507701       -0.93318635     -1.1111038      1.0057137       0.093072094     0.16315712      -0.18079235     0.80998576      0.6703253     0.21223836\n-1.007659       1.5507021       -0.14909777     0.49734116      1.4081444       0.1438721       1.7318599       -1.3321369      -0.6123855      0.43861434     0.9198252       1.1758715       -0.5824179      -0.90594006     -0.33974242     -0.58157283     1.3687168       -2.160458       -0.18854974   0.4541929\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5819317       0.7231704       0.21700777      -0.1763548      0.02167879      0.19229038      0.7264892       -0.7566038      -0.8883222      0.47539598\n-0.92322034     -0.33127156     0.48748493      -0.7715719      1.0859711       0.5226875       -0.6108173      -0.29417562     0.75702786      0.009688854\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import KerasLayerWrapper\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.nn.layer import Linear\n\nmodel = Sequential()\nmodel.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, )))\ninput = np.random.random([2, 20])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444,\n  0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214,\n  0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721,\n  0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057],\n [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703,\n  0.74951992, 0.71846465, 0.72513163, 0.141432  , 0.54936796,\n  0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522,\n  0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]]\n\n\n\n\nOutput is\n\n\n[[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539,\n   0.03494176, -0.66940045,  0.6229225 ,  0.38492152, -0.527405  ],\n [-0.36529738, -0.57997525,  0.08127502, -0.7578952 , -0.1762895 ,\n  -0.10188193, -0.18423618,  0.37726521,  0.21360731, -0.5451691 ]]",
            "title": "Layer Wrappers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/#keraslayerwrapper",
            "text": "Wrap a torch style layer to keras style layer.  This layer can be built multiple times.  Scala:  KerasLayerWrapper(torchLayer, inputShape = null)  Python:  KerasLayerWrapper(torch_layer, input_shape=None)  Parameters:   torchLayer : a torch style layer.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.nn.Linear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20))\nmodel.add(dense)\nval input = Tensor[Float](2, 20).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.55278283      -0.5434559      -0.13098523     0.3069534       -0.12007129     0.031956512     -0.019634819    -0.09178751     -1.2957728      1.3516346      1.3507701       -0.93318635     -1.1111038      1.0057137       0.093072094     0.16315712      -0.18079235     0.80998576      0.6703253     0.21223836\n-1.007659       1.5507021       -0.14909777     0.49734116      1.4081444       0.1438721       1.7318599       -1.3321369      -0.6123855      0.43861434     0.9198252       1.1758715       -0.5824179      -0.90594006     -0.33974242     -0.58157283     1.3687168       -2.160458       -0.18854974   0.4541929\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5819317       0.7231704       0.21700777      -0.1763548      0.02167879      0.19229038      0.7264892       -0.7566038      -0.8883222      0.47539598\n-0.92322034     -0.33127156     0.48748493      -0.7715719      1.0859711       0.5226875       -0.6108173      -0.29417562     0.75702786      0.009688854\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import KerasLayerWrapper\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.nn.layer import Linear\n\nmodel = Sequential()\nmodel.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, )))\ninput = np.random.random([2, 20])\noutput = model.forward(input)  Input is:  [[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444,\n  0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214,\n  0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721,\n  0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057],\n [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703,\n  0.74951992, 0.71846465, 0.72513163, 0.141432  , 0.54936796,\n  0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522,\n  0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]]  Output is  [[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539,\n   0.03494176, -0.66940045,  0.6229225 ,  0.38492152, -0.527405  ],\n [-0.36529738, -0.57997525,  0.08127502, -0.7578952 , -0.1762895 ,\n  -0.10188193, -0.18423618,  0.37726521,  0.21360731, -0.5451691 ]]",
            "title": "KerasLayerWrapper"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/self-attention/",
            "text": "TransformerLayer\n\n\nA network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Refer to this \npaper\n for more details.\n\n\nInput is a Table which consists of 2 tensors.\n\n\n\n\nToken id tensor: shape (batch, seqLen) with the word token indices in the vocabulary\n\n\nPosition id tensor: shape (batch, seqLen) with positions in the sentence.\n\n\n\n\nOutput is a Table as well.\n\n\n\n\nThe states of Transformer layer.\n\n\nThe pooled output which processes the hidden state of the last layer with regard to the first token of the sequence. This would be useful for segment-level tasks.\n\n\n\n\nWith Default Embedding:\n\n\nScala:\n\n\nTransformerLayer[Float](vocab = 40990,\n    seqLen = 77,\n    nBlock = 12,\n    residPdrop = 0.1,\n    attnPdrop = 0.1,\n    nHead = 12,\n    hiddenSize = 768,\n    embeddingDrop = 0,\n    initializerRange = 0.02,\n    bidirectional = false,\n    outputAllBlock = false)\n\n\n\n\nPython:\n\n\nTransformerLayer.init(vocab=40990, seq_len=77, n_block=12, hidden_drop=0.1,\n    attn_drop=0.1, n_head=12, hidden_size=768,\n    embedding_drop=0.1, initializer_range=0.02,\n    bidirectional=False, output_all_block=False)\n\n\n\n\nParameters:\n\n\n\n\nvocab\n: vocabulary size of training data, default is 40990\n\n\nseqLen\n: max sequence length of training data, default is 77\n\n\nnBlock\n: block number, default is 12\n\n\nresidPdrop\n: drop probability of projection, default is 0.1\n\n\nattnPdrop\n: drop probability of attention, default is 0.1\n\n\nnHead\n: head number, default is 12\n\n\nhiddenSize\n: is also embedding size\n\n\nembeddingDrop\n: drop probability of embedding layer, default is 0.1\n\n\ninitializerRange\n: weight initialization range, default is 0.02\n\n\nbidirectional\n: whether unidirectional or bidirectional, default is false\n\n\noutputAllBlock\n: whether output all blocks' output, default is false\n\n\n\n\nWith Customized Embedding:\n\n\nScala:\n\n\nTransformerLayer[Float](nBlock = 12,\n    residPdrop = 0.1,\n    attnPdrop = 0.1,\n    nHead = 12,\n    bidirectional = false,\n    initializerRange = 0.02,\n    outputAllBlock = true,\n    embeddingLayer = embedding.asInstanceOf[KerasLayer[Activity, Tensor[Float], Float]])\n\n\n\n\nPython:\n\n\nTransformerLayer(n_block=12,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    n_head=12,\n    initializer_range=0.02,\n    bidirectional=False,\n    output_all_block=False,\n    embedding_layer=embedding,\n    input_shape=((seq_len,), (seq_len,)),\n    intermediate_size=0)\n\n\n\n\nParameters:\n\n\n\n\nnBlock\n: block number\n\n\nresidPdrop\n: drop probability of projection\n\n\nattnPdrop\n: drop probability of attention\n\n\nnHead\n: head number\n\n\ninitializerRange\n: weight initialization range\n\n\nbidirectional\n: whether unidirectional or bidirectional\n\n\noutputAllBlock\n: whether output all blocks' output\n\n\nembeddingLayer\n: embedding layer\n\n\n\n\nScala example:\n\n\nval shape1 = Shape(20)\nval shape2 = Shape(20)\nval input1 = Variable[Float](shape1)\nval input2 = Variable[Float](shape2)\nval input = Array(input1, input2)\nval seq = TransformerLayer[Float](200, hiddenSize = 128, nHead = 8,\n  seqLen = 20, nBlock = 1).from(input: _*)\nval model = Model[Float](input, seq)\n\nval trainToken = Tensor[Float](1, 20).rand()\nval trainPos = Tensor.ones[Float](1, 20)\nval input3 = T(trainToken, trainPos)\nval output = model.forward(input3)\n\n\n\n\nInput is:\n\n\n{\n2: 1.0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x20]\n1: 0.8087359    0.16409875  0.7404631   0.4836999   0.034994964 0.033039592 0.6694243   0.84700763  0.32154092  0.17410904  0.66117364  0.30495027  0.19573595  0.058101892 0.65923077  0.84077805  0.50113535  0.48393667  0.06523132  0.0667426\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20]\n}\n\n\n\n\nOutput is:\n\n\n{\n2: 0.83383083   0.72725344  0.16394942  -0.79005975 0.8877357   -0.9060916  -0.6796065  0.46835706  -0.4700584  0.43868023  0.6641587   0.6711142   -0.70056283 -0.42694178 0.7615595   -0.25590983 0.21654142  0.35254374  0.83790034  0.1103606   -0.20419843 -0.9739706  0.6150182   0.4499923   0.3355538   -0.01543447 -0.99528116 0.45984524  -0.22544041 0.10049125  0.8418835   -0.116228305    -0.112435654    0.5183222   -0.59375525 0.31828925  0.50506884  0.14892755  0.94327587  -0.19001998 0.54074824  -0.07616825 -0.79334164 -0.49726814 0.23889944  -0.91731304 -0.5484148  0.5048103   0.9743351   0.10505025  0.81167877  -0.47498485 -0.83443964 -0.89340115 0.6443838   0.10184191  -0.38618097 -0.32026938 0.51587516  -0.40602723 -0.2931675  -0.86100364 0.109585665 0.9023708   0.46609795  0.0028693299    -0.5746851  -0.45607233 -0.9075561  -0.91294044 0.8077997   0.23019081  0.51124465  -0.39125186 0.16946821  -0.36827865 -0.32563296 0.62560886  -0.7278883  0.8076773   0.89344263  -0.9259615  0.21476166  0.67077845  0.5857905   -0.32905066 -0.16318946 0.6435858   -0.28905967 -0.6991412  -0.5289766  -0.6954091  0.1577004   0.5618301   -0.6290018  0.114078626 -0.52474076 0.27916297  -0.76610357 0.67119384  -0.4308661  0.063731246 -0.5281069  -0.65910465 0.5383283   -0.2875557  0.24594739  -0.6789035  0.7002648   -0.64659894 -0.70994437 -0.8416273  0.4666695   -0.55062526 0.14995292  -0.978979   0.40934727  -0.9028927  0.38194665  0.2334618   -0.9481384  -0.51903373 -0.947906   0.2667679   -0.76987743 -0.7490675  0.6777159   0.9593161\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x128]\n1: (1,.,.) =\n   0.8369983    -0.9907519  0.74404025  ... 0.6154673   0.107825294 -0.806892\n   0.7676861    -0.962961   0.73240614  ... 0.534349    0.0049344404    -0.81643736\n   0.7487803    -0.9717681  0.7315394   ... 0.59831613  0.010904985 -0.82502025\n   ...\n   0.06956328   -1.2103055  1.4155688   ... -0.759053   0.6966926   -0.53496075\n   0.0759853    -1.2265961  1.4023252   ... -0.7500985  0.68647313  -0.52275336\n   0.06356962   -1.2309887  1.3984702   ... -0.751963   0.69192046  -0.52820134\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20x128]\n}\n\n\n\n\nPython example:\n\n\nmodel = TransformerLayer.init(\n    vocab=200, hidden_size=128, n_head=4, seq_len=20)\n\ntrain_token = np.random.randint(20, size=(2, 20))\ntrain_pos = np.zeros((2, 20), dtype=np.int32)\ninput = [train_token, train_pos]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n<type 'list'>: [array([[11,  2, 16,  6, 17, 18,  2,  4,  5, 16, 18, 15, 13, 19,  5, 15,\n    14, 14,  2,  9],\n   [10, 15, 13,  6, 12,  0, 11,  3, 16, 13,  6, 13, 17, 13,  3,  4,\n    15,  5,  7, 15]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n  dtype=int32)]\n\n\n\n\nOutput is\n\n\n<type 'list'>: [array([[[ 0.26004127, -0.31793368, -1.1605529 , ..., -0.81875914,\n -0.02121837, -0.8328352 ],\n[-0.8622302 , -0.35201085,  0.63190293, ...,  2.0652232 ,\n  1.5278    ,  0.38224357],\n[-2.5103235 ,  1.4465114 ,  0.71134603, ...,  1.1776686 ,\n  0.6882701 ,  0.3534629 ],\n...,\n[-0.22725764,  1.2112792 , -0.40597847, ...,  2.2241254 ,\n  0.2580125 , -1.1470895 ],\n[-0.56174546,  1.3353435 , -0.7445968 , ...,  1.1259638 ,\n  0.6951011 , -1.1421459 ],\n[-0.6615135 ,  1.1899865 , -0.81727505, ...,  2.0474243 ,\n  0.20160393, -0.7789728 ]],\n\n[[-1.1624268 , -0.5375418 , -0.7274868 , ..., -0.99061227,\n -0.57117355,  1.0684316 ],\n[ 0.11317759, -0.7231343 ,  0.7723393 , ...,  1.6518786 ,\n  1.0916579 ,  0.18682887],\n[-1.9651127 ,  0.9987117 ,  0.32025027, ...,  0.94719195,\n -0.21028236, -0.02251417],\n...,\n[-0.6677234 ,  0.69822913, -0.9714249 , ...,  2.208334  ,\n  0.7719772 , -0.93855625],\n[-0.63691545,  1.3876344 , -0.8491991 , ...,  2.060551  ,\n  0.34702447, -0.8160082 ],\n[-0.6608573 ,  1.2608795 , -0.46634364, ...,  2.100828  ,\n  0.2967869 , -1.0938305 ]]], dtype=float32), array([[ 0.06879381,  0.6821829 , -0.8267953 , -0.02695777, -0.53899264,\n 0.8241045 ,  0.6976903 ,  0.31741282,  0.23590134,  0.5565326 ,\n 0.95292866,  0.5658284 , -0.2916065 , -0.37934095, -0.2774958 ,\n 0.73409927, -0.71731025,  0.07897043,  0.88609815, -0.27966806,\n 0.93520796,  0.72740096,  0.1626402 , -0.26063287,  0.28597558,\n-0.12945679,  0.7151408 , -0.8463592 , -0.48385444, -0.29313505,\n 0.86453205, -0.93834317,  0.41815573,  0.92436415,  0.8209114 ,\n 0.6627246 , -0.574135  ,  0.607416  ,  0.04769071, -0.29779348,\n-0.26268572, -0.78998053, -0.7522611 ,  0.89941144, -0.15754697,\n 0.9298859 , -0.8327022 , -0.63423705, -0.63789636, -0.14168388,\n-0.56104964, -0.80995566,  0.9244693 ,  0.4679966 , -0.16284083,\n 0.8478645 ,  0.29836348, -0.15369722, -0.4490478 ,  0.11052075,\n 0.23767054,  0.59320366, -0.79055625,  0.22201608, -0.88366413,\n-0.4410687 ,  0.8762162 , -0.6516914 , -0.5993653 , -0.5972125 ,\n-0.86697286, -0.17644943,  0.95839834, -0.06382846,  0.7430881 ,\n-0.59690744,  0.3901914 ,  0.06803267,  0.9142394 ,  0.7583274 ,\n-0.18442968,  0.56280667, -0.37844184, -0.41195455, -0.8376329 ,\n 0.87641823, -0.98970294, -0.6764397 , -0.86945957, -0.69273126,\n 0.9911777 ,  0.417286  , -0.8774987 ,  0.17141937,  0.7204654 ,\n-0.62387246, -0.8795049 ,  0.62618923, -0.29725042, -0.4565646 ,\n-0.47798416, -0.97555065, -0.94241685, -0.97800356,  0.8523641 ,\n-0.96860206,  0.5378995 , -0.73754525, -0.01649606, -0.4274561 ,\n-0.5290453 ,  0.11851768,  0.48821065,  0.4822751 ,  0.49497148,\n-0.5734494 , -0.29612035, -0.7254394 , -0.1418346 , -0.56686646,\n 0.03665365, -0.9586826 , -0.0983429 , -0.09348761, -0.96338177,\n 0.76481736,  0.87975204,  0.70463663],\n[-0.09654156,  0.78266025, -0.9125131 , -0.6706971 , -0.58709925,\n-0.94729275, -0.32309514, -0.95263994,  0.2036015 , -0.9297767 ,\n 0.6164713 ,  0.3484337 ,  0.46247053,  0.21615174, -0.8382687 ,\n-0.55828595, -0.59234536, -0.9643932 ,  0.9310115 , -0.12657425,\n 0.63812125,  0.80040973, -0.47581342,  0.9823402 , -0.5400171 ,\n 0.5864317 , -0.19979174, -0.5721838 ,  0.9190707 ,  0.31628668,\n 0.08952013,  0.8719338 ,  0.26684833,  0.8955768 , -0.9275499 ,\n-0.81994563,  0.28863704, -0.16376448,  0.15855551,  0.04302022,\n 0.4440408 , -0.7293209 ,  0.2255107 ,  0.16333969,  0.38721767,\n-0.04512435, -0.5473172 , -0.5812051 , -0.8219114 , -0.43659028,\n-0.04860768, -0.8912252 ,  0.62100273,  0.7187475 , -0.06158534,\n 0.6554498 , -0.62163985,  0.63035303,  0.19207267, -0.68847877,\n 0.10341872, -0.88906926, -0.38804066, -0.8157233 , -0.81641346,\n 0.8846337 , -0.70225614,  0.6281251 , -0.81235796,  0.77828485,\n 0.9393982 , -0.42554784,  0.4150426 , -0.32612413, -0.721988  ,\n 0.96166253, -0.6080237 , -0.7312329 ,  0.06843777, -0.09806018,\n-0.7357863 , -0.28613612, -0.8895085 , -0.9027925 ,  0.56311375,\n 0.85699487, -0.32128897,  0.80635303, -0.01190906, -0.23292968,\n-0.5115769 ,  0.17153661, -0.79993784,  0.6232265 , -0.06049479,\n-0.83510727,  0.9652135 ,  0.08310007, -0.9671807 , -0.17466563,\n 0.48009604,  0.594712  ,  0.19612817, -0.9279629 , -0.59968966,\n-0.36079255, -0.7250685 ,  0.59395283,  0.7574965 , -0.4377294 ,\n 0.45312116,  0.7117049 , -0.82085943, -0.10442825,  0.73688287,\n 0.38598123,  0.35439053, -0.3862137 , -0.56253886,  0.7388591 ,\n-0.6024478 , -0.699977  , -0.46581215, -0.79513186,  0.09657894,\n 0.280869  , -0.38445532, -0.98311806]], dtype=float32)]\n\n\n\n\n\n\nBERT\n\n\nBidirectional Encoder Representations from Transformers. Refer https://arxiv.org/pdf/1810.04805.pdf\n\n\nInput is a Table which consists of 4 tensors.\n\n\n\n\nToken id tensor: shape (batch, seqLen) with the word token indices in the vocabulary\n\n\nToken type id tensor: shape (batch, seqLen) with the token types in (0, 1).\n   0 means \nsentence A\n and 1 means a \nsentence B\n (see BERT paper for more details).\n\n\nPosition id tensor: shape (batch, seqLen) with positions in the sentence.\n\n\nAttention_mask tensor: shape (batch, seqLen) with indices in (0, 1).\n  It's a mask to be used if the input sequence length is smaller than seqLen in the current batch.\n\n\n\n\nOutput is a Table as well.\n\n\n\n\nThe states of BERT layer.\n\n\nThe pooled output which processes the hidden state of the last layer with regard to the first token of the sequence. This would be useful for segment-level tasks.\n\n\n\n\nWith Default Embedding:\n\n\nScala:\n\n\nBERT[Float](vocab: Int = 40990,\n    hiddenSize: Int = 768,\n    nBlock: Int = 12,\n    nHead: Int = 12,\n    maxPositionLen: Int = 512,\n    intermediateSize: Int = 3072,\n    hiddenPDrop: Double = 0.1,\n    attnPDrop: Double = 0.1,\n    initializerRange: Double = 0.02,\n    outputAllBlock: Boolean = true,\n    inputSeqLen: Int = -1)\n\n\n\n\nPython:\n\n\nBERT.init(vocab=40990,\n    hidden_size=768,\n    n_block=12,\n    n_head=12,\n    seq_len=512,\n    intermediate_size=3072,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    initializer_range=0.02,\n    output_all_block=True)\n\n\n\n\nParameters:\n\n\n\n\nvocab\n: vocabulary size of training data, default is 40990\n\n\nhiddenSize\n: size of the encoder layers, default is 768\n\n\nnBlock\n: block number, default is 12\n\n\nnHead\n: head number, default is 12\n\n\nmaxPositionLen\n: sequence length, default is 512\n\n\nintermediateSize\n: The size of the \"intermediate\" (i.e., feed-forward), default is 3072\n\n\nhiddenPDrop\n: The dropout probability for all fully connected layers, default is 0.1\n\n\nattnPDrop\n: drop probability of attention, default is 0.1\n\n\ninitializerRange\n: weight initialization range, default is 0.02\n\n\noutputAllBlock\n: whether output all blocks' output, default is false\n\n\ninputSeqLen\n: sequence length of input, default is -1 which means the same with maxPositionLen\n\n\n\n\nWith Customized Embedding:\n\n\nScala:\n\n\nBERT[Float](nBlock = 12,\n    nHead = 12,\n    intermediateSize = 3072,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    initializerRange = 0.02,\n    outputAllBlock = true,\n    embeddingLayer = embedding)\n\n\n\n\nPython:\n\n\nBERT(n_block=12,\n    n_head=12,\n    intermediate_size=3072,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    initializer_range=0.02,\n    output_all_block=True,\n    embedding_layer=embedding,\n    input_shape=((seq_len,), (seq_len,), (seq_len,), (1, 1, seq_len)))\n\n\n\n\nParameters:\n\n\n\n\nnBlock\n: block number\n\n\nnHead\n: head number\n\n\nintermediateSize\n: The size of the \"intermediate\" (i.e., feed-forward)\n\n\nhiddenPDrop\n: The dropout probability for all fully connected layers\n\n\nattnPdrop\n: drop probability of attention\n\n\ninitializerRange\n: weight initialization range\n\n\noutputAllBlock\n: whether output all blocks' output\n\n\nembeddingLayer\n: embedding layer\n\n\n\n\nLoading from existing pretrained model:\n\n\nScala:\n\n\nBERT[Float](path = \"\",\n    weightPath = null,\n    inputSeqLen = 11,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    outputAllBlock = true)\n\n\n\n\nPython:\n\n\nBERT.init_from_existing_model(path=\"\",\n    weight_path=None,\n    input_seq_len=-1.0,\n    hidden_drop=-1.0,\n    attn_drop=-1.0,\n    output_all_block=True)\n\n\n\n\nParameters:\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any\n\n\ninputSeqLen\n: sequence length of input, will be ignored if existing model is built with customized embedding\n\n\nhiddenPDrop\n: The dropout probability for all fully connected layers, will be ignored if existing model is built with customized embedding\n\n\nattnPdrop\n: drop probability of attention, will be ignored if existing model is built with customized embedding\n\n\n\n\nScala example:\n\n\nval layer = BERT[Float](vocab = 100,\n    hiddenSize = 10,\n    nBlock = 3,\n    nHead = 2,\n    intermediateSize = 64,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    maxPositionLen = 10,\n    outputAllBlock = false,\n    inputSeqLen = 10)\n\nval shape = Shape(List(Shape(1, 10), Shape(1, 10), Shape(1, 10), Shape(1, 1, 1, 10)))\nlayer.build(shape)\nval inputIds = Tensor[Float](Array[Float](7, 20, 39, 27, 10,\n  39, 30, 21, 17, 15), Array(1, 10))\nval segmentIds = Tensor[Float](Array[Float](0, 0, 0, 0, 0, 1, 1, 1, 1, 1), Array(1, 10))\nval positionIds = Tensor[Float](Array[Float](0, 1, 2, 3, 4, 5, 6, 7, 8, 9), Array(1, 10))\nval masks = Tensor[Float](1, 1, 1, 10).fill(1.0f)\n\nval output = layer.forward(T(inputIds, segmentIds, positionIds, masks))\n\n\n\n\nInput is:\n\n\n{\n2: 0.0  0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n4: (1,1,.,.) =\n   1.0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x10]\n1: 7.0  20.0    39.0    27.0    10.0    39.0    30.0    21.0    17.0    15.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n3: 0.0  1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n}\n\n\n\n\nOutput is:\n\n\n{\n2: 0.5398573    0.08571402  -0.9461041  -0.35362077 -0.24374364 0.24349216  0.9587727   -0.03278971 -0.826852   -0.8808889\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n1: (1,.,.) =\n   1.3381815    1.7575556   -1.1870699  0.8455374   -1.6000531  0.115945406 -0.33695826 -0.39254665 -0.33637434 -0.20421773\n   -0.08370285  0.056055143 -0.91990083 1.6324282   -0.093128644    -0.4484297  -2.0828273  0.10244746  0.577287    1.2597716\n   0.3563086    0.37092525  -0.5089354  0.4525072   1.7706354   0.65231055  -2.0269241  -0.2548585  0.3711578   -1.1831268\n   0.2429675    -0.023419544    -0.28389466 0.6601246   -0.009858845    -0.028412571    -2.5104556  1.0338438   1.3621751   -0.44306967\n   1.7147139    1.1627073   -0.19394834 0.8043055   -1.0080436  -1.7716306  -0.7668168  -0.19861369 0.45103902  -0.19371253\n   0.077525005  0.0722655   1.0745171   0.07997274  0.06562643  1.6474637   0.18938908  -2.377528   -0.6107291  -0.21850263\n   -1.3190242   1.7057956   0.32655835  0.5711799   -0.80318034 0.2776545   1.4860673   -0.676896   -0.39734793 -1.1708072\n   -0.4327645   -0.19849697 0.3695452   -0.08213705 1.2378154   0.591234    -1.505518   1.684885    -1.6251724  -0.03939093\n   0.6422535    -0.582018   1.6665243   -1.0995792  0.19488664  1.3563607   -0.60793823 -0.05846788 -1.7225715  0.21054967\n   -1.0927358   -0.37666538 0.70802236  -2.0131714  0.94964516  1.4701655   0.053027537 0.051168486 -0.58528    0.83582383\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10x10]\n}\n\n\n\n\nPython example:\n\n\nlayer = BERT.init(\n    vocab=200, hidden_size=128, n_head=4, seq_len=20, intermediate_size=20)\n\ntrain_token = np.random.randint(20, size=(2, 20))\ntoken_type_id = np.zeros((2, 20), dtype=np.int32)\ntrain_pos = np.zeros((2, 20), dtype=np.int32)\nmask_attention = np.ones((2, 1, 1, 20), dtype=np.int32)\ninput = [train_token, token_type_id, train_pos, mask_attention]\noutput = layer.forward(input)\n\n\n\n\nInput is:\n\n\n<type 'list'>: [array([[ 8, 19,  5,  8,  4, 13, 13, 12,  1,  6, 16, 14, 19,  0, 11, 18,\n 1, 17,  0,  0],\n[17, 10, 15, 19, 15,  2, 18,  8,  1, 11, 10, 17,  7,  2,  0,  0,\n 9, 14, 11,  6]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\ndtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\ndtype=int32), array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n\n[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]],\ndtype=int32)]\n\n\n\n\nOutput is\n\n\n<type 'list'>: [array([[[ 1.01330066e+00,  4.74100798e-01,  3.81211847e-01, ...,\n -8.00989151e-01, -6.18815482e-01, -1.09804094e+00],\n[-6.29726201e-02,  6.71391249e-01, -2.28019580e-01, ...,\n  3.97501498e-01, -3.32217604e-01, -2.04850674e+00],\n[ 5.04802346e-01,  1.00434709e+00, -7.63663530e-01, ...,\n -1.11675525e+00,  1.41550392e-01, -6.47688091e-01],\n...,\n[ 5.07664750e-04,  6.47843182e-01, -5.33694960e-02, ...,\n -2.01566055e-01, -6.62943959e-01, -2.93835902e+00],\n[-1.49255514e-01, -5.47551095e-01, -3.36264402e-01, ...,\n  1.11121520e-01, -4.42977905e-01, -2.13847613e+00],\n[-1.33390293e-01, -5.50503194e-01, -3.49355727e-01, ...,\n  9.34313685e-02, -4.41935956e-01, -8.25921223e-02]],\n\n[[ 1.34967836e-02,  3.90778482e-02, -2.22317409e-02, ...,\n -9.81532633e-02, -6.08992100e-01, -2.77224326e+00],\n[-5.21431923e-01, -6.74456656e-02, -4.66892511e-01, ...,\n  1.05466165e-01, -2.67068297e-01, -9.00964141e-01],\n[ 9.41378593e-01,  5.21076620e-01, -5.35079956e-01, ...,\n -3.15736473e-01,  8.08603615e-02, -2.44178265e-01],\n...,\n[ 4.16017324e-02, -5.65874994e-01,  6.68676615e-01, ...,\n -6.28256857e-01, -9.09847617e-02, -2.42878512e-01],\n[-1.36971796e+00,  5.37231266e-01, -1.33729517e+00, ...,\n -1.47498712e-01,  8.00304264e-02, -5.09030581e-01],\n[ 3.98404837e-01, -7.18296226e-03, -1.08256066e+00, ...,\n -5.17360926e-01,  5.50065935e-01, -2.32753420e+00]]],\ndtype=float32), array([[[ 1.0795887 ,  0.44977495,  0.45561683, ..., -0.729603  ,\n -0.6098092 , -1.0323973 ],\n[ 0.0154253 ,  0.6424524 , -0.15503715, ...,  0.45100495,\n -0.3161888 , -1.9826275 ],\n[ 0.58491707,  0.9876782 , -0.69952184, ..., -1.0432141 ,\n  0.1380458 , -0.5642554 ],\n...,\n[ 0.06806332,  0.61824507,  0.02341641, ..., -0.21342012,\n -0.63312817, -2.8557966 ],\n[-0.06217962, -0.5528828 , -0.34740448, ...,  0.16651583,\n -0.41633344, -2.064906  ],\n[-0.04626712, -0.57442385, -0.277238  , ...,  0.13806444,\n -0.43256086, -0.01180306]],\n\n[[ 0.10532085,  0.01057051,  0.07536474, ..., -0.03406155,\n -0.572023  , -2.6935408 ],\n[-0.42477775, -0.10768362, -0.37653154, ...,  0.17155378,\n -0.27841952, -0.8244427 ],\n[ 1.0290473 ,  0.5059685 , -0.5359356 , ..., -0.25725254,\n  0.1034779 , -0.16898313],\n...,\n[ 0.14118548, -0.5945706 ,  0.7681386 , ..., -0.55807835,\n -0.07778832, -0.15940095],\n[-1.2648381 ,  0.50598496, -1.2431567 , ..., -0.06980868,\n  0.10642368, -0.4181047 ],\n[ 0.48330045, -0.05184587, -0.9985824 , ..., -0.5360492 ,\n  0.56541353, -2.2607849 ]]], dtype=float32), array([[[ 1.1541002 ,  0.47630545,  0.40673187, ..., -0.7284888 ,\n -0.55945337, -1.0810231 ],\n[ 0.10070852,  0.64252985, -0.2007717 , ...,  0.4489277 ,\n -0.24709189, -2.0173872 ],\n[ 0.67520154,  0.9793912 , -0.7441366 , ..., -1.0376649 ,\n  0.20359974, -0.6060102 ],\n...,\n[ 0.07809319,  0.63523245, -0.02464442, ..., -0.21328981,\n -0.5693355 , -2.8386393 ],\n[ 0.02228299, -0.5229728 , -0.33483037, ...,  0.16430138,\n -0.40036577, -2.094183  ],\n[ 0.02232744, -0.54113156, -0.3307599 , ...,  0.14321396,\n -0.3796677 , -0.04973204]],\n\n[[ 0.20497712,  0.02804335,  0.028764  , ..., -0.01617111,\n -0.5416485 , -2.7333891 ],\n[-0.3361876 , -0.08618001, -0.41299412, ...,  0.17708196,\n -0.23643918, -0.8763187 ],\n[ 1.1118197 ,  0.5178778 , -0.57264006, ..., -0.2597192 ,\n  0.15024357, -0.23373066],\n...,\n[ 0.23304611, -0.57528406,  0.71815467, ..., -0.5524511 ,\n -0.04103457, -0.15449452],\n[-1.1629226 ,  0.5377656 , -1.2816569 , ..., -0.05795323,\n  0.1603044 , -0.47194824],\n[ 0.5773567 , -0.04114214, -1.0306932 , ..., -0.52537155,\n  0.5703101 , -2.3124278 ]]], dtype=float32), array([[[ 1.1319652e+00,  4.2663044e-01,  3.9611375e-01, ...,\n -7.7264631e-01, -5.3006041e-01, -1.0942854e+00],\n[ 7.3858641e-02,  6.1578143e-01, -2.0985913e-01, ...,\n  4.0289888e-01, -2.2484708e-01, -2.0233095e+00],\n[ 6.3545388e-01,  9.4610500e-01, -7.6165521e-01, ...,\n -1.0820770e+00,  2.2266804e-01, -6.0132843e-01],\n...,\n[ 3.9479308e-02,  6.0636342e-01, -2.8302141e-02, ...,\n -2.6316714e-01, -5.5309945e-01, -2.8510940e+00],\n[-2.8412668e-03, -5.5100703e-01, -3.4540960e-01, ...,\n  1.5979633e-01, -3.8844827e-01, -2.0994248e+00],\n[-1.4572166e-02, -5.7526213e-01, -3.3382124e-01, ...,\n  1.0289014e-01, -3.6059290e-01, -6.5041430e-02]],\n\n[[ 1.5256011e-01,  3.3955947e-03,  1.7648729e-02, ...,\n -4.9600061e-02, -5.1613468e-01, -2.7417533e+00],\n[-3.6988521e-01, -8.8330485e-02, -4.2416954e-01, ...,\n  1.2959087e-01, -2.1623056e-01, -8.8821554e-01],\n[ 1.0618008e+00,  5.0827748e-01, -5.8256608e-01, ...,\n -2.9023758e-01,  1.6930477e-01, -2.3869993e-01],\n...,\n[ 1.8475071e-01, -5.8594310e-01,  7.0973599e-01, ...,\n -5.9211296e-01, -1.7043589e-02, -1.5649734e-01],\n[-1.2073172e+00,  5.1577950e-01, -1.2952001e+00, ...,\n -1.0562765e-01,  1.8499596e-01, -4.6483174e-01],\n[ 5.8209622e-01, -5.3714752e-02, -1.0255412e+00, ...,\n -5.6718546e-01,  5.9832001e-01, -2.3260906e+00]]], dtype=float32), array([[[ 1.1358043 ,  0.38664085,  0.43075162, ..., -0.762137  ,\n -0.53836805, -1.1419276 ],\n[ 0.0705715 ,  0.61749744, -0.1978054 , ...,  0.39686537,\n -0.23118263, -2.0863478 ],\n[ 0.6286853 ,  0.9499371 , -0.75073713, ..., -1.0837915 ,\n  0.20451419, -0.64585996],\n...,\n[ 0.04084783,  0.5485716 ,  0.02199897, ..., -0.265642  ,\n -0.54954815, -2.8985202 ],\n[-0.00433184, -0.5782148 , -0.28893095, ...,  0.15305014,\n -0.3942154 , -2.1390564 ],\n[-0.01938614, -0.6034715 , -0.3210429 , ...,  0.11286073,\n -0.3612479 , -0.12291119]],\n\n[[ 0.13899514, -0.04281238,  0.05966739, ..., -0.05543021,\n -0.51721877, -2.7725601 ],\n[-0.38874203, -0.13524944, -0.37960985, ...,  0.12579904,\n -0.23764463, -0.94251025],\n[ 1.0436667 ,  0.4891924 , -0.5470476 , ..., -0.30531114,\n  0.143379  , -0.28663573],\n...,\n[ 0.17597033, -0.6172772 ,  0.75050735, ..., -0.59396976,\n -0.02840331, -0.20918237],\n[-1.2121452 ,  0.47985265, -1.2640744 , ..., -0.11457531,\n  0.17777829, -0.5216857 ],\n[ 0.5724598 , -0.08497301, -0.99838203, ..., -0.569392  ,\n  0.5878865 , -2.3820512 ]]], dtype=float32), array([[[ 1.1923821 ,  0.40376186,  0.4216827 , ..., -0.7753511 ,\n -0.58085346, -1.1371452 ],\n[ 0.13859609,  0.6558944 , -0.1899949 , ...,  0.37358993,\n -0.27038255, -2.0870223 ],\n[ 0.7083764 ,  0.977537  , -0.76046735, ..., -1.101789  ,\n  0.1981793 , -0.6461577 ],\n...,\n[ 0.10095584,  0.5967537 ,  0.02207649, ..., -0.28193793,\n -0.5789527 , -2.9001386 ],\n[ 0.05901275, -0.53504837, -0.28481779, ...,  0.13802934,\n -0.41621858, -2.1443312 ],\n[ 0.04528951, -0.5612042 , -0.31392562, ...,  0.09289672,\n -0.38395336, -0.12475596]],\n\n[[ 0.19919002, -0.0038989 ,  0.06975131, ..., -0.05898362,\n -0.5476832 , -2.7802918 ],\n[-0.32966843, -0.10950038, -0.3582222 , ...,  0.08165199,\n -0.2624505 , -0.93702954],\n[ 1.119693  ,  0.5142474 , -0.5341173 , ..., -0.3251373 ,\n  0.10789905, -0.30592436],\n...,\n[ 0.24882485, -0.5699529 ,  0.77695113, ..., -0.63034034,\n -0.07624292, -0.2281592 ],\n[-1.1650497 ,  0.5175082 , -1.2281002 , ..., -0.14287077,\n  0.15133552, -0.532626  ],\n[ 0.64303875, -0.05680082, -0.9739305 , ..., -0.5787345 ,\n  0.5447517 , -2.403577  ]]], dtype=float32), array([[[ 1.1747141 ,  0.44174162,  0.3848741 , ..., -0.8011676 ,\n -0.5708256 , -1.143519  ],\n[ 0.11874287,  0.7037242 , -0.22899102, ...,  0.36200705,\n -0.22287843, -2.0832918 ],\n[ 0.68290263,  1.0014081 , -0.8112288 , ..., -1.0980991 ,\n  0.22316812, -0.637702  ],\n...,\n[ 0.07541095,  0.63492006,  0.02669529, ..., -0.27486983,\n -0.53397936, -2.8813968 ],\n[ 0.07104072, -0.54481   , -0.33232585, ...,  0.12730087,\n -0.37563673, -2.1450465 ],\n[ 0.03186123, -0.51601535, -0.35520643, ...,  0.09008651,\n -0.33910847, -0.11906879]],\n\n[[ 0.19884765,  0.06095114,  0.00477777, ..., -0.0960753 ,\n -0.49155453, -2.7463722 ],\n[-0.32222956, -0.08950429, -0.4053724 , ...,  0.05162536,\n -0.21072339, -0.9155606 ],\n[ 1.1117101 ,  0.56429935, -0.59156317, ..., -0.3369357 ,\n  0.14969075, -0.29045773],\n...,\n[ 0.25635508, -0.5126209 ,  0.7268977 , ..., -0.62107044,\n -0.01715574, -0.21087953],\n[-1.1460723 ,  0.56120336, -1.2668271 , ..., -0.16734022,\n  0.19381218, -0.517316  ],\n[ 0.63978064, -0.01486263, -1.0128225 , ..., -0.56719303,\n  0.58368987, -2.3722165 ]]], dtype=float32), array([[[ 1.20512652e+00,  4.72038895e-01,  3.60962778e-01, ...,\n -9.00623977e-01, -5.82258105e-01, -1.14907408e+00],\n[ 1.55033678e-01,  7.28412509e-01, -2.72546947e-01, ...,\n  2.74131984e-01, -2.24478737e-01, -2.06169677e+00],\n[ 7.13116527e-01,  1.01666617e+00, -8.43635857e-01, ...,\n -1.18351495e+00,  2.21053749e-01, -6.17874563e-01],\n...,\n[ 1.19287886e-01,  6.56103075e-01, -7.38978712e-03, ...,\n -3.54864419e-01, -5.37513494e-01, -2.87535477e+00],\n[ 1.16591401e-01, -5.55387378e-01, -3.71099353e-01, ...,\n  2.78753694e-02, -3.70597601e-01, -2.16417289e+00],\n[ 8.63942727e-02, -4.81025964e-01, -3.91344100e-01, ...,\n -1.84133966e-02, -3.39215338e-01, -1.10263892e-01]],\n\n[[ 2.64633745e-01,  7.25395158e-02, -1.39633343e-02, ...,\n -1.85173869e-01, -5.20042717e-01, -2.70796871e+00],\n[-2.58721560e-01, -6.35206550e-02, -4.14235502e-01, ...,\n  4.62563671e-02, -2.47269630e-01, -8.77729058e-01],\n[ 1.17845881e+00,  5.93900442e-01, -6.18097663e-01, ...,\n -4.23726231e-01,  1.19810022e-01, -2.55170494e-01],\n...,\n[ 3.06802571e-01, -4.83913153e-01,  7.05836833e-01, ...,\n -6.99279726e-01, -5.64565696e-02, -1.74492225e-01],\n[-1.07746637e+00,  5.83848476e-01, -1.28454113e+00, ...,\n -2.29663596e-01,  1.96212217e-01, -5.23399591e-01],\n[ 7.02956200e-01,  2.42653489e-03, -1.03614473e+00, ...,\n -6.54396653e-01,  5.55146933e-01, -2.35132337e+00]]],\ndtype=float32), array([[[ 1.1732985 ,  0.48227564,  0.4141097 , ..., -0.9222415 ,\n -0.5581617 , -1.1467376 ],\n[ 0.10594734,  0.75098526, -0.23052076, ...,  0.23048519,\n -0.23638739, -2.033264  ],\n[ 0.6784295 ,  1.0418617 , -0.810519  , ..., -1.2120562 ,\n  0.24596576, -0.60291487],\n...,\n[ 0.07915874,  0.6732479 ,  0.02875949, ..., -0.38714084,\n -0.5037479 , -2.8571    ],\n[ 0.07176737, -0.52642834, -0.31701285, ..., -0.01229298,\n -0.34029967, -2.1321528 ],\n[ 0.04126783, -0.46029058, -0.34176344, ..., -0.05429364,\n -0.31155083, -0.10451217]],\n\n[[ 0.22600769,  0.09270672,  0.02146479, ..., -0.22232075,\n -0.48217994, -2.6969097 ],\n[-0.29719839, -0.05968198, -0.37710896, ...,  0.02224515,\n -0.20888865, -0.872187  ],\n[ 1.1335284 ,  0.60064685, -0.58743286, ..., -0.45202363,\n  0.13883159, -0.2602308 ],\n...,\n[ 0.27142784, -0.47967467,  0.70926106, ..., -0.71909636,\n -0.01251143, -0.1811402 ],\n[-1.095905  ,  0.6111897 , -1.2443895 , ..., -0.27054876,\n  0.22430526, -0.5081292 ],\n[ 0.7027022 ,  0.01059689, -1.0006222 , ..., -0.6746712 ,\n  0.58800125, -2.352779  ]]], dtype=float32), array([[[ 1.2434555 ,  0.44558033,  0.4151337 , ..., -0.8851603 ,\n -0.5718673 , -1.1482117 ],\n[ 0.11962966,  0.72577155, -0.25604928, ...,  0.2687037 ,\n -0.2457071 , -2.0307996 ],\n[ 0.763747  ,  1.0119921 , -0.8592167 , ..., -1.1870402 ,\n  0.2256221 , -0.6277423 ],\n...,\n[ 0.08759235,  0.64535457,  0.03834408, ..., -0.35554865,\n -0.5139612 , -2.8475935 ],\n[ 0.13679026, -0.55156755, -0.32664305, ...,  0.01780019,\n -0.3558066 , -2.1313274 ],\n[ 0.11818186, -0.4789727 , -0.3590175 , ..., -0.01446133,\n -0.32358617, -0.10938768]],\n\n[[ 0.29418862,  0.09591774,  0.00587363, ..., -0.18236086,\n -0.49953887, -2.694323  ],\n[-0.22257486, -0.07352418, -0.4024905 , ...,  0.05929026,\n -0.22622454, -0.8882016 ],\n[ 1.19449   ,  0.5713768 , -0.6041051 , ..., -0.4231223 ,\n  0.1122172 , -0.28642637],\n...,\n[ 0.3465784 , -0.4939726 ,  0.68308717, ..., -0.68765515,\n -0.04439323, -0.20094715],\n[-1.0187647 ,  0.59667283, -1.2578517 , ..., -0.24298497,\n  0.19871093, -0.53237087],\n[ 0.71921486,  0.00342394, -1.026827  , ..., -0.63569874,\n  0.5502706 , -2.3338537 ]]], dtype=float32), array([[[ 1.2440691 ,  0.477769  ,  0.40438044, ..., -0.8634442 ,\n -0.516493  , -1.2156196 ],\n[ 0.09270077,  0.7480357 , -0.26808444, ...,  0.2696572 ,\n -0.19946648, -2.0294373 ],\n[ 0.7727248 ,  1.0203358 , -0.8804002 , ..., -1.1491328 ,\n  0.26056868, -0.70166045],\n...,\n[ 0.07362438,  0.6428618 ,  0.02992919, ..., -0.3656686 ,\n -0.47058144, -2.8904293 ],\n[ 0.11636666, -0.52916086, -0.3162666 , ...,  0.0035085 ,\n -0.32273746, -2.211205  ],\n[ 0.09450418, -0.46651682, -0.38872302, ..., -0.02868051,\n -0.284238  , -0.20115192]],\n\n[[ 0.24763471,  0.10591529, -0.02833212, ..., -0.19653179,\n -0.44746324, -2.6951957 ],\n[-0.2705241 , -0.05053078, -0.38580215, ...,  0.0737243 ,\n -0.18193349, -0.9320284 ],\n[ 1.1450722 ,  0.5878723 , -0.6142542 , ..., -0.4155699 ,\n  0.1653907 , -0.3516124 ],\n...,\n[ 0.31275982, -0.48012054,  0.6611108 , ..., -0.6956505 ,\n  0.01540092, -0.20229349],\n[-1.0758246 ,  0.6180846 , -1.2664212 , ..., -0.20339848,\n  0.25243902, -0.5957573 ],\n[ 0.6647455 ,  0.02233337, -1.0082287 , ..., -0.6396673 ,\n  0.6092897 , -2.3386178 ]]], dtype=float32), array([[[ 1.16829467e+00,  4.73457277e-01,  3.55845094e-01, ...,\n -8.79491448e-01, -5.13881445e-01, -1.31691360e+00],\n[ 2.06558462e-02,  7.50393629e-01, -2.97149330e-01, ...,\n  2.75190771e-01, -1.88330606e-01, -2.13159895e+00],\n[ 6.88944340e-01,  1.01597929e+00, -9.25147057e-01, ...,\n -1.15003026e+00,  2.47588441e-01, -7.96685874e-01],\n...,\n[ 2.88018938e-02,  6.88098967e-01, -2.68854816e-02, ...,\n -3.84741157e-01, -4.76365626e-01, -2.96942425e+00],\n[ 5.18963784e-02, -4.60506737e-01, -3.59559625e-01, ...,\n -1.14138005e-02, -3.24753582e-01, -2.23346853e+00],\n[ 7.39114806e-02, -4.01132107e-01, -4.24620807e-01, ...,\n -3.33240032e-02, -2.84682035e-01, -3.12762260e-01]],\n\n[[ 2.14906067e-01,  1.72432721e-01, -8.47420394e-02, ...,\n -2.10198522e-01, -4.30923790e-01, -2.79578996e+00],\n[-3.10599983e-01,  1.65538397e-03, -4.26579088e-01, ...,\n  5.09980768e-02, -1.56658575e-01, -1.01907480e+00],\n[ 1.09326482e+00,  6.40747488e-01, -6.59607410e-01, ...,\n -4.15965647e-01,  1.87072530e-01, -4.48307097e-01],\n...,\n[ 2.86490113e-01, -4.34108675e-01,  6.18547022e-01, ...,\n -7.17846394e-01,  3.06018218e-02, -2.91922033e-01],\n[-1.13503909e+00,  6.14412308e-01, -1.32140326e+00, ...,\n -2.04109967e-01,  2.61365235e-01, -6.73554838e-01],\n[ 6.21745884e-01,  8.54183882e-02, -1.06341887e+00, ...,\n -6.34258091e-01,  6.15509987e-01, -2.41539836e+00]]],\ndtype=float32), array([[ 0.5620128 , -0.2001392 , -0.11440954, -0.04526514, -0.8816746 ,\n-0.5549258 ,  0.51452374,  0.13439347,  0.53412014,  0.46277392,\n 0.8692565 , -0.90509814,  0.31514823,  0.8086619 ,  0.58900446,\n-0.3894673 , -0.45003602,  0.37346584,  0.69269675,  0.21574067,\n-0.72299725,  0.528553  , -0.83846116,  0.98062813, -0.05183166,\n 0.33388335, -0.63176596,  0.21661893,  0.43943346,  0.33758652,\n-0.24407507, -0.17800584,  0.59364974,  0.47616154,  0.558793  ,\n 0.27490366, -0.9666731 , -0.8721832 ,  0.743239  ,  0.04293209,\n-0.5673905 , -0.14399827, -0.41138482,  0.8764746 , -0.11112919,\n 0.21457899,  0.88060266,  0.88843846,  0.18521515, -0.84538144,\n-0.57872075,  0.7840174 ,  0.8682007 , -0.5286343 ,  0.2563142 ,\n 0.9634152 ,  0.03505438,  0.91062546,  0.3279442 , -0.61855054,\n 0.22826263,  0.42789218, -0.48171976, -0.13283452, -0.86695194,\n 0.9060679 ,  0.78916115,  0.16227603, -0.36374012, -0.5703023 ,\n 0.19644596, -0.6927085 ,  0.19042683, -0.43984833, -0.7866716 ,\n 0.9690585 , -0.42288277,  0.8037468 ,  0.70858365,  0.87470776,\n 0.630474  ,  0.17134413,  0.99327976, -0.46532467, -0.00972999,\n 0.9460259 ,  0.09055056,  0.7293024 , -0.9081666 ,  0.15192512,\n-0.8813194 , -0.7241285 ,  0.11484392,  0.5220332 ,  0.6182944 ,\n 0.5697724 ,  0.80298615, -0.916839  ,  0.8679731 ,  0.3047138 ,\n-0.7162764 , -0.852553  ,  0.8317937 ,  0.6582049 , -0.06668244,\n 0.36977607,  0.80465484,  0.10356631,  0.5558003 ,  0.29966184,\n 0.93551975, -0.89290446,  0.15027076, -0.66376805, -0.6382408 ,\n 0.6717352 ,  0.9509484 , -0.79286   , -0.18582785, -0.36172768,\n-0.9791676 , -0.94657   , -0.47834975,  0.4030182 ,  0.8983884 ,\n 0.74833804, -0.24173705, -0.6059107 ],\n[ 0.01938096, -0.08230975,  0.2434453 , -0.8368162 , -0.31632444,\n-0.137336  ,  0.8550923 , -0.51500845,  0.5093535 ,  0.7847338 ,\n 0.2958318 , -0.3608949 ,  0.3377346 ,  0.7592404 , -0.10613706,\n 0.45210105, -0.39598942, -0.32519925,  0.89480245,  0.6049605 ,\n-0.81980604,  0.6129146 ,  0.5854233 ,  0.8875059 ,  0.8888534 ,\n 0.38860276, -0.81435287, -0.8599018 , -0.7989145 ,  0.87724596,\n-0.09401844,  0.8232204 ,  0.5973142 , -0.47759202, -0.2035289 ,\n 0.86339366, -0.78711975, -0.8843788 ,  0.50736386,  0.7154904 ,\n 0.02759624, -0.29022685, -0.21070601,  0.37119249, -0.93711466,\n-0.41830346,  0.49852479,  0.7634121 , -0.73495114, -0.8023139 ,\n-0.56360126,  0.7008394 ,  0.9837745 , -0.09430382,  0.35603583,\n 0.98780483,  0.3609371 , -0.31916958, -0.48238578, -0.65934813,\n 0.67085034, -0.43169144,  0.86363876, -0.1453511 , -0.8397705 ,\n-0.35035503,  0.88129896,  0.16335464,  0.34733585,  0.24485897,\n-0.5006221 , -0.9430847 , -0.80959797, -0.8578838 , -0.7431067 ,\n 0.49626076, -0.03579912, -0.5582668 ,  0.9786438 ,  0.2536843 ,\n 0.895339  , -0.42590025,  0.9813974 ,  0.4913268 , -0.95859706,\n 0.5229873 , -0.75750285,  0.01685579, -0.37524623, -0.4403388 ,\n-0.91602516, -0.63672376,  0.28235126,  0.5060775 ,  0.03505507,\n 0.8782664 ,  0.06858374, -0.81789017,  0.41628596,  0.9114354 ,\n 0.79067975, -0.76645094,  0.90893763,  0.95445615, -0.8870664 ,\n 0.50881255,  0.30905575,  0.4437762 , -0.2528932 , -0.14799164,\n 0.93950725, -0.7908481 ,  0.44684762, -0.9644589 ,  0.37588173,\n 0.9690541 , -0.6058538 ,  0.2965665 , -0.07335383, -0.6774956 ,\n-0.9477332 , -0.8670143 ,  0.03564278, -0.8282162 ,  0.24308446,\n 0.5860108 , -0.93586445, -0.8312509 ]], dtype=float32)]",
            "title": "Self Attention Layers"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/self-attention/#transformerlayer",
            "text": "A network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Refer to this  paper  for more details.  Input is a Table which consists of 2 tensors.   Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary  Position id tensor: shape (batch, seqLen) with positions in the sentence.   Output is a Table as well.   The states of Transformer layer.  The pooled output which processes the hidden state of the last layer with regard to the first token of the sequence. This would be useful for segment-level tasks.   With Default Embedding:  Scala:  TransformerLayer[Float](vocab = 40990,\n    seqLen = 77,\n    nBlock = 12,\n    residPdrop = 0.1,\n    attnPdrop = 0.1,\n    nHead = 12,\n    hiddenSize = 768,\n    embeddingDrop = 0,\n    initializerRange = 0.02,\n    bidirectional = false,\n    outputAllBlock = false)  Python:  TransformerLayer.init(vocab=40990, seq_len=77, n_block=12, hidden_drop=0.1,\n    attn_drop=0.1, n_head=12, hidden_size=768,\n    embedding_drop=0.1, initializer_range=0.02,\n    bidirectional=False, output_all_block=False)  Parameters:   vocab : vocabulary size of training data, default is 40990  seqLen : max sequence length of training data, default is 77  nBlock : block number, default is 12  residPdrop : drop probability of projection, default is 0.1  attnPdrop : drop probability of attention, default is 0.1  nHead : head number, default is 12  hiddenSize : is also embedding size  embeddingDrop : drop probability of embedding layer, default is 0.1  initializerRange : weight initialization range, default is 0.02  bidirectional : whether unidirectional or bidirectional, default is false  outputAllBlock : whether output all blocks' output, default is false   With Customized Embedding:  Scala:  TransformerLayer[Float](nBlock = 12,\n    residPdrop = 0.1,\n    attnPdrop = 0.1,\n    nHead = 12,\n    bidirectional = false,\n    initializerRange = 0.02,\n    outputAllBlock = true,\n    embeddingLayer = embedding.asInstanceOf[KerasLayer[Activity, Tensor[Float], Float]])  Python:  TransformerLayer(n_block=12,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    n_head=12,\n    initializer_range=0.02,\n    bidirectional=False,\n    output_all_block=False,\n    embedding_layer=embedding,\n    input_shape=((seq_len,), (seq_len,)),\n    intermediate_size=0)  Parameters:   nBlock : block number  residPdrop : drop probability of projection  attnPdrop : drop probability of attention  nHead : head number  initializerRange : weight initialization range  bidirectional : whether unidirectional or bidirectional  outputAllBlock : whether output all blocks' output  embeddingLayer : embedding layer   Scala example:  val shape1 = Shape(20)\nval shape2 = Shape(20)\nval input1 = Variable[Float](shape1)\nval input2 = Variable[Float](shape2)\nval input = Array(input1, input2)\nval seq = TransformerLayer[Float](200, hiddenSize = 128, nHead = 8,\n  seqLen = 20, nBlock = 1).from(input: _*)\nval model = Model[Float](input, seq)\n\nval trainToken = Tensor[Float](1, 20).rand()\nval trainPos = Tensor.ones[Float](1, 20)\nval input3 = T(trainToken, trainPos)\nval output = model.forward(input3)  Input is:  {\n2: 1.0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x20]\n1: 0.8087359    0.16409875  0.7404631   0.4836999   0.034994964 0.033039592 0.6694243   0.84700763  0.32154092  0.17410904  0.66117364  0.30495027  0.19573595  0.058101892 0.65923077  0.84077805  0.50113535  0.48393667  0.06523132  0.0667426\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20]\n}  Output is:  {\n2: 0.83383083   0.72725344  0.16394942  -0.79005975 0.8877357   -0.9060916  -0.6796065  0.46835706  -0.4700584  0.43868023  0.6641587   0.6711142   -0.70056283 -0.42694178 0.7615595   -0.25590983 0.21654142  0.35254374  0.83790034  0.1103606   -0.20419843 -0.9739706  0.6150182   0.4499923   0.3355538   -0.01543447 -0.99528116 0.45984524  -0.22544041 0.10049125  0.8418835   -0.116228305    -0.112435654    0.5183222   -0.59375525 0.31828925  0.50506884  0.14892755  0.94327587  -0.19001998 0.54074824  -0.07616825 -0.79334164 -0.49726814 0.23889944  -0.91731304 -0.5484148  0.5048103   0.9743351   0.10505025  0.81167877  -0.47498485 -0.83443964 -0.89340115 0.6443838   0.10184191  -0.38618097 -0.32026938 0.51587516  -0.40602723 -0.2931675  -0.86100364 0.109585665 0.9023708   0.46609795  0.0028693299    -0.5746851  -0.45607233 -0.9075561  -0.91294044 0.8077997   0.23019081  0.51124465  -0.39125186 0.16946821  -0.36827865 -0.32563296 0.62560886  -0.7278883  0.8076773   0.89344263  -0.9259615  0.21476166  0.67077845  0.5857905   -0.32905066 -0.16318946 0.6435858   -0.28905967 -0.6991412  -0.5289766  -0.6954091  0.1577004   0.5618301   -0.6290018  0.114078626 -0.52474076 0.27916297  -0.76610357 0.67119384  -0.4308661  0.063731246 -0.5281069  -0.65910465 0.5383283   -0.2875557  0.24594739  -0.6789035  0.7002648   -0.64659894 -0.70994437 -0.8416273  0.4666695   -0.55062526 0.14995292  -0.978979   0.40934727  -0.9028927  0.38194665  0.2334618   -0.9481384  -0.51903373 -0.947906   0.2667679   -0.76987743 -0.7490675  0.6777159   0.9593161\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x128]\n1: (1,.,.) =\n   0.8369983    -0.9907519  0.74404025  ... 0.6154673   0.107825294 -0.806892\n   0.7676861    -0.962961   0.73240614  ... 0.534349    0.0049344404    -0.81643736\n   0.7487803    -0.9717681  0.7315394   ... 0.59831613  0.010904985 -0.82502025\n   ...\n   0.06956328   -1.2103055  1.4155688   ... -0.759053   0.6966926   -0.53496075\n   0.0759853    -1.2265961  1.4023252   ... -0.7500985  0.68647313  -0.52275336\n   0.06356962   -1.2309887  1.3984702   ... -0.751963   0.69192046  -0.52820134\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x20x128]\n}  Python example:  model = TransformerLayer.init(\n    vocab=200, hidden_size=128, n_head=4, seq_len=20)\n\ntrain_token = np.random.randint(20, size=(2, 20))\ntrain_pos = np.zeros((2, 20), dtype=np.int32)\ninput = [train_token, train_pos]\noutput = model.forward(input)  Input is:  <type 'list'>: [array([[11,  2, 16,  6, 17, 18,  2,  4,  5, 16, 18, 15, 13, 19,  5, 15,\n    14, 14,  2,  9],\n   [10, 15, 13,  6, 12,  0, 11,  3, 16, 13,  6, 13, 17, 13,  3,  4,\n    15,  5,  7, 15]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n  dtype=int32)]  Output is  <type 'list'>: [array([[[ 0.26004127, -0.31793368, -1.1605529 , ..., -0.81875914,\n -0.02121837, -0.8328352 ],\n[-0.8622302 , -0.35201085,  0.63190293, ...,  2.0652232 ,\n  1.5278    ,  0.38224357],\n[-2.5103235 ,  1.4465114 ,  0.71134603, ...,  1.1776686 ,\n  0.6882701 ,  0.3534629 ],\n...,\n[-0.22725764,  1.2112792 , -0.40597847, ...,  2.2241254 ,\n  0.2580125 , -1.1470895 ],\n[-0.56174546,  1.3353435 , -0.7445968 , ...,  1.1259638 ,\n  0.6951011 , -1.1421459 ],\n[-0.6615135 ,  1.1899865 , -0.81727505, ...,  2.0474243 ,\n  0.20160393, -0.7789728 ]],\n\n[[-1.1624268 , -0.5375418 , -0.7274868 , ..., -0.99061227,\n -0.57117355,  1.0684316 ],\n[ 0.11317759, -0.7231343 ,  0.7723393 , ...,  1.6518786 ,\n  1.0916579 ,  0.18682887],\n[-1.9651127 ,  0.9987117 ,  0.32025027, ...,  0.94719195,\n -0.21028236, -0.02251417],\n...,\n[-0.6677234 ,  0.69822913, -0.9714249 , ...,  2.208334  ,\n  0.7719772 , -0.93855625],\n[-0.63691545,  1.3876344 , -0.8491991 , ...,  2.060551  ,\n  0.34702447, -0.8160082 ],\n[-0.6608573 ,  1.2608795 , -0.46634364, ...,  2.100828  ,\n  0.2967869 , -1.0938305 ]]], dtype=float32), array([[ 0.06879381,  0.6821829 , -0.8267953 , -0.02695777, -0.53899264,\n 0.8241045 ,  0.6976903 ,  0.31741282,  0.23590134,  0.5565326 ,\n 0.95292866,  0.5658284 , -0.2916065 , -0.37934095, -0.2774958 ,\n 0.73409927, -0.71731025,  0.07897043,  0.88609815, -0.27966806,\n 0.93520796,  0.72740096,  0.1626402 , -0.26063287,  0.28597558,\n-0.12945679,  0.7151408 , -0.8463592 , -0.48385444, -0.29313505,\n 0.86453205, -0.93834317,  0.41815573,  0.92436415,  0.8209114 ,\n 0.6627246 , -0.574135  ,  0.607416  ,  0.04769071, -0.29779348,\n-0.26268572, -0.78998053, -0.7522611 ,  0.89941144, -0.15754697,\n 0.9298859 , -0.8327022 , -0.63423705, -0.63789636, -0.14168388,\n-0.56104964, -0.80995566,  0.9244693 ,  0.4679966 , -0.16284083,\n 0.8478645 ,  0.29836348, -0.15369722, -0.4490478 ,  0.11052075,\n 0.23767054,  0.59320366, -0.79055625,  0.22201608, -0.88366413,\n-0.4410687 ,  0.8762162 , -0.6516914 , -0.5993653 , -0.5972125 ,\n-0.86697286, -0.17644943,  0.95839834, -0.06382846,  0.7430881 ,\n-0.59690744,  0.3901914 ,  0.06803267,  0.9142394 ,  0.7583274 ,\n-0.18442968,  0.56280667, -0.37844184, -0.41195455, -0.8376329 ,\n 0.87641823, -0.98970294, -0.6764397 , -0.86945957, -0.69273126,\n 0.9911777 ,  0.417286  , -0.8774987 ,  0.17141937,  0.7204654 ,\n-0.62387246, -0.8795049 ,  0.62618923, -0.29725042, -0.4565646 ,\n-0.47798416, -0.97555065, -0.94241685, -0.97800356,  0.8523641 ,\n-0.96860206,  0.5378995 , -0.73754525, -0.01649606, -0.4274561 ,\n-0.5290453 ,  0.11851768,  0.48821065,  0.4822751 ,  0.49497148,\n-0.5734494 , -0.29612035, -0.7254394 , -0.1418346 , -0.56686646,\n 0.03665365, -0.9586826 , -0.0983429 , -0.09348761, -0.96338177,\n 0.76481736,  0.87975204,  0.70463663],\n[-0.09654156,  0.78266025, -0.9125131 , -0.6706971 , -0.58709925,\n-0.94729275, -0.32309514, -0.95263994,  0.2036015 , -0.9297767 ,\n 0.6164713 ,  0.3484337 ,  0.46247053,  0.21615174, -0.8382687 ,\n-0.55828595, -0.59234536, -0.9643932 ,  0.9310115 , -0.12657425,\n 0.63812125,  0.80040973, -0.47581342,  0.9823402 , -0.5400171 ,\n 0.5864317 , -0.19979174, -0.5721838 ,  0.9190707 ,  0.31628668,\n 0.08952013,  0.8719338 ,  0.26684833,  0.8955768 , -0.9275499 ,\n-0.81994563,  0.28863704, -0.16376448,  0.15855551,  0.04302022,\n 0.4440408 , -0.7293209 ,  0.2255107 ,  0.16333969,  0.38721767,\n-0.04512435, -0.5473172 , -0.5812051 , -0.8219114 , -0.43659028,\n-0.04860768, -0.8912252 ,  0.62100273,  0.7187475 , -0.06158534,\n 0.6554498 , -0.62163985,  0.63035303,  0.19207267, -0.68847877,\n 0.10341872, -0.88906926, -0.38804066, -0.8157233 , -0.81641346,\n 0.8846337 , -0.70225614,  0.6281251 , -0.81235796,  0.77828485,\n 0.9393982 , -0.42554784,  0.4150426 , -0.32612413, -0.721988  ,\n 0.96166253, -0.6080237 , -0.7312329 ,  0.06843777, -0.09806018,\n-0.7357863 , -0.28613612, -0.8895085 , -0.9027925 ,  0.56311375,\n 0.85699487, -0.32128897,  0.80635303, -0.01190906, -0.23292968,\n-0.5115769 ,  0.17153661, -0.79993784,  0.6232265 , -0.06049479,\n-0.83510727,  0.9652135 ,  0.08310007, -0.9671807 , -0.17466563,\n 0.48009604,  0.594712  ,  0.19612817, -0.9279629 , -0.59968966,\n-0.36079255, -0.7250685 ,  0.59395283,  0.7574965 , -0.4377294 ,\n 0.45312116,  0.7117049 , -0.82085943, -0.10442825,  0.73688287,\n 0.38598123,  0.35439053, -0.3862137 , -0.56253886,  0.7388591 ,\n-0.6024478 , -0.699977  , -0.46581215, -0.79513186,  0.09657894,\n 0.280869  , -0.38445532, -0.98311806]], dtype=float32)]",
            "title": "TransformerLayer"
        },
        {
            "location": "/KerasStyleAPIGuide/Layers/self-attention/#bert",
            "text": "Bidirectional Encoder Representations from Transformers. Refer https://arxiv.org/pdf/1810.04805.pdf  Input is a Table which consists of 4 tensors.   Token id tensor: shape (batch, seqLen) with the word token indices in the vocabulary  Token type id tensor: shape (batch, seqLen) with the token types in (0, 1).\n   0 means  sentence A  and 1 means a  sentence B  (see BERT paper for more details).  Position id tensor: shape (batch, seqLen) with positions in the sentence.  Attention_mask tensor: shape (batch, seqLen) with indices in (0, 1).\n  It's a mask to be used if the input sequence length is smaller than seqLen in the current batch.   Output is a Table as well.   The states of BERT layer.  The pooled output which processes the hidden state of the last layer with regard to the first token of the sequence. This would be useful for segment-level tasks.   With Default Embedding:  Scala:  BERT[Float](vocab: Int = 40990,\n    hiddenSize: Int = 768,\n    nBlock: Int = 12,\n    nHead: Int = 12,\n    maxPositionLen: Int = 512,\n    intermediateSize: Int = 3072,\n    hiddenPDrop: Double = 0.1,\n    attnPDrop: Double = 0.1,\n    initializerRange: Double = 0.02,\n    outputAllBlock: Boolean = true,\n    inputSeqLen: Int = -1)  Python:  BERT.init(vocab=40990,\n    hidden_size=768,\n    n_block=12,\n    n_head=12,\n    seq_len=512,\n    intermediate_size=3072,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    initializer_range=0.02,\n    output_all_block=True)  Parameters:   vocab : vocabulary size of training data, default is 40990  hiddenSize : size of the encoder layers, default is 768  nBlock : block number, default is 12  nHead : head number, default is 12  maxPositionLen : sequence length, default is 512  intermediateSize : The size of the \"intermediate\" (i.e., feed-forward), default is 3072  hiddenPDrop : The dropout probability for all fully connected layers, default is 0.1  attnPDrop : drop probability of attention, default is 0.1  initializerRange : weight initialization range, default is 0.02  outputAllBlock : whether output all blocks' output, default is false  inputSeqLen : sequence length of input, default is -1 which means the same with maxPositionLen   With Customized Embedding:  Scala:  BERT[Float](nBlock = 12,\n    nHead = 12,\n    intermediateSize = 3072,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    initializerRange = 0.02,\n    outputAllBlock = true,\n    embeddingLayer = embedding)  Python:  BERT(n_block=12,\n    n_head=12,\n    intermediate_size=3072,\n    hidden_drop=0.1,\n    attn_drop=0.1,\n    initializer_range=0.02,\n    output_all_block=True,\n    embedding_layer=embedding,\n    input_shape=((seq_len,), (seq_len,), (seq_len,), (1, 1, seq_len)))  Parameters:   nBlock : block number  nHead : head number  intermediateSize : The size of the \"intermediate\" (i.e., feed-forward)  hiddenPDrop : The dropout probability for all fully connected layers  attnPdrop : drop probability of attention  initializerRange : weight initialization range  outputAllBlock : whether output all blocks' output  embeddingLayer : embedding layer   Loading from existing pretrained model:  Scala:  BERT[Float](path = \"\",\n    weightPath = null,\n    inputSeqLen = 11,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    outputAllBlock = true)  Python:  BERT.init_from_existing_model(path=\"\",\n    weight_path=None,\n    input_seq_len=-1.0,\n    hidden_drop=-1.0,\n    attn_drop=-1.0,\n    output_all_block=True)  Parameters:   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any  inputSeqLen : sequence length of input, will be ignored if existing model is built with customized embedding  hiddenPDrop : The dropout probability for all fully connected layers, will be ignored if existing model is built with customized embedding  attnPdrop : drop probability of attention, will be ignored if existing model is built with customized embedding   Scala example:  val layer = BERT[Float](vocab = 100,\n    hiddenSize = 10,\n    nBlock = 3,\n    nHead = 2,\n    intermediateSize = 64,\n    hiddenPDrop = 0.1,\n    attnPDrop = 0.1,\n    maxPositionLen = 10,\n    outputAllBlock = false,\n    inputSeqLen = 10)\n\nval shape = Shape(List(Shape(1, 10), Shape(1, 10), Shape(1, 10), Shape(1, 1, 1, 10)))\nlayer.build(shape)\nval inputIds = Tensor[Float](Array[Float](7, 20, 39, 27, 10,\n  39, 30, 21, 17, 15), Array(1, 10))\nval segmentIds = Tensor[Float](Array[Float](0, 0, 0, 0, 0, 1, 1, 1, 1, 1), Array(1, 10))\nval positionIds = Tensor[Float](Array[Float](0, 1, 2, 3, 4, 5, 6, 7, 8, 9), Array(1, 10))\nval masks = Tensor[Float](1, 1, 1, 10).fill(1.0f)\n\nval output = layer.forward(T(inputIds, segmentIds, positionIds, masks))  Input is:  {\n2: 0.0  0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n4: (1,1,.,.) =\n   1.0  1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x10]\n1: 7.0  20.0    39.0    27.0    10.0    39.0    30.0    21.0    17.0    15.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n3: 0.0  1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n}  Output is:  {\n2: 0.5398573    0.08571402  -0.9461041  -0.35362077 -0.24374364 0.24349216  0.9587727   -0.03278971 -0.826852   -0.8808889\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10]\n1: (1,.,.) =\n   1.3381815    1.7575556   -1.1870699  0.8455374   -1.6000531  0.115945406 -0.33695826 -0.39254665 -0.33637434 -0.20421773\n   -0.08370285  0.056055143 -0.91990083 1.6324282   -0.093128644    -0.4484297  -2.0828273  0.10244746  0.577287    1.2597716\n   0.3563086    0.37092525  -0.5089354  0.4525072   1.7706354   0.65231055  -2.0269241  -0.2548585  0.3711578   -1.1831268\n   0.2429675    -0.023419544    -0.28389466 0.6601246   -0.009858845    -0.028412571    -2.5104556  1.0338438   1.3621751   -0.44306967\n   1.7147139    1.1627073   -0.19394834 0.8043055   -1.0080436  -1.7716306  -0.7668168  -0.19861369 0.45103902  -0.19371253\n   0.077525005  0.0722655   1.0745171   0.07997274  0.06562643  1.6474637   0.18938908  -2.377528   -0.6107291  -0.21850263\n   -1.3190242   1.7057956   0.32655835  0.5711799   -0.80318034 0.2776545   1.4860673   -0.676896   -0.39734793 -1.1708072\n   -0.4327645   -0.19849697 0.3695452   -0.08213705 1.2378154   0.591234    -1.505518   1.684885    -1.6251724  -0.03939093\n   0.6422535    -0.582018   1.6665243   -1.0995792  0.19488664  1.3563607   -0.60793823 -0.05846788 -1.7225715  0.21054967\n   -1.0927358   -0.37666538 0.70802236  -2.0131714  0.94964516  1.4701655   0.053027537 0.051168486 -0.58528    0.83582383\n\n   [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x10x10]\n}  Python example:  layer = BERT.init(\n    vocab=200, hidden_size=128, n_head=4, seq_len=20, intermediate_size=20)\n\ntrain_token = np.random.randint(20, size=(2, 20))\ntoken_type_id = np.zeros((2, 20), dtype=np.int32)\ntrain_pos = np.zeros((2, 20), dtype=np.int32)\nmask_attention = np.ones((2, 1, 1, 20), dtype=np.int32)\ninput = [train_token, token_type_id, train_pos, mask_attention]\noutput = layer.forward(input)  Input is:  <type 'list'>: [array([[ 8, 19,  5,  8,  4, 13, 13, 12,  1,  6, 16, 14, 19,  0, 11, 18,\n 1, 17,  0,  0],\n[17, 10, 15, 19, 15,  2, 18,  8,  1, 11, 10, 17,  7,  2,  0,  0,\n 9, 14, 11,  6]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\ndtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\ndtype=int32), array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n\n[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]],\ndtype=int32)]  Output is  <type 'list'>: [array([[[ 1.01330066e+00,  4.74100798e-01,  3.81211847e-01, ...,\n -8.00989151e-01, -6.18815482e-01, -1.09804094e+00],\n[-6.29726201e-02,  6.71391249e-01, -2.28019580e-01, ...,\n  3.97501498e-01, -3.32217604e-01, -2.04850674e+00],\n[ 5.04802346e-01,  1.00434709e+00, -7.63663530e-01, ...,\n -1.11675525e+00,  1.41550392e-01, -6.47688091e-01],\n...,\n[ 5.07664750e-04,  6.47843182e-01, -5.33694960e-02, ...,\n -2.01566055e-01, -6.62943959e-01, -2.93835902e+00],\n[-1.49255514e-01, -5.47551095e-01, -3.36264402e-01, ...,\n  1.11121520e-01, -4.42977905e-01, -2.13847613e+00],\n[-1.33390293e-01, -5.50503194e-01, -3.49355727e-01, ...,\n  9.34313685e-02, -4.41935956e-01, -8.25921223e-02]],\n\n[[ 1.34967836e-02,  3.90778482e-02, -2.22317409e-02, ...,\n -9.81532633e-02, -6.08992100e-01, -2.77224326e+00],\n[-5.21431923e-01, -6.74456656e-02, -4.66892511e-01, ...,\n  1.05466165e-01, -2.67068297e-01, -9.00964141e-01],\n[ 9.41378593e-01,  5.21076620e-01, -5.35079956e-01, ...,\n -3.15736473e-01,  8.08603615e-02, -2.44178265e-01],\n...,\n[ 4.16017324e-02, -5.65874994e-01,  6.68676615e-01, ...,\n -6.28256857e-01, -9.09847617e-02, -2.42878512e-01],\n[-1.36971796e+00,  5.37231266e-01, -1.33729517e+00, ...,\n -1.47498712e-01,  8.00304264e-02, -5.09030581e-01],\n[ 3.98404837e-01, -7.18296226e-03, -1.08256066e+00, ...,\n -5.17360926e-01,  5.50065935e-01, -2.32753420e+00]]],\ndtype=float32), array([[[ 1.0795887 ,  0.44977495,  0.45561683, ..., -0.729603  ,\n -0.6098092 , -1.0323973 ],\n[ 0.0154253 ,  0.6424524 , -0.15503715, ...,  0.45100495,\n -0.3161888 , -1.9826275 ],\n[ 0.58491707,  0.9876782 , -0.69952184, ..., -1.0432141 ,\n  0.1380458 , -0.5642554 ],\n...,\n[ 0.06806332,  0.61824507,  0.02341641, ..., -0.21342012,\n -0.63312817, -2.8557966 ],\n[-0.06217962, -0.5528828 , -0.34740448, ...,  0.16651583,\n -0.41633344, -2.064906  ],\n[-0.04626712, -0.57442385, -0.277238  , ...,  0.13806444,\n -0.43256086, -0.01180306]],\n\n[[ 0.10532085,  0.01057051,  0.07536474, ..., -0.03406155,\n -0.572023  , -2.6935408 ],\n[-0.42477775, -0.10768362, -0.37653154, ...,  0.17155378,\n -0.27841952, -0.8244427 ],\n[ 1.0290473 ,  0.5059685 , -0.5359356 , ..., -0.25725254,\n  0.1034779 , -0.16898313],\n...,\n[ 0.14118548, -0.5945706 ,  0.7681386 , ..., -0.55807835,\n -0.07778832, -0.15940095],\n[-1.2648381 ,  0.50598496, -1.2431567 , ..., -0.06980868,\n  0.10642368, -0.4181047 ],\n[ 0.48330045, -0.05184587, -0.9985824 , ..., -0.5360492 ,\n  0.56541353, -2.2607849 ]]], dtype=float32), array([[[ 1.1541002 ,  0.47630545,  0.40673187, ..., -0.7284888 ,\n -0.55945337, -1.0810231 ],\n[ 0.10070852,  0.64252985, -0.2007717 , ...,  0.4489277 ,\n -0.24709189, -2.0173872 ],\n[ 0.67520154,  0.9793912 , -0.7441366 , ..., -1.0376649 ,\n  0.20359974, -0.6060102 ],\n...,\n[ 0.07809319,  0.63523245, -0.02464442, ..., -0.21328981,\n -0.5693355 , -2.8386393 ],\n[ 0.02228299, -0.5229728 , -0.33483037, ...,  0.16430138,\n -0.40036577, -2.094183  ],\n[ 0.02232744, -0.54113156, -0.3307599 , ...,  0.14321396,\n -0.3796677 , -0.04973204]],\n\n[[ 0.20497712,  0.02804335,  0.028764  , ..., -0.01617111,\n -0.5416485 , -2.7333891 ],\n[-0.3361876 , -0.08618001, -0.41299412, ...,  0.17708196,\n -0.23643918, -0.8763187 ],\n[ 1.1118197 ,  0.5178778 , -0.57264006, ..., -0.2597192 ,\n  0.15024357, -0.23373066],\n...,\n[ 0.23304611, -0.57528406,  0.71815467, ..., -0.5524511 ,\n -0.04103457, -0.15449452],\n[-1.1629226 ,  0.5377656 , -1.2816569 , ..., -0.05795323,\n  0.1603044 , -0.47194824],\n[ 0.5773567 , -0.04114214, -1.0306932 , ..., -0.52537155,\n  0.5703101 , -2.3124278 ]]], dtype=float32), array([[[ 1.1319652e+00,  4.2663044e-01,  3.9611375e-01, ...,\n -7.7264631e-01, -5.3006041e-01, -1.0942854e+00],\n[ 7.3858641e-02,  6.1578143e-01, -2.0985913e-01, ...,\n  4.0289888e-01, -2.2484708e-01, -2.0233095e+00],\n[ 6.3545388e-01,  9.4610500e-01, -7.6165521e-01, ...,\n -1.0820770e+00,  2.2266804e-01, -6.0132843e-01],\n...,\n[ 3.9479308e-02,  6.0636342e-01, -2.8302141e-02, ...,\n -2.6316714e-01, -5.5309945e-01, -2.8510940e+00],\n[-2.8412668e-03, -5.5100703e-01, -3.4540960e-01, ...,\n  1.5979633e-01, -3.8844827e-01, -2.0994248e+00],\n[-1.4572166e-02, -5.7526213e-01, -3.3382124e-01, ...,\n  1.0289014e-01, -3.6059290e-01, -6.5041430e-02]],\n\n[[ 1.5256011e-01,  3.3955947e-03,  1.7648729e-02, ...,\n -4.9600061e-02, -5.1613468e-01, -2.7417533e+00],\n[-3.6988521e-01, -8.8330485e-02, -4.2416954e-01, ...,\n  1.2959087e-01, -2.1623056e-01, -8.8821554e-01],\n[ 1.0618008e+00,  5.0827748e-01, -5.8256608e-01, ...,\n -2.9023758e-01,  1.6930477e-01, -2.3869993e-01],\n...,\n[ 1.8475071e-01, -5.8594310e-01,  7.0973599e-01, ...,\n -5.9211296e-01, -1.7043589e-02, -1.5649734e-01],\n[-1.2073172e+00,  5.1577950e-01, -1.2952001e+00, ...,\n -1.0562765e-01,  1.8499596e-01, -4.6483174e-01],\n[ 5.8209622e-01, -5.3714752e-02, -1.0255412e+00, ...,\n -5.6718546e-01,  5.9832001e-01, -2.3260906e+00]]], dtype=float32), array([[[ 1.1358043 ,  0.38664085,  0.43075162, ..., -0.762137  ,\n -0.53836805, -1.1419276 ],\n[ 0.0705715 ,  0.61749744, -0.1978054 , ...,  0.39686537,\n -0.23118263, -2.0863478 ],\n[ 0.6286853 ,  0.9499371 , -0.75073713, ..., -1.0837915 ,\n  0.20451419, -0.64585996],\n...,\n[ 0.04084783,  0.5485716 ,  0.02199897, ..., -0.265642  ,\n -0.54954815, -2.8985202 ],\n[-0.00433184, -0.5782148 , -0.28893095, ...,  0.15305014,\n -0.3942154 , -2.1390564 ],\n[-0.01938614, -0.6034715 , -0.3210429 , ...,  0.11286073,\n -0.3612479 , -0.12291119]],\n\n[[ 0.13899514, -0.04281238,  0.05966739, ..., -0.05543021,\n -0.51721877, -2.7725601 ],\n[-0.38874203, -0.13524944, -0.37960985, ...,  0.12579904,\n -0.23764463, -0.94251025],\n[ 1.0436667 ,  0.4891924 , -0.5470476 , ..., -0.30531114,\n  0.143379  , -0.28663573],\n...,\n[ 0.17597033, -0.6172772 ,  0.75050735, ..., -0.59396976,\n -0.02840331, -0.20918237],\n[-1.2121452 ,  0.47985265, -1.2640744 , ..., -0.11457531,\n  0.17777829, -0.5216857 ],\n[ 0.5724598 , -0.08497301, -0.99838203, ..., -0.569392  ,\n  0.5878865 , -2.3820512 ]]], dtype=float32), array([[[ 1.1923821 ,  0.40376186,  0.4216827 , ..., -0.7753511 ,\n -0.58085346, -1.1371452 ],\n[ 0.13859609,  0.6558944 , -0.1899949 , ...,  0.37358993,\n -0.27038255, -2.0870223 ],\n[ 0.7083764 ,  0.977537  , -0.76046735, ..., -1.101789  ,\n  0.1981793 , -0.6461577 ],\n...,\n[ 0.10095584,  0.5967537 ,  0.02207649, ..., -0.28193793,\n -0.5789527 , -2.9001386 ],\n[ 0.05901275, -0.53504837, -0.28481779, ...,  0.13802934,\n -0.41621858, -2.1443312 ],\n[ 0.04528951, -0.5612042 , -0.31392562, ...,  0.09289672,\n -0.38395336, -0.12475596]],\n\n[[ 0.19919002, -0.0038989 ,  0.06975131, ..., -0.05898362,\n -0.5476832 , -2.7802918 ],\n[-0.32966843, -0.10950038, -0.3582222 , ...,  0.08165199,\n -0.2624505 , -0.93702954],\n[ 1.119693  ,  0.5142474 , -0.5341173 , ..., -0.3251373 ,\n  0.10789905, -0.30592436],\n...,\n[ 0.24882485, -0.5699529 ,  0.77695113, ..., -0.63034034,\n -0.07624292, -0.2281592 ],\n[-1.1650497 ,  0.5175082 , -1.2281002 , ..., -0.14287077,\n  0.15133552, -0.532626  ],\n[ 0.64303875, -0.05680082, -0.9739305 , ..., -0.5787345 ,\n  0.5447517 , -2.403577  ]]], dtype=float32), array([[[ 1.1747141 ,  0.44174162,  0.3848741 , ..., -0.8011676 ,\n -0.5708256 , -1.143519  ],\n[ 0.11874287,  0.7037242 , -0.22899102, ...,  0.36200705,\n -0.22287843, -2.0832918 ],\n[ 0.68290263,  1.0014081 , -0.8112288 , ..., -1.0980991 ,\n  0.22316812, -0.637702  ],\n...,\n[ 0.07541095,  0.63492006,  0.02669529, ..., -0.27486983,\n -0.53397936, -2.8813968 ],\n[ 0.07104072, -0.54481   , -0.33232585, ...,  0.12730087,\n -0.37563673, -2.1450465 ],\n[ 0.03186123, -0.51601535, -0.35520643, ...,  0.09008651,\n -0.33910847, -0.11906879]],\n\n[[ 0.19884765,  0.06095114,  0.00477777, ..., -0.0960753 ,\n -0.49155453, -2.7463722 ],\n[-0.32222956, -0.08950429, -0.4053724 , ...,  0.05162536,\n -0.21072339, -0.9155606 ],\n[ 1.1117101 ,  0.56429935, -0.59156317, ..., -0.3369357 ,\n  0.14969075, -0.29045773],\n...,\n[ 0.25635508, -0.5126209 ,  0.7268977 , ..., -0.62107044,\n -0.01715574, -0.21087953],\n[-1.1460723 ,  0.56120336, -1.2668271 , ..., -0.16734022,\n  0.19381218, -0.517316  ],\n[ 0.63978064, -0.01486263, -1.0128225 , ..., -0.56719303,\n  0.58368987, -2.3722165 ]]], dtype=float32), array([[[ 1.20512652e+00,  4.72038895e-01,  3.60962778e-01, ...,\n -9.00623977e-01, -5.82258105e-01, -1.14907408e+00],\n[ 1.55033678e-01,  7.28412509e-01, -2.72546947e-01, ...,\n  2.74131984e-01, -2.24478737e-01, -2.06169677e+00],\n[ 7.13116527e-01,  1.01666617e+00, -8.43635857e-01, ...,\n -1.18351495e+00,  2.21053749e-01, -6.17874563e-01],\n...,\n[ 1.19287886e-01,  6.56103075e-01, -7.38978712e-03, ...,\n -3.54864419e-01, -5.37513494e-01, -2.87535477e+00],\n[ 1.16591401e-01, -5.55387378e-01, -3.71099353e-01, ...,\n  2.78753694e-02, -3.70597601e-01, -2.16417289e+00],\n[ 8.63942727e-02, -4.81025964e-01, -3.91344100e-01, ...,\n -1.84133966e-02, -3.39215338e-01, -1.10263892e-01]],\n\n[[ 2.64633745e-01,  7.25395158e-02, -1.39633343e-02, ...,\n -1.85173869e-01, -5.20042717e-01, -2.70796871e+00],\n[-2.58721560e-01, -6.35206550e-02, -4.14235502e-01, ...,\n  4.62563671e-02, -2.47269630e-01, -8.77729058e-01],\n[ 1.17845881e+00,  5.93900442e-01, -6.18097663e-01, ...,\n -4.23726231e-01,  1.19810022e-01, -2.55170494e-01],\n...,\n[ 3.06802571e-01, -4.83913153e-01,  7.05836833e-01, ...,\n -6.99279726e-01, -5.64565696e-02, -1.74492225e-01],\n[-1.07746637e+00,  5.83848476e-01, -1.28454113e+00, ...,\n -2.29663596e-01,  1.96212217e-01, -5.23399591e-01],\n[ 7.02956200e-01,  2.42653489e-03, -1.03614473e+00, ...,\n -6.54396653e-01,  5.55146933e-01, -2.35132337e+00]]],\ndtype=float32), array([[[ 1.1732985 ,  0.48227564,  0.4141097 , ..., -0.9222415 ,\n -0.5581617 , -1.1467376 ],\n[ 0.10594734,  0.75098526, -0.23052076, ...,  0.23048519,\n -0.23638739, -2.033264  ],\n[ 0.6784295 ,  1.0418617 , -0.810519  , ..., -1.2120562 ,\n  0.24596576, -0.60291487],\n...,\n[ 0.07915874,  0.6732479 ,  0.02875949, ..., -0.38714084,\n -0.5037479 , -2.8571    ],\n[ 0.07176737, -0.52642834, -0.31701285, ..., -0.01229298,\n -0.34029967, -2.1321528 ],\n[ 0.04126783, -0.46029058, -0.34176344, ..., -0.05429364,\n -0.31155083, -0.10451217]],\n\n[[ 0.22600769,  0.09270672,  0.02146479, ..., -0.22232075,\n -0.48217994, -2.6969097 ],\n[-0.29719839, -0.05968198, -0.37710896, ...,  0.02224515,\n -0.20888865, -0.872187  ],\n[ 1.1335284 ,  0.60064685, -0.58743286, ..., -0.45202363,\n  0.13883159, -0.2602308 ],\n...,\n[ 0.27142784, -0.47967467,  0.70926106, ..., -0.71909636,\n -0.01251143, -0.1811402 ],\n[-1.095905  ,  0.6111897 , -1.2443895 , ..., -0.27054876,\n  0.22430526, -0.5081292 ],\n[ 0.7027022 ,  0.01059689, -1.0006222 , ..., -0.6746712 ,\n  0.58800125, -2.352779  ]]], dtype=float32), array([[[ 1.2434555 ,  0.44558033,  0.4151337 , ..., -0.8851603 ,\n -0.5718673 , -1.1482117 ],\n[ 0.11962966,  0.72577155, -0.25604928, ...,  0.2687037 ,\n -0.2457071 , -2.0307996 ],\n[ 0.763747  ,  1.0119921 , -0.8592167 , ..., -1.1870402 ,\n  0.2256221 , -0.6277423 ],\n...,\n[ 0.08759235,  0.64535457,  0.03834408, ..., -0.35554865,\n -0.5139612 , -2.8475935 ],\n[ 0.13679026, -0.55156755, -0.32664305, ...,  0.01780019,\n -0.3558066 , -2.1313274 ],\n[ 0.11818186, -0.4789727 , -0.3590175 , ..., -0.01446133,\n -0.32358617, -0.10938768]],\n\n[[ 0.29418862,  0.09591774,  0.00587363, ..., -0.18236086,\n -0.49953887, -2.694323  ],\n[-0.22257486, -0.07352418, -0.4024905 , ...,  0.05929026,\n -0.22622454, -0.8882016 ],\n[ 1.19449   ,  0.5713768 , -0.6041051 , ..., -0.4231223 ,\n  0.1122172 , -0.28642637],\n...,\n[ 0.3465784 , -0.4939726 ,  0.68308717, ..., -0.68765515,\n -0.04439323, -0.20094715],\n[-1.0187647 ,  0.59667283, -1.2578517 , ..., -0.24298497,\n  0.19871093, -0.53237087],\n[ 0.71921486,  0.00342394, -1.026827  , ..., -0.63569874,\n  0.5502706 , -2.3338537 ]]], dtype=float32), array([[[ 1.2440691 ,  0.477769  ,  0.40438044, ..., -0.8634442 ,\n -0.516493  , -1.2156196 ],\n[ 0.09270077,  0.7480357 , -0.26808444, ...,  0.2696572 ,\n -0.19946648, -2.0294373 ],\n[ 0.7727248 ,  1.0203358 , -0.8804002 , ..., -1.1491328 ,\n  0.26056868, -0.70166045],\n...,\n[ 0.07362438,  0.6428618 ,  0.02992919, ..., -0.3656686 ,\n -0.47058144, -2.8904293 ],\n[ 0.11636666, -0.52916086, -0.3162666 , ...,  0.0035085 ,\n -0.32273746, -2.211205  ],\n[ 0.09450418, -0.46651682, -0.38872302, ..., -0.02868051,\n -0.284238  , -0.20115192]],\n\n[[ 0.24763471,  0.10591529, -0.02833212, ..., -0.19653179,\n -0.44746324, -2.6951957 ],\n[-0.2705241 , -0.05053078, -0.38580215, ...,  0.0737243 ,\n -0.18193349, -0.9320284 ],\n[ 1.1450722 ,  0.5878723 , -0.6142542 , ..., -0.4155699 ,\n  0.1653907 , -0.3516124 ],\n...,\n[ 0.31275982, -0.48012054,  0.6611108 , ..., -0.6956505 ,\n  0.01540092, -0.20229349],\n[-1.0758246 ,  0.6180846 , -1.2664212 , ..., -0.20339848,\n  0.25243902, -0.5957573 ],\n[ 0.6647455 ,  0.02233337, -1.0082287 , ..., -0.6396673 ,\n  0.6092897 , -2.3386178 ]]], dtype=float32), array([[[ 1.16829467e+00,  4.73457277e-01,  3.55845094e-01, ...,\n -8.79491448e-01, -5.13881445e-01, -1.31691360e+00],\n[ 2.06558462e-02,  7.50393629e-01, -2.97149330e-01, ...,\n  2.75190771e-01, -1.88330606e-01, -2.13159895e+00],\n[ 6.88944340e-01,  1.01597929e+00, -9.25147057e-01, ...,\n -1.15003026e+00,  2.47588441e-01, -7.96685874e-01],\n...,\n[ 2.88018938e-02,  6.88098967e-01, -2.68854816e-02, ...,\n -3.84741157e-01, -4.76365626e-01, -2.96942425e+00],\n[ 5.18963784e-02, -4.60506737e-01, -3.59559625e-01, ...,\n -1.14138005e-02, -3.24753582e-01, -2.23346853e+00],\n[ 7.39114806e-02, -4.01132107e-01, -4.24620807e-01, ...,\n -3.33240032e-02, -2.84682035e-01, -3.12762260e-01]],\n\n[[ 2.14906067e-01,  1.72432721e-01, -8.47420394e-02, ...,\n -2.10198522e-01, -4.30923790e-01, -2.79578996e+00],\n[-3.10599983e-01,  1.65538397e-03, -4.26579088e-01, ...,\n  5.09980768e-02, -1.56658575e-01, -1.01907480e+00],\n[ 1.09326482e+00,  6.40747488e-01, -6.59607410e-01, ...,\n -4.15965647e-01,  1.87072530e-01, -4.48307097e-01],\n...,\n[ 2.86490113e-01, -4.34108675e-01,  6.18547022e-01, ...,\n -7.17846394e-01,  3.06018218e-02, -2.91922033e-01],\n[-1.13503909e+00,  6.14412308e-01, -1.32140326e+00, ...,\n -2.04109967e-01,  2.61365235e-01, -6.73554838e-01],\n[ 6.21745884e-01,  8.54183882e-02, -1.06341887e+00, ...,\n -6.34258091e-01,  6.15509987e-01, -2.41539836e+00]]],\ndtype=float32), array([[ 0.5620128 , -0.2001392 , -0.11440954, -0.04526514, -0.8816746 ,\n-0.5549258 ,  0.51452374,  0.13439347,  0.53412014,  0.46277392,\n 0.8692565 , -0.90509814,  0.31514823,  0.8086619 ,  0.58900446,\n-0.3894673 , -0.45003602,  0.37346584,  0.69269675,  0.21574067,\n-0.72299725,  0.528553  , -0.83846116,  0.98062813, -0.05183166,\n 0.33388335, -0.63176596,  0.21661893,  0.43943346,  0.33758652,\n-0.24407507, -0.17800584,  0.59364974,  0.47616154,  0.558793  ,\n 0.27490366, -0.9666731 , -0.8721832 ,  0.743239  ,  0.04293209,\n-0.5673905 , -0.14399827, -0.41138482,  0.8764746 , -0.11112919,\n 0.21457899,  0.88060266,  0.88843846,  0.18521515, -0.84538144,\n-0.57872075,  0.7840174 ,  0.8682007 , -0.5286343 ,  0.2563142 ,\n 0.9634152 ,  0.03505438,  0.91062546,  0.3279442 , -0.61855054,\n 0.22826263,  0.42789218, -0.48171976, -0.13283452, -0.86695194,\n 0.9060679 ,  0.78916115,  0.16227603, -0.36374012, -0.5703023 ,\n 0.19644596, -0.6927085 ,  0.19042683, -0.43984833, -0.7866716 ,\n 0.9690585 , -0.42288277,  0.8037468 ,  0.70858365,  0.87470776,\n 0.630474  ,  0.17134413,  0.99327976, -0.46532467, -0.00972999,\n 0.9460259 ,  0.09055056,  0.7293024 , -0.9081666 ,  0.15192512,\n-0.8813194 , -0.7241285 ,  0.11484392,  0.5220332 ,  0.6182944 ,\n 0.5697724 ,  0.80298615, -0.916839  ,  0.8679731 ,  0.3047138 ,\n-0.7162764 , -0.852553  ,  0.8317937 ,  0.6582049 , -0.06668244,\n 0.36977607,  0.80465484,  0.10356631,  0.5558003 ,  0.29966184,\n 0.93551975, -0.89290446,  0.15027076, -0.66376805, -0.6382408 ,\n 0.6717352 ,  0.9509484 , -0.79286   , -0.18582785, -0.36172768,\n-0.9791676 , -0.94657   , -0.47834975,  0.4030182 ,  0.8983884 ,\n 0.74833804, -0.24173705, -0.6059107 ],\n[ 0.01938096, -0.08230975,  0.2434453 , -0.8368162 , -0.31632444,\n-0.137336  ,  0.8550923 , -0.51500845,  0.5093535 ,  0.7847338 ,\n 0.2958318 , -0.3608949 ,  0.3377346 ,  0.7592404 , -0.10613706,\n 0.45210105, -0.39598942, -0.32519925,  0.89480245,  0.6049605 ,\n-0.81980604,  0.6129146 ,  0.5854233 ,  0.8875059 ,  0.8888534 ,\n 0.38860276, -0.81435287, -0.8599018 , -0.7989145 ,  0.87724596,\n-0.09401844,  0.8232204 ,  0.5973142 , -0.47759202, -0.2035289 ,\n 0.86339366, -0.78711975, -0.8843788 ,  0.50736386,  0.7154904 ,\n 0.02759624, -0.29022685, -0.21070601,  0.37119249, -0.93711466,\n-0.41830346,  0.49852479,  0.7634121 , -0.73495114, -0.8023139 ,\n-0.56360126,  0.7008394 ,  0.9837745 , -0.09430382,  0.35603583,\n 0.98780483,  0.3609371 , -0.31916958, -0.48238578, -0.65934813,\n 0.67085034, -0.43169144,  0.86363876, -0.1453511 , -0.8397705 ,\n-0.35035503,  0.88129896,  0.16335464,  0.34733585,  0.24485897,\n-0.5006221 , -0.9430847 , -0.80959797, -0.8578838 , -0.7431067 ,\n 0.49626076, -0.03579912, -0.5582668 ,  0.9786438 ,  0.2536843 ,\n 0.895339  , -0.42590025,  0.9813974 ,  0.4913268 , -0.95859706,\n 0.5229873 , -0.75750285,  0.01685579, -0.37524623, -0.4403388 ,\n-0.91602516, -0.63672376,  0.28235126,  0.5060775 ,  0.03505507,\n 0.8782664 ,  0.06858374, -0.81789017,  0.41628596,  0.9114354 ,\n 0.79067975, -0.76645094,  0.90893763,  0.95445615, -0.8870664 ,\n 0.50881255,  0.30905575,  0.4437762 , -0.2528932 , -0.14799164,\n 0.93950725, -0.7908481 ,  0.44684762, -0.9644589 ,  0.37588173,\n 0.9690541 , -0.6058538 ,  0.2965665 , -0.07335383, -0.6774956 ,\n-0.9477332 , -0.8670143 ,  0.03564278, -0.8282162 ,  0.24308446,\n 0.5860108 , -0.93586445, -0.8312509 ]], dtype=float32)]",
            "title": "BERT"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/",
            "text": "This page shows how to train, evaluate or predict a model using the Keras-Style API.\n\n\nYou may refer to the \nUser Guide\n page to see how to define a model in \nPython\n or \nScala\n correspondingly.\n\n\nYou may refer to \nLayers\n section to find all the available layers.\n\n\nAfter defining a model with the Keras-Style API, you can call the following \nmethods\n on the model:\n\n\n\n\nCompile\n\n\nConfigure the learning process. Must be called before \nfit\n or \nevaluate\n.\n\n\nScala:\n\n\ncompile(optimizer, loss, metrics = null)\n\n\n\n\nParameters:\n\n\n\n\noptimizer\n: Optimization method to be used.\n\n\nloss\n: Criterion to be used.\n\n\nmetrics\n: Validation method(s) to be used. Default is null if no validation is needed. \n\n\n\n\nAlternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\")\n\n\nPython\n\n\ncompile(optimizer, loss, metrics=None)\n\n\n\n\nParameters:\n\n\n\n\noptimizer\n: Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'.\n\n\nloss\n: Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see \nhere\n).\n\n\nmetrics\n: List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy'].\n\n\n\n\n\n\nFit\n\n\nTrain a model for a fixed number of epochs on a DataSet.\n\n\nScala:\n\n\nfit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Training dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchSize\n: Number of samples per gradient update. Default is 32.\n\n\nnbEpoch\n: Number of epochs to train. Default is 10.\n\n\nvalidationData\n: RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null.\n\n\n\n\nPython\n\n\nfit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Training data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\ny\n: Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet.\n\n\nbatch_size\n: Number of samples per gradient update. Default is 32.\n\n\nnb_epoch\n: Number of epochs to train. Default is 10.\n\n\nvalidation_data\n: Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays.\n                    Can also be RDD of Sample or ImageSet or TextSet.\n                    Default is None if no validation is involved.\n\n\ndistributed\n: Boolean. Whether to train the model in distributed mode or local mode.\n                 Default is True. In local mode, x and y must both be Numpy arrays.\n\n\n\n\n\n\nEvaluate\n\n\nEvaluate a model on a given dataset in distributed mode.\n\n\nScala:\n\n\nevaluate(x, batchSize = 32)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Evaluation dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchSize\n: Number of samples per batch. Default is 32.\n\n\n\n\nPython\n\n\nevaluate(x, y=None, batch_size=32)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Evaluation data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\ny\n: Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet.\n\n\nbatch_size\n: Number of samples per batch. Default is 32.\n\n\n\n\n\n\nPredict\n\n\nUse a model to do prediction.\n\n\nScala:\n\n\npredict(x, batchPerThread = 4)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchPerThread\n: The total batchSize is batchPerThread * numOfCores.\n\n\n\n\nPython\n\n\npredict(x, batch_per_thread=4, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatch_per_thread\n:\n        The default value is 4.\n        When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False, the total batch size is batch_per_thread * numOfCores.\n\n\ndistributed\n: Boolean. Whether to do prediction in distributed mode or local mode.\n                 Default is True. In local mode, x must be a Numpy array.\n\n\n\n\nUse a model to predict class labels.\n\n\nScala:\n\n\npredictClasses(x, batchPerThread = 4, zeroBasedLabel = true)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchPerThread\n: The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions.\n\n\nzeroBasedLabel\n: Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1.\n\n\n\n\nPython\n\n\npredict_classes(x, batch_per_thread=4, zero_based_label=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatch_per_thread\n:\n        The default value is 4.\n        When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False the total batch size is batch_per_thread * numOfCores.\n\n\nzero_based_label\n: Boolean. Whether result labels start from 0.\n                      Default is True. If False, result labels start from 1.\n\n\n\n\nVisualization\n\n\nWe use tensorbroad-compatible tevent file to store the training and validation metrics. Then you could use tensorboard to visualize the training, or use analytics-zoo build-in API to read the metrics.\n\n\nEnable training metrics\n\n\nThe training metrics will be saved to \nlogDir/appName/training\n, and validation metrics will be saved to \nlogDir/appName/validation\n\n\nscala\n\n\nsetTensorBoard(logDir, appName)\n\n\n\n\nParameters:\n\n\n\n\nlogDir\n: The base directory path to store training and validation logs.\n\n\nappName\n: The name of the application.\n\n\n\n\npython\n\n\nset_tensorboard(log_dir, app_name)\n\n\n\n\nParameters:\n\n\n\n\nlog_dir\n: The base directory path to store training and validation logs.\n\n\napp_name\n: The name of the application.\n\n\n\n\nValidation with tensorboard\n\n\nTODO: add link\n\n\nReading metrics with build-in API\n\n\nTo get scalar metrics with build-in API, you can use following API. \n\n\nscala\n\n\ngetTrainSummary(tag)\n\n\n\n\nGet training metrics by tag. Parameters:  \n\n\n\n\ntag\n: The string variable represents the parameter you want to return supported tags are \"LearningRate\", \"Loss\", \"Throughput\".\n\n\n\n\nscala\n\n\ngetValidationSummary(tag)\n\n\n\n\nGet validation metrics by tag. Parameters:  \n\n\n\n\ntag\n: The string variable represents the parameter you want to return supported tags are 'AUC', 'Accuracy', 'BinaryAccuracy', 'CategoricalAccuracy', 'HitRatio', 'Loss', 'MAE', 'NDCG', 'SparseCategoricalAccuracy', 'TFValidationMethod', 'Top1Accuracy', 'Top5Accuracy', 'TreeNNAccuracy'.\n\n\n\n\npython\n\n\nget_train_summary(tag)\n\n\n\n\nGet training metrics by tag. Parameters:  \n\n\n\n\ntag\n: The string variable represents the parameter you want to return supported tags are \"LearningRate\", \"Loss\", \"Throughput\".\n\n\n\n\npython\n\n\nget_validation_summary(tag)\n\n\n\n\nGet validation metrics by tag. Parameters:  \n\n\n\n\ntag\n: The string variable represents the parameter you want to return supported tags are 'AUC', 'Accuracy', 'BinaryAccuracy', 'CategoricalAccuracy', 'HitRatio', 'Loss', 'MAE', 'NDCG', 'SparseCategoricalAccuracy', 'TFValidationMethod', 'Top1Accuracy', 'Top5Accuracy', 'TreeNNAccuracy'.",
            "title": "Train, evaluate or predict a model"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#compile",
            "text": "Configure the learning process. Must be called before  fit  or  evaluate .  Scala:  compile(optimizer, loss, metrics = null)  Parameters:   optimizer : Optimization method to be used.  loss : Criterion to be used.  metrics : Validation method(s) to be used. Default is null if no validation is needed.    Alternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\")  Python  compile(optimizer, loss, metrics=None)  Parameters:   optimizer : Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'.  loss : Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see  here ).  metrics : List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy'].",
            "title": "Compile"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#fit",
            "text": "Train a model for a fixed number of epochs on a DataSet.  Scala:  fit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null)  Parameters:   x : Training dataset. RDD of Sample or  ImageSet  or  TextSet .  batchSize : Number of samples per gradient update. Default is 32.  nbEpoch : Number of epochs to train. Default is 10.  validationData : RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null.   Python  fit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)  Parameters:   x : Training data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  y : Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet.  batch_size : Number of samples per gradient update. Default is 32.  nb_epoch : Number of epochs to train. Default is 10.  validation_data : Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays.\n                    Can also be RDD of Sample or ImageSet or TextSet.\n                    Default is None if no validation is involved.  distributed : Boolean. Whether to train the model in distributed mode or local mode.\n                 Default is True. In local mode, x and y must both be Numpy arrays.",
            "title": "Fit"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#evaluate",
            "text": "Evaluate a model on a given dataset in distributed mode.  Scala:  evaluate(x, batchSize = 32)  Parameters:   x : Evaluation dataset. RDD of Sample or  ImageSet  or  TextSet .  batchSize : Number of samples per batch. Default is 32.   Python  evaluate(x, y=None, batch_size=32)  Parameters:   x : Evaluation data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  y : Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet.  batch_size : Number of samples per batch. Default is 32.",
            "title": "Evaluate"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#predict",
            "text": "Use a model to do prediction.  Scala:  predict(x, batchPerThread = 4)  Parameters:   x : Prediction dataset. RDD of Sample or  ImageSet  or  TextSet .  batchPerThread : The total batchSize is batchPerThread * numOfCores.   Python  predict(x, batch_per_thread=4, distributed=True)  Parameters:   x : Prediction data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  batch_per_thread :\n        The default value is 4.\n        When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False, the total batch size is batch_per_thread * numOfCores.  distributed : Boolean. Whether to do prediction in distributed mode or local mode.\n                 Default is True. In local mode, x must be a Numpy array.   Use a model to predict class labels.  Scala:  predictClasses(x, batchPerThread = 4, zeroBasedLabel = true)  Parameters:   x : Prediction dataset. RDD of Sample or  ImageSet  or  TextSet .  batchPerThread : The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions.  zeroBasedLabel : Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1.   Python  predict_classes(x, batch_per_thread=4, zero_based_label=True)  Parameters:   x : Prediction data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  batch_per_thread :\n        The default value is 4.\n        When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False the total batch size is batch_per_thread * numOfCores.  zero_based_label : Boolean. Whether result labels start from 0.\n                      Default is True. If False, result labels start from 1.",
            "title": "Predict"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#visualization",
            "text": "We use tensorbroad-compatible tevent file to store the training and validation metrics. Then you could use tensorboard to visualize the training, or use analytics-zoo build-in API to read the metrics.",
            "title": "Visualization"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#enable-training-metrics",
            "text": "The training metrics will be saved to  logDir/appName/training , and validation metrics will be saved to  logDir/appName/validation  scala  setTensorBoard(logDir, appName)  Parameters:   logDir : The base directory path to store training and validation logs.  appName : The name of the application.   python  set_tensorboard(log_dir, app_name)  Parameters:   log_dir : The base directory path to store training and validation logs.  app_name : The name of the application.",
            "title": "Enable training metrics"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#validation-with-tensorboard",
            "text": "TODO: add link",
            "title": "Validation with tensorboard"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#reading-metrics-with-build-in-api",
            "text": "To get scalar metrics with build-in API, you can use following API.   scala  getTrainSummary(tag)  Get training metrics by tag. Parameters:     tag : The string variable represents the parameter you want to return supported tags are \"LearningRate\", \"Loss\", \"Throughput\".   scala  getValidationSummary(tag)  Get validation metrics by tag. Parameters:     tag : The string variable represents the parameter you want to return supported tags are 'AUC', 'Accuracy', 'BinaryAccuracy', 'CategoricalAccuracy', 'HitRatio', 'Loss', 'MAE', 'NDCG', 'SparseCategoricalAccuracy', 'TFValidationMethod', 'Top1Accuracy', 'Top5Accuracy', 'TreeNNAccuracy'.   python  get_train_summary(tag)  Get training metrics by tag. Parameters:     tag : The string variable represents the parameter you want to return supported tags are \"LearningRate\", \"Loss\", \"Throughput\".   python  get_validation_summary(tag)  Get validation metrics by tag. Parameters:     tag : The string variable represents the parameter you want to return supported tags are 'AUC', 'Accuracy', 'BinaryAccuracy', 'CategoricalAccuracy', 'HitRatio', 'Loss', 'MAE', 'NDCG', 'SparseCategoricalAccuracy', 'TFValidationMethod', 'Top1Accuracy', 'Top5Accuracy', 'TreeNNAccuracy'.",
            "title": "Reading metrics with build-in API"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/",
            "text": "Usage of optimizers\n\n\nAn optimizer is one of the two arguments required for compiling a model.\n\n\nScala:\n\n\nmodel.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\nScala:\n\n\nmodel.compile(loss = \"mean_squared_error\", optimizer = Adam())\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer=Adam())\n\n\n\n\n\n\nAvailable optimizers\n\n\nSGD\n\n\nA plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.\n\n\nScala:\n\n\nval optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, \n                      weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, \n                      nesterov = false, learningRateSchedule = Default(), \n                      learningRates = null, weightDecays = null)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\nweightDecay\n : weight decay\n\n\nmomentum\n : momentum\n\n\ndampening\n : dampening for momentum\n\n\nnesterov\n : enables Nesterov momentum\n\n\nlearningRateSchedule\n : learning rate scheduler\n\n\nlearningRates\n : 1D tensor of individual learning rates\n\n\nweightDecays\n : 1D tensor of individual weight decays\n\n\n\n\nPython:\n\n\noptim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, \n                   momentum=0.0, dampening=DOUBLEMAX, nesterov=False, \n                   leaningrate_schedule=None, learningrates=None, \n                   weightdecays=None)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\nweightdecay\n : weight decay\n\n\nmomentum\n : momentum\n\n\ndampening\n : dampening for momentum\n\n\nnesterov\n : enables Nesterov momentum\n\n\nleaningrate_schedule\n : learning rate scheduler\n\n\nlearningrates\n : 1D tensor of individual learning rates\n\n\nweightdecays\n : 1D tensor of individual weight decays\n\n\n\n\nAdam\n\n\nAn implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. \nhttp://arxiv.org/pdf/1412.6980.pdf\n\n\nScala:\n\n\nval optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n learning rate. Default value is 1e-3. \n\n\nlearningRateDecay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nEpsilon\n for numerical stability. Default value is 1e-8.\n\n\n\n\nPython:\n\n\noptim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n learning rate. Default value is 1e-3. \n\n\nlearningrate_decay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nepsilon\n for numerical stability. Default value is 1e-8.\n\n\n\n\nAdamax\n\n\nAn implementation of Adamax: \nhttp://arxiv.org/pdf/1412.6980.pdf\n\n\nScala:\n\n\nval optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nbeta1\n : first moment coefficient\n\n\nbeta2\n : second moment coefficient\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nbeta1\n : first moment coefficient\n\n\nbeta2\n : second moment coefficient\n\n\nepsilon\n : for numerical stability\n\n\n\n\nAdadelta\n\n\nAdaDelta\n implementation for \nSGD\n \nIt has been proposed in \nADADELTA: An Adaptive Learning Rate Method\n.\n\nhttp://arxiv.org/abs/1212.5701.\n\n\nScala:\n\n\nval optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)\n\n\n\n\nParameters:\n\n\n\n\ndecayRate\n : decayRate, also called interpolation parameter rho\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = AdaDelta(decayrate=0.9, epsilon=1e-10)\n\n\n\n\nParameters:\n\n\n\n\ndecayrate\n : decayRate, also called interpolation parameter rho\n\n\nepsilon\n : for numerical stability\n\n\n\n\nAdagrad\n\n\nAn implementation of Adagrad. See the original paper:\n \nhttp://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf\n\n\nScala:\n\n\nval optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0)\n\n\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\nweightDecay\n : weight decay\n\n\n\n\nPython:\n\n\noptim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\nweightdecay\n : weight decay\n\n\n\n\nRmsprop\n\n\nAn implementation of RMSprop (Reference: \nhttp://arxiv.org/pdf/1308.0850v5.pdf\n, Sec 4.2)\n\n\nScala:\n\n\nval optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\ndecayRate\n : decayRate, also called rho\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\ndecayrate\n : decayRate, also called rho\n\n\nepsilon\n : for numerical stability",
            "title": "Optimizers"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#usage-of-optimizers",
            "text": "An optimizer is one of the two arguments required for compiling a model.  Scala:  model.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")  Python:  model.compile(loss='mean_squared_error', optimizer='sgd')  Scala:  model.compile(loss = \"mean_squared_error\", optimizer = Adam())  Python:  model.compile(loss='mean_squared_error', optimizer=Adam())",
            "title": "Usage of optimizers"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#available-optimizers",
            "text": "",
            "title": "Available optimizers"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#sgd",
            "text": "A plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.  Scala:  val optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, \n                      weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, \n                      nesterov = false, learningRateSchedule = Default(), \n                      learningRates = null, weightDecays = null)  Parameters:   learningRate  : learning rate  learningRateDecay  : learning rate decay  weightDecay  : weight decay  momentum  : momentum  dampening  : dampening for momentum  nesterov  : enables Nesterov momentum  learningRateSchedule  : learning rate scheduler  learningRates  : 1D tensor of individual learning rates  weightDecays  : 1D tensor of individual weight decays   Python:  optim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, \n                   momentum=0.0, dampening=DOUBLEMAX, nesterov=False, \n                   leaningrate_schedule=None, learningrates=None, \n                   weightdecays=None)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  weightdecay  : weight decay  momentum  : momentum  dampening  : dampening for momentum  nesterov  : enables Nesterov momentum  leaningrate_schedule  : learning rate scheduler  learningrates  : 1D tensor of individual learning rates  weightdecays  : 1D tensor of individual weight decays",
            "title": "SGD"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adam",
            "text": "An implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions.  http://arxiv.org/pdf/1412.6980.pdf  Scala:  val optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)  Parameters:   learningRate  learning rate. Default value is 1e-3.   learningRateDecay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  Epsilon  for numerical stability. Default value is 1e-8.   Python:  optim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8)  Parameters:   learningrate  learning rate. Default value is 1e-3.   learningrate_decay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  epsilon  for numerical stability. Default value is 1e-8.",
            "title": "Adam"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adamax",
            "text": "An implementation of Adamax:  http://arxiv.org/pdf/1412.6980.pdf  Scala:  val optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)  Parameters:   learningRate  : learning rate  beta1  : first moment coefficient  beta2  : second moment coefficient  Epsilon  : for numerical stability   Python:  optim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8)  Parameters:   learningrate  : learning rate  beta1  : first moment coefficient  beta2  : second moment coefficient  epsilon  : for numerical stability",
            "title": "Adamax"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adadelta",
            "text": "AdaDelta  implementation for  SGD  \nIt has been proposed in  ADADELTA: An Adaptive Learning Rate Method . http://arxiv.org/abs/1212.5701.  Scala:  val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)  Parameters:   decayRate  : decayRate, also called interpolation parameter rho  Epsilon  : for numerical stability   Python:  optim_method = AdaDelta(decayrate=0.9, epsilon=1e-10)  Parameters:   decayrate  : decayRate, also called interpolation parameter rho  epsilon  : for numerical stability",
            "title": "Adadelta"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adagrad",
            "text": "An implementation of Adagrad. See the original paper:\n  http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf  Scala:  val optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0)   learningRate  : learning rate  learningRateDecay  : learning rate decay  weightDecay  : weight decay   Python:  optim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  weightdecay  : weight decay",
            "title": "Adagrad"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#rmsprop",
            "text": "An implementation of RMSprop (Reference:  http://arxiv.org/pdf/1308.0850v5.pdf , Sec 4.2)  Scala:  val optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8)  Parameters:   learningRate  : learning rate  learningRateDecay  : learning rate decay  decayRate  : decayRate, also called rho  Epsilon  : for numerical stability   Python:  optim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  decayrate  : decayRate, also called rho  epsilon  : for numerical stability",
            "title": "Rmsprop"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/",
            "text": "Usage of objectives\n\n\nAn objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:\n\n\nScala:\n\n\nmodel.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\nScala:\n\n\nmodel.compile(loss = MeanSquaredError(sizeAverage = true), optimizer = \"sgd\")\n\n\n\n\nPython:\n\n\nmodel.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd')\n\n\n\n\n\n\nAvailable objectives\n\n\nMeanSquaredError\n\n\nThe mean squared error criterion e.g. input: a, target: b, total elements: n\n\n\nloss(a, b) = 1/n * sum(|a_i - b_i|^2)\n\n\n\n\nScala:\n\n\nloss = MeanSquaredError(sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanSquaredError(size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nMeanAbsoluteError\n\n\nMeasures the mean absolute value of the element-wise difference between input and target\n\n\nScala:\n\n\nloss = MeanAbsoluteError(sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanAbsoluteError(size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nBinaryCrossEntropy\n\n\nAlso known as logloss. \n\n\nScala:\n\n\nloss = BinaryCrossEntropy(weights = null, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsizeAverage\n whether to divide the sequence length. Default is true.\n\n\n\n\nPython:\n\n\nloss = BinaryCrossEntropy(weights=None, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsize_average\n whether to divide the sequence length. Default is True.\n\n\n\n\nSparseCategoricalCrossEntropy\n\n\nA loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0.\n\n\nScala:\n\n\nloss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1)\n\n\n\n\nParameters:\n\n\n\n\nlogProbAsInput\n Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.\n\n\nzeroBasedLabel\n Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.\n\n\nweights\n Tensor. Weights of each class if you have an unbalanced training set. Default is null.\n\n\nsizeAverage\n Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch.\n\n\npaddingValue\n Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.\n\n\n\n\nPython:\n\n\nloss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1)\n\n\n\n\nParameters:\n\n\n\n\nlog_prob_as_input\n Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.\n\n\nzero_based_label\n Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.\n\n\nweights\n A Numpy array. Weights of each class if you have an unbalanced training set. Default is None.\n\n\nsize_average\n Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch.\n\n\npadding_value\n Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.\n\n\n\n\nMeanAbsolutePercentageError\n\n\nCompute mean absolute percentage error for intput and target\n\n\nScala:\n\n\nloss = MeanAbsolutePercentageError()\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanAbsolutePercentageError()\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nMeanSquaredLogarithmicError\n\n\nCompute mean squared logarithmic error for input and target\n\n\nScala:\n\n\nloss = MeanSquaredLogarithmicError()\n\n\n\n\nPython:\n\n\nloss = MeanSquaredLogarithmicError()\n\n\n\n\nCategoricalCrossEntropy\n\n\nThis is same with cross entropy criterion, except the target tensor is a\none-hot tensor.\n\n\nScala:\n\n\nloss = CategoricalCrossEntropy()\n\n\n\n\nPython:\n\n\nloss = CategoricalCrossEntropy()\n\n\n\n\nHinge\n\n\nCreates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n\n\nScala:\n\n\nloss = Hinge(margin = 1.0, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsizeAverage\n whether to average the loss, is by default true\n\n\n\n\nPython:\n\n\nloss = Hinge(margin=1.0, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsize_average\n whether to average the loss, is by default True\n\n\n\n\nRankHinge\n\n\nHinge loss for pairwise ranking problems.\n\n\nScala:\n\n\nloss = RankHinge(margin = 1.0)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\n\n\nPython:\n\n\nloss = RankHinge(margin=1.0)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\n\n\nSquaredHinge\n\n\nCreates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n\n\nScala:\n\n\nloss = SquaredHinge(margin = 1.0, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsizeAverage\n whether to average the loss, is by default true\n\n\n\n\nPython:\n\n\nloss = SquaredHinge(margin=1.0, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsize_average\n whether to average the loss, is by default True\n\n\n\n\nPoisson\n\n\nCompute Poisson error for intput and target\n\n\nScala:\n\n\nloss = Poisson()\n\n\n\n\nPython:\n\n\nloss = Poisson()\n\n\n\n\nCosineProximity\n\n\nComputes the negative of the mean cosine proximity between predictions and targets.\n\n\nScala:\n\n\nloss = CosineProximity()\n\n\n\n\nPython:\n\n\nloss = CosineProximity()\n\n\n\n\nKullbackLeiblerDivergence\n\n\nLoss calculated as:\n\n\ny_true = K.clip(y_true, K.epsilon(), 1)\ny_pred = K.clip(y_pred, K.epsilon(), 1)\n\n\n\n\nand output K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n\n\nScala:\n\n\nloss = KullbackLeiblerDivergence()\n\n\n\n\nPython:\n\n\nloss = KullbackLeiblerDivergence()",
            "title": "Objectives"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#usage-of-objectives",
            "text": "An objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:  Scala:  model.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")  Python:  model.compile(loss='mean_squared_error', optimizer='sgd')  Scala:  model.compile(loss = MeanSquaredError(sizeAverage = true), optimizer = \"sgd\")  Python:  model.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd')",
            "title": "Usage of objectives"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#available-objectives",
            "text": "",
            "title": "Available objectives"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meansquarederror",
            "text": "The mean squared error criterion e.g. input: a, target: b, total elements: n  loss(a, b) = 1/n * sum(|a_i - b_i|^2)  Scala:  loss = MeanSquaredError(sizeAverage = true)  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanSquaredError(size_average=True)  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True",
            "title": "MeanSquaredError"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meanabsoluteerror",
            "text": "Measures the mean absolute value of the element-wise difference between input and target  Scala:  loss = MeanAbsoluteError(sizeAverage = true)  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanAbsoluteError(size_average=True)  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True",
            "title": "MeanAbsoluteError"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#binarycrossentropy",
            "text": "Also known as logloss.   Scala:  loss = BinaryCrossEntropy(weights = null, sizeAverage = true)  Parameters:   weights  A tensor assigning weight to each of the classes  sizeAverage  whether to divide the sequence length. Default is true.   Python:  loss = BinaryCrossEntropy(weights=None, size_average=True)  Parameters:   weights  A tensor assigning weight to each of the classes  size_average  whether to divide the sequence length. Default is True.",
            "title": "BinaryCrossEntropy"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#sparsecategoricalcrossentropy",
            "text": "A loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0.  Scala:  loss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1)  Parameters:   logProbAsInput  Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.  zeroBasedLabel  Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.  weights  Tensor. Weights of each class if you have an unbalanced training set. Default is null.  sizeAverage  Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch.  paddingValue  Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.   Python:  loss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1)  Parameters:   log_prob_as_input  Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.  zero_based_label  Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.  weights  A Numpy array. Weights of each class if you have an unbalanced training set. Default is None.  size_average  Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch.  padding_value  Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.",
            "title": "SparseCategoricalCrossEntropy"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meanabsolutepercentageerror",
            "text": "Compute mean absolute percentage error for intput and target  Scala:  loss = MeanAbsolutePercentageError()  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanAbsolutePercentageError()  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True",
            "title": "MeanAbsolutePercentageError"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meansquaredlogarithmicerror",
            "text": "Compute mean squared logarithmic error for input and target  Scala:  loss = MeanSquaredLogarithmicError()  Python:  loss = MeanSquaredLogarithmicError()",
            "title": "MeanSquaredLogarithmicError"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#categoricalcrossentropy",
            "text": "This is same with cross entropy criterion, except the target tensor is a\none-hot tensor.  Scala:  loss = CategoricalCrossEntropy()  Python:  loss = CategoricalCrossEntropy()",
            "title": "CategoricalCrossEntropy"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#hinge",
            "text": "Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.  Scala:  loss = Hinge(margin = 1.0, sizeAverage = true)  Parameters:   margin  if unspecified, is by default 1.  sizeAverage  whether to average the loss, is by default true   Python:  loss = Hinge(margin=1.0, size_average=True)  Parameters:   margin  if unspecified, is by default 1.  size_average  whether to average the loss, is by default True",
            "title": "Hinge"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#rankhinge",
            "text": "Hinge loss for pairwise ranking problems.  Scala:  loss = RankHinge(margin = 1.0)  Parameters:   margin  if unspecified, is by default 1.   Python:  loss = RankHinge(margin=1.0)  Parameters:   margin  if unspecified, is by default 1.",
            "title": "RankHinge"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#squaredhinge",
            "text": "Creates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.  Scala:  loss = SquaredHinge(margin = 1.0, sizeAverage = true)  Parameters:   margin  if unspecified, is by default 1.  sizeAverage  whether to average the loss, is by default true   Python:  loss = SquaredHinge(margin=1.0, size_average=True)  Parameters:   margin  if unspecified, is by default 1.  size_average  whether to average the loss, is by default True",
            "title": "SquaredHinge"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#poisson",
            "text": "Compute Poisson error for intput and target  Scala:  loss = Poisson()  Python:  loss = Poisson()",
            "title": "Poisson"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#cosineproximity",
            "text": "Computes the negative of the mean cosine proximity between predictions and targets.  Scala:  loss = CosineProximity()  Python:  loss = CosineProximity()",
            "title": "CosineProximity"
        },
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#kullbackleiblerdivergence",
            "text": "Loss calculated as:  y_true = K.clip(y_true, K.epsilon(), 1)\ny_pred = K.clip(y_pred, K.epsilon(), 1)  and output K.sum(y_true * K.log(y_true / y_pred), axis=-1)  Scala:  loss = KullbackLeiblerDivergence()  Python:  loss = KullbackLeiblerDivergence()",
            "title": "KullbackLeiblerDivergence"
        },
        {
            "location": "/Zouwu/overview/",
            "text": "Project Zouwu: Analytics Zoo Time Series for Telco\n\n\nProject Zouwu provides a reference solution that is designed and optimized for common time series applications in the Telco industry, including:\n\n\n\n\nUse case\n - reference time series use cases in the Telco industry (such as network traffic forcasting, etc.)\n\n\nModel\n - built-in deep learning models for time series analysis (such as LSTM, \nMTNet\n and TCMF)\n\n\nAutoTS\n - AutoML support for building end-to-end time series analysis pipelines (including automatic feature generation, model selection and hyperparameter tuning).\n\n\n\n\nForecasting\n\n\nTime series forecasting has many applications in telco. Accurate forecast of telco KPIs (e.g. traffic, utilizations, user experience, etc.) for communication networks ( 2G/3G/4G/5G/wired) can help predict network failures, allocate resource, or save energy. Time series forecasting can also be used for log and metric analysis for data center IT operations for telco. Metrics to be analyzed can be hardware or VM utilizations, database metrics or servce quality indicators.\n\n\nWe provided a reference use case where we forecast network traffic KPI's as a demo. Refer to \nNetwork Traffic\n for forecasting.\n\n\nTo learn how to use built-in models, refer to tutorials (i.e. \nLSTMForecaster and MTNetForcaster\n, \nTCMFForecaster\n) and API docs (i.e. \nLSTMForecaster\n, \nMTNetForecaster\n) and \nTCMFForecaster\n for built-in models. \n\n\nTo learn how to use AutoTS, refer to \nAutoTS tutorial\n and API docs (i.e. \nAutoTSTrainer\n and \nTSPipeline\n) for automated training.",
            "title": "Overview"
        },
        {
            "location": "/Zouwu/overview/#project-zouwu-analytics-zoo-time-series-for-telco",
            "text": "Project Zouwu provides a reference solution that is designed and optimized for common time series applications in the Telco industry, including:   Use case  - reference time series use cases in the Telco industry (such as network traffic forcasting, etc.)  Model  - built-in deep learning models for time series analysis (such as LSTM,  MTNet  and TCMF)  AutoTS  - AutoML support for building end-to-end time series analysis pipelines (including automatic feature generation, model selection and hyperparameter tuning).",
            "title": "Project Zouwu: Analytics Zoo Time Series for Telco"
        },
        {
            "location": "/Zouwu/overview/#forecasting",
            "text": "Time series forecasting has many applications in telco. Accurate forecast of telco KPIs (e.g. traffic, utilizations, user experience, etc.) for communication networks ( 2G/3G/4G/5G/wired) can help predict network failures, allocate resource, or save energy. Time series forecasting can also be used for log and metric analysis for data center IT operations for telco. Metrics to be analyzed can be hardware or VM utilizations, database metrics or servce quality indicators.  We provided a reference use case where we forecast network traffic KPI's as a demo. Refer to  Network Traffic  for forecasting.  To learn how to use built-in models, refer to tutorials (i.e.  LSTMForecaster and MTNetForcaster ,  TCMFForecaster ) and API docs (i.e.  LSTMForecaster ,  MTNetForecaster ) and  TCMFForecaster  for built-in models.   To learn how to use AutoTS, refer to  AutoTS tutorial  and API docs (i.e.  AutoTSTrainer  and  TSPipeline ) for automated training.",
            "title": "Forecasting"
        },
        {
            "location": "/Zouwu/UseCase/network-traffic/",
            "text": "Network Traffic Forecasting\n\n\nTime series forecasting has many applications in telco. Accurate forecast of telco KPIs (e.g. traffic, utilizations, user experience, etc.) for communication networks ( 2G/3G/4G/5G/wired) can help predict network failures, allocate resource, or save energy. Time series forecasting can also be used for log and metric analysis for data center IT operations for telco. Metrics to be analyzed can be hardware or VM utilizations, database metrics or servce quality indicators. \n\n\nIn \nnetwork traffic reference use case\n, we demonstrate a time series forecasting use case using a public telco dataset, i.e. the aggregated network traffic traces at the transit link of WIDE to the upstream ISP (\ndataset link\n). In particular, we used aggregated traffic metrics (e.g. total bytes, average MBps) in the past to forecast the traffic in the furture. \n\n\n\n\nUsing Bulit-in Models\n\n\nIn this \nnotebook\n, we demostrate how to use built-in forecaster models to do univariant forecasting (predict only 1 series), and multivariant forecasting (predicts more than 1 series at the same time).\n\n\n\n\nUsing AutoTS\n\n\nIn this \nnotebook\n, we demostrate how to use AutoTS to build a time series forcasting pipeline.",
            "title": "Network Traffic"
        },
        {
            "location": "/Zouwu/UseCase/network-traffic/#network-traffic-forecasting",
            "text": "Time series forecasting has many applications in telco. Accurate forecast of telco KPIs (e.g. traffic, utilizations, user experience, etc.) for communication networks ( 2G/3G/4G/5G/wired) can help predict network failures, allocate resource, or save energy. Time series forecasting can also be used for log and metric analysis for data center IT operations for telco. Metrics to be analyzed can be hardware or VM utilizations, database metrics or servce quality indicators.   In  network traffic reference use case , we demonstrate a time series forecasting use case using a public telco dataset, i.e. the aggregated network traffic traces at the transit link of WIDE to the upstream ISP ( dataset link ). In particular, we used aggregated traffic metrics (e.g. total bytes, average MBps) in the past to forecast the traffic in the furture.",
            "title": "Network Traffic Forecasting"
        },
        {
            "location": "/Zouwu/UseCase/network-traffic/#using-bulit-in-models",
            "text": "In this  notebook , we demostrate how to use built-in forecaster models to do univariant forecasting (predict only 1 series), and multivariant forecasting (predicts more than 1 series at the same time).",
            "title": "Using Bulit-in Models"
        },
        {
            "location": "/Zouwu/UseCase/network-traffic/#using-autots",
            "text": "In this  notebook , we demostrate how to use AutoTS to build a time series forcasting pipeline.",
            "title": "Using AutoTS"
        },
        {
            "location": "/Zouwu/tutorials/LSTMForecasterAndMTNetForecaster/",
            "text": "In this guide, we will show you how to use the built-in LSTMForecaster and MTNetForecaster for time series forecasting.\n\n\nThe built-in LSTMForecaster and MTNetForecaster are both derived from \ntfpark.KerasModels\n. \n\n\nRefer to \nnetwork traffic notebook\n for demonstration of forecasting network traffic data with Zouwu built-in LSTMForecaster and MTNetForecaster.\n\n\nRefer to \nLSTMForecaster API\n and \nMTNetForecaster API\n detailed explanation of all arguments for each forecast model.\n\n\n\n\nStep 0: Prepare environment\n\n\nWe recommend you to use \nAnaconda\n to prepare the enviroments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).\n\n\nconda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above\n\n\n\n\nStep 1: Create forecast model\n\n\nTo start, you need to create a forecast model first. Specify \ntarget_dim\n and \nfeature_dim\n in constructor. \n\n\n\n\ntarget_dim\n: dimension of target output\n\n\nfeature_dim\n: dimension of input feature\n\n\n\n\nBelow are some example code to create forecast models.\n\n\n#import forecast models\nfrom zoo.zouwu.model.forecast.lstm_forecaster import LSTMForecaster\nfrom zoo.zouwu.model.forecast.mtnet_forecaster import MTNetForecaster\n\n#build a lstm forecast model\nlstm_forecaster = LSTMForecaster(target_dim=1, \n                      feature_dim=4)\n\n#build a mtnet forecast model\nmtnet_forecaster = MTNetForecaster(target_dim=1,\n                        feature_dim=4,\n                        long_series_num=1,\n                        series_length=3,\n                        ar_window_size=2,\n                        cnn_height=2)\n\n\n\n\nStep 2: Use forecast model\n\n\nUse \nforecaster.fit/evalute/predict\n in the same way as \ntfpark.KerasModel\n\n\nFor univariant forecasting (i.e. to predict one series at a time), you can use either \nLSTMForecaster\n or \nMTNetForecaster\n. The input data shape for \nfit/evaluation/predict\n should match the arguments you used to create the forecaster. Specifically:\n\n\n\n\nX\n shape should be \n(num of samples, lookback, feature_dim)\n\n\nY\n shape should be \n(num of samples, target_dim)\n\n\nWhere, \nfeature_dim\n is the number of features as specified in Forecaster constructors. \nlookback\n is the number of time steps you want to look back in history. \ntarget_dim\n is the number of series to forecast at the same time as specified in Forecaster constructors and should be 1 here. If you want to do multi-step forecasting and use the second dimension as no. of steps to look forward, you won't get error but the performance may be uncertain and we don't recommend using that way.\n\n\n\n\nFor multivariant forecasting (i.e. to predict several series at the same time), you have to use \nMTNetForecaster\n. The input data shape should meet below criteria.  \n\n\n\n\nX\n shape should be \n(num of samples, lookback, feature_dim)\n\n\nY\n shape should be \n(num of samples, target_dim)\n \n\n\nWhere \nlookback\n should equal \n(lb_long_steps+1) * lb_long_stepsize\n, where \nlb_long_steps\n and \nlb_long_stepsize\n are as specified in \nMTNetForecaster\n constructor. \ntarget_dim\n should equal number of series in input.",
            "title": "LSTMForecaster and MTNetForecaster"
        },
        {
            "location": "/Zouwu/tutorials/LSTMForecasterAndMTNetForecaster/#step-0-prepare-environment",
            "text": "We recommend you to use  Anaconda  to prepare the enviroments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).  conda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above",
            "title": "Step 0: Prepare environment"
        },
        {
            "location": "/Zouwu/tutorials/LSTMForecasterAndMTNetForecaster/#step-1-create-forecast-model",
            "text": "To start, you need to create a forecast model first. Specify  target_dim  and  feature_dim  in constructor.    target_dim : dimension of target output  feature_dim : dimension of input feature   Below are some example code to create forecast models.  #import forecast models\nfrom zoo.zouwu.model.forecast.lstm_forecaster import LSTMForecaster\nfrom zoo.zouwu.model.forecast.mtnet_forecaster import MTNetForecaster\n\n#build a lstm forecast model\nlstm_forecaster = LSTMForecaster(target_dim=1, \n                      feature_dim=4)\n\n#build a mtnet forecast model\nmtnet_forecaster = MTNetForecaster(target_dim=1,\n                        feature_dim=4,\n                        long_series_num=1,\n                        series_length=3,\n                        ar_window_size=2,\n                        cnn_height=2)",
            "title": "Step 1: Create forecast model"
        },
        {
            "location": "/Zouwu/tutorials/LSTMForecasterAndMTNetForecaster/#step-2-use-forecast-model",
            "text": "Use  forecaster.fit/evalute/predict  in the same way as  tfpark.KerasModel  For univariant forecasting (i.e. to predict one series at a time), you can use either  LSTMForecaster  or  MTNetForecaster . The input data shape for  fit/evaluation/predict  should match the arguments you used to create the forecaster. Specifically:   X  shape should be  (num of samples, lookback, feature_dim)  Y  shape should be  (num of samples, target_dim)  Where,  feature_dim  is the number of features as specified in Forecaster constructors.  lookback  is the number of time steps you want to look back in history.  target_dim  is the number of series to forecast at the same time as specified in Forecaster constructors and should be 1 here. If you want to do multi-step forecasting and use the second dimension as no. of steps to look forward, you won't get error but the performance may be uncertain and we don't recommend using that way.   For multivariant forecasting (i.e. to predict several series at the same time), you have to use  MTNetForecaster . The input data shape should meet below criteria.     X  shape should be  (num of samples, lookback, feature_dim)  Y  shape should be  (num of samples, target_dim)    Where  lookback  should equal  (lb_long_steps+1) * lb_long_stepsize , where  lb_long_steps  and  lb_long_stepsize  are as specified in  MTNetForecaster  constructor.  target_dim  should equal number of series in input.",
            "title": "Step 2: Use forecast model"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/",
            "text": "In this guide, we will show you how to use Zouwu TCMFForecaster for high dimension time series forecasting.\n\n\nRefer to \nTCMFForecaster example\n for demonstration of using TCMFForecaster for distributed training and inference. \n\n\nRefer to \nTCMFForecaster API Guide\n for more details of AutoTS APIs.\n\n\n\n\nStep 0: Prepare environment\n\n\na. We recommend conda to set up your environment. Note that conda environment is required to run onq\nyarn, but not strictly necessary for running on local. \n\n\nconda create -n zoo python=3.7\nconda activate zoo\n\n\n\n\nb. If you want to enable TCMFForecaster distributed training, it requires pre-install pytorch and horovod. You can follow the \nhorovod document\n to install the horovod and pytorch with Gloo support.\nAnd here are the commands that work on for us on ubuntu 16.04. The exact steps may vary from different machines.\n\n\nconda install -y pytorch==1.4.0 torchvision==0.5.0 cpuonly -c pytorch\nconda install -y cmake==3.16.0 -c conda-forge\nconda install cxx-compiler==1.0 -c conda-forge\nconda install openmpi\nHOROVOD_WITH_PYTORCH=1; HOROVOD_WITH_GLOO=1; pip install --no-cache-dir horovod==0.19.1\npip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl[ray]\n\n\n\n\nIf you don't need distributed training. You only need to install pytorch in your environment.\n\n\npip install torch==1.4.0 torchvision==0.5.0\n\n\n\n\nc. Download and install nightly build analytics zoo whl by following instructions (\nhere\n).\n\n\npip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl[ray]\n\n\n\n\nd. Install other packages\n\n\npip install scikit-learn==0.22\npip install pandas==1.0\npip install requests\n\n\n\n\nStep 1: Init Orca Context\n\n\nYou need to init an orca context with \ninit_ray_on_spark=True\n before distributed training, and stop it after training is completed. Note orca context is not needed if you don't want to enable distributed training.\n\n\nfrom zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\ninit_orca_context(cluster_mode=\"local\", cores=4, memory='2g', num_nodes=1, init_ray_on_spark=True)\n\n# run in yarn client mode\ninit_orca_context(cluster_mode=\"yarn-client\", \n                  num_nodes=2, cores=2, \n                  driver_memory=\"6g\", driver_cores=4, \n                  conda_name='zoo', \n                  extra_memory_for_ray=\"10g\", \n                  object_store_memory='5g')\n\n\n\n\n\n\nReference: \nOrca Context\n\n\n\n\nStep 2: Create a TCMFForecaster\n\n\nfrom zoo.zouwu.model.forecast.tcmf_forecaster import TCMFForecaster\nmodel = TCMFForecaster(\n        vbsize=128,\n        hbsize=256,\n        num_channels_X=[32, 32, 32, 32, 32, 1],\n        num_channels_Y=[16, 16, 16, 16, 16, 1],\n        kernel_size=7,\n        dropout=0.1,\n        rank=64,\n        kernel_size_Y=7,\n        learning_rate=0.0005,\n        normalize=False,\n        use_time=True,\n        svd=True,)\n\n\n\n\nStep 3: Use TCMFForecaster\n\n\nFit with TCMFForecaster\n\n\nmodel.fit(\n        x,\n        val_len=24,\n        start_date=\"2020-4-1\",\n        freq=\"1H\",\n        covariates=None,\n        dti=None,\n        period=24,\n        y_iters=10,\n        init_FX_epoch=100,\n        max_FX_epoch=300,\n        max_TCN_epoch=300,\n        alt_iters=10,\n        num_workers=num_workers_for_fit)\n\n\n\n\nEvaluate with TCMFForecaster\n\n\nYou can either directly call \nmodel.evaluate\n as\n\n\nmodel.evaluate(target_value,\n               metric=['mae'],\n               target_covariates=None,\n               target_dti=None,\n               num_workers=num_workers_for_predict,\n               )\n\n\n\n\nOr you could predict first and then evaluate with metric name.\n\n\nyhat = model.predict(horizon,\n                     future_covariates=None,\n                     future_dti=None,\n                     num_workers=num_workers_for_predict)\n\nfrom zoo.automl.common.metrics import Evaluator\nevaluate_mse = Evaluator.evaluate(\"mse\", target_data, yhat)\n\n\n\n\nIncremental fit TCMFForecaster\n\n\nmodel.fit_incremental(x_incr, covariates_incr=None, dti_incr=None)\n\n\n\n\nSave and Load\n\n\nmodel.save(dirname)\nloaded_model = TCMFForecaster.load(dirname)",
            "title": "TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#step-0-prepare-environment",
            "text": "a. We recommend conda to set up your environment. Note that conda environment is required to run onq\nyarn, but not strictly necessary for running on local.   conda create -n zoo python=3.7\nconda activate zoo  b. If you want to enable TCMFForecaster distributed training, it requires pre-install pytorch and horovod. You can follow the  horovod document  to install the horovod and pytorch with Gloo support.\nAnd here are the commands that work on for us on ubuntu 16.04. The exact steps may vary from different machines.  conda install -y pytorch==1.4.0 torchvision==0.5.0 cpuonly -c pytorch\nconda install -y cmake==3.16.0 -c conda-forge\nconda install cxx-compiler==1.0 -c conda-forge\nconda install openmpi\nHOROVOD_WITH_PYTORCH=1; HOROVOD_WITH_GLOO=1; pip install --no-cache-dir horovod==0.19.1\npip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl[ray]  If you don't need distributed training. You only need to install pytorch in your environment.  pip install torch==1.4.0 torchvision==0.5.0  c. Download and install nightly build analytics zoo whl by following instructions ( here ).  pip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl[ray]  d. Install other packages  pip install scikit-learn==0.22\npip install pandas==1.0\npip install requests",
            "title": "Step 0: Prepare environment"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#step-1-init-orca-context",
            "text": "You need to init an orca context with  init_ray_on_spark=True  before distributed training, and stop it after training is completed. Note orca context is not needed if you don't want to enable distributed training.  from zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\ninit_orca_context(cluster_mode=\"local\", cores=4, memory='2g', num_nodes=1, init_ray_on_spark=True)\n\n# run in yarn client mode\ninit_orca_context(cluster_mode=\"yarn-client\", \n                  num_nodes=2, cores=2, \n                  driver_memory=\"6g\", driver_cores=4, \n                  conda_name='zoo', \n                  extra_memory_for_ray=\"10g\", \n                  object_store_memory='5g')   Reference:  Orca Context",
            "title": "Step 1: Init Orca Context"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#step-2-create-a-tcmfforecaster",
            "text": "from zoo.zouwu.model.forecast.tcmf_forecaster import TCMFForecaster\nmodel = TCMFForecaster(\n        vbsize=128,\n        hbsize=256,\n        num_channels_X=[32, 32, 32, 32, 32, 1],\n        num_channels_Y=[16, 16, 16, 16, 16, 1],\n        kernel_size=7,\n        dropout=0.1,\n        rank=64,\n        kernel_size_Y=7,\n        learning_rate=0.0005,\n        normalize=False,\n        use_time=True,\n        svd=True,)",
            "title": "Step 2: Create a TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#step-3-use-tcmfforecaster",
            "text": "",
            "title": "Step 3: Use TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#fit-with-tcmfforecaster",
            "text": "model.fit(\n        x,\n        val_len=24,\n        start_date=\"2020-4-1\",\n        freq=\"1H\",\n        covariates=None,\n        dti=None,\n        period=24,\n        y_iters=10,\n        init_FX_epoch=100,\n        max_FX_epoch=300,\n        max_TCN_epoch=300,\n        alt_iters=10,\n        num_workers=num_workers_for_fit)",
            "title": "Fit with TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#evaluate-with-tcmfforecaster",
            "text": "You can either directly call  model.evaluate  as  model.evaluate(target_value,\n               metric=['mae'],\n               target_covariates=None,\n               target_dti=None,\n               num_workers=num_workers_for_predict,\n               )  Or you could predict first and then evaluate with metric name.  yhat = model.predict(horizon,\n                     future_covariates=None,\n                     future_dti=None,\n                     num_workers=num_workers_for_predict)\n\nfrom zoo.automl.common.metrics import Evaluator\nevaluate_mse = Evaluator.evaluate(\"mse\", target_data, yhat)",
            "title": "Evaluate with TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#incremental-fit-tcmfforecaster",
            "text": "model.fit_incremental(x_incr, covariates_incr=None, dti_incr=None)",
            "title": "Incremental fit TCMFForecaster"
        },
        {
            "location": "/Zouwu/tutorials/TCMFForecaster/#save-and-load",
            "text": "model.save(dirname)\nloaded_model = TCMFForecaster.load(dirname)",
            "title": "Save and Load"
        },
        {
            "location": "/Zouwu/tutorials/Autots/",
            "text": "Zouwu AutoTS Quickstart\n\n\nIn this guide, we will show you how to use AutoTS for automated time series forecasting.\n\n\nThe general workflow using AutoTS contains below two steps. \n\n\n\n\ncreate a \nAutoTSTrainer\n to train a \nTSPipeline\n, save it to file to use later or elsewhere if you wish.\n\n\nuse \nTSPipeline\n to do prediction, evaluation, and incremental fitting as well. \n\n\n\n\nRefer to \nAutoTS notebook\n for demonstration how to use AutoTS to build a time series forcasting pipeline. \n\n\nRefer to \nAutoTS API Guide\n for more details of AutoTS APIs.\n\n\n\n\nStep 0: Prepare environment\n\n\nZouwu AutoTS needs below requirements to run.\n\n\n\n\npython 3.6 or 3.7\n\n\npySpark\n\n\nanalytics-zoo\n\n\ntensorflow>=1.15.0,<2.0.0\n\n\nh5py==2.10.0\n\n\nray[tune]==0.8.4\n\n\npsutil\n\n\naiohttp\n\n\nsetproctitle\n\n\npandas\n\n\nscikit-learn>=0.20.0,<=0.22.0\n\n\nrequests\n\n\n\n\nYou can install above python dependencies manually. But we strongly recommend you to use \nAnaconda\n to prepare the environments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).\n\n\nconda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above\n\n\n\n\nStep 1: Init Orca Context\n\n\nYou'll need \nRayOnSpark\n for training with \nAutoTSTrainer\n, so you should init an orca context with \ninit_ray_on_spark=True\n before auto training, and stop it after training is completed. Note orca context is not needed if you just use TSPipeline for inference, evaluation or incremental training. \n\n\nfrom zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\ninit_orca_context(cluster_mode=\"local\", cores=4, memory='2g', num_nodes=1, init_ray_on_spark=True)\n\n# run in yarn client mode\ninit_orca_context(cluster_mode=\"yarn-client\", \n                  num_nodes=2, cores=2, \n                  driver_memory=\"6g\", driver_cores=4, \n                  conda_name='zoo', \n                  extra_memory_for_ray=\"10g\", \n                  object_store_memory='5g')\n\n\n\n\n\n\nReference: \nOrca Context\n\n\n\n\nStep 2: Create an AutoTSTrainer\n\n\nTo create an AutoTSTrainer. Specify below arguments in constructor. See below example.\n\n\n\n\ndt_col\n: the column specifying datetime \n\n\ntarget_col\n: target column to predict\n\n\nhorizon\n : num of steps to look forward \n\n\nextra_feature_col\n: a list of columns which are also included in input as features except target column\n\n\nsearch_alg\n: Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.\n\n\nsearch_alg_params\n: Optional(Dict). params of search_alg.\n\n\nscheduler\n: Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".\n\n\nscheduler_params\n: Optional(Dict). Necessary params of scheduler.\n\n\n\n\nfrom zoo.zouwu.autots.forecast import AutoTSTrainer\n\ntrainer = AutoTSTrainer(dt_col=\"datetime\",\n                        target_col=\"value\",\n                        horizon=1,\n                        extra_features_col=None)\n\n\n\n\n\nStep 3: Fit with AutoTSTrainer\n\n\nUse \nAutoTSTrainer.fit\n on train data and validation data. A TSPipeline will be returned. \n\n\nts_pipeline = trainer.fit(train_df, validation_df)\n\n\n\n\nBoth AutoTSTrainer and TSPipeline accepts data frames as input. An exmaple data frame looks like below.\n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue\n\n\nextra_feature_1\n\n\nextra_feature_2\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n1\n\n\n2\n\n\n\n\n\n\n2019-06-07\n\n\n2.3\n\n\n0\n\n\n2\n\n\n\n\n\n\n\n\nNote:\n you should call \nstop_orca_context()\n when your distributed automated training finishes.\n\n\nFor visualization, please refer to \nhere\n.\n\n\nStep 4: Further deployment with TSPipeline\n\n\nUse \nTSPipeline.fit/evaluate/predict\n to train pipeline (incremental fitting), evaluate or predict. \n\n\n#incremental fitting\nts_pipeline.fit(new_train_df, new_val_df, epochs=10)\n#evaluate\nts_pipeline.evalute(val_df)\nts_pipeline.predict(test_df) \n\n\n\n\n\nUse \nTSPipeline.save/load\n to load from file or save to file. \n\n\nfrom zoo.zouwu.autots.forecast import TSPipeline\nloaded_ppl = TSPipeline.load(file)\n# ... do sth. e.g. incremental fitting\nloaded_ppl.save(another_file)",
            "title": "AutoTS"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#zouwu-autots-quickstart",
            "text": "In this guide, we will show you how to use AutoTS for automated time series forecasting.  The general workflow using AutoTS contains below two steps.    create a  AutoTSTrainer  to train a  TSPipeline , save it to file to use later or elsewhere if you wish.  use  TSPipeline  to do prediction, evaluation, and incremental fitting as well.    Refer to  AutoTS notebook  for demonstration how to use AutoTS to build a time series forcasting pipeline.   Refer to  AutoTS API Guide  for more details of AutoTS APIs.",
            "title": "Zouwu AutoTS Quickstart"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#step-0-prepare-environment",
            "text": "Zouwu AutoTS needs below requirements to run.   python 3.6 or 3.7  pySpark  analytics-zoo  tensorflow>=1.15.0,<2.0.0  h5py==2.10.0  ray[tune]==0.8.4  psutil  aiohttp  setproctitle  pandas  scikit-learn>=0.20.0,<=0.22.0  requests   You can install above python dependencies manually. But we strongly recommend you to use  Anaconda  to prepare the environments, especially if you want to run automated training on a yarn cluster (yarn-client mode only).  conda create -n zoo python=3.7 #zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics-zoo[automl]==0.9.0.dev0 # or above",
            "title": "Step 0: Prepare environment"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#step-1-init-orca-context",
            "text": "You'll need  RayOnSpark  for training with  AutoTSTrainer , so you should init an orca context with  init_ray_on_spark=True  before auto training, and stop it after training is completed. Note orca context is not needed if you just use TSPipeline for inference, evaluation or incremental training.   from zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\ninit_orca_context(cluster_mode=\"local\", cores=4, memory='2g', num_nodes=1, init_ray_on_spark=True)\n\n# run in yarn client mode\ninit_orca_context(cluster_mode=\"yarn-client\", \n                  num_nodes=2, cores=2, \n                  driver_memory=\"6g\", driver_cores=4, \n                  conda_name='zoo', \n                  extra_memory_for_ray=\"10g\", \n                  object_store_memory='5g')   Reference:  Orca Context",
            "title": "Step 1: Init Orca Context"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#step-2-create-an-autotstrainer",
            "text": "To create an AutoTSTrainer. Specify below arguments in constructor. See below example.   dt_col : the column specifying datetime   target_col : target column to predict  horizon  : num of steps to look forward   extra_feature_col : a list of columns which are also included in input as features except target column  search_alg : Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.  search_alg_params : Optional(Dict). params of search_alg.  scheduler : Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".  scheduler_params : Optional(Dict). Necessary params of scheduler.   from zoo.zouwu.autots.forecast import AutoTSTrainer\n\ntrainer = AutoTSTrainer(dt_col=\"datetime\",\n                        target_col=\"value\",\n                        horizon=1,\n                        extra_features_col=None)",
            "title": "Step 2: Create an AutoTSTrainer"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#step-3-fit-with-autotstrainer",
            "text": "Use  AutoTSTrainer.fit  on train data and validation data. A TSPipeline will be returned.   ts_pipeline = trainer.fit(train_df, validation_df)  Both AutoTSTrainer and TSPipeline accepts data frames as input. An exmaple data frame looks like below.     datetime  value  extra_feature_1  extra_feature_2      2019-06-06  1.2  1  2    2019-06-07  2.3  0  2     Note:  you should call  stop_orca_context()  when your distributed automated training finishes.  For visualization, please refer to  here .",
            "title": "Step 3: Fit with AutoTSTrainer"
        },
        {
            "location": "/Zouwu/tutorials/Autots/#step-4-further-deployment-with-tspipeline",
            "text": "Use  TSPipeline.fit/evaluate/predict  to train pipeline (incremental fitting), evaluate or predict.   #incremental fitting\nts_pipeline.fit(new_train_df, new_val_df, epochs=10)\n#evaluate\nts_pipeline.evalute(val_df)\nts_pipeline.predict(test_df)   Use  TSPipeline.save/load  to load from file or save to file.   from zoo.zouwu.autots.forecast import TSPipeline\nloaded_ppl = TSPipeline.load(file)\n# ... do sth. e.g. incremental fitting\nloaded_ppl.save(another_file)",
            "title": "Step 4: Further deployment with TSPipeline"
        },
        {
            "location": "/Zouwu/Algorithm/MTNetAlgorithm/",
            "text": "MTNet Algorithm\n\n\nAs we have mentioned before, MTNet is a memory-network based solution for multivariate time-series forecasting. The input data has a form of time series signal with several variables observed in each time stamp. Input data is divided into two parts, long-term historical data \n{X_i}\n and a short-term data series \nQ\n. Long-term historical data typically has several data series and each of them has the same length of the short-term data series.\n\n\nOne of the main modules of MTNet is its Encoder. It composes of three parts, a convolutional layer, an attention layer and a recurrent layer. For the convolutional layer, we have \ncnn_hid_size\n filters with width as the number of input feature \nfeature_dim\n and height as \ncnn_height\n.  Then the convolution output is sent to a recurrent neural network with attention mechanism. You can have several RNN layers and the units number is set in \nrnn_hid_size\n The recurrent neural network is implemented as a GRU in this case.\n\n\n\n\nAs we have mentioned before, MTNet has two input, long-term historical data \n{X_i}\n and a short-term data series \nQ\n. The length of each long-term historical data series and the short-term data series is \nseries_length\n and there are \nlong_series_num\n  long-term historical data series in all (typically 7 as shown in this flow chart). Each \nX_i\n in \n{X_i}\n is encoded by the encoder to get \nlong_series_num\n input memory representations \n{m_i}\n. Short-term data series is encoded by the encoder to get a query vector \nu\n.  By inner product between each \nm_i\n in \n{m_i}\n with \nu\n and a SoftMax operation, we get an attention weight distribution vector. The attention weight distribution vector is then element-wise multiplied by another encoded  representation \n{c_i}\n and get a weighted output \n{o_i}\n. The weighted output is concatenated with the query vector \nu\n and sent through a fully connected layer with output dimension as \ntarget_dim\n.\n\n\n\n\nThere is another auxiliary autoregressive model works independently. The autoregressive model assumes that the value to be forecasted is relevant to its previous value. \nar_window_size\n states the number of previous value you want to use in the regression. The output feature number is also \ntarget_dim\n.\n\n\nAt last, the autoregressive model result is added with the memory network result to get the final time series prediction.\n\n\nYou can find API instructions \nhere\n.\n\n\nReference\n\n\nYen-YuChang, Fan-YunSun, Yueh-HuaWu, Shou-DeLin,  \nA Memory-Network Based Solution for Multivariate Time-Series Forecasting\n.",
            "title": "MTNet"
        },
        {
            "location": "/Zouwu/Algorithm/MTNetAlgorithm/#mtnet-algorithm",
            "text": "As we have mentioned before, MTNet is a memory-network based solution for multivariate time-series forecasting. The input data has a form of time series signal with several variables observed in each time stamp. Input data is divided into two parts, long-term historical data  {X_i}  and a short-term data series  Q . Long-term historical data typically has several data series and each of them has the same length of the short-term data series.  One of the main modules of MTNet is its Encoder. It composes of three parts, a convolutional layer, an attention layer and a recurrent layer. For the convolutional layer, we have  cnn_hid_size  filters with width as the number of input feature  feature_dim  and height as  cnn_height .  Then the convolution output is sent to a recurrent neural network with attention mechanism. You can have several RNN layers and the units number is set in  rnn_hid_size  The recurrent neural network is implemented as a GRU in this case.   As we have mentioned before, MTNet has two input, long-term historical data  {X_i}  and a short-term data series  Q . The length of each long-term historical data series and the short-term data series is  series_length  and there are  long_series_num   long-term historical data series in all (typically 7 as shown in this flow chart). Each  X_i  in  {X_i}  is encoded by the encoder to get  long_series_num  input memory representations  {m_i} . Short-term data series is encoded by the encoder to get a query vector  u .  By inner product between each  m_i  in  {m_i}  with  u  and a SoftMax operation, we get an attention weight distribution vector. The attention weight distribution vector is then element-wise multiplied by another encoded  representation  {c_i}  and get a weighted output  {o_i} . The weighted output is concatenated with the query vector  u  and sent through a fully connected layer with output dimension as  target_dim .   There is another auxiliary autoregressive model works independently. The autoregressive model assumes that the value to be forecasted is relevant to its previous value.  ar_window_size  states the number of previous value you want to use in the regression. The output feature number is also  target_dim .  At last, the autoregressive model result is added with the memory network result to get the final time series prediction.  You can find API instructions  here .",
            "title": "MTNet Algorithm"
        },
        {
            "location": "/Zouwu/Algorithm/MTNetAlgorithm/#reference",
            "text": "Yen-YuChang, Fan-YunSun, Yueh-HuaWu, Shou-DeLin,   A Memory-Network Based Solution for Multivariate Time-Series Forecasting .",
            "title": "Reference"
        },
        {
            "location": "/Zouwu/Algorithm/LSTMAlgorithm/",
            "text": "VanillaLSTM Algorithm\n\n\nVanillaLSTM is constructed by two LSTM layers, two dropout layers and a dense layer. The flow chart is clearly plotted in the following plot. A more detailed LSTM unit structure can be found in \nhere\n.\n\n\n\n\nYou can find API instructions \nhere\n.",
            "title": "LSTM"
        },
        {
            "location": "/Zouwu/Algorithm/LSTMAlgorithm/#vanillalstm-algorithm",
            "text": "VanillaLSTM is constructed by two LSTM layers, two dropout layers and a dense layer. The flow chart is clearly plotted in the following plot. A more detailed LSTM unit structure can be found in  here .   You can find API instructions  here .",
            "title": "VanillaLSTM Algorithm"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/",
            "text": "LSTMForecaster\n\n\nIntroduction\n\n\nLong short-term memory(LSTM) is a special type of recurrent neural network(RNN). We implement the basic version of LSTM - VanillaLSTM for this forecaster for time-series forecasting task. It has two LSTM layers, two dropout layer and a dense layer. LSTMForecaster is derived from tfpark.KerasMode, and can use all methods of KerasModel. Refer to \ntfpark.KerasModel API Doc\n for details.\n\n\nFor the detailed algorithm description, please refer to \nhere\n.\n\n\nMethod\n\n\nArguments\n\n\n\n\ntarget_dim\n: Specify the number of variables we want to forecast. i.e. the the dimension of model output feature. This value defaults to 1.\n\n\nfeature_dim\n: Specify the number of variables we have in the input data. i.e. the the dimension of model input feature. This value defaults to 1.\n\n\nlstm_units\n: Specify the dimensionality of the output space for LSTM layers. This value defaults to (16, 8). \n\n\ndropouts\n: Specify the fraction of the input units to drop for dropout layers. This value defaults to 0.2. Note that The same dropout rate will be set to all\n            layers if dropouts is one float value while lstm_units has multiple elements.\n\n\nmetric\n: Specify the metric for validation and evaluation. This value defaults to MSE.\n\n\nlr\n: Specify the learning rate. This value defaults to 0.001.\n\n\nloss\n: Specify the target function you want to optimize on. This value defaults to MSE.\n\n\noptimizer\n: Specify the optimizer used for training. This value defaults to Adam.\n\n\n\n\n__init__\n\n\nLSTMForecaster(target_dim=1,\n               feature_dim=1,\n               lstm_units=(16, 8),\n               dropouts=0.2,\n               metric=\"mean_squared_error\",\n               lr=0.001,\n               loss=\"mse\",\n               optimizer=\"Adam\",\n               )\n\n\n\n\nfit, evaluate, predict\n\n\nRefer to \nfit\n, \nevaluate\n, \npredict\n defined in \ntfpark.KerasModel API Doc",
            "title": "LSTMForecaster"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#lstmforecaster",
            "text": "",
            "title": "LSTMForecaster"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#introduction",
            "text": "Long short-term memory(LSTM) is a special type of recurrent neural network(RNN). We implement the basic version of LSTM - VanillaLSTM for this forecaster for time-series forecasting task. It has two LSTM layers, two dropout layer and a dense layer. LSTMForecaster is derived from tfpark.KerasMode, and can use all methods of KerasModel. Refer to  tfpark.KerasModel API Doc  for details.  For the detailed algorithm description, please refer to  here .",
            "title": "Introduction"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#method",
            "text": "",
            "title": "Method"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#arguments",
            "text": "target_dim : Specify the number of variables we want to forecast. i.e. the the dimension of model output feature. This value defaults to 1.  feature_dim : Specify the number of variables we have in the input data. i.e. the the dimension of model input feature. This value defaults to 1.  lstm_units : Specify the dimensionality of the output space for LSTM layers. This value defaults to (16, 8).   dropouts : Specify the fraction of the input units to drop for dropout layers. This value defaults to 0.2. Note that The same dropout rate will be set to all\n            layers if dropouts is one float value while lstm_units has multiple elements.  metric : Specify the metric for validation and evaluation. This value defaults to MSE.  lr : Specify the learning rate. This value defaults to 0.001.  loss : Specify the target function you want to optimize on. This value defaults to MSE.  optimizer : Specify the optimizer used for training. This value defaults to Adam.",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#__init__",
            "text": "LSTMForecaster(target_dim=1,\n               feature_dim=1,\n               lstm_units=(16, 8),\n               dropouts=0.2,\n               metric=\"mean_squared_error\",\n               lr=0.001,\n               loss=\"mse\",\n               optimizer=\"Adam\",\n               )",
            "title": "__init__"
        },
        {
            "location": "/Zouwu/API/LSTMForecaster/#fit-evaluate-predict",
            "text": "Refer to  fit ,  evaluate ,  predict  defined in  tfpark.KerasModel API Doc",
            "title": "fit, evaluate, predict"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/",
            "text": "MTNetForecaster\n\n\nIntroduction\n\n\nMTNet is a memory-network based solution for multivariate time-series forecasting. In a specific task of multivariate time-series forecasting, we have several variables observed in time series and we want to forecast some or all of the variables' value in a future time stamp.\n\n\nMTNet is proposed by paper \nA Memory-Network Based Solution for Multivariate Time-Series Forecasting\n. MTNetForecaster is derived from tfpark.KerasMode, and can use all methods of KerasModel. Refer to \ntfpark.KerasModel API Doc\n for details.\n\n\nFor the detailed algorithm description, please refer to \nhere\n.\n\n\nMethod\n\n\nArguments\n\n\n\n\ntarget_dim\n: Specify the number of variables we want to forecast. i.e. the the dimension of model output feature. This value defaults to 1.\n\n\nfeature_dim\n: Specify the number of variables we have in the input data. i.e. the the dimension of model input feature. This value defaults to 1.\n\n\nlong_series_num\n: Specify the number of long-term historical data series. This value defaults to 1. Typically, as stated in the \npaper\n, the value is set to 7.\n\n\nseries_length\n: Specify the length of long-term historical data series, which is equal to the length of short-term data series. This value defaults to 1. The value should be larger or equal to 1.\n\n\nar_window_size\n: Specify the auto regression window size in MTNet. This value defaults to 1. Since the parameter is along the time dimension, the value should be smaller or equal to \nseries_length\n.\n\n\ncnn_height\n: Specify convolutional layer filter height in MTNet's encoder. This value defaults to 1. Since the parameter is along the time dimension, the value should be smaller or equal to \nseries_length\n.\n\n\ncnn_hid_size\n: Specify the convolutional layer filter number in MTNet's encoder. This value defaults to 32. Typically, as stated in the \npaper\n, the value is grid searched in {32, 50, 100}.\n\n\nrnn_hid_size\n: Specify the the hidden RNN layers unit number in MTNet's encoder. This value defaults to [16, 32] as a stacked RNN.  Typically, as stated in the \npaper\n, the value is grid searched in {32, 50, 100} for each layer. This parameter should be set as a list.\n\n\nlr\n: Specify the learning rate. This value defaults to 0.001.\n\n\nloss\n: Specify the target function you want to optimize on. This value defaults to MAE. \n\n\nmetric\n: Specify the metric for validation and evaluation. This value defaults to MSE.\n\n\ncnn_dropout\n: Specify the dropout close possibility for CNN in encoder. This value defaults to 0.2, as stated in the \npaper\n.\n\n\nrnn_dropout\n: Specify the dropout close possibility for RNN in encoder. This value defaults to 0.2, as stated in the \npaper\n.\n\n\nuncertainty\n: Specify whether the forecaster can perform the calculation of uncertainty.\n\n\n\n\n__init__\n\n\nMTNetForecaster(target_dim=1,\n                 feature_dim=1,\n                 long_series_num=1,\n                 series_length=1,\n                 ar_window_size=1,\n                 cnn_height=1,\n                 cnn_hid_size=32,\n                 rnn_hid_sizes=[16, 32],\n                 lr=0.001,\n                 loss=\"mae\",\n                 cnn_dropout=0.2,\n                 rnn_dropout=0.2,\n                 metric=\"mean_squared_error\",\n                 uncertainty: bool = False,\n                 )\n\n\n\n\n\nfit, evaluate, predict\n\n\nRefer to \nfit\n, \nevaluate\n, \npredict\n defined in \ntfpark.KerasModel API Doc\n\n\nReference\n\n\nYen-YuChang, Fan-YunSun, Yueh-HuaWu, Shou-DeLin,  \nA Memory-Network Based Solution for Multivariate Time-Series Forecasting\n.",
            "title": "MTNetForecaster"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#mtnetforecaster",
            "text": "",
            "title": "MTNetForecaster"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#introduction",
            "text": "MTNet is a memory-network based solution for multivariate time-series forecasting. In a specific task of multivariate time-series forecasting, we have several variables observed in time series and we want to forecast some or all of the variables' value in a future time stamp.  MTNet is proposed by paper  A Memory-Network Based Solution for Multivariate Time-Series Forecasting . MTNetForecaster is derived from tfpark.KerasMode, and can use all methods of KerasModel. Refer to  tfpark.KerasModel API Doc  for details.  For the detailed algorithm description, please refer to  here .",
            "title": "Introduction"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#method",
            "text": "",
            "title": "Method"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#arguments",
            "text": "target_dim : Specify the number of variables we want to forecast. i.e. the the dimension of model output feature. This value defaults to 1.  feature_dim : Specify the number of variables we have in the input data. i.e. the the dimension of model input feature. This value defaults to 1.  long_series_num : Specify the number of long-term historical data series. This value defaults to 1. Typically, as stated in the  paper , the value is set to 7.  series_length : Specify the length of long-term historical data series, which is equal to the length of short-term data series. This value defaults to 1. The value should be larger or equal to 1.  ar_window_size : Specify the auto regression window size in MTNet. This value defaults to 1. Since the parameter is along the time dimension, the value should be smaller or equal to  series_length .  cnn_height : Specify convolutional layer filter height in MTNet's encoder. This value defaults to 1. Since the parameter is along the time dimension, the value should be smaller or equal to  series_length .  cnn_hid_size : Specify the convolutional layer filter number in MTNet's encoder. This value defaults to 32. Typically, as stated in the  paper , the value is grid searched in {32, 50, 100}.  rnn_hid_size : Specify the the hidden RNN layers unit number in MTNet's encoder. This value defaults to [16, 32] as a stacked RNN.  Typically, as stated in the  paper , the value is grid searched in {32, 50, 100} for each layer. This parameter should be set as a list.  lr : Specify the learning rate. This value defaults to 0.001.  loss : Specify the target function you want to optimize on. This value defaults to MAE.   metric : Specify the metric for validation and evaluation. This value defaults to MSE.  cnn_dropout : Specify the dropout close possibility for CNN in encoder. This value defaults to 0.2, as stated in the  paper .  rnn_dropout : Specify the dropout close possibility for RNN in encoder. This value defaults to 0.2, as stated in the  paper .  uncertainty : Specify whether the forecaster can perform the calculation of uncertainty.",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#__init__",
            "text": "MTNetForecaster(target_dim=1,\n                 feature_dim=1,\n                 long_series_num=1,\n                 series_length=1,\n                 ar_window_size=1,\n                 cnn_height=1,\n                 cnn_hid_size=32,\n                 rnn_hid_sizes=[16, 32],\n                 lr=0.001,\n                 loss=\"mae\",\n                 cnn_dropout=0.2,\n                 rnn_dropout=0.2,\n                 metric=\"mean_squared_error\",\n                 uncertainty: bool = False,\n                 )",
            "title": "__init__"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#fit-evaluate-predict",
            "text": "Refer to  fit ,  evaluate ,  predict  defined in  tfpark.KerasModel API Doc",
            "title": "fit, evaluate, predict"
        },
        {
            "location": "/Zouwu/API/MTNetForecaster/#reference",
            "text": "Yen-YuChang, Fan-YunSun, Yueh-HuaWu, Shou-DeLin,   A Memory-Network Based Solution for Multivariate Time-Series Forecasting .",
            "title": "Reference"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/",
            "text": "Introduction\n\n\nAnalytics Zoo Zouwu TCMFForecaster provides an efficient way to forecast high dimensional time series. \n\n\nTCMFForecaster is based on DeepGLO algorithm, which is a deep forecasting model which thinks globally and acts locally.\nYou can refer to \nthe deepglo paper\n for more details. \n\n\nTCMFForecaster supports distributed training and inference. It is based on Orca PyTorch Estimator, which is an estimator to do PyTorch training/evaluation/prediction on Spark in a distributed fashion. Also you can choose to enable distributed training and inference or not.\n\n\nRemarks\n:\n\n\n\n\nYou can refer to \nTCMFForecaster installation\n to install required packages.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\n\n\n\n\nTCMFForecaster\n\n\nCreate TCMFForecaster\n\n\nfrom zoo.zouwu.model.forecast.tcmf_forecaster import TCMFForecaster\nmodel = TCMFForecaster(\n         vbsize=128,\n         hbsize=256,\n         num_channels_X=[32, 32, 32, 32, 32, 1],\n         num_channels_Y=[16, 16, 16, 16, 16, 1],\n         kernel_size=7,\n         dropout=0.1,\n         rank=64,\n         kernel_size_Y=7,\n         learning_rate=0.0005,\n         normalize=False,\n         use_time=True,\n         svd=True,)\n\n\n\n\n\n\nvbsize\n: int, default is 128.\n            Vertical batch size, which is the number of cells per batch.\n\n\nhbsize\n: int, default is 256.\n            Horizontal batch size, which is the number of time series per batch.\n\n\nnum_channels_X\n: list, default=[32, 32, 32, 32, 32, 1].\n            List containing channel progression of temporal convolution network for local model\n\n\nnum_channels_Y\n: list, default=[16, 16, 16, 16, 16, 1]\n            List containing channel progression of temporal convolution network for hybrid model.\n\n\nkernel_size\n: int, default is 7.\n            Kernel size for local models\n\n\ndropout\n: float, default is 0.1.\n            Dropout rate during training\n\n\nrank\n: int, default is 64.\n            The rank in matrix factorization of global model.\n\n\nkernel_size_Y\n: int, default is 7.\n            Kernel size of hybrid model\n\n\nlearning_rate\n:  float, default is 0.0005\n\n\nnormalize\n: boolean, false by default.\n            Whether to normalize input data for training.\n\n\nuse_time\n: boolean, default is True.\n            Whether to use time coveriates.\n\n\nsvd\n: boolean, default is False.\n            Whether factor matrices are initialized by NMF\n\n\n\n\nUse TCMFForecaster\n\n\nTrain model\n\n\nAfter an TCMFForecaster is created, you can call forecaster API to train a tcmf model:\n\n\nmodel.fit(x,\n          val_len=24,\n          start_date=\"2020-4-1\",\n          freq=\"1H\",\n          covariates=None,\n          dti=None,\n          period=24,\n          y_iters=10,\n          init_FX_epoch=100,\n          max_FX_epoch=300,\n          max_TCN_epoch=300,\n          alt_iters=10,\n          num_workers=None)\n\n\n\n\n\n\nx\n: the input for fit. Only dict of ndarray and SparkXShards of dict of ndarray\n       are supported. Example: {'id': id_arr, 'y': data_ndarray}. If input is SparkXShards, each partition will use one model to fit.\n\n\nval_len\n:int, default is 24.\n            Validation length. We will use the last val_len time points as validation data.\n\n\nstart_date\n: str or datetime-like.\n            Start date time for the time-series. e.g. \"2020-01-01\"\n\n\nfreq\n: str or DateOffset, default is 'H'\n            Frequency of data\n\n\ncovariates\n: 2-D ndarray or None. The shape of ndarray should be (r, T), where r is\n            the number of covariates and T is the number of time points.\n            Global covariates for all time series. If None, only default time coveriates will be\n            used while use_time is True. If not, the time coveriates used is the stack of input\n            covariates and default time coveriates.\n\n\ndti\n: DatetimeIndex or None.\n            If None, use default fixed frequency DatetimeIndex generated with start_date and freq.\n\n\nperiod\n: int, default is 24.\n            Periodicity of input time series, leave it out if not known\n\n\ny_iters\n: int, default is 10.\n            Number of iterations while training the hybrid model.\n\n\ninit_FX_epoch\n: int, default is 100.\n            Number of iterations while initializing factors\n\n\nmax_FX_epoch\n: int, default is 300.\n            Max number of iterations while training factors.\n\n\nmax_TCN_epoch\n: int, default is 300.\n            Max number of iterations while training the local model.\n\n\nalt_iters\n: int, default is 10.\n            Number of iterations while alternate training.\n\n\nnum_workers\n: the number of workers you want to use for fit. It is only effective while input x is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.\n\n\n\n\nGet prediction results of model\n\n\nAfter Training, you can call forecaster API to get the prediction result of tcmf model. \nmodel.predict\n will output the prediction results of future \nhorizon\n steps after \nx\n in \nfit\n.\n\n\nmodel.predict(horizon=24,\n              future_covariates=None,\n              future_dti=None,\n              num_workers=None,\n              )\n\n\n\n\n\n\nfuture_covariates\n: covariates corresponding to future horizon steps data to predict.\n        2-D ndarray or None.\n        The shape of ndarray should be (r, horizon), where r is the number of covariates.\n        Global covariates for all time series. If None, only default time coveriates will be\n        used while use_time is True. If not, the time coveriates used is the stack of input\n        covariates and default time coveriates.\n\n\nfuture_dti\n: dti corresponding to future horizon steps data to predict.\n        DatetimeIndex or None.\n        If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n        fit and freq.\n\n\nnum_workers\n: the number of workers to use in predict. It is only effective while input \nx\n in \nfit\n is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.\n\n\n\n\nEvaluate model\n\n\nAfter Training, you can call forecaster API to evaluate the tcmf model. \nmodel.evaluate\n will output the evaluation results for future \nhorizon\n steps after \nx\n in \nfit\n.\n\n\nmodel.evaluate(target_value,\n               metric=['mae'],\n               target_covariates=None,\n               target_dti=None,\n               num_workers=None,\n               )\n\n\n\n\n\n\ntarget_value\n: target value for evaluation. It should be of the same format as input x in fit, which is a dict of ndarray or SparkXShards of dict of ndarray.\n                  We interpret the second dimension of y in target value as the horizon length for evaluation.\n\n\nmetric\n: the metrics. A list of metric names.\n\n\ntarget_covariates\n: covariates corresponding to target_value.\n        2-D ndarray or None.\n        The shape of ndarray should be (r, horizon), where r is the number of covariates.\n        Global covariates for all time series. If None, only default time coveriates will be\n        used while use_time is True. If not, the time coveriates used is the stack of input\n        covariates and default time coveriates.\n\n\ntarget_dti\n: dti corresponding to target_value.\n        DatetimeIndex or None.\n        If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n        fit and freq.\n\n\nnum_workers\n: the number of workers to use in evaluate. It is only effective while input target value is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.\n\n\n\n\nIncrementally fit the model with additional data\n\n\nIncrementally fit the model. Note that we only incrementally fit X_seq (TCN in global model). We haven't enable fit_incremental for input SparkXshards yet.\n\n\nmodel.fit_incremental(x_incr,\n                      covariates_incr=None,\n                      dti_incr=None\n                     )\n\n\n\n\n\n\nx_incr\n: incremental data to be fitted. It should be of the same format as input x in fit, which is a dict of ndarray or SparkXShards of dict of ndarray.\nExample: {'id': id_arr, 'y': incr_ndarray}, and incr_ndarray is of shape (n, T_incr), where\nn is the number of target time series, T_incr is the number of time steps incremented. You\ncan choose not to input 'id' in x_incr, but if you do, the elements of id in x_incr should\nbe the same as id in x of fit.\n\n\ncovariates_incr\n: covariates corresponding to x_incr. 2-D ndarray or None.\n    The shape of ndarray should be (r, T_incr), where r is the number of covariates.\n    Global covariates for all time series. If None, only default time coveriates will be\n    used while use_time is True. If not, the time coveriates used is the stack of input\n    covariates and default time coveriates.\n\n\ndti_incr\n: dti corresponding to the x_incr. DatetimeIndex or None.\n    If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n    fit and freq.\n\n\n\n\nSave model\n\n\nYou can save model after fit for future deployment.\n\n\nmodel.save(path)\n\n\n\n\n\n\npath\n: (str) Path to target saved file.\n\n\n\n\nLoad model\n\n\nYou can load saved model with \n\n\nTCMFForecaster.load(path, \n                    distributed=False, \n                    minPartitions=None)\n\n\n\n\n\n\npath\n: (str) Path to target saved file.\n\n\ndistributed\n: Whether the model is distributed trained with input of dict of SparkXshards.\n\n\nminPartitions\n: The minimum partitions for the XShards.\n\n\n\n\nCheck whether model is distributed with input xshards\n\n\nYou can check whether model is distributed by input xshards with \nmodel.is_xshards_distributed()\n.",
            "title": "TCMFForecaster"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#introduction",
            "text": "Analytics Zoo Zouwu TCMFForecaster provides an efficient way to forecast high dimensional time series.   TCMFForecaster is based on DeepGLO algorithm, which is a deep forecasting model which thinks globally and acts locally.\nYou can refer to  the deepglo paper  for more details.   TCMFForecaster supports distributed training and inference. It is based on Orca PyTorch Estimator, which is an estimator to do PyTorch training/evaluation/prediction on Spark in a distributed fashion. Also you can choose to enable distributed training and inference or not.  Remarks :   You can refer to  TCMFForecaster installation  to install required packages.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .",
            "title": "Introduction"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#tcmfforecaster",
            "text": "",
            "title": "TCMFForecaster"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#create-tcmfforecaster",
            "text": "from zoo.zouwu.model.forecast.tcmf_forecaster import TCMFForecaster\nmodel = TCMFForecaster(\n         vbsize=128,\n         hbsize=256,\n         num_channels_X=[32, 32, 32, 32, 32, 1],\n         num_channels_Y=[16, 16, 16, 16, 16, 1],\n         kernel_size=7,\n         dropout=0.1,\n         rank=64,\n         kernel_size_Y=7,\n         learning_rate=0.0005,\n         normalize=False,\n         use_time=True,\n         svd=True,)   vbsize : int, default is 128.\n            Vertical batch size, which is the number of cells per batch.  hbsize : int, default is 256.\n            Horizontal batch size, which is the number of time series per batch.  num_channels_X : list, default=[32, 32, 32, 32, 32, 1].\n            List containing channel progression of temporal convolution network for local model  num_channels_Y : list, default=[16, 16, 16, 16, 16, 1]\n            List containing channel progression of temporal convolution network for hybrid model.  kernel_size : int, default is 7.\n            Kernel size for local models  dropout : float, default is 0.1.\n            Dropout rate during training  rank : int, default is 64.\n            The rank in matrix factorization of global model.  kernel_size_Y : int, default is 7.\n            Kernel size of hybrid model  learning_rate :  float, default is 0.0005  normalize : boolean, false by default.\n            Whether to normalize input data for training.  use_time : boolean, default is True.\n            Whether to use time coveriates.  svd : boolean, default is False.\n            Whether factor matrices are initialized by NMF",
            "title": "Create TCMFForecaster"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#use-tcmfforecaster",
            "text": "",
            "title": "Use TCMFForecaster"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#train-model",
            "text": "After an TCMFForecaster is created, you can call forecaster API to train a tcmf model:  model.fit(x,\n          val_len=24,\n          start_date=\"2020-4-1\",\n          freq=\"1H\",\n          covariates=None,\n          dti=None,\n          period=24,\n          y_iters=10,\n          init_FX_epoch=100,\n          max_FX_epoch=300,\n          max_TCN_epoch=300,\n          alt_iters=10,\n          num_workers=None)   x : the input for fit. Only dict of ndarray and SparkXShards of dict of ndarray\n       are supported. Example: {'id': id_arr, 'y': data_ndarray}. If input is SparkXShards, each partition will use one model to fit.  val_len :int, default is 24.\n            Validation length. We will use the last val_len time points as validation data.  start_date : str or datetime-like.\n            Start date time for the time-series. e.g. \"2020-01-01\"  freq : str or DateOffset, default is 'H'\n            Frequency of data  covariates : 2-D ndarray or None. The shape of ndarray should be (r, T), where r is\n            the number of covariates and T is the number of time points.\n            Global covariates for all time series. If None, only default time coveriates will be\n            used while use_time is True. If not, the time coveriates used is the stack of input\n            covariates and default time coveriates.  dti : DatetimeIndex or None.\n            If None, use default fixed frequency DatetimeIndex generated with start_date and freq.  period : int, default is 24.\n            Periodicity of input time series, leave it out if not known  y_iters : int, default is 10.\n            Number of iterations while training the hybrid model.  init_FX_epoch : int, default is 100.\n            Number of iterations while initializing factors  max_FX_epoch : int, default is 300.\n            Max number of iterations while training factors.  max_TCN_epoch : int, default is 300.\n            Max number of iterations while training the local model.  alt_iters : int, default is 10.\n            Number of iterations while alternate training.  num_workers : the number of workers you want to use for fit. It is only effective while input x is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.",
            "title": "Train model"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#get-prediction-results-of-model",
            "text": "After Training, you can call forecaster API to get the prediction result of tcmf model.  model.predict  will output the prediction results of future  horizon  steps after  x  in  fit .  model.predict(horizon=24,\n              future_covariates=None,\n              future_dti=None,\n              num_workers=None,\n              )   future_covariates : covariates corresponding to future horizon steps data to predict.\n        2-D ndarray or None.\n        The shape of ndarray should be (r, horizon), where r is the number of covariates.\n        Global covariates for all time series. If None, only default time coveriates will be\n        used while use_time is True. If not, the time coveriates used is the stack of input\n        covariates and default time coveriates.  future_dti : dti corresponding to future horizon steps data to predict.\n        DatetimeIndex or None.\n        If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n        fit and freq.  num_workers : the number of workers to use in predict. It is only effective while input  x  in  fit  is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.",
            "title": "Get prediction results of model"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#evaluate-model",
            "text": "After Training, you can call forecaster API to evaluate the tcmf model.  model.evaluate  will output the evaluation results for future  horizon  steps after  x  in  fit .  model.evaluate(target_value,\n               metric=['mae'],\n               target_covariates=None,\n               target_dti=None,\n               num_workers=None,\n               )   target_value : target value for evaluation. It should be of the same format as input x in fit, which is a dict of ndarray or SparkXShards of dict of ndarray.\n                  We interpret the second dimension of y in target value as the horizon length for evaluation.  metric : the metrics. A list of metric names.  target_covariates : covariates corresponding to target_value.\n        2-D ndarray or None.\n        The shape of ndarray should be (r, horizon), where r is the number of covariates.\n        Global covariates for all time series. If None, only default time coveriates will be\n        used while use_time is True. If not, the time coveriates used is the stack of input\n        covariates and default time coveriates.  target_dti : dti corresponding to target_value.\n        DatetimeIndex or None.\n        If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n        fit and freq.  num_workers : the number of workers to use in evaluate. It is only effective while input target value is dict of ndarray. If None, it defaults to\n        num_ray_nodes in the created RayContext or 1 if there is no active RayContext.",
            "title": "Evaluate model"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#incrementally-fit-the-model-with-additional-data",
            "text": "Incrementally fit the model. Note that we only incrementally fit X_seq (TCN in global model). We haven't enable fit_incremental for input SparkXshards yet.  model.fit_incremental(x_incr,\n                      covariates_incr=None,\n                      dti_incr=None\n                     )   x_incr : incremental data to be fitted. It should be of the same format as input x in fit, which is a dict of ndarray or SparkXShards of dict of ndarray.\nExample: {'id': id_arr, 'y': incr_ndarray}, and incr_ndarray is of shape (n, T_incr), where\nn is the number of target time series, T_incr is the number of time steps incremented. You\ncan choose not to input 'id' in x_incr, but if you do, the elements of id in x_incr should\nbe the same as id in x of fit.  covariates_incr : covariates corresponding to x_incr. 2-D ndarray or None.\n    The shape of ndarray should be (r, T_incr), where r is the number of covariates.\n    Global covariates for all time series. If None, only default time coveriates will be\n    used while use_time is True. If not, the time coveriates used is the stack of input\n    covariates and default time coveriates.  dti_incr : dti corresponding to the x_incr. DatetimeIndex or None.\n    If None, use default fixed frequency DatetimeIndex generated with the last date of x in\n    fit and freq.",
            "title": "Incrementally fit the model with additional data"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#save-model",
            "text": "You can save model after fit for future deployment.  model.save(path)   path : (str) Path to target saved file.",
            "title": "Save model"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#load-model",
            "text": "You can load saved model with   TCMFForecaster.load(path, \n                    distributed=False, \n                    minPartitions=None)   path : (str) Path to target saved file.  distributed : Whether the model is distributed trained with input of dict of SparkXshards.  minPartitions : The minimum partitions for the XShards.",
            "title": "Load model"
        },
        {
            "location": "/Zouwu/API/TCMFForecaster/#check-whether-model-is-distributed-with-input-xshards",
            "text": "You can check whether model is distributed by input xshards with  model.is_xshards_distributed() .",
            "title": "Check whether model is distributed with input xshards"
        },
        {
            "location": "/Zouwu/API/AutoTSTrainer/",
            "text": "AutoTSTrainer\n\n\nZouwu AutoTSTrainer is used to train a TSPipeline for forecasting using AutoML.\n\n\nIt is built upon \nAnalytics Zoo AutoML module\n (refer to \nAutoML ProgrammingGuide\n and \nAutoML APIGuide\n for details), which uses \nRay Tune\n for hyper parameter tuning and runs on \nAnalytics Zoo RayOnSpark\n.\n\n\nMethods\n\n\n__init__\n\n\nfrom zoo.zouwu.autots.forecast import AutoTSTrainer\n\ntrainer = AutoTSTrainer(dt_col=\"datetime\",\n                         target_col=\"value\",\n                         horizon=1,\n                         extra_features_col=None,\n                         search_alg=None,\n                         search_alg_params=None,\n                         scheduler=None,\n                         scheduler_params=None,)\n\n\n\n\n\n\n\ndt_col\n: the column specifying datetime\n\n\ntarget_col\n: target column to predict\n\n\nhorizon\n : num of steps to look forward\n\n\nextra_feature_col\n: a list of columns which are also included in input as features except target column\n\n\nsearch_alg\n: Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.\n\n\nsearch_alg_params\n: Optional(Dict). params of search_alg.\n\n\nscheduler\n: Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".\n\n\nscheduler_params\n: Optional(Dict). Necessary params of scheduler.\n\n\n\n\nfit\n\n\npython \nfit(train_df,\n    validation_df=None,\n    metric=\"mse\",\n    recipe: Recipe = SmokeRecipe(),\n    uncertainty: bool = False)\n\n\n\n\ntrain_df\n: the input dataframe (as pandas.dataframe)\n\n\nvalidation_df\n: the validation dataframe (as pandas.dataframe)\n\n\nrecipe\n: the configuration of searching, refer to definition in \nautoml.config.recipe\n\n\nmetric\n: the evaluation metric to optimize\n\n\nuncertainty\n: whether to enable uncertainty calculation (will output an uncertainty sigma)\n\n\nreturn\n: a TSPipeline\n\n\n\n\nNote:\n\n\ntrain_df and validation_df are data frames. An exmaple data frame looks like below.\n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue\n\n\nextra_feature_1\n\n\nextra_feature_2\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n1\n\n\n2\n\n\n\n\n\n\n2019-06-07\n\n\n2.3\n\n\n0\n\n\n2",
            "title": "AutoTSTrainer"
        },
        {
            "location": "/Zouwu/API/AutoTSTrainer/#autotstrainer",
            "text": "Zouwu AutoTSTrainer is used to train a TSPipeline for forecasting using AutoML.  It is built upon  Analytics Zoo AutoML module  (refer to  AutoML ProgrammingGuide  and  AutoML APIGuide  for details), which uses  Ray Tune  for hyper parameter tuning and runs on  Analytics Zoo RayOnSpark .",
            "title": "AutoTSTrainer"
        },
        {
            "location": "/Zouwu/API/AutoTSTrainer/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/Zouwu/API/AutoTSTrainer/#__init__",
            "text": "from zoo.zouwu.autots.forecast import AutoTSTrainer\n\ntrainer = AutoTSTrainer(dt_col=\"datetime\",\n                         target_col=\"value\",\n                         horizon=1,\n                         extra_features_col=None,\n                         search_alg=None,\n                         search_alg_params=None,\n                         scheduler=None,\n                         scheduler_params=None,)   dt_col : the column specifying datetime  target_col : target column to predict  horizon  : num of steps to look forward  extra_feature_col : a list of columns which are also included in input as features except target column  search_alg : Optional(str). The search algorithm to use. We only support \"bayesopt\" and \"skopt\" for now.\n                The default search_alg is None and variants will be generated according to the search method in search space.  search_alg_params : Optional(Dict). params of search_alg.  scheduler : Optional(str). Scheduler name. Allowed scheduler names are \"fifo\", \"async_hyperband\",\n    \"asynchyperband\", \"median_stopping_rule\", \"medianstopping\", \"hyperband\", \"hb_bohb\", \"pbt\". The default scheduler is \"fifo\".  scheduler_params : Optional(Dict). Necessary params of scheduler.",
            "title": "__init__"
        },
        {
            "location": "/Zouwu/API/AutoTSTrainer/#fit",
            "text": "python \nfit(train_df,\n    validation_df=None,\n    metric=\"mse\",\n    recipe: Recipe = SmokeRecipe(),\n    uncertainty: bool = False)   train_df : the input dataframe (as pandas.dataframe)  validation_df : the validation dataframe (as pandas.dataframe)  recipe : the configuration of searching, refer to definition in  automl.config.recipe  metric : the evaluation metric to optimize  uncertainty : whether to enable uncertainty calculation (will output an uncertainty sigma)  return : a TSPipeline   Note:  train_df and validation_df are data frames. An exmaple data frame looks like below.     datetime  value  extra_feature_1  extra_feature_2      2019-06-06  1.2  1  2    2019-06-07  2.3  0  2",
            "title": "fit"
        },
        {
            "location": "/Zouwu/API/TSPipeline/",
            "text": "TSPipeline\n\n\nA pipeline for time series forecasting. \n\n\nfrom zoo.zouwu.autots.forecast import TSPipeline\n\n\n\n\nNote:\n\n\n\n\nTSPipeline can be obtained from AutoTSTrainer or loaded from saved file.\n\n\ntrain_df and validation_df in fit/evalute/predict are data frames. An exmaple data frame looks like below.\n\n\n\n\n\n\n\n\n\n\ndatetime\n\n\nvalue\n\n\nextra_feature_1\n\n\nextra_feature_2\n\n\n\n\n\n\n\n\n\n\n2019-06-06\n\n\n1.2\n\n\n1\n\n\n2\n\n\n\n\n\n\n2019-06-07\n\n\n2.3\n\n\n0\n\n\n2\n\n\n\n\n\n\n\n\nMethods\n\n\nfit\n\n\nThis is usually for incremental fitting, and doesn't involve AutoML.\n\n\nfit(input_df,validation_df=None,uncertainty: bool = False,epochs=1,**user_config)\n\n\n\n\nArguments\n\n\n\n\ninput_df\n: the input dataframe\n\n\nvalidation_df\n: the validation dataframe\n\n\nuncertainty\n: whether to calculate uncertainty\n\n\nepochs\n: number of epochs to train\n\n\nuser_config\n: user configurations\n\n\n\n\npredict\n\n\npredict(input_df) \n\n\n\n\nArguments\n\n\n\n\ninput_df\n: the input dataframe\n\n\nreturn\n: the forecast results\n\n\n\n\nevaluate\n\n\nevaluate(input_df,metrics=[\"mse\"],multioutput='raw_values')\n\n\n\n\nArguments\n\n\n\n\ninput_df\n: the input dataframe\n\n\nmetrics\n: the evaluation metrics\n\n\nmultioutput\n: output mode of multiple output, whether to aggregate\n\n\nreturn\n: the evaluation results\n\n\n\n\n\n\nLoad and Save a TSPipeline can be used in below way.\n\n\nfrom zoo.zouwu.autots.forecast import TSPipeline\nloaded_ppl = TSPipeline.load(file)\n# ... do sth. e.g. incremental fitting\nloaded_ppl.save(another_file)\n\n\n\n\nload\n\n\nload is a static method. \n\n\nload(pipeline_file)\n\n\n\n\nArguments\n\n\n\n\npipeline_file\n: the pipeline file\n\n\n\n\nsave\n\n\nsave(pipeline_file)\n\n\n\n\nArguments\n\n\n\n\npipeline_file\n: the pipeline file",
            "title": "TSPipeline"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#tspipeline",
            "text": "A pipeline for time series forecasting.   from zoo.zouwu.autots.forecast import TSPipeline  Note:   TSPipeline can be obtained from AutoTSTrainer or loaded from saved file.  train_df and validation_df in fit/evalute/predict are data frames. An exmaple data frame looks like below.      datetime  value  extra_feature_1  extra_feature_2      2019-06-06  1.2  1  2    2019-06-07  2.3  0  2",
            "title": "TSPipeline"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#methods",
            "text": "",
            "title": "Methods"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#fit",
            "text": "This is usually for incremental fitting, and doesn't involve AutoML.  fit(input_df,validation_df=None,uncertainty: bool = False,epochs=1,**user_config)",
            "title": "fit"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#arguments",
            "text": "input_df : the input dataframe  validation_df : the validation dataframe  uncertainty : whether to calculate uncertainty  epochs : number of epochs to train  user_config : user configurations",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#predict",
            "text": "predict(input_df)",
            "title": "predict"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#arguments_1",
            "text": "input_df : the input dataframe  return : the forecast results",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#evaluate",
            "text": "evaluate(input_df,metrics=[\"mse\"],multioutput='raw_values')",
            "title": "evaluate"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#arguments_2",
            "text": "input_df : the input dataframe  metrics : the evaluation metrics  multioutput : output mode of multiple output, whether to aggregate  return : the evaluation results    Load and Save a TSPipeline can be used in below way.  from zoo.zouwu.autots.forecast import TSPipeline\nloaded_ppl = TSPipeline.load(file)\n# ... do sth. e.g. incremental fitting\nloaded_ppl.save(another_file)",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#load",
            "text": "load is a static method.   load(pipeline_file)",
            "title": "load"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#arguments_3",
            "text": "pipeline_file : the pipeline file",
            "title": "Arguments"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#save",
            "text": "save(pipeline_file)",
            "title": "save"
        },
        {
            "location": "/Zouwu/API/TSPipeline/#arguments_4",
            "text": "pipeline_file : the pipeline file",
            "title": "Arguments"
        },
        {
            "location": "/Orca/overview/",
            "text": "Project Orca: Easily Scaling out Python AI pipelines\n\n\nMost AI projects start with a Python notebook running on a single laptop; however, one usually needs to go through a mountain of pains to scale it to handle larger data set in a distributed fashion. \n\n\nProject Orca\n allows you to easily scale out your single node Python notebook across large clusters, by providing:\n\n\n\n\n\n\nData-parallel preprocessing for Python AI (supporting common Python libraries such as Pandas, Numpy, PIL, TensorFlow Dataset, PyTorch DataLoader, etc.)\n\n\n\n\n\n\nSklearn-style APIs for transparently distributed training and inference (supporting TensorFlow, PyTorch, Keras, MXNet, Horovod, etc.)",
            "title": "Overview"
        },
        {
            "location": "/Orca/context/",
            "text": "Initialization and Termination\n\n\nAs a starting point of \nProject Orca\n, you need to call \ninit_orca_context\n to create or get a SparkContext for your Spark cluster (and launch Ray services\nacross the cluster if necessary). When your application finishes, you need to call \nstop_orca_context\n to stop the SparkContext (and stop Ray services across the cluster if necessary).\n\n\nfrom zoo.orca import init_orca_context, stop_orca_context\n\n# At the very beginning:\nsc = init_orca_context(cluster_mode=\"local\", cores=2, memory=\"2g\", num_nodes=1,\n                       init_ray_on_spark=False, **kwargs)\n\n# Your application goes after init_orca_context.\n\n# When your application finishes:\nstop_orca_context()\n\n\n\n\nArguments for\n \ninit_orca_context\n:\n\n\n\n\ncluster_mode\n: The mode for the Spark cluster. One of \"local\", \"yarn-client\", \"k8s-client\", \"standalone\" and \"spark-submit\". Default to be \"local\". \n\n\n\n\nFor \"spark-submit\", you are supposed to use spark-submit to submit the application. In this case, please set the Spark configurations through command line options or\nthe properties file. You need to use \"spark-submit\" for yarn-cluster or k8s-cluster mode. To make things easier, you are recommended to use the \nlaunch \nscripts\n we provide.\n\n\nFor other cluster modes, you are recommended to install and run analytics-zoo through pip, which is more convenient.\n\n\n\n\ncores\n: The number of cores to be used on each node. Default to be 2.\n\n\nmemory\n: The memory allocated for each node. Default to be '2g'.\n\n\nnum_nodes\n: The number of nodes to be used in the cluster. Default to be 1. For Spark local, num_nodes should always be 1 and you don't need to change it.\n\n\ninit_ray_on_spark\n: Whether to launch Ray services across the cluster. Default to be False and in this case the Ray cluster would be launched lazily when Ray is involved in Project Orca.\n\n\nkwargs\n: The extra keyword arguments used for creating SparkContext and launching Ray if any.\n\n\n\n\n\n\nExtra Configurations\n\n\nUsers can make extra configurations when using the functionalities of Project Orca via \nOrcaContext\n.\n\n\nImport OrcaContext using \nfrom from zoo.orca import OrcaContext\n and then you can choose to modify the following options:\n\n\n\n\nlog_output\n\n\n\n\nOrcaContext.log_output = False  # Default\nOrcaContext.log_output = True\n\n\n\n\nWhether to redirect Spark driver JVM's stdout and stderr to the current python process. \nThis is useful when running Analytics Zoo in jupyter notebook.\nDefault to be False. Needs to be set before initializing SparkContext.\n\n\n\n\npandas_read_backend\n\n\n\n\nOrcaContext.pandas_read_backend = \"spark\"  # Default\nOrcaContext.pandas_read_backend = \"pandas\"\n\n\n\n\nThe backend for reading csv/json files. Either \"spark\" or \"pandas\". \n\"spark\" backend would call \nspark.read\n and \"pandas\" backend would call \npandas.read\n. \nDefault to be \"spark\".\n\n\n\n\nserialize_data_creation\n\n\n\n\nOrcaContext.serialize_data_creation = False  # Default\nOrcaContext.serialize_data_creation = True\n\n\n\n\nWhether add a file lock to the data loading process for PyTorch Horovod training. \nThis would be useful when you run multiple workers on a single node to download data to the same destination. \nDefault to be False.",
            "title": "OrcaContext"
        },
        {
            "location": "/Orca/context/#initialization-and-termination",
            "text": "As a starting point of  Project Orca , you need to call  init_orca_context  to create or get a SparkContext for your Spark cluster (and launch Ray services\nacross the cluster if necessary). When your application finishes, you need to call  stop_orca_context  to stop the SparkContext (and stop Ray services across the cluster if necessary).  from zoo.orca import init_orca_context, stop_orca_context\n\n# At the very beginning:\nsc = init_orca_context(cluster_mode=\"local\", cores=2, memory=\"2g\", num_nodes=1,\n                       init_ray_on_spark=False, **kwargs)\n\n# Your application goes after init_orca_context.\n\n# When your application finishes:\nstop_orca_context()  Arguments for   init_orca_context :   cluster_mode : The mode for the Spark cluster. One of \"local\", \"yarn-client\", \"k8s-client\", \"standalone\" and \"spark-submit\". Default to be \"local\".    For \"spark-submit\", you are supposed to use spark-submit to submit the application. In this case, please set the Spark configurations through command line options or\nthe properties file. You need to use \"spark-submit\" for yarn-cluster or k8s-cluster mode. To make things easier, you are recommended to use the \nlaunch  scripts  we provide.  For other cluster modes, you are recommended to install and run analytics-zoo through pip, which is more convenient.   cores : The number of cores to be used on each node. Default to be 2.  memory : The memory allocated for each node. Default to be '2g'.  num_nodes : The number of nodes to be used in the cluster. Default to be 1. For Spark local, num_nodes should always be 1 and you don't need to change it.  init_ray_on_spark : Whether to launch Ray services across the cluster. Default to be False and in this case the Ray cluster would be launched lazily when Ray is involved in Project Orca.  kwargs : The extra keyword arguments used for creating SparkContext and launching Ray if any.",
            "title": "Initialization and Termination"
        },
        {
            "location": "/Orca/context/#extra-configurations",
            "text": "Users can make extra configurations when using the functionalities of Project Orca via  OrcaContext .  Import OrcaContext using  from from zoo.orca import OrcaContext  and then you can choose to modify the following options:   log_output   OrcaContext.log_output = False  # Default\nOrcaContext.log_output = True  Whether to redirect Spark driver JVM's stdout and stderr to the current python process. \nThis is useful when running Analytics Zoo in jupyter notebook.\nDefault to be False. Needs to be set before initializing SparkContext.   pandas_read_backend   OrcaContext.pandas_read_backend = \"spark\"  # Default\nOrcaContext.pandas_read_backend = \"pandas\"  The backend for reading csv/json files. Either \"spark\" or \"pandas\". \n\"spark\" backend would call  spark.read  and \"pandas\" backend would call  pandas.read . \nDefault to be \"spark\".   serialize_data_creation   OrcaContext.serialize_data_creation = False  # Default\nOrcaContext.serialize_data_creation = True  Whether add a file lock to the data loading process for PyTorch Horovod training. \nThis would be useful when you run multiple workers on a single node to download data to the same destination. \nDefault to be False.",
            "title": "Extra Configurations"
        },
        {
            "location": "/Orca/data/",
            "text": "Introduction\n\n\nAnalytics Zoo Orca data provides data-parallel pre-processing support for Python AI.\n\n\nIt supports data pre-processing from different data sources, like TensorFlow DataSet, PyTorch DataLoader, MXNet DataLoader, etc. and it supports various data formats, like Pandas DataFrame, Numpy, Images, Parquet, etc.\n\n\nThe distributed backend engine can be \nSpark\n or \nRay\n. We now support Spark-based transformations to do the pre-processing, and provide functionality to seamlessly put data to Ray cluster for later training/inference on Ray. \n\n\n\n\nXShards\n\n\nXShards is a collection of data in Orca data API. We provide different backends(Spark and Ray) for XShards.\n\n\nXShards General Operations\n\n\nPre-processing on XShards\n\n\nYou can do pre-processing with your customized function on XShards using below API:\n\n\ntransform_shard(func, *args)\n\n\n\n\n\n\nfunc\n is your pre-processing function. In this function, you can do the pre-processing with the data using common Python libraries such as Pandas, Numpy, PIL, TensorFlow Dataset, PyTorch DataLoader, etc., then return the processed object. \n\n\nargs\n are the augurments for the pre-processing function.\n\n\n\n\nThis method would parallelly pre-process each element in the XShards with the customized function, and return a new XShards after transformation.\n\n\nSharedValue\n\n\nSharedValue can be used to give every node a copy of a large input dataset in an efficient manner.\nThis is an example of using SharedValue:\n\n\ndef func(df, item_set)\n   item_set = item_set.value\n   ....\n\nitem_set= ...\nitem_set= orca.data.SharedValue(item_set)\nfull_data.transform_shard(func, item_set)\n\n\n\n\nGet all the elements in XShards\n\n\nYou can get all of elements in XShards with such API:\n\n\ncollect()\n\n\n\n\nThis method returns a list that contains all of the elements in this XShards. \n\n\nRepartition XShards\n\n\nYou can repartition XShards to different number of partitions.\n\n\nrepartition(num_partitions)\n\n\n\n\n\n\nnum_partitions\n is the target number of partitions for the new XShards.\n\n\n\n\nThe method returns a new XShards that has exactly num_partitions partitions.\n\n\nSplit XShards\n\n\nYou can split one XShards into multiple XShards. Each element in the XShards needs be a list or tuple with same length.\n\n\nsplit()\n\n\n\n\nThis method returns splits of XShards. If each element in the input SparkDataShard is not a list or tuple, return list of input SparkDataShards.\n\n\nSave/Load XShards\n\n\nYou can save XShards on Spark as SequenceFiles of serialized objects.\nThe serializer used is pyspark.serializers.PickleSerializer.\n\n\nsave_pickle(path, batchSize=10)\n\n\n\n\n\n\npath\n is target save path.\n\n\nbatchSize\n batch size for each chunk in sequence file.\n\n\n\n\nAnd you can load pickle file to XShards if you use save_pickle() to save data.\n\n\nzoo.orca.data.XShards.load_pickle(path, minPartitions=None)\n\n\n\n\n\n\npath\n: The pickle file path/directory.\n\n\nminPartitions\n: The minimum partitions for the XShards.\n\n\n\n\nThis method return an XShards object from pickle files.\n\n\nMove XShards on Spark to Ray backend\n\n\nYou can put data of the XShards on Spark to Ray cluster object store for later processing on Ray.\n\n\nto_ray()\n\n\n\n\nThis method save data of XShards on Spark to Ray object store, and return a new RayXShards which contains plasma ObjectID, the plasma object_store_address and the node IP on each partition.\n\n\nXShards with Pandas DataFrame\n\n\nRead data into XShards\n\n\nYou can read csv/json files/directory into XShards with such APIs:\n\n\nzoo.orca.data.pandas.read_csv(file_path, **kwargs)\n\nzoo.orca.data.pandas.read_json(file_path, **kwargs)\n\n\n\n\n\n\nThe \nfile_path\n could be a csv/json file, list of multiple csv/json file paths, a directory containing csv/json files. Supported file systems are local file system,\nhdfs\n, and \ns3\n.\n\n\n**kwargs\n is read_csv/read_json options supported by pandas.\n\n\nYou can use \nOrcaContext.pandas_read_backend = \"pandas\"\n to switch to pandas backend. Reference: \nOrca Context\n\n\n\n\nAfter calling these APIs, you would get a XShards of Pandas DataFrame on Spark.\n\n\nFor Cloudera YARN client mode users:\n\nIf you use \npandas\n as pandas_read_backend, you should configure \nARROW_LIBHDFS_DIR\n before calling read_csv:\n1. use \nlocate libhdfs.so\n to find libhdfs.so\n2. \nexport ARROW_LIBHDFS_DIR=/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib64\n (replace with the result of \nlocate libhdfs.so\n)\n3. use \n--conf \"spark.executorEnv.ARROW_LIBHDFS_DIR=/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib64\"\n to export the environment variable to all executors.\n\n\nPartition by Pandas DataFrame columns\n\n\nYou can re-partition XShards of Pandas DataFrame with specified columns.\n\n\npartition_by(cols, num_partitions=None)\n\n\n\n\n\n\ncols\n: DataFrame columns to partition by.\n\n\nnum_partitions\n: target number of partitions. If not specified, the new XShards would keep the current partition number.\n\n\n\n\nThis method return a new XShards partitioned using the specified columns.\n\n\nGet unique element list of XShards of Pandas Series\n\n\nYou can get a unique list of elements of this XShards. This is useful when you want to count/get unique set of some column in the XShards of Pandas DataFrame. \n\n\nunique()\n\n\n\n\nThis method return a unique list of elements of the XShards of Pandas Series.\n\n\nXShards with Numpy\n\n\nLoad local numpy data to XShards\n\n\nYou can partition local in memory data and form an XShards on Spark.\n\n\nzoo.orca.data.XShards.partition(data)\n\n\n\n\n\n\ndata\n: The local data can be numpy.ndarray, a tuple, list, dict of numpy.ndarray, or a nested structure made of tuple, list, dict with ndarray as the leaf value.\n\n\n\n\nThis method returns a XShards which dispatch local data in parallel on Spark.",
            "title": "Data"
        },
        {
            "location": "/Orca/data/#introduction",
            "text": "Analytics Zoo Orca data provides data-parallel pre-processing support for Python AI.  It supports data pre-processing from different data sources, like TensorFlow DataSet, PyTorch DataLoader, MXNet DataLoader, etc. and it supports various data formats, like Pandas DataFrame, Numpy, Images, Parquet, etc.  The distributed backend engine can be  Spark  or  Ray . We now support Spark-based transformations to do the pre-processing, and provide functionality to seamlessly put data to Ray cluster for later training/inference on Ray.",
            "title": "Introduction"
        },
        {
            "location": "/Orca/data/#xshards",
            "text": "XShards is a collection of data in Orca data API. We provide different backends(Spark and Ray) for XShards.",
            "title": "XShards"
        },
        {
            "location": "/Orca/data/#xshards-general-operations",
            "text": "",
            "title": "XShards General Operations"
        },
        {
            "location": "/Orca/data/#pre-processing-on-xshards",
            "text": "You can do pre-processing with your customized function on XShards using below API:  transform_shard(func, *args)   func  is your pre-processing function. In this function, you can do the pre-processing with the data using common Python libraries such as Pandas, Numpy, PIL, TensorFlow Dataset, PyTorch DataLoader, etc., then return the processed object.   args  are the augurments for the pre-processing function.   This method would parallelly pre-process each element in the XShards with the customized function, and return a new XShards after transformation.",
            "title": "Pre-processing on XShards"
        },
        {
            "location": "/Orca/data/#sharedvalue",
            "text": "SharedValue can be used to give every node a copy of a large input dataset in an efficient manner.\nThis is an example of using SharedValue:  def func(df, item_set)\n   item_set = item_set.value\n   ....\n\nitem_set= ...\nitem_set= orca.data.SharedValue(item_set)\nfull_data.transform_shard(func, item_set)",
            "title": "SharedValue"
        },
        {
            "location": "/Orca/data/#get-all-the-elements-in-xshards",
            "text": "You can get all of elements in XShards with such API:  collect()  This method returns a list that contains all of the elements in this XShards.",
            "title": "Get all the elements in XShards"
        },
        {
            "location": "/Orca/data/#repartition-xshards",
            "text": "You can repartition XShards to different number of partitions.  repartition(num_partitions)   num_partitions  is the target number of partitions for the new XShards.   The method returns a new XShards that has exactly num_partitions partitions.",
            "title": "Repartition XShards"
        },
        {
            "location": "/Orca/data/#split-xshards",
            "text": "You can split one XShards into multiple XShards. Each element in the XShards needs be a list or tuple with same length.  split()  This method returns splits of XShards. If each element in the input SparkDataShard is not a list or tuple, return list of input SparkDataShards.",
            "title": "Split XShards"
        },
        {
            "location": "/Orca/data/#saveload-xshards",
            "text": "You can save XShards on Spark as SequenceFiles of serialized objects.\nThe serializer used is pyspark.serializers.PickleSerializer.  save_pickle(path, batchSize=10)   path  is target save path.  batchSize  batch size for each chunk in sequence file.   And you can load pickle file to XShards if you use save_pickle() to save data.  zoo.orca.data.XShards.load_pickle(path, minPartitions=None)   path : The pickle file path/directory.  minPartitions : The minimum partitions for the XShards.   This method return an XShards object from pickle files.",
            "title": "Save/Load XShards"
        },
        {
            "location": "/Orca/data/#move-xshards-on-spark-to-ray-backend",
            "text": "You can put data of the XShards on Spark to Ray cluster object store for later processing on Ray.  to_ray()  This method save data of XShards on Spark to Ray object store, and return a new RayXShards which contains plasma ObjectID, the plasma object_store_address and the node IP on each partition.",
            "title": "Move XShards on Spark to Ray backend"
        },
        {
            "location": "/Orca/data/#xshards-with-pandas-dataframe",
            "text": "",
            "title": "XShards with Pandas DataFrame"
        },
        {
            "location": "/Orca/data/#read-data-into-xshards",
            "text": "You can read csv/json files/directory into XShards with such APIs:  zoo.orca.data.pandas.read_csv(file_path, **kwargs)\n\nzoo.orca.data.pandas.read_json(file_path, **kwargs)   The  file_path  could be a csv/json file, list of multiple csv/json file paths, a directory containing csv/json files. Supported file systems are local file system, hdfs , and  s3 .  **kwargs  is read_csv/read_json options supported by pandas.  You can use  OrcaContext.pandas_read_backend = \"pandas\"  to switch to pandas backend. Reference:  Orca Context   After calling these APIs, you would get a XShards of Pandas DataFrame on Spark.  For Cloudera YARN client mode users: \nIf you use  pandas  as pandas_read_backend, you should configure  ARROW_LIBHDFS_DIR  before calling read_csv:\n1. use  locate libhdfs.so  to find libhdfs.so\n2.  export ARROW_LIBHDFS_DIR=/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib64  (replace with the result of  locate libhdfs.so )\n3. use  --conf \"spark.executorEnv.ARROW_LIBHDFS_DIR=/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib64\"  to export the environment variable to all executors.",
            "title": "Read data into XShards"
        },
        {
            "location": "/Orca/data/#partition-by-pandas-dataframe-columns",
            "text": "You can re-partition XShards of Pandas DataFrame with specified columns.  partition_by(cols, num_partitions=None)   cols : DataFrame columns to partition by.  num_partitions : target number of partitions. If not specified, the new XShards would keep the current partition number.   This method return a new XShards partitioned using the specified columns.",
            "title": "Partition by Pandas DataFrame columns"
        },
        {
            "location": "/Orca/data/#get-unique-element-list-of-xshards-of-pandas-series",
            "text": "You can get a unique list of elements of this XShards. This is useful when you want to count/get unique set of some column in the XShards of Pandas DataFrame.   unique()  This method return a unique list of elements of the XShards of Pandas Series.",
            "title": "Get unique element list of XShards of Pandas Series"
        },
        {
            "location": "/Orca/data/#xshards-with-numpy",
            "text": "",
            "title": "XShards with Numpy"
        },
        {
            "location": "/Orca/data/#load-local-numpy-data-to-xshards",
            "text": "You can partition local in memory data and form an XShards on Spark.  zoo.orca.data.XShards.partition(data)   data : The local data can be numpy.ndarray, a tuple, list, dict of numpy.ndarray, or a nested structure made of tuple, list, dict with ndarray as the leaf value.   This method returns a XShards which dispatch local data in parallel on Spark.",
            "title": "Load local numpy data to XShards"
        },
        {
            "location": "/Orca/orca-tf-quickstart/",
            "text": "In this guide we will describe how to scale out TensorFlow (v1.15) programs using Orca in 4 simple steps.\n\n\nStep 0: Prepare Environment\n\n\nWe recommend using \nConda\n to prepare the environment. Please refer to the \ninstall guide\n for more details.\n\n\nNote:\n Conda environment is required to run on the distributed cluster, but not strictly necessary for running on the local machine.\n\n\nconda create -n zoo python=3.7 # \"zoo\" is conda environment name, you can use any name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION} # install either version 0.9 or latest nightly build\npip install tensorflow==1.15.0\npip install tensorflow-datasets==2.0\npip install psutil\n\n\n\n\nNote:\n The original \nsource code\n for the tutorial below only supports TensorFlow 1.15.\n\n\nStep 1: Init Orca Context\n\n\nif args.cluster_mode == \"local\":  \n    init_orca_context(cluster_mode=\"local\", cores=4)# run in local mode\nelif args.cluster_mode == \"yarn\":  \n    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\nelif args.cluster_mode == \"yarn\":  \n    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2) # run on Hadoop YARN cluster\n\n\n\n\nThis is the only place where you need to specify local or distributed mode. View \nOrca Context\n for more details.\n\n\nStep 2: Define the Model\n\n\nYou may define your model, loss and metrics in the same way as in any standard (single node) TensorFlow program.\n\n\nimport tensorflow as tf\n\ndef accuracy(logits, labels):\n    predictions = tf.argmax(logits, axis=1, output_type=labels.dtype)\n    is_correct = tf.cast(tf.equal(predictions, labels), dtype=tf.float32)\n    return tf.reduce_mean(is_correct)\n\ndef lenet(images):\n    with tf.variable_scope('LeNet', [images]):\n        net = tf.layers.conv2d(images, 32, (5, 5), activation=tf.nn.relu, name='conv1')\n        net = tf.layers.max_pooling2d(net, (2, 2), 2, name='pool1')\n        net = tf.layers.conv2d(net, 64, (5, 5), activation=tf.nn.relu, name='conv2')\n        net = tf.layers.max_pooling2d(net, (2, 2), 2, name='pool2')\n        net = tf.layers.flatten(net)\n        net = tf.layers.dense(net, 1024, activation=tf.nn.relu, name='fc3')\n        logits = tf.layers.dense(net, 10)\n        return logits\n\n# tensorflow inputs\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28, 1))\n# tensorflow labels\nlabels = tf.placeholder(dtype=tf.int32, shape=(None,))\n\nlogits = lenet(images)\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\nacc = accuracy(logits, labels)\n\n\n\n\nStep 3: Define Train Dataset\n\n\nYou can define the dataset using standard \ntf.data.Dataset\n. Orca also supports \nSpark DataFrame\n and \nOrca XShards\n.\n\n\nimport tensorflow_datasets as tfds\n\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    return data['image'], data['label']\n\n# get DataSet\nmnist_train = tfds.load(name=\"mnist\", split=\"train\", data_dir=dataset_dir)\nmnist_test = tfds.load(name=\"mnist\", split=\"test\", data_dir=dataset_dir)\n\nmnist_train = mnist_train.map(preprocess)\nmnist_test = mnist_test.map(preprocess)\n\n\n\n\nStep 4: Fit with Orca Estimator\n\n\nFirst, create an Estimator.\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nest = Estimator.from_graph(inputs=images,\n                           outputs=logits,\n                           labels=labels,\n                           loss=loss,\n                           optimizer=tf.train.AdamOptimizer(),\n                           metrics={\"acc\": acc})\n\n\n\n\nNext, fit and evaluate using the Estimator.\n\n\nest.fit(data=train_dataset,\n        batch_size=320,\n        epochs=5,\n        validation_data=mnist_test)\n\nresult = est.evaluate(mnist_test)\nprint(result)\n\n\n\n\nThat's it, the same code can run seamlessly in your local laptop and the distribute K8s or Hadoop cluster.\n\n\nNote:\n You should call \nstop_orca_context()\n when your program finishes.",
            "title": "TensorFlow Quickstart"
        },
        {
            "location": "/Orca/orca-tf-quickstart/#step-0-prepare-environment",
            "text": "We recommend using  Conda  to prepare the environment. Please refer to the  install guide  for more details.  Note:  Conda environment is required to run on the distributed cluster, but not strictly necessary for running on the local machine.  conda create -n zoo python=3.7 # \"zoo\" is conda environment name, you can use any name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION} # install either version 0.9 or latest nightly build\npip install tensorflow==1.15.0\npip install tensorflow-datasets==2.0\npip install psutil  Note:  The original  source code  for the tutorial below only supports TensorFlow 1.15.",
            "title": "Step 0: Prepare Environment"
        },
        {
            "location": "/Orca/orca-tf-quickstart/#step-1-init-orca-context",
            "text": "if args.cluster_mode == \"local\":  \n    init_orca_context(cluster_mode=\"local\", cores=4)# run in local mode\nelif args.cluster_mode == \"yarn\":  \n    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\nelif args.cluster_mode == \"yarn\":  \n    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2) # run on Hadoop YARN cluster  This is the only place where you need to specify local or distributed mode. View  Orca Context  for more details.",
            "title": "Step 1: Init Orca Context"
        },
        {
            "location": "/Orca/orca-tf-quickstart/#step-2-define-the-model",
            "text": "You may define your model, loss and metrics in the same way as in any standard (single node) TensorFlow program.  import tensorflow as tf\n\ndef accuracy(logits, labels):\n    predictions = tf.argmax(logits, axis=1, output_type=labels.dtype)\n    is_correct = tf.cast(tf.equal(predictions, labels), dtype=tf.float32)\n    return tf.reduce_mean(is_correct)\n\ndef lenet(images):\n    with tf.variable_scope('LeNet', [images]):\n        net = tf.layers.conv2d(images, 32, (5, 5), activation=tf.nn.relu, name='conv1')\n        net = tf.layers.max_pooling2d(net, (2, 2), 2, name='pool1')\n        net = tf.layers.conv2d(net, 64, (5, 5), activation=tf.nn.relu, name='conv2')\n        net = tf.layers.max_pooling2d(net, (2, 2), 2, name='pool2')\n        net = tf.layers.flatten(net)\n        net = tf.layers.dense(net, 1024, activation=tf.nn.relu, name='fc3')\n        logits = tf.layers.dense(net, 10)\n        return logits\n\n# tensorflow inputs\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28, 1))\n# tensorflow labels\nlabels = tf.placeholder(dtype=tf.int32, shape=(None,))\n\nlogits = lenet(images)\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\nacc = accuracy(logits, labels)",
            "title": "Step 2: Define the Model"
        },
        {
            "location": "/Orca/orca-tf-quickstart/#step-3-define-train-dataset",
            "text": "You can define the dataset using standard  tf.data.Dataset . Orca also supports  Spark DataFrame  and  Orca XShards .  import tensorflow_datasets as tfds\n\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    return data['image'], data['label']\n\n# get DataSet\nmnist_train = tfds.load(name=\"mnist\", split=\"train\", data_dir=dataset_dir)\nmnist_test = tfds.load(name=\"mnist\", split=\"test\", data_dir=dataset_dir)\n\nmnist_train = mnist_train.map(preprocess)\nmnist_test = mnist_test.map(preprocess)",
            "title": "Step 3: Define Train Dataset"
        },
        {
            "location": "/Orca/orca-tf-quickstart/#step-4-fit-with-orca-estimator",
            "text": "First, create an Estimator.  from zoo.orca.learn.tf.estimator import Estimator\n\nest = Estimator.from_graph(inputs=images,\n                           outputs=logits,\n                           labels=labels,\n                           loss=loss,\n                           optimizer=tf.train.AdamOptimizer(),\n                           metrics={\"acc\": acc})  Next, fit and evaluate using the Estimator.  est.fit(data=train_dataset,\n        batch_size=320,\n        epochs=5,\n        validation_data=mnist_test)\n\nresult = est.evaluate(mnist_test)\nprint(result)  That's it, the same code can run seamlessly in your local laptop and the distribute K8s or Hadoop cluster.  Note:  You should call  stop_orca_context()  when your program finishes.",
            "title": "Step 4: Fit with Orca Estimator"
        },
        {
            "location": "/Orca/orca-keras-quickstart/",
            "text": "In this guide we will describe how to scale out Keras (v2.3) programs using Orca in 4 simple steps.\n\n\nStep 0: Prepare Environment\n\n\nWe recommend using \nConda\n to prepare the environment. Please refer to the \ninstall guide\n for more details.\n\n\nNote:\n Conda environment is required to run on the distributed cluster, but not strictly necessary for running on the local machine.\n\n\nconda create -n zoo python=3.7 # \"zoo\" is conda environment name, you can use any name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION} # install either version 0.9 or latest nightly build\npip install tensorflow==1.15.0\npip install tensorflow-datasets==2.0\npip install psutil\npip install pandas\npip install scikit-learn\n\n\n\n\nNote:\n The original \nsource code\n for the tutorial below only supports TensorFlow 1.15.\n\n\nStep 1: Init Orca Context\n\n\nif args.cluster_mode == \"local\":\n    init_orca_context(cluster_mode=\"local\", cores=4)# run in local mode\nelif args.cluster_mode == \"yarn\":\n    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\nelif args.cluster_mode == \"yarn\":\n    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2, driver_memory=\"6g\") # run on Hadoop YARN cluster\n\n\n\n\nThis is the only place where you need to specify local or distributed mode. View \nOrca Context\n for more details.\n\n\nStep 2: Define the Model\n\n\nYou may define your model, loss and metrics in the same way as in any standard (single node) Keras program.\n\n\nfrom tensorflow import keras\n\nmodel = keras.Sequential(\n    [keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                         input_shape=(28, 28, 1), padding='valid'),\n     keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n     keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                         padding='valid'),\n     keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n     keras.layers.Flatten(),\n     keras.layers.Dense(500, activation='tanh'),\n     keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n\n\nStep 3: Define Train Dataset\n\n\nYou can define the dataset using standard \ntf.data.Dataset\n. Orca also supports \nSpark DataFrame\n and \nOrca XShards\n.\n\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    return data['image'], data['label']\n\n# get DataSet\nmnist_train = tfds.load(name=\"mnist\", split=\"train\", data_dir=dataset_dir)\nmnist_test = tfds.load(name=\"mnist\", split=\"test\", data_dir=dataset_dir)\n\nmnist_train = mnist_train.map(preprocess)\nmnist_test = mnist_test.map(preprocess)\n\n\n\n\nStep 4: Fit with Orca Estimator\n\n\nFirst, create an Estimator.\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nest = Estimator.from_keras(keras_model=model)\n\n\n\n\nNext, fit and evaluate using the Estimator.\n\n\nest.fit(data=mnist_train,\n        batch_size=320,\n        epochs=5,\n        validation_data=mnist_test)\n\nresult = est.evaluate(mnist_test)\nprint(result)\n\n\n\n\nThat's it, the same code can run seamlessly in your local laptop and the distribute K8s or Hadoop cluster.\n\n\nNote:\n You should call \nstop_orca_context()\n when your program finishes.",
            "title": "TensorFlow Keras Quickstart"
        },
        {
            "location": "/Orca/orca-keras-quickstart/#step-0-prepare-environment",
            "text": "We recommend using  Conda  to prepare the environment. Please refer to the  install guide  for more details.  Note:  Conda environment is required to run on the distributed cluster, but not strictly necessary for running on the local machine.  conda create -n zoo python=3.7 # \"zoo\" is conda environment name, you can use any name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION} # install either version 0.9 or latest nightly build\npip install tensorflow==1.15.0\npip install tensorflow-datasets==2.0\npip install psutil\npip install pandas\npip install scikit-learn  Note:  The original  source code  for the tutorial below only supports TensorFlow 1.15.",
            "title": "Step 0: Prepare Environment"
        },
        {
            "location": "/Orca/orca-keras-quickstart/#step-1-init-orca-context",
            "text": "if args.cluster_mode == \"local\":\n    init_orca_context(cluster_mode=\"local\", cores=4)# run in local mode\nelif args.cluster_mode == \"yarn\":\n    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2) # run on K8s cluster\nelif args.cluster_mode == \"yarn\":\n    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2, driver_memory=\"6g\") # run on Hadoop YARN cluster  This is the only place where you need to specify local or distributed mode. View  Orca Context  for more details.",
            "title": "Step 1: Init Orca Context"
        },
        {
            "location": "/Orca/orca-keras-quickstart/#step-2-define-the-model",
            "text": "You may define your model, loss and metrics in the same way as in any standard (single node) Keras program.  from tensorflow import keras\n\nmodel = keras.Sequential(\n    [keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                         input_shape=(28, 28, 1), padding='valid'),\n     keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n     keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                         padding='valid'),\n     keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n     keras.layers.Flatten(),\n     keras.layers.Dense(500, activation='tanh'),\n     keras.layers.Dense(10, activation='softmax'),\n     ]\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])",
            "title": "Step 2: Define the Model"
        },
        {
            "location": "/Orca/orca-keras-quickstart/#step-3-define-train-dataset",
            "text": "You can define the dataset using standard  tf.data.Dataset . Orca also supports  Spark DataFrame  and  Orca XShards .  import tensorflow as tf\nimport tensorflow_datasets as tfds\n\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    return data['image'], data['label']\n\n# get DataSet\nmnist_train = tfds.load(name=\"mnist\", split=\"train\", data_dir=dataset_dir)\nmnist_test = tfds.load(name=\"mnist\", split=\"test\", data_dir=dataset_dir)\n\nmnist_train = mnist_train.map(preprocess)\nmnist_test = mnist_test.map(preprocess)",
            "title": "Step 3: Define Train Dataset"
        },
        {
            "location": "/Orca/orca-keras-quickstart/#step-4-fit-with-orca-estimator",
            "text": "First, create an Estimator.  from zoo.orca.learn.tf.estimator import Estimator\n\nest = Estimator.from_keras(keras_model=model)  Next, fit and evaluate using the Estimator.  est.fit(data=mnist_train,\n        batch_size=320,\n        epochs=5,\n        validation_data=mnist_test)\n\nresult = est.evaluate(mnist_test)\nprint(result)  That's it, the same code can run seamlessly in your local laptop and the distribute K8s or Hadoop cluster.  Note:  You should call  stop_orca_context()  when your program finishes.",
            "title": "Step 4: Fit with Orca Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/",
            "text": "Introduction\n\n\nAnalytics Zoo Orca Tenorflow Estimator provides a set APIs for running TensorFlow model on Spark in a distributed fashion. \n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntensorflow==1.15.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\nTo run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found \nhere\n.\n\n\n\n\n\n\nOrca TF Estimator\n\n\nOrca TF Estimator is an estimator to do Tensorflow training/evaluation/prediction on Spark in a distributed fashion. \n\n\nIt can support various data types, like XShards, Spark DataFrame, tf.data.Dataset, numpy.ndarrays, etc. \n\n\nIt supports both native Tensorflow Graph model and Tensorflow Keras model in the unified APIs. \n\n\nFor native Tensorflow Graph model, you can reference our \ngraph model example\n.\n\n\nFor Tensorflow Keras model, you can reference our \nkeras model example\n.\n\n\nCreate Estimator with graph model\n\n\nYou can creating Orca TF Estimator with native Tensorflow graph model.\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nEstimator.from_graph(*, inputs, outputs=None, labels=None, loss=None, optimizer=None,\n           clip_norm=None, clip_value=None,\n           metrics=None, updates=None,\n           sess=None, model_dir=None, backend=\"bigdl\")\n\n\n\n\n\n\ninputs\n: input tensorflow tensors.\n\n\noutputs\n: output tensorflow tensors.\n\n\nlabels\n: label tensorflow tensors.\n\n\nloss\n: The loss tensor of the TensorFlow model, should be a scalar\n\n\noptimizer\n: tensorflow optimization method.\n\n\nclip_norm\n: float >= 0. Gradients will be clipped when their L2 norm exceeds this value.\n\n\nclip_value\n:  a float >= 0 or a tuple of two floats.\n\n\n\n\nIf \nclip_value\n is a float, gradients will be clipped when their absolute value exceeds this value.\n\n\nIf \nclip_value\n is a tuple of two floats, gradients will be clipped when their value less than \nclip_value[0]\n or larger than \nclip_value[1]\n.\n\n\n\n\nmetrics\n: dictionary of {metric_name: metric tensor}.\n\n\nsess\n: the current TensorFlow Session, if you want to used a pre-trained model, you should use the Session to load the pre-trained variables and pass it to estimator\n\n\nmodel_dir\n: location to save model checkpoint and summaries.\n\n\nbackend\n: backend for estimator. Now it only can be \"bigdl\".\n\n\n\n\nThis method returns an Estimator object.\n\n\nE.g. To create Orca TF Estimator with tf graph:\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nclass SimpleModel(object):\n    def __init__(self):\n        self.user = tf.placeholder(dtype=tf.int32, shape=(None,))\n        self.item = tf.placeholder(dtype=tf.int32, shape=(None,))\n        self.label = tf.placeholder(dtype=tf.int32, shape=(None,))\n\n        feat = tf.stack([self.user, self.item], axis=1)\n        self.logits = tf.layers.dense(tf.to_float(feat), 2)\n\n        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=self.logits,\n                                                                          labels=self.label))\n\nmodel = SimpleModel()\n\nest = Estimator.from_graph(\n            inputs=[model.user, model.item],\n            labels=[model.label],\n            outputs=[model.logits],\n            loss=model.loss,\n            optimizer=tf.train.AdamOptimizer(),\n            metrics={\"loss\": model.loss})\n\n\n\n\nTrain graph model with Estimator\n\n\nAfter an Estimator created, you can call estimator API to train Tensorflow graph model:\n\n\nfit(data,\n    epochs=1,\n    batch_size=32,\n    feature_cols=None,\n    labels_cols=None,\n    validation_data=None,\n    hard_code_batch_size=False,\n    session_config=None,\n    feed_dict=None,\n    checkpoint_trigger=None\n    )\n\n\n\n\n\n\ndata\n: train data. It can be XShards, Spark DataFrame, tf.data.Dataset.\n\n\n\n\nIf \ndata\n is XShards, each element needs to be {'x': a feature numpy array\n         or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of\n         label numpy arrays}\n\n\nIf \ndata\n is tf.data.Dataset, each element is a tuple of input tensors.\n\n\n\n\nepochs\n: number of epochs to train.\n\n\nbatch_size\n: total batch size for each iteration.\n\n\nfeature_cols\n: feature column names if train data is Spark DataFrame.\n\n\nlabels_cols\n: label column names if train data is Spark DataFrame.\n\n\nvalidation_data\n: validation data. Validation data type should be the same as train data.\n\n\nhard_code_batch_size\n: whether hard code batch size for training. Default is False.\n\n\nsession_config\n: tensorflow session configuration for training. Should be object of tf.ConfigProto\n\n\nfeed_dict\n: a dictionary. The key is TensorFlow tensor, usually a placeholder, the value of the dictionary is a tuple of two elements. \n\n\n\n\nThe first one of the tuple is the value to feed to the tensor in training phase and the second one is the value to feed to the tensor in validation phase.\n* \ncheckpoint_trigger\n: when to trigger checkpoint during training. Should be bigdl optimzer trigger, like EveryEpoch(), SeveralIteration(num_iterations),etc.\n\n\nExample of Train with Orca TF Estimator. \n\n\n\n\nTrain data is tf.data.DataSet. E.g.\n\n\n\n\ndataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100,)),\n                                              np.random.randint(0, 50, size=(100,)),\n                                              np.ones(shape=(100,), dtype=np.int32)))\nest.fit(data=dataset,\n        batch_size=8,\n        epochs=10,\n        validation_data=dataset)\n\n\n\n\n\n\nTrain data is Spark DataFrame. E.g.\n\n\n\n\nest.fit(data=df,\n        batch_size=8,\n        epochs=10,\n        feature_cols=['user', 'item'],\n        labels_cols=['label'],\n        validation_data=df)\n\n\n\n\n\n\nTrain data is \nXShards\n. E.g.\n\n\n\n\nfile_path = os.path.join(resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy(), df['item'].to_numpy()),\n        \"y\": df['label'].to_numpy()\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)\n\n\n\n\nCreate Estimator with Keras model\n\n\nYou can creating Orca TF Estimator with Tensorflow Keras model. The model must be compiled.\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nEstimator.from_keras(keras_model, metrics=None, model_dir=None, backend=\"bigdl\")\n\n\n\n\n\n\nkeras_model\n: the tensorflow.keras model, which must be compiled.\n\n\nmetrics\n: user specified metric.\n\n\nmodel_dir\n: location to save model checkpoint and summaries.\n\n\nbackend\n: backend for estimator. Now it only can be \"bigdl\".\n\n\n\n\nThis method returns an Estimator object.\n\n\nE.g. To create Orca TF Estimator with tf keras model:\n\n\nfrom zoo.orca.learn.tf.estimator import Estimator\n\nuser = tf.keras.layers.Input(shape=[1])\nitem = tf.keras.layers.Input(shape=[1])\n\nfeat = tf.keras.layers.concatenate([user, item], axis=1)\npredictions = tf.keras.layers.Dense(2, activation='softmax')(feat)\n\nmodel = tf.keras.models.Model(inputs=[user, item], outputs=predictions)\nmodel.compile(optimizer='rmsprop',\n              oss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nest = Estimator.from_keras(keras_model=model)              \n\n\n\n\nTrain Keras model with Estimator\n\n\nAfter an Estimator created, you can call estimator's API to train Tensorflow Keras model:\n\n\nfit(data,\n    epochs=1,\n    batch_size=32,\n    feature_cols=None,\n    labels_cols=None,\n    validation_data=None,\n    hard_code_batch_size=False,\n    session_config=None,\n    checkpoint_trigger=None\n    )\n\n\n\n\n\n\ndata\n: train data. It can be XShards, Spark DataFrame, tf.data.Dataset.\n\n\n\n\nIf \ndata\n is XShards, each element needs to be {'x': a feature numpy array\n         or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of\n         label numpy arrays}\n\n\nIf \ndata\n is tf.data.Dataset, each element is a tuple of input tensors.\n\n\n\n\nepochs\n: number of epochs to train.\n\n\nbatch_size\n: total batch size for each iteration.\n\n\nfeature_cols\n: feature column names if train data is Spark DataFrame.\n\n\nlabels_cols\n: label column names if train data is Spark DataFrame.\n\n\nvalidation_data\n: validation data. Validation data type should be the same as train data.\n\n\nhard_code_batch_size\n: whether hard code batch size for training. Default is False.\n\n\nsession_config\n: tensorflow session configuration for training. Should be object of tf.ConfigProto\n\n\n\n\ncheckpoint_trigger\n: when to trigger checkpoint during training. Should be bigdl optimzer trigger, like EveryEpoch(), SeveralIteration(num_iterations),etc.\n\n\n\n\n\n\nTrain data is tf.data.DataSet. E.g.\n\n\n\n\n\n\ndataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100,)),\n                                              np.random.randint(0, 50, size=(100,)),\n                                              np.ones(shape=(100,), dtype=np.int32)))\n\ndataset = dataset.map(lambda user, item, label: [(user, item), label])\n\nest.fit(data=dataset,\n        batch_size=8,\n        epochs=10,\n        validation_data=dataset)\n\n\n\n\n\n\nTrain data is Spark DataFrame. E.g.\n\n\n\n\nest.fit(data=df,\n        batch_size=8,\n        epochs=10,\n        feature_cols=['user', 'item'],\n        labels_cols=['label'],\n        validation_data=df)\n\n\n\n\n\n\nIf train data is XShards, e.g.\n\n\n\n\nfile_path = os.path.join(self.resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy().reshape([-1, 1]),\n              df['item'].to_numpy().reshape([-1, 1])),\n        \"y\": df['label'].to_numpy()\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)\n\n\n\n\n\nEvaluate with Estimator\n\n\nYou can call estimator's API to evaluate Tensorflow graph model or keras model.\n\n\nevaluate(data, batch_size=4,\n         feature_cols=None,\n         labels_cols=None,\n         hard_code_batch_size=False\n        )\n\n\n\n\n\n\ndata\n: evaluation data. It can be XShards, Spark DataFrame, tf.data.Dataset.\n\n\n\n\nIf \ndata\n is XShards, each element needs to be {'x': a feature numpy array or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of label numpy arrays}\n\n\nIf \ndata\n is tf.data.Dataset, each element is \n[feature tensor tuple, label tensor tuple]\n\n\n\n\nbatch_size\n: batch size per thread.\n\n\nfeature_cols\n: feature_cols: feature column names if train data is Spark DataFrame.\n\n\nlabels_cols\n: label column names if train data is Spark DataFrame.\n\n\nhard_code_batch_size\n: whether to hard code batch size for evaluation.\n\n\n\n\nThis method returns evaluation result as a dictionary in the format of {'metric name': metric value}\n\n\nPredict with Estimator\n\n\nYou can call estimator's such APIs to predict with trained model.\n\n\npredict(data, batch_size=4,\n        feature_cols=None,\n        hard_code_batch_size=False\n        ):\n\n\n\n\n\n\n\n\ndata\n: data to be predicted. It can be XShards, Spark DataFrame, or tf.data.Dataset.        \n\n\nIf \ndata\n is XShard, each element needs to be {'x': a feature numpy array\n     or a tuple of feature numpy arrays}.         \n\n\nIf \ndata\n is tf.data.Dataset, each element is feature tensor tuple.\n\n\n\n\n\n\nbatch_size\n: batch size per thread\n\n\n\n\nfeature_cols\n: list of feature column names if input data is Spark DataFrame.\n\n\nhard_code_batch_size\n: if require hard code batch size for prediction. The default value is False.\n\n\n\n\nThis method returns a predicted result.\n\n\n\n\nPredict data is tf.data.DataSet. The prediction result should be an XShards and each element is {'prediction': predicted numpy array or list of predicted numpy arrays}.\n\n\n\n\ndataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100, 1)),\n                                              np.random.randint(0, 50, size=(100, 1))))\npredictions = est.predict(dataset)\n\nprediction_shards = est.predict(data_shard)\npredictions = prediction_shards.collect()\n\nassert 'prediction' in predictions[0]\n\n\n\n\n\n\nPredict data is Spark DataFrame. The predict result is a DataFrame which includes original columns plus \nprediction\n column. The \nprediction\n column can be FloatType, VectorUDT or Array of VectorUDT depending on model outputs shape.\n\n\n\n\nprediction_df = est.predict(df, batch_size=4, feature_cols=['user', 'item'])\n\nassert 'prediction' in prediction_df.columns\n\n\n\n\n\n\nPredict data is XShards. The prediction result should be an XShards and each element is {'prediction': predicted numpy array or list of predicted numpy arrays}.\n\n\n\n\nfile_path = os.path.join(resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy(), df['item'].to_numpy())\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nprediction_shards = est.predict(data_shard)\npredictions = prediction_shards.collect()\n\nassert 'prediction' in predictions[0]\n\n\n\n\nCheckpointing and Resume Training\n\n\nDuring training, Orca TF Estimator would save Orca checkpoint every epoch. You can also specify \ncheckpoint_trigger\n in fit() to set checkpoint interval. The Orca checckpoints are saved in \nmodel_dir\n which is specified when you create estimator. You can load previous Orca checkpoint and resume train with it with such APIs:\n\n\nload_latest_orca_checkpoint(path)\n\n\n\n\n\n\npath: directory containing Orca checkpoint files.\n\n\n\n\nThis method load latest checkpoint under specified directory.\n\n\nE.g.\n\n\nest = Estimator.from_keras(keras_model=model, model_dir=model_dir)\nest.load_latest_orca_checkpoint(model_dir)\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard,\n        checkpoint_trigger=SeveralIteration(4))\n\n\n\n\nIf you want to load specified version of checkpoint, you can use:\n\n\nload_orca_checkpoint(path, version)\n\n\n\n\n\n\npath: checkpoint directory which contains model.\n and optimMethod-TFParkTraining.\n files.\n\n\nversion: checkpoint version, which is the suffix of model.* file, i.e., for modle.4 file, the version is 4.\n\n\n\n\nAfter loading checkpoint, you can resume training with fit(). \n\n\nTensorboard support\n\n\nDuring training and validation, Orca TF Estimator would save Tensorflow summary data under \nmodel_dir\n which is specified when you create estimator. This data can be visualized in TensorBoard, or you can use estimator's APIs to retrieve it. If you want to save train/validation summary data to different directory or you don't specify \nmodel_dir\n, you can set the logdir and app name with such API:\n\n\nset_tensorboard(log_dir, app_name)\n\n\n\n\n\n\nlog_dir\n: The base directory path to store training and validation logs.\n\n\napp_name\n: The name of the application.\n\n\n\n\nThis method sets summary information during the training process for visualization purposes. Saved summary can be viewed via TensorBoard. In order to take effect, it needs to be called before fit.\n\n\nTraining summary will be saved to 'log_dir/app_name/train' and validation summary (if any) will be saved to 'log_dir/app_name/validation'.\n\n\nE.g. Set tensorboard for the estimator:\n\n\nest = Estimator.from_keras(keras_model=model)\nlog_dir = os.path.join(temp, \"log\")\nest.set_tensorboard(log_dir, \"test\")\n\n\n\n\nNow, you can see the summary data in TensorBoard. Or else, you can get summary data with such APIs:\n\n\nget_train_summary(tag)\n\n\n\n\n\n\ntag\n: The string variable represents the scalar wanted. It can only be \"Loss\", \"LearningRate\", or \"Throughput\".\n\n\n\n\nThis method get the scalar from model train summary. Return list of summary data of [iteration_number, scalar_value, timestamp].\n\n\nE.g.\n\n\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)\n\nassert os.path.exists(os.path.join(log_dir, \"test/train\"))\nassert os.path.exists(os.path.join(log_dir, \"test/validation\"))\n\ntrain_loss = est.get_train_summary(\"Loss\")\n\n\n\n\nget_validation_summary(tag)\n\n\n\n\n\n\ntag\n: The string variable represents the scalar wanted.\n\n\n\n\nThis method gets the scalar from model validation summary. Return list of summary data of [iteration_number, scalar_value, timestamp]\n\n\nE.g.\n\n\nval_scores = est.get_validation_summary(\"Loss\")\n\n\n\n\nSave model\n\n\nAfter training, you can save model in the estimator:\n\n\nSave Tensorflow checkpoint\n\n\nsave_tf_checkpoint(path)\n\n\n\n\n\n\npath\n: tensorflow checkpoint path.\n\n\n\n\nIf you use tensorflow graph model in this estimator, this method would save tensorflow checkpoint.\n\n\nE.g.\n\n\ntemp = tempfile.mkdtemp()\nmodel_checkpoint = os.path.join(temp, 'test.ckpt')\nest.save_tf_checkpoint(model_checkpoint)\n\n\n\n\nSave TF Keras model\n\n\nsave_keras_model(path, overwrite=True)\n\n\n\n\n\n\npath\n: keras model save path.\n\n\noverwrite\n: Boolean. Whether to silently overwrite any existing file at the target location. Default: True.\n\n\n\n\nIf you use tensorflow keras model in this estimator, this method would save keras model in specified path.\n\n\nE.g.\n\n\ntemp = tempfile.mkdtemp()\nmodel_path = os.path.join(temp, 'test.h5')\nest.save_keras_model(model_path, overwrite=True)",
            "title": "TensorFlow Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#introduction",
            "text": "Analytics Zoo Orca Tenorflow Estimator provides a set APIs for running TensorFlow model on Spark in a distributed fashion.   Remarks :   You need to install  tensorflow==1.15.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .  To run on other systems, you need to manually compile the TensorFlow source code. Instructions can\n  be found  here .",
            "title": "Introduction"
        },
        {
            "location": "/Orca/orca-tf-estimator/#orca-tf-estimator",
            "text": "Orca TF Estimator is an estimator to do Tensorflow training/evaluation/prediction on Spark in a distributed fashion.   It can support various data types, like XShards, Spark DataFrame, tf.data.Dataset, numpy.ndarrays, etc.   It supports both native Tensorflow Graph model and Tensorflow Keras model in the unified APIs.   For native Tensorflow Graph model, you can reference our  graph model example .  For Tensorflow Keras model, you can reference our  keras model example .",
            "title": "Orca TF Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#create-estimator-with-graph-model",
            "text": "You can creating Orca TF Estimator with native Tensorflow graph model.  from zoo.orca.learn.tf.estimator import Estimator\n\nEstimator.from_graph(*, inputs, outputs=None, labels=None, loss=None, optimizer=None,\n           clip_norm=None, clip_value=None,\n           metrics=None, updates=None,\n           sess=None, model_dir=None, backend=\"bigdl\")   inputs : input tensorflow tensors.  outputs : output tensorflow tensors.  labels : label tensorflow tensors.  loss : The loss tensor of the TensorFlow model, should be a scalar  optimizer : tensorflow optimization method.  clip_norm : float >= 0. Gradients will be clipped when their L2 norm exceeds this value.  clip_value :  a float >= 0 or a tuple of two floats.   If  clip_value  is a float, gradients will be clipped when their absolute value exceeds this value.  If  clip_value  is a tuple of two floats, gradients will be clipped when their value less than  clip_value[0]  or larger than  clip_value[1] .   metrics : dictionary of {metric_name: metric tensor}.  sess : the current TensorFlow Session, if you want to used a pre-trained model, you should use the Session to load the pre-trained variables and pass it to estimator  model_dir : location to save model checkpoint and summaries.  backend : backend for estimator. Now it only can be \"bigdl\".   This method returns an Estimator object.  E.g. To create Orca TF Estimator with tf graph:  from zoo.orca.learn.tf.estimator import Estimator\n\nclass SimpleModel(object):\n    def __init__(self):\n        self.user = tf.placeholder(dtype=tf.int32, shape=(None,))\n        self.item = tf.placeholder(dtype=tf.int32, shape=(None,))\n        self.label = tf.placeholder(dtype=tf.int32, shape=(None,))\n\n        feat = tf.stack([self.user, self.item], axis=1)\n        self.logits = tf.layers.dense(tf.to_float(feat), 2)\n\n        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=self.logits,\n                                                                          labels=self.label))\n\nmodel = SimpleModel()\n\nest = Estimator.from_graph(\n            inputs=[model.user, model.item],\n            labels=[model.label],\n            outputs=[model.logits],\n            loss=model.loss,\n            optimizer=tf.train.AdamOptimizer(),\n            metrics={\"loss\": model.loss})",
            "title": "Create Estimator with graph model"
        },
        {
            "location": "/Orca/orca-tf-estimator/#train-graph-model-with-estimator",
            "text": "After an Estimator created, you can call estimator API to train Tensorflow graph model:  fit(data,\n    epochs=1,\n    batch_size=32,\n    feature_cols=None,\n    labels_cols=None,\n    validation_data=None,\n    hard_code_batch_size=False,\n    session_config=None,\n    feed_dict=None,\n    checkpoint_trigger=None\n    )   data : train data. It can be XShards, Spark DataFrame, tf.data.Dataset.   If  data  is XShards, each element needs to be {'x': a feature numpy array\n         or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of\n         label numpy arrays}  If  data  is tf.data.Dataset, each element is a tuple of input tensors.   epochs : number of epochs to train.  batch_size : total batch size for each iteration.  feature_cols : feature column names if train data is Spark DataFrame.  labels_cols : label column names if train data is Spark DataFrame.  validation_data : validation data. Validation data type should be the same as train data.  hard_code_batch_size : whether hard code batch size for training. Default is False.  session_config : tensorflow session configuration for training. Should be object of tf.ConfigProto  feed_dict : a dictionary. The key is TensorFlow tensor, usually a placeholder, the value of the dictionary is a tuple of two elements.    The first one of the tuple is the value to feed to the tensor in training phase and the second one is the value to feed to the tensor in validation phase.\n*  checkpoint_trigger : when to trigger checkpoint during training. Should be bigdl optimzer trigger, like EveryEpoch(), SeveralIteration(num_iterations),etc.  Example of Train with Orca TF Estimator.    Train data is tf.data.DataSet. E.g.   dataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100,)),\n                                              np.random.randint(0, 50, size=(100,)),\n                                              np.ones(shape=(100,), dtype=np.int32)))\nest.fit(data=dataset,\n        batch_size=8,\n        epochs=10,\n        validation_data=dataset)   Train data is Spark DataFrame. E.g.   est.fit(data=df,\n        batch_size=8,\n        epochs=10,\n        feature_cols=['user', 'item'],\n        labels_cols=['label'],\n        validation_data=df)   Train data is  XShards . E.g.   file_path = os.path.join(resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy(), df['item'].to_numpy()),\n        \"y\": df['label'].to_numpy()\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)",
            "title": "Train graph model with Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#create-estimator-with-keras-model",
            "text": "You can creating Orca TF Estimator with Tensorflow Keras model. The model must be compiled.  from zoo.orca.learn.tf.estimator import Estimator\n\nEstimator.from_keras(keras_model, metrics=None, model_dir=None, backend=\"bigdl\")   keras_model : the tensorflow.keras model, which must be compiled.  metrics : user specified metric.  model_dir : location to save model checkpoint and summaries.  backend : backend for estimator. Now it only can be \"bigdl\".   This method returns an Estimator object.  E.g. To create Orca TF Estimator with tf keras model:  from zoo.orca.learn.tf.estimator import Estimator\n\nuser = tf.keras.layers.Input(shape=[1])\nitem = tf.keras.layers.Input(shape=[1])\n\nfeat = tf.keras.layers.concatenate([user, item], axis=1)\npredictions = tf.keras.layers.Dense(2, activation='softmax')(feat)\n\nmodel = tf.keras.models.Model(inputs=[user, item], outputs=predictions)\nmodel.compile(optimizer='rmsprop',\n              oss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nest = Estimator.from_keras(keras_model=model)",
            "title": "Create Estimator with Keras model"
        },
        {
            "location": "/Orca/orca-tf-estimator/#train-keras-model-with-estimator",
            "text": "After an Estimator created, you can call estimator's API to train Tensorflow Keras model:  fit(data,\n    epochs=1,\n    batch_size=32,\n    feature_cols=None,\n    labels_cols=None,\n    validation_data=None,\n    hard_code_batch_size=False,\n    session_config=None,\n    checkpoint_trigger=None\n    )   data : train data. It can be XShards, Spark DataFrame, tf.data.Dataset.   If  data  is XShards, each element needs to be {'x': a feature numpy array\n         or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of\n         label numpy arrays}  If  data  is tf.data.Dataset, each element is a tuple of input tensors.   epochs : number of epochs to train.  batch_size : total batch size for each iteration.  feature_cols : feature column names if train data is Spark DataFrame.  labels_cols : label column names if train data is Spark DataFrame.  validation_data : validation data. Validation data type should be the same as train data.  hard_code_batch_size : whether hard code batch size for training. Default is False.  session_config : tensorflow session configuration for training. Should be object of tf.ConfigProto   checkpoint_trigger : when to trigger checkpoint during training. Should be bigdl optimzer trigger, like EveryEpoch(), SeveralIteration(num_iterations),etc.    Train data is tf.data.DataSet. E.g.    dataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100,)),\n                                              np.random.randint(0, 50, size=(100,)),\n                                              np.ones(shape=(100,), dtype=np.int32)))\n\ndataset = dataset.map(lambda user, item, label: [(user, item), label])\n\nest.fit(data=dataset,\n        batch_size=8,\n        epochs=10,\n        validation_data=dataset)   Train data is Spark DataFrame. E.g.   est.fit(data=df,\n        batch_size=8,\n        epochs=10,\n        feature_cols=['user', 'item'],\n        labels_cols=['label'],\n        validation_data=df)   If train data is XShards, e.g.   file_path = os.path.join(self.resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy().reshape([-1, 1]),\n              df['item'].to_numpy().reshape([-1, 1])),\n        \"y\": df['label'].to_numpy()\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)",
            "title": "Train Keras model with Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#evaluate-with-estimator",
            "text": "You can call estimator's API to evaluate Tensorflow graph model or keras model.  evaluate(data, batch_size=4,\n         feature_cols=None,\n         labels_cols=None,\n         hard_code_batch_size=False\n        )   data : evaluation data. It can be XShards, Spark DataFrame, tf.data.Dataset.   If  data  is XShards, each element needs to be {'x': a feature numpy array or a tuple of feature numpy arrays, 'y': a label numpy array or a tuple of label numpy arrays}  If  data  is tf.data.Dataset, each element is  [feature tensor tuple, label tensor tuple]   batch_size : batch size per thread.  feature_cols : feature_cols: feature column names if train data is Spark DataFrame.  labels_cols : label column names if train data is Spark DataFrame.  hard_code_batch_size : whether to hard code batch size for evaluation.   This method returns evaluation result as a dictionary in the format of {'metric name': metric value}",
            "title": "Evaluate with Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#predict-with-estimator",
            "text": "You can call estimator's such APIs to predict with trained model.  predict(data, batch_size=4,\n        feature_cols=None,\n        hard_code_batch_size=False\n        ):    data : data to be predicted. It can be XShards, Spark DataFrame, or tf.data.Dataset.          If  data  is XShard, each element needs to be {'x': a feature numpy array\n     or a tuple of feature numpy arrays}.           If  data  is tf.data.Dataset, each element is feature tensor tuple.    batch_size : batch size per thread   feature_cols : list of feature column names if input data is Spark DataFrame.  hard_code_batch_size : if require hard code batch size for prediction. The default value is False.   This method returns a predicted result.   Predict data is tf.data.DataSet. The prediction result should be an XShards and each element is {'prediction': predicted numpy array or list of predicted numpy arrays}.   dataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0, 200, size=(100, 1)),\n                                              np.random.randint(0, 50, size=(100, 1))))\npredictions = est.predict(dataset)\n\nprediction_shards = est.predict(data_shard)\npredictions = prediction_shards.collect()\n\nassert 'prediction' in predictions[0]   Predict data is Spark DataFrame. The predict result is a DataFrame which includes original columns plus  prediction  column. The  prediction  column can be FloatType, VectorUDT or Array of VectorUDT depending on model outputs shape.   prediction_df = est.predict(df, batch_size=4, feature_cols=['user', 'item'])\n\nassert 'prediction' in prediction_df.columns   Predict data is XShards. The prediction result should be an XShards and each element is {'prediction': predicted numpy array or list of predicted numpy arrays}.   file_path = os.path.join(resource_path, \"orca/learn/ncf.csv\")\ndata_shard = zoo.orca.data.pandas.read_csv(file_path)\n\ndef transform(df):\n    result = {\n        \"x\": (df['user'].to_numpy(), df['item'].to_numpy())\n    }\n    return result\n\ndata_shard = data_shard.transform_shard(transform)\n\nprediction_shards = est.predict(data_shard)\npredictions = prediction_shards.collect()\n\nassert 'prediction' in predictions[0]",
            "title": "Predict with Estimator"
        },
        {
            "location": "/Orca/orca-tf-estimator/#checkpointing-and-resume-training",
            "text": "During training, Orca TF Estimator would save Orca checkpoint every epoch. You can also specify  checkpoint_trigger  in fit() to set checkpoint interval. The Orca checckpoints are saved in  model_dir  which is specified when you create estimator. You can load previous Orca checkpoint and resume train with it with such APIs:  load_latest_orca_checkpoint(path)   path: directory containing Orca checkpoint files.   This method load latest checkpoint under specified directory.  E.g.  est = Estimator.from_keras(keras_model=model, model_dir=model_dir)\nest.load_latest_orca_checkpoint(model_dir)\nest.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard,\n        checkpoint_trigger=SeveralIteration(4))  If you want to load specified version of checkpoint, you can use:  load_orca_checkpoint(path, version)   path: checkpoint directory which contains model.  and optimMethod-TFParkTraining.  files.  version: checkpoint version, which is the suffix of model.* file, i.e., for modle.4 file, the version is 4.   After loading checkpoint, you can resume training with fit().",
            "title": "Checkpointing and Resume Training"
        },
        {
            "location": "/Orca/orca-tf-estimator/#tensorboard-support",
            "text": "During training and validation, Orca TF Estimator would save Tensorflow summary data under  model_dir  which is specified when you create estimator. This data can be visualized in TensorBoard, or you can use estimator's APIs to retrieve it. If you want to save train/validation summary data to different directory or you don't specify  model_dir , you can set the logdir and app name with such API:  set_tensorboard(log_dir, app_name)   log_dir : The base directory path to store training and validation logs.  app_name : The name of the application.   This method sets summary information during the training process for visualization purposes. Saved summary can be viewed via TensorBoard. In order to take effect, it needs to be called before fit.  Training summary will be saved to 'log_dir/app_name/train' and validation summary (if any) will be saved to 'log_dir/app_name/validation'.  E.g. Set tensorboard for the estimator:  est = Estimator.from_keras(keras_model=model)\nlog_dir = os.path.join(temp, \"log\")\nest.set_tensorboard(log_dir, \"test\")  Now, you can see the summary data in TensorBoard. Or else, you can get summary data with such APIs:  get_train_summary(tag)   tag : The string variable represents the scalar wanted. It can only be \"Loss\", \"LearningRate\", or \"Throughput\".   This method get the scalar from model train summary. Return list of summary data of [iteration_number, scalar_value, timestamp].  E.g.  est.fit(data=data_shard,\n        batch_size=8,\n        epochs=10,\n        validation_data=data_shard)\n\nassert os.path.exists(os.path.join(log_dir, \"test/train\"))\nassert os.path.exists(os.path.join(log_dir, \"test/validation\"))\n\ntrain_loss = est.get_train_summary(\"Loss\")  get_validation_summary(tag)   tag : The string variable represents the scalar wanted.   This method gets the scalar from model validation summary. Return list of summary data of [iteration_number, scalar_value, timestamp]  E.g.  val_scores = est.get_validation_summary(\"Loss\")",
            "title": "Tensorboard support"
        },
        {
            "location": "/Orca/orca-tf-estimator/#save-model",
            "text": "After training, you can save model in the estimator:",
            "title": "Save model"
        },
        {
            "location": "/Orca/orca-tf-estimator/#save-tensorflow-checkpoint",
            "text": "save_tf_checkpoint(path)   path : tensorflow checkpoint path.   If you use tensorflow graph model in this estimator, this method would save tensorflow checkpoint.  E.g.  temp = tempfile.mkdtemp()\nmodel_checkpoint = os.path.join(temp, 'test.ckpt')\nest.save_tf_checkpoint(model_checkpoint)",
            "title": "Save Tensorflow checkpoint"
        },
        {
            "location": "/Orca/orca-tf-estimator/#save-tf-keras-model",
            "text": "save_keras_model(path, overwrite=True)   path : keras model save path.  overwrite : Boolean. Whether to silently overwrite any existing file at the target location. Default: True.   If you use tensorflow keras model in this estimator, this method would save keras model in specified path.  E.g.  temp = tempfile.mkdtemp()\nmodel_path = os.path.join(temp, 'test.h5')\nest.save_keras_model(model_path, overwrite=True)",
            "title": "Save TF Keras model"
        },
        {
            "location": "/Orca/orca-pytorch-quickstart/",
            "text": "In this guide we\u2019ll show you how to organize your PyTorch code into Orca in 3 steps.\n\n\nScaling your Pytorch applications with Orca makes your code:\n\n\n\n\nWell-organized and flexible\n\n\nEasier to reproduce\n\n\nAble to perform distributed training without changing your model\n\n\n\n\nStep 0: Prepare Environment\n\n\nWe recommend you to use \nAnaconda\n to prepare the environments, especially if you want to run on a yarn cluster (yarn-client mode only).\n\n\nDownload and install latest analytics-zoo whl by the following instructions \nhere\n.  \n\n\nNote:\n Conda environment is required to run on Yarn, but not strictly necessary for running on local.\n\n\nconda create -n zoo python=3.7 # zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl \npip install jep==3.9.0\nconda install pytorch torchvision cpuonly -c pytorch # command for linux\nconda install pytorch torchvision -c pytorch # command for macOS\n\n\n\n\nStep 1: Init Orca Context\n\n\nfrom zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\nsc = init_orca_context(cores=1, memory=\"20g\")\n\n# run in yarn client mode\nsc = init_orca_context(\n    cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n    driver_memory=\"10g\", driver_cores=1,\n    conf={\"spark.rpc.message.maxSize\": \"1024\",\n        \"spark.task.maxFailures\": \"1\",\n        \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})\n\n\n\n\nNote:\n You should \nexport HADOOP_CONF_DIR=/path/to/hadoop/conf/dir\n. \n\n\nView \nOrca Context\n for more details.\n\n\nStep 2: Define PyTorch Model, Loss function and Optimizer\n\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom bigdl.optim.optimizer import Adam\n\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\nmodel = LeNet()\nmodel.train()\ncriterion = nn.NLLLoss()\nadam = Adam(1e-4)\n\n\n\n\nStep 3: Fit with Orca PyTorch Estimator\n\n\n1)  Define the data in whatever way you want. Orca just needs a \nPytorch DataLoader\n, a data creator function or \nOrca SparkXShards\n.\n\n\nimport torch\nfrom torchvision import datasets, transforms\n\ntorch.manual_seed(0)\ndir='./dataset'\nbatch_size=64\ntest_batch_size=64\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(dir, train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(dir, train=False,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=test_batch_size, shuffle=False) \n\n\n\n\n2)  Create an Estimator\n\n\nfrom zoo.orca.learn.pytorch import Estimator \n\nzoo_estimator = Estimator.from_torch(model=model, optimizer=adam, loss=criterion, backend=\"bigdl\") \n\n\n\n\n3)  Fit with Estimator\n\n\nfrom zoo.orca.learn.metrics import Accuracy\nfrom zoo.orca.learn.trigger import EveryEpoch \n\nzoo_estimator.fit(data=train_loader, epochs=10, validation_data=test_loader,\n                  validation_methods=[Accuracy()], checkpoint_trigger=EveryEpoch()) \n\n\n\n\nNote:\n You should call \nstop_orca_context()\n when your application finishes.",
            "title": "PyTorch Quickstart"
        },
        {
            "location": "/Orca/orca-pytorch-quickstart/#step-0-prepare-environment",
            "text": "We recommend you to use  Anaconda  to prepare the environments, especially if you want to run on a yarn cluster (yarn-client mode only).  Download and install latest analytics-zoo whl by the following instructions  here .    Note:  Conda environment is required to run on Yarn, but not strictly necessary for running on local.  conda create -n zoo python=3.7 # zoo is conda enviroment name, you can set another name you like.\nconda activate zoo\npip install analytics_zoo-${VERSION}-${TIMESTAMP}-py2.py3-none-${OS}_x86_64.whl \npip install jep==3.9.0\nconda install pytorch torchvision cpuonly -c pytorch # command for linux\nconda install pytorch torchvision -c pytorch # command for macOS",
            "title": "Step 0: Prepare Environment"
        },
        {
            "location": "/Orca/orca-pytorch-quickstart/#step-1-init-orca-context",
            "text": "from zoo.orca import init_orca_context, stop_orca_context\n\n# run in local mode\nsc = init_orca_context(cores=1, memory=\"20g\")\n\n# run in yarn client mode\nsc = init_orca_context(\n    cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n    driver_memory=\"10g\", driver_cores=1,\n    conf={\"spark.rpc.message.maxSize\": \"1024\",\n        \"spark.task.maxFailures\": \"1\",\n        \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})  Note:  You should  export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir .   View  Orca Context  for more details.",
            "title": "Step 1: Init Orca Context"
        },
        {
            "location": "/Orca/orca-pytorch-quickstart/#step-2-define-pytorch-model-loss-function-and-optimizer",
            "text": "import torch.nn as nn\nimport torch.nn.functional as F\nfrom bigdl.optim.optimizer import Adam\n\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\nmodel = LeNet()\nmodel.train()\ncriterion = nn.NLLLoss()\nadam = Adam(1e-4)",
            "title": "Step 2: Define PyTorch Model, Loss function and Optimizer"
        },
        {
            "location": "/Orca/orca-pytorch-quickstart/#step-3-fit-with-orca-pytorch-estimator",
            "text": "1)  Define the data in whatever way you want. Orca just needs a  Pytorch DataLoader , a data creator function or  Orca SparkXShards .  import torch\nfrom torchvision import datasets, transforms\n\ntorch.manual_seed(0)\ndir='./dataset'\nbatch_size=64\ntest_batch_size=64\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(dir, train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(dir, train=False,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=test_batch_size, shuffle=False)   2)  Create an Estimator  from zoo.orca.learn.pytorch import Estimator \n\nzoo_estimator = Estimator.from_torch(model=model, optimizer=adam, loss=criterion, backend=\"bigdl\")   3)  Fit with Estimator  from zoo.orca.learn.metrics import Accuracy\nfrom zoo.orca.learn.trigger import EveryEpoch \n\nzoo_estimator.fit(data=train_loader, epochs=10, validation_data=test_loader,\n                  validation_methods=[Accuracy()], checkpoint_trigger=EveryEpoch())   Note:  You should call  stop_orca_context()  when your application finishes.",
            "title": "Step 3: Fit with Orca PyTorch Estimator"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/",
            "text": "Introduction\n\n\nAnalytics Zoo Orca PyTorch Estimator provides a set APIs for running PyTorch model on Spark in a distributed fashion.\n\n\nRemarks\n:\n\n\n\n\nYou need to install \ntorch==1.5.0\n and \ntorchvision==0.6.0\n on your driver node.\n\n\nYour operating system (OS) is required to be one of the following 64-bit systems:\n\nUbuntu 16.04 or later\n and \nmacOS 10.12.6 or later\n.\n\n\n\n\n\n\nOrca PyTorch Estimator\n\n\nOrca PyTorch Estimator is an estimator to do PyTorch training/evaluation/prediction on Spark in a distributed fashion.\n\n\nIt can support various data types, like XShards, PyTorch DataLoader, PyTorch DataLoader creator, etc.\n\n\nIt supports horovod backend and BigDL backend in the unified APIs.\n\n\nCreate Estimator from pyTorch Model\n\n\nYou can create Orca PyTorch Estimator with native PyTorch model.\n\n\nfrom zoo.orca.learn.pytorch import Estimator\nEstimator.from_torch(*,\n                   model,\n                   optimizer,\n                   loss=None,\n                   scheduler_creator=None,\n                   training_operator_cls=TrainingOperator,\n                   initialization_hook=None,\n                   config=None,\n                   scheduler_step_freq=\"batch\",\n                   use_tqdm=False,\n                   workers_per_node=1,\n                   model_dir=None,\n                   backend=\"bigdl\"):\n\n\n\n\n\n\nmodel\n: PyTorch model if \nbackend=\"bigdl\"\n, PyTorch model creator if \nbackend=\"horovod\"\n\n\noptimizer\n: bigdl optimizer if \nbackend=\"bigdl\"\n, PyTorch optimizer creator if \nbackend=\"horovod\"\n\n\nloss\n: PyTorch loss if \nbackend=\"bigdl\"\n, PyTorch loss creator if \nbackend=\"horovod\"\n\n\nscheduler_creator\n: parameter for horovod. a learning rate scheduler wrapping the optimizer. You will need to set \nTorchTrainer(scheduler_step_freq=\"epoch\")\n for the scheduler to be incremented correctly. If using a scheduler for validation loss, be sure to call \ntrainer.update_scheduler(validation_loss)\n\n\ntraining_operator_cls\n: parameter for horovod. Custom training operator class that subclasses the TrainingOperator class. This class will be copied onto all remote workers and used to specify custom training and validation operations. Defaults to TrainingOperator.\n\n\ninitialization_hook\n: parameter for horovod.\n\n\nconfig\n: parameter for horovod. Config dict to create model, optimizer loss and data.\n\n\nscheduler_step_freq\n: parameter for horovod. \"batch\", \"epoch\", \"manual\", or None. This will determine when \nscheduler.step\n is called. If \"batch\", \nstep\n will be called after every optimizer step. If \"epoch\", \nstep\n will be called after one pass of the DataLoader. If \"manual\", the scheduler will not be incremented automatically - you are expected to call \ntrainer.update_schedulers\n manually. If a scheduler is passed in, this value is expected to not be None.\n\n\nuse_tqdm\n: parameter for horovod. You can monitor training progress if use_tqdm=True.\n\n\nworkers_per_node\n: parameter for horovod. worker number on each node. default: 1.\n\n\nmodel_dir\n: parameter for \nbigdl\n. The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.\n\n\nbackend\n: You can choose \"horovod\" or \"bigdl\" as backend. Default: bigdl.\n\n\n\n\nUse horovod Estimator\n\n\nTrain model\n\n\nAfter an Estimator is created, you can call estimator API to train PyTorch model:\n\n\nfit(self, data, epochs=1, profile=False, reduce_results=True, info=None)\n\n\n\n\n\n\ndata\n: (callable) a funtion that takes a config dict as input and return a data loader containing the training data.\n\n\nepochs\n: (int) Number of epochs to train the model\n\n\nprofile\n: (bool) Returns time stats for the training procedure.\n\n\nreduce_results\n: (bool) Whether to average all metrics across all workers into one dict. If a metric is a non-numerical value (or nested dictionaries), one value will be randomly selected among the workers. If False, returns a list of dicts.\n\n\ninfo\n: (dict) Optional dictionary passed to the training operator for \ntrain_epoch\n and \ntrain_batch\n.\n\n\n\n\nEvaluate model\n\n\nAfter Training, you can call estimator API to evaluate PyTorch model:\n\n\nevaluate(self, data, num_steps=None, profile=False, info=None)\n\n\n\n\n\n\ndata\n: (callable) a funtion that takes a config dict as input and return a data loader containing the validation data.\n\n\nnum_steps\n: (int) Number of batches to compute update steps on. This corresponds also to the number of times \nTrainingOperator.validate_batch\n is called.\n\n\nprofile\n: (bool) Returns time stats for the evaluation procedure.\n\n\ninfo\n: (dict) Optional dictionary passed to the training operator for \nvalidate\n and \nvalidate_batch\n.\n\n\n\n\nGet model\n\n\nYou can get the trained model using \nget_model(self)\n\n\nSave model\n\n\nYou can save model using \nsave(self, checkpoint)\n\n* \ncheckpoint\n: (str) Path to target checkpoint file.\n\n\nLoad model\n\n\nYou can load saved model using \nload(self, checkpoint)\n\n* \ncheckpoint\n: (str) Path to target checkpoint file.\n\n\nShutdown workers\n\n\nYou can shut down workers and releases resources using \nshutdown(self, force=False)\n\n\nUse BigDL Estimator\n\n\nTrain model\n\n\nAfter an Estimator is created, you can call estimator API to train PyTorch model:\n\n\nfit(self, data, epochs=1, batch_size=32, validation_data=None, validation_methods=None, checkpoint_trigger=None):\n\n\n\n\n\n\ndata\n: Training data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.\n\n\nepochs\n: Number of epochs to train the model.\n\n\nbatch_size\n: Batch size used for training. Only used when data is a SparkXShard.\n\n\nvalidation_data\n: Validation data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.\n\n\nvalidation_methods\n: BigDL validation methods.\n\n\ncheckpoint_trigger\n: BigDL Trigger to set a checkpoint.\n\n\n\n\nEvaluate model\n\n\nAfter Training, you can call estimator API to evaluate PyTorch model:\n\n\nevaluate(self, data, validation_methods=None, batch_size=32)\n\n\n\n\n\n\ndata\n: Validation data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.\n\n\nvalidation_methods\n: BigDL validation methods.\n\n\nbatch_size\n: Batch size used for evaluation. Only used when data is a SparkXShard.\n\n\n\n\nGet model\n\n\nYou can get model using \nget_model(self)\n\n\nLoad model\n\n\nYou can load saved model using \nload(self, checkpoint, loss=None)\n\n* \ncheckpoint\n: (str) Path to target checkpoint file.\n* \nloss\n: PyTorch loss function.\n\n\nClear gradient clipping\n\n\nYou can clear gradient clipping parameters using \nclear_gradient_clipping(self)\n. In this case, gradient clipping will not be applied.\n\nNote:\n In order to take effect, it needs to be called before fit.\n\n\nSet constant gradient clipping\n\n\nYou can Set constant gradient clipping during the training process using \nset_constant_gradient_clipping(self, min, max)\n.\n* \nmin\n: The minimum value to clip by.\n* \nmax\n: The maximum value to clip by.\n\nNote:\n In order to take effect, it needs to be called before fit.\n\n\nSet clip gradient to a maximum L2-Norm\n\n\nYou can set clip gradient to a maximum L2-Norm during the training process using \nset_l2_norm_gradient_clipping(self, clip_norm)\n.\n* \nclip_norm\n: Gradient L2-Norm threshold.\n\nNote:\n In order to take effect, it needs to be called before fit.",
            "title": "PyTorch Estimator"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#introduction",
            "text": "Analytics Zoo Orca PyTorch Estimator provides a set APIs for running PyTorch model on Spark in a distributed fashion.  Remarks :   You need to install  torch==1.5.0  and  torchvision==0.6.0  on your driver node.  Your operating system (OS) is required to be one of the following 64-bit systems: Ubuntu 16.04 or later  and  macOS 10.12.6 or later .",
            "title": "Introduction"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#orca-pytorch-estimator",
            "text": "Orca PyTorch Estimator is an estimator to do PyTorch training/evaluation/prediction on Spark in a distributed fashion.  It can support various data types, like XShards, PyTorch DataLoader, PyTorch DataLoader creator, etc.  It supports horovod backend and BigDL backend in the unified APIs.",
            "title": "Orca PyTorch Estimator"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#create-estimator-from-pytorch-model",
            "text": "You can create Orca PyTorch Estimator with native PyTorch model.  from zoo.orca.learn.pytorch import Estimator\nEstimator.from_torch(*,\n                   model,\n                   optimizer,\n                   loss=None,\n                   scheduler_creator=None,\n                   training_operator_cls=TrainingOperator,\n                   initialization_hook=None,\n                   config=None,\n                   scheduler_step_freq=\"batch\",\n                   use_tqdm=False,\n                   workers_per_node=1,\n                   model_dir=None,\n                   backend=\"bigdl\"):   model : PyTorch model if  backend=\"bigdl\" , PyTorch model creator if  backend=\"horovod\"  optimizer : bigdl optimizer if  backend=\"bigdl\" , PyTorch optimizer creator if  backend=\"horovod\"  loss : PyTorch loss if  backend=\"bigdl\" , PyTorch loss creator if  backend=\"horovod\"  scheduler_creator : parameter for horovod. a learning rate scheduler wrapping the optimizer. You will need to set  TorchTrainer(scheduler_step_freq=\"epoch\")  for the scheduler to be incremented correctly. If using a scheduler for validation loss, be sure to call  trainer.update_scheduler(validation_loss)  training_operator_cls : parameter for horovod. Custom training operator class that subclasses the TrainingOperator class. This class will be copied onto all remote workers and used to specify custom training and validation operations. Defaults to TrainingOperator.  initialization_hook : parameter for horovod.  config : parameter for horovod. Config dict to create model, optimizer loss and data.  scheduler_step_freq : parameter for horovod. \"batch\", \"epoch\", \"manual\", or None. This will determine when  scheduler.step  is called. If \"batch\",  step  will be called after every optimizer step. If \"epoch\",  step  will be called after one pass of the DataLoader. If \"manual\", the scheduler will not be incremented automatically - you are expected to call  trainer.update_schedulers  manually. If a scheduler is passed in, this value is expected to not be None.  use_tqdm : parameter for horovod. You can monitor training progress if use_tqdm=True.  workers_per_node : parameter for horovod. worker number on each node. default: 1.  model_dir : parameter for  bigdl . The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.  backend : You can choose \"horovod\" or \"bigdl\" as backend. Default: bigdl.",
            "title": "Create Estimator from pyTorch Model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#use-horovod-estimator",
            "text": "",
            "title": "Use horovod Estimator"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#train-model",
            "text": "After an Estimator is created, you can call estimator API to train PyTorch model:  fit(self, data, epochs=1, profile=False, reduce_results=True, info=None)   data : (callable) a funtion that takes a config dict as input and return a data loader containing the training data.  epochs : (int) Number of epochs to train the model  profile : (bool) Returns time stats for the training procedure.  reduce_results : (bool) Whether to average all metrics across all workers into one dict. If a metric is a non-numerical value (or nested dictionaries), one value will be randomly selected among the workers. If False, returns a list of dicts.  info : (dict) Optional dictionary passed to the training operator for  train_epoch  and  train_batch .",
            "title": "Train model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#evaluate-model",
            "text": "After Training, you can call estimator API to evaluate PyTorch model:  evaluate(self, data, num_steps=None, profile=False, info=None)   data : (callable) a funtion that takes a config dict as input and return a data loader containing the validation data.  num_steps : (int) Number of batches to compute update steps on. This corresponds also to the number of times  TrainingOperator.validate_batch  is called.  profile : (bool) Returns time stats for the evaluation procedure.  info : (dict) Optional dictionary passed to the training operator for  validate  and  validate_batch .",
            "title": "Evaluate model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#get-model",
            "text": "You can get the trained model using  get_model(self)",
            "title": "Get model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#save-model",
            "text": "You can save model using  save(self, checkpoint) \n*  checkpoint : (str) Path to target checkpoint file.",
            "title": "Save model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#load-model",
            "text": "You can load saved model using  load(self, checkpoint) \n*  checkpoint : (str) Path to target checkpoint file.",
            "title": "Load model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#shutdown-workers",
            "text": "You can shut down workers and releases resources using  shutdown(self, force=False)",
            "title": "Shutdown workers"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#use-bigdl-estimator",
            "text": "",
            "title": "Use BigDL Estimator"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#train-model_1",
            "text": "After an Estimator is created, you can call estimator API to train PyTorch model:  fit(self, data, epochs=1, batch_size=32, validation_data=None, validation_methods=None, checkpoint_trigger=None):   data : Training data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.  epochs : Number of epochs to train the model.  batch_size : Batch size used for training. Only used when data is a SparkXShard.  validation_data : Validation data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.  validation_methods : BigDL validation methods.  checkpoint_trigger : BigDL Trigger to set a checkpoint.",
            "title": "Train model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#evaluate-model_1",
            "text": "After Training, you can call estimator API to evaluate PyTorch model:  evaluate(self, data, validation_methods=None, batch_size=32)   data : Validation data. SparkXShard, PyTorch DataLoader and PyTorch DataLoader creator are supported.  validation_methods : BigDL validation methods.  batch_size : Batch size used for evaluation. Only used when data is a SparkXShard.",
            "title": "Evaluate model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#get-model_1",
            "text": "You can get model using  get_model(self)",
            "title": "Get model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#load-model_1",
            "text": "You can load saved model using  load(self, checkpoint, loss=None) \n*  checkpoint : (str) Path to target checkpoint file.\n*  loss : PyTorch loss function.",
            "title": "Load model"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#clear-gradient-clipping",
            "text": "You can clear gradient clipping parameters using  clear_gradient_clipping(self) . In this case, gradient clipping will not be applied. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Clear gradient clipping"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#set-constant-gradient-clipping",
            "text": "You can Set constant gradient clipping during the training process using  set_constant_gradient_clipping(self, min, max) .\n*  min : The minimum value to clip by.\n*  max : The maximum value to clip by. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Set constant gradient clipping"
        },
        {
            "location": "/Orca/orca-pytorch-estimator/#set-clip-gradient-to-a-maximum-l2-norm",
            "text": "You can set clip gradient to a maximum L2-Norm during the training process using  set_l2_norm_gradient_clipping(self, clip_norm) .\n*  clip_norm : Gradient L2-Norm threshold. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Set clip gradient to a maximum L2-Norm"
        },
        {
            "location": "/Orca/orca-openvino-estimator/",
            "text": "Introduction\n\n\nAnalytics Zoo Orca OpenVINO Estimator provides a set APIs for running OpenVINO model on Spark in a distributed fashion.\n\n\n\n\nOrca OpenVINO Estimator\n\n\nOrca OpenVINO Estimator is an estimator to do OpenVINO prediction on Spark in a distributed fashion.\n\n\nIt can support various data types, like XShards, ndarray, list of ndarray, etc.\n\n\nCreate Estimator from OpenVINO Model\n\n\nYou can create Orca OpenVINO Estimator with OpenVINO IR xml file and bin file.\n\n\nfrom zoo.orca.learn.openvino.estimator import Estimator\n\nEstimator.from_openvino(*, model_path, batch_size=0)\n\n\n\n\n\n\nmodel_path\n: (string) The file path to the OpenVINO IR xml file. Please put the OpenVINO IR bin file in the same folder with the xml file.\n\n\nbatch_size\n: (int) Set batch Size, default is 0 (use default batch size).\n\n\n\n\nInference with Orca OpenVINO Estimator\n\n\nAfter an Estimator is created, you can call estimator API to predict data:\n\n\npredict(self, data)\n\n\n\n\n\n\ndata\n:  Inference data. Ndarray, list of ndarrays and SparkXShards are supported.\n\n\n\n\nLoad OpenVINO model\n\n\nYou can load an OpenVINO model using \nload(self, model_path, batch_size=0)\n\n\n\n\nmodel_path\n: (string) The file path to the OpenVINO IR xml file. Please put the OpenVINO IR bin file in the same folder with the xml file.\n\n\nbatch_size\n: (int) Set batch Size, default is 0 (use default batch size).",
            "title": "OpenVINO Estimator"
        },
        {
            "location": "/Orca/orca-openvino-estimator/#introduction",
            "text": "Analytics Zoo Orca OpenVINO Estimator provides a set APIs for running OpenVINO model on Spark in a distributed fashion.",
            "title": "Introduction"
        },
        {
            "location": "/Orca/orca-openvino-estimator/#orca-openvino-estimator",
            "text": "Orca OpenVINO Estimator is an estimator to do OpenVINO prediction on Spark in a distributed fashion.  It can support various data types, like XShards, ndarray, list of ndarray, etc.",
            "title": "Orca OpenVINO Estimator"
        },
        {
            "location": "/Orca/orca-openvino-estimator/#create-estimator-from-openvino-model",
            "text": "You can create Orca OpenVINO Estimator with OpenVINO IR xml file and bin file.  from zoo.orca.learn.openvino.estimator import Estimator\n\nEstimator.from_openvino(*, model_path, batch_size=0)   model_path : (string) The file path to the OpenVINO IR xml file. Please put the OpenVINO IR bin file in the same folder with the xml file.  batch_size : (int) Set batch Size, default is 0 (use default batch size).",
            "title": "Create Estimator from OpenVINO Model"
        },
        {
            "location": "/Orca/orca-openvino-estimator/#inference-with-orca-openvino-estimator",
            "text": "After an Estimator is created, you can call estimator API to predict data:  predict(self, data)   data :  Inference data. Ndarray, list of ndarrays and SparkXShards are supported.",
            "title": "Inference with Orca OpenVINO Estimator"
        },
        {
            "location": "/Orca/orca-openvino-estimator/#load-openvino-model",
            "text": "You can load an OpenVINO model using  load(self, model_path, batch_size=0)   model_path : (string) The file path to the OpenVINO IR xml file. Please put the OpenVINO IR bin file in the same folder with the xml file.  batch_size : (int) Set batch Size, default is 0 (use default batch size).",
            "title": "Load OpenVINO model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/",
            "text": "Introduction\n\n\nAnalytics Zoo Orca BigDL Estimator provides a set APIs for running BigDL model on Spark in a distributed fashion.\n\n\n\n\nOrca BigDL Estimator\n\n\nOrca BigDL Estimator is an estimator to do BigDL training/evaluation/prediction on Spark in a distributed fashion.\n\n\nIt can support various data types, like XShards, Spark DataFrame, etc.\n\n\nIt supports BigDL backend in the unified APIs.\n\n\nCreate Estimator from BigDL Model\n\n\nYou can create Orca BigDL Estimator with BigDL model.\n\n\nfrom zoo.orca.learn.bigdl import Estimator\nEstimator.from_bigdl(*, model, loss=None, optimizer=None, feature_preprocessing=None,\n                   label_preprocessing=None, model_dir=None)\n\n\n\n\n\n\nmodel\n: BigDL Model to be trained.\n\n\noptimizer\n: BigDL optimizer.\n\n\nloss\n: BigDL criterion.\n\n\nfeature_preprocessing\n: Used if the input data in fit function is Spark DataFrame.The param converts the data in feature column to a Tensor or to a Sample directly. It expects a List of Int as the size of the converted Tensor, or a Preprocessing[F, Tensor[T]]\n    If a List of Int is set as feature_preprocessing, it can only handle the case that feature column contains the following data types: Float, Double, Int, Array[Float], Array[Double], Array[Int] and MLlib Vector. The feature data are converted to Tensors with the specified sizes before sending to the model. Internally, a SeqToTensor is generated according to the size, and used as the feature_preprocessing.\n    Alternatively, user can set feature_preprocessing as Preprocessing[F, Tensor[T]] that transforms the feature data to a Tensor[T]. Some pre-defined Preprocessing are provided in package zoo.feature. Multiple Preprocessing can be combined as a ChainedPreprocessing.\n    The feature_preprocessing will also be copied to the generated NNModel and applied to feature column during transform.\n\n\nlabel_preprocessing\n: Similar to feature_preprocessing, but applies to Label data.\n\n\nmodel_dir\n: The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.\n\n\n\n\nTrain BigDL model with orca BigDL Estimator\n\n\nAfter an Estimator is created, you can call estimator API to train BigDL model:\n\n\nfit(self, data, epochs, feature_cols=\"features\", labels_cols=\"label\", batch_size=32,\n    caching_sample=True, val_data=None, val_trigger=None, val_methods=None,\n    checkpoint_trigger=None)\n\n\n\n\n\n\ndata\n: Training data. SparkXShard and Spark DataFrame are supported.\n\n\nepochs\n: (int) Number of epochs to train the model.\n\n\nfeature_cols\n: (string or list of string) Feature column name(s) of data. Only used when data is a Spark DataFrame. Default: \"features\".\n\n\nlabels_cols\n: (string or list of string) Label column name(s) of data. Only used when data is a Spark DataFrame. Default: \"label\".\n\n\nbatch_size\n: (int) Batch size used for training. Default: 32.\n\n\ncaching_sample\n: (Boolean) Whether to cache the Samples after preprocessing. Default: True.\n\n\nval_data\n: Validation data. SparkXShard and Spark DataFrame are supported. Default: None.\n\n\nval_trigger\n: BigDL Trigger to validate model.\n\n\nval_methods\n: BigDL validation methods.\n\n\ncheckpoint_trigger\n: BigDL Trigger to set a checkpoint.\n\n\n\n\nInference with orca BigDL Estimator\n\n\nAfter training or loading trained model, you can call estimator API to inference:\n\n\npredict(self, data, batch_size=8, feature_cols=\"features\", sample_preprocessing=None)\n\n\n\n\n\n\ndata\n: Inference data. SparkXShard and Spark DataFrame are supported.\n\n\nbatch_size\n: (int) Batch size used for inference. Default: 8.\n\n\nfeature_cols\n:  (string or list of string) Feature column name(s) of data. Only used when data is a Spark DataFrame.\n\n\nsample_preprocessing\n: Used if the input data in predict function is Spark DataFrame. The user defined sample_preprocessing will directly compose Sample according to user-specified Preprocessing.\n\n\n\n\nEvaluate model\n\n\nAfter Training, you can call estimator API to evaluate BigDL model:\n\n\nevaluate(self, data, validation_methods=None, batch_size=32)\n\n\n\n\n\n\ndata\n: Validation data. SparkXShard and Spark DataFrame are supported.\n\n\nvalidation_methods\n: BigDL validation methods.\n\n\nbatch_size\n: Batch size used for evaluation. Only used when data is a SparkXShard.\n\n\n\n\nGet model\n\n\nYou can get model using \nget_model(self)\n\n\nSave model\n\n\nYou can save model using \nsave(self, model_path)\n\n* \ncheckpoint\n: (str) Path to model saved folder.\n\n\nLoad model\n\n\nYou can load saved model using\n\n\nload(self, checkpoint, optimizer=None, loss=None, feature_preprocessing=None,\n             label_preprocessing=None, model_dir=None, is_checkpoint=False):\n\n\n\n\n\n\ncheckpoint\n: (str) Path to target checkpoint file or saved model folder.\n\n\noptimizer\n: BigDL optimizer.\n\n\nloss\n: BigDL criterion.\n\n\nfeature_preprocessing\n: Used if the input data in fit function is Spark DataFrame.The param converts the data in feature column to a Tensor or to a Sample directly. It expects a List of Int as the size of the converted Tensor, or a Preprocessing[F, Tensor[T]]\n    If a List of Int is set as feature_preprocessing, it can only handle the case that feature column contains the following data types: Float, Double, Int, Array[Float], Array[Double], Array[Int] and MLlib Vector. The feature data are converted to Tensors with the specified sizes before sending to the model. Internally, a SeqToTensor is generated according to the size, and used as the feature_preprocessing.\n    Alternatively, user can set feature_preprocessing as Preprocessing[F, Tensor[T]] that transforms the feature data to a Tensor[T]. Some pre-defined Preprocessing are provided in package zoo.feature. Multiple Preprocessing can be combined as a ChainedPreprocessing.\n    The feature_preprocessing will also be copied to the generated NNModel and applied to feature column during transform.\n\n\nlabel_preprocessing\n: Similar to feature_preprocessing, but applies to Label data.\n\n\nmodel_dir\n: The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.\n\n\nis_checkpoint\n: (boolean) Whether load BigDL saved model or checkpoint.\n\n\n\n\nSet TensorBoard & get Training and Validation Summary\n\n\nDuring training and validation, Orca BigDL Estimator would save summary data to specified log_dir. This data can be visualized in TensorBoard, or you can use estimator's APIs to retrieve it. You can set the logdir and app name with such API:\n\n\nset_tensorboard(log_dir, app_name)\n\n\n\n\n\n\nlog_dir\n: The base directory path to store training and validation logs.\n\n\napp_name\n: The name of the application.\n\n\n\n\nThis method sets summary information during the training process for visualization purposes. Saved summary can be viewed via TensorBoard. In order to take effect, it needs to be called before fit.\n\n\nTraining summary will be saved to 'log_dir/app_name/train' and validation summary (if any) will be saved to 'log_dir/app_name/validation'.\n\n\nYou can get Training summary with \nget_train_summary(self, tag=None)\n and Validation summary with \nget_validation_summary(self, tag=None)\n.\n\n\nClear gradient clipping\n\n\nYou can clear gradient clipping parameters using \nclear_gradient_clipping(self)\n. In this case, gradient clipping will not be applied.\n\nNote:\n In order to take effect, it needs to be called before fit.\n\n\nSet constant gradient clipping\n\n\nYou can Set constant gradient clipping during the training process using \nset_constant_gradient_clipping(self, min, max)\n.\n* \nmin\n: The minimum value to clip by.\n* \nmax\n: The maximum value to clip by.\n\nNote:\n In order to take effect, it needs to be called before fit.\n\n\nSet clip gradient to a maximum L2-Norm\n\n\nYou can set clip gradient to a maximum L2-Norm during the training process using \nset_l2_norm_gradient_clipping(self, clip_norm)\n.\n* \nclip_norm\n: Gradient L2-Norm threshold.\n\nNote:\n In order to take effect, it needs to be called before fit.",
            "title": "BigDL Estimator"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#introduction",
            "text": "Analytics Zoo Orca BigDL Estimator provides a set APIs for running BigDL model on Spark in a distributed fashion.",
            "title": "Introduction"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#orca-bigdl-estimator",
            "text": "Orca BigDL Estimator is an estimator to do BigDL training/evaluation/prediction on Spark in a distributed fashion.  It can support various data types, like XShards, Spark DataFrame, etc.  It supports BigDL backend in the unified APIs.",
            "title": "Orca BigDL Estimator"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#create-estimator-from-bigdl-model",
            "text": "You can create Orca BigDL Estimator with BigDL model.  from zoo.orca.learn.bigdl import Estimator\nEstimator.from_bigdl(*, model, loss=None, optimizer=None, feature_preprocessing=None,\n                   label_preprocessing=None, model_dir=None)   model : BigDL Model to be trained.  optimizer : BigDL optimizer.  loss : BigDL criterion.  feature_preprocessing : Used if the input data in fit function is Spark DataFrame.The param converts the data in feature column to a Tensor or to a Sample directly. It expects a List of Int as the size of the converted Tensor, or a Preprocessing[F, Tensor[T]]\n    If a List of Int is set as feature_preprocessing, it can only handle the case that feature column contains the following data types: Float, Double, Int, Array[Float], Array[Double], Array[Int] and MLlib Vector. The feature data are converted to Tensors with the specified sizes before sending to the model. Internally, a SeqToTensor is generated according to the size, and used as the feature_preprocessing.\n    Alternatively, user can set feature_preprocessing as Preprocessing[F, Tensor[T]] that transforms the feature data to a Tensor[T]. Some pre-defined Preprocessing are provided in package zoo.feature. Multiple Preprocessing can be combined as a ChainedPreprocessing.\n    The feature_preprocessing will also be copied to the generated NNModel and applied to feature column during transform.  label_preprocessing : Similar to feature_preprocessing, but applies to Label data.  model_dir : The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.",
            "title": "Create Estimator from BigDL Model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#train-bigdl-model-with-orca-bigdl-estimator",
            "text": "After an Estimator is created, you can call estimator API to train BigDL model:  fit(self, data, epochs, feature_cols=\"features\", labels_cols=\"label\", batch_size=32,\n    caching_sample=True, val_data=None, val_trigger=None, val_methods=None,\n    checkpoint_trigger=None)   data : Training data. SparkXShard and Spark DataFrame are supported.  epochs : (int) Number of epochs to train the model.  feature_cols : (string or list of string) Feature column name(s) of data. Only used when data is a Spark DataFrame. Default: \"features\".  labels_cols : (string or list of string) Label column name(s) of data. Only used when data is a Spark DataFrame. Default: \"label\".  batch_size : (int) Batch size used for training. Default: 32.  caching_sample : (Boolean) Whether to cache the Samples after preprocessing. Default: True.  val_data : Validation data. SparkXShard and Spark DataFrame are supported. Default: None.  val_trigger : BigDL Trigger to validate model.  val_methods : BigDL validation methods.  checkpoint_trigger : BigDL Trigger to set a checkpoint.",
            "title": "Train BigDL model with orca BigDL Estimator"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#inference-with-orca-bigdl-estimator",
            "text": "After training or loading trained model, you can call estimator API to inference:  predict(self, data, batch_size=8, feature_cols=\"features\", sample_preprocessing=None)   data : Inference data. SparkXShard and Spark DataFrame are supported.  batch_size : (int) Batch size used for inference. Default: 8.  feature_cols :  (string or list of string) Feature column name(s) of data. Only used when data is a Spark DataFrame.  sample_preprocessing : Used if the input data in predict function is Spark DataFrame. The user defined sample_preprocessing will directly compose Sample according to user-specified Preprocessing.",
            "title": "Inference with orca BigDL Estimator"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#evaluate-model",
            "text": "After Training, you can call estimator API to evaluate BigDL model:  evaluate(self, data, validation_methods=None, batch_size=32)   data : Validation data. SparkXShard and Spark DataFrame are supported.  validation_methods : BigDL validation methods.  batch_size : Batch size used for evaluation. Only used when data is a SparkXShard.",
            "title": "Evaluate model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#get-model",
            "text": "You can get model using  get_model(self)",
            "title": "Get model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#save-model",
            "text": "You can save model using  save(self, model_path) \n*  checkpoint : (str) Path to model saved folder.",
            "title": "Save model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#load-model",
            "text": "You can load saved model using  load(self, checkpoint, optimizer=None, loss=None, feature_preprocessing=None,\n             label_preprocessing=None, model_dir=None, is_checkpoint=False):   checkpoint : (str) Path to target checkpoint file or saved model folder.  optimizer : BigDL optimizer.  loss : BigDL criterion.  feature_preprocessing : Used if the input data in fit function is Spark DataFrame.The param converts the data in feature column to a Tensor or to a Sample directly. It expects a List of Int as the size of the converted Tensor, or a Preprocessing[F, Tensor[T]]\n    If a List of Int is set as feature_preprocessing, it can only handle the case that feature column contains the following data types: Float, Double, Int, Array[Float], Array[Double], Array[Int] and MLlib Vector. The feature data are converted to Tensors with the specified sizes before sending to the model. Internally, a SeqToTensor is generated according to the size, and used as the feature_preprocessing.\n    Alternatively, user can set feature_preprocessing as Preprocessing[F, Tensor[T]] that transforms the feature data to a Tensor[T]. Some pre-defined Preprocessing are provided in package zoo.feature. Multiple Preprocessing can be combined as a ChainedPreprocessing.\n    The feature_preprocessing will also be copied to the generated NNModel and applied to feature column during transform.  label_preprocessing : Similar to feature_preprocessing, but applies to Label data.  model_dir : The path to save model. During the training, if checkpoint_trigger is defined and triggered, the model will be saved to model_dir.  is_checkpoint : (boolean) Whether load BigDL saved model or checkpoint.",
            "title": "Load model"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#set-tensorboard-get-training-and-validation-summary",
            "text": "During training and validation, Orca BigDL Estimator would save summary data to specified log_dir. This data can be visualized in TensorBoard, or you can use estimator's APIs to retrieve it. You can set the logdir and app name with such API:  set_tensorboard(log_dir, app_name)   log_dir : The base directory path to store training and validation logs.  app_name : The name of the application.   This method sets summary information during the training process for visualization purposes. Saved summary can be viewed via TensorBoard. In order to take effect, it needs to be called before fit.  Training summary will be saved to 'log_dir/app_name/train' and validation summary (if any) will be saved to 'log_dir/app_name/validation'.  You can get Training summary with  get_train_summary(self, tag=None)  and Validation summary with  get_validation_summary(self, tag=None) .",
            "title": "Set TensorBoard &amp; get Training and Validation Summary"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#clear-gradient-clipping",
            "text": "You can clear gradient clipping parameters using  clear_gradient_clipping(self) . In this case, gradient clipping will not be applied. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Clear gradient clipping"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#set-constant-gradient-clipping",
            "text": "You can Set constant gradient clipping during the training process using  set_constant_gradient_clipping(self, min, max) .\n*  min : The minimum value to clip by.\n*  max : The maximum value to clip by. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Set constant gradient clipping"
        },
        {
            "location": "/Orca/orca-bigdl-estimator/#set-clip-gradient-to-a-maximum-l2-norm",
            "text": "You can set clip gradient to a maximum L2-Norm during the training process using  set_l2_norm_gradient_clipping(self, clip_norm) .\n*  clip_norm : Gradient L2-Norm threshold. Note:  In order to take effect, it needs to be called before fit.",
            "title": "Set clip gradient to a maximum L2-Norm"
        },
        {
            "location": "/powered-by/",
            "text": "Alibaba\n\n  \nDeploy Analytics Zoo in Aliyun EMR\n\n\nBaosight\n\n  \nLSTM-Based Time Series Anomaly Detection Using Analytics Zoo for Apache Spark and BigDL at Baosight\n\n\nBurger King\n\n  \nContext-Aware Fast Food Recommendation at Burger King with RayOnSpark\n\n\nCERN\n\n \nDeep Learning Pipelines for High Energy Physics using Apache Spark with Distributed Keras on Analytics Zoo\n\n \nTopology classification at CERN's Large Hadron Collider using Analytics Zoo\n\n \nDeep Learning on Apache Spark at CERN's Large Hadron Collider with Intel Technologies\n\n\nChina Telecom\n\n \nFace Recognition Application and Practice Based on Intel Analytics Zoo: Part 1\n (in Chinese)\n \nFace Recognition Application and Practice Based on Intel Analytics Zoo: Part 2\n (in Chinese)\n\n\nCray\n \n\nA deep learning approach for precipitation nowcasting with RNN using Analytics Zoo in Cray\n\n\nDell EMC\n\n\nBuild AI on PowerEdge with Domino Data Labs, Apache Spark and Analytics Zoo\n\n\nAI-assisted Radiology Using Distributed Deep\nLearning on Apache Spark and Analytics Zoo\n\n\nUsing Deep Learning on Apache Spark to Diagnose Thoracic Pathology from Chest X-rays\n\n\nGOLDWIND SE\n\n\nIntel big data analysis + AI platform helps GOLDWIND SE to build a new energy intelligent power prediction solution\n\n\nJD\n\n\nObject Detection and Image Feature Extraction at JD.com\n\n\nMasterCard\n\n\n \nDeep Learning with Analytic Zoo Optimizes Mastercard Recommender AI Service\n\n\nMicrosoft Azure\n\n\nUse Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 1\n\n\nUse Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 2\n\n\nMidea\n\n\nIndustrial Inspection Platform in Midea and KUKA: Using Distributed TensorFlow on Analytics Zoo\n \n\nAbility to add \"eyes\" and \"brains\" to smart manufacturing\n (in Chinese)\n\n\nMLSListings\n\n\nImage Similarity-Based House Recommendations and Search\n\n\nNeuSoft/BMW\n\n\nNeusoft RealSight APM partners with Intel to create an application performance management platform with active defense capabilities\n (in Chinese)\n\n\nNeuSoft/Mazda\n\n\nJD, Neusoft and Intel Jointly Building Intelligent and Connected Vehicle Cloud for HaiMa(former Hainan Mazda)\n\n\nJD, Neusoft and Intel Jointly Building Intelligent and Connected Vehicle Cloud for Hainan-Mazda\n (in Chinese)\n\n\nOffice Depot\n\n\nReal-time Product Recommendations for Office Depot Using Apache Spark and Analytics Zoo on AWS\n\n\nOffice Depot product recommender using Analytics Zoo on AWS\n\n\nSK Telecom\n\n\nSK Telecom, Intel Build AI Pipeline to Improve Network Quality\n\n\nVectorized Deep Learning Acceleration from Preprocessing to Inference and Training on Apache Spark in SK Telecom\n\n\nApache Spark AI Use Case in Telco: Network Quality Analysis and Prediction with Geospatial Visualization\n\n\nTalroo\n\n\nUses Analytics Zoo and AWS to Leverage Deep Learning for Job Recommendations\n\n\nJob recommendations leveraging deep learning using Analytics Zoo on Apache Spark and BigDL\n\n\nTelefonica\n\n \nRunning Analytics Zoo jobs on Telef\u00f3nica Open Cloud\u2019s MRS Service\n\n\nTencent\n\n\nAnalytics Zoo helps Tencent Cloud improve the performance of its intelligent titanium machine learning platform\n\n\nTencent\n Cloud Leverages Analytics Zoo to Improve Performance of TI-ONE\n ML Platform\n\n\nEnhance Tencent's TUSI Identity Practice with Intel Analytics Zoo\n (in Chinese)\n\n\nUC Berkeley RISELab\n\n\nRayOnSpark: Running Emerging AI Applications on Big Data Clusters with Ray and Analytics Zoo\n\n\nScalable AutoML for Time Series Prediction Using Ray and Analytics Zoo\n\n\nWorld Bank\n\n\nUsing Crowdsourced Images to Create Image Recognition Models with Analytics Zoo using BigDL\n\n\nYunda\n\n\nIntelligent transformation brings \"quality change\" to the express delivery industry\n (in Chinese)",
            "title": "Powered by"
        },
        {
            "location": "/presentations/",
            "text": "Tutorial:\n\n\n\n\nAnalytics Zoo: Distributed TensorFlow and Keras on Apache Spark, \nAI conference\n, Sep 2019, San Jose (\nslides\n)\n\n\n\n\nTalks:\n\n\n\n\n\n\nContext-aware Fast Food Recommendation with Ray on Apache Spark at Burger King, \nData + AI Summit Europe 2020\n, November 2020, (\nslides\n)\n\n\n\n\n\n\nCluster Serving: Distributed Model Inference using Apache Flink in Analytics Zoo, \nFlink Forward 2020\n, October 2020, (\nslides\n)\n\n\n\n\n\n\nProject Zouwu: Scalable AutoML for Telco Time Series Analysis using Ray and Analytics Zoo, \nRay Summit Connect 2020\n, August 2020, (\nslides\n)\n\n\n\n\n\n\nCluster Serving: Distributed Model Inference using Big Data Streaming in Analytics Zoo, \nOpML 2020\n, July 2020, (\nslides\n)\n\n\n\n\n\n\nScalable AutoML for Time Series Forecasting using Ray, \nOpML 2020\n, July 2020, (\nslides\n)\n\n\n\n\n\n\nScalable AutoML for Time Series Forecasting using Ray, \nSpark + AI Summit 2020\n, June 2020, (\nslides\n)\n\n\n\n\n\n\nRunning Emerging AI Applications on Big Data Platforms with Ray On Apache Spark, \nSpark + AI Summit 2020\n, June 2020, (\nslides\n)\n\n\n\n\n\n\nVectorized Deep Learning Acceleration from Preprocessing to Inference and Training on Apache Spark in SK Telecom, \nSpark + AI Summit 2020\n, June 2020, (\nslides\n)\n\n\n\n\n\n\nArchitecture and practice of big data analysis and deep learning model inference using Analytics Zoo on Flink, \nFlink Forward Asia 2019\n, Nov 2019, Beijing (\nslides\n)\n\n\n\n\n\n\nData analysis + AI platform technology and case studies, \nAICon BJ 2019\n, Nov 2019, Beijing (\nslides\n)\n\n\n\n\n\n\nArchitectural practices for building a unified big data AI application with Analytics-Zoo, \nQCon SH 2019\n, Oct 2019, Shanghai (\nslides\n)\n\n\n\n\n\n\nBuilding AI to play the FIFA video game using distributed TensorFlow, \nTensorFlow World\n, Oct 2019, Santa Clara (\nslides\n)\n\n\n\n\n\n\nDeep Learning Pipelines for High Energy Physics using Apache Spark with Distributed Keras on Analytics Zoo, \nSpark+AI Summit\n, Oct 2019, Amsterdam (\nslides\n)\n\n\n\n\n\n\nApache Spark AI Use Case in Telco: Network Quality Analysis and Prediction with Geospatial Visualization, \nSpark+AI Summit\n, Oct 2019, Amsterdam (\nslides\n)\n\n\n\n\n\n\nLSTM-based time series anomaly detection using Analytics Zoo for Spark and BigDL, \nStrata Data conference\n, May 2019, London (\nslides\n)\n\n\n\n\n\n\nGame Playing Using AI on Apache Spark, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing Deep Learning on Apache Spark to Diagnose Thoracic Pathology from Chest X-rays in DELL EMC, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nLeveraging NLP and Deep Learning for Document Recommendation in the Cloud, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nAnalytics Zoo: Distributed Tensorflow, Keras and BigDL in production on Apache Spark, \nStrata Data conference\n, March 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nUser-based real-time product recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Office Depot, \nStrata Data conference\n, March 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nAnalytics Zoo: Unifying Big Data Analytics and AI for Apache Spark, \nShanghai Apache Spark + AI meetup\n, Nov 2018, Shanghai (\nslides\n)\n\n\n\n\n\n\nUse Intel Analytics Zoo to build an intelligent QA Bot for Microsoft Azure, \nShanghai Apache Spark + AI meetup\n, Nov 2018, Shanghai (\nslides\n)\n\n\n\n\n\n\nA deep learning approach for precipitation nowcasting with RNN using Analytics Zoo in Cray, \nStrata Data conference\n, Sep 2018, New York (\nslides\n)\n\n\n\n\n\n\nJob recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Talroo, \nStrata Data conference\n, Sep 2018, New York (\nslides\n)\n\n\n\n\n\n\nAccelerating Deep Learning Training with BigDL and Drizzle on Apache Spark, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing Crowdsourced Images to Create Image Recognition Models with Analytics Zoo in World Bank, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nBuilding Deep Reinforcement Learning Applications on Apache Spark with Analytics Zoo using BigDL, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing BigDL on Apache Spark to Improve the MLS Real Estate Search Experience at Scale, \nSpark + AI Summit\n, June 2018, San Francisco\n\n\n\n\n\n\nAnalytics Zoo: Building Analytics and AI Pipeline for Apache Spark and BigDL, \nSpark + AI Summit\n, June 2018, San Francisco\n\n\n\n\n\n\nUsing Siamese CNNs for removing duplicate entries from real estate listing databases, \nStrata Data conference\n, May 2018, London (\nslides\n)\n\n\n\n\n\n\nClassifying images on Spark in World Bank, \nAI conference\n, May 2018, New York (\nslides\n)\n\n\n\n\n\n\nImproving user-merchant propensity modeling using neural collaborative filtering and wide and deep models on Spark BigDL in Mastercard, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)\n\n\n\n\n\n\nAccelerating deep learning on Apache Spark using BigDL with coarse-grained scheduling, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)\n\n\n\n\n\n\nAutomatic 3D MRI knee damage classification with 3D CNN using BigDL on Spark in UCSF, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)",
            "title": "Presentations"
        },
        {
            "location": "/meetup/",
            "text": "Webinar:\n\n\n\n\nAI Monitoring of Network Health using Analytics Zoo in SK Telecom, March 26 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\nMeetup:\n\n\n\n\n\n\nPrivacy Preserving Machine Learning with Analytics Zoo and Intel SGX, \nShanghai Spark+AI Online Meetup\n, August 21 2020 (\nVideo\n, \nSlide1\n, \nSlide2\n)\n\n\n\n\n\n\nTFPark: Distributed TensorFlow in Production on Apache Spark, \nShanghai Spark+AI Online Meetup\n, July 23 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nRunning Emerging AI Applications on Big Data Platforms with Ray On Apache Spark, \nShanghai Spark+AI Online Meetup\n, July 10 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nCluster Serving Introduction and Use Cases, \nShanghai Spark+AI Online Meetup\n, June 12 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nBigDL: A Distributed Deep Learning Framework for Big Data, \nShanghai Spark+AI Online Meetup\n, May 29 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nBuilding AI to play the FIFA video game using distributed TensorFlow On Analytics Zoo, \nShanghai Spark+AI Online Meetup\n, May 14 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nUsing Analytics-Zoo to Realize AI Diagnosis and Treatment of Thoracic Diseases Based on Deep Learning, \nShanghai Spark+AI Online Meetup\n, April 29 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nUltra Fast Deep Learning in Hybrid Cloud Using Intel Analytics Zoo & Alluxio, \nALLUXIO GLOBAL ONLINE MEETUP\n, April 23 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nWhat\u2019s on-going in Spark + AI Community - views from a contributor & practitioner, \nShanghai Spark+AI Online Meetup\n, April 17 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nDistributed and Real time Deep Learning Model Inference with Analytics Zoo in Apache Flink, \nShanghai Spark+AI Online Meetup\n, April 03 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nProduct recommendations leveraging deep learning using Analytics Zoo in Office Depot, \nShanghai Spark+AI Online Meetup\n, March 26 2020 (\nVideo\n, \nSlide\n)\n\n\n\n\n\n\nAutomated Time Series Analysis using Deep Learning, Ray and Analytics Zoo, \nShanghai Spark+AI Online Meetup\n, March 13 2020 (\nVideo\n, \nSlide\n)",
            "title": "Meetup & Webinar"
        },
        {
            "location": "/known-issues/",
            "text": "If you encounter the following exception when calling the Python API of Analytics Zoo using Python 3.5 or 3.6:\n\n\n\n\nPy4JJavaError: An error occurred while calling z:org.apache.spark.bigdl.api.python.BigDLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\n\n\n\nyou may need to check whether your input argument involves Numpy types (such as \nnumpy.int64\n). See \nhere\n for the related issue.\n\n\nFor example, invoking \nnp.min\n, \nnp.max\n, \nnp.unique\n, etc. will return type \nnumpy.int64\n. One way to solve this is to use \nint()\n to convert a number of type \nnumpy.int64\n to a Python int.\n\n\n\n\nIf you use two StringIndexs to convert String feature to index using Spark 2.4, it will be very slow in the next \ndataframe.rdd.map\n opteration. 6,000,000 records cost 12 hours, and 1/3 of the time is GC.  \n\n\n\n\nFor example\uff0cone of our customer change \nNCF recommender\n's preprocessing to match their data:\n\n\ndf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"xxx.csv\") # The header is user, item, label. The type is string, string, int.\nuser_indexer = StringIndexer(inputCol='user',outputCol='user_index',handleInvalid=\"skip\")\nitem_indexer = StringIndexer(inputCol='item',outputCol='item_index',handleInvalid=\"skip\")\npipe = Pipeline(stages=[user_indexer, item_indexer])\npipe_fit = pip.fit(df)\ndf = pipe_fit.transform(df)\ntrain_data = df.select('user_index','item_index','label')\n\n\n\n\nThen they use a map to transform this \ntrain_data\n to RDD[Sample]:\n\n\ndef build_sample(user_id, item_id, rating):\n    sample = Sample.from_ndarray(np.array([user_id, item_id]), np.array([rating]))\n    return UserItemFeature(user_id, item_id, sample)\npairFeatureRdds = train_data.rdd.map(lambda x: build_sample(x[0], x[1], x[2]-1))\n\n\n\n\nIf they execute a \npairFeatureRdds.count()\n, this counting job will cost 12 hours when the dataset has 6,000,000 records.\n\nIt seems a bug of StringIndexer. But we find a good way to work around this, before transform \nuser_index\n, \nitem_index\n and \nlabel\n to \nUserItemFeature\n we need to cast the Double \nindex\ns to Float, like this:\n\n\ntrain_data = train_data.withColumn(\"user_index\", df_r_new[\"user_index\"].cast(FloatType()))\ntrain_data = train_data.withColumn(\"item_index\", df_r_new[\"item_index\"].cast(FloatType()))\n\n\n\n\nThen the job finish in about 30s, the GC is also disappeared.",
            "title": "FAQ and Known Issues"
        }
    ]
}