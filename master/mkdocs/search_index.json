{
    "docs": [
        {
            "location": "/", 
            "text": "Analytics Zoo\n\n\nA unified analytics + AI platform for \ndistributed TensorFlow, Keras and BigDL on Apache Spark\n\n\n\n\nWhat is Analytics Zoo?\n\n\nAnalytics Zoo\n provides a unified analytics + AI platform that seamlessly unites \nSpark, TensorFlow, Keras and BigDL\n programs into an integrated pipeline; the entire pipeline can then transparently scale out to a large Hadoop/Spark cluster for distributed training or inference. \n\n\n\n\nData wrangling and analysis using PySpark\n\n\nDeep learning model development using TensorFlow or Keras\n\n\nDistributed training/inference on Spark and BigDL\n\n\nAll within a single unified pipeline and in a user-transparent fashion!\n\n\n\n\nIn addition, Analytics Zoo also provides a rich set of analytics and AI support for the end-to-end pipeline, including:\n\n\n\n\nEasy-to-use abstractions and APIs\n (e.g., transfer learning support, autograd operations, Spark DataFrame and ML pipeline support, online model serving API, etc.) \n\n\nCommon feature engineering operations\n (for image, text, 3D image, etc.)\n\n\nBuilt-in deep learning models\n (e.g., object detection, image classification, text classification, recommendation, anomaly detection, text matching, sequence to sequence etc.)\n\n\nReference use cases\n (e.g., anomaly detection, sentiment analysis, fraud detection, image similarity, etc.)\n\n\n\n\nHow to use Analytics Zoo?\n\n\n\n\n\n\nTo get started, please refer to the \nPython install guide\n or \nScala install guide\n.\n\n\n\n\n\n\nFor running distributed TensorFlow on Spark and BigDL, please refer to the quick start \nhere\n and the details \nhere\n.\n\n\n\n\n\n\nFor more information, You may refer to the \nAnalytics Zoo document website\n.\n\n\n\n\n\n\nFor additional questions and discussions, you can join the \nGoogle User Group\n (or subscribe to the \nMail List\n).\n\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\nDistributed TensorFlow and Keras on Spark/BigDL\n\n\n\n\nData wrangling and analysis using PySpark\n\n\nDeep learning model development using TensorFlow or Keras\n\n\nDistributed training/inference on Spark and BigDL\n\n\nAll within a single unified pipeline and in a user-transparent fashion!\n\n\n\n\n\n\n\n\nHigh level abstractions and APIs\n\n\n\n\nTransfer learning\n: customize pretrained model for \nfeature extraction or fine-tuning\n\n\nautograd\n: build custom layer/loss using \nauto differentiation operations\n \n\n\nnnframes\n: native deep learning support in \nSpark DataFrames and ML Pipelines\n\n\nModel serving\n: productionize \nmodel serving and inference\n using \nPOJO\n APIs\n\n\n\n\n\n\n\n\nBuilt-in deep learning models\n\n\n\n\nObject detection API\n: high-level API and pretrained models (e.g., SSD and Faster-RCNN) for \nobject detection\n\n\nImage classification API\n: high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for \nimage classification\n\n\nText classification API\n: high-level API and pre-defined models (using CNN, LSTM, etc.) for \ntext classification\n\n\nRecommendation API\n: high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for \nrecommendation\n\n\nAnomaly detection API\n: high-level API and pre-defined models based on LSTM for \nanomaly detection\n\n\nText matching API\n: high-level API and pre-defined KNRM model for \ntext matching\n\n\nSequence to sequence API\n: high-level API and pre-defined models for \nsequence to sequence\n\n\n\n\n\n\n\n\nReference use cases\n: a collection of end-to-end \nreference use cases\n (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)\n\n\n\n\n\n\nDocker images and builders\n\n\n\n\nAnalytics-Zoo in Docker\n\n\nHow to build it\n\n\nHow to use the image\n\n\nNotice\n\n\n\n\n\n\n\n\nDistributed TensorFlow and Keras on Spark/BigDL\n\n\nTo make it easy to build and productionize the deep learning applications for Big Data, Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline (as illustrated below), which can then transparently run on a large-scale Hadoop/Spark clusters for distributed training and inference. (Please see more details \nhere\n).\n\n\n1.Data wrangling and analysis using PySpark\n\n\n   from zoo import init_nncontext\n   from zoo.pipeline.api.net import TFDataset\n\n   sc = init_nncontext()\n\n   #Each record in the train_rdd consists of a list of NumPy ndrrays\n   train_rdd = sc.parallelize(file_list)\n     .map(lambda x: read_image_and_label(x))\n     .map(lambda image_label: decode_to_ndarrays(image_label))\n\n   #TFDataset represents a distributed set of elements,\n   #in which each element contains one or more TensorFlow Tensor objects. \n   dataset = TFDataset.from_rdd(train_rdd,\n                                names=[\nfeatures\n, \nlabels\n],\n                                shapes=[[28, 28, 1], [1]],\n                                types=[tf.float32, tf.int32],\n                                batch_size=BATCH_SIZE)\n\n\n\n\n2.Deep learning model development using TensorFlow\n\n\n   import tensorflow as tf\n\n   slim = tf.contrib.slim\n\n   images, labels = dataset.tensors\n   labels = tf.squeeze(labels)\n   with slim.arg_scope(lenet.lenet_arg_scope()):\n        logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\n   loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n\n\n\n\n3.Distributed training on Spark and BigDL\n\n\n   from zoo.pipeline.api.net import TFOptimizer\n   from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\n   optimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\n   optimizer.set_train_summary(TrainSummary(\n/tmp/az_lenet\n, \nlenet\n))\n   optimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\n4.Alternatively, using Keras APIs for model development and distributed training\n\n\n   from zoo.pipeline.api.keras.models import *\n   from zoo.pipeline.api.keras.layers import *\n\n   model = Sequential()\n   model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\n   model.add(Convolution2D(6, 5, 5, activation=\ntanh\n, name=\nconv1_5x5\n))\n   model.add(MaxPooling2D())\n   model.add(Convolution2D(12, 5, 5, activation=\ntanh\n, name=\nconv2_5x5\n))\n   model.add(MaxPooling2D())\n   model.add(Flatten())\n   model.add(Dense(100, activation=\ntanh\n, name=\nfc1\n))\n   model.add(Dense(class_num, activation=\nsoftmax\n, name=\nfc2\n))\n\n   model.compile(loss='sparse_categorical_crossentropy',\n                 optimizer='adam')\n   model.fit(train_rdd, batch_size=BATCH_SIZE, nb_epoch=5)\n\n\n\n\nHigh level abstractions and APIs\n\n\nAnalytics Zoo provides a set of easy-to-use, high level abstractions and APIs that natively transfer learning, autograd and custom layer/loss, Spark DataFrames and ML Pipelines, online model serving, etc. etc.\n\n\nTransfer learning\n\n\nUsing the high level transfer learning APIs, you can easily customize pretrained models for \nfeature extraction or fine-tuning\n. (See more details \nhere\n)\n\n\n1.Load an existing model (pretrained in Caffe)\n\n\n   from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)\n\n\n\n\n2.Remove the last few layers\n\n\n   # create a new model by removing layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\n3.Freeze the first few layers\n\n\n   # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\n4.Add a few new layers\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name=\ninput\n, shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)\n\n\n\n\nautograd\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustrated below. (See more details \nhere\n)\n\n\n1.Define model using Keras-style API and \nautograd\n \n\n\n   import zoo.pipeline.api.autograd as A\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n\n   input = Input(shape=[2, 20])\n   features = TimeDistributed(layer=Dense(30))(input)\n   f1 = features.index_select(1, 0)\n   f2 = features.index_select(1, 1)\n   diff = A.abs(f1 - f2)\n   model = Model(input, diff)\n\n\n\n\n2.Optionally define custom loss function using \nautograd\n\n\n   def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)\n\n\n\n\n3.Train model with \ncustom loss function\n\n\n   model.compile(optimizer=SGD(), loss=mean_absolute_error)\n   model.fit(x=..., y=...)\n\n\n\n\nnnframes\n\n\nnnframes\n provides \nnative deep learning support in Spark DataFrames and ML Pipelines\n, so that you can easily build complex deep learning pipelines in just a few lines, as illustrated below. (See more details \nhere\n)\n\n\n1.Initialize \nNNContext\n and load images into \nDataFrames\n using \nNNImageReader\n\n\n   from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   from zoo.feature.image import *\n   sc = init_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)\n\n\n\n\n2.Process loaded data using \nDataFrames transformations\n\n\n   getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn(\nname\n, getName(col(\nimage\n))).withColumn(\nlabel\n, getLabel(col('name')))\n\n\n\n\n3.Processing image using built-in \nfeature engineering operations\n\n\n   transformer = RowToImageFeature() -\n ImageResize(64, 64) -\n ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -\n ImageMatToTensor() -\n ImageFeatureToTensor())\n\n\n\n\n4.Define model using \nKeras-style APIs\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))\n\n\n\n\n5.Train model using \nSpark ML Pipelines\n\n\n   classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol(\nimage\n).setCachingSample(False)\n   nnModel = classifier.fit(df)\n\n\n\n\nModel Serving\n\n\nUsing the \nPOJO\n model serving API, you can productionize model serving and inference in any Java based frameworks (e.g., \nSpring Framework\n, Apache \nStorm\n, \nKafka\n or \nFlink\n, etc.), as illustrated below:\n\n\nimport com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n}\n\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\n\nList\nJTensor\n inputs = preprocess(...);\nList\nList\nJTensor\n result = model.predict(inputs);\n...\n\n\n\n\nBuilt-in deep learning models\n\n\nAnalytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as \nobject detection\n, \nimage classification\n, \ntext classification\n, \nrecommendation\n, \nanomaly detection\n, \ntext matching\n, \nsequence to sequence\n,  etc.\n\n\nObject detection API\n\n\nUsing \nAnalytics Zoo Object Detection API\n (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details \nhere\n)\n\n\n1.Download object detection models in Analytics Zoo\n\n\nYou can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from \ndetection model zoo\n.\n\n\n2.Use \nObject Detection API\n for off-the-shell inference\n\n\n   from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nImage classification API\n\n\nUsing \nAnalytics Zoo Image Classification API\n (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details \nhere\n)\n\n\n1.Download image classification models in Analytics Zoo\n\n\nYou can download a collection of image classification models (pretrained on the ImageNet dataset) from \nimage classification model zoo\n.\n\n\n2.Use \nImage classification API\n for off-the-shell inference\n\n\n   from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nText classification API\n\n\nAnalytics Zoo Text Classification API\n provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details \nhere\n)\n\n\nRecommendation API\n\n\nAnalytics Zoo Recommendation API\n provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details \nhere\n)\n\n\nAnomaly detection API\n\n\nAnalytics Zoo Anomaly Detection API\n provides a set of pre-defined models based on LSTM to detect anomalies for time series data. (See more details \nhere\n)\n\n\nText matching API\n\n\nAnalytics Zoo Text Matching API\n provides pre-defined KNRM model for ranking or classification. (See more details \nhere\n)\n\n\nSequence to sequence API\n\n\nAnalytics Zoo Sequence to Sequence API\n provides a set of pre-defined models based on Recurrent neural network for sequence to sequence problems. (See more details \nhere\n)\n\n\nReference use cases\n\n\nAnalytics Zoo provides a collection of end-to-end reference use cases, including \ntime series anomaly detection\n, \nsentiment analysis\n, \nfraud detection\n, \nimage similarity\n, etc. (See more details \nhere\n)\n\n\nDocker images and builders\n\n\nAnalytics-Zoo in Docker\n\n\nBy default, the Analytics-Zoo image has installed below packages:\n\n- git\n- maven\n- Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152)\n- python 2.7.6\n- pip\n- numpy\n- scipy\n- pandas\n- scikit-learn\n- matplotlib\n- seaborn\n- jupyter\n- wordcloud\n- moviepy\n- requests\n- tensorflow_\n- spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION})\n- Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION})\n- Analytics-Zoo source code (in /opt/work/analytics-zoo)\n\n\nThe work dir for Analytics-Zoo is /opt/work.\n\n- download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.\n- start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a specified jupyter notebook.\n- analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution.\n- analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution.\n- spark-${SPARK_VERSION} is the Spark home.\n- analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.\n\n\nHow to build it\n\n\nBy default, you can build a Analytics-Zoo:default image with latest nightly-build Analytics-Zoo distributions:\n\n\nsudo docker build --rm -t intelanalytics/analytics-zoo:default .\n\n\n\n\nIf you need http and https proxy to build the image:\n\n\nsudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --rm -t intelanalytics/analytics-zoo:default .\n\n\n\n\nYou can also specify the ANALYTICS_ZOO_VERSION and SPARK_VERSION to build a specific Analytics-Zoo image:\n\n\nsudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --build-arg ANALYTICS_ZOO_VERSION=0.3.0 \\\n    --build-arg BIGDL_VERSION=0.6.0 \\\n    --build-arg SPARK_VERSION=2.3.1 \\\n    --rm -t intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 .\n\n\n\n\nHow to use the image\n\n\nTo start a notebook directly with a specified port(e.g. 12345). You can view the notebook on http://[host-ip]:12345\n\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\n\n\n\nIf you need http and https proxy in your environment:\n\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\n\n\n\nYou can also start the container first\n\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\nyour-token\n \\\n    intelanalytics/analytics-zoo:default bash\n\n\n\n\nIn the container, after setting proxy and ports, you can start the Notebook by:\n\n\n/opt/work/start-notebook.sh\n\n\n\n\nNotice\n\n\nIf you need nightly build version of Analytics-Zoo, please pull the image form Dockerhub with:\n\n\nsudo docker pull intelanalytics/analytics-zoo:latest\n\n\n\n\nPlease follow the readme in each app folder to test the jupyter notebooks !!!\n\n\nWith 0.3+ version of Anaytics-Zoo Docker image, you can specify the runtime conf of spark\n\n\nsudo docker run -itd --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken=\n1234qwer\n \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port  \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port  \\\n    -e RUNTIME_DRIVER_CORES_ENV=4 \\\n    -e RUNTIME_DRIVER_MEMORY=20g \\\n    -e RUNTIME_EXECUTOR_CORES=4 \\\n    -e RUNTIME_EXECUTOR_MEMORY=20g \\\n    -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\\n    intelanalytics/analytics-zoo:latest", 
            "title": "Overview"
        }, 
        {
            "location": "/#analytics-zoo", 
            "text": "A unified analytics + AI platform for  distributed TensorFlow, Keras and BigDL on Apache Spark", 
            "title": "Analytics Zoo"
        }, 
        {
            "location": "/#what-is-analytics-zoo", 
            "text": "Analytics Zoo  provides a unified analytics + AI platform that seamlessly unites  Spark, TensorFlow, Keras and BigDL  programs into an integrated pipeline; the entire pipeline can then transparently scale out to a large Hadoop/Spark cluster for distributed training or inference.    Data wrangling and analysis using PySpark  Deep learning model development using TensorFlow or Keras  Distributed training/inference on Spark and BigDL  All within a single unified pipeline and in a user-transparent fashion!   In addition, Analytics Zoo also provides a rich set of analytics and AI support for the end-to-end pipeline, including:   Easy-to-use abstractions and APIs  (e.g., transfer learning support, autograd operations, Spark DataFrame and ML pipeline support, online model serving API, etc.)   Common feature engineering operations  (for image, text, 3D image, etc.)  Built-in deep learning models  (e.g., object detection, image classification, text classification, recommendation, anomaly detection, text matching, sequence to sequence etc.)  Reference use cases  (e.g., anomaly detection, sentiment analysis, fraud detection, image similarity, etc.)", 
            "title": "What is Analytics Zoo?"
        }, 
        {
            "location": "/#how-to-use-analytics-zoo", 
            "text": "To get started, please refer to the  Python install guide  or  Scala install guide .    For running distributed TensorFlow on Spark and BigDL, please refer to the quick start  here  and the details  here .    For more information, You may refer to the  Analytics Zoo document website .    For additional questions and discussions, you can join the  Google User Group  (or subscribe to the  Mail List ).", 
            "title": "How to use Analytics Zoo?"
        }, 
        {
            "location": "/#overview", 
            "text": "Distributed TensorFlow and Keras on Spark/BigDL   Data wrangling and analysis using PySpark  Deep learning model development using TensorFlow or Keras  Distributed training/inference on Spark and BigDL  All within a single unified pipeline and in a user-transparent fashion!     High level abstractions and APIs   Transfer learning : customize pretrained model for  feature extraction or fine-tuning  autograd : build custom layer/loss using  auto differentiation operations    nnframes : native deep learning support in  Spark DataFrames and ML Pipelines  Model serving : productionize  model serving and inference  using  POJO  APIs     Built-in deep learning models   Object detection API : high-level API and pretrained models (e.g., SSD and Faster-RCNN) for  object detection  Image classification API : high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for  image classification  Text classification API : high-level API and pre-defined models (using CNN, LSTM, etc.) for  text classification  Recommendation API : high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for  recommendation  Anomaly detection API : high-level API and pre-defined models based on LSTM for  anomaly detection  Text matching API : high-level API and pre-defined KNRM model for  text matching  Sequence to sequence API : high-level API and pre-defined models for  sequence to sequence     Reference use cases : a collection of end-to-end  reference use cases  (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)    Docker images and builders   Analytics-Zoo in Docker  How to build it  How to use the image  Notice", 
            "title": "Overview"
        }, 
        {
            "location": "/#distributed-tensorflow-and-keras-on-sparkbigdl", 
            "text": "To make it easy to build and productionize the deep learning applications for Big Data, Analytics Zoo provides a unified analytics + AI platform that seamlessly unites Spark, TensorFlow, Keras and BigDL programs into an integrated pipeline (as illustrated below), which can then transparently run on a large-scale Hadoop/Spark clusters for distributed training and inference. (Please see more details  here ).  1.Data wrangling and analysis using PySpark     from zoo import init_nncontext\n   from zoo.pipeline.api.net import TFDataset\n\n   sc = init_nncontext()\n\n   #Each record in the train_rdd consists of a list of NumPy ndrrays\n   train_rdd = sc.parallelize(file_list)\n     .map(lambda x: read_image_and_label(x))\n     .map(lambda image_label: decode_to_ndarrays(image_label))\n\n   #TFDataset represents a distributed set of elements,\n   #in which each element contains one or more TensorFlow Tensor objects. \n   dataset = TFDataset.from_rdd(train_rdd,\n                                names=[ features ,  labels ],\n                                shapes=[[28, 28, 1], [1]],\n                                types=[tf.float32, tf.int32],\n                                batch_size=BATCH_SIZE)  2.Deep learning model development using TensorFlow     import tensorflow as tf\n\n   slim = tf.contrib.slim\n\n   images, labels = dataset.tensors\n   labels = tf.squeeze(labels)\n   with slim.arg_scope(lenet.lenet_arg_scope()):\n        logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\n   loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))  3.Distributed training on Spark and BigDL     from zoo.pipeline.api.net import TFOptimizer\n   from bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\n   optimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\n   optimizer.set_train_summary(TrainSummary( /tmp/az_lenet ,  lenet ))\n   optimizer.optimize(end_trigger=MaxEpoch(5))  4.Alternatively, using Keras APIs for model development and distributed training     from zoo.pipeline.api.keras.models import *\n   from zoo.pipeline.api.keras.layers import *\n\n   model = Sequential()\n   model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\n   model.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 ))\n   model.add(MaxPooling2D())\n   model.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 ))\n   model.add(MaxPooling2D())\n   model.add(Flatten())\n   model.add(Dense(100, activation= tanh , name= fc1 ))\n   model.add(Dense(class_num, activation= softmax , name= fc2 ))\n\n   model.compile(loss='sparse_categorical_crossentropy',\n                 optimizer='adam')\n   model.fit(train_rdd, batch_size=BATCH_SIZE, nb_epoch=5)", 
            "title": "Distributed TensorFlow and Keras on Spark/BigDL"
        }, 
        {
            "location": "/#high-level-abstractions-and-apis", 
            "text": "Analytics Zoo provides a set of easy-to-use, high level abstractions and APIs that natively transfer learning, autograd and custom layer/loss, Spark DataFrames and ML Pipelines, online model serving, etc. etc.", 
            "title": "High level abstractions and APIs"
        }, 
        {
            "location": "/#transfer-learning", 
            "text": "Using the high level transfer learning APIs, you can easily customize pretrained models for  feature extraction or fine-tuning . (See more details  here )  1.Load an existing model (pretrained in Caffe)     from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)  2.Remove the last few layers     # create a new model by removing layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([ pool5/drop_7x7_s1 ])  3.Freeze the first few layers     # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([ pool4/3x3_s2 ])  4.Add a few new layers     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name= input , shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)", 
            "title": "Transfer learning"
        }, 
        {
            "location": "/#autograd", 
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustrated below. (See more details  here )  1.Define model using Keras-style API and  autograd       import zoo.pipeline.api.autograd as A\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n\n   input = Input(shape=[2, 20])\n   features = TimeDistributed(layer=Dense(30))(input)\n   f1 = features.index_select(1, 0)\n   f2 = features.index_select(1, 1)\n   diff = A.abs(f1 - f2)\n   model = Model(input, diff)  2.Optionally define custom loss function using  autograd     def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)  3.Train model with  custom loss function     model.compile(optimizer=SGD(), loss=mean_absolute_error)\n   model.fit(x=..., y=...)", 
            "title": "autograd"
        }, 
        {
            "location": "/#nnframes", 
            "text": "nnframes  provides  native deep learning support in Spark DataFrames and ML Pipelines , so that you can easily build complex deep learning pipelines in just a few lines, as illustrated below. (See more details  here )  1.Initialize  NNContext  and load images into  DataFrames  using  NNImageReader     from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   from zoo.feature.image import *\n   sc = init_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)  2.Process loaded data using  DataFrames transformations     getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn( name , getName(col( image ))).withColumn( label , getLabel(col('name')))  3.Processing image using built-in  feature engineering operations     transformer = RowToImageFeature() -  ImageResize(64, 64) -  ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -  ImageMatToTensor() -  ImageFeatureToTensor())  4.Define model using  Keras-style APIs     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))  5.Train model using  Spark ML Pipelines     classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol( image ).setCachingSample(False)\n   nnModel = classifier.fit(df)", 
            "title": "nnframes"
        }, 
        {
            "location": "/#model-serving", 
            "text": "Using the  POJO  model serving API, you can productionize model serving and inference in any Java based frameworks (e.g.,  Spring Framework , Apache  Storm ,  Kafka  or  Flink , etc.), as illustrated below:  import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n}\n\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\n\nList JTensor  inputs = preprocess(...);\nList List JTensor  result = model.predict(inputs);\n...", 
            "title": "Model Serving"
        }, 
        {
            "location": "/#built-in-deep-learning-models", 
            "text": "Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as  object detection ,  image classification ,  text classification ,  recommendation ,  anomaly detection ,  text matching ,  sequence to sequence ,  etc.", 
            "title": "Built-in deep learning models"
        }, 
        {
            "location": "/#object-detection-api", 
            "text": "Using  Analytics Zoo Object Detection API  (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details  here )  1.Download object detection models in Analytics Zoo  You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from  detection model zoo .  2.Use  Object Detection API  for off-the-shell inference     from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Object detection API"
        }, 
        {
            "location": "/#image-classification-api", 
            "text": "Using  Analytics Zoo Image Classification API  (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details  here )  1.Download image classification models in Analytics Zoo  You can download a collection of image classification models (pretrained on the ImageNet dataset) from  image classification model zoo .  2.Use  Image classification API  for off-the-shell inference     from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Image classification API"
        }, 
        {
            "location": "/#text-classification-api", 
            "text": "Analytics Zoo Text Classification API  provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details  here )", 
            "title": "Text classification API"
        }, 
        {
            "location": "/#recommendation-api", 
            "text": "Analytics Zoo Recommendation API  provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details  here )", 
            "title": "Recommendation API"
        }, 
        {
            "location": "/#anomaly-detection-api", 
            "text": "Analytics Zoo Anomaly Detection API  provides a set of pre-defined models based on LSTM to detect anomalies for time series data. (See more details  here )", 
            "title": "Anomaly detection API"
        }, 
        {
            "location": "/#text-matching-api", 
            "text": "Analytics Zoo Text Matching API  provides pre-defined KNRM model for ranking or classification. (See more details  here )", 
            "title": "Text matching API"
        }, 
        {
            "location": "/#sequence-to-sequence-api", 
            "text": "Analytics Zoo Sequence to Sequence API  provides a set of pre-defined models based on Recurrent neural network for sequence to sequence problems. (See more details  here )", 
            "title": "Sequence to sequence API"
        }, 
        {
            "location": "/#reference-use-cases", 
            "text": "Analytics Zoo provides a collection of end-to-end reference use cases, including  time series anomaly detection ,  sentiment analysis ,  fraud detection ,  image similarity , etc. (See more details  here )", 
            "title": "Reference use cases"
        }, 
        {
            "location": "/#docker-images-and-builders", 
            "text": "", 
            "title": "Docker images and builders"
        }, 
        {
            "location": "/#analytics-zoo-in-docker", 
            "text": "By default, the Analytics-Zoo image has installed below packages: \n- git\n- maven\n- Oracle jdk 1.8.0_152 (in /opt/jdk1.8.0_152)\n- python 2.7.6\n- pip\n- numpy\n- scipy\n- pandas\n- scikit-learn\n- matplotlib\n- seaborn\n- jupyter\n- wordcloud\n- moviepy\n- requests\n- tensorflow_\n- spark-${SPARK_VERSION} (in /opt/work/spark-${SPARK_VERSION})\n- Analytics-Zoo distribution (in /opt/work/analytics-zoo-${ANALYTICS_ZOO_VERSION})\n- Analytics-Zoo source code (in /opt/work/analytics-zoo)  The work dir for Analytics-Zoo is /opt/work. \n- download-analytics-zoo.sh is used for downloading Analytics-Zoo distributions.\n- start-notebook.sh is used for starting the jupyter notebook. You can specify the environment settings and spark settings to start a specified jupyter notebook.\n- analytics-Zoo-${ANALYTICS_ZOO_VERSION} is the Analytics-Zoo home of Analytics-Zoo distribution.\n- analytics-zoo-SPARK_x.x-x.x.x-dist.zip is the zip file of Analytics-Zoo distribution.\n- spark-${SPARK_VERSION} is the Spark home.\n- analytics-zoo is cloned from https://github.com/intel-analytics/analytics-zoo, contains apps, examples using analytics-zoo.", 
            "title": "Analytics-Zoo in Docker"
        }, 
        {
            "location": "/#how-to-build-it", 
            "text": "By default, you can build a Analytics-Zoo:default image with latest nightly-build Analytics-Zoo distributions:  sudo docker build --rm -t intelanalytics/analytics-zoo:default .  If you need http and https proxy to build the image:  sudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --rm -t intelanalytics/analytics-zoo:default .  You can also specify the ANALYTICS_ZOO_VERSION and SPARK_VERSION to build a specific Analytics-Zoo image:  sudo docker build \\\n    --build-arg http_proxy=http://your-proxy-host:your-proxy-port \\\n    --build-arg https_proxy=https://your-proxy-host:your-proxy-port \\\n    --build-arg ANALYTICS_ZOO_VERSION=0.3.0 \\\n    --build-arg BIGDL_VERSION=0.6.0 \\\n    --build-arg SPARK_VERSION=2.3.1 \\\n    --rm -t intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1 .", 
            "title": "How to build it"
        }, 
        {
            "location": "/#how-to-use-the-image", 
            "text": "To start a notebook directly with a specified port(e.g. 12345). You can view the notebook on http://[host-ip]:12345  sudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1  If you need http and https proxy in your environment:  sudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:default\n\nsudo docker run -it --rm -p 12345:12345 \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1\n\nsudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port \\\n    intelanalytics/analytics-zoo:0.3.0-bigdl_0.6.0-spark_2.3.1  You can also start the container first  sudo docker run -it --rm --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= your-token  \\\n    intelanalytics/analytics-zoo:default bash  In the container, after setting proxy and ports, you can start the Notebook by:  /opt/work/start-notebook.sh", 
            "title": "How to use the image"
        }, 
        {
            "location": "/#notice", 
            "text": "If you need nightly build version of Analytics-Zoo, please pull the image form Dockerhub with:  sudo docker pull intelanalytics/analytics-zoo:latest  Please follow the readme in each app folder to test the jupyter notebooks !!!  With 0.3+ version of Anaytics-Zoo Docker image, you can specify the runtime conf of spark  sudo docker run -itd --net=host \\\n    -e NotebookPort=12345 \\\n    -e NotebookToken= 1234qwer  \\\n    -e http_proxy=http://your-proxy-host:your-proxy-port  \\\n    -e https_proxy=https://your-proxy-host:your-proxy-port  \\\n    -e RUNTIME_DRIVER_CORES_ENV=4 \\\n    -e RUNTIME_DRIVER_MEMORY=20g \\\n    -e RUNTIME_EXECUTOR_CORES=4 \\\n    -e RUNTIME_EXECUTOR_MEMORY=20g \\\n    -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \\\n    intelanalytics/analytics-zoo:latest", 
            "title": "Notice"
        }, 
        {
            "location": "/release-download/", 
            "text": "Release 0.5.0 nightly build\n\n\n\n\n\n\n\n\n\n\nBigDL 0.7.2\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.0\n\n\ndownload\n\n\n\n\n\n\n\n\nRelease 0.4.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.7.2\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.4.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.3.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.6.0\n\n\nBigDL 0.7.1\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.3.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.2.0\n\n\n\n\n\n\n\n\n\n\nBigDL 0.6.0\n\n\nBigDL 0.5.0\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.1.0\n\n\n\n\n\n\n\n\n\n\nDownload Links\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload", 
            "title": "Download"
        }, 
        {
            "location": "/release-download/#release-050-nightly-build", 
            "text": "BigDL 0.7.2      Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download    Spark 2.3.1  download    Spark 2.4.0  download", 
            "title": "Release 0.5.0 nightly build"
        }, 
        {
            "location": "/release-download/#release-040", 
            "text": "BigDL 0.7.2      Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download    Spark 2.3.1  download    Spark 2.4.0  download", 
            "title": "Release 0.4.0"
        }, 
        {
            "location": "/release-download/#release-030", 
            "text": "BigDL 0.6.0  BigDL 0.7.1      Spark 1.6.2  download  download    Spark 2.1.1  download  download    Spark 2.2.0  download  download    Spark 2.3.1  download  download", 
            "title": "Release 0.3.0"
        }, 
        {
            "location": "/release-download/#release-020", 
            "text": "BigDL 0.6.0  BigDL 0.5.0      Spark 1.6.2  download  download    Spark 2.1.1  download  download    Spark 2.2.0  download  download", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-download/#release-010", 
            "text": "Download Links      Spark 1.6.0  download    Spark 2.1.0  download    Spark 2.2.0  download", 
            "title": "Release 0.1.0"
        }, 
        {
            "location": "/release-docs/", 
            "text": "Release 0.4.0\n\n\nAnalytics-Zoo 0.4.0 Docs\n\n\nRelease 0.3.0\n\n\nAnalytics-Zoo 0.3.0 Docs\n\n\nRelease 0.2.0\n\n\nAnalytics-Zoo 0.2.0 Docs\n\n\nRelease 0.1.0\n\n\nAnalytics-Zoo 0.1.0 Docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/release-docs/#release-040", 
            "text": "Analytics-Zoo 0.4.0 Docs", 
            "title": "Release 0.4.0"
        }, 
        {
            "location": "/release-docs/#release-030", 
            "text": "Analytics-Zoo 0.3.0 Docs", 
            "title": "Release 0.3.0"
        }, 
        {
            "location": "/release-docs/#release-020", 
            "text": "Analytics-Zoo 0.2.0 Docs", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-docs/#release-010", 
            "text": "Analytics-Zoo 0.1.0 Docs", 
            "title": "Release 0.1.0"
        }, 
        {
            "location": "/PythonUserGuide/install/", 
            "text": "For Python users, Analytics Zoo can be installed either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: Only \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\n\n\nInstall from pip\n\n\nYou can use the following command to install the latest release version of \nanalytics-zoo\n via pip easily:\n\n\npip install analytics-zoo     # for Python 2.7\npip3 install analytics-zoo    # for Python 3.5 and Python 3.6\n\n\n\n\n\n\nNote that you might need to add \nsudo\n if you don't have the permission for installation.\n\n\n\n\nImportant:\n\n\n\n\n\n\nInstalling analytics-zoo from pip will automatically install \npyspark\n. To avoid possible conflicts, you are highly recommended to \nunset \nSPARK_HOME\n if it exists in your environment.\n\n\n\n\n\n\nPlease always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\n\n\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nRemarks:\n\n\n\n\nWe've tested this package with pip 9.0.1. \npip install --upgrade pip\n if necessary.\n\n\nPip install supports \nMac\n and \nLinux\n platforms.\n\n\nPip install only supports \nlocal\n mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to \ninstall without pip\n.\n\n\nYou need to install Java \n= JDK8\n before running Analytics Zoo, which is required by \npyspark\n.\n\n\npyspark==2.3.2\n, \nbigdl==0.8.0\n and their dependencies will automatically be installed if they haven't been detected in the current Python environment.\n\n\n\n\n\n\nInstall without pip\n\n\nIf you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.\n\n\nSteps:\n\n\n\n\n\n\nDownload Spark\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and \n=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\n\n\n\n\nYou are recommended to download Analytics Zoo prebuilt release and nightly build package from the \nRelease Page\n and extract it.\nAlternatively, you can also build the Analytics Zoo from \nsource\n.\n\n\n\n\n\n\nInstall Python dependencies. Analytics Zoo only depends on \nnumpy\n and \nsix\n for now.\n\n\n\n\n\n\nFor Spark standalone cluster\n\n\n\n\nRemark\n: If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.\n\n\nInstall numpy: \n\nsudo apt-get install python-numpy\n (Ubuntu)\n\n\nInstall six: \n\nsudo apt-get install python-six\n (Ubuntu)\n\n\n\n\nFor Yarn cluster\n\n\nYou can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).\n\n\nYou can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment.\n\n\nFollow the steps below to create the virtual environment: \n\n\n\n\nMake sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first.\nOn Ubuntu, you can run these commands to install:\n\n\n\n\napt-get update\napt-get install -y python-setuptools python-dev\napt-get install -y gcc make\napt-get install -y zip\neasy_install pip\n\n\n\n\n\n\n\n\nCreate the virtualenv package for dependencies.\n\n\n\n\n\n\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\n\n\n\n\n\n\nRun \n${ANALYTICS_ZOO_HOME}/bin/python_package.sh\n to create the dependency virtual environment according to the dependencies listed in \nrequirements.txt\n. You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.\n\n\n\n\n\n\nAfter running this script, there will be \nvenv.zip\n and \nvenv\n directory generated in current directory. You can use them to submit your Python jobs. Please refer to \nhere\n for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster.\n\n\n\n\n\n\n\n\n\n\nFAQ\n\n\nIn case you encounter the following errors when you create the environment package using the above command:\n\n\n\n\nvirtualenv ImportError: No module named urllib3\n\n\nUsing python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.\n\n\n\n\n\n\nAttributeError: 'module' object has no attribute 'sslwrap'\n\n\nTry upgrading \ngevent\n with \npip install --upgrade gevent\n.", 
            "title": "Install"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-from-pip", 
            "text": "You can use the following command to install the latest release version of  analytics-zoo  via pip easily:  pip install analytics-zoo     # for Python 2.7\npip3 install analytics-zoo    # for Python 3.5 and Python 3.6   Note that you might need to add  sudo  if you don't have the permission for installation.   Important:    Installing analytics-zoo from pip will automatically install  pyspark . To avoid possible conflicts, you are highly recommended to  unset  SPARK_HOME  if it exists in your environment.    Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.    from zoo.common.nncontext import *\nsc = init_nncontext()  Remarks:   We've tested this package with pip 9.0.1.  pip install --upgrade pip  if necessary.  Pip install supports  Mac  and  Linux  platforms.  Pip install only supports  local  mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to  install without pip .  You need to install Java  = JDK8  before running Analytics Zoo, which is required by  pyspark .  pyspark==2.3.2 ,  bigdl==0.8.0  and their dependencies will automatically be installed if they haven't been detected in the current Python environment.", 
            "title": "Install from pip"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-without-pip", 
            "text": "If you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.  Steps:    Download Spark   Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and  =2.2.0. See  this issue  for more discussion.     You are recommended to download Analytics Zoo prebuilt release and nightly build package from the  Release Page  and extract it.\nAlternatively, you can also build the Analytics Zoo from  source .    Install Python dependencies. Analytics Zoo only depends on  numpy  and  six  for now.", 
            "title": "Install without pip"
        }, 
        {
            "location": "/PythonUserGuide/install/#for-spark-standalone-cluster", 
            "text": "Remark : If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.  Install numpy:  sudo apt-get install python-numpy  (Ubuntu)  Install six:  sudo apt-get install python-six  (Ubuntu)", 
            "title": "For Spark standalone cluster"
        }, 
        {
            "location": "/PythonUserGuide/install/#for-yarn-cluster", 
            "text": "You can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).  You can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment.  Follow the steps below to create the virtual environment:    Make sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first.\nOn Ubuntu, you can run these commands to install:   apt-get update\napt-get install -y python-setuptools python-dev\napt-get install -y gcc make\napt-get install -y zip\neasy_install pip    Create the virtualenv package for dependencies.    export ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package    Run  ${ANALYTICS_ZOO_HOME}/bin/python_package.sh  to create the dependency virtual environment according to the dependencies listed in  requirements.txt . You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.    After running this script, there will be  venv.zip  and  venv  directory generated in current directory. You can use them to submit your Python jobs. Please refer to  here  for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster.      FAQ  In case you encounter the following errors when you create the environment package using the above command:   virtualenv ImportError: No module named urllib3  Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.    AttributeError: 'module' object has no attribute 'sslwrap'  Try upgrading  gevent  with  pip install --upgrade gevent .", 
            "title": "For Yarn cluster"
        }, 
        {
            "location": "/PythonUserGuide/run/", 
            "text": "You need to first \ninstall\n analytics-zoo, either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: Only \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\n\n\nRun after pip install\n\n\nImportant:\n\n\n\n\n\n\nInstalling analytics-zoo from pip will automatically install \npyspark\n. To avoid possible conflicts, you are highly recommended to \nunset \nSPARK_HOME\n if it exists in your environment.\n\n\n\n\n\n\nPlease always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\n\n\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nUse an Interactive Shell\n\n\n\n\nType \npython\n in the command line to start a REPL.\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nUse Jupyter Notebook\n\n\n\n\nStart jupyter notebook as you normally do, e.g.\n\n\n\n\njupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nConfigurations\n\n\n\n\nIncrease memory\n\n\n\n\nexport SPARK_DRIVER_MEMORY=20g\n\n\n\n\n\n\nAdd extra jars or python packages\n\n\n\n\n Set the environment variables \nBIGDL_JARS\n and \nBIGDL_PACKAGES\n \nBEFORE\n creating \nSparkContext\n:\n\n\nexport BIGDL_JARS=...\nexport BIGDL_PACKAGES=...\n\n\n\n\n\n\nRun without pip install\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and \n=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nSet SPARK_HOME and ANALYTICS_ZOO_HOME\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo\n\n\n\n\nUpdate spark-analytics-zoo.conf (Optional)\n\n\nIf you have some customized properties in some files, which will be used with the \n--properties-file\n option\nin \nspark-submit/pyspark\n, you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.\n\n\n\n\nRun with pyspark\n\n\n${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with spark-submit\n\n\nAn Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo \nObject Detection Python example\n\nas follows:\n\n\n${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path\n\n\n\n\n\n\nRun with Jupyter Notebook\n\n\nWith the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.\n\n\nPrerequisites\n: Install all the necessary libraries on the local node where you will run Jupyter, e.g., \n\n\nsudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud\n\n\n\n\nLaunch the Jupyter Notebook as follows:\n\n\n${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nAfter successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with virtual environment on Yarn\n\n\nIf you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide \nhere\n,\nyou can run Python programs using Analytics Zoo using the following command.\n\n\nHere we use Analytics Zoo \nObject Detection Python example\n for illustration.\n\n\n\n\nYarn cluster mode\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport VENV_HOME=the parent directory of venv.zip and venv folder\n\nPYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --archives ${VENV_HOME}/venv.zip \\\n    predict.py model_path image_path output_path\n\n\n\n\n\n\nYarn client mode\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport VENV_HOME=the parent directory of venv.zip and venv folder\n\nPYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --archives ${VENV_HOME}/venv.zip \\\n    predict.py model_path image_path output_path\n\n\n\n\n\n\nExample code\n\n\nTo verify if Analytics Zoo can run successfully, run the following simple code:\n\n\nimport zoo\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))", 
            "title": "Run"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-after-pip-install", 
            "text": "Important:    Installing analytics-zoo from pip will automatically install  pyspark . To avoid possible conflicts, you are highly recommended to  unset  SPARK_HOME  if it exists in your environment.    Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.    from zoo.common.nncontext import *\nsc = init_nncontext()  Use an Interactive Shell   Type  python  in the command line to start a REPL.  Try to run the  example code  to verify the installation.   Use Jupyter Notebook   Start jupyter notebook as you normally do, e.g.   jupyter notebook --notebook-dir=./ --ip=* --no-browser   Try to run the  example code  to verify the installation.   Configurations   Increase memory   export SPARK_DRIVER_MEMORY=20g   Add extra jars or python packages    Set the environment variables  BIGDL_JARS  and  BIGDL_PACKAGES   BEFORE  creating  SparkContext :  export BIGDL_JARS=...\nexport BIGDL_PACKAGES=...", 
            "title": "Run after pip install"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-without-pip-install", 
            "text": "Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and  =2.2.0. See  this issue  for more discussion.   Set SPARK_HOME and ANALYTICS_ZOO_HOME   If you download Analytics Zoo from the  Release Page :   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package   If you build Analytics Zoo by yourself:   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo  Update spark-analytics-zoo.conf (Optional)  If you have some customized properties in some files, which will be used with the  --properties-file  option\nin  spark-submit/pyspark , you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.", 
            "title": "Run without pip install"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-pyspark", 
            "text": "${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  Try to run the  example code  for verification.", 
            "title": "Run with pyspark"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-spark-submit", 
            "text": "An Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo  Object Detection Python example \nas follows:  ${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path", 
            "title": "Run with spark-submit"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-jupyter-notebook", 
            "text": "With the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.  Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g.,   sudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud  Launch the Jupyter Notebook as follows:  ${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/  Try to run the  example code  for verification.", 
            "title": "Run with Jupyter Notebook"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-virtual-environment-on-yarn", 
            "text": "If you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide  here ,\nyou can run Python programs using Analytics Zoo using the following command.  Here we use Analytics Zoo  Object Detection Python example  for illustration.   Yarn cluster mode   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport VENV_HOME=the parent directory of venv.zip and venv folder\n\nPYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --archives ${VENV_HOME}/venv.zip \\\n    predict.py model_path image_path output_path   Yarn client mode   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the folder where you extract the downloaded Analytics Zoo zip package\nexport VENV_HOME=the parent directory of venv.zip and venv folder\n\nPYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=venv.zip/venv/bin/python ${ANALYTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --archives ${VENV_HOME}/venv.zip \\\n    predict.py model_path image_path output_path", 
            "title": "Run with virtual environment on Yarn"
        }, 
        {
            "location": "/PythonUserGuide/run/#example-code", 
            "text": "To verify if Analytics Zoo can run successfully, run the following simple code:  import zoo\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))", 
            "title": "Example code"
        }, 
        {
            "location": "/PythonUserGuide/examples/", 
            "text": "Analytics Zoo provides plenty of examples and notebooks ready for re-use as listed below.\n\n\n\n\nImage Classification\n: This example illustrates how to classify images with a pre-trained model.\n\n\nObject Detection\n: This example illustrates how to detect objects in images with a pre-trained model.\n\n\nRecommendation: There are two Python notebooks for recommendation models, including \nWide and Deep\n and \nNeural Collaborative Filtering\n.\n\n\nText Classification\n: This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU TextClassifier model on 20 Newsgroup dataset.\n\n\nDataFrame\n: There are three examples to show how to perform transfer learning and model inference using pre-trained Inception v1 model with DataFrame-based API.\n\n\nTFNet\n: This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences.\n\n\nQARanker\n: This example trains and evaluates a KNRM model on WikiQA dataset for ranking.\n\n\nDistributed TensorFlow\n: There are several examples to demonstrate how to run distributed TensorFlow and Keras on Spark/BigDL.\n\n\nAnomaly Detection\n: This example illustrates how to use LSTM to detect anomalies on NYC taxi passengers dataset.\n\n\nSee \nhere\n for more notebooks on user applications and demos.", 
            "title": "Examples"
        }, 
        {
            "location": "/PythonUserGuide/python-faq/", 
            "text": "This page lists solutions to some common questions.\n\n\n\n\n\n\nImportError\n: from zoo.pipeline.api.keras.layers import *\n\n\n\n\nCheck if the path is pointing to python-api.zip: \n--py-files ${ANALYTICS_ZOO_PY_ZIP}\n\n\nCheck if the path is pointing to python-api.zip:\n\n\n\n\nexport PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n\n\n\n\n\n\nPython in worker has a different version 2.7 than that in driver 3.5\n\n\n\n\nexport PYSPARK_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every worker node.\n\n\nexport PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every driver node.\n\n\n\n\n\n\n\n\nTypeError\n: 'JavaPackage' object is not callable\n\n\n\n\nCheck if every path within the launch script is valid especially the path that ends with jar.\n\n\nIf there are extra jars involved, check if the Spark version Analytics Zoo is built and the Spark version the extra jar is built are compatible.\n\n\n\n\n\n\n\n\njava.lang.\nNoSuchMethodError\n:XXX or \nPy4JError\n: ofFloat does not exist in the JVM\n\n\n\n\nCheck if the Spark version matches, i.e check if you are using Spark 2.x but the underneath Analytics Zoo is compiled with Spark 1.6.\n\n\nIf there are extra jars involved, also check if the Spark version matches.", 
            "title": "FAQ"
        }, 
        {
            "location": "/ScalaUserGuide/install/", 
            "text": "Download a pre-built library\n\n\nYou can download the Analytics Zoo release and nightly build from the \nRelease Page\n\n\n\n\nLink with a release version\n\n\nCurrently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.zoo\n/groupId\n\n    \nartifactId\nanalytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1]\n/artifactId\n\n    \nversion\n${ANALYTICS_ZOO_VERSION}\n/version\n\n\n/dependency\n\n\n\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.zoo\n % \nanalytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1]\n % \n${ANALYTICS_ZOO_VERSION}\n\n\n\n\n\nRemarks:\n\n\n\n\nPlease choose the available suffix above according to your Spark platform and the BigDL version you want to use.\n\n\nYou don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo.\n\n\nYou can find the option \n${ANALYTICS_ZOO_VERSION}\n from the \nRelease Page\n.\n\n\n\n\n\n\nLink with a development version\n\n\nCurrently, Analytics Zoo development version is hosted on \nSonaType\n.\n\n\nTo link your application with the latest Analytics Zoo development version, you should add some dependencies like \nLinking with Analytics Zoo releases\n, but set \n${ANALYTICS_ZOO_VERSION}\n to latest version, and add below repository to your pom.xml.\n\n\nrepository\n\n    \nid\nsonatype\n/id\n\n    \nname\nsonatype repository\n/name\n\n    \nurl\nhttps://oss.sonatype.org/content/groups/public/\n/url\n\n    \nreleases\n\n        \nenabled\ntrue\n/enabled\n\n    \n/releases\n\n    \nsnapshots\n\n        \nenabled\ntrue\n/enabled\n\n    \n/snapshots\n\n\n/repository\n\n\n\n\n\nSBT developers can use\n\n\nresolvers += \nossrh repository\n at \nhttps://oss.sonatype.org/content/repositories/snapshots/\n\n\n\n\n\nDownload Analytics Zoo Source\n\n\nAnalytics Zoo source code is available at \nGitHub\n\n\n$ git clone https://github.com/intel-analytics/analytics-zoo.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of Analytics Zoo, if you want a release version, you can use command \ngit checkout\n to change the version.\n\n\nSetup Build Environment\n\n\nThe following instructions are aligned with master code.\n\n\nMaven 3 is needed to build Analytics Zoo, you can download it from the \nmaven website\n.\n\n\nAfter installing Maven 3, please set the environment variable MAVEN_OPTS as follows:\n\n\n$ export MAVEN_OPTS=\n-Xmx2g -XX:ReservedCodeCacheSize=512m\n\n\n\n\n\nWhen compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.\n\n\nBuild with script (Recommended)\n\n\nIt is highly recommended that you build Analytics Zoo using the \nmake-dist.sh script\n. And it will handle the MAVEN_OPTS variable.\n\n\nOnce downloaded, you can build Analytics Zoo with the following commands:\n\n\n$ bash make-dist.sh\n\n\n\n\nAfter that, you can find a \ndist\n folder, which contains all the needed files to run a Analytics Zoo program. The files in \ndist\n include:\n\n\n\n\ndist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n: This jar package contains all dependencies except Spark classes.\n\n\ndist/lib/analytics-zoo-VERSION-python-api.zip\n: This zip package contains all Python files of Analytics Zoo.\n\n\n\n\nThe instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use \nJava 8\n when running with Spark 2.x; otherwise you may observe very poor performance.\n\n\nBuild for Spark 1.6\n\n\nTo build for Spark 1.6(which uses Scala 2.10 by default), pass \n-P spark_1.6\n to the \nmake-dist.sh\n script:\n\n\n$ bash make-dist.sh -P spark_1.6\n\n\n\n\nBuild for Scala 2.10 or 2.11\n\n\nBy default, \nmake-dist.sh\n uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass \n-P scala_2.10\n or \n-P scala_2.11\n to \nmake-dist.sh\n as appropriate.\n\n\n\n\nBuild with Maven\n\n\nTo build Analytics Zoo directly using Maven, run the command below:\n\n\n$ mvn clean package -DskipTests\n\n\n\n\nAfter that, you can find that jar packages in \nPATH_TO_ANALYTICS_ZOO\n/target/, where \nPATH_TO_ANALYTICS_ZOO\n is the path to the directory of the Analytics Zoo.\n\n\nNote that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven:\n\n\n\n\n-P spark_1.6\n: build for Spark 1.6 (using Scala 2.10).\n\n\n-P scala_2.10\n (or \n-P scala_2.11\n): build using Scala 2.10 (or Scala 2.11)\n\n\n\n\n\n\nSetup IDE\n\n\nWe set the scope of spark related library to \nprovided\n in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.\n\n\nThis will cause a problem in IDE. When you run applications, it will throw \nNoClassDefFoundError\n because the library scope is \nprovided\n.\n\n\nYou can easily change the scopes by the \nall-in-one\n profile.\n\n\n\n\nIn Intellij, go to View -\n Tools Windows -\n Maven Projects. Then in the Maven Projects panel, Profiles -\n click \"all-in-one\".", 
            "title": "Install"
        }, 
        {
            "location": "/ScalaUserGuide/install/#download-a-pre-built-library", 
            "text": "You can download the Analytics Zoo release and nightly build from the  Release Page", 
            "title": "Download a pre-built library"
        }, 
        {
            "location": "/ScalaUserGuide/install/#link-with-a-release-version", 
            "text": "Currently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:  dependency \n     groupId com.intel.analytics.zoo /groupId \n     artifactId analytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1] /artifactId \n     version ${ANALYTICS_ZOO_VERSION} /version  /dependency   SBT developers can use  libraryDependencies +=  com.intel.analytics.zoo  %  analytics-zoo-bigdl_0.7.1-[spark_1.6.2|spark_2.1.1|spark_2.2.0|spark_2.3.1]  %  ${ANALYTICS_ZOO_VERSION}   Remarks:   Please choose the available suffix above according to your Spark platform and the BigDL version you want to use.  You don't need to add the BigDL dependency to your project as it has already been packaged within Analytics Zoo.  You can find the option  ${ANALYTICS_ZOO_VERSION}  from the  Release Page .", 
            "title": "Link with a release version"
        }, 
        {
            "location": "/ScalaUserGuide/install/#link-with-a-development-version", 
            "text": "Currently, Analytics Zoo development version is hosted on  SonaType .  To link your application with the latest Analytics Zoo development version, you should add some dependencies like  Linking with Analytics Zoo releases , but set  ${ANALYTICS_ZOO_VERSION}  to latest version, and add below repository to your pom.xml.  repository \n     id sonatype /id \n     name sonatype repository /name \n     url https://oss.sonatype.org/content/groups/public/ /url \n     releases \n         enabled true /enabled \n     /releases \n     snapshots \n         enabled true /enabled \n     /snapshots  /repository   SBT developers can use  resolvers +=  ossrh repository  at  https://oss.sonatype.org/content/repositories/snapshots/", 
            "title": "Link with a development version"
        }, 
        {
            "location": "/ScalaUserGuide/install/#download-analytics-zoo-source", 
            "text": "Analytics Zoo source code is available at  GitHub  $ git clone https://github.com/intel-analytics/analytics-zoo.git  By default,  git clone  will download the development version of Analytics Zoo, if you want a release version, you can use command  git checkout  to change the version.", 
            "title": "Download Analytics Zoo Source"
        }, 
        {
            "location": "/ScalaUserGuide/install/#setup-build-environment", 
            "text": "The following instructions are aligned with master code.  Maven 3 is needed to build Analytics Zoo, you can download it from the  maven website .  After installing Maven 3, please set the environment variable MAVEN_OPTS as follows:  $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m   When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.", 
            "title": "Setup Build Environment"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-with-script-recommended", 
            "text": "It is highly recommended that you build Analytics Zoo using the  make-dist.sh script . And it will handle the MAVEN_OPTS variable.  Once downloaded, you can build Analytics Zoo with the following commands:  $ bash make-dist.sh  After that, you can find a  dist  folder, which contains all the needed files to run a Analytics Zoo program. The files in  dist  include:   dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes.  dist/lib/analytics-zoo-VERSION-python-api.zip : This zip package contains all Python files of Analytics Zoo.   The instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use  Java 8  when running with Spark 2.x; otherwise you may observe very poor performance.", 
            "title": "Build with script (Recommended)"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-for-spark-16", 
            "text": "To build for Spark 1.6(which uses Scala 2.10 by default), pass  -P spark_1.6  to the  make-dist.sh  script:  $ bash make-dist.sh -P spark_1.6", 
            "title": "Build for Spark 1.6"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-for-scala-210-or-211", 
            "text": "By default,  make-dist.sh  uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass  -P scala_2.10  or  -P scala_2.11  to  make-dist.sh  as appropriate.", 
            "title": "Build for Scala 2.10 or 2.11"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-with-maven", 
            "text": "To build Analytics Zoo directly using Maven, run the command below:  $ mvn clean package -DskipTests  After that, you can find that jar packages in  PATH_TO_ANALYTICS_ZOO /target/, where  PATH_TO_ANALYTICS_ZOO  is the path to the directory of the Analytics Zoo.  Note that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven:   -P spark_1.6 : build for Spark 1.6 (using Scala 2.10).  -P scala_2.10  (or  -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11)", 
            "title": "Build with Maven"
        }, 
        {
            "location": "/ScalaUserGuide/install/#setup-ide", 
            "text": "We set the scope of spark related library to  provided  in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.  This will cause a problem in IDE. When you run applications, it will throw  NoClassDefFoundError  because the library scope is  provided .  You can easily change the scopes by the  all-in-one  profile.   In Intellij, go to View -  Tools Windows -  Maven Projects. Then in the Maven Projects panel, Profiles -  click \"all-in-one\".", 
            "title": "Setup IDE"
        }, 
        {
            "location": "/ScalaUserGuide/run/", 
            "text": "Set Environment Variables\n\n\nSet \nANALYTICS_ZOO_HOME\n and \nSPARK_HOME\n:\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder\n\n\n\n\n\n\nUse Interactive Spark Shell\n\n\nYou can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:\n\n\n${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]\n\n\n\n\nYou will see a welcome message looking like below:\n\n\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala\n\n\n\n\n\nNow you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:\n\n\nscala\n import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala\n ObjectDetector.loadModel[Float](params.modelPath)\n\n\n\n\n\n\nRun as a Spark Program\n\n\nYou can run a analytics zoo program, e.g., the \nObject Detection\n, as a standard Spark program (running in either local mode or cluster mode) as follows:\n\n\n\n\nDownload the pre-trained model from \nhere\n.\n\n\nPrepare predict images\n\n\nRun the following command:\n\n\n\n\n  # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n\n\n\nIf you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.\n\n\nimport com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)", 
            "title": "Run"
        }, 
        {
            "location": "/ScalaUserGuide/run/#set-environment-variables", 
            "text": "Set  ANALYTICS_ZOO_HOME  and  SPARK_HOME :   If you download Analytics Zoo from the  Release Page   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package   If you build Analytics Zoo by yourself   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder", 
            "title": "Set Environment Variables"
        }, 
        {
            "location": "/ScalaUserGuide/run/#use-interactive-spark-shell", 
            "text": "You can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:  ${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]  You will see a welcome message looking like below:  Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala   Now you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:  scala  import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala  ObjectDetector.loadModel[Float](params.modelPath)", 
            "title": "Use Interactive Spark Shell"
        }, 
        {
            "location": "/ScalaUserGuide/run/#run-as-a-spark-program", 
            "text": "You can run a analytics zoo program, e.g., the  Object Detection , as a standard Spark program (running in either local mode or cluster mode) as follows:   Download the pre-trained model from  here .  Prepare predict images  Run the following command:     # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model  If you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.  import com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)", 
            "title": "Run as a Spark Program"
        }, 
        {
            "location": "/ScalaUserGuide/examples/", 
            "text": "Analytics Zoo provides plenty of examples ready for re-use as listed below.\n\n\n\n\nImage Classification\n: This example illustrates how to do the image classification with pre-trained model.\n\n\nObject Detection\n: This example illustrates how to detect objects in image with pre-trained model.\n\n\nRecommendation\n: There are two Scala examples for recommender models, including wide and deep(WND) model and Neural network-based Collaborative Filtering(NCF) model.\n\n\nText Classification\n: This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU \nTextClassifier\n model on 20 Newsgroup dataset\n\n\nDataFrame\n: There are three examples to show how to perform transfer learning/model inference using pre-trained Inception v1 model with DataFrame-based API.\n\n\nTFNet\n: TFNet can encapsulate a frozen TensorFlow graph as an Analytics Zoo layer for inference. This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences using Analytics Zoo on Spark.\n\n\nQARanker\n: This example trains and evaluates a KNRM model on WikiQA dataset for ranking.\n\n\nAnomaly Detection\n: This example illustrates how to use LSTM to detect anomalies on NYC taxi passengers dataset.\n\n\nSeq2seq\n: This example illustrates how to train a seq2seq model and generate answer for a given query with a seq2seq model using Analytics Zoo on Spark.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/", 
            "text": "Overview\n\n\nNNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.\n\n\nHighlights\n\n\n\n\n\n\nEasy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.\n\n\n\n\n\n\nEffortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.\n\n\n\n\n\n\nIn a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.\n\n\n\n\n\n\nTraining of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).\n\n\n\n\n\n\nRich toolset for feature extraction and processing, including image, audio and texts.\n\n\n\n\n\n\nExamples:\n\n\nThe examples are included in the Analytics Zoo source code.\n\n\n\n\nimage classification: model inference using pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\nimage classification: transfer learning from pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\n\n\nPrimary APIs\n\n\nNNEstimator and NNModel\n\n\nAnalytics Zoo provides \nNNEstimator\n for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark\n\nEstimator\n/\n\nTransfomer\n\npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of\n\nNNEstimator\n is a NNModel, which is a Spark ML Transformer.\n\n\nplease check our\n\nNNEstimator API\n for detailed usage.\n\n\nNNClassifier and NNClassifierModel\n\n\nNNClassifier\n and \nNNClassifierModel\nextends \nNNEstimator\n and \nNNModel\n and focus on \nclassification tasks, where both label column and prediction column are of Double type.\n\n\nNNImageReader\n\nNNImageReader loads image into Spark DataFrame.\n\n\nplease check our\n\nImageProcessing\n for detailed usage.", 
            "title": "DataFrame and ML Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#overview", 
            "text": "NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.  Highlights    Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.    Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.    In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.    Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).    Rich toolset for feature extraction and processing, including image, audio and texts.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#examples", 
            "text": "The examples are included in the Analytics Zoo source code.   image classification: model inference using pre-trained Inception v1 model.\n     Scala version \n     Python version  image classification: transfer learning from pre-trained Inception v1 model.\n     Scala version \n     Python version", 
            "title": "Examples:"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#primary-apis", 
            "text": "NNEstimator and NNModel  Analytics Zoo provides  NNEstimator  for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer \npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator  is a NNModel, which is a Spark ML Transformer.  please check our NNEstimator API  for detailed usage.  NNClassifier and NNClassifierModel  NNClassifier  and  NNClassifierModel extends  NNEstimator  and  NNModel  and focus on \nclassification tasks, where both label column and prediction column are of Double type.  NNImageReader \nNNImageReader loads image into Spark DataFrame.  please check our ImageProcessing  for detailed usage.", 
            "title": "Primary APIs"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/", 
            "text": "Overview\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustracted below. (See more examples \nhere\n). Conceptually we use reverse mode together with the chain rule for automatic differentiation. \nVariable\n is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input \nvariables\n and roots are the output \nvariables\n.\n\n\nCustomLoss\n\n\n1.Define a custom function using \nautograd\n\n\nfrom zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)\n\n\n\n\n\n\nUse \nCustomLoss\n in \ncompile\n method.\n\n\n\n\n# You can pass the loss function directly into `loss`\nmodel.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)\n\n\n\n\n\n\nUse \nCustomLoss\n in \nnnframe\n pipeline.\n\n\n\n\n# 1) Create a CustomLoss object from function.\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\n# 2) Passing the CustomLoss object to NNClassifier.\nclassifier = NNClassifier(lrModel, loss, SeqToTensor([1000]))\n\n\n\n\n\n\nUse \nforward\n and \nbackward\n to evaluate a \nCustomLoss\n for debugging.\n\n\n\n\n# y_pred_shape=[2] is a shape without batch\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\nerror = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\ngrad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\n\n\n\n\nLambda layer\n\n\n1.Define custom function using \nautograd\n\n\nfrom zoo.pipeline.api.autograd import *\ndef add_one_func(x):\n   return x + 1.0\n\n\n\n\n2.Define model using Keras-style API and \ncustom \nLambda\n layer\n\n\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size\n\n\n\n\n\nConstruct variable computation without \nLambda\n layer\n\n\n\n\nThe returning type for each operation is a \nVariable\n, so you can connect those \nVariable\n together freely without using \nLambda\n. i.e \nDense[Float](3).from(input2)\n or \ninput1 + input2\n\n\nShape inference is supported as well, which means you can check the output shape of a \nVariable\n by calling \nget_output_shape()\n\n\n\n\nPython\n\n\nimport zoo.pipeline.api.autograd as auto\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\ninput = Input(shape=[2, 20]) # create a variable\ntime = TimeDistributed(layer=Dense(30))(input) # time is a variable\nt1 = time.index_select(1, 0) # t1 is a variable\nt2 = time.index_select(1, 1)\ndiff = auto.abs(t1 - t2)\nassert diff.get_output_shape() == (None, 30)\nassert diff.get_input_shape() == (None, 30)\nmodel = Model(input, diff)\ndata = np.random.uniform(0, 1, [10, 2, 20])\noutput = model.forward(data)\n\n\n\n\nScala\n- In respect of backward compatibility, the scala API is slightly different with the python API.\n- \nlayer.inputs(node)\n would return a node(backward compatibility).\n- \nlayer.from(variable)\n would return a variable.(You may want to use this style as it can support autograd.)\n\n\nimport com.intel.analytics.zoo.pipeline.api.autograd.Variable\nimport com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\n\nval input1 = Variable[Float](inputShape = Shape(3))\nval input2 = Variable[Float](inputShape = Shape(3))\nval diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2))\nval model = Model[Float](input = Array(input1, input2), output = diff)\nval inputValue = Tensor[Float](1, 3).randn()\n// In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table.\nval out = model.forward(T(inputValue, inputValue)).toTensor[Float]\n\n\n\n\nDefine a model using trainable Parameter\n\n\nBuild a \nLinear\n Model (Wx + b) by using trainable \nParameter\n which is equivalent to use \nDense\n layer.\n* Scala\n\n\nimport com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nval input = Variable[Float](Shape(3))\nval w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize\nval bias = Parameter[Float](Shape(2))\nval cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias\nval model = Model[Float](input = input, output = cDense)\n\n\n\n\n\n\n\nPython\n\n\n\n\nfrom zoo.pipeline.api.autograd import *\nfrom zoo.pipeline.api.keras.models import *\ninput = Variable((3,))\nw = Parameter((2, 3)) # outputSize * inputSize\nbias = Parameter((2,))\ncDense = mm(input, w, axes = (1, 1)) + bias\nmodel = Model(input = input, output = cDense)", 
            "title": "Autograd"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#overview", 
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustracted below. (See more examples  here ). Conceptually we use reverse mode together with the chain rule for automatic differentiation.  Variable  is used to record the linkage of the operation history, which would generated a static directed acyclic graph for the backward execution. Within the execution graph, leaves are the input  variables  and roots are the output  variables .", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#customloss", 
            "text": "1.Define a custom function using  autograd  from zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)   Use  CustomLoss  in  compile  method.   # You can pass the loss function directly into `loss`\nmodel.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)   Use  CustomLoss  in  nnframe  pipeline.   # 1) Create a CustomLoss object from function.\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\n# 2) Passing the CustomLoss object to NNClassifier.\nclassifier = NNClassifier(lrModel, loss, SeqToTensor([1000]))   Use  forward  and  backward  to evaluate a  CustomLoss  for debugging.   # y_pred_shape=[2] is a shape without batch\nloss = CustomLoss(mean_absolute_error, y_pred_shape=[2], y_true_shape=[2])\nerror = loss.forward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))\ngrad = loss.backward(y_true=np.random.uniform(0, 1, shape[3, 2]), y_pred=np.random.uniform(0, 1, shape[3, 2]))", 
            "title": "CustomLoss"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#lambda-layer", 
            "text": "1.Define custom function using  autograd  from zoo.pipeline.api.autograd import *\ndef add_one_func(x):\n   return x + 1.0  2.Define model using Keras-style API and  custom  Lambda  layer  from zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size", 
            "title": "Lambda layer"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#construct-variable-computation-without-lambda-layer", 
            "text": "The returning type for each operation is a  Variable , so you can connect those  Variable  together freely without using  Lambda . i.e  Dense[Float](3).from(input2)  or  input1 + input2  Shape inference is supported as well, which means you can check the output shape of a  Variable  by calling  get_output_shape()   Python  import zoo.pipeline.api.autograd as auto\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\ninput = Input(shape=[2, 20]) # create a variable\ntime = TimeDistributed(layer=Dense(30))(input) # time is a variable\nt1 = time.index_select(1, 0) # t1 is a variable\nt2 = time.index_select(1, 1)\ndiff = auto.abs(t1 - t2)\nassert diff.get_output_shape() == (None, 30)\nassert diff.get_input_shape() == (None, 30)\nmodel = Model(input, diff)\ndata = np.random.uniform(0, 1, [10, 2, 20])\noutput = model.forward(data)  Scala\n- In respect of backward compatibility, the scala API is slightly different with the python API.\n-  layer.inputs(node)  would return a node(backward compatibility).\n-  layer.from(variable)  would return a variable.(You may want to use this style as it can support autograd.)  import com.intel.analytics.zoo.pipeline.api.autograd.Variable\nimport com.intel.analytics.zoo.pipeline.api.autograd.AutoGrad\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\n\nval input1 = Variable[Float](inputShape = Shape(3))\nval input2 = Variable[Float](inputShape = Shape(3))\nval diff = AutoGrad.abs(input1 - Dense[Float](3).from(input2))\nval model = Model[Float](input = Array(input1, input2), output = diff)\nval inputValue = Tensor[Float](1, 3).randn()\n// In scala, we use Table for multiple inputs. `T` is a short-cut for creating a Table.\nval out = model.forward(T(inputValue, inputValue)).toTensor[Float]", 
            "title": "Construct variable computation without Lambda layer"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#define-a-model-using-trainable-parameter", 
            "text": "Build a  Linear  Model (Wx + b) by using trainable  Parameter  which is equivalent to use  Dense  layer.\n* Scala  import com.intel.analytics.zoo.pipeline.api.autograd.{AutoGrad, Parameter, Variable}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nval input = Variable[Float](Shape(3))\nval w = Parameter[Float](Shape(2, 3)) // outputSize * inputSize\nval bias = Parameter[Float](Shape(2))\nval cDense = AutoGrad.mm(input, w, axes = List(1, 1)) + bias\nval model = Model[Float](input = input, output = cDense)   Python   from zoo.pipeline.api.autograd import *\nfrom zoo.pipeline.api.keras.models import *\ninput = Variable((3,))\nw = Parameter((2, 3)) # outputSize * inputSize\nbias = Parameter((2,))\ncDense = mm(input, w, axes = (1, 1)) + bias\nmodel = Model(input = input, output = cDense)", 
            "title": "Define a model using trainable Parameter"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/", 
            "text": "Overview\n\n\nAnalytics Zoo provides some useful utilities for transfer learning.\n\n\nLoading a pre-trained model\n\n\nWe can use the \nNet\n api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to \nNet API Guide\n\n\nRemove the last a few layers\n\n\nWhen a model is loaded using \nNet\n, we can use the \nnewGraph(output)\n api to define a Model with\nthe output specified by the parameter.\n\n\nFor example, \n\n\nIn scala:\n\n\nval inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output = \npool5/drop_7x7_s1\n)\n\n\n\n\n\nIn python:\n\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\nThe returning model's output layer is \"pool5/drop_7x7_s1\".\n\n\nFreeze some layers\n\n\nIn transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the \nfreezeUpTo(endPoint)\n api to do that.\n\n\nFor example,\n\n\nIn scala:\n\n\ninception.freezeUpTo(\npool4/3x3_s2\n) // freeze layer pool4/3x3_s2 and the layers before it\n\n\n\n\nIn python:\n\n\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\nThis will freeze all the layers from the input layer to \"pool4/3x3_s2\"\n\n\nExample\n\n\nFor a complete example, refer to the \nscala transfer learning example\n\nand \npython transfer learning example", 
            "title": "Transfer Learning"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#overview", 
            "text": "Analytics Zoo provides some useful utilities for transfer learning.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#loading-a-pre-trained-model", 
            "text": "We can use the  Net  api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to  Net API Guide", 
            "title": "Loading a pre-trained model"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#remove-the-last-a-few-layers", 
            "text": "When a model is loaded using  Net , we can use the  newGraph(output)  api to define a Model with\nthe output specified by the parameter.  For example,   In scala:  val inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output =  pool5/drop_7x7_s1 )  In python:  full_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])  The returning model's output layer is \"pool5/drop_7x7_s1\".", 
            "title": "Remove the last a few layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#freeze-some-layers", 
            "text": "In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the  freezeUpTo(endPoint)  api to do that.  For example,  In scala:  inception.freezeUpTo( pool4/3x3_s2 ) // freeze layer pool4/3x3_s2 and the layers before it  In python:  # freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])  This will freeze all the layers from the input layer to \"pool4/3x3_s2\"", 
            "title": "Freeze some layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#example", 
            "text": "For a complete example, refer to the  scala transfer learning example \nand  python transfer learning example", 
            "title": "Example"
        }, 
        {
            "location": "/ProgrammingGuide/inference/", 
            "text": "Inference Model\n\n\nOverview\n\n\nInference is a package in Analytics Zoo aiming to provide high level APIs to speed-up development. It \nallows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\nInference provides multiple Scala interfaces.\n\n\nHighlights\n\n\n\n\n\n\nEasy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\n\n\n\n\n\n\nSupport transformation of various input data type, thus supporting future prediction tasks.\n\n\n\n\n\n\nTransparently support the OpenVINO toolkit, which deliver a significant boost for inference speed (\nup to 19.9x\n).\n\n\n\n\n\n\nJava Example\n\n\nIt's very easy to apply abstract inference model for inference with below code piece.\nYou will need to write a subclass that extends AbstractinferenceModel.\n\n\nimport com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n }\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\nList\nList\nJTensor\n result = model.predict(inputList);\n\n\n\n\nScala Example\n\n\nimport com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nclass TextClassificationModel extends InferenceModel {\n\n}\n\nval model = new TextClassificationModel()\nmodel.doLoad(modelPath, weightPath)\nval result = model.doPredict(inputList)", 
            "title": "Model Serving"
        }, 
        {
            "location": "/ProgrammingGuide/inference/#inference-model", 
            "text": "", 
            "title": "Inference Model"
        }, 
        {
            "location": "/ProgrammingGuide/inference/#overview", 
            "text": "Inference is a package in Analytics Zoo aiming to provide high level APIs to speed-up development. It \nallows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\nInference provides multiple Scala interfaces.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/inference/#highlights", 
            "text": "Easy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).    Support transformation of various input data type, thus supporting future prediction tasks.    Transparently support the OpenVINO toolkit, which deliver a significant boost for inference speed ( up to 19.9x ).", 
            "title": "Highlights"
        }, 
        {
            "location": "/ProgrammingGuide/inference/#java-example", 
            "text": "It's very easy to apply abstract inference model for inference with below code piece.\nYou will need to write a subclass that extends AbstractinferenceModel.  import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n }\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\nList List JTensor  result = model.predict(inputList);", 
            "title": "Java Example"
        }, 
        {
            "location": "/ProgrammingGuide/inference/#scala-example", 
            "text": "import com.intel.analytics.zoo.pipeline.inference.InferenceModel\n\nclass TextClassificationModel extends InferenceModel {\n\n}\n\nval model = new TextClassificationModel()\nmodel.doLoad(modelPath, weightPath)\nval result = model.doPredict(inputList)", 
            "title": "Scala Example"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/", 
            "text": "Analytics-Zoo provides a set APIs for running TensorFlow model on Spark in a distributed fashion.\n\n\nSystem Requirement\n\n\nTensorFlow version: 1.10\n\n\nOS version (all 64-bit): \nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n, \nWindows 7 or later\n (TensorFlow is\n only tested and supported on these 64-bit systems as stated \nhere\n).\n\n\nTo run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found \nhere\n.\n\n\nConcepts\n\n\n\n\n\n\nTFDatasets\n represents a distributed collection of elements to be fed into a TensorFlow graph.\nTFDatasets can be created directly from an RDD; each record in the RDD should be a list of numpy.ndarray\nrepresenting the input data. TFDatasets must be used with the TFOptimizer or TFPredictor (to be described next).\n\n\n\n\n\n\nTFOptimizer\n is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. It takes the user specified \nloss\n (a TensorFlow scalar tensor) as\nan argument and runs stochastic gradient descent using the given \noptimMethod\n on all the \nVariables\n that\ncontribute to this loss.\n\n\n\n\n\n\nTFPredictor\n takes a list of user specified TensorFlow tensors as the model outputs, and feed all the\nelements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the\nmodel prediction for the corresponding input elements.\n\n\n\n\n\n\nTraining\n\n\n1.Data wrangling and analysis using PySpark\n\n\nfrom zoo import init_nncontext\nfrom zoo.pipeline.api.net import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             names=[\nfeatures\n, \nlabels\n],\n                             shapes=[[28, 28, 1], [1]],\n                             types=[tf.float32, tf.int32],\n                             batch_size=BATCH_SIZE)\n\n\n\n\n2.Deep learning model development using TensorFlow\n\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nsqueezed_labels = tf.squeeze(labels)\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels))\n\n\n\n\nYou can also construct your model using Keras provided by Tensorflow.\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\n\n\n\n3.Distributed training on Spark and BigDL\n\n\nfrom zoo.pipeline.api.net import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.set_train_summary(TrainSummary(\n/tmp/az_lenet\n, \nlenet\n))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nFor Keras model:\n\n\nfrom zoo.pipeline.api.net import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset)\noptimizer.set_train_summary(TrainSummary(\n/tmp/az_lenet\n, \nlenet\n))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\n4.Save the variable to checkpoint\n\n\nsaver = tf.train.Saver()\nsaver.save(optimizer.sess, \n/tmp/lenet/\n)\n\n\n\n\nFor Keras model, you can also Keras' \nsave_weights\n api.\n\n\nmodel.save_weights(\n/tmp/keras.h5\n)\n\n\n\n\nInference\n\n\n1.Data processing using PySpark\n\n\nfrom zoo import init_nncontext\nfrom zoo.pipeline.api.net import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntesting_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(testing_rdd,\n                             names=[\nfeatures\n],\n                             shapes=[[28, 28, 1]],\n                             types=[tf.float32])\n\n\n\n\n2.Reconstruct the model for inference and load the checkpoint\n\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \n/tmp/lenet\n)\n\n\n\n\nAs before, you can also construct and restore your model using Keras provided by Tensorflow.\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.load_weights(\n/tmp/mnist_keras.h5\n)\n\n\n\n\n\n3.Run predictions\n\n\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()\n\n\n\n\nFor keras model:\n\n\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()\n\n\n\n\nRelationship to TFNet\n\n\nTFNet\n is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors).\nIt implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers\nto construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API. \n\n\nYou can think of \nTFDatasets\n, \nTFOptimizer\n, \nTFPredictor\n as a set API for training/testing TensorFlow models\non Spark/BigDL, while \nTFNet\n as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph.\n\n\nFor more information on TFNet, please refer to the \nAPI Guide", 
            "title": "Distributed Tensoflow on Spark/BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/#system-requirement", 
            "text": "TensorFlow version: 1.10  OS version (all 64-bit):  Ubuntu 16.04 or later ,  macOS 10.12.6 or later ,  Windows 7 or later  (TensorFlow is\n only tested and supported on these 64-bit systems as stated  here ).  To run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found  here .", 
            "title": "System Requirement"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/#concepts", 
            "text": "TFDatasets  represents a distributed collection of elements to be fed into a TensorFlow graph.\nTFDatasets can be created directly from an RDD; each record in the RDD should be a list of numpy.ndarray\nrepresenting the input data. TFDatasets must be used with the TFOptimizer or TFPredictor (to be described next).    TFOptimizer  is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. It takes the user specified  loss  (a TensorFlow scalar tensor) as\nan argument and runs stochastic gradient descent using the given  optimMethod  on all the  Variables  that\ncontribute to this loss.    TFPredictor  takes a list of user specified TensorFlow tensors as the model outputs, and feed all the\nelements in TFDatasets to produce those outputs; it returns a Spark RDD with each of its records representing the\nmodel prediction for the corresponding input elements.", 
            "title": "Concepts"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/#training", 
            "text": "1.Data wrangling and analysis using PySpark  from zoo import init_nncontext\nfrom zoo.pipeline.api.net import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntrain_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(train_rdd,\n                             names=[ features ,  labels ],\n                             shapes=[[28, 28, 1], [1]],\n                             types=[tf.float32, tf.int32],\n                             batch_size=BATCH_SIZE)  2.Deep learning model development using TensorFlow  import tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nsqueezed_labels = tf.squeeze(labels)\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n\nloss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=squeezed_labels))  You can also construct your model using Keras provided by Tensorflow.  from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])  3.Distributed training on Spark and BigDL  from zoo.pipeline.api.net import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, Adam, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.set_train_summary(TrainSummary( /tmp/az_lenet ,  lenet ))\noptimizer.optimize(end_trigger=MaxEpoch(5))  For Keras model:  from zoo.pipeline.api.net import TFOptimizer\nfrom bigdl.optim.optimizer import MaxIteration, MaxEpoch, TrainSummary\n\noptimizer = TFOptimizer.from_keras(keras_model=model, dataset=dataset)\noptimizer.set_train_summary(TrainSummary( /tmp/az_lenet ,  lenet ))\noptimizer.optimize(end_trigger=MaxEpoch(5))  4.Save the variable to checkpoint  saver = tf.train.Saver()\nsaver.save(optimizer.sess,  /tmp/lenet/ )  For Keras model, you can also Keras'  save_weights  api.  model.save_weights( /tmp/keras.h5 )", 
            "title": "Training"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/#inference", 
            "text": "1.Data processing using PySpark  from zoo import init_nncontext\nfrom zoo.pipeline.api.net import TFDataset\nfrom tensorflow as tf\n\nsc = init_nncontext()\n\n# Each record in the train_rdd consists of a list of NumPy ndrrays\ntesting_rdd = sc.parallelize(file_list)\n  .map(lambda x: read_image_and_label(x))\n  .map(lambda image_label: decode_to_ndarrays(image_label))\n\n# TFDataset represents a distributed set of elements,\n# in which each element contains one or more TensorFlow Tensor objects. \ndataset = TFDataset.from_rdd(testing_rdd,\n                             names=[ features ],\n                             shapes=[[28, 28, 1]],\n                             types=[tf.float32])  2.Reconstruct the model for inference and load the checkpoint  import tensorflow as tf\n\nslim = tf.contrib.slim\n\nimages, labels = dataset.tensors\nwith slim.arg_scope(lenet.lenet_arg_scope()):\n     logits, end_points = lenet.lenet(images, num_classes=10, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess,  /tmp/lenet )  As before, you can also construct and restore your model using Keras provided by Tensorflow.  from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\n\ndata = Input(shape=[28, 28, 1])\n\nx = Flatten()(data)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=data, outputs=predictions)\n\nmodel.load_weights( /tmp/mnist_keras.h5 )  3.Run predictions  predictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()  For keras model:  predictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()", 
            "title": "Inference"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow/#relationship-to-tfnet", 
            "text": "TFNet  is a layer representing a TensorFlow sub-graph (specified by the input and output TensorFlow tensors).\nIt implements the standard BigDL layer API, and can be used with other Analytics-Zoo/BigDL layers\nto construct more complex models for training or inference using the standard Analytics-Zoo/BigDL API.   You can think of  TFDatasets ,  TFOptimizer ,  TFPredictor  as a set API for training/testing TensorFlow models\non Spark/BigDL, while  TFNet  as an Analytics-Zoo/BigDL layer initialized using TensorFlow graph.  For more information on TFNet, please refer to the  API Guide", 
            "title": "Relationship to TFNet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/", 
            "text": "Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nAnalytics Zoo can process image data as Spark Data Frame.\n\nNNImageReader\n is the primary DataFrame-based image loading interface to read images into DataFrame.\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext(\napp\n)\nval imageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nval imageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nval imageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\n\nPython:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext(\napp\n)\nimageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nimageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nimageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.\n\n\nLoad to ImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\n// create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython example:\n\n\n# create LocalImageSet from an image folder\nlocal_image_frame2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageSet from an image folder\ndistributed_image_frame = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo has many pre-defined image processing transformers built on top of OpenCV:\n\n\n\n\nImageBrightness\n: Adjust the image brightness.\n\n\nImageHue\n: Adjust the image hue.\n\n\nImageSaturation\n: Adjust the image Saturation.\n\n\nImageContrast\n: Adjust the image Contrast.\n\n\nImageChannelOrder\n: Random change the channel order of an image\n\n\nImageColorJitter\n: Random adjust brightness, contrast, hue, saturation\n\n\nImageResize\n: Resize image\n\n\nImageAspectScale\n: Resize the image, keep the aspect ratio. scale according to the short edge\n\n\nImageRandomAspectScale\n: Resize the image by randomly choosing a scale\n\n\nImageChannelNormalize\n: Image channel normalize\n\n\nImagePixelNormalizer\n: Pixel level normalizer\n\n\nImageCenterCrop\n: Crop a \ncropWidth\n x \ncropHeight\n patch from center of image.\n\n\nImageRandomCrop\n: Random crop a \ncropWidth\n x \ncropHeight\n patch from an image.\n\n\nImageFixedCrop\n: Crop a fixed area of image\n\n\nImageDetectionCrop\n: Crop from object detections, each image should has a tensor detection,\n\n\nImageExpand\n: Expand image, fill the blank part with the meanR, meanG, meanB\n\n\nImageFiller\n: Fill part of image with certain pixel value\n\n\nImageHFlip\n: Flip the image horizontally\n\n\nImageRandomPreprocessing\n: It is a wrapper for transformers to control the transform probability\n\n\nImageBytesToMat\n: Transform byte array(original image file in byte) to OpenCVMat\n\n\nImageMatToFloats\n: Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n\n\nImageMatToTensor\n: Transform opencv mat to tensor, note that in this transformer, the mat is released.\n\n\nImageSetToSample\n: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.\n\n\n\n\nMore examples can be found \nhere\n\n\nYou can also define your own Transformer by extending \nImageProcessing\n,\nand override the function \ntransformMat\n to do the actual transformation to \nImageFeature\n.\n\n\nBuild Image Transformation Pipeline\n\n\nYou can easily build the image transformation pipeline by chaining transformers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -\n ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n             ImageChannelNormalize(123, 117, 104) -\n\n             ImageMatToTensor[Float]() -\n\n             ImageSetToSample[Float]()\n\n\n\n\nIn the above example, the transformations will perform sequentially.\n\n\nAssume you have an ImageSet containing original bytes array,\n\n\n\n\n\n\nImageBytesToMat\n will transform the bytes array to \nOpenCVMat\n.\n\n\n\n\n\n\nImageColorJitter\n, \nImageExpand\n, \nImageResize\n, \nImageHFlip\n and \nImageChannelNormalize\n will transform over \nOpenCVMat\n,\nnote that \nOpenCVMat\n is overwrite by default.\n\n\n\n\n\n\nImageMatToTensor\n transform \nOpenCVMat\n to \nTensor\n, and \nOpenCVMat\n is released in this step.\n\n\n\n\n\n\nImageSetToSample\n transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.\n\n\n\n\n\n\nPython example:\n\n\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.feature.common import ChainedPreprocessing\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])\n\n\n\n\nImage Train\n\n\nTrain with Image DataFrame\n\n\nYou can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call \nfit\n method to let Analytics Zoo train the model\n\n\nFor detail APIs, please refer to: \nNNFrames\n\n\nScala example:\n\n\nval batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                   ImageCenterCrop(224, 224) -\n\n                                   ImageChannelNormalize(123, 117, 104) -\n\n                                   ImageMatToTensor() -\n\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\nimage\n)\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n\n\n\n\nPython example:\n\n\nbatchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\nimage\n)\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\n\n\nTrain with ImageSet\n\n\nYou can train Zoo Keras model with ImageSet. Just call \nfit\n method to let Analytics Zoo train the model.\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\ntrain keras\n)\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\n\n\n\n\nImage Predict\n\n\nPredict with Image DataFrame\n\n\nAfter training with \nNNEstimator/NNCLassifier\n, you'll get a trained \nNNModel/NNClassifierModel\n . You can call \ntransform\n to predict Image DataFrame with this \nNNModel/NNClassifierModel\n . Or you can load pre-trained \nAnalytics-Zoo/BigDL/Caffe/Torch/Tensorflow\n  model and create \nNNModel/NNClassifierModel\n with this model. Then call to \ntransform\n to Image DataFrame.\n\n\nAfter prediction, there is a new column \nprediction\n in the prediction image dataframe.\n\n\nScala example:\n\n\n val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                    ImageCenterCrop(224, 224) -\n\n                                    ImageChannelNormalize(123, 117, 104) -\n\n                                    ImageMatToTensor() -\n\n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n         .setFeaturesCol(\nimage\n)\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col(\nimage\n), col(\nlabel\n), col(\nprediction\n)).show(false)\n\n // predict with loaded pre-trained model\n val model = Module.loadModule[Float](modelPath)\n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol(\nimage\n)\n         .setPredictionCol(\nprediction\n) \n val resultDF = dlmodel.transform(testDf)\n\n\n\n\nPython example:\n\n\n batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol(\nimage\n)\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n# predict with trained model\npredictions = trainedModel.transform(testDf)\npredictions.select(\nimage\n, \nlabel\n,\nprediction\n).show(False)\n\n# predict with loaded pre-trained model\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\nimage\n)\\\n         .setPredictionCol(\nprediction\n) \nresultDF = dlmodel.transform(testDf)\n\n\n\n\nPredict with ImageSet\n\n\nAfter training Zoo Keras model, you can call \npredict\n to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nPredict with trained Zoo Keras Model\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(\ntrain keras\n)\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()\n\n\n\n\nPredict with loaded Model\n\n\nYou can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nFor details, you can check guide of \nimage classificaion\n or \nobject detection\n\n\n3D Image Support\n\n\nFor 3D images, we can support above operations based on ImageSet. For details, please refer to \nimage API guide\n\n\nCaching Images in Persistent Memory\n\n\nHere is a scala \nexample\n to train Inception V1 with ImageNet-2012 dataset. If you set the option \nmemoryType\n to \nPMEM\n, the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide \nhere\n on how to set up the system environment.\n\n\nIn the InceptionV1 example, we use an new dataset called \nFeatureSet\n to cache the data. Only scala API is currently available.\n\n\nScala example:\n\n\nscala\n val rawData = readFromSeqFiles(path, sc, classNumber)\n val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM)\n\n \nreadFromSeqFiles\n read the Sequence File into \nRDD[ByteRecord]\n, then \nFeatureSet.rdd(rawData, memoryType = PMEM)\n will cache the data to Intel Optane DC Persistent Memory.", 
            "title": "Working with Images"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-data-frame", 
            "text": "Analytics Zoo can process image data as Spark Data Frame. NNImageReader  is the primary DataFrame-based image loading interface to read images into DataFrame.  Scala example:  import com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext( app )\nval imageDF1 = NNImageReader.readImages( /tmp , sc)\nval imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nval imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  Python:  from zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext( app )\nimageDF1 = NNImageReader.readImages( /tmp , sc)\nimageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nimageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  // create LocalImageSet from an image folder\nval localImageSet = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2)  Python example:  # create LocalImageSet from an image folder\nlocal_image_frame2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageSet from an image folder\ndistributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "Load to ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-transformer", 
            "text": "Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV:   ImageBrightness : Adjust the image brightness.  ImageHue : Adjust the image hue.  ImageSaturation : Adjust the image Saturation.  ImageContrast : Adjust the image Contrast.  ImageChannelOrder : Random change the channel order of an image  ImageColorJitter : Random adjust brightness, contrast, hue, saturation  ImageResize : Resize image  ImageAspectScale : Resize the image, keep the aspect ratio. scale according to the short edge  ImageRandomAspectScale : Resize the image by randomly choosing a scale  ImageChannelNormalize : Image channel normalize  ImagePixelNormalizer : Pixel level normalizer  ImageCenterCrop : Crop a  cropWidth  x  cropHeight  patch from center of image.  ImageRandomCrop : Random crop a  cropWidth  x  cropHeight  patch from an image.  ImageFixedCrop : Crop a fixed area of image  ImageDetectionCrop : Crop from object detections, each image should has a tensor detection,  ImageExpand : Expand image, fill the blank part with the meanR, meanG, meanB  ImageFiller : Fill part of image with certain pixel value  ImageHFlip : Flip the image horizontally  ImageRandomPreprocessing : It is a wrapper for transformers to control the transform probability  ImageBytesToMat : Transform byte array(original image file in byte) to OpenCVMat  ImageMatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released.  ImageMatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released.  ImageSetToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.   More examples can be found  here  You can also define your own Transformer by extending  ImageProcessing ,\nand override the function  transformMat  to do the actual transformation to  ImageFeature .", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#build-image-transformation-pipeline", 
            "text": "You can easily build the image transformation pipeline by chaining transformers.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -  ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n             ImageChannelNormalize(123, 117, 104) - \n             ImageMatToTensor[Float]() - \n             ImageSetToSample[Float]()  In the above example, the transformations will perform sequentially.  Assume you have an ImageSet containing original bytes array,    ImageBytesToMat  will transform the bytes array to  OpenCVMat .    ImageColorJitter ,  ImageExpand ,  ImageResize ,  ImageHFlip  and  ImageChannelNormalize  will transform over  OpenCVMat ,\nnote that  OpenCVMat  is overwrite by default.    ImageMatToTensor  transform  OpenCVMat  to  Tensor , and  OpenCVMat  is released in this step.    ImageSetToSample  transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.    Python example:  from zoo.feature.image.imagePreprocessing import *\nfrom zoo.feature.common import ChainedPreprocessing\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])", 
            "title": "Build Image Transformation Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-train", 
            "text": "", 
            "title": "Image Train"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-image-dataframe", 
            "text": "You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call  fit  method to let Analytics Zoo train the model  For detail APIs, please refer to:  NNFrames  Scala example:  val batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                   ImageCenterCrop(224, 224) - \n                                   ImageChannelNormalize(123, 117, 104) - \n                                   ImageMatToTensor() - \n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol( image )\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)  Python example:  batchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol( image )\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)", 
            "title": "Train with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-imageset", 
            "text": "You can train Zoo Keras model with ImageSet. Just call  fit  method to let Analytics Zoo train the model.  Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext( train keras )\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)", 
            "title": "Train with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-predict", 
            "text": "", 
            "title": "Image Predict"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-image-dataframe", 
            "text": "After training with  NNEstimator/NNCLassifier , you'll get a trained  NNModel/NNClassifierModel  . You can call  transform  to predict Image DataFrame with this  NNModel/NNClassifierModel  . Or you can load pre-trained  Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow   model and create  NNModel/NNClassifierModel  with this model. Then call to  transform  to Image DataFrame.  After prediction, there is a new column  prediction  in the prediction image dataframe.  Scala example:   val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                    ImageCenterCrop(224, 224) - \n                                    ImageChannelNormalize(123, 117, 104) - \n                                    ImageMatToTensor() - \n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n         .setFeaturesCol( image )\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col( image ), col( label ), col( prediction )).show(false)\n\n // predict with loaded pre-trained model\n val model = Module.loadModule[Float](modelPath)\n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol( image )\n         .setPredictionCol( prediction ) \n val resultDF = dlmodel.transform(testDf)  Python example:   batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol( image )\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n# predict with trained model\npredictions = trainedModel.transform(testDf)\npredictions.select( image ,  label , prediction ).show(False)\n\n# predict with loaded pre-trained model\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol( image )\\\n         .setPredictionCol( prediction ) \nresultDF = dlmodel.transform(testDf)", 
            "title": "Predict with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-imageset", 
            "text": "After training Zoo Keras model, you can call  predict  to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.", 
            "title": "Predict with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-zoo-keras-model", 
            "text": "Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext( train keras )\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()", 
            "title": "Predict with trained Zoo Keras Model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-model", 
            "text": "You can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.  For details, you can check guide of  image classificaion  or  object detection", 
            "title": "Predict with loaded Model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#3d-image-support", 
            "text": "For 3D images, we can support above operations based on ImageSet. For details, please refer to  image API guide", 
            "title": "3D Image Support"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#caching-images-in-persistent-memory", 
            "text": "Here is a scala  example  to train Inception V1 with ImageNet-2012 dataset. If you set the option  memoryType  to  PMEM , the data will be cached in Intel Optane DC Persistent Memory; please refer to the guide  here  on how to set up the system environment.  In the InceptionV1 example, we use an new dataset called  FeatureSet  to cache the data. Only scala API is currently available.  Scala example:  scala\n val rawData = readFromSeqFiles(path, sc, classNumber)\n val featureSet = FeatureSet.rdd(rawData, memoryType = PMEM) \n  readFromSeqFiles  read the Sequence File into  RDD[ByteRecord] , then  FeatureSet.rdd(rawData, memoryType = PMEM)  will cache the data to Intel Optane DC Persistent Memory.", 
            "title": "Caching Images in Persistent Memory"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/", 
            "text": "Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline,\nincluding text loading, pre-processing, training and inference, etc.\n\n\n\n\nTextSet\n\n\nTextSet\n is a collection of TextFeatures where each \nTextFeature\n keeps information of a single text record.\n\n\nTextSet\n can either be a \nDistributedTextSet\n consisting of text RDD or a \nLocalTextSet\n consisting of text array.\n\n\n\n\nRead texts as TextSet\n\n\nRead texts from a directory\n\n\nRead texts with labels from a directory.\n\n\nUnder this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.\n\n\nScala\n\n\ntextSet = TextSet.read(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from csv file\n\n\nRead texts with id from csv file.\n\n\nEach record is supposed to contain id(String) and text(String) in order.\n\n\nNote that the csv file should be without header.\n\n\nScala\n\n\ntextSet = TextSet.readCSV(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_csv(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from parquet file\n\n\nRead texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.\n\n\nScala\n\n\ntextSet = TextSet.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.\n\n\n\n\n\n\nBuild Text Transformation Pipeline\n\n\nYou can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to \nhere\n for more details.\n\n\nScala Example\n\n\ntransformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample()\n\n\n\n\nPython Example\n\n\ntransformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample()\n\n\n\n\n\n\nText Training\n\n\nAfter doing text transformation, you can directly feed the transformed TextSet into the model for training.\n\n\nScala\n\n\nmodel.fit(transformedTextSet, batchSize, nbEpoch)\n\n\n\n\nPython\n\n\nmodel.fit(transformed_text_set, batch_size, nb_epoch)\n\n\n\n\n\n\nText Prediction\n\n\nYou can also directly input the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature.\n\n\nScala\n\n\npredictionTextSet = model.predict(transformedTextSet)\n\n\n\n\nPython\n\n\nprediction_text_set = model.predict(transformed_text_set)\n\n\n\n\n\n\nExamples\n\n\nYou can refer to our TextClassification example for TextSet transformation, training and inference.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.", 
            "title": "Working with Texts"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#textset", 
            "text": "TextSet  is a collection of TextFeatures where each  TextFeature  keeps information of a single text record.  TextSet  can either be a  DistributedTextSet  consisting of text RDD or a  LocalTextSet  consisting of text array.", 
            "title": "TextSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-as-textset", 
            "text": "", 
            "title": "Read texts as TextSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-a-directory", 
            "text": "Read texts with labels from a directory.  Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.  Scala  textSet = TextSet.read(path, sc = null, minPartitions = 1)   path : String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read(path, sc=None, min_partitions=1)   path : String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.", 
            "title": "Read texts from a directory"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-csv-file", 
            "text": "Read texts with id from csv file.  Each record is supposed to contain id(String) and text(String) in order.  Note that the csv file should be without header.  Scala  textSet = TextSet.readCSV(path, sc = null, minPartitions = 1)   path : String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read_csv(path, sc=None, min_partitions=1)   path : String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.", 
            "title": "Read texts from csv file"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#read-texts-from-parquet-file", 
            "text": "Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.  Scala  textSet = TextSet.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  text_set = TextSet.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.", 
            "title": "Read texts from parquet file"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#build-text-transformation-pipeline", 
            "text": "You can easily call transformation methods of a TextSet one by one to build the text transformation pipeline. Please refer to  here  for more details.  Scala Example  transformedTextSet = textSet.tokenize().normalize().word2idx().shapeSequence(len).generateSample()  Python Example  transformed_text_set = text_set.tokenize().normalize().word2idx().shape_sequence(len).generate_sample()", 
            "title": "Build Text Transformation Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#text-training", 
            "text": "After doing text transformation, you can directly feed the transformed TextSet into the model for training.  Scala  model.fit(transformedTextSet, batchSize, nbEpoch)  Python  model.fit(transformed_text_set, batch_size, nb_epoch)", 
            "title": "Text Training"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#text-prediction", 
            "text": "You can also directly input the transformed TextSet into the model for prediction and the prediction result will be stored in each TextFeature.  Scala  predictionTextSet = model.predict(transformedTextSet)  Python  prediction_text_set = model.predict(transformed_text_set)", 
            "title": "Text Prediction"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithtexts/#examples", 
            "text": "You can refer to our TextClassification example for TextSet transformation, training and inference.  See  here  for the Scala example.  See  here  for the Python example.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Apache Spark, Apache Storm or Apache Flink.\n\n\nObject Detection examples\n\n\nAnalytics Zoo provides two typical kind of pre-trained Object Detection models : \nSSD\n and \nFaster-RCNN\n on dataset \nPASCAL\n and \nCOCO\n. For the usage of these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nNote: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set \nimageCodec\n when loading images \nImageSet.read\n. See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples\n\n\nUsers can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) -\n\n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) -\n\n                         MatToTensor() -\n ImageFrameToSample()\nval output = model.predictImageset(data)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nDownload link\n\n\nPASCAL VOC models\n\n\n\n\nSSD 300x300 MobileNet\n\n\nSSD 300x300 VGG\n\n\nSSD 300x300 VGG Quantize\n\n\nSSD 512x512 VGG\n\n\nSSD 512x512 VGG Quantize\n\n\nFaster-RCNN VGG\n\n\nFaster-RCNN VGG Compress\n\n\nFaster-RCNN VGG Compress Quantize\n\n\nFaster-RCNN PvaNet\n\n\nFaster-RCNN PvaNet Compress\n\n\nFaster-RCNN PvaNet Compress Quantize\n\n\n\n\nCOCO models\n\n\n\n\nSSD 300x300 VGG\n\n\nSSD 300x300 VGG Quantize\n\n\nSSD 512x512 VGG\n\n\nSSD 512x512 VGG Quantize", 
            "title": "Object Detection API"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#object-detection-examples", 
            "text": "Analytics Zoo provides two typical kind of pre-trained Object Detection models :  SSD  and  Faster-RCNN  on dataset  PASCAL  and  COCO . For the usage of these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)  For preprocessors for Object Detection models, please check  Object Detection Config  Note: We expect the loaded images has 3 channels. If the channel is not 3(eg, gray/png images), please set  imageCodec  when loading images  ImageSet.read . See https://analytics-zoo.github.io/0.1.0/#ProgrammingGuide/object-detection/#object-detection-examples  Users can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) - \n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) - \n                         MatToTensor() -  ImageFrameToSample()\nval output = model.predictImageset(data)  Python  Python example  It's very easy to apply the model for inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)  For preprocessors for Object Detection models, please check  Object Detection Config", 
            "title": "Object Detection examples"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#download-link", 
            "text": "PASCAL VOC models   SSD 300x300 MobileNet  SSD 300x300 VGG  SSD 300x300 VGG Quantize  SSD 512x512 VGG  SSD 512x512 VGG Quantize  Faster-RCNN VGG  Faster-RCNN VGG Compress  Faster-RCNN VGG Compress Quantize  Faster-RCNN PvaNet  Faster-RCNN PvaNet Compress  Faster-RCNN PvaNet Compress Quantize   COCO models   SSD 300x300 VGG  SSD 300x300 VGG Quantize  SSD 512x512 VGG  SSD 512x512 VGG Quantize", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nImage Classification examples\n\n\nAnalytics Zoo provides several typical kind of pre-trained Image Classfication models : \nAlexnet\n, \nInception-V1\n, \nVGG\n, \nResnet\n, \nDensenet\n, \nMobilenet\n, \nSqueezenet\n models. To use these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n        ImageChannelNormalize(123, 117, 104) -\n\n        ImageMatToTensor[Float]() -\n\n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Image Classification models, please check \nImage Classification Config\n\n\nDownload link\n\n\n\n\nAlexnet\n\n\nAlexnet Quantize\n\n\nInception-V1\n\n\nInception-V1 Quantize\n\n\nInception-V3\n\n\nInception-V3 Quantize\n\n\nVGG-16\n\n\nVGG-16 Quantize\n\n\nVGG-19\n\n\nVGG-19 Quantize\n\n\nResnet-50\n\n\nResnet-50 Quantize\n\n\nResnet-50 Int8\n\n\nDensenet-161\n\n\nDensenet-161 Quantize\n\n\nMobilenet\n\n\nMobilenet-V2\n\n\nMobilenet-V2 Quantize\n\n\nSqueezenet\n\n\nSqueezenet Quantize", 
            "title": "Image Classification API"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#image-classification-examples", 
            "text": "Analytics Zoo provides several typical kind of pre-trained Image Classfication models :  Alexnet ,  Inception-V1 ,  VGG ,  Resnet ,  Densenet ,  Mobilenet ,  Squeezenet  models. To use these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)  User can also define his own configuration to do the inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n        ImageChannelNormalize(123, 117, 104) - \n        ImageMatToTensor[Float]() - \n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)  Python  Python example  It's very easy to apply the model for inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)  For preprocessors for Image Classification models, please check  Image Classification Config", 
            "title": "Image Classification examples"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#download-link", 
            "text": "Alexnet  Alexnet Quantize  Inception-V1  Inception-V1 Quantize  Inception-V3  Inception-V3 Quantize  VGG-16  VGG-16 Quantize  VGG-19  VGG-19 Quantize  Resnet-50  Resnet-50 Quantize  Resnet-50 Int8  Densenet-161  Densenet-161 Quantize  Mobilenet  Mobilenet-V2  Mobilenet-V2 Quantize  Squeezenet  Squeezenet Quantize", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/", 
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\n\n\nHighlights\n\n\n\n\nEasy-to-use Keras-Style defined models which provides compile and fit methods for training. Alternatively, they could be fed into NNFrames or BigDL Optimizer.\n\n\nThe encoders we support include CNN, LSTM and GRU.\n\n\n\n\n\n\nBuild a TextClassifier model\n\n\nYou can call the following API in Scala and Python respectively to create a \nTextClassifier\n with \npre-trained GloVe word embeddings as the first layer\n.\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \ncnn\n, encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\nembeddingFile\n The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\ncnn\n, encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\nembedding_file\n The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\n\n\nTrain a TextClassifier model\n\n\nAfter building the model, we can call compile and fit to train it (with validation).\n\n\nFor training and validation data, you can first read files as \nTextSet\n (see \nhere\n) and then do preprocessing (see \nhere\n).\n\n\nScala\n\n\nmodel.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy()))\nmodel.fit(trainSet, batchSize, nbEpoch, validateSet)\n\n\n\n\nPython\n\n\nmodel.compile(optimizer=Adagrad(learning_rate, loss=\nsparse_categorical_crossentropy\n, metrics=['accuracy'])\nmodel.fit(train_set, batch_size, nb_epoch, validate_set)\n\n\n\n\n\n\nDo prediction\n\n\nAfter training the model, it can be used to predict probability distributions.\n\n\nScala\n\n\nval predictSet = textClassifier.predict(validateSet)\n\n\n\n\nPython\n\n\npredict_set = text_classifier.predict(validate_set)\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.", 
            "title": "Text Classification API"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#build-a-textclassifier-model", 
            "text": "You can call the following API in Scala and Python respectively to create a  TextClassifier  with  pre-trained GloVe word embeddings as the first layer .  Scala  val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder =  cnn , encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  embeddingFile  The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex  Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   Python  text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  embedding_file  The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index  Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.", 
            "title": "Build a TextClassifier model"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#train-a-textclassifier-model", 
            "text": "After building the model, we can call compile and fit to train it (with validation).  For training and validation data, you can first read files as  TextSet  (see  here ) and then do preprocessing (see  here ).  Scala  model.compile(optimizer = new Adagrad(learningRate), loss = SparseCategoricalCrossEntropy(), metrics = List(new Accuracy()))\nmodel.fit(trainSet, batchSize, nbEpoch, validateSet)  Python  model.compile(optimizer=Adagrad(learning_rate, loss= sparse_categorical_crossentropy , metrics=['accuracy'])\nmodel.fit(train_set, batch_size, nb_epoch, validate_set)", 
            "title": "Train a TextClassifier model"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#do-prediction", 
            "text": "After training the model, it can be used to predict probability distributions.  Scala  val predictSet = textClassifier.predict(validateSet)  Python  predict_set = text_classifier.predict(validate_set)", 
            "title": "Do prediction"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#examples", 
            "text": "We provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  See  here  for the Scala example.  See  here  for the Python example.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/", 
            "text": "Analytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model. \n\n\nHighlights\n\n\n\n\nEasy-to-use models, could be fed into NNFrames or BigDL Optimizer for training.\n\n\nRecommenders can handle either explict or implicit feedback, given corresponding features.\n\n\nIt provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items).\n\n\n\n\nThe examples/notebooks are included in the Analytics Zoo source code.\n\n\n\n\nWide and Deep Learning Model.\n    \nScala example\n\n    \nPython notebook\n\n\nNCF.\n    \nScala example\n\n    \nPython notebook\n\n\n\n\n\n\nWide and Deep\n\n\nScala\n\n\nBuild a WND model for recommendation. \n\n\nval wideAndDeep = WideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer.\n\n\nval optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n.\n\n\nPython\n\n\nBuild a WND model for recommendation. \n\n\nwide_n_deep = WideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nScala\n\n\nBuild a NCF model for recommendation. \n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\nval optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a NCF model for recommendation. \n\n\nncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.", 
            "title": "Recommendation API"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#wide-and-deep", 
            "text": "Scala  Build a WND model for recommendation.   val wideAndDeep = WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))  Train a WND model using BigDL Optimizer.  val optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example .  Python  Build a WND model for recommendation.   wide_n_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))  Train a WND model using BigDL Optimizer   optimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .", 
            "title": "Wide and Deep"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "Scala  Build a NCF model for recommendation.   val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)  Train a NCF model using BigDL Optimizer   val optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example  Python  Build a NCF model for recommendation.   ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)  Train a NCF model using BigDL Optimizer   optimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/", 
            "text": "Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. \nA sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions.  \n\n\nHightlights\n\n\n\n\nKeras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training.\n\n\nModels are defined base on LSTM.\n\n\n\n\n\n\nBuild an AnomalyDetction model\n\n\nYou can call the following API in Scala and Python respectively to create an \nAnomalyDetrctor\n model\n\n\nScala\n\n\nimport com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)\n\n\n\n\n\n\nfeatureShape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhiddenLayers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nPython\n\n\nfrom zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])\n\n\n\n\n\n\nfeature_shape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhidden_layers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nTrain an AnomalyDetector model\n\n\nAfter building the model, we can compile and train it using RDD of \nSample\n.\n\n\nNote that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples.\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.optim._\n\nmodel.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9),\n      loss = MeanSquaredError[Float]())\nmodel.fit(trainRdd, batchSize = 1024, nbEpoch = 20)\n\n\n\n\nPython\n\n\nmodel.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(train, batch_size = 1024, nb_epoch = 20)\n\n\n\n\n\n\nDo prediction to detect anomalies\n\n\nAfter training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top \nanomalySize\n data points are anomalies).\n\n\nScala\n\n\nval yPredict = model.predict(testRdd).map(x =\n x.toTensor.toArray()(0))\nval yTruth: RDD[Float] = testRdd.map(x =\n x.label.toArray()(0))\nval anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20)\n\n\n\n\nPython\n\n\ny_predict = model.predict(test).map(lambda x: float(x[0]))\ny_test = test.map(lambda x: float(x.label.to_ndarray()[0]))\nanomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20)\n\n\n\n\n\n\nExamples\n\n\nWe provide examples to train the AnomalyDetector model and detect possible anomalies using data of \nNYC taxi passengers\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.\n\n\nSee a \nPython notebook\n for defining and training a model using simple Keras layers, and more details.", 
            "title": "Anomaly Detection API"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/#build-an-anomalydetction-model", 
            "text": "You can call the following API in Scala and Python respectively to create an  AnomalyDetrctor  model  Scala  import com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)   featureShape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hiddenLayers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.   Python  from zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])   feature_shape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hidden_layers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.", 
            "title": "Build an AnomalyDetction model"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/#train-an-anomalydetector-model", 
            "text": "After building the model, we can compile and train it using RDD of  Sample .  Note that original features need to go through AnomalyDetector.unroll before being fed into the model. See more details in the examples.  Scala  import com.intel.analytics.bigdl.optim._\n\nmodel.compile(optimizer = new RMSprop(learningRate = 0.001, decayRate = 0.9),\n      loss = MeanSquaredError[Float]())\nmodel.fit(trainRdd, batchSize = 1024, nbEpoch = 20)  Python  model.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(train, batch_size = 1024, nb_epoch = 20)", 
            "title": "Train an AnomalyDetector model"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/#do-prediction-to-detect-anomalies", 
            "text": "After training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top  anomalySize  data points are anomalies).  Scala  val yPredict = model.predict(testRdd).map(x =  x.toTensor.toArray()(0))\nval yTruth: RDD[Float] = testRdd.map(x =  x.label.toArray()(0))\nval anomalies = AnomalyDetector.detectAnomalies(yPredict, yTruth, 20)  Python  y_predict = model.predict(test).map(lambda x: float(x[0]))\ny_test = test.map(lambda x: float(x.label.to_ndarray()[0]))\nanomalies = AnomalyDetector.detect_anomalies(y_test, y_predict, 20)", 
            "title": "Do prediction to detect anomalies"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/#examples", 
            "text": "We provide examples to train the AnomalyDetector model and detect possible anomalies using data of  NYC taxi passengers  See  here  for the Scala example.  See  here  for the Python example.  See a  Python notebook  for defining and training a model using simple Keras layers, and more details.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/text-matching/", 
            "text": "Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering).\nMore text matching models will be supported in the future.\n\n\nHighlights\n\n\n\n\nEasy-to-use Keras-Style defined model which provides compile and fit methods for training. Alternatively, it could be fed into NNFrames or BigDL Optimizer.\n\n\nThe model can be used for both ranking and classification tasks.\n\n\n\n\n\n\nBuild a KNRM Model\n\n\nKernel-pooling Neural Ranking Model with RBF kernel. See \nhere\n for more details.\n\n\nYou can call the following API in Scala and Python respectively to create a \nKNRM\n with \npre-trained GloVe word embeddings\n.\n\n\nScala\n\n\nval knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \nranking\n)\n\n\n\n\n\n\ntext1Length\n: Sequence length of text1 (query).\n\n\ntext2Length\n: Sequence length of text2 (doc).\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainEmbed\n: Boolean. Whether to train the embedding layer or not. Default is true.\n\n\nkernelNum\n: Integer \n 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexactSigma\n: Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntargetMode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nPython\n\n\nknrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\nranking\n)\n\n\n\n\n\n\ntext1_length\n: Sequence length of text1 (query).\n\n\ntext2_length\n: Sequence length of text2 (doc).\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrain_embed\n: Boolean. Whether to train the embedding layer or not. Default is True.\n\n\nkernel_num\n: Int \n 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexact_sigma\n: Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntarget_mode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\n\n\nPairwise training\n\n\nFor ranking, the model can be trained pairwisely with the following steps:\n\n\n\n\nRead train relations. See \nhere\n for more details.\n\n\nRead text1 and text2 corpus as TextSet. See \nhere\n for more details.\n\n\nPreprocess text1 and text2 corpus. See \nhere\n for more details.\n\n\nGenerate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1.\nDuring the training process, we intend to optimize the margin loss within each pair.\nWe provide the following API to generate a \nTextSet\n for pairwise training:\n\n\n\n\nScala\n\n\nval trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or array of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling \ntokenize\n, \nword2idx\n \n  and \nshapeSequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nPython\n\n\ntrain_set = TextSet.from_relation_pairs(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or list of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling \ntokenize\n, \nword2idx\n \n  and \nshape_sequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nCall compile and fit to train the model:\n\n\nScala\n\n\nval model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length)))\nmodel.compile(optimizer = new SGD(learningRate), loss = RankHinge())\nmodel.fit(trainSet, batchSize, nbEpoch)\n\n\n\n\nPython\n\n\nmodel = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length)))\nmodel.compile(optimizer=SGD(learning_rate), loss='rank_hinge')\nmodel.fit(train_set, batch_size, nb_epoch)\n\n\n\n\n\n\nListwise evaluation\n\n\nGiven text1 and a list of text2 candidates, we provide metrics \nNDCG\n and \nMAP\n to listwisely evaluate a ranking model with the following steps:\n\n\n\n\nRead validation relations. See \nhere\n for more details.\n\n\nRead text1 and text2 corpus as TextSet. See \nhere\n for more details.\n\n\nPreprocess text1 and text2 corpus same as the training phase. See \nhere\n for more details.\n\n\nGenerate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1.\nWe provide the following API to generate a \nTextSet\n for listwise evaluation:\n\n\n\n\nScala\n\n\nval validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or array of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling \ntokenize\n, \nword2idx\n \nand \nshapeSequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nPython\n\n\nvalidate_set = TextSet.from_relation_lists(relations, corpus1, corpus2)\n\n\n\n\n\n\nrelations\n: RDD or list of Relation.\n\n\ncorpus1\n: TextSet that contains all id1 in relations.\n\n\ncorpus2\n: TextSet that contains all id2 in relations.\n\n\nFor corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling \ntokenize\n, \nword2idx\n \nand \nshape_sequence\n in order.\n\n\nIf relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.\n\n\n\n\nCall evaluateNDCG or evaluateMAP to evaluate the model:\n\n\nScala\n\n\nknrm.evaluateNDCG(validateSet, k, threshold = 0.0)\nknrm.evaluateMAP(validateSet, threshold = 0.0)\n\n\n\n\nPython\n\n\nknrm.evaluate_ndcg(validate_set, k, threshold=0.0)\nknrm.evaluate_map(validate_set, threshold=0.0)\n\n\n\n\n\n\nk\n: Positive integer. Rank position in NDCG.\n\n\nthreshold\n: If label \n threshold, then it will be considered as a positive record. Default is 0.0.\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.", 
            "title": "Text Matching API"
        }, 
        {
            "location": "/ProgrammingGuide/text-matching/#build-a-knrm-model", 
            "text": "Kernel-pooling Neural Ranking Model with RBF kernel. See  here  for more details.  You can call the following API in Scala and Python respectively to create a  KNRM  with  pre-trained GloVe word embeddings .  Scala  val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode =  ranking )   text1Length : Sequence length of text1 (query).  text2Length : Sequence length of text2 (doc).  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true.  kernelNum : Integer   1. The number of kernels to use. Default is 21.  sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   Python  knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking )   text1_length : Sequence length of text1 (query).  text2_length : Sequence length of text2 (doc).  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  train_embed : Boolean. Whether to train the embedding layer or not. Default is True.  kernel_num : Int   1. The number of kernels to use. Default is 21.  sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.", 
            "title": "Build a KNRM Model"
        }, 
        {
            "location": "/ProgrammingGuide/text-matching/#pairwise-training", 
            "text": "For ranking, the model can be trained pairwisely with the following steps:   Read train relations. See  here  for more details.  Read text1 and text2 corpus as TextSet. See  here  for more details.  Preprocess text1 and text2 corpus. See  here  for more details.  Generate all relation pairs from train relations. Each pair is made up of a positive relation and a negative one of the same id1.\nDuring the training process, we intend to optimize the margin loss within each pair.\nWe provide the following API to generate a  TextSet  for pairwise training:   Scala  val trainSet = TextSet.fromRelationPairs(relations, corpus1, corpus2)   relations : RDD or array of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling  tokenize ,  word2idx  \n  and  shapeSequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.   Python  train_set = TextSet.from_relation_pairs(relations, corpus1, corpus2)   relations : RDD or list of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length by\n  calling  tokenize ,  word2idx  \n  and  shape_sequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.   Call compile and fit to train the model:  Scala  val model = Sequential().add(TimeDistributed(knrm, inputShape = Shape(2, text1Length + text2Length)))\nmodel.compile(optimizer = new SGD(learningRate), loss = RankHinge())\nmodel.fit(trainSet, batchSize, nbEpoch)  Python  model = Sequential().add(TimeDistributed(knrm, input_shape=(2, text1Length + text2Length)))\nmodel.compile(optimizer=SGD(learning_rate), loss='rank_hinge')\nmodel.fit(train_set, batch_size, nb_epoch)", 
            "title": "Pairwise training"
        }, 
        {
            "location": "/ProgrammingGuide/text-matching/#listwise-evaluation", 
            "text": "Given text1 and a list of text2 candidates, we provide metrics  NDCG  and  MAP  to listwisely evaluate a ranking model with the following steps:   Read validation relations. See  here  for more details.  Read text1 and text2 corpus as TextSet. See  here  for more details.  Preprocess text1 and text2 corpus same as the training phase. See  here  for more details.  Generate all relation lists from validation relations. Each list is made up of one id1 and all id2 combined with id1.\nWe provide the following API to generate a  TextSet  for listwise evaluation:   Scala  val validateSet = TextSet.fromRelationLists(relations, corpus1, corpus2)   relations : RDD or array of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling  tokenize ,  word2idx  \nand  shapeSequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is an array, then corpus1 and corpus2 must both be LocalTextSet.   Python  validate_set = TextSet.from_relation_lists(relations, corpus1, corpus2)   relations : RDD or list of Relation.  corpus1 : TextSet that contains all id1 in relations.  corpus2 : TextSet that contains all id2 in relations.  For corpus1 and corpus2 respectively, each text must have been transformed to indices of the same length as during the training process by \ncalling  tokenize ,  word2idx  \nand  shape_sequence  in order.  If relations is an RDD, then corpus1 and corpus2 must both be DistributedTextSet.\nIf relations is a list, then corpus1 and corpus2 must both be LocalTextSet.   Call evaluateNDCG or evaluateMAP to evaluate the model:  Scala  knrm.evaluateNDCG(validateSet, k, threshold = 0.0)\nknrm.evaluateMAP(validateSet, threshold = 0.0)  Python  knrm.evaluate_ndcg(validate_set, k, threshold=0.0)\nknrm.evaluate_map(validate_set, threshold=0.0)   k : Positive integer. Rank position in NDCG.  threshold : If label   threshold, then it will be considered as a positive record. Default is 0.0.", 
            "title": "Listwise evaluation"
        }, 
        {
            "location": "/ProgrammingGuide/text-matching/#examples", 
            "text": "We provide an example to train and evaluate a KNRM model on WikiQA dataset for ranking.  See  here  for the Scala example.  See  here  for the Python example.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/seq2seq/", 
            "text": "Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more.\n\n\nHighlights\n\n\n\n\nEasy-to-use models, could be fed into NNFrames or BigDL Optimizer for training.\n\n\nSupport SimpleRNN, LSTM and GRU.\n\n\nSupport transform encoder states before fed into decoder\n\n\n\n\n\n\nBuild a Seq2seq model\n\n\nYou can call the following API in Scala and Python respectively to create a \nSeq2seq\n.\n\n\nScala\n\n\nval encoder = RNNEncoder[Float](rnnType=\nlstm\n, numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval decoder = RNNDecoder[Float](rnnType=\nlstm\n, numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval bridge = Bridge[Float](bridgeType=\ndense\n, decoderHiddenSize=3)\nval model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge)\n\n\n\n\n\n\nrnnType\n: currently support \"simplernn | lstm | gru\"\n\n\nnumLayer\n: number of layers\n\n\nhiddenSize\n: hidden size\n\n\nembedding\n: embedding layer\n\n\nbridgeType\n: currently only support \"dense | densenonlinear\"\n\n\ninput_shape\n: shape of encoder input\n\n\noutput_shape\n: shape of decoder input\n\n\n\n\nPython\n\n\nencoder = RNNEncoder.initialize(rnn_tpye=\nLSTM\n, nlayers=1, hidden_size=4)\ndecoder = RNNDecoder.initialize(rnn_tpye=\nLSTM\n, nlayers=1, hidden_size=4)\nbridge = Bridge.initialize(bridge_type=\ndense\n, decoder_hidden_size=4)\nseq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge)\n\n\n\n\n\n\nrnn_type\n: currently support \"simplernn | lstm | gru\"\n\n\nnlayers\n: number of layers\n\n\nhidden_size\n: hidden size\n\n\nbridge_type\n: currently only support \"dense | densenonlinear\"\n\n\ninput_shape\n: shape of encoder input\n\n\noutput_shape\n: shape of decoder input\n\n\n\n\n\n\nTrain a Seq2seq model\n\n\nAfter building the model, we can use BigDL Optimizer to train it (with validation) using RDD of \nSample\n.\n\nfeature\n is expected to be a sequence(eg. batch x seqLen x feature) and \nlabel\n is also a sequence(eg. batch x seqLen x feature).\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ClassNLLCriterion}\n\nval optimizer = Optimizer(\nmodel,\ntrainSet,\nTimeDistributedMaskCriterion(\n  ClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n),\nbatchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()\n\n\n\n\nAlso we can use \nSeq2seq.fit\n api to train the model.\n\n\nmodel.compile(\noptimizer = optimMethod,\nloss = TimeDistributedMaskCriterion(\n  ClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n))\n\nmodel.fit(\n  trainSet, batchSize = param.batchSize,\n  nbEpoch = 20)\n\n\n\n\nPython\n\n\nfrom bigdl.optim.optimizer import *\n\noptimizer = Optimizer(\n    model=seq2seq,\n    training_rdd=train_rdd,\n    criterion=TimeDistributedMaskCriterion(ClassNLLCriterion()),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    trigger=EveryEpoch())\n\n\n\n\nAlso we can use \nSeq2seq.fit\n api to train the model.\n\n\nmodel.compile(optimizer, loss, metrics)\n\nmodel.fit(x, batch_size=32, nb_epoch=10, validation_data=None)\n\n\n\n\n\n\nDo prediction\n\n\nPredict output with given input\n\nScala\n\n\nval result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput)\n\n\n\n\n\n\ninput\n: a sequence of data feed into encoder, eg: batch x seqLen x featureSize\n\n\nstartSign\n: a tensor which represents start and is fed into decoder\n\n\nmaxSeqLen\n: max sequence length for final output\n\n\nstopSign\n: a tensor that indicates model should stop infer further if current output is the same with stopSign\n\n\nbuildOutput\n: Feeding model output to buildOutput to generate final result\n\n\n\n\nPython\n\n\nresult = model.infer(input, start_sign, max_seq_len, stop_sign, build_output)\n\n\n\n\n\n\ninput\n: a sequence of data feed into encoder, eg: batch x seqLen x featureSize\n\n\nstart_sign\n: a ndarray which represents start and is fed into decoder\n\n\nmax_seq_len\n: max sequence length for final output\n\n\nstop_sign\n: a ndarray that indicates model should stop infer further if current output is the same with stopSign\n\n\nbuild_output\n: Feeding model output to buildOutput to generate final result\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction.\n\n\nSee \nhere\n for the Scala example.", 
            "title": "Sequence to Sequence API"
        }, 
        {
            "location": "/ProgrammingGuide/seq2seq/#build-a-seq2seq-model", 
            "text": "You can call the following API in Scala and Python respectively to create a  Seq2seq .  Scala  val encoder = RNNEncoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval decoder = RNNDecoder[Float](rnnType= lstm , numLayers=3, hiddenSize=3, embedding=Embedding[Float](10, inputSize))\nval bridge = Bridge[Float](bridgeType= dense , decoderHiddenSize=3)\nval model = Seq2seq[Float](encoder, decoder, inputShape=SingleShape(List(-1)), outputShape=SingleShape(List(-1)), bridge)   rnnType : currently support \"simplernn | lstm | gru\"  numLayer : number of layers  hiddenSize : hidden size  embedding : embedding layer  bridgeType : currently only support \"dense | densenonlinear\"  input_shape : shape of encoder input  output_shape : shape of decoder input   Python  encoder = RNNEncoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4)\ndecoder = RNNDecoder.initialize(rnn_tpye= LSTM , nlayers=1, hidden_size=4)\nbridge = Bridge.initialize(bridge_type= dense , decoder_hidden_size=4)\nseq2seq = Seq2seq(encoder, decoder, input_shape=[2, 4], output_shape=[2, 4], bridge)   rnn_type : currently support \"simplernn | lstm | gru\"  nlayers : number of layers  hidden_size : hidden size  bridge_type : currently only support \"dense | densenonlinear\"  input_shape : shape of encoder input  output_shape : shape of decoder input", 
            "title": "Build a Seq2seq model"
        }, 
        {
            "location": "/ProgrammingGuide/seq2seq/#train-a-seq2seq-model", 
            "text": "After building the model, we can use BigDL Optimizer to train it (with validation) using RDD of  Sample . feature  is expected to be a sequence(eg. batch x seqLen x feature) and  label  is also a sequence(eg. batch x seqLen x feature).  Scala  import com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.nn.{TimeDistributedMaskCriterion, ClassNLLCriterion}\n\nval optimizer = Optimizer(\nmodel,\ntrainSet,\nTimeDistributedMaskCriterion(\n  ClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n),\nbatchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()  Also we can use  Seq2seq.fit  api to train the model.  model.compile(\noptimizer = optimMethod,\nloss = TimeDistributedMaskCriterion(\n  ClassNLLCriterion(paddingValue = padId),\n  paddingValue = padId\n))\n\nmodel.fit(\n  trainSet, batchSize = param.batchSize,\n  nbEpoch = 20)  Python  from bigdl.optim.optimizer import *\n\noptimizer = Optimizer(\n    model=seq2seq,\n    training_rdd=train_rdd,\n    criterion=TimeDistributedMaskCriterion(ClassNLLCriterion()),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    trigger=EveryEpoch())  Also we can use  Seq2seq.fit  api to train the model.  model.compile(optimizer, loss, metrics)\n\nmodel.fit(x, batch_size=32, nb_epoch=10, validation_data=None)", 
            "title": "Train a Seq2seq model"
        }, 
        {
            "location": "/ProgrammingGuide/seq2seq/#do-prediction", 
            "text": "Predict output with given input Scala  val result = model.infer(input, startSign, maxSeqLen, stopSign, buildOutput)   input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize  startSign : a tensor which represents start and is fed into decoder  maxSeqLen : max sequence length for final output  stopSign : a tensor that indicates model should stop infer further if current output is the same with stopSign  buildOutput : Feeding model output to buildOutput to generate final result   Python  result = model.infer(input, start_sign, max_seq_len, stop_sign, build_output)   input : a sequence of data feed into encoder, eg: batch x seqLen x featureSize  start_sign : a ndarray which represents start and is fed into decoder  max_seq_len : max sequence length for final output  stop_sign : a ndarray that indicates model should stop infer further if current output is the same with stopSign  build_output : Feeding model output to buildOutput to generate final result", 
            "title": "Do prediction"
        }, 
        {
            "location": "/ProgrammingGuide/seq2seq/#examples", 
            "text": "We provide an example to train the Seq2seq model on a QA dataset and uses the model to do prediction.  See  here  for the Scala example.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/usercases-overview/", 
            "text": "Analytics Zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in \nanalytics-zoo/apps\n.\n\n\n\n\n\n\nAnomaly Detection\n demostrates using LSTM network to detect anomalies in time series data.\n\n\n\n\n\n\nFraud Detection\n demostrates using feed-forward neural network to detect frauds in credit card transactions data. \n\n\n\n\n\n\nImage Augmentation\n demostrates how to do image augmentation for vision projects. \n\n\n\n\n\n\nObject Detection\n demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos. \n\n\n\n\n\n\nRecommendation demonstrates how to use Analytics Zoo Recommendation APIs (i.e. \nNeural Collaborative Filtering\n, \nWide and Deep\n) to do recommendation on data with explicit feedback. \n\n\n\n\n\n\nSentiment Analysis\n demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU, Bi-LSTM).  \n\n\n\n\n\n\nVariational AutoEncoder\n demostrates how to use variational autoencoder to generate faces and digital numbers.", 
            "title": "Reference Use Cases"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/", 
            "text": "Deploy Analytics Zoo with BigDL on Dataproc\n\n\nBefore using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc \n(you may refer to \nhttps://cloud.google.com/sdk/docs/how-to\n \nfor more instructions). \nNow you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/) \n\ngcloud\n command-line tool.\n\n\nNote:\n The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]).\n So at the time of writing you should download and place the updated version of this script somewhere accessible for you \n (into your own Google Storage bucket, for example) and set appropriate location for \n--initialization-actions\n.\n\n\nYou can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed \nin it.\n\n\nBy default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8).\nSo you must specify to download Analytics Zoo instead (which includes BigDL) with: \nbigdl-download-url\n \nproperty in metadata:\n\n\ngcloud dataproc clusters create \nCLUSTER_NAME\n \\\n    --image-version 1.3 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip'\n\n\n\n\nTo download a different version of Zoo or one targeted to a different version of Spark/Scala, \nfind the download URL from the \nAnalytics Zoo releases page\n \nor \nmaven repository\n, \nand set the metadata key \"bigdl-download-url\" \n.\n\n\nMore information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl\n\n\nOnce the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.\n\n\nCloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,\n\n\ngcloud compute --project \nPROJECT_ID\n ssh --zone \nZONE\n \nCLUSTER_NAME\n\n\n\n\n\nGoogle cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).\n\n\nYou should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. \nNow you can run jobs with Zoo and BigDL on Google Dataproc \nas usual with \ngcloud dataproc jobs submit spark\n.", 
            "title": "Run on Google Cloud Dataproc"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/#deploy-analytics-zoo-with-bigdl-on-dataproc", 
            "text": "Before using Analytics Zoo and BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc \n(you may refer to  https://cloud.google.com/sdk/docs/how-to  \nfor more instructions). \nNow you can create a Cloud Dataproc cluster using the Google Cloud SDK's (https://cloud.google.com/sdk/docs/)  gcloud  command-line tool.  Note:\n The actual version of the initialization script with Zoo support is still under review here: [https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/469]).\n So at the time of writing you should download and place the updated version of this script somewhere accessible for you \n (into your own Google Storage bucket, for example) and set appropriate location for  --initialization-actions .  You can use use this initialization action to create a new Dataproc cluster with Analytics Zoo and BigDL pre-installed \nin it.  By default, it will automatically download only BigDL 0.7.2 for Dataproc 1.3 (Spark 2.3 and Scala 2.11.8).\nSo you must specify to download Analytics Zoo instead (which includes BigDL) with:  bigdl-download-url  \nproperty in metadata:  gcloud dataproc clusters create  CLUSTER_NAME  \\\n    --image-version 1.3 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://repo1.maven.org/maven2/com/intel/analytics/zoo/analytics-zoo-bigdl_0.7.2-spark_2.3.1/0.4.0/analytics-zoo-bigdl_0.7.2-spark_2.3.1-0.4.0-dist-all.zip'  To download a different version of Zoo or one targeted to a different version of Spark/Scala, \nfind the download URL from the  Analytics Zoo releases page  \nor  maven repository , \nand set the metadata key \"bigdl-download-url\" \n.  More information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl  Once the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.  Cloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,  gcloud compute --project  PROJECT_ID  ssh --zone  ZONE   CLUSTER_NAME   Google cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).  You should be able to find Analytics Zoo and BigDL located under /opt/intel-bigdl. \nNow you can run jobs with Zoo and BigDL on Google Dataproc \nas usual with  gcloud dataproc jobs submit spark .", 
            "title": "Deploy Analytics Zoo with BigDL on Dataproc"
        }, 
        {
            "location": "/wp-bigdl/", 
            "text": "BigDL: A Distributed Deep Learning Framework for Big Data\n\n\nJason (Jinquan) Dai\n1\n, Yiheng Wang\n1\n, Xin Qiu\n1\n, Ding Ding\n1\n, Yao Zhang\n2 \u01c2\n, Yanzhang Wang\n1\n, Xianyan Jia\n2 \u01c2\n, Cherry (Li) Zhang\n1\n, Yan Wan\n3 \u01c2\n, Zhichao Li\n1\n, Jiao Wang\n1\n, Shengsheng Huang\n1\n, Zhongyuan Wu\n1\n, Yang Wang\n1\n, Yuhao Yang\n1\n, Bowen She\n1\n, Dongjie Shi\n1\n, Qi Lu\n1\n, Kai Huang\n1\n, Guoqiong Song\n1\n\n\n1\nIntel Corporation,    \n2\nTencent Inc.,    \n3\nAlibaba Group\n\n\n\u01c2\nWork was done when the author worked at Intel\n\n\n\n\nAbstract\n\n\nIn this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an \nAllReduce\n like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.\n\n\n1. Introduction\n\n\nRecent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:\n\n\n\n\n\n\nData scale drives deep learning process.\n Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).\n\n\n\n\n\n\nReal-world deep learning applications are complex big data pipelines,\n which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].\n\n\n\n\n\n\nDeep learning is increasingly adopted by the big data and data science community.\n Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.\n\n\n\n\n\n\nWe have developed \nBigDL\n [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.\n\n\nBigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms.\n\n\n2. Programming Model\n\n\nBigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.\n\n\n1    spark = SparkContext(appName=\ntext_classifier\n, \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile(\nhdfs://...\n)\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   optimizer.set_train_summary(summary = TrainSummary(\u2026))\n25   trained_model =optimizer.optimize()\n26   //model prediction\n27   test_rdd = \u2026\n28   prediction_rdd = trained_model.predict(test_rdd)\n\n\n\n\nFigure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.\n\n\n2.1. Spark\n\n\nSpark provides the \nResilient Distributed Dataset\n (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like \nmap, filter and reduce.\n Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.\n\n\n2.2. Data transformation\n\n\nSpark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector. \n\n\n\n\n\n\nN-dimensional array:\n In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by \nnumpy.ndarry\n [22] and \nBigDL.Tensor\n (similar to \nTorch.Tensor\n [23]) for BigDL Python and Scala/Java APIs respectively.\n\n\n\n\n\n\nSample:\n Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more \nN-dimensional arrays.\n For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of \nSamples,\n which will later be used by BigDL model training.\n\n\n\n\n\n\n2.3. Model Construction\n\n\nSimilar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as \nReLu, Spatial Convolution and LSTM\n). BigDL then uses the semantics of the layers for model evaluation (\nforward\n) and gradient computation (\nbackward\n). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.\n\n\n2.4. Model training\n\n\nThe transformed input data (RDD of Samples) and the constructed model can then be passed over to the \nOptimizer\n in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in \nFigure 1.\n\n\n\n\n\n\nOptimizer:\n In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as \nSGD, AdaGrad [24], Adam [25], etc.\n).\n\n\n\n\n\n\nVisualization:\n To make it easy for users to understand the behaviors of model training, the \noptimizer\n in BigDL can be configured to produce a \nTrainSummary\n that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27].\n\n\n\n\n\n\n2.5. Model Inference\n\n\nBigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1. \n\n\n\n\nModelBroadcast:\n BigDL provides the \nModelBroadcast\n abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation (\npredict\n) in BigDL uses \nModelBroadcast\n to cache a single copy of the model on each machine (by leveraging the \nbroadcast\n [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.\n\n\n\n\n2.6. Spark DataFrame and ML Pipeline\n\n\nBesides RDD, Spark provides a high level \nDataFrame\n abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like \nfilter\n and \njoin\n for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML \n(machine learning) pipeline\n [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its \nDLModel\n and \nDLEstimator\n abstractions). \n\n\n3. Execution Model\n\n\nSimilar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items). \n\n\n \n\n\nFigure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.\n\n\nOn the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).\n\n\n3.1. Data-parallel training\n\n\nTo train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.\n\n\nfor (i \n- 1 to N) {\n  //\nmodel forward-backward\n job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local Sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  //\nparameter synchronization\n job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}\n\n\n\n\nFigure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.\n\n\nAs described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional \nzip\n operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4.\n\n\n \n\n\nFigure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.\n\n\n3.2. Parameter synchronization\n\n\nParameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the \nparameter server\n [33][34][35] architecture or \nAllReduce\n [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.\n\n\nIn BigDL, we have adapted the primitives available in Spark (e.g., \nshuffle, broadcast, in-memory cache\n, etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).\n\n\n \n\n\nFigure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.\n\n\n\n\n\n\nA Spark job has \nN\n tasks, each of which is assigned a unique Id ranging from \n1\n to \nN\n in BigDL. After each task in the \u201c\nmodel forward-backward\n\u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into \nN\n partitions, as shown in Figure 5.\n\n\n\n\n\n\nNext, another \u201c\nparameter synchronization\n\u201d job is launched; each task \nn\n in the \u201c\nparameter synchronization\n\u201d job is responsible for managing the n\nth\n partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n\nth\n partition of the gradients (from all the tasks of the previous \u201c\nmodel forward-backward\n\u201d job) are first \nshuffled\n to task \nn\n, which then aggregates (sums) these gradients, and applies the updates to the n\nth\n partition of the weights (using the specific \noptimization method\n), as illustrated in Figure 5.\n\n\n\n\n\n\n \n\n\nFigure 6. The \u201cparameter synchronization\u201d Spark job, manages the n\nth\n partition of the parameters (similar to a parameter server).\n\n\n\n\n\n\nAfter that, each task \nn\n in the \u201c\nparameter synchronization\n\u201d job \nbroadcasts\n the n\nth\n partition of the updated weights; consequently, tasks in the \u201c\nmodel forward-backward\n\u201d job of the next iteration can read the latest value of all the weights before the next training step begins.\n\n\n\n\n\n\nThe \nshuffle\n and \ntask-side broadcast\n operations described above are implemented on top of the distributed \nin-memory\n storage in Spark: both the shuffled \ngradients\n and broadcasted \nweights\n are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.\n\n\n\n\n\n\nBy implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7. \n\n\n \n\n\nFigure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).\n\n\n3.3. Task scheduling\n\n\nWhile BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization.\n\n\nIn contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above). \n\n\nTo scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by \nDrizzle\n [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8.\n\n\n \n\n\nFigure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39].\n\n\n3.4. Model quantization\n\n\nQuantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.\n\n\nBigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.\n\n\nMath.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte\n\n\n\n\nFigure 9. Equation for quantizing 32-bit floating point to 8-bit integer.\n\n\nUnlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10.\n\n\n\n\nFigure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40].\n\n\n3.5. Local execution\n\n\nIn addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.\n\n\n4. Applications\n\n\nSince its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL.\n\n\n4.1. Model Inference: image feature extraction\n\n\nJD.com [41] is one of the largest online retailers in the world. It has built an end-to-end \nobject detection and image feature extraction\n pipeline on top of Spark and BigDL[42], as illustrated in Figure 11.\n\n\n \n\n\nFigure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42].\n\n\n\n\n\n\nThe pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including \nresizing\n, \nnormalization\n, and \nbatching\n) in a distributed fashion using Spark.\n\n\n\n\n\n\nAfter that, it uses BigDL to load a \nSSD\n [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.\n\n\n\n\n\n\nIt then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including \nresizing\n and \nbatching\n).\n\n\n\n\n\n\nFinally it uses BigDL to load a \nDeepBit\n [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).\n\n\n\n\n\n\nThe entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12.\n\n\n \n\n\nFigure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).\n\n\n4.2. Distributed training: precipitation nowcasting\n\n\nCray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting (\npredicting short-term precipitation\n) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13). \n\n\n \n\n\nFigure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL.\n\n\n\n\n\n\nThe application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of \nNumPy ndarrays\n.\n\n\n\n\n\n\nIt then trains a \nsequence-to-sequence\n model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output.\n\n\n\n\n\n\nAfter the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.\n\n\n\n\n\n\n \n\n\nFigure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37]\n\n\n4.3. Transfer learning: image-similarity based house recommendations\n\n\nMLSListings Inc. is a large \nMultiple Listing Service\n (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15.\n\n\n \n\n\nFigure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47]\n\n\nTo compute the \nsemantic similarity\n for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo.\n\n\nTo compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage.\n\n\nAt \nmodel serving\n time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the \n\u201cSimilar Houses\u201d\n section of the webpage in Figure 16.\n\n\n \n\n\nFigure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47]\n\n\n5.Related Work\n\n\nExisting big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model.\n\n\nExisting deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark.\n\n\nRecently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark). \n\n\n6. Summary\n\n\nWe have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training. \n\n\nBigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.\n\n\n7. Acknowledgement\n\n\nWe gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project.\n\n\n8. Reference\n\n\n[1] Caffe. \nhttp://caffe.berkeleyvision.org\n\n\n[2] Torch. \nhttp://torch.ch\n\n\n[3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.\n\n\n[4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.\n\n\n[5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.\n\n\n[6] Apache Hadoop. \nhttp://hadoop.apache.org\n\n\n[7] Apache Spark. \nhttps://spark.apache.org\n\n\n[8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.\n\n\n[9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]\n\n\n[10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]\n\n\n[11] BigDL. \nhttps://github.com/intel-analytics/BigDL/\n\n\n[12] Keras. \nhttps://keras.io\n\n\n[13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.\n\n\n[14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.\n\n\n[15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.\n\n\n[16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.\n\n\n[17] Apache Storm. \nhttp://storm.apache.org\n\n\n[18] Apache Flink. \nhttps://flink.apache.org\n\n\n[19] Apache Kafka. \nhttps://kafka.apache.org\n\n\n[20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.\n\n\n[21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.\n\n\n[22] Numpy. \nhttp://www.numpy.org\n\n\n[23] Torch7. \nhttps://github.com/torch/torch7\n\n\n[24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.\n\n\n[25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.\n\n\n[26] M. Abadi, et al.\n\u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems.\n, 2016.\n\n\n[27] Project Jupyter. \nhttp://jupyter.org\n\n\n[28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.\n\n\n[29] SciKit-Learn. \nhttp://scikit-learn.org/stable/\n\n\n[30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.\n\n\n[31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.\n\n\n[32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.\n\n\n[33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.\n\n\n[34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.\n\n\n[35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.\n\n\n[36] Andrew Gibiansky. \nBringing HPC Techniques to Deep Learning\n\n\n[37] Alex Heye, et al. \nScalable Deep Learning with BigDL on the Urika-XC Software Suite\n\n\n[38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.\n\n\n[39] Shivaram Venkataraman, et al. \nAccelerating Deep Learning Training with BigDL and Drizzle on Apache Spark\n\n\n[40] Jason (Jinquan) Dai, et al. \nLeveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL\n\n\n[41] JD. \nhttps://en.wikipedia.org/wiki/JD.com\n\n\n[42] Jason (Jinquan) Dai, et al. \nBuilding Large-Scale Image Feature Extraction with BigDL at JD.com\n\n\n[43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.\n\n\n[44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.\n\n\n[45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014. \n\n\n[46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.\n\n\n[47] Jason (Jinquan) Dai, et al. \n\u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d\n\n\n[48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015.\n\n\n[49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.\n\n\n[50] Karen Simonyan, at al. \n\u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d\n, 2014.\n\n\n[51]    Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017.\n\n\n[52]    DJ4J. https://deeplearning4j.org/\n\n\n[53]    TensorFrames. https://github.com/databricks/tensorframes\n\n\n[54]    Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning\n\n\n[55]    CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark\n\n\n[56]    TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark\n\n\n[57]    Philipp Moritz, et al.  \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.", 
            "title": "BigDL"
        }, 
        {
            "location": "/wp-bigdl/#bigdl-a-distributed-deep-learning-framework-for-big-data", 
            "text": "Jason (Jinquan) Dai 1 , Yiheng Wang 1 , Xin Qiu 1 , Ding Ding 1 , Yao Zhang 2 \u01c2 , Yanzhang Wang 1 , Xianyan Jia 2 \u01c2 , Cherry (Li) Zhang 1 , Yan Wan 3 \u01c2 , Zhichao Li 1 , Jiao Wang 1 , Shengsheng Huang 1 , Zhongyuan Wu 1 , Yang Wang 1 , Yuhao Yang 1 , Bowen She 1 , Dongjie Shi 1 , Qi Lu 1 , Kai Huang 1 , Guoqiong Song 1  1 Intel Corporation,     2 Tencent Inc.,     3 Alibaba Group  \u01c2 Work was done when the author worked at Intel", 
            "title": "BigDL: A Distributed Deep Learning Framework for Big Data"
        }, 
        {
            "location": "/wp-bigdl/#abstract", 
            "text": "In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an  AllReduce  like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.", 
            "title": "Abstract"
        }, 
        {
            "location": "/wp-bigdl/#1-introduction", 
            "text": "Recent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:    Data scale drives deep learning process.  Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).    Real-world deep learning applications are complex big data pipelines,  which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].    Deep learning is increasingly adopted by the big data and data science community.  Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.    We have developed  BigDL  [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.  BigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark and big data platforms.", 
            "title": "1. Introduction"
        }, 
        {
            "location": "/wp-bigdl/#2-programming-model", 
            "text": "BigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.  1    spark = SparkContext(appName= text_classifier , \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile( hdfs://... )\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   optimizer.set_train_summary(summary = TrainSummary(\u2026))\n25   trained_model =optimizer.optimize()\n26   //model prediction\n27   test_rdd = \u2026\n28   prediction_rdd = trained_model.predict(test_rdd)  Figure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.", 
            "title": "2. Programming Model"
        }, 
        {
            "location": "/wp-bigdl/#21-spark", 
            "text": "Spark provides the  Resilient Distributed Dataset  (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like  map, filter and reduce.  Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.", 
            "title": "2.1. Spark"
        }, 
        {
            "location": "/wp-bigdl/#22-data-transformation", 
            "text": "Spark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector.     N-dimensional array:  In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by  numpy.ndarry  [22] and  BigDL.Tensor  (similar to  Torch.Tensor  [23]) for BigDL Python and Scala/Java APIs respectively.    Sample:  Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more  N-dimensional arrays.  For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of  Samples,  which will later be used by BigDL model training.", 
            "title": "2.2. Data transformation"
        }, 
        {
            "location": "/wp-bigdl/#23-model-construction", 
            "text": "Similar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as  ReLu, Spatial Convolution and LSTM ). BigDL then uses the semantics of the layers for model evaluation ( forward ) and gradient computation ( backward ). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.", 
            "title": "2.3. Model Construction"
        }, 
        {
            "location": "/wp-bigdl/#24-model-training", 
            "text": "The transformed input data (RDD of Samples) and the constructed model can then be passed over to the  Optimizer  in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 25 in  Figure 1.    Optimizer:  In BigDL, the distributed training process is modelled by the Optimizer abstraction, which runs multiple, iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as  SGD, AdaGrad [24], Adam [25], etc. ).    Visualization:  To make it easy for users to understand the behaviors of model training, the  optimizer  in BigDL can be configured to produce a  TrainSummary  that contains various summary data (e.g., loss, weight, etc.), as illustrated by line 24 in Figure 1; the summary data can then be visualized in, for instance, TensorBoard [26] or Jupytor Notebooks [27].", 
            "title": "2.4. Model training"
        }, 
        {
            "location": "/wp-bigdl/#25-model-inference", 
            "text": "BigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 26 ~ 28 in Figure 1.    ModelBroadcast:  BigDL provides the  ModelBroadcast  abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation ( predict ) in BigDL uses  ModelBroadcast  to cache a single copy of the model on each machine (by leveraging the  broadcast  [28] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.", 
            "title": "2.5. Model Inference"
        }, 
        {
            "location": "/wp-bigdl/#26-spark-dataframe-and-ml-pipeline", 
            "text": "Besides RDD, Spark provides a high level  DataFrame  abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like  filter  and  join  for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML  (machine learning) pipeline  [15] similar to SciKit-Learn [29], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its  DLModel  and  DLEstimator  abstractions).", 
            "title": "2.6. Spark DataFrame and ML Pipeline"
        }, 
        {
            "location": "/wp-bigdl/#3-execution-model", 
            "text": "Similar to other Big Data systems (such as MapReduce [30]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items).      Figure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.  On the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).", 
            "title": "3. Execution Model"
        }, 
        {
            "location": "/wp-bigdl/#31-data-parallel-training", 
            "text": "To train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [31][32]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.  for (i  - 1 to N) {\n  // model forward-backward  job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local Sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  // parameter synchronization  job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}  Figure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.  As described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and Sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional  zip  operator to the partitions of model and Sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located Sample partition), as illustrated in Figure 4.     Figure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.", 
            "title": "3.1. Data-parallel training"
        }, 
        {
            "location": "/wp-bigdl/#32-parameter-synchronization", 
            "text": "Parameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the  parameter server  [33][34][35] architecture or  AllReduce  [36] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.  In BigDL, we have adapted the primitives available in Spark (e.g.,  shuffle, broadcast, in-memory cache , etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).     Figure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.    A Spark job has  N  tasks, each of which is assigned a unique Id ranging from  1  to  N  in BigDL. After each task in the \u201c model forward-backward \u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into  N  partitions, as shown in Figure 5.    Next, another \u201c parameter synchronization \u201d job is launched; each task  n  in the \u201c parameter synchronization \u201d job is responsible for managing the n th  partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n th  partition of the gradients (from all the tasks of the previous \u201c model forward-backward \u201d job) are first  shuffled  to task  n , which then aggregates (sums) these gradients, and applies the updates to the n th  partition of the weights (using the specific  optimization method ), as illustrated in Figure 5.       Figure 6. The \u201cparameter synchronization\u201d Spark job, manages the n th  partition of the parameters (similar to a parameter server).    After that, each task  n  in the \u201c parameter synchronization \u201d job  broadcasts  the n th  partition of the updated weights; consequently, tasks in the \u201c model forward-backward \u201d job of the next iteration can read the latest value of all the weights before the next training step begins.    The  shuffle  and  task-side broadcast  operations described above are implemented on top of the distributed  in-memory  storage in Spark: both the shuffled  gradients  and broadcasted  weights  are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.    By implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [37] and shown in Figure 7.      Figure 7. Throughput of ImageNet Inception v1 training reported by Cary [37] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).", 
            "title": "3.2. Parameter synchronization"
        }, 
        {
            "location": "/wp-bigdl/#33-task-scheduling", 
            "text": "While BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and parameter synchronization.  In contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [39]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability on large clusters (e.g., up to 256 servers as shown in Figure 7 above).   To scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by  Drizzle  [38] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [39] and shown in Figure 8.     Figure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [39].", 
            "title": "3.3. Task scheduling"
        }, 
        {
            "location": "/wp-bigdl/#34-model-quantization", 
            "text": "Quantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.  BigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.  Math.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte  Figure 9. Equation for quantizing 32-bit floating point to 8-bit integer.  Unlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [40] and shown in Figure 10.   Figure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [40].", 
            "title": "3.4. Model quantization"
        }, 
        {
            "location": "/wp-bigdl/#35-local-execution", 
            "text": "In addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.", 
            "title": "3.5. Local execution"
        }, 
        {
            "location": "/wp-bigdl/#4-applications", 
            "text": "Since its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes three typical use cases (namely, model inference, distributed training and transfer learning) using Spark and BigDL.", 
            "title": "4. Applications"
        }, 
        {
            "location": "/wp-bigdl/#41-model-inference-image-feature-extraction", 
            "text": "JD.com [41] is one of the largest online retailers in the world. It has built an end-to-end  object detection and image feature extraction  pipeline on top of Spark and BigDL[42], as illustrated in Figure 11.     Figure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [42].    The pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including  resizing ,  normalization , and  batching ) in a distributed fashion using Spark.    After that, it uses BigDL to load a  SSD  [43] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.    It then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including  resizing  and  batching ).    Finally it uses BigDL to load a  DeepBit  [44] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).    The entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [42] and shown in Figure 12.     Figure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [42]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).", 
            "title": "4.1. Model Inference: image feature extraction"
        }, 
        {
            "location": "/wp-bigdl/#42-distributed-training-precipitation-nowcasting", 
            "text": "Cray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting ( predicting short-term precipitation ) workflow on spark and BigDL[37], including data preparation, model training and inference (as illustrated in Figure 13).      Figure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [37] on Spark and BigDL.    The application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of  NumPy ndarrays .    It then trains a  sequence-to-sequence  model [45][46] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images in the future as the output.    After the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.       Figure 14. Predicting precipitation patterns for the next hour (i.e., a sequence of images for the future time steps of the next hour) on Spark and BigDL [37]", 
            "title": "4.2. Distributed training: precipitation nowcasting"
        }, 
        {
            "location": "/wp-bigdl/#43-transfer-learning-image-similarity-based-house-recommendations", 
            "text": "MLSListings Inc. is a large  Multiple Listing Service  (MLS) for real estate listings, who has been building an image-similarity based house recommendation system on Spark and BigDL [47]. The end-to-end workflow is implemented by leveraging transfer learning (including feature extractions and fine-tuning) technologies, so as to compute both the semantic and visual similarity of the house photos, as illustrated in Figure 15.     Figure 15. End-to-end workflow for image-similarity based house recommendations on Spark and BigDL [47]  To compute the  semantic similarity  for the photos, the system fine-tunes the Inception v1 [48] model pre-trained on the Places dataset [49], so as to train three new classifiers (namely, whether the photo shows the house front exterior, the house style and the house stories). In particular, it first loads three pre-trained Inception v1 models, and then appends two new layers (a fully-connected layer followed by a Softmax layer) to each model, so as to train the new classifiers (using photos for which MLSListings have been assigned copyrights). After the training, it can use these classifiers to produce the tags (or labels) for each house listing photo.  To compute the visual similarity, the system use the VGG-16 [50] model pre-trained on the Places dataset to extract the image feature for each house listing photo, which is then combined with the tags generated by the classifiers and stored into a distributed table storage.  At  model serving  time, the user can select a house listing photo, and have the system to recommend house listings of similar visual characteristics (by computing the cosine similarity score using the image features, while taking into considerations other properties of the houses such as photo tags, house prices, locations, etc.), as illustrated in the  \u201cSimilar Houses\u201d  section of the webpage in Figure 16.     Figure 16. Automatically recommending \u201cSimilar Houses\u201d with similar visual characteristics [47]", 
            "title": "4.3. Transfer learning: image-similarity based house recommendations"
        }, 
        {
            "location": "/wp-bigdl/#5related-work", 
            "text": "Existing big data systems, such as MapReduce [30], Dryad [51] and Spark [8], provide a data-parallel, functional compute model (with potentially dataflow DAG support), so as to efficiently support data partitioning, parallel and distributed computing, fault tolerance, incremental scale-out, etc., in an automatic and transparent fashion. BigDL is built on top of this data-parallel, functional compute model, and adds new support of deep learning technologies to Apache Spark, so as to provide the \u201cdata-analytics integrated\u201d deep learning programming model.  Existing deep learning frameworks, such as Caffe [1], Torch [2], TensorFlow [3], Keras [12], MXNet [4] and DL4J [52], usually use a dataflow graph (of either primitive operators or more complex layers) to represent neural network models. For distributed training, they typically implement the parameter server architecture or AllReduce operation (with fine-grained data access and in-place data mutation [3]), which are however not supported by existing big data systems. In contrast, BigDL adopts the similar dataflow representation of neural network models, but provides efficient distributed training directly on top of Apache Spark.  Recently there are also a lot of efforts to bring existing deep learning frameworks to Apache Spark. For instance, TensorFrames [53] and Deep Learning Pipelines [54] allow users to directly run TensorFlow or Keras models on each individual partition of Spark Dataframes, for both model inference and single-node model tuning; however, they do not support distributed model training or fine-tuning across multiple machines in a cluster. CaffeOnSpark [55] and TensorFlowOnSpark [56] frameworks use Spark as the orchestration layer to allocate resources from the cluster, and then launch the distributed Caffe or TensorFlow job on the allocated machines; however, the Caffe or TensorFlow job still runs outside of the big data framework, and has very limited interactions with the analytics pipelines. SparkNet [57] uses asynchronous SGD for distributed training on Spark; the master first broadcasts weights to the workers, and each work then trains its own Caffe model for a certain period of time, after which the weights on each worker are sent to the master and averaged to form the new weights; however, the broadcast and weight averaging is very inefficient in SparkNet (e.g., ~20 seconds with just 5 workers [57]). In contrast, BigDL provides highly efficient and scalable distributed training, directly on top of big data framework (using the primitives available in Spark).", 
            "title": "5.Related Work"
        }, 
        {
            "location": "/wp-bigdl/#6-summary", 
            "text": "We have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training.   BigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2400 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.", 
            "title": "6. Summary"
        }, 
        {
            "location": "/wp-bigdl/#7-acknowledgement", 
            "text": "We gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Yan Dai, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Xiao Xu, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Joseph Spisak, Gopi Kumar, Suqiang Song, Karthik Palaniappan, Rong Gu, etc.) to the BigDL project.", 
            "title": "7. Acknowledgement"
        }, 
        {
            "location": "/wp-bigdl/#8-reference", 
            "text": "[1] Caffe.  http://caffe.berkeleyvision.org  [2] Torch.  http://torch.ch  [3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.  [4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.  [5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.  [6] Apache Hadoop.  http://hadoop.apache.org  [7] Apache Spark.  https://spark.apache.org  [8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.  [9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]  [10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]  [11] BigDL.  https://github.com/intel-analytics/BigDL/  [12] Keras.  https://keras.io  [13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.  [14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.  [15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.  [16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.  [17] Apache Storm.  http://storm.apache.org  [18] Apache Flink.  https://flink.apache.org  [19] Apache Kafka.  https://kafka.apache.org  [20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.  [21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.  [22] Numpy.  http://www.numpy.org  [23] Torch7.  https://github.com/torch/torch7  [24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.  [25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.  [26] M. Abadi, et al. \u201cTensorflow: Large-scale machine learning on heterogeneous distributed systems. , 2016.  [27] Project Jupyter.  http://jupyter.org  [28] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.  [29] SciKit-Learn.  http://scikit-learn.org/stable/  [30] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.  [31] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.  [32] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.  [33] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.  [34] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.  [35] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.  [36] Andrew Gibiansky.  Bringing HPC Techniques to Deep Learning  [37] Alex Heye, et al.  Scalable Deep Learning with BigDL on the Urika-XC Software Suite  [38] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.  [39] Shivaram Venkataraman, et al.  Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark  [40] Jason (Jinquan) Dai, et al.  Leveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL  [41] JD.  https://en.wikipedia.org/wiki/JD.com  [42] Jason (Jinquan) Dai, et al.  Building Large-Scale Image Feature Extraction with BigDL at JD.com  [43] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.  [44] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.  [45] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014.   [46] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.  [47] Jason (Jinquan) Dai, et al.  \u201cUsing BigDL to Build Image Similarity-Based House Recommendations\u201d  [48] Christian Szegedy, et al. \u201cGoing deeper with convolutions\u201d, CVPR 2015.  [49] B. Zhou, et al. \u201cPlaces: A 10 million Image Database for Scene Recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.  [50] Karen Simonyan, at al.  \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d , 2014.  [51]    Michael Isard, et al. \u201cDryad: distributed data-parallel programs from sequential building blocks\u201d, EuroSys 2017.  [52]    DJ4J. https://deeplearning4j.org/  [53]    TensorFrames. https://github.com/databricks/tensorframes  [54]    Deep Learning Pipelines. https://github.com/databricks/spark-deep-learning  [55]    CaffeOnSpark. https://github.com/yahoo/CaffeOnSpark  [56]    TensorFlowOnSpark. https://github.com/yahoo/TensorFlowOnSpark  [57]    Philipp Moritz, et al.  \u201cSparkNet: Training Deep Networks in Spark\u201d, ICLR 2016.", 
            "title": "8. Reference"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/", 
            "text": "NNEstimator\n\n\nScala:\n\n\nval estimator = NNEstimator(model, criterion)\n\n\n\n\nPython:\n\n\nestimator = NNEstimator(model, criterion)\n\n\n\n\nNNEstimator\n extends \norg.apache.spark.ml.Estimator\n and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.\n\n\nNNEstimator\n supports different feature and label data types through \nPreprocessing\n.\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe \nPreprocessing\n to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL \nSample\n. \n\n\nEach\nPreprocessing\n conducts a data conversion step in the preprocessing phase, multiple\n\nPreprocessing\n can be combined into a \nChainedPreprocessing\n. Some pre-defined \n\nPreprocessing\n for popular data types like Image, Array or Vector are provided in package\n\ncom.intel.analytics.zoo.feature\n, while user can also develop customized \nPreprocessing\n.\n\n\nBy default, \nSeqToTensor\n is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the \nPreprocessing\n allows \nNNEstimator\n to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\n\n\nMore concrete examples are available in package \ncom.intel.analytics.zoo.examples.nnframes\n\n\nNNEstimator\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNEstimator(model, criterion)\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   \nPreprocessing\n. \nNNEstimator\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL \nSample\n and send to model for\n   training.\n\n\n2.\n \nNNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). \nNNEstimator\n\n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n\n\n3.\n \nNNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion, featurePreprocessing and labelPreprocessing.  \nNNEstimator\n\n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNEstimator\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample according to user-specified Preprocessing.\n\n\nScala Example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)\n\n\n\n\n\n\nNNModel\n\n\nScala:\n\n\nval nnModel = NNModel(bigDLModel)\n\n\n\n\nPython:\n\n\nnn_model = NNModel(bigDLModel)\n\n\n\n\nNNModel\n extends Spark's ML\n\nTransformer\n. User can invoke\n\nfit\n in \nNNEstimator\n to get a \nNNModel\n, or directly compose a \nNNModel\n from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for \nDataFrame\n(DataSet)\n. \n\n\nNNModel\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNModel(model)\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNModel\n will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n\n\n2.\n \nNNModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n\n\n3.\n \nNNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNModel\n will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNModel\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nNNClassifier\n\n\nScala:\n\n\nval classifer =  NNClassifer(model, criterion)\n\n\n\n\nPython:\n\n\nclassifier = NNClassifer(model, criterion)\n\n\n\n\nNNClassifier\n is a specialized \nNNEstimator\n that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted \nNNClassifierModel\n will have the prediction column of \nDoubleType.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\n\n\nNNClassifier\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNClassifier(model, criterion)\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   Preprocessing. \nNNClassifier\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n\n\n2.\n \nNNClassifier(model, criterion, featureSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int). \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size. \nScalarToTensor\n is used to convert the label column.\n\n\n3.\n \nNNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion and featurePreprocessing.  \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifier\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample with user-specified Preprocessing.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\n\n\n\n\nNNClassifierModel\n\n\nScala:\n\n\nval nnClassifierModel = NNClassifierModel(model, featureSize)\n\n\n\n\nPython:\n\n\nnn_classifier_model = NNClassifierModel(model)\n\n\n\n\nNNClassifierModel is a specialized \nNNModel\n for classification tasks.\nBoth label and prediction column will have the datatype of Double.\n\n\nNNClassifierModel\n can be created with various parameters for different scenarios.\n\n\n1.\n \nNNClassifierModel(model)\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNClassifierModel\n will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n\n\n2.\n \nNNClassifierModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNClassifierModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n\n\n3.\n \nNNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNClassifierModel\n will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifierModel\n\nsupports: \nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nHyperparameter setting\n\n\nPrior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or\n\nNNEstimator\n/\nNNClassifier\n will use the default value.\n\n\nContinue the codes above, NNEstimator and NNClassifier can be set in the same way.\n\n\nScala:\n\n\n//for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n\n\n\n\nPython:\n\n\n# for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n\n\n\n\n\nPrepare the data and start the training process\n\n\nNNEstimator/NNCLassifer supports training with Spark's\n\nDataFrame/DataSet\n\n\nSuppose \ndf\n is the training data, simple call \nfit\n method and let Analytics Zoo train the model\nfor you.\n\n\nScala:\n\n\n//get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)\n\n\n\n\nPython:\n\n\n# get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)\n\n\n\n\nUser may also set validation DataFrame and validation frequency through \nsetValidation\n method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.\n\n\nMake prediction on chosen data\n\n\nSince \nNNModel\n/\nNNClassifierModel\n inherits from Spark's \nTransformer\n abstract class, simply call \n\ntransform\n method on \nNNModel\n/\nNNClassifierModel\n to make prediction.\n\n\nScala:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nPython:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nFor the complete examples of NNFrames, please refer to:\n\nScala examples\n\n\nPython examples\n\n\nNNImageReader\n\n\nNNImageReader\n is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.\n\n\nScala:\n\n\n    val imageDF = NNImageReader.readImages(imageDirectory, sc)\n\n\n\n\nPython:\n\n\n    image_frame = NNImageReader.readImages(image_path, self.sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.", 
            "title": "NNFrames"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnestimator", 
            "text": "Scala:  val estimator = NNEstimator(model, criterion)  Python:  estimator = NNEstimator(model, criterion)  NNEstimator  extends  org.apache.spark.ml.Estimator  and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.  NNEstimator  supports different feature and label data types through  Preprocessing .\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe  Preprocessing  to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL  Sample .   Each Preprocessing  conducts a data conversion step in the preprocessing phase, multiple Preprocessing  can be combined into a  ChainedPreprocessing . Some pre-defined  Preprocessing  for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized  Preprocessing .  By default,  SeqToTensor  is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the  Preprocessing  allows  NNEstimator  to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.  More concrete examples are available in package  com.intel.analytics.zoo.examples.nnframes  NNEstimator  can be created with various parameters for different scenarios.  1.   NNEstimator(model, criterion)  Takes only model and criterion and use  SeqToTensor  as feature and label\n    Preprocessing .  NNEstimator  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL  Sample  and send to model for\n   training.  2.   NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])  Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int).  NNEstimator \n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.  3.   NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion, featurePreprocessing and labelPreprocessing.   NNEstimator \n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNEstimator  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample according to user-specified Preprocessing.  Scala Example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)", 
            "title": "NNEstimator"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnmodel", 
            "text": "Scala:  val nnModel = NNModel(bigDLModel)  Python:  nn_model = NNModel(bigDLModel)  NNModel  extends Spark's ML Transformer . User can invoke fit  in  NNEstimator  to get a  NNModel , or directly compose a  NNModel  from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for  DataFrame\n(DataSet) .   NNModel  can be created with various parameters for different scenarios.  1.   NNModel(model)  Takes only model and use  SeqToTensor  as feature Preprocessing.  NNModel  will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.  2.   NNModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.  3.   NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNModel  will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNModel  supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifier", 
            "text": "Scala:  val classifer =  NNClassifer(model, criterion)  Python:  classifier = NNClassifer(model, criterion)  NNClassifier  is a specialized  NNEstimator  that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted  NNClassifierModel  will have the prediction column of \nDoubleType.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient   NNClassifier  can be created with various parameters for different scenarios.  1.   NNClassifier(model, criterion)  Takes only model and criterion and use  SeqToTensor  as feature and label\n   Preprocessing.  NNClassifier  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.  2.   NNClassifier(model, criterion, featureSize: Array[Int])  Takes model, criterion, featureSize(Array of Int).  NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size.  ScalarToTensor  is used to convert the label column.  3.   NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion and featurePreprocessing.   NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifier  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample with user-specified Preprocessing.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)", 
            "title": "NNClassifier"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifiermodel", 
            "text": "Scala:  val nnClassifierModel = NNClassifierModel(model, featureSize)  Python:  nn_classifier_model = NNClassifierModel(model)  NNClassifierModel is a specialized  NNModel  for classification tasks.\nBoth label and prediction column will have the datatype of Double.  NNClassifierModel  can be created with various parameters for different scenarios.  1.   NNClassifierModel(model)  Takes only model and use  SeqToTensor  as feature Preprocessing.  NNClassifierModel  will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.  2.   NNClassifierModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNClassifierModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.  3.   NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNClassifierModel  will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifierModel \nsupports:  setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNClassifierModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#hyperparameter-setting", 
            "text": "Prior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier  will use the default value.  Continue the codes above, NNEstimator and NNClassifier can be set in the same way.  Scala:  //for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())  Python:  # for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())", 
            "title": "Hyperparameter setting"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#prepare-the-data-and-start-the-training-process", 
            "text": "NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet  Suppose  df  is the training data, simple call  fit  method and let Analytics Zoo train the model\nfor you.  Scala:  //get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)  Python:  # get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)  User may also set validation DataFrame and validation frequency through  setValidation  method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.", 
            "title": "Prepare the data and start the training process"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#make-prediction-on-chosen-data", 
            "text": "Since  NNModel / NNClassifierModel  inherits from Spark's  Transformer  abstract class, simply call  transform  method on  NNModel / NNClassifierModel  to make prediction.  Scala:  nnModel.transform(df).show(false)  Python:  nnModel.transform(df).show(false)  For the complete examples of NNFrames, please refer to: Scala examples  Python examples", 
            "title": "Make prediction on chosen data"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnimagereader", 
            "text": "NNImageReader  is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.  Scala:      val imageDF = NNImageReader.readImages(imageDirectory, sc)  Python:      image_frame = NNImageReader.readImages(image_path, self.sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "NNImageReader"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/", 
            "text": "mean\n\n\nMean of a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepDims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeepDims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nmean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nmean(x, axis=0, keepDims=False):\n\n\n\n\nabs\n\n\nElement-wise absolute value.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nabs(x: Variable[T])\n\n\n\n\nPython example\n\n\nabs(x):\n\n\n\n\nsum\n\n\nSum of the values in a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepDims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeepDims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nsum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nsum(x, axis=0, keepDims=False):\n\n\n\n\nclip\n\n\nElement-wise value clipping.\n- \nx\n A \nVariable\n.\n- \nmin\n Double\n- \nmax\n Double\n\n\nScala example\n\n\nclip(x: Variable[T], min: Double, max: Double)\n\n\n\n\nPython example\n\n\nclip(x, min, max)\n\n\n\n\nsquare\n\n\nElement-wise square.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsquare(x: Variable[T])\n\n\n\n\nPython example\n\n\nsquare(x):\n\n\n\n\nsqrt\n\n\nElement-wise square root.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsqrt(x: Variable[T])\n\n\n\n\nPython example\n\n\nsqrt(x):\n\n\n\n\nmaximum\n\n\nElement-wise maximum of two \nVariables\n.\n- \nx\n A \nVariable\n.\n- \ny\n A \nVariable\n or Double.\n\n\nScala example\n\n\nmaximum(x: Variable[T], y: Variable[T])\n\n\n\n\nPython example\n\n\nmaximum(x, y):\n\n\n\n\nlog\n\n\nElement-wise log.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nlog(x: Variable[T])\n\n\n\n\nPython example\n\n\nlog(x):\n\n\n\n\nexp\n\n\nElement-wise exponential.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nexp(x: Variable[T])\n\n\n\n\nPython example\n\n\nexp(x):\n\n\n\n\npow\n\n\nElement-wise exponentiation.\n- \nx\n A \nVariable\n.\n- \na\n Double.   \n\n\nScala example\n\n\npow(x: Variable[T])\n\n\n\n\nPython example\n\n\npow(x):\n\n\n\n\nsoftsign\n\n\nSoftsign of a \nVariable\n.\n\n\nScala example\n\n\nsoftsign(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftsign(x):\n\n\n\n\nsoftplus\n\n\nSoftplus of a \nVariable\n.\n\n\nScala example\n\n\nsoftplus(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftplus(x):\n\n\n\n\nstack\n\n\nStacks a list of rank \nR\n tensors into a rank \nR+1\n tensor.\n   You should start from 1 as dim 0 is for batch.\n   - inputs: List of variables (tensors)\n   - axis: xis along which to perform stacking.\n\n\nScala example\n\n\ndef stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1)\n\n\n\n\nPython example\n\n\ndef stack(inputs, axis=1)\n\n\n\n\nexpand_dims\n\n\nAdds a 1-sized dimension at index \"axis\".\n\n\nScala example\n\n\ndef expandDims[T: ClassTag](x: Variable[T], axis: Int)\n\n\n\n\nPython example\n\n\nexpand_dims(x, axis)\n\n\n\n\ncontiguous\n\n\nTurn the output and grad to be contiguous for the input Variable\n\n\nScala example\n\n\ndef contiguous[T: ClassTag](input: Variable[T])\n\n\n\n\nPython example\n\n\ndef contiguous(x)\n\n\n\n\nmm\n\n\nModule to perform matrix multiplication on two mini-batch inputs, producing a mini-batch.\n- \nx\n A variable.\n- \ny\n A variable.\n- \naxes\n Axes along which to perform multiplication.\n\n\nScala example\n\n\ndef mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int])\n\n\n\n\nPython example\n\n\ndef mm(x, y, axes)\n\n\n\n\nbatch_dot\n\n\nOperator that computes a dot product between samples in two tensors.\n- \nx\n Shape should only be [batch, xx]\n- \ny\n Shape should only be [batch, xx]\n- \naxes\n Integer or tuple of integers, axis or axes along which to take the dot product.\n- \nnormalize\n Whether to L2-normalize samples along the\n              dot product axis before taking the dot product.\n              If set to True, then the output of the dot product\n              is the cosine proximity between the two samples.\n\n\nScala example\n\n\ndef batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false)\n\n\n\n\nPython example\n\n\ndef batch_dot(x, y, axes=1, normalize=False)\n\n\n\n\nl2_normalize\n\n\nNormalizes a tensor wrt the L2 norm alongside the specified axis.\n- \nx\n A variable.\n- \naxis\n Axis along which to perform normalization.\n\n\nScala example\n\n\ndef l2Normalize[T: ClassTag](x: Variable[T], axis: Int)\n\n\n\n\nPython example\n\n\ndef l2_normalize(x, axis)", 
            "title": "Autograd-Math"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#mean", 
            "text": "Mean of a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepDims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keepDims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  mean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  mean(x, axis=0, keepDims=False):", 
            "title": "mean"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#abs", 
            "text": "Element-wise absolute value.\n-  x  A  Variable .  Scala example  abs(x: Variable[T])  Python example  abs(x):", 
            "title": "abs"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#sum", 
            "text": "Sum of the values in a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepDims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keepDims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  sum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  sum(x, axis=0, keepDims=False):", 
            "title": "sum"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#clip", 
            "text": "Element-wise value clipping.\n-  x  A  Variable .\n-  min  Double\n-  max  Double  Scala example  clip(x: Variable[T], min: Double, max: Double)  Python example  clip(x, min, max)", 
            "title": "clip"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#square", 
            "text": "Element-wise square.\n-  x  A  Variable .  Scala example  square(x: Variable[T])  Python example  square(x):", 
            "title": "square"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#sqrt", 
            "text": "Element-wise square root.\n-  x  A  Variable .  Scala example  sqrt(x: Variable[T])  Python example  sqrt(x):", 
            "title": "sqrt"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#maximum", 
            "text": "Element-wise maximum of two  Variables .\n-  x  A  Variable .\n-  y  A  Variable  or Double.  Scala example  maximum(x: Variable[T], y: Variable[T])  Python example  maximum(x, y):", 
            "title": "maximum"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#log", 
            "text": "Element-wise log.\n-  x  A  Variable .  Scala example  log(x: Variable[T])  Python example  log(x):", 
            "title": "log"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#exp", 
            "text": "Element-wise exponential.\n-  x  A  Variable .  Scala example  exp(x: Variable[T])  Python example  exp(x):", 
            "title": "exp"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#pow", 
            "text": "Element-wise exponentiation.\n-  x  A  Variable .\n-  a  Double.     Scala example  pow(x: Variable[T])  Python example  pow(x):", 
            "title": "pow"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#softsign", 
            "text": "Softsign of a  Variable .  Scala example  softsign(x: Variable[T])  Python example  softsign(x):", 
            "title": "softsign"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#softplus", 
            "text": "Softplus of a  Variable .  Scala example  softplus(x: Variable[T])  Python example  softplus(x):", 
            "title": "softplus"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#stack", 
            "text": "Stacks a list of rank  R  tensors into a rank  R+1  tensor.\n   You should start from 1 as dim 0 is for batch.\n   - inputs: List of variables (tensors)\n   - axis: xis along which to perform stacking.  Scala example  def stack[T: ClassTag](inputs: List[Variable[T]], axis: Int = 1)  Python example  def stack(inputs, axis=1)", 
            "title": "stack"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#expand_dims", 
            "text": "Adds a 1-sized dimension at index \"axis\".  Scala example  def expandDims[T: ClassTag](x: Variable[T], axis: Int)  Python example  expand_dims(x, axis)", 
            "title": "expand_dims"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#contiguous", 
            "text": "Turn the output and grad to be contiguous for the input Variable  Scala example  def contiguous[T: ClassTag](input: Variable[T])  Python example  def contiguous(x)", 
            "title": "contiguous"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#mm", 
            "text": "Module to perform matrix multiplication on two mini-batch inputs, producing a mini-batch.\n-  x  A variable.\n-  y  A variable.\n-  axes  Axes along which to perform multiplication.  Scala example  def mm[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int])  Python example  def mm(x, y, axes)", 
            "title": "mm"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#batch_dot", 
            "text": "Operator that computes a dot product between samples in two tensors.\n-  x  Shape should only be [batch, xx]\n-  y  Shape should only be [batch, xx]\n-  axes  Integer or tuple of integers, axis or axes along which to take the dot product.\n-  normalize  Whether to L2-normalize samples along the\n              dot product axis before taking the dot product.\n              If set to True, then the output of the dot product\n              is the cosine proximity between the two samples.  Scala example  def batchDot[T: ClassTag](x: Variable[T], y: Variable[T], axes: List[Int], normalize: Boolean = false)  Python example  def batch_dot(x, y, axes=1, normalize=False)", 
            "title": "batch_dot"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/math/#l2_normalize", 
            "text": "Normalizes a tensor wrt the L2 norm alongside the specified axis.\n-  x  A variable.\n-  axis  Axis along which to perform normalization.  Scala example  def l2Normalize[T: ClassTag](x: Variable[T], axis: Int)  Python example  def l2_normalize(x, axis)", 
            "title": "l2_normalize"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/variable/", 
            "text": "Basic operators: \n+ - * /\n\n\nThose are supported as element-wise operation.\n\n\nScala example\n\n\nx + 1.0\nx + y\n\n\n\n\nPython example\n\n\nx + 1.0\nx + y\n\n\n\n\nsqueeze\n\n\nDelete the singleton dimension(s).\n   The batch dimension needs to be unchanged.\n   For example, if input has size (2, 1, 3, 4, 1):\n   - squeeze(dim = 1) will give output size (2, 3, 4, 1)\n   - squeeze(dims = null) will give output size (2, 3, 4)\n\n\nScala example\n\n\nx.squeeze(1)\n\n\n\n\nPython example\n\n\nx.squeeze(1)\n\n\n\n\nslice\n\n\nSlice the input with the number of dimensions not being reduced.\nThe batch dimension needs to be unchanged.\n- dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension.\n     -1 means the last dimension of the input.\n- startIndex Non-negative integer. The start index on the given dimension. 0-based index.\n- length The length to be sliced. Default is 1.\n\n\nFor example, \nif input is:\n1 2 3\n4 5 6\n- slice(1, 1, 2) will give output\n2 3\n5 6\n- slice(1, 2, -1) will give output\n3\n6\n\n\nScala example\n\n\nx.slice(1, 1, 2)\n\n\n\n\nPython example\n\n\nx.slice(1, 1, 2)\n\n\n\n\nindex_select\n\n\nSelect an index of the input in the given dim and return the subset part.\n The batch dimension needs to be unchanged.\n The selected dim would be remove after this operation.\n - dim: The dimension to select. 0-based index. Cannot select the batch dimension.\n                 -1 means the last dimension of the input.\n - index: The index of the dimension to be selected. 0-based index.\n                -1 means the last dimension of the input.\n\n\nFor example, if input is:\n           1 2 3\n           4 5 6\n - Select(1, 1) will give output [2 5]\n - Select(1, -1) will give output [3 6]\n\n\nScala example\n\n\nx.select(1, 1)\n\n\n\n\nPython example\n\n\nx.select(1, 1)", 
            "title": "Autograd-Variable"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/variable/#basic-operators-", 
            "text": "Those are supported as element-wise operation.  Scala example  x + 1.0\nx + y  Python example  x + 1.0\nx + y", 
            "title": "Basic operators: + - * /"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/variable/#squeeze", 
            "text": "Delete the singleton dimension(s).\n   The batch dimension needs to be unchanged.\n   For example, if input has size (2, 1, 3, 4, 1):\n   - squeeze(dim = 1) will give output size (2, 3, 4, 1)\n   - squeeze(dims = null) will give output size (2, 3, 4)  Scala example  x.squeeze(1)  Python example  x.squeeze(1)", 
            "title": "squeeze"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/variable/#slice", 
            "text": "Slice the input with the number of dimensions not being reduced.\nThe batch dimension needs to be unchanged.\n- dim The dimension to narrow. 0-based index. Cannot narrow the batch dimension.\n     -1 means the last dimension of the input.\n- startIndex Non-negative integer. The start index on the given dimension. 0-based index.\n- length The length to be sliced. Default is 1.  For example, \nif input is:\n1 2 3\n4 5 6\n- slice(1, 1, 2) will give output\n2 3\n5 6\n- slice(1, 2, -1) will give output\n3\n6  Scala example  x.slice(1, 1, 2)  Python example  x.slice(1, 1, 2)", 
            "title": "slice"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/variable/#index_select", 
            "text": "Select an index of the input in the given dim and return the subset part.\n The batch dimension needs to be unchanged.\n The selected dim would be remove after this operation.\n - dim: The dimension to select. 0-based index. Cannot select the batch dimension.\n                 -1 means the last dimension of the input.\n - index: The index of the dimension to be selected. 0-based index.\n                -1 means the last dimension of the input.  For example, if input is:\n           1 2 3\n           4 5 6\n - Select(1, 1) will give output [2 5]\n - Select(1, -1) will give output [3 6]  Scala example  x.select(1, 1)  Python example  x.select(1, 1)", 
            "title": "index_select"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/", 
            "text": "Net\n\n\nLoad Analytics Zoo Model\n\n\nUse \nNet.load\n(in Scala) or \nNet.load\n (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.  \nNet\n (Scala) or \nNet\n(Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.\n\n\nScala example\n\n\nval model = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.load(\nhdfs://...\n) //load from hdfs\nval model = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.load(\nhdfs://...\n) //load from hdfs\nmodel = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nLoad BigDL Model\n\n\nScala example\n\n\nval model = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nval model = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nLoad Torch Model\n\n\nScala example\n\n\nval model = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nval model = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nval model = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nmodel = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nLoad Caffe Model\n\n\nScala example\n\n\nval model = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nval model = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nval model = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nmodel = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nmodel = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nLoad TensorFlow model\n\n\nWe also provides utilities to load tensorflow model.\n\n\nIf we already have a frozen graph protobuf file, we can use the \nloadTF\n api directly to\nload the tensorflow model. \n\n\nOtherwise, we should first use the \nexport_tf_checkpoint.py\n script provided by BigDL's distribution\npackage, or the \ndump_model\n function defined in \nhere\n to\ngenerate the model definition file (\nmodel.pb\n) and variable binary file (\nmodel.bin\n). \n\n\nUse Script\n\n\nGRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH\n\n\n\n\nUse python function\n\n\nimport tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path = \n/tmp/model\n\n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)\n\n\n\n\nThen we can use the \nloadTF\n api to load the tensorflow model into BigDL.\n\n\nScala example\n\n\nval modelPath = \n/tmp/model/model.pb\n\nval binPath = \n/tmp/model/model.bin\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\n\n// For tensorflow frozen graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))\n\n\n\n\nPython example\n\n\nmodel_def = \n/tmp/model/model.pb\n\nmodel_variable = \n/tmp/model/model.bin\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\n# For tensorflow frozen graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n)\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n, bin_file=model_variable)\n\n\n\n\nTFNet\n\n\nTFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel.\n\n\nThe difference between Net.loadTF() is that TFNet will call tensorflow's java api to do the computation.\n\n\nTFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model.\nWhen used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient\nfrom TFNet is set to zero.\n\n\nNote\n: This feature currently supports \ntensorflow 1.10\n and requires the OS to be one of the following 64-bit systems.\n\nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found \nhere\n.\n\n\nExport TensorFlow model to frozen inference graph\n\n\nAnalytics-zoo provides a useful utility function, \nexport_tf\n, to export a TensorFlow model\nto frozen inference graph.\n\n\nFor example:\n\n\nPython:\n\n\nimport tensorflow as tf\nfrom nets import inception\nslim = tf.contrib.slim\n\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3))\n\nwith slim.arg_scope(inception.inception_v1_arg_scope()):\n    logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \n/tmp/models/inception_v1.ckpt\n)\n\nfrom zoo.util.tf import export_tf\nexport_tf(sess, \n/tmp/models/tfnet\n, inputs=[images], outputs=[logits])\n\n\n\n\nIn the above code, the \nexport_tf\n utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names. \n\n\nCreating a TFNet\n\n\nAfter we have export the TensorFlow model, we can easily create a TFNet.\n\n\nScala:\n\n\nval m = TFNet(\n/tmp/models/tfnet\n)\n\n\n\n\nPython:\n\n\nm = TFNet.from_export_folder(\n/tmp/models/tfnet\n)\n\n\n\n\nPlease refer to \nTFNet Object Detection Example (Scala)\n\nor \nTFNet Object Detection Example (Python)\n and\nthe \nImage Classification Using TFNet Notebook\n for more information.\n\n\nTFDataset\n\n\nTFDatset represents a distributed collection of elements to be feed into TensorFlow graph.\nTFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing\nthe tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the\nTFOptimizer or TFPredictor.\n\n\nNote\n: This feature currently requires \ntensorflow 1.10\n and OS is one of the following 64-bit systems.\n\nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found \nhere\n.\n\n\nPython\n\n\n   dataset = TFDataset.from_rdd(train_rdd,\n                                 names=[\nfeatures\n, \nlabels\n],\n                                 shapes=[[28, 28, 1], [1]],\n                                 types=[tf.float32, tf.int32],\n                                 batch_size=BATCH_SIZE)\n\n\n\n\nTFOptimizer\n\n\nTFOptimizer is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. There are two ways to create a TFOptimizer.\n\n\nThe \nfrom_loss\n API takes the \nloss\n (a scalar tensor) as input and runs\nstochastic gradient descent using the given \noptimMethod\n on all the \nVariables\n that contributing\nto this loss.\n\n\nThe \nfrom_keras\n API takes a compiled \nKeras Model\n and a \nTFDataset\n and runs stochastic gradient\ndescent using the loss function, optimizer and metrics specified by the Keras model.\n\n\nNote\n: This feature currently requires \ntensorflow 1.10\n and OS is one of the following 64-bit systems.\n\nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found \nhere\n.\n\n\nPython\n\n\nloss = ...\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nFor Keras model:\n\n\n\n\nmodel = Model(inputs=..., outputs=...)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\noptimizer = TFOptimizer.from_keras(model, dataset)\noptimizer.optimize(end_trigger=MaxEpoch(5))\n\n\n\n\nTFPredictor\n\n\nTFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in\n TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the\n model prediction for the corresponding input elements.\n\n\nNote\n: This feature currently requires \ntensorflow 1.10\n and OS is one of the following 64-bit systems.\n \nUbuntu 16.04 or later\n, \nmacOS 10.12.6 or later\n and \nWindows 7 or later\n.\n\n\nTo run on other system may require you to manually compile the TensorFlow source code. Instructions can\n be found \nhere\n.\n\n\nPython\n\n\nlogist = ...\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()\n\n\n\n\nFor Keras model:\n\n\nmodel = Model(inputs=..., outputs=...)\nmodel.load_weights(\n/tmp/mnist_keras.h5\n)\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#net", 
            "text": "", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-analytics-zoo-model", 
            "text": "Use  Net.load (in Scala) or  Net.load  (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.   Net  (Scala) or  Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.  Scala example  val model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.load( hdfs://... ) //load from hdfs\nval model = Net.load( s3://... ) //load from s3  Python example  model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.load( hdfs://... ) //load from hdfs\nmodel = Net.load( s3://... ) //load from s3", 
            "title": "Load Analytics Zoo Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-bigdl-model", 
            "text": "Scala example  val model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.loadBigDL( hdfs://... ) //load from hdfs\nval model = Net.loadBigDL( s3://... ) //load from s3  Python example  model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.loadBigDL( hdfs://... ) //load from hdfs\nmodel = Net.loadBigDL( s3://... ) //load from s3", 
            "title": "Load BigDL Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-torch-model", 
            "text": "Scala example  val model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nval model = Net.loadTorch( hdfs://... ) //load from hdfs\nval model = Net.loadTorch( s3://... ) //load from s3  Python example  model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nmodel = Net.loadTorch( hdfs://... ) //load from hdfs\nmodel = Net.loadTorch( s3://... ) //load from s3", 
            "title": "Load Torch Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-caffe-model", 
            "text": "Scala example  val model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nval model = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nval model = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3  Python example  model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nmodel = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nmodel = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3", 
            "title": "Load Caffe Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-tensorflow-model", 
            "text": "We also provides utilities to load tensorflow model.  If we already have a frozen graph protobuf file, we can use the  loadTF  api directly to\nload the tensorflow model.   Otherwise, we should first use the  export_tf_checkpoint.py  script provided by BigDL's distribution\npackage, or the  dump_model  function defined in  here  to\ngenerate the model definition file ( model.pb ) and variable binary file ( model.bin ).   Use Script  GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH  Use python function  import tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path =  /tmp/model \n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)  Then we can use the  loadTF  api to load the tensorflow model into BigDL.  Scala example  val modelPath =  /tmp/model/model.pb \nval binPath =  /tmp/model/model.bin \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\n\n// For tensorflow frozen graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))  Python example  model_def =  /tmp/model/model.pb \nmodel_variable =  /tmp/model/model.bin \ninputs = [ Placeholder ]\noutputs = [ output ]\n# For tensorflow frozen graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float )\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float , bin_file=model_variable)", 
            "title": "Load TensorFlow model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfnet", 
            "text": "TFNet is a analytics-zoo layer that wraps a tensorflow frozen graph and can easily run in parallel.  The difference between Net.loadTF() is that TFNet will call tensorflow's java api to do the computation.  TFNet cannot be trained, so it can only be used for inference or as a feature extractor for fine tuning a model.\nWhen used as feature extractor, there should not be any trainable layers before TFNet, as all the gradient\nfrom TFNet is set to zero.  Note : This feature currently supports  tensorflow 1.10  and requires the OS to be one of the following 64-bit systems. Ubuntu 16.04 or later ,  macOS 10.12.6 or later  and  Windows 7 or later .  To run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found  here .", 
            "title": "TFNet"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#export-tensorflow-model-to-frozen-inference-graph", 
            "text": "Analytics-zoo provides a useful utility function,  export_tf , to export a TensorFlow model\nto frozen inference graph.  For example:  Python:  import tensorflow as tf\nfrom nets import inception\nslim = tf.contrib.slim\n\nimages = tf.placeholder(dtype=tf.float32, shape=(None, 224, 224, 3))\n\nwith slim.arg_scope(inception.inception_v1_arg_scope()):\n    logits, end_points = inception.inception_v1(images, num_classes=1001, is_training=False)\n\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess,  /tmp/models/inception_v1.ckpt )\n\nfrom zoo.util.tf import export_tf\nexport_tf(sess,  /tmp/models/tfnet , inputs=[images], outputs=[logits])  In the above code, the  export_tf  utility function will frozen the TensorFlow graph, strip unused operation according to the inputs and outputs and save it to the specified directory along with the input/output tensor names.", 
            "title": "Export TensorFlow model to frozen inference graph"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#creating-a-tfnet", 
            "text": "After we have export the TensorFlow model, we can easily create a TFNet.  Scala:  val m = TFNet( /tmp/models/tfnet )  Python:  m = TFNet.from_export_folder( /tmp/models/tfnet )  Please refer to  TFNet Object Detection Example (Scala) \nor  TFNet Object Detection Example (Python)  and\nthe  Image Classification Using TFNet Notebook  for more information.", 
            "title": "Creating a TFNet"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfdataset", 
            "text": "TFDatset represents a distributed collection of elements to be feed into TensorFlow graph.\nTFDatasets can be created using a RDD and each of its records is a list of numpy.ndarray representing\nthe tensors to be feed into TensorFlow graph on each iteration. TFDatasets must be used with the\nTFOptimizer or TFPredictor.  Note : This feature currently requires  tensorflow 1.10  and OS is one of the following 64-bit systems. Ubuntu 16.04 or later ,  macOS 10.12.6 or later  and  Windows 7 or later .  To run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found  here .  Python     dataset = TFDataset.from_rdd(train_rdd,\n                                 names=[ features ,  labels ],\n                                 shapes=[[28, 28, 1], [1]],\n                                 types=[tf.float32, tf.int32],\n                                 batch_size=BATCH_SIZE)", 
            "title": "TFDataset"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfoptimizer", 
            "text": "TFOptimizer is the class that does all the hard work in distributed training, such as model\ndistribution and parameter synchronization. There are two ways to create a TFOptimizer.  The  from_loss  API takes the  loss  (a scalar tensor) as input and runs\nstochastic gradient descent using the given  optimMethod  on all the  Variables  that contributing\nto this loss.  The  from_keras  API takes a compiled  Keras Model  and a  TFDataset  and runs stochastic gradient\ndescent using the loss function, optimizer and metrics specified by the Keras model.  Note : This feature currently requires  tensorflow 1.10  and OS is one of the following 64-bit systems. Ubuntu 16.04 or later ,  macOS 10.12.6 or later  and  Windows 7 or later .  To run on other system may require you to manually compile the TensorFlow source code. Instructions can\nbe found  here .  Python  loss = ...\noptimizer = TFOptimizer.from_loss(loss, Adam(1e-3))\noptimizer.optimize(end_trigger=MaxEpoch(5))  For Keras model:  \n\nmodel = Model(inputs=..., outputs=...)\n\nmodel.compile(optimizer='rmsprop',\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\noptimizer = TFOptimizer.from_keras(model, dataset)\noptimizer.optimize(end_trigger=MaxEpoch(5))", 
            "title": "TFOptimizer"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfpredictor", 
            "text": "TFPredictor takes a list of TensorFlow tensors as the model outputs and feed all the elements in\n TFDatasets to produce those outputs and returns a Spark RDD with each of its elements representing the\n model prediction for the corresponding input elements.  Note : This feature currently requires  tensorflow 1.10  and OS is one of the following 64-bit systems.\n  Ubuntu 16.04 or later ,  macOS 10.12.6 or later  and  Windows 7 or later .  To run on other system may require you to manually compile the TensorFlow source code. Instructions can\n be found  here .  Python  logist = ...\npredictor = TFPredictor.from_outputs(sess, [logits])\npredictions_rdd = predictor.predict()  For Keras model:  model = Model(inputs=..., outputs=...)\nmodel.load_weights( /tmp/mnist_keras.h5 )\npredictor = TFPredictor.from_keras(model, dataset)\npredictions_rdd = predictor.predict()", 
            "title": "TFPredictor"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/", 
            "text": "Inference Model\n\n\nOverview\n\n\nInference is a package in Analytics Zoo aiming to provide high level APIs to speed-up development. It \nallows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\nInference provides multiple Scala interfaces.\n\n\nHighlights\n\n\n\n\n\n\nEasy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\n\n\n\n\n\n\nSupport transformation of various input data type, thus supporting future prediction tasks.\n\n\n\n\n\n\nTransparently support the OpenVINO toolkit, which deliver a significant boost for inference speed (\nup to 19.9x\n).\n\n\n\n\n\n\nPrimary APIs for Java\n\n\nload\n\n\nAbstractInferenceModel provides \nload\n API for loading a pre-trained model,\nthus we can conveniently load various kinds of pre-trained models in java applications. The load result of\n\nAbstractInferenceModel\n is an \nAbstractModel\n.\nWe just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nload\n\n\nload\n method is to load a BigDL model.\n\n\nloadCaffe\n\n\nloadCaffe\n method is to load a caffe model.\n\n\nloadTF\n\n\nloadTF\n method is to load a tensorflow model. There are two backends to load a tensorflow model and to do the predictions: TFNet and OpenVINO. For OpenVINO backend, supported tensorflow models are listed below:\n\n\nfaster_rcnn_inception_resnet_v2_atrous_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_oid\nfaster_rcnn_inception_resnet_v2_atrous_oid\nfaster_rcnn_nas_coco\nfaster_rcnn_nas_lowproposals_coco\nfaster_rcnn_resnet101_coco\nfaster_rcnn_resnet101_kitti\nfaster_rcnn_resnet101_lowproposals_coco\nmask_rcnn_inception_resnet_v2_atrous_coco\nmask_rcnn_inception_v2_coco\nmask_rcnn_resnet101_atrous_coco\nmask_rcnn_resnet50_atrous_coco\nssd_inception_v2_coco\nssd_mobilenet_v1_coco\nssd_mobilenet_v2_coco\nssdlite_mobilenet_v2_coco\n\n\n\nloadOpenVINO\n\n\nloadOpenVINO\n method is to load an OpenVINO Intermediate Representation(IR).\n\n\npredict\n\n\nAbstractInferenceModel provides \npredict\n API for prediction with loaded model.\nThe predict result of\nAbstractInferenceModel\n is a \nList\nList\nJTensor\n by default.\n\n\nExamples\n\n\nIt's very easy to apply abstract inference model for inference with below code piece.\nYou will need to write a subclass that extends AbstractinferenceModel.\n\n\nimport com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n }\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\nList\nList\nJTensor\n result = model.predict(inputList);\n\n\n\n\nPrimary APIs for Scala\n\n\nInferenceModel\n\n\nInferenceModel\n is a thead-safe wrapper of AbstractModels, which can be used to load models and do the predictions.\n\n\ndoLoad\n\n\ndoLoad\n method is to load a bigdl, analytics-zoo model.\n\n\ndoLoadCaffe\n\n\ndoLoadCaffe\n method is to load a caffe model.\n\n\ndoLoadTF\n\n\ndoLoadTF\n method is to load a tensorflow model. The model can be loaded as a \nFloatModel\n or an \nOpenVINOModel\n. There are two backends to load a tensorflow model: TFNet and OpenVINO. \n\n\nFor OpenVINO backend, supported tensorflow models are listed below:\n\n\nfaster_rcnn_inception_resnet_v2_atrous_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_oid\nfaster_rcnn_inception_resnet_v2_atrous_oid\nfaster_rcnn_nas_coco\nfaster_rcnn_nas_lowproposals_coco\nfaster_rcnn_resnet101_coco\nfaster_rcnn_resnet101_kitti\nfaster_rcnn_resnet101_lowproposals_coco\nmask_rcnn_inception_resnet_v2_atrous_coco\nmask_rcnn_inception_v2_coco\nmask_rcnn_resnet101_atrous_coco\nmask_rcnn_resnet50_atrous_coco\nssd_inception_v2_coco\nssd_mobilenet_v1_coco\nssd_mobilenet_v2_coco\nssdlite_mobilenet_v2_coco\n\n\n\ndoLoadOpenVINO\n\n\ndoLoadOpenVINO\n method is to load an OpenVINO Intermediate Representation(IR).\n\n\ndoReload\n\n\ndoReload\n method is to reload the bigdl, analytics-zoo model.\n\n\ndoPredict\n\n\ndoPredict\n method is to do the prediction.\n\n\nInferenceSupportive\n\n\nInferenceSupportive\n is a trait containing several methods for type transformation, which transfer a model input \nto a valid data type, thus supporting future inference model prediction tasks.\n\n\nFor example, method \ntransferTensorToJTensor\n convert a model input of data type \nTensor\n \nto \nJTensor\n\n, which will be the input for a FloatInferenceModel.\n\n\nAbstractModel\n\n\nAbstractModel\n is an abstract class to provide APIs for basic functions - \npredict\n interface for prediction, \ncopy\n interface for coping the model into the queue of AbstractModels, \nrelease\n interface for releasing the model and \nisReleased\n interface for checking the state of model release.  \n\n\nFloatModel\n\n\nFloatModel\n is an extending class of \nAbstractModel\n and achieves all \nAbstractModel\n interfaces.\n\n\nOpenVINOModel\n\n\nOpenVINOModel\n is an extending class of \nAbstractModel\n. It achieves all \nAbstractModel\n functions.\n\n\nInferenceModelFactory\n\n\nInferenceModelFactory\n is an object with APIs for loading pre-trained Analytics Zoo models, Caffe models, Tensorflow models and OpenVINO Intermediate Representations(IR).\nAnalytics Zoo models, Caffe models, Tensorflow models can be loaded as FloatModels. The load result of it is a \nFloatModel\n\nTensorflow models and OpenVINO Intermediate Representations(IR) can be loaded as OpenVINOModels. The load result of it is an \nOpenVINOModel\n. \nThe load result of it is a \nFloatModel\n or an \nOpenVINOModel\n. \n\n\nOpenVinoInferenceSupportive\n\n\nOpenVinoInferenceSupportive\n is an extending object of \nInferenceSupportive\n and focus on the implementation of loading pre-trained models, including tensorflow models and OpenVINO Intermediate Representations(IR). \nThere are two backends to load a tensorflow model: TFNet and OpenVINO. For OpenVINO backend, \nsupported tensorflow models\n are listed in the section of \ndoLoadTF\n method of \nInferenceModel\n API above.", 
            "title": "Inference"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#inference-model", 
            "text": "", 
            "title": "Inference Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#overview", 
            "text": "Inference is a package in Analytics Zoo aiming to provide high level APIs to speed-up development. It \nallows user to conveniently use pre-trained models from Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).\nInference provides multiple Scala interfaces.", 
            "title": "Overview"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#highlights", 
            "text": "Easy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).    Support transformation of various input data type, thus supporting future prediction tasks.    Transparently support the OpenVINO toolkit, which deliver a significant boost for inference speed ( up to 19.9x ).", 
            "title": "Highlights"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#primary-apis-for-java", 
            "text": "load  AbstractInferenceModel provides  load  API for loading a pre-trained model,\nthus we can conveniently load various kinds of pre-trained models in java applications. The load result of AbstractInferenceModel  is an  AbstractModel .\nWe just need to specify the model path and optionally weight path if exists where we previously saved the model.  load  load  method is to load a BigDL model.  loadCaffe  loadCaffe  method is to load a caffe model.  loadTF  loadTF  method is to load a tensorflow model. There are two backends to load a tensorflow model and to do the predictions: TFNet and OpenVINO. For OpenVINO backend, supported tensorflow models are listed below:  faster_rcnn_inception_resnet_v2_atrous_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_oid\nfaster_rcnn_inception_resnet_v2_atrous_oid\nfaster_rcnn_nas_coco\nfaster_rcnn_nas_lowproposals_coco\nfaster_rcnn_resnet101_coco\nfaster_rcnn_resnet101_kitti\nfaster_rcnn_resnet101_lowproposals_coco\nmask_rcnn_inception_resnet_v2_atrous_coco\nmask_rcnn_inception_v2_coco\nmask_rcnn_resnet101_atrous_coco\nmask_rcnn_resnet50_atrous_coco\nssd_inception_v2_coco\nssd_mobilenet_v1_coco\nssd_mobilenet_v2_coco\nssdlite_mobilenet_v2_coco  loadOpenVINO  loadOpenVINO  method is to load an OpenVINO Intermediate Representation(IR).  predict  AbstractInferenceModel provides  predict  API for prediction with loaded model.\nThe predict result of AbstractInferenceModel  is a  List List JTensor  by default.", 
            "title": "Primary APIs for Java"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#examples", 
            "text": "It's very easy to apply abstract inference model for inference with below code piece.\nYou will need to write a subclass that extends AbstractinferenceModel.  import com.intel.analytics.zoo.pipeline.inference.AbstractInferenceModel;\nimport com.intel.analytics.zoo.pipeline.inference.JTensor;\n\npublic class TextClassificationModel extends AbstractInferenceModel {\n    public TextClassificationModel() {\n        super();\n    }\n }\nTextClassificationModel model = new TextClassificationModel();\nmodel.load(modelPath, weightPath);\nList List JTensor  result = model.predict(inputList);", 
            "title": "Examples"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/inference/#primary-apis-for-scala", 
            "text": "InferenceModel  InferenceModel  is a thead-safe wrapper of AbstractModels, which can be used to load models and do the predictions.  doLoad  doLoad  method is to load a bigdl, analytics-zoo model.  doLoadCaffe  doLoadCaffe  method is to load a caffe model.  doLoadTF  doLoadTF  method is to load a tensorflow model. The model can be loaded as a  FloatModel  or an  OpenVINOModel . There are two backends to load a tensorflow model: TFNet and OpenVINO.   For OpenVINO backend, supported tensorflow models are listed below:  faster_rcnn_inception_resnet_v2_atrous_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_coco\nfaster_rcnn_inception_resnet_v2_atrous_lowproposals_oid\nfaster_rcnn_inception_resnet_v2_atrous_oid\nfaster_rcnn_nas_coco\nfaster_rcnn_nas_lowproposals_coco\nfaster_rcnn_resnet101_coco\nfaster_rcnn_resnet101_kitti\nfaster_rcnn_resnet101_lowproposals_coco\nmask_rcnn_inception_resnet_v2_atrous_coco\nmask_rcnn_inception_v2_coco\nmask_rcnn_resnet101_atrous_coco\nmask_rcnn_resnet50_atrous_coco\nssd_inception_v2_coco\nssd_mobilenet_v1_coco\nssd_mobilenet_v2_coco\nssdlite_mobilenet_v2_coco  doLoadOpenVINO  doLoadOpenVINO  method is to load an OpenVINO Intermediate Representation(IR).  doReload  doReload  method is to reload the bigdl, analytics-zoo model.  doPredict  doPredict  method is to do the prediction.  InferenceSupportive  InferenceSupportive  is a trait containing several methods for type transformation, which transfer a model input \nto a valid data type, thus supporting future inference model prediction tasks.  For example, method  transferTensorToJTensor  convert a model input of data type  Tensor  \nto  JTensor \n, which will be the input for a FloatInferenceModel.  AbstractModel  AbstractModel  is an abstract class to provide APIs for basic functions -  predict  interface for prediction,  copy  interface for coping the model into the queue of AbstractModels,  release  interface for releasing the model and  isReleased  interface for checking the state of model release.    FloatModel  FloatModel  is an extending class of  AbstractModel  and achieves all  AbstractModel  interfaces.  OpenVINOModel  OpenVINOModel  is an extending class of  AbstractModel . It achieves all  AbstractModel  functions.  InferenceModelFactory  InferenceModelFactory  is an object with APIs for loading pre-trained Analytics Zoo models, Caffe models, Tensorflow models and OpenVINO Intermediate Representations(IR).\nAnalytics Zoo models, Caffe models, Tensorflow models can be loaded as FloatModels. The load result of it is a  FloatModel \nTensorflow models and OpenVINO Intermediate Representations(IR) can be loaded as OpenVINOModels. The load result of it is an  OpenVINOModel . \nThe load result of it is a  FloatModel  or an  OpenVINOModel .   OpenVinoInferenceSupportive  OpenVinoInferenceSupportive  is an extending object of  InferenceSupportive  and focus on the implementation of loading pre-trained models, including tensorflow models and OpenVINO Intermediate Representations(IR). \nThere are two backends to load a tensorflow model: TFNet and OpenVINO. For OpenVINO backend,  supported tensorflow models  are listed in the section of  doLoadTF  method of  InferenceModel  API above.", 
            "title": "Primary APIs for Scala"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/featureset/", 
            "text": "A FeatureSet can be used to represent an input pipeline as a collection of elements which is used in the model optimization process. You can use FeatureSet to switch the memory type between \nDRAM\n \nand \nPMEM\n in consideration of the hardware optimization.\n\n \nDRAM\n is the default mode which would cached the training data in main memory.\n\n \nPMEM\n mode would try to cache the training data in AEP rather than main memory. You should install the AEP hardware and \nmemkind library\n before switching\n to this option. \n\n\n\n\nThe FeatureSet can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the data() method to get the data sequence.\n\n\nYou can use FeatureSet.rdd() function to create a FeatureSet.\n\n\n\n\nScala example:\n\n\n   import com.intel.analytics.zoo.feature.FeatureSet\n   val featureSet = FeatureSet.rdd(rawRDD, memoryType = DRAM)\n   // featureSet -\n feature transformer -\n batch and sample transformer\n   model.fit(featureSet)\n\n\n\n\nTake a look at \nInceptionV1 example\n for more details.", 
            "title": "FeatureSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/relation/", 
            "text": "A Relation represents the relationship between two items.\n\n\nScala/Python\n\n\nrelation = Relation(id1, id2, label)\n\n\n\n\n\n\nid1\n: String. The id of one item.\n\n\nid2\n: String. The id of the other item.\n\n\nlabel\n: Integer. The label between the two items. By convention you can use 0 if they are unrelated and a positive integer if they are related.\n\n\n\n\nA RelationPair is made up of two relations of the same id1, namely:\n\n\n\n\nRelation(id1, id2Positive, label\n0) (A positive Relation)\n\n\nRelation(id1, id2Negative, label=0) (A negative Relation)\n\n\n\n\n\n\nRead Relations\n\n\nFrom csv or txt file\n\n\nEach record is supposed to contain id1, id2 and label described above in the exact order.\n\n\nFor csv file, it should be without header.\n\n\nFor txt file, each line should contain one record with fields separated by comma.\n\n\nScala\n\n\nrelationsRDD = Relations.read(path, sc, minPartitions = 1)\nrelationsArray = Relations.read(path)\n\n\n\n\n\n\npath\n: The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).\n\n\nsc\n: An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation.\n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.\n\n\n\n\nPython\n\n\nrelations_rdd = Relations.read(path, sc, min_partitions = 1)\nrelations_list = Relations.read(path)\n\n\n\n\n\n\npath\n: The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).\n\n\nsc\n: An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation.\n\n\nmin_partitions\n: Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.\n\n\n\n\nFrom parquet file\n\n\nRead relations from parquet file exactly with the schema in Relation. Return RDD of Relation.\n\n\nScala\n\n\nrelationsRDD = Relations.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\nrelations_rdd = Relations.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.", 
            "title": "Relation"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/relation/#read-relations", 
            "text": "From csv or txt file  Each record is supposed to contain id1, id2 and label described above in the exact order.  For csv file, it should be without header.  For txt file, each line should contain one record with fields separated by comma.  Scala  relationsRDD = Relations.read(path, sc, minPartitions = 1)\nrelationsArray = Relations.read(path)   path : The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).  sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return array of Relation.  minPartitions : Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.   Python  relations_rdd = Relations.read(path, sc, min_partitions = 1)\nrelations_list = Relations.read(path)   path : The path to the relations file, which can either be a local file path or HDFS path (in this case sc needs to be specified).  sc : An instance of SparkContext. If specified, return RDD of Relation. Otherwise, return list of Relation.  min_partitions : Integer. A suggestion value of the minimal partition number for input\ntexts. Only takes effect when sc is specified. Default is 1.   From parquet file  Read relations from parquet file exactly with the schema in Relation. Return RDD of Relation.  Scala  relationsRDD = Relations.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  relations_rdd = Relations.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.", 
            "title": "Read Relations"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/", 
            "text": "Analytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nScala:\n\n\npackage com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame\n}\n\n\n\n\nRead the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.\n\n\n\n\npath: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).\n\n\nsc: SparkContext to be used.\n\n\nminPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead\n\n\nresizeH: height after resize, by default is -1 which will not resize the image\n\n\nresizeW: width after resize, by default is -1 which will not resize the image\n\n\n\n\nPython:\n\n\nclass zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type=\nfloat\n)\n\n\n\n\nImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala APIs:\n\n\nobject com.intel.analytics.zoo.feature.image.ImageSet\n\n\n\n\ndef array(data: Array[ImageFeature]): LocalImageSet\n\n\n\n\nCreate LocalImageSet from array of ImeageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\ndef rdd(data: RDD[ImageFeature]): DistributedImageSet\n\n\n\n\nCreate DistributedImageSet from rdd of ImageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\n  def read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\nresizeH: height after resize, by default is -1 which will not resize the image\n\n\nresizeW: width after resize, by default is -1 which will not resize the image\n\n\n\n\nExample:\n\n\n// create LocalImageSet from an image folder\nval localImageSet = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.ImageSet\n\n\n\n\nread(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type=\nfloat\n)\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nmin_partitions: A suggestion value of the minimal splitting number for input data.\n\n\nresize_height height after resize, by default is -1 which will not resize the image\n\n\nresize_width width after resize, by default is -1 which will not resize the image\n\n\n\n\nPython example:\n\n\n# create LocalImageSet from an image folder\nlocal_image_set2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageSet from an image folder\ndistributed_image_set = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. \n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndeltaLow: low bound of brightness parameter\n\n\ndeltaHigh: high bound of brightness parameter\n\n\n\n\nExample:\n\n\nval transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type=\nfloat\n)\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndelta_low: low bound of brightness parameter\n\n\ndelta_high: high bound of brightness parameter\n\n\n\n\nExample:\n\n\ntransformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)\n\n\n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBytesToMat\n\ndef apply(byteKey: String = ImageFeature.bytes,\n          imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat\n\n\n\n\nTransform byte array(original image file in byte) to OpenCVMat\n\n\n\n\nbyteKey: key that maps byte array. Default value is ImageFeature.bytes\n\n\nimageCodec: specifying the color type of a loaded image, same as in OpenCV.imread.\n              1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.\n              2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one\n              3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one\n              4. \n0 Return a 3-channel color image.\n              Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel.\n              5. =0 Return a grayscale image.\n              6. \n0 Return the loaded image as is (with alpha channel).\n              Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED.\n\n\n\n\nExample:\n\n\nval imageSet = ImageSet.read(path, sc)\nimageSet -\n ImageBytesToMat()\n\n\n\n\n3D Image Support\n\n\nCreate ImageSet for 3D Images\n\n\nFor 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python).\n\n\nScala example:\n\n\nval image = ImageFeature3D(tensor)\n\n// create local imageset for 3D images\nval arr = Array[ImageFeature](image)\nval localImageSet = ImageSet.array(arr)\n\n// create distributed imageset for 3D images\nval rdd = sc.parallelize(Seq[ImageFeature](image))\nval imageSet = ImageSet.rdd(rdd)\n\n\n\n\nPython example:\n\n\n\n# get image numpy array\nimg_np =\n\n# create local imageset for 3D images\nlocal_imageset = LocalImageSet(image_list=[img_np])\n\n# create distributed imageset for 3D images\nrdd = sc.parallelize([img_np])\ndist_imageSet = DistributedImageSet(image_rdd=rdd)\n\n\n\n\n3D Image Transformers\n\n\nAnalytics zoo also provides several image transformers for 3D Images.\nThe usage is similar as 2D image transformers. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet.\n\n\nCurrently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation.\n\n\nCrop transformers\n\n\nCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.Crop3D\n\n// create Crop3D transformer\nval cropper = Crop3D(start, patchSize)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size.\n   * start: start point array(depth, height, width) for cropping\n   * patchSize: patch size array(depth, height, width)\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import Crop3D\n\ncrop = Crop3D(start, patch_size)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\nstart: start point list[]depth, height, width] for cropping\n\n\npatch_size: patch size list[]depth, height, width]\n\n\n\n\nRandomCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.RandomCrop3D\n\n// create Crop3D transformer\nval cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a random patch from an 3D image with specified patch size. The patch size should be less than the image size.\n\n cropDepth: depth after crop\n\n cropHeight: height after crop\n* cropWidth: width after crop\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import RandomCrop3D\n\ncrop = RandomCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\ncrop_depth: depth after crop\n\n\ncrop_height: height after crop\n\n\ncrop_width: width after crop\n\n\n\n\nCenterCrop3D\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.CenterCrop3D\n\n// create Crop3D transformer\nval cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)\n\n\n\n\nCrop a \ncropDepth\n x \ncropWidth\n x \ncropHeight\n patch from center of image. The patch size should be less than the image size.\n\n cropDepth: depth after crop\n\n cropHeight: height after crop\n* cropWidth: width after crop\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import CenterCrop3D\n\ncrop = CenterCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)\n\n\n\n\n\n\ncrop_depth: depth after crop\n\n\ncrop_height: height after crop\n\n\ncrop_width: width after crop\n\n\n\n\nRotation\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.Rotate3D\n\n// create Crop3D transformer\nval rotAngles = Array[Double](yaw, pitch, roll)\nval rot = Rotate3D(rotAngles)\nval outputImageSet = imageset.transform(rot)\n\n\n\n\nRotate a 3D image with specified angles.\n* rotationAngles: the angles for rotation.\n   Which are the yaw(a counterclockwise rotation angle about the z-axis),\n   pitch(a counterclockwise rotation angle about the y-axis),\n   and roll(a counterclockwise rotation angle about the x-axis).\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import Rotate3D\n\nrot = Rotate3D(rotation_angles)\ntransformed_image = rot(image_set)\n\n\n\n\nAffine Transformation\n\n\nScala:\n\n\nimport com.intel.analytics.zoo.feature.image3d.AffineTransform3D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// create Crop3D transformer\nval matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4)\nval matTensor = Tensor[Double](matArray, Array[Int](3, 3))\nval trans = Tensor[Double](3)\ntrans(1) = 0\ntrans(2) = 1.8\ntrans(3) = 1.1\nval aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode = \nclamp\n, padVal = 0)\nval outputImageSet = imageset.transform(aff)\n\n\n\n\nAffine transformer implements affine transformation on a given tensor.\nTo avoid defects in resampling, the mapping is from destination to source.\ndst(z,y,x) = src(f(z),f(y),f(x)) where f: dst -\n src\n\n\n\n\nmat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src.\n\n\ntranslation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis.\n\n\nclampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image.\n\n\npadVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.\n\n\n\n\nPython:\n\n\nfrom zoo.feature.image3d.transformation import AffineTransform3D\n\naffine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val)\ntransformed_image = affine(image_set)\n\n\n\n\n\n\naffine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src.\n\n\ntranslation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis.\n\n\nclamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image.\n\n\npad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.", 
            "title": "Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-to-data-frame", 
            "text": "Scala:  package com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): DataFrame\n}  Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.   path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).  sc: SparkContext to be used.  minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead  resizeH: height after resize, by default is -1 which will not resize the image  resizeW: width after resize, by default is -1 which will not resize the image   Python:  class zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, resizeH=-1, resizeW=-1, bigdl_type= float )", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala APIs:  object com.intel.analytics.zoo.feature.image.ImageSet  def array(data: Array[ImageFeature]): LocalImageSet  Create LocalImageSet from array of ImeageFeature   data: array of ImageFeature   def rdd(data: RDD[ImageFeature]): DistributedImageSet  Create DistributedImageSet from rdd of ImageFeature   data: array of ImageFeature     def read(path: String, sc: SparkContext = null, minPartitions: Int = 1, resizeH: Int = -1, resizeW: Int = -1): ImageSet  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.  resizeH: height after resize, by default is -1 which will not resize the image  resizeW: width after resize, by default is -1 which will not resize the image   Example:  // create LocalImageSet from an image folder\nval localImageSet = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageSet from an image folder\nval distributedImageSet2 = ImageSet.read( /tmp/image/ , sc, 2)  Python APIs:  class zoo.feature.image.ImageSet  read(path, sc=None, min_partitions=1, resize_height=-1, resize_width=-1, bigdl_type= float )  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  min_partitions: A suggestion value of the minimal splitting number for input data.  resize_height height after resize, by default is -1 which will not resize the image  resize_width width after resize, by default is -1 which will not resize the image   Python example:  # create LocalImageSet from an image folder\nlocal_image_set2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageSet from an image folder\ndistributed_image_set = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "ImageSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#image-transformer", 
            "text": "Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call  transform  with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training.   Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness  Adjust the image brightness.   deltaLow: low bound of brightness parameter  deltaHigh: high bound of brightness parameter   Example:  val transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)  Python APIs:  class zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type= float )  Adjust the image brightness.   delta_low: low bound of brightness parameter  delta_high: high bound of brightness parameter   Example:  transformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)  Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBytesToMat\n\ndef apply(byteKey: String = ImageFeature.bytes,\n          imageCodec: Int = Imgcodecs.CV_LOAD_IMAGE_UNCHANGED): ImageBytesToMat  Transform byte array(original image file in byte) to OpenCVMat   byteKey: key that maps byte array. Default value is ImageFeature.bytes  imageCodec: specifying the color type of a loaded image, same as in OpenCV.imread.\n              1. CV_LOAD_IMAGE_ANYDEPTH - If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.\n              2. CV_LOAD_IMAGE_COLOR - If set, always convert image to the color one\n              3. CV_LOAD_IMAGE_GRAYSCALE - If set, always convert image to the grayscale one\n              4.  0 Return a 3-channel color image.\n              Note The alpha channel is stripped from the output image. Use negative value if you need the alpha channel.\n              5. =0 Return a grayscale image.\n              6.  0 Return the loaded image as is (with alpha channel).\n              Default value is Imgcodecs.CV_LOAD_IMAGE_UNCHANGED.   Example:  val imageSet = ImageSet.read(path, sc)\nimageSet -  ImageBytesToMat()", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#3d-image-support", 
            "text": "", 
            "title": "3D Image Support"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#create-imageset-for-3d-images", 
            "text": "For 3D images, you can still use ImageSet as the collection of ImageFeature3D. You can create ImageSet for 3D images in the similar way as for 2D images. Since we do not provide 3D image reader in analytics zoo, before create ImageSet, we suppose you already read 3D images to tensor(scala) or numpy array(python).  Scala example:  val image = ImageFeature3D(tensor)\n\n// create local imageset for 3D images\nval arr = Array[ImageFeature](image)\nval localImageSet = ImageSet.array(arr)\n\n// create distributed imageset for 3D images\nval rdd = sc.parallelize(Seq[ImageFeature](image))\nval imageSet = ImageSet.rdd(rdd)  Python example:  \n# get image numpy array\nimg_np =\n\n# create local imageset for 3D images\nlocal_imageset = LocalImageSet(image_list=[img_np])\n\n# create distributed imageset for 3D images\nrdd = sc.parallelize([img_np])\ndist_imageSet = DistributedImageSet(image_rdd=rdd)", 
            "title": "Create ImageSet for 3D Images"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#3d-image-transformers", 
            "text": "Analytics zoo also provides several image transformers for 3D Images.\nThe usage is similar as 2D image transformers. After create these transformers, call  transform  with ImageSet to get transformed ImageSet.  Currently we support three kinds of 3D image transformers: Crop, Rotation and Affine Transformation.", 
            "title": "3D Image Transformers"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#crop-transformers", 
            "text": "", 
            "title": "Crop transformers"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#crop3d", 
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.Crop3D\n\n// create Crop3D transformer\nval cropper = Crop3D(start, patchSize)\nval outputImageSet = imageset.transform(cropper)  Crop a patch from a 3D image from 'start' of patch size. The patch size should be less than the image size.\n   * start: start point array(depth, height, width) for cropping\n   * patchSize: patch size array(depth, height, width)  Python:  from zoo.feature.image3d.transformation import Crop3D\n\ncrop = Crop3D(start, patch_size)\ntransformed_image = crop(image_set)   start: start point list[]depth, height, width] for cropping  patch_size: patch size list[]depth, height, width]", 
            "title": "Crop3D"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#randomcrop3d", 
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.RandomCrop3D\n\n// create Crop3D transformer\nval cropper = RandomCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)  Crop a random patch from an 3D image with specified patch size. The patch size should be less than the image size.  cropDepth: depth after crop  cropHeight: height after crop\n* cropWidth: width after crop  Python:  from zoo.feature.image3d.transformation import RandomCrop3D\n\ncrop = RandomCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)   crop_depth: depth after crop  crop_height: height after crop  crop_width: width after crop", 
            "title": "RandomCrop3D"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#centercrop3d", 
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.CenterCrop3D\n\n// create Crop3D transformer\nval cropper = CenterCrop3D(cropDepth, cropHeight, cropWidth)\nval outputImageSet = imageset.transform(cropper)  Crop a  cropDepth  x  cropWidth  x  cropHeight  patch from center of image. The patch size should be less than the image size.  cropDepth: depth after crop  cropHeight: height after crop\n* cropWidth: width after crop  Python:  from zoo.feature.image3d.transformation import CenterCrop3D\n\ncrop = CenterCrop3D(crop_depth, crop_height, crop_width)\ntransformed_image = crop(image_set)   crop_depth: depth after crop  crop_height: height after crop  crop_width: width after crop", 
            "title": "CenterCrop3D"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#rotation", 
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.Rotate3D\n\n// create Crop3D transformer\nval rotAngles = Array[Double](yaw, pitch, roll)\nval rot = Rotate3D(rotAngles)\nval outputImageSet = imageset.transform(rot)  Rotate a 3D image with specified angles.\n* rotationAngles: the angles for rotation.\n   Which are the yaw(a counterclockwise rotation angle about the z-axis),\n   pitch(a counterclockwise rotation angle about the y-axis),\n   and roll(a counterclockwise rotation angle about the x-axis).  Python:  from zoo.feature.image3d.transformation import Rotate3D\n\nrot = Rotate3D(rotation_angles)\ntransformed_image = rot(image_set)", 
            "title": "Rotation"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#affine-transformation", 
            "text": "Scala:  import com.intel.analytics.zoo.feature.image3d.AffineTransform3D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// create Crop3D transformer\nval matArray = Array[Double](1, 0, 0, 0, 1.5, 1.2, 0, 1.3, 1.4)\nval matTensor = Tensor[Double](matArray, Array[Int](3, 3))\nval trans = Tensor[Double](3)\ntrans(1) = 0\ntrans(2) = 1.8\ntrans(3) = 1.1\nval aff = AffineTransform3D(mat=matTensor, translation = trans, clampMode =  clamp , padVal = 0)\nval outputImageSet = imageset.transform(aff)  Affine transformer implements affine transformation on a given tensor.\nTo avoid defects in resampling, the mapping is from destination to source.\ndst(z,y,x) = src(f(z),f(y),f(x)) where f: dst -  src   mat: [Tensor[Double], dim: DxHxW] defines affine transformation from dst to src.  translation: [Tensor[Double], dim: 3, default: (0,0,0)] defines translation in each axis.  clampMode: [String, (default: \"clamp\",'padding')] defines how to handle interpolation off the input image.  padVal: [Double, default: 0] defines padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.   Python:  from zoo.feature.image3d.transformation import AffineTransform3D\n\naffine = AffineTransform3D(affine_mat, translation, clamp_mode, pad_val)\ntransformed_image = affine(image_set)   affine_mat: numpy array in 3x3 shape.Define affine transformation from dst to src.  translation: numpy array in 3 dimension.Default value is np.zero(3). Define translation in each axis.  clamp_mode: str, default value is \"clamp\". Define how to handle interpolation off the input image.  pad_val: float, default is 0.0. Define padding value when clampMode=\"padding\". Setting this value when clampMode=\"clamp\" will cause an error.", 
            "title": "Affine Transformation"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/", 
            "text": "Analytics Zoo provides a series of text related APIs for end-to-end text processing pipeline,\nincluding text loading, pre-processing, training and inference, etc.\n\n\n\n\nTextSet\n\n\nTextSet\n is a collection of TextFeatures where each \nTextFeature\n keeps information of a single text record.\n\n\nTextSet\n can either be a \nDistributedTextSet\n consisting of text RDD or a \nLocalTextSet\n consisting of text array.\n\n\n\n\nRead texts as TextSet\n\n\nRead texts from a directory\n\n\nRead texts with labels from a directory.\n\n\nUnder this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.\n\n\nScala\n\n\ntextSet = TextSet.read(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from csv file\n\n\nRead texts with id from csv file.\n\n\nEach record is supposed to contain id(String) and text(String) in order.\n\n\nNote that the csv file should be without header.\n\n\nScala\n\n\ntextSet = TextSet.readCSV(path, sc = null, minPartitions = 1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet. \n\n\nminPartitions\n: Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_csv(path, sc=None, min_partitions=1)\n\n\n\n\n\n\npath\n: String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.\n\n\nsc\n: An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet. \n\n\nmin_partitions\n: Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.\n\n\n\n\nRead texts from parquet file\n\n\nRead texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.\n\n\nScala\n\n\ntextSet = TextSet.readParquet(path, sqlContext)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsqlContext\n: An instance of SQLContext.\n\n\n\n\nPython\n\n\ntext_set = TextSet.read_parquet(path, sc)\n\n\n\n\n\n\npath\n: The path to the parquet file.\n\n\nsc\n: An instance of SparkContext.\n\n\n\n\n\n\nTextSet Transformations\n\n\nAnalytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference:\n\n\nTokenization\n\n\nDo tokenization on original text.\n\n\nScala\n\n\ntransformedTextSet = textSet.tokenize()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.tokenize()\n\n\n\n\nNormalization\n\n\nRemoves all dirty (non English alphabet) characters from tokens and converts words to lower case. \nNeed to tokenize first.\n\n\nScala\n\n\ntransformedTextSet = textSet.normalize()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.normalize()\n\n\n\n\nWord To Index\n\n\nMap word tokens to indices. \nResult index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order. \nHere we adopt the convention that index 0 will be reserved for unknown words.\nNeed to tokenize first.\n\n\nAfter word2idx, you can get the generated wordIndex map by calling \ngetWordIndex\n (Scala) or \nget_word_index()\n (Python) of the transformed TextSet.\n\n\nScala\n\n\ntransformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null)\n\n\n\n\n\n\nremoveTopN\n: Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.\n\n\nmaxWordsNum\n: Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer.\n\n\nminFreq\n: Positive integer. Only those words with frequency \n= minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered.\n\n\nexistingMap\n: Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. \nIf not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words.\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None)\n\n\n\n\n\n\nremove_topN\n: Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.\n\n\nmax_words_num\n: Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int.\n\n\nmin_freq\n: Positive int. Only those words with frequency \n= min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered.\n\n\nexisting_map\n: Existing dictionary of word index if any. Default is None and in this case a new map with index starting from 1 will be generated. \nIf not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words.\n\n\n\n\nSequence Shaping\n\n\nShape the sequence of indices to a fixed length. \nNeed to word2idx first.\n\n\nScala\n\n\ntransformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0)\n\n\n\n\n\n\nlen\n: Positive integer. The target length.\n\n\ntruncMode\n: Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. \nIf 'TruncMode.pre', the sequence will be truncated from the beginning. \nIf 'TruncMode.post', the sequence will be truncated from the end. \nDefault is 'TruncMode.post'.\n\n\npadElement\n: Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.shape_sequence(len, trunc_mode=\npre\n, pad_element=0)\n\n\n\n\n\n\nlen\n: Positive int. The target length.\n\n\ntruncMode\n: String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. \nIf 'pre', the sequence will be truncated from the beginning. \nIf 'post', the sequence will be truncated from the end. \nDefault is 'post'.\n\n\npadElement\n: Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.\n\n\n\n\nBigDL Sample Generation\n\n\nTransform indices and label (if any) to a BigDL \nSample\n. \nNeed to word2idx first.\n\n\nScala\n\n\ntransformedTextSet = textSet.generateSample()\n\n\n\n\nPython\n\n\ntransformed_text_set = text_set.generate_sample()\n\n\n\n\n\n\nWordEmbedding\n\n\nThis is a special Embedding layer that directly loads pre-trained word vectors as weights, \nwhich turns non-negative integers (indices) into dense vectors of fixed size.\n\n\nCurrently only GloVe embedding is supported for this layer.\n\n\nThe input of this layer should be 2D.\n\n\nScala\n\n\nembedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)\n\n\n\n\n\n\nembeddingFile\n: The path to the word embedding file. Currently \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not. Only false is supported for now.\n\n\ninputLength\n: Positive integer. The sequence length of each input.\n\n\n\n\nPython\n\n\nembedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None)\n\n\n\n\n\n\nembedding_file\n The path to the word embedding file. Currently \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not. Only False is supported for now.\n\n\ninputLength\n: Positive int. The sequence length of each input.", 
            "title": "Text"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#textset", 
            "text": "TextSet  is a collection of TextFeatures where each  TextFeature  keeps information of a single text record.  TextSet  can either be a  DistributedTextSet  consisting of text RDD or a  LocalTextSet  consisting of text array.", 
            "title": "TextSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-as-textset", 
            "text": "", 
            "title": "Read texts as TextSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-a-directory", 
            "text": "Read texts with labels from a directory.  Under this specified directory path, there are supposed to be several subdirectories, each of which contains a number of text files belonging to this category. \nEach category will be a given a label (starting from 0) according to its position in the ascending order sorted among all subdirectories. \nEach text will be a given a label according to the directory where it is located.  Scala  textSet = TextSet.read(path, sc = null, minPartitions = 1)   path : String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read(path, sc=None, min_partitions=1)   path : String. Folder path to texts. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.", 
            "title": "Read texts from a directory"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-csv-file", 
            "text": "Read texts with id from csv file.  Each record is supposed to contain id(String) and text(String) in order.  Note that the csv file should be without header.  Scala  textSet = TextSet.readCSV(path, sc = null, minPartitions = 1)   path : String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be specified.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is null and in this case texts will be read as a LocalTextSet.   minPartitions : Integer. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not null. Default is 1.   Python  text_set = TextSet.read_csv(path, sc=None, min_partitions=1)   path : String. The path to the csv file. Local file system and HDFS are supported. If you want to read from HDFS, sc needs to be defined.  sc : An instance of SparkContext. If specified, texts will be read as a DistributedTextSet. \nDefault is None and in this case texts will be read as a LocalTextSet.   min_partitions : Int. A suggestion value of the minimal partition number for input texts.\nOnly need to specify this when sc is not None. Default is 1.", 
            "title": "Read texts from csv file"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#read-texts-from-parquet-file", 
            "text": "Read texts with id from parquet file with schema id(String) and text(String). Return a DistributedTextSet.  Scala  textSet = TextSet.readParquet(path, sqlContext)   path : The path to the parquet file.  sqlContext : An instance of SQLContext.   Python  text_set = TextSet.read_parquet(path, sc)   path : The path to the parquet file.  sc : An instance of SparkContext.", 
            "title": "Read texts from parquet file"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#textset-transformations", 
            "text": "Analytics Zoo provides many transformation methods for a TextSet to form a text preprocessing pipeline, which will return the transformed TextSet that can be directly used for training and inference:", 
            "title": "TextSet Transformations"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#tokenization", 
            "text": "Do tokenization on original text.  Scala  transformedTextSet = textSet.tokenize()  Python  transformed_text_set = text_set.tokenize()", 
            "title": "Tokenization"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#normalization", 
            "text": "Removes all dirty (non English alphabet) characters from tokens and converts words to lower case. \nNeed to tokenize first.  Scala  transformedTextSet = textSet.normalize()  Python  transformed_text_set = text_set.normalize()", 
            "title": "Normalization"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#word-to-index", 
            "text": "Map word tokens to indices. \nResult index will start from 1 and corresponds to the occurrence frequency of each word sorted in descending order. \nHere we adopt the convention that index 0 will be reserved for unknown words.\nNeed to tokenize first.  After word2idx, you can get the generated wordIndex map by calling  getWordIndex  (Scala) or  get_word_index()  (Python) of the transformed TextSet.  Scala  transformedTextSet = textSet.word2idx(removeTopN = 0, maxWordsNum = -1, minFreq = 1, existingMap = null)   removeTopN : Non-negative integer. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.  maxWordsNum : Integer. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive integer.  minFreq : Positive integer. Only those words with frequency  = minFreq will be taken into consideration. Default is 1, namely all words that occur will be considered.  existingMap : Existing map of word index if any. Default is null and in this case a new map with index starting from 1 will be generated. \nIf not null, then the generated map will preserve the word index in existingMap and assign subsequent indices to new words.   Python  transformed_text_set = text_set.word2idx(remove_topN=0, max_words_num=-1, min_freq=1, existing_map=None)   remove_topN : Non-negative int. Remove the topN words with highest frequencies in the case where those are treated as stopwords. Default is 0, namely remove nothing.  max_words_num : Int. The maximum number of words to be taken into consideration. Default is -1, namely all words will be considered. Otherwise, it should be a positive int.  min_freq : Positive int. Only those words with frequency  = min_freq will be taken into consideration. Default is 1, namely all words that occur will be considered.  existing_map : Existing dictionary of word index if any. Default is None and in this case a new map with index starting from 1 will be generated. \nIf not None, then the generated map will preserve the word index in existing_map and assign subsequent indices to new words.", 
            "title": "Word To Index"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#sequence-shaping", 
            "text": "Shape the sequence of indices to a fixed length. \nNeed to word2idx first.  Scala  transformedTextSet = textSet.shapeSequence(len, truncMode = TruncMode.pre, padElement = 0)   len : Positive integer. The target length.  truncMode : Truncation mode if the original sequence is longer than the target length. Either 'TruncMode.pre' or 'TruncMode.post'. \nIf 'TruncMode.pre', the sequence will be truncated from the beginning. \nIf 'TruncMode.post', the sequence will be truncated from the end. \nDefault is 'TruncMode.post'.  padElement : Integer. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.   Python  transformed_text_set = text_set.shape_sequence(len, trunc_mode= pre , pad_element=0)   len : Positive int. The target length.  truncMode : String. Truncation mode if the original sequence is longer than the target length. Either 'pre' or 'post'. \nIf 'pre', the sequence will be truncated from the beginning. \nIf 'post', the sequence will be truncated from the end. \nDefault is 'post'.  padElement : Int. The index element to be padded to the end of the sequence if the original length is smaller than the target length.\nDefault is 0 with the convention that we reserve index 0 for unknown words.", 
            "title": "Sequence Shaping"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#bigdl-sample-generation", 
            "text": "Transform indices and label (if any) to a BigDL  Sample . \nNeed to word2idx first.  Scala  transformedTextSet = textSet.generateSample()  Python  transformed_text_set = text_set.generate_sample()", 
            "title": "BigDL Sample Generation"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/text/#wordembedding", 
            "text": "This is a special Embedding layer that directly loads pre-trained word vectors as weights, \nwhich turns non-negative integers (indices) into dense vectors of fixed size.  Currently only GloVe embedding is supported for this layer.  The input of this layer should be 2D.  Scala  embedding = WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)   embeddingFile : The path to the word embedding file. Currently  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainable : To configure whether the weights of this layer will be updated or not. Only false is supported for now.  inputLength : Positive integer. The sequence length of each input.   Python  embedding = WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None)   embedding_file  The path to the word embedding file. Currently  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index  Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  trainable : To configure whether the weights of this layer will be updated or not. Only False is supported for now.  inputLength : Positive int. The sequence length of each input.", 
            "title": "WordEmbedding"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink.\n\n\nModel Load\n\n\nUse \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float](\n/tmp/zoo.model\n) //load from local fs\nval model = ObjectDetector.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ObjectDetector.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model(\n/tmp/zoo.model\n) //load from local fs\nmodel = ObjectDetector.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ObjectDetector.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.\n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageSet before model inference\n\n\npostProcessor: postprocessor of ImageSet after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)\n\n\n\n\nPredict with loaded object detection model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this prediction\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel(\n/tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model\n)\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  prediction\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Object Detection"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#model-load", 
            "text": "Use  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float]( /tmp/zoo.model ) //load from local fs\nval model = ObjectDetector.loadModel( hdfs://... ) //load from hdfs\nval model = ObjectDetector.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model( /tmp/zoo.model ) //load from local fs\nmodel = ObjectDetector.load_model( hdfs://... ) //load from hdfs\nmodel = ObjectDetector.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.  Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageSet before model inference  postProcessor: postprocessor of ImageSet after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#predict-with-loaded-object-detection-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this prediction   Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel( /tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model )\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  prediction   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Predict with loaded object detection model"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nModel Load\n\n\nUse \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.  \nModule\n (Scala) or \nModel\n(Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float](\n/tmp/model.zoo\n, \n/tmp/model.bin\n) //load from local fs\nval model = ImageClassifier.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ImageClassifier.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model(\n/tmp/...model\n, \n/tmp/model.bin\n) //load from local fs\nmodel = ImageClassifier.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ImageClassifier.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. \n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageFrame before model inference\n\n\npostProcessor: postprocessor of ImageFrame after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing) \n\n\n\n\nPredict with loaded image classification model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  predcition\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel(\n/tmp/analytics-zoo_inception-v1_imagenet_0.1.0\n) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this predcition\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Image Classification"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#model-load", 
            "text": "Use  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.   Module  (Scala) or  Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float]( /tmp/model.zoo ,  /tmp/model.bin ) //load from local fs\nval model = ImageClassifier.loadModel( hdfs://... ) //load from hdfs\nval model = ImageClassifier.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model( /tmp/...model ,  /tmp/model.bin ) //load from local fs\nmodel = ImageClassifier.load_model( hdfs://... ) //load from hdfs\nmodel = ImageClassifier.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.   Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageFrame before model inference  postProcessor: postprocessor of ImageFrame after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#predict-with-loaded-image-classification-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  predcition   Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel( /tmp/analytics-zoo_inception-v1_imagenet_0.1.0 ) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this predcition   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Predict with loaded image classification model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/", 
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\nThe model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\n\n\nBuild a TextClassifier Model\n\n\nYou can call the following API in Scala and Python respectively to create a \nTextClassifier\n with \npre-trained GloVe word embeddings as the first layer\n.\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder = \ncnn\n, encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nSee \nhere\n for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder=\ncnn\n, encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\nSee \nhere\n for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\n\n\nSave Model\n\n\nAfter building and training a TextClassifier model, you can save it for future use.\n\n\nScala\n\n\ntextClassifier.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\ntext_classifier.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load a TextClassifier model (with weights) saved \nabove\n:\n\n\nScala\n\n\nTextClassifier.loadModel(path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nTextClassifier.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.", 
            "title": "Text Classification"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#build-a-textclassifier-model", 
            "text": "You can call the following API in Scala and Python respectively to create a  TextClassifier  with  pre-trained GloVe word embeddings as the first layer .  Scala  val textClassifier = TextClassifier(classNum, embeddingFile, wordIndex = null, sequenceLength = 500, encoder =  cnn , encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   See  here  for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  Python  text_classifier = TextClassifier(class_num, embedding_file, word_index=None, sequence_length=500, encoder= cnn , encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.   See  here  for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.", 
            "title": "Build a TextClassifier Model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#save-model", 
            "text": "After building and training a TextClassifier model, you can save it for future use.  Scala  textClassifier.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  text_classifier.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Save Model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#load-model", 
            "text": "To load a TextClassifier model (with weights) saved  above :  Scala  TextClassifier.loadModel(path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  TextClassifier.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Load Model"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/", 
            "text": "Analytics Zoo provides two Recommenders, including Wide and Deep (WND) model and Neural network-based Collaborative Filtering (NCF) model. Each model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\nRecommenders can handle models with either explict or implicit feedback, given corresponding features.\n\n\nWe also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See \nhere\n for more details.\n\n\n\n\nWide and Deep\n\n\nWide and Deep Learning Model, proposed by \nGoogle, 2016\n, is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.\n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval wideAndDeep = WideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\n\n\nmodelType\n: String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\ncolumnInfo\n An instance of \nColumnFeatureInfo\n.\n\n\nhiddenLayers\n: Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).\n\n\n\n\nSee \nhere\n for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nwide_and_deep = WideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\n\n\nclass_num\n: The number of classes. Positive int.\n\n\ncolumn_info\n: An instance of \nColumnFeatureInfo\n.\n\n\nmodel_type\n: String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.\n\n\nhidden_layers\n: Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).\n\n\n\n\nSee \nhere\n for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nNCF (\nHe, 2015\n) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. \nincludeMF\n(Boolean) is provided for users to build a \nNeuralCF\n model with or without matrix factorization. \n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\n\n\nuserCount\n: The number of users. Positive integer.\n\n\nitemCount\n: The number of items. Positive integer.\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\nuserEmbed\n: Units of user embedding. Positive integer. Default is 20.\n\n\nitemEmbed\n: Units of item embedding. Positive integer. Default is 20.\n\n\nhiddenLayers\n: Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).\n\n\nincludeMF\n: Whether to include Matrix Factorization. Boolean. Default is true.\n\n\nmfEmbed\n: Units of matrix factorization embedding. Positive integer. Default is 20.\n\n\n\n\nSee \nhere\n for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\n\n\nuser_count\n: The number of users. Positive int.\n\n\nitem_count\n: The number of classes. Positive int.\n\n\nclass_num:\n The number of classes. Positive int.\n\n\nuser_embed\n: Units of user embedding. Positive int. Default is 20.\n\n\nitem_embed\n: itemEmbed Units of item embedding. Positive int. Default is 20.\n\n\nhidden_layers\n: Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).\n\n\ninclude_mf\n: Whether to include Matrix Factorization. Boolean. Default is True.\n\n\nmf_embed\n: Units of matrix factorization embedding. Positive int. Default is 20.\n\n\n\n\nSee \nhere\n for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nPrediction and Recommendation\n\n\nPredict for user-item pairs\n\n\nGive prediction for each pair of user and item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\npredictUserItemPair(featureRdd)\n\n\n\n\nPython\n\n\npredict_user_item_pair(feature_rdd)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\n\n\nRecommend for users\n\n\nRecommend a number of items for each user. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForUser(featureRdd, maxItems)\n\n\n\n\nPython\n\n\nrecommend_for_user(feature_rdd, max_items)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxItems\n: The number of items to be recommended to each user. Positive integer.\n\n\n\n\nRecommend for items\n\n\nRecommend a number of users for each item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForItem(featureRdd, maxUsers)\n\n\n\n\nPython\n\n\nrecommend_for_item(feature_rdd, max_users)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxUsers\n: The number of users to be recommended to each item. Positive integer.\n\n\n\n\n\n\nModel Save\n\n\nAfter building and training a WideAndDeep or NeuralCF model, you can save it for future use.\n\n\nScala\n\n\nwideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nwide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nModel Load\n\n\nTo load a WideAndDeep or NeuralCF model (with weights) saved \nabove\n:\n\n\nScala\n\n\nWideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nWideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.\n\n\n\n\n\n\nUserItemFeature\n\n\nRepresent records of user-item with features.\n\n\nEach record should contain the following fields:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitem_id\n: Positive integer.\n\n\nsample\n: \nSample\n which consists of feature(s) and label(s).\n\n\n\n\nScala\n\n\nUserItemFeature(userId, itemId, sample)\n\n\n\n\nPython\n\n\nUserItemFeature(user_id, item_id, sample)\n\n\n\n\n\n\nUserItemPrediction\n\n\nRepresent the prediction results of user-item pairs.\n\n\nEach prediction record will contain the following information:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitemId\n: Positive integer.\n\n\nprediction\n: The prediction (rating) for the user on the item.\n\n\nprobability\n: The probability for the prediction.\n\n\n\n\nScala\n\n\nUserItemPrediction(userId, itemId, prediction, probability)\n\n\n\n\nPython\n\n\nUserItemPrediction(user_id, item_id, prediction, probability)\n\n\n\n\n\n\nColumnFeatureInfo\n\n\nAn instance of \nColumnFeatureInfo\n contains the same data information shared by the \nWideAndDeep\n model and its feature generation part.\n\n\nYou can choose to include the following information for feature engineering and the \nWideAndDeep\n model:\n\n\n\n\nwideBaseCols\n: Data of \nwideBaseCols\n together with \nwideCrossCols\n will be fed into the wide model.\n\n\nwideBaseDims\n: Dimensions of \nwideBaseCols\n. The dimensions of the data in \nwideBaseCols\n should be within the range of \nwideBaseDims\n.\n\n\nwideCrossCols\n: Data of \nwideCrossCols\n will be fed into the wide model.\n\n\nwideCrossDims\n: Dimensions of \nwideCrossCols\n. The dimensions of the data in \nwideCrossCols\n should be within the range of \nwideCrossDims\n.\n\n\nindicatorCols\n: Data of \nindicatorCols\n will be fed into the deep model as multi-hot vectors. \n\n\nindicatorDims\n: Dimensions of \nindicatorCols\n. The dimensions of the data in \nindicatorCols\n should be within the range of \nindicatorDims\n.\n\n\nembedCols\n: Data of \nembedCols\n will be fed into the deep model as embeddings.\n\n\nembedInDims\n: Input dimension of the data in \nembedCols\n. The dimensions of the data in \nembedCols\n should be within the range of \nembedInDims\n.\n\n\nembedOutDims\n: The dimensions of embeddings for \nembedCols\n.\n\n\ncontinuousCols\n: Data of \ncontinuousCols\n will be treated as continuous values for the deep model.\n\n\nlabel\n: The name of the 'label' column. String. Default is \"label\".\n\n\n\n\nRemark:\n\n\nFields that involve \nCols\n should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.\n\n\nFields that involve \nDims\n should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.\n\n\nIf any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).\n\n\nScala\n\n\nColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label = \nlabel\n)\n\n\n\n\nPython\n\n\nColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label=\nlabel\n)", 
            "title": "Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#wide-and-deep", 
            "text": "Wide and Deep Learning Model, proposed by  Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.  After training the model, users can use the model to  do prediction and recommendation .  Scala  val wideAndDeep = WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))   modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".  numClasses : The number of classes. Positive integer.  columnInfo  An instance of  ColumnFeatureInfo .  hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).   See  here  for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  wide_and_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))   class_num : The number of classes. Positive int.  column_info : An instance of  ColumnFeatureInfo .  model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.  hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).   See  here  for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Wide and Deep"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework.  includeMF (Boolean) is provided for users to build a  NeuralCF  model with or without matrix factorization.   After training the model, users can use the model to  do prediction and recommendation .  Scala  val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)   userCount : The number of users. Positive integer.  itemCount : The number of items. Positive integer.  numClasses : The number of classes. Positive integer.  userEmbed : Units of user embedding. Positive integer. Default is 20.  itemEmbed : Units of item embedding. Positive integer. Default is 20.  hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).  includeMF : Whether to include Matrix Factorization. Boolean. Default is true.  mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20.   See  here  for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  ncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)   user_count : The number of users. Positive int.  item_count : The number of classes. Positive int.  class_num:  The number of classes. Positive int.  user_embed : Units of user embedding. Positive int. Default is 20.  item_embed : itemEmbed Units of item embedding. Positive int. Default is 20.  hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).  include_mf : Whether to include Matrix Factorization. Boolean. Default is True.  mf_embed : Units of matrix factorization embedding. Positive int. Default is 20.   See  here  for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#prediction-and-recommendation", 
            "text": "Predict for user-item pairs  Give prediction for each pair of user and item. Return RDD of  UserItemPrediction .  Scala  predictUserItemPair(featureRdd)  Python  predict_user_item_pair(feature_rdd)  Parameters:   featureRdd : RDD of  UserItemFeature .   Recommend for users  Recommend a number of items for each user. Return RDD of  UserItemPrediction .  Scala  recommendForUser(featureRdd, maxItems)  Python  recommend_for_user(feature_rdd, max_items)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxItems : The number of items to be recommended to each user. Positive integer.   Recommend for items  Recommend a number of users for each item. Return RDD of  UserItemPrediction .  Scala  recommendForItem(featureRdd, maxUsers)  Python  recommend_for_item(feature_rdd, max_users)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxUsers : The number of users to be recommended to each item. Positive integer.", 
            "title": "Prediction and Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#model-save", 
            "text": "After building and training a WideAndDeep or NeuralCF model, you can save it for future use.  Scala  wideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  wide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Model Save"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#model-load", 
            "text": "To load a WideAndDeep or NeuralCF model (with weights) saved  above :  Scala  WideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  WideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemfeature", 
            "text": "Represent records of user-item with features.  Each record should contain the following fields:   userId : Positive integer.  item_id : Positive integer.  sample :  Sample  which consists of feature(s) and label(s).   Scala  UserItemFeature(userId, itemId, sample)  Python  UserItemFeature(user_id, item_id, sample)", 
            "title": "UserItemFeature"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemprediction", 
            "text": "Represent the prediction results of user-item pairs.  Each prediction record will contain the following information:   userId : Positive integer.  itemId : Positive integer.  prediction : The prediction (rating) for the user on the item.  probability : The probability for the prediction.   Scala  UserItemPrediction(userId, itemId, prediction, probability)  Python  UserItemPrediction(user_id, item_id, prediction, probability)", 
            "title": "UserItemPrediction"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#columnfeatureinfo", 
            "text": "An instance of  ColumnFeatureInfo  contains the same data information shared by the  WideAndDeep  model and its feature generation part.  You can choose to include the following information for feature engineering and the  WideAndDeep  model:   wideBaseCols : Data of  wideBaseCols  together with  wideCrossCols  will be fed into the wide model.  wideBaseDims : Dimensions of  wideBaseCols . The dimensions of the data in  wideBaseCols  should be within the range of  wideBaseDims .  wideCrossCols : Data of  wideCrossCols  will be fed into the wide model.  wideCrossDims : Dimensions of  wideCrossCols . The dimensions of the data in  wideCrossCols  should be within the range of  wideCrossDims .  indicatorCols : Data of  indicatorCols  will be fed into the deep model as multi-hot vectors.   indicatorDims : Dimensions of  indicatorCols . The dimensions of the data in  indicatorCols  should be within the range of  indicatorDims .  embedCols : Data of  embedCols  will be fed into the deep model as embeddings.  embedInDims : Input dimension of the data in  embedCols . The dimensions of the data in  embedCols  should be within the range of  embedInDims .  embedOutDims : The dimensions of embeddings for  embedCols .  continuousCols : Data of  continuousCols  will be treated as continuous values for the deep model.  label : The name of the 'label' column. String. Default is \"label\".   Remark:  Fields that involve  Cols  should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.  Fields that involve  Dims  should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.  If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).  Scala  ColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label =  label )  Python  ColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label= label )", 
            "title": "ColumnFeatureInfo"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/", 
            "text": "Analytics Zoo provides pre-defined models based on LSTM to detect anomalies in time series data. \nA sequence of values (e.g., last 50 hours) leading to the current time are used as input for the model, which then tries to predict the next data point. Anomalies are defined when actual values are distant from the model predictions.  \n\n\nHightlights\n\n\n\n\nKeras style models, could use Keras style APIs(compile and fit), as well as NNFrames or BigDL Optimizer for training.\n\n\nModels are defined base on LSTM.\n\n\n\n\n\n\nBuild an AnomalyDetction model\n\n\nYou can call the following API in Scala and Python respectively to create an \nAnomalyDetrctor\n model\n\n\nScala\n\n\nimport com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)\n\n\n\n\n\n\nfeatureShape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhiddenLayers\n Units of hidden layers of LSTM.\n\n\ndropouts\n     Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nPython\n\n\nfrom zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])\n\n\n\n\n\n\nfeature_shape\n The input shape of features, fist dimension is unroll length, second dimension is feature size.\n\n\nhidden_layers\n Units of hidden layers of LSTM.\n\n\ndropouts\n      Fraction of the input units to drop out. Float between 0 and 1.\n\n\n\n\nUnroll features\n\n\nTo prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length.\n\n\nScala\n\n\nval unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep)\n\n\n\n\n\n\ndataRdd\n       RDD[Array]. data to be unrolled, it holds original time series features\n\n\nunrollLength\n  Int. the length of precious values to predict future value.\n\n\npredictStep\n   Int. How many time steps to predict future value, default is 1.\n\n\n\n\nPython\n\n\nunrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step)\n\n\n\n\n\n\ndata_rdd\n       RDD[Array]. data to be unrolled, it holds original time series features\n\n\nunroll_length\n  Int. The length of precious values to predict future value.\n\n\npredict_step\n   Int. How many time steps to predict future value, default is 1.\n\n\n\n\n\n\nDetect anomalies\n\n\nAfter training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top \nanomalySize\n data points are anomalies).\n\n\nScala\n\n\nval anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize)\n\n\n\n\n\n\nyTruth\n      RDD of float or double values. Truth to be compared. \n\n\nyPredict\n    RDD of float or double values. Predictions.\n\n\nanomalySize\n Int. The size to be considered as anomalies.\n\n\n\n\nPython\n``\n\n\nanomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size)\n\n\n\n\n\n\ny_truth\n      RDD of float or double values. Truth to be compared. \n\n\ny_predict\n    RDD of float or double values. Predictions.\n\n\nanomaly_size\n Int. The size to be considered as anomalies.\n\n\n\n\n\n\nSave Model\n\n\nAfter building and training an AnomalyDetector model, you can save it for future use.\n\n\nScala\n\n\nmodel.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nmodel.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load an AnomalyDetector model (with weights) saved \nabove\n:\n\n\nScala\n\n\nAnomalyDetector.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nAnomalyDetector.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.", 
            "title": "Anomaly Detection"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/#build-an-anomalydetction-model", 
            "text": "You can call the following API in Scala and Python respectively to create an  AnomalyDetrctor  model  Scala  import com.intel.analytics.zoo.models.anomalydetection._\nval model = AnomalyDetector(featureShape, hiddenLayers, dropouts)   featureShape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hiddenLayers  Units of hidden layers of LSTM.  dropouts      Fraction of the input units to drop out. Float between 0 and 1.   Python  from zoo.models.anomalydetection import AnomalyDetector\nmodel = AnomalyDetector(feature_shape=(10, 3), hidden_layers=[8, 32, 15], dropouts=[0.2, 0.2, 0.2])   feature_shape  The input shape of features, fist dimension is unroll length, second dimension is feature size.  hidden_layers  Units of hidden layers of LSTM.  dropouts       Fraction of the input units to drop out. Float between 0 and 1.", 
            "title": "Build an AnomalyDetction model"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/#unroll-features", 
            "text": "To prepare input for an AnomalyDetector model, you can use unroll a time series data with a unroll length.  Scala  val unrolled = AnomalyDetector.unroll(dataRdd, unrollLength, predictStep)   dataRdd        RDD[Array]. data to be unrolled, it holds original time series features  unrollLength   Int. the length of precious values to predict future value.  predictStep    Int. How many time steps to predict future value, default is 1.   Python  unrolled = AnomalyDetector.unroll(data_rdd, unroll_length, predict_step)   data_rdd        RDD[Array]. data to be unrolled, it holds original time series features  unroll_length   Int. The length of precious values to predict future value.  predict_step    Int. How many time steps to predict future value, default is 1.", 
            "title": "Unroll features"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/#detect-anomalies", 
            "text": "After training the model, it can be used to predict values using previous data, then to detect anomalies.\nAnomalies are defined by comparing the predictions and actual values. It ranks all the absolute difference of predictions and actual values with descending order, the top  anomalySize  data points are anomalies).  Scala  val anomalies = AnomalyDetector.detectAnomalies(yTruth, yPredict, amonalySize)   yTruth       RDD of float or double values. Truth to be compared.   yPredict     RDD of float or double values. Predictions.  anomalySize  Int. The size to be considered as anomalies.   Python ``  anomalies = AnomalyDetector.detect_anomalies(y_truth, y_predict, anomaly_size)   y_truth       RDD of float or double values. Truth to be compared.   y_predict     RDD of float or double values. Predictions.  anomaly_size  Int. The size to be considered as anomalies.", 
            "title": "Detect anomalies"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/#save-model", 
            "text": "After building and training an AnomalyDetector model, you can save it for future use.  Scala  model.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  model.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Save Model"
        }, 
        {
            "location": "/APIGuide/Models/anomaly-detection/#load-model", 
            "text": "To load an AnomalyDetector model (with weights) saved  above :  Scala  AnomalyDetector.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  AnomalyDetector.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Load Model"
        }, 
        {
            "location": "/APIGuide/Models/text-matching/", 
            "text": "Analytics Zoo provides a pre-defined KNRM model that can be used for text matching (e.g. question answering).\nFor training, you can use Keras-Style API methods or alternatively feed the model into NNFrames and BigDL Optimizer.\nMore text matching models will be supported in the future.\n\n\n\n\nBuild a KNRM Model\n\n\nKernel-pooling Neural Ranking Model with RBF kernel. See \nhere\n for more details.\n\n\nYou can call the following API in Scala and Python respectively to create a \nKNRM\n with \npre-trained GloVe word embeddings\n.\n\n\nScala\n\n\nval knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode = \nranking\n)\n\n\n\n\n\n\ntext1Length\n: Sequence length of text1 (query).\n\n\ntext2Length\n: Sequence length of text2 (doc).\n\n\nembeddingFile\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call \nWordEmbedding.getWordIndex(embeddingFile)\n to retrieve the map.\n\n\ntrainEmbed\n: Boolean. Whether to train the embedding layer or not. Default is true.\n\n\nkernelNum\n: Integer \n 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexactSigma\n: Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntargetMode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nSee \nhere\n for the Scala example that trains a KNRM model on WikiQA dataset.\n\n\nPython\n\n\nknrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode=\nranking\n)\n\n\n\n\n\n\ntext1_length\n: Sequence length of text1 (query).\n\n\ntext2_length\n: Sequence length of text2 (doc).\n\n\nembedding_file\n: The path to the word embedding file. Currently only \nglove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt\n are supported. You can download from \nhere\n.\n\n\nword_index\n: Dictionary of word (string) and its corresponding index (int). The index is supposed to \nstart from 1\n with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call \nWordEmbedding.get_word_index(embedding_file)\n to retrieve the dictionary.\n\n\ntrain_embed\n: Boolean. Whether to train the embedding layer or not. Default is True.\n\n\nkernel_num\n: Int \n 1. The number of kernels to use. Default is 21.\n\n\nsigma\n: Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.\n\n\nexact_sigma\n: Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.\n\n\ntarget_mode\n: String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.\n\n\n\n\nSee \nhere\n for the Python example that trains a KNRM model on WikiQA dataset.\n\n\n\n\nSave Model\n\n\nAfter building and training a KNRM model, you can save it for future use.\n\n\nScala\n\n\nknrm.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nknrm.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nLoad Model\n\n\nTo load a KNRM model (with weights) saved \nabove\n:\n\n\nScala\n\n\nKNRM.loadModel(path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nKNRM.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.", 
            "title": "Text Matching"
        }, 
        {
            "location": "/APIGuide/Models/text-matching/#build-a-knrm-model", 
            "text": "Kernel-pooling Neural Ranking Model with RBF kernel. See  here  for more details.  You can call the following API in Scala and Python respectively to create a  KNRM  with  pre-trained GloVe word embeddings .  Scala  val knrm = KNRM(text1Length, text2Length, embeddingFile, wordIndex = null, trainEmbed = true, kernelNum = 21, sigma = 0.1, exactSigma = 0.001, targetMode =  ranking )   text1Length : Sequence length of text1 (query).  text2Length : Sequence length of text2 (doc).  embeddingFile : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  wordIndex : Map of word (String) and its corresponding index (integer). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is null. In this case, all the words in the embeddingFile will be taken into account and you can call  WordEmbedding.getWordIndex(embeddingFile)  to retrieve the map.  trainEmbed : Boolean. Whether to train the embedding layer or not. Default is true.  kernelNum : Integer   1. The number of kernels to use. Default is 21.  sigma : Double. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exactSigma : Double. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  targetMode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   See  here  for the Scala example that trains a KNRM model on WikiQA dataset.  Python  knrm = KNRM(text1_length, text2_length, embedding_file, word_index=None, train_embed=True, kernel_num=21, sigma=0.1, exact_sigma=0.001, target_mode= ranking )   text1_length : Sequence length of text1 (query).  text2_length : Sequence length of text2 (doc).  embedding_file : The path to the word embedding file. Currently only  glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt, glove.42B.300d.txt, glove.840B.300d.txt  are supported. You can download from  here .  word_index : Dictionary of word (string) and its corresponding index (int). The index is supposed to  start from 1  with 0 reserved for unknown words. During the prediction, if you have words that are not in the wordIndex for the training, you can map them to index 0. Default is None. In this case, all the words in the embedding_file will be taken into account and you can call  WordEmbedding.get_word_index(embedding_file)  to retrieve the dictionary.  train_embed : Boolean. Whether to train the embedding layer or not. Default is True.  kernel_num : Int   1. The number of kernels to use. Default is 21.  sigma : Float. Defines the kernel width, or the range of its softTF count. Default is 0.1.  exact_sigma : Float. The sigma used for the kernel that harvests exact matches in the case where RBF mu=1.0. Default is 0.001.  target_mode : String. The target mode of the model. Either 'ranking' or 'classification'. For ranking, the output will be the relevance score between text1 and text2 and you are recommended to use 'rank_hinge' as loss for pairwise training.\nFor classification, the last layer will be sigmoid and the output will be the probability between 0 and 1 indicating whether text1 is related to text2 and\nyou are recommended to use 'binary_crossentropy' as loss for binary classification. Default mode is 'ranking'.   See  here  for the Python example that trains a KNRM model on WikiQA dataset.", 
            "title": "Build a KNRM Model"
        }, 
        {
            "location": "/APIGuide/Models/text-matching/#save-model", 
            "text": "After building and training a KNRM model, you can save it for future use.  Scala  knrm.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  knrm.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Save Model"
        }, 
        {
            "location": "/APIGuide/Models/text-matching/#load-model", 
            "text": "To load a KNRM model (with weights) saved  above :  Scala  KNRM.loadModel(path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  KNRM.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Load Model"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/", 
            "text": "Analytics Zoo provides Seq2seq model which is a general-purpose encoder-decoder framework that can be used for Chatbot, Machine Translation and more.\nThe model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\n\n\nBuild a Seq2seq Model\n\n\nBefore build Seq2seq Model, you need build \nEncoder\n, \nDecoder\n. And \nBridge\n if you want to do some transformation before passing encoder states to decoder.\n\n\nBuild an Encoder\n\n\nCurrently we only support \nRNNEncoder\n which enables you to put RNN layers into encoder.\nYou can call the following API in Scala and Python respectively to create a \nRNNEncoder\n.\n\n\nScala\n\n\nval encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding)\n\n\n\n\n\n\nrnnType\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnumLayers\n number of layers used in encoder\n\n\nhiddenSize\n hidden size of encoder\n\n\nembedding\n embedding layer in encoder, default is \nnull\n\n\n\n\nYou can also define RNN layers yourself\n\n\nval encoder = RNNEncoder(rnns, embedding, inputShape)\n\n\n\n\n\n\nrnns\n rnn layers used for encoder, support stacked rnn layers\n\n\nembedding\n embedding layer in encoder, default is \nnull\n\n\n\n\nPython\n\n\nencoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding)\n\n\n\n\n\n\nrnn_type\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnlayers\n number of layers used in encoder\n\n\nhidden_size\n hidden size of encoder\n\n\nembedding\n embedding layer in encoder, default is \nNone\n\n\n\n\nOr\n\n\nencoder = RNNEncoder(rnns, embedding, input_shape)\n\n\n\n\n\n\nrnns\n rnn layers used for encoder, support stacked rnn layers\n\n\nembedding\n embedding layer in encoder, default is \nNone\n\n\n\n\nBuild a Decoder\n\n\nSimilar to Encoder, we only support \nRNNDecoder\n and API is pretty much the same with \nRNNEncoder\n\n\nScala\n\n\nval decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding)\n\n\n\n\n\n\nrnnType\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnumLayers\n number of layers used in decoder\n\n\nhiddenSize\n hidden size of decoder\n\n\nembedding\n embedding layer in decoder, default is \nnull\n\n\n\n\nYou can also define RNN layers yourself\n\n\nval decoder = RNNDecoder(rnns, embedding, inputShape)\n\n\n\n\n\n\nrnns\n rnn layers used for decoder, support stacked rnn layers\n\n\nembedding\n embedding layer in decoder, default is \nnull\n\n\n\n\nPython\n\n\nencoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding):\n\n\n\n\n\n\nrnn_type\n style of recurrent unit, one of [SimpleRNN, LSTM, GRU]\n\n\nnlayers\n number of layers used in decoder\n\n\nhidden_size\n hidden size of decoder\n\n\nembedding\n embedding layer in decoder, default is \nNone\n\n\n\n\nOr\n\n\ndecoder = RNNDecoder(rnns, embedding, input_shape)\n\n\n\n\n\n\nrnns\n rnn layers used for decoder, support stacked rnn layers\n\n\nembedding\n embedding layer in decoder, default is \nNone\n\n\n\n\nBuild a Bridge\n\n\nBy default, encoder states are directly fed into decoder. In this case, you don't need build a \nBridge\n. But if you want to do some transformation before feed encoder states to decoder,\nplease use following API to create a \nBridge\n.\n\n\nScala\n\n\nval bridge = Bridge(bridgeType, decoderHiddenSize)\n\n\n\n\n\n\nbridgeType\n currently only support \"dense | densenonlinear\"\n\n\ndecoderHiddenSize\n hidden size of decoder\n\n\n\n\nYou can also specify various keras layers as a \nBridge\n\n\nval bridge = Bridge(bridge)\n\n\n\n\n\n\nbridge\n keras layers used to do the transformation\n\n\n\n\nPython\n\n\nbridge = Bridge.initialize(bridge_type, decoder_hidden_size)\n\n\n\n\n\n\nbridge_type\n: currently only support \"dense | densenonlinear\"\n\n\ndecoder_hidden_size\n: hidden size of decoder\n\n\n\n\nOr\n\n\nbridge = Bridge.initialize_from_keras_layer(bridge)\n\n\n\n\n\n\nbridge\n keras layers used to do the transformation\n\n\n\n\nBuild a Seq2seq\n\n\nScala\n\n\nval seq2seq = Seq2seq(encoder,\n    decoder,\n    inputShape,\n    outputShape,\n    bridge,\n    generator)\n\n\n\n\n\n\nencoder\n an encoder object\n\n\ndecoder\n a decoder object\n\n\ninputShape\n shape of encoder input, for variable length, please input -1\n\n\noutputShape\n shape of decoder input, for variable length, please input -1\n\n\nbridge\n connect encoder and decoder, you can input \nnull\n\n\ngenerator\n Feeding decoder output to generator to generate final result, \nnull\n is supported\n\n\n\n\nSee \nhere\n for the Scala example that trains the Seq2seq model and uses the model to do prediction.\n\n\nPython\n\n\nseq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge,\n                 generator)\n\n\n\n\n\n\nencoder\n an encoder object\n\n\ndecoder\n a decoder object\n\n\ninput_shape\n shape of encoder input, for variable length, please input -1\n\n\noutput_shape\n shape of decoder input, for variable length, please input -1\n\n\nbridge\n connect encoder and decoder, you can input \nnull\n\n\ngenerator\n Feeding decoder output to generator to generate final result, \nNone\n is supported", 
            "title": "Sequence to Sequence"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-seq2seq-model", 
            "text": "Before build Seq2seq Model, you need build  Encoder ,  Decoder . And  Bridge  if you want to do some transformation before passing encoder states to decoder.", 
            "title": "Build a Seq2seq Model"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/#build-an-encoder", 
            "text": "Currently we only support  RNNEncoder  which enables you to put RNN layers into encoder.\nYou can call the following API in Scala and Python respectively to create a  RNNEncoder .  Scala  val encoder = RNNEncoder(rnnType, numLayer, hiddenSize, embedding)   rnnType  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  numLayers  number of layers used in encoder  hiddenSize  hidden size of encoder  embedding  embedding layer in encoder, default is  null   You can also define RNN layers yourself  val encoder = RNNEncoder(rnns, embedding, inputShape)   rnns  rnn layers used for encoder, support stacked rnn layers  embedding  embedding layer in encoder, default is  null   Python  encoder = RNNEncoder.initialize(rnn_type, nlayers, hidden_size, embedding)   rnn_type  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  nlayers  number of layers used in encoder  hidden_size  hidden size of encoder  embedding  embedding layer in encoder, default is  None   Or  encoder = RNNEncoder(rnns, embedding, input_shape)   rnns  rnn layers used for encoder, support stacked rnn layers  embedding  embedding layer in encoder, default is  None", 
            "title": "Build an Encoder"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-decoder", 
            "text": "Similar to Encoder, we only support  RNNDecoder  and API is pretty much the same with  RNNEncoder  Scala  val decoder = RNNDecoder(rnnType, numLayers, hiddenSize, embedding)   rnnType  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  numLayers  number of layers used in decoder  hiddenSize  hidden size of decoder  embedding  embedding layer in decoder, default is  null   You can also define RNN layers yourself  val decoder = RNNDecoder(rnns, embedding, inputShape)   rnns  rnn layers used for decoder, support stacked rnn layers  embedding  embedding layer in decoder, default is  null   Python  encoder = RNNDecoder.initialize(rnn_type, nlayers, hidden_size, embedding):   rnn_type  style of recurrent unit, one of [SimpleRNN, LSTM, GRU]  nlayers  number of layers used in decoder  hidden_size  hidden size of decoder  embedding  embedding layer in decoder, default is  None   Or  decoder = RNNDecoder(rnns, embedding, input_shape)   rnns  rnn layers used for decoder, support stacked rnn layers  embedding  embedding layer in decoder, default is  None", 
            "title": "Build a Decoder"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-bridge", 
            "text": "By default, encoder states are directly fed into decoder. In this case, you don't need build a  Bridge . But if you want to do some transformation before feed encoder states to decoder,\nplease use following API to create a  Bridge .  Scala  val bridge = Bridge(bridgeType, decoderHiddenSize)   bridgeType  currently only support \"dense | densenonlinear\"  decoderHiddenSize  hidden size of decoder   You can also specify various keras layers as a  Bridge  val bridge = Bridge(bridge)   bridge  keras layers used to do the transformation   Python  bridge = Bridge.initialize(bridge_type, decoder_hidden_size)   bridge_type : currently only support \"dense | densenonlinear\"  decoder_hidden_size : hidden size of decoder   Or  bridge = Bridge.initialize_from_keras_layer(bridge)   bridge  keras layers used to do the transformation", 
            "title": "Build a Bridge"
        }, 
        {
            "location": "/APIGuide/Models/seq2seq/#build-a-seq2seq", 
            "text": "Scala  val seq2seq = Seq2seq(encoder,\n    decoder,\n    inputShape,\n    outputShape,\n    bridge,\n    generator)   encoder  an encoder object  decoder  a decoder object  inputShape  shape of encoder input, for variable length, please input -1  outputShape  shape of decoder input, for variable length, please input -1  bridge  connect encoder and decoder, you can input  null  generator  Feeding decoder output to generator to generate final result,  null  is supported   See  here  for the Scala example that trains the Seq2seq model and uses the model to do prediction.  Python  seq2seq = Seq2seq(encoder, decoder, input_shape, output_shape, bridge,\n                 generator)   encoder  an encoder object  decoder  a decoder object  input_shape  shape of encoder input, for variable length, please input -1  output_shape  shape of decoder input, for variable length, please input -1  bridge  connect encoder and decoder, you can input  null  generator  Feeding decoder output to generator to generate final result,  None  is supported", 
            "title": "Build a Seq2seq"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/", 
            "text": "Introduction\n\n\nWe provide \nKeras-Style API\n based on \nKeras 1.2.2\n in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Python using the Keras-Style API, now one just need to import the following packages:\n\n\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\n\n\n\n\nOne of the highlighted features with regard to the Keras-Style API is \nshape inference\n. Users only need to specify the input shape (a shape tuple \nexcluding\n batch dimension, for example, \ninput_shape=(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\nget_input_shape()\n\n\n\n\nget_output_shape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a shape tuple. The first entry is \nNone\n representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.\n\n\n\n\nset_name(name)\n\n\n\n\n\n\nSet the name of the model. Can alternatively specify the argument \nname\n in the constructor when creating a model.\n\n\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation(\nrelu\n))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nshape\n: A shape tuple indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or a list of input nodes.\n\n\noutput\n: An output node or a list of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nmerge(inputs, mode=\nsum\n, concat_axis=-1) # This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcat_axis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nfrom zoo.pipeline.api.keras.models import Model\nfrom zoo.pipeline.api.keras.layers import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode=\nsum\n)\n# create a graph container\nmodel = Model([input1, input2], output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the Keras-Style API.\n\n\nTo set the name of a layer, you can either call \nset_name(name)\n or alternatively specify the argument \nname\n in the constructor when creating a layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation=\ntanh\n, name=\nconv1_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation=\ntanh\n, name=\nconv2_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation=\ntanh\n, name=\nfc1\n))\nmodel.add(Dense(10, activation=\nsoftmax\n, name=\nfc2\n))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)\n\n\n\n\n\n\nKeras Code Support\n\n\nIf you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with:\n\n\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n\n\n\nand making modifications subject to the following limitations:\n\n\n\n\n\n\nThe Keras version we support and test is \nKeras 1.2.2\n with TensorFlow backend.\n\n\n\n\n\n\nThere exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See \nhere\n for the full list of unsupported layer arguments. \n\n\n\n\n\n\nThe default dim_ordering in Analytics Zoo is \nth\n (Channel First, channel_axis=1).\n\n\n\n\n\n\nKeras \nbackend\n related code needs to be deleted or refactored appropriately.\n\n\n\n\n\n\nCode involving Keras utility functions or loading weights from HDF5 files should be removed.\n\n\n\n\n\n\nRemark:\n We have tested for migrating Keras code definition of \nVGG16\n, \nVGG19\n, \nResNet50\n and \nInceptionV3\n into Analytics Zoo.", 
            "title": "Python Guide"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#introduction", 
            "text": "We provide  Keras-Style API  based on  Keras 1.2.2  in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.  To define a model in Python using the Keras-Style API, now one just need to import the following packages:  from zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *  One of the highlighted features with regard to the Keras-Style API is  shape inference . Users only need to specify the input shape (a shape tuple  excluding  batch dimension, for example,  input_shape=(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.", 
            "title": "Introduction"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#define-a-model", 
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  get_input_shape()  get_output_shape()   Return the input or output shape of a model, which is a shape tuple. The first entry is  None  representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.   set_name(name)   Set the name of the model. Can alternatively specify the argument  name  in the constructor when creating a model.", 
            "title": "Define a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#sequential-api", 
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation( relu ))", 
            "title": "Sequential API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#functional-api", 
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(shape=None, name=None)  Parameters:   shape : A shape tuple indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or a list of input nodes.  output : An output node or a list of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  merge(inputs, mode= sum , concat_axis=-1) # This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concat_axis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  from zoo.pipeline.api.keras.models import Model\nfrom zoo.pipeline.api.keras.layers import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode= sum )\n# create a graph container\nmodel = Model([input1, input2], output)", 
            "title": "Functional API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#layers", 
            "text": "See  here  for all the available layers for the Keras-Style API.  To set the name of a layer, you can either call  set_name(name)  or alternatively specify the argument  name  in the constructor when creating a layer.", 
            "title": "Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#lenet-example", 
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation= tanh , name= fc1 ))\nmodel.add(Dense(10, activation= softmax , name= fc2 ))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)", 
            "title": "LeNet Example"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#keras-code-support", 
            "text": "If you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct an Analytics Zoo model by just replacing Keras import lines with:  from zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *  and making modifications subject to the following limitations:    The Keras version we support and test is  Keras 1.2.2  with TensorFlow backend.    There exist some arguments supported in Keras layers but not supported in Analytics Zoo for now. See  here  for the full list of unsupported layer arguments.     The default dim_ordering in Analytics Zoo is  th  (Channel First, channel_axis=1).    Keras  backend  related code needs to be deleted or refactored appropriately.    Code involving Keras utility functions or loading weights from HDF5 files should be removed.    Remark:  We have tested for migrating Keras code definition of  VGG16 ,  VGG19 ,  ResNet50  and  InceptionV3  into Analytics Zoo.", 
            "title": "Keras Code Support"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/", 
            "text": "Introduction\n\n\nWe provide \nKeras-Style API\n based on \nKeras 1.2.2\n in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Scala using the Keras-Style API, now one just need to import the following packages:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\n\n\n\nOne of the highlighted features with regard to the new API is \nshape inference\n. Users only need to specify the input shape (a \nShape\n object \nexcluding\n batch dimension, for example, \ninputShape=Shape(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nShape\n\n\nInput and output shapes of a model in the Keras-Style API are described by the \nShape\n object in Scala, which can be classified into \nSingleShape\n and \nMultiShape\n.\n\n\nSingleShape\n is just a list of Int indicating shape dimensions while \nMultiShape\n is essentially a list of \nShape\n.\n\n\nExample code to create a shape:\n\n\n// create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))\n\n\n\n\nYou can use method \ntoSingle()\n to cast a \nShape\n to a \nSingleShape\n. Similarly, use \ntoMulti()\n to cast a \nShape\n to a \nMultiShape\n.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\ngetInputShape()\n\n\n\n\ngetOutputShape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a \nShape\n object. For \nSingleShape\n, the first entry is \n-1\n representing the batch dimension. For a model with multiple inputs or outputs, it will return a \nMultiShape\n.\n\n\n\n\nsetName(name)\n\n\n\n\n\n\nSet the name of the model.\n\n\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](32, inputShape = Shape(128)))\nmodel.add(Activation[Float](\nrelu\n))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(inputShape = null, name = null)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: A \nShape\n object indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or an array of input nodes.\n\n\noutput\n: An output node or an array of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\n\nmerge(inputs, mode = \nsum\n, concatAxis = -1) // This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input}\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.bigdl.utils.Shape\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode = \nsum\n)\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the Keras-Style API.\n\n\nTo set the name of a layer, call the method \nsetName(name)\n of the layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation = \ntanh\n).setName(\nconv1_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation = \ntanh\n).setName(\nconv2_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation = \ntanh\n).setName(\nfc1\n))\nmodel.add(Dense(10, activation = \nsoftmax\n).setName(\nfc2\n))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)", 
            "title": "Scala Guide"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#introduction", 
            "text": "We provide  Keras-Style API  based on  Keras 1.2.2  in Analytics Zoo for the sake of user-friendliness. Users, especially those familiar with Keras, can easily use our API to create an Analytics Zoo model and train, evaluate or tune it in a distributed fashion.  To define a model in Scala using the Keras-Style API, now one just need to import the following packages:  import com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape  One of the highlighted features with regard to the new API is  shape inference . Users only need to specify the input shape (a  Shape  object  excluding  batch dimension, for example,  inputShape=Shape(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.", 
            "title": "Introduction"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#shape", 
            "text": "Input and output shapes of a model in the Keras-Style API are described by the  Shape  object in Scala, which can be classified into  SingleShape  and  MultiShape .  SingleShape  is just a list of Int indicating shape dimensions while  MultiShape  is essentially a list of  Shape .  Example code to create a shape:  // create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))  You can use method  toSingle()  to cast a  Shape  to a  SingleShape . Similarly, use  toMulti()  to cast a  Shape  to a  MultiShape .", 
            "title": "Shape"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#define-a-model", 
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  getInputShape()  getOutputShape()   Return the input or output shape of a model, which is a  Shape  object. For  SingleShape , the first entry is  -1  representing the batch dimension. For a model with multiple inputs or outputs, it will return a  MultiShape .   setName(name)   Set the name of the model.", 
            "title": "Define a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#sequential-api", 
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Activation}\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](32, inputShape = Shape(128)))\nmodel.add(Activation[Float]( relu ))", 
            "title": "Sequential API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#functional-api", 
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(inputShape = null, name = null)  Parameters:   inputShape : A  Shape  object indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or an array of input nodes.  output : An output node or an array of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\n\nmerge(inputs, mode =  sum , concatAxis = -1) // This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  import com.intel.analytics.zoo.pipeline.api.keras.layers.{Dense, Input}\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge.merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Model\nimport com.intel.analytics.bigdl.utils.Shape\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode =  sum )\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)", 
            "title": "Functional API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#layers", 
            "text": "See  here  for all the available layers for the Keras-Style API.  To set the name of a layer, call the method  setName(name)  of the layer.", 
            "title": "Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#lenet-example", 
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.pipeline.api.keras.layers._\nimport com.intel.analytics.zoo.pipeline.api.keras.models._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation =  tanh ).setName( conv1_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation =  tanh ).setName( conv2_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation =  tanh ).setName( fc1 ))\nmodel.add(Dense(10, activation =  softmax ).setName( fc2 ))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)", 
            "title": "LeNet Example"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/", 
            "text": "Activation\n\n\nSimple activation function to be applied to the output.\n\n\nScala:\n\n\nActivation(activation, inputShape = null)\n\n\n\n\nPython:\n\n\nActivation(activation, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: Name of the activation function as string. See \nhere\n for available activation strings.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Activation\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation[Float](\ntanh\n, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Activation\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Activation(\ntanh\n, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]\n\n\n\n\nOutput is\n\n\n[[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]\n\n\n\n\nNote that the following two pieces of code will be equivalent:\n\n\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\n\n\n\n\nmodel.add(Dense(32, activation=\nrelu\n))\n\n\n\n\n\n\nAvailable Activations\n\n\n\n\nelu\n\n\nrrelu\n\n\nrelu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input.\n\n\nselu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information).\n\n\ntanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.\n\n\nhardtanh\n\n\nsigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.\n\n\nhard_sigmoid\n\n\nsoftmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\n            elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\n            Softmax is defined as:\nf_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift)\n\n            where \nshift = max_i(x_i)\n.\n\n\nsoftplus : Apply the SoftPlus function to an n-dimensional input tensor.\n\n\nsoftsign : SoftSign applies SoftSign function to the input tensor\n\n\nexponential : Exponential (base e) activation function.\n\n\nlinear : Linear (i.e. identity) activation function.\n\n\n\n\n\n\nELU\n\n\nApplies exponential linear unit (\nELU\n), which parameter a varies the convergence value of the exponential function below zero:\n\n\nELU\n is defined as:\n\n\nf(x) = max(0, x) + min(0, alpha * (exp(x) - 1))\n\n\n\n\nThe output dimension is always equal to input dimension.\n\n\nFor reference see \nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n.\n\n\nScala:\n\n\nELU(alpha = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nm = ELU(alpha=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Double, scale for the negative factor. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](1.2, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.3208098      -0.3994111      1.5678865       -0.5417255      -0.72367394\n-0.16772668     -0.28669843     1.0305564       0.15613572      0.29151332\n-1.1018531      -0.32264477     -1.4345981      -0.4781121      -2.1548445\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4647158      -0.64999336     0.97413754\n1.0128744       -0.3654132      0.15322192      1.048261        0.9095614\n-0.6602698      0.2848114       -0.35451657     -1.3011501      0.7933063\n-1.5871915      -0.9177772      0.4741297       0.34224162      -2.7270272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8796972      -0.3951421      1.5678865       -0.5019077      -0.61803937\n-0.18529809     -0.29911432     1.0305564       0.15613572      0.29151332\n-0.8012943      -0.33092272     -0.9141467      -0.4560568      -1.0608946\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4460236      -0.5735409      0.97413754\n1.0128744       -0.36730814     0.15322192      1.048261        0.9095614\n-0.57994574     0.2848114       -0.358185       -0.8733378      0.7933063\n-0.9546011      -0.720713       0.4741297       0.34224162      -1.1215038\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(1.2, input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075],\n        [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956],\n        [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748],\n        [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108],\n        [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063],\n        [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432  ],\n        [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]])\n\n\n\n\nOutput is\n\n\narray([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076],\n        [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957],\n        [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748],\n        [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ],\n        [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066],\n        [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432  ],\n        [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]],\n      dtype=float32)\n\n\n\n\n\n\nRReLU\n\n\nApplies the randomized leaky rectified linear unit element-wise to the input.\n\n\nf(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).\n\n\nIn the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u).\n\n\nIn the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2.\n\n\nIf l == u, a RReLU essentially becomes a LeakyReLU.\n\n\nRegardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.\n\n\nFor reference, see \nEmpirical Evaluation of Rectified Activations in Convolutional Network\n.\n\n\nScala:\n\n\nRReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null)\n\n\n\n\nPython:\n\n\nRReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlower\n: Lower boundary of the uniform random distribution. Default is 1.0/8.\n\n\nupper\n: Upper boundary of the uniform random distribution. Default is 1.0/3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RReLU[Float](inputShape = Shape(1, 4)))\nval input = Tensor[Float](1, 1, 4).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import RReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RReLU(input_shape = (1, 4)))\ninput = np.random.random([1, 1, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]])\n\n\n\n\nOuput is:\n\n\narray([[[0.421039  , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32)\n\n\n\n\n\n\nHardTanh\n\n\nApplies the hard tanh function element-wise to the input.\n\n\nf(x) = maxValue, if x \n maxValue\n\n\nf(x) = minValue, if x \n minValue\n\n\nf(x) = x, otherwise\n\n\nScala:\n\n\nHardTanh(minValue = -1, maxValue = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nHardTanh(min_value=-1, max_value=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nminValue\n: The minimum threshold value. Default is -1.\n\n\nmaxValue\n: The maximum threshold value. Default is 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8396661       -2.096241       -0.36010137     -1.97987\n-0.20326108     1.5972694       -1.4166505      -0.3369559\n-0.22637285     -1.1021988      1.0707928       -1.5014135\n\n(2,.,.) =\n-0.24511681     -1.1103313      -0.7901563      -1.0394055\n-0.033373486    0.22657289      -0.7928737      1.5241393\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5     -1.0    -0.36010137     -1.0\n-0.20326108     0.5     -1.0    -0.3369559\n-0.22637285     -1.0    0.5     -1.0\n\n(2,.,.) =\n-0.24511681     -1.0    -0.7901563      -1.0\n-0.033373486    0.22657289      -0.7928737      0.5\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import HardTanh\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(HardTanh(-1, 0.5, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.38707977, 0.94085094, 0.50552125, 0.42818523],\n  [0.5544486 , 0.36521357, 0.42551631, 0.93228245],\n  [0.29155494, 0.61710319, 0.93137551, 0.05688166]],\n\n [[0.75222706, 0.36454257, 0.83076327, 0.82004643],\n  [0.29213453, 0.71532663, 0.99556398, 0.57001469],\n  [0.58088671, 0.32646428, 0.60736   , 0.14861018]]]\n\n\n\n\nOutput is\n\n\n[[[0.38707978, 0.5       , 0.5       , 0.42818522],\n  [0.5       , 0.36521357, 0.4255163 , 0.5       ],\n  [0.29155496, 0.5       , 0.5       , 0.05688166]],\n\n [[0.5       , 0.36454257, 0.5       , 0.5       ],\n  [0.29213452, 0.5       , 0.5       , 0.5       ],\n  [0.5       , 0.3264643 , 0.5       , 0.14861017]]]", 
            "title": "Activation"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#activation", 
            "text": "Simple activation function to be applied to the output.  Scala:  Activation(activation, inputShape = null)  Python:  Activation(activation, input_shape=None, name=None)  Parameters:   activation : Name of the activation function as string. See  here  for available activation strings.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Activation\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation[Float]( tanh , inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Activation\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Activation( tanh , input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]  Output is  [[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]  Note that the following two pieces of code will be equivalent:  model.add(Dense(32))\nmodel.add(Activation('relu'))  model.add(Dense(32, activation= relu ))", 
            "title": "Activation"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#available-activations", 
            "text": "elu  rrelu  relu : ReLU applies the element-wise rectified linear unit (ReLU) function to the input.  selu : Scaled Exponential Linear Unit (SELU). SELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants. The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see lecun_normal initialization) and the number of inputs is \"large enough\" (see references for more information).  tanh : Applies the Tanh function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.  hardtanh  sigmoid : Applies the Sigmoid function element-wise to the input Tensor, thus outputting a Tensor of the same dimension.  hard_sigmoid  softmax : Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\n            elements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\n            Softmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift) \n            where  shift = max_i(x_i) .  softplus : Apply the SoftPlus function to an n-dimensional input tensor.  softsign : SoftSign applies SoftSign function to the input tensor  exponential : Exponential (base e) activation function.  linear : Linear (i.e. identity) activation function.", 
            "title": "Available Activations"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#elu", 
            "text": "Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero:  ELU  is defined as:  f(x) = max(0, x) + min(0, alpha * (exp(x) - 1))  The output dimension is always equal to input dimension.  For reference see  Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) .  Scala:  ELU(alpha = 1.0, inputShape = null)  Python:  m = ELU(alpha=1.0, input_shape=None, name=None)  Parameters:   alpha : Double, scale for the negative factor. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](1.2, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.3208098      -0.3994111      1.5678865       -0.5417255      -0.72367394\n-0.16772668     -0.28669843     1.0305564       0.15613572      0.29151332\n-1.1018531      -0.32264477     -1.4345981      -0.4781121      -2.1548445\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4647158      -0.64999336     0.97413754\n1.0128744       -0.3654132      0.15322192      1.048261        0.9095614\n-0.6602698      0.2848114       -0.35451657     -1.3011501      0.7933063\n-1.5871915      -0.9177772      0.4741297       0.34224162      -2.7270272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8796972      -0.3951421      1.5678865       -0.5019077      -0.61803937\n-0.18529809     -0.29911432     1.0305564       0.15613572      0.29151332\n-0.8012943      -0.33092272     -0.9141467      -0.4560568      -1.0608946\n0.29493016      1.147811        0.8544963       0.15185815      0.6745268\n\n(2,.,.) =\n1.0066849       0.5372675       -0.4460236      -0.5735409      0.97413754\n1.0128744       -0.36730814     0.15322192      1.048261        0.9095614\n-0.57994574     0.2848114       -0.358185       -0.8733378      0.7933063\n-0.9546011      -0.720713       0.4741297       0.34224162      -1.1215038\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(1.2, input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)  Input is:  array([[[0.23377795, 0.63399382, 0.20220825, 0.04624555, 0.27801075],\n        [0.03957081, 0.35381371, 0.79261921, 0.99816918, 0.16381956],\n        [0.49612051, 0.26899042, 0.2938966 , 0.33734888, 0.38244748],\n        [0.49566264, 0.32071271, 0.91188529, 0.28086761, 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135255, 0.89603108],\n        [0.60468387, 0.30496216, 0.87750968, 0.56073388, 0.74250063],\n        [0.63637121, 0.79358453, 0.26458867, 0.19688831, 0.825432  ],\n        [0.14432605, 0.71667083, 0.54347079, 0.82549804, 0.82994232]]])  Output is  array([[[0.23377796, 0.6339938 , 0.20220825, 0.04624555, 0.27801076],\n        [0.03957081, 0.3538137 , 0.7926192 , 0.9981692 , 0.16381957],\n        [0.4961205 , 0.26899043, 0.29389662, 0.33734888, 0.38244748],\n        [0.49566263, 0.32071272, 0.91188526, 0.2808676 , 0.8337798 ]],\n\n       [[0.38511148, 0.9840061 , 0.24044046, 0.27135256, 0.8960311 ],\n        [0.6046839 , 0.30496216, 0.87750965, 0.5607339 , 0.74250066],\n        [0.6363712 , 0.7935845 , 0.26458865, 0.19688831, 0.825432  ],\n        [0.14432605, 0.7166708 , 0.5434708 , 0.82549804, 0.82994235]]],\n      dtype=float32)", 
            "title": "ELU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#rrelu", 
            "text": "Applies the randomized leaky rectified linear unit element-wise to the input.  f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).  In the training mode, negative inputs are multiplied by a factor drawn from a uniform random distribution U(l, u).  In the evaluation mode, a RReLU behaves like a LeakyReLU with a constant mean factor a = (l + u) / 2.  If l == u, a RReLU essentially becomes a LeakyReLU.  Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.  For reference, see  Empirical Evaluation of Rectified Activations in Convolutional Network .  Scala:  RReLU(lower = 1.0/8, upper = 1.0/3, inputShape = null)  Python:  RReLU(lower=1.0/8, upper=1.0/3, input_shape=None, name=None)  Parameters:   lower : Lower boundary of the uniform random distribution. Default is 1.0/8.  upper : Upper boundary of the uniform random distribution. Default is 1.0/3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RReLU\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RReLU[Float](inputShape = Shape(1, 4)))\nval input = Tensor[Float](1, 1, 4).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1308445       0.001281989     0.13936701      0.21237929\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import RReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RReLU(input_shape = (1, 4)))\ninput = np.random.random([1, 1, 4])\noutput = model.forward(input)  Input is:  array([[[0.42103899, 0.5255088 , 0.70384155, 0.55685647]]])  Ouput is:  array([[[0.421039  , 0.5255088 , 0.70384157, 0.55685645]]], dtype=float32)", 
            "title": "RReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#hardtanh", 
            "text": "Applies the hard tanh function element-wise to the input.  f(x) = maxValue, if x   maxValue  f(x) = minValue, if x   minValue  f(x) = x, otherwise  Scala:  HardTanh(minValue = -1, maxValue = 1, inputShape = null)  Python:  HardTanh(min_value=-1, max_value=1, input_shape=None, name=None)  Parameters:   minValue : The minimum threshold value. Default is -1.  maxValue : The maximum threshold value. Default is 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.HardTanh\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(HardTanh[Float](-1, 0.5, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8396661       -2.096241       -0.36010137     -1.97987\n-0.20326108     1.5972694       -1.4166505      -0.3369559\n-0.22637285     -1.1021988      1.0707928       -1.5014135\n\n(2,.,.) =\n-0.24511681     -1.1103313      -0.7901563      -1.0394055\n-0.033373486    0.22657289      -0.7928737      1.5241393\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5     -1.0    -0.36010137     -1.0\n-0.20326108     0.5     -1.0    -0.3369559\n-0.22637285     -1.0    0.5     -1.0\n\n(2,.,.) =\n-0.24511681     -1.0    -0.7901563      -1.0\n-0.033373486    0.22657289      -0.7928737      0.5\n0.49224186      -0.21418595     -0.32379007     -0.941034\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import HardTanh\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(HardTanh(-1, 0.5, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.38707977, 0.94085094, 0.50552125, 0.42818523],\n  [0.5544486 , 0.36521357, 0.42551631, 0.93228245],\n  [0.29155494, 0.61710319, 0.93137551, 0.05688166]],\n\n [[0.75222706, 0.36454257, 0.83076327, 0.82004643],\n  [0.29213453, 0.71532663, 0.99556398, 0.57001469],\n  [0.58088671, 0.32646428, 0.60736   , 0.14861018]]]  Output is  [[[0.38707978, 0.5       , 0.5       , 0.42818522],\n  [0.5       , 0.36521357, 0.4255163 , 0.5       ],\n  [0.29155496, 0.5       , 0.5       , 0.05688166]],\n\n [[0.5       , 0.36454257, 0.5       , 0.5       ],\n  [0.29213452, 0.5       , 0.5       , 0.5       ],\n  [0.5       , 0.3264643 , 0.5       , 0.14861017]]]", 
            "title": "HardTanh"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/initialization/", 
            "text": "", 
            "title": "Initialization"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/", 
            "text": "Masking\n\n\nUse a mask value to skip timesteps for a sequence.\n\n\nScala:\n\n\nMasking(maskValue = 0.0, inputShape = null)\n\n\n\n\nPython:\n\n\nMasking(mask_value=0.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nmaskValue\n: Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Masking\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.31542103 0.20640659 0.22282763]\n [0.99352167 0.90135718 0.24504717]]\n\n\n\n\nOutput is\n\n\n[[0.31542102 0.2064066  0.22282763]\n [0.9935217  0.9013572  0.24504717]]\n\n\n\n\n\n\nSparseDense\n\n\nSparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:\nfirstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward\ngradient to next layer in the backpropagation by default, as the gradInput of SparseDense is\nuseless and very big in most cases.\n\n\nBut, considering model like Wide\nDeep, we provide backwardStart and backwardLength to backward\npart of the gradient to next layer.\n\n\nThe most common input is 2D.\n\n\nScala:\n\n\nSparseDense(outputDim, init = \nglorot_uniform\n, activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nSparseDense(output_dim, init=\nglorot_uniform\n, activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of the output dimension.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. Default is null.\n\n\nwRegularizer\n: An instance of [Regularizer], applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of [Regularizer], applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\nbackwardStart\n: Backward start index, counting from 1.\n\n\nbackwardLength\n: Backward length.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4))\nlayer.build(Shape(-1, 2, 4))\nval input = Tensor[Float](Array(2, 4)).rand()\ninput.setValue(1, 1, 1f)\ninput.setValue(2, 3, 3f)\nval sparseInput = Tensor.sparse(input)\nval output = layer.forward(sparseInput)\n\n\n\n\nInput is:\n\n\ninput: \n(0, 0) : 1.0\n(0, 1) : 0.2992794\n(0, 2) : 0.11227019\n(0, 3) : 0.722947\n(1, 0) : 0.6147614\n(1, 1) : 0.4288646\n(1, 2) : 3.0\n(1, 3) : 0.7749917\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: \n0.053516    0.33429605  0.22587383  -0.8998945  0.24308181  \n0.76745665  -1.614114   0.5381658   -2.2226436  -0.15573677 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseDense\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseDense(output_dim=2, input_shape=(3, 4)))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\nJTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float\n\n\n\n\nOutput is\n\n\n[[ 1.57136     2.29596   ]\n [ 0.5791738  -1.6598101 ]\n [ 2.331141   -0.84687066]]\n ```\n\n## **SoftShrink**\nApplies the soft shrinkage function element-wise to the input.\n\nWhen you use this layer as the first layer of a model, you need to provide\nthe argument inputShape (a Single Shape, does not include the batch dimension).\n\nRemark: This layer is from Torch and wrapped in Keras style.\n\n\n**Scala:**\n```scala\nSoftShrink(value = 0.5, inputShape = null)\n\n\n\n\nPython:\n\n\nSoftShrink(value = 0.5, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nvalue\n: value The threshold value. Default is 0.5.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.36938807 0.023556225 -1.1655436  -0.34449077\n0.9444338   -0.086538695    -1.0425501  1.364976\n-1.2563878  -0.1842559  0.43428117  1.0756494\n\n(1,2,.,.) =\n-0.19888283 1.251872    0.114836805 -0.6208773\n0.0051822234    -0.8998633  0.06937465  -0.3929931\n-0.1058129  0.6945743   -0.40083578 -0.6252444\n\n(2,1,.,.) =\n-0.9899709  -0.77926594 -0.15497442 -0.15031165\n-0.6028622  0.86623466  -2.1543107  0.41970536\n-0.8215522  0.3014275   -0.32184362 0.14445356\n\n(2,2,.,.) =\n0.74701905  0.10044397  -0.40519297 0.03822808\n0.30726334  0.27862388  1.731753    0.032177072\n-1.3476961  -0.2294767  0.99794704  0.7398458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0 0.0 -0.56554353 0.0\n0.34443378  0.0 -0.44255006 0.764976\n-0.6563878  0.0 0.0 0.47564936\n\n(1,2,.,.) =\n0.0 0.6518719   0.0 -0.020877302\n0.0 -0.29986328 0.0 0.0\n0.0 0.09457427  0.0 -0.025244355\n\n(2,1,.,.) =\n-0.3899709  -0.17926592 0.0 0.0\n-0.0028621554   0.26623464  -1.5543107  0.0\n-0.2215522  0.0 0.0 0.0\n\n(2,2,.,.) =\n0.14701903  0.0 0.0 0.0\n0.0 0.0 1.131753    0.0\n-0.74769604 0.0 0.397947    0.13984579\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SoftShrink\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SoftShrink(0.6, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[ 0.43421006,  0.28394451,  0.15221226,  0.47268966],\n         [ 0.22426224,  0.24855662,  0.790498  ,  0.67767582],\n         [ 0.14879562,  0.56077882,  0.61470262,  0.94875862]],\n\n        [[ 0.72404932,  0.89780875,  0.08456734,  0.01303937],\n         [ 0.25023568,  0.45392504,  0.587254  ,  0.51164461],\n         [ 0.12277567,  0.05571182,  0.17076456,  0.71660884]]],\n\n\n       [[[ 0.06369975,  0.85395557,  0.35752425,  0.606633  ],\n         [ 0.67640252,  0.86861737,  0.18040722,  0.55467108],\n         [ 0.24102058,  0.37580645,  0.81601612,  0.56513788]],\n\n        [[ 0.8461435 ,  0.65668365,  0.17969807,  0.51602926],\n         [ 0.86191073,  0.34245714,  0.62795207,  0.36706125],\n         [ 0.80344028,  0.81056003,  0.80959083,  0.15366483]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.19049799,  0.07767582],\n         [ 0.        ,  0.        ,  0.01470262,  0.34875858]],\n\n        [[ 0.12404931,  0.29780871,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.1166088 ]]],\n\n\n       [[[ 0.        ,  0.25395554,  0.        ,  0.00663298],\n         [ 0.07640249,  0.26861733,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.21601611,  0.        ]],\n\n        [[ 0.24614346,  0.05668366,  0.        ,  0.        ],\n         [ 0.26191074,  0.        ,  0.02795208,  0.        ],\n         [ 0.20344025,  0.21056002,  0.20959079,  0.        ]]]], dtype=float32)\n\n ```\n\n---\n## **Reshape**\nReshapes an output to a certain shape.\n\nSupports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).\n\n**Scala:**\n```scala\nReshape(targetShape, inputShape = null)\n\n\n\n\nPython:\n\n\nReshape(target_shape, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntargetShape\n: The target shape that you desire to have. Batch dimension should be excluded.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Reshape\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]\n\n\n\n\nOutput is\n\n\n[[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]\n\n\n\n\n\n\nMerge\n\n\nUsed to merge a list of inputs into a single output, following some merge mode.\n\n\nMerge must have at least two input layers.\n\n\nScala:\n\n\nMerge(layers = null, mode = \nsum\n, concatAxis = -1, inputShape = null)\n\n\n\n\nPython:\n\n\nMerge(layers=None, mode=\nsum\n, concat_axis=-1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlayers\n: A list of layer instances. Must be more than one layer.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode = \nsum\n)\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -\n input1, 2 -\n input2)\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Merge, InputLayer\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n   [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n   [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n  [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n   [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n   [0.56138318, 0.68165639, 0.10644523, 0.51860127]]],\n\n [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n   [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n   [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n  [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n   [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n   [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]]\n\n\n\n\nOutput is\n\n\n[[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]\n\n\n\n\n\n\nMaxoutDense\n\n\nA dense maxout layer that takes the element-wise maximum of linear layers.\n\n\nThis allows the layer to learn a convex, piecewise linear activation function over the inputs.\n\n\nThe input of this layer should be 2D.\n\n\nScala:\n\n\nMaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of output dimension.\n\n\nnbFeature\n: Number of Dense layers to use internally. Integer. Default is 4.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxoutDense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]\n\n\n\n\nOutput is\n\n\n[[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]\n\n\n\n\n\n\nSqueeze\n\n\nDelete the singleton dimension(s). The batch dimension needs to be unchanged.\n\n\nFor example, if input has size (2, 1, 3, 4, 1):\n\n\nSqueeze(1) will give output size (2, 3, 4, 1),\n\n\nSqueeze() will give output size (2, 3, 4)\n\n\nScala:\n\n\nSqueeze(dims = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSqueeze(dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndims\n: The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32)))\nval input = Tensor[Float](1, 1, 1, 32).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Squeeze\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Squeeze(1, input_shape=(1, 1, 32)))\ninput = np.random.random([1, 1, 1, 32])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281,\n    0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763,\n    0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269,\n    0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821,\n    0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 ,\n    0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729,\n    0.89774196, 0.77838838]]]]\n\n\n\n\nOutput is\n\n\n[[[0.20585343, 0.470117  , 0.14553176, 0.939156  , 0.5723428 ,\n   0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763,\n   0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 ,\n   0.48919672, 0.284064  , 0.20962799, 0.8807176 , 0.45501822,\n   0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 ,\n   0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 ,\n   0.897742  , 0.7783884 ]]]\n\n\n\n\n\n\nBinaryThreshold\n\n\nThreshold the input.\n\n\nIf an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1.\n\n\nScala:\n\n\nBinaryThreshold(value = 1e-6, inputShape = null)\n\n\n\n\nPython:\n\n\nBinaryThreshold(value=1e-6, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nvalue\n: The threshold value to compare with. Default is 1e-6.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1907398      -0.18995096     -2.0344417      -1.3789974\n-1.8801064      -0.74757665     -0.4339697      0.0058485097\n0.7012256       -0.6363152      2.0156987       -0.5512639\n\n(1,2,.,.) =\n-0.5251603      0.082127444     0.29550993      1.6357868\n-1.3828015      -0.11842779     0.3316966       -0.14360528\n0.21216457      -0.117370956    -0.12934707     -0.35854268\n\n(2,1,.,.) =\n-0.9071151      -2.8566089      -0.4796377      -0.915065\n-0.8439908      -0.25404388     -0.39926198     -0.15191565\n-1.0496653      -0.403675       -1.3591816      0.5311797\n\n(2,2,.,.) =\n0.53509855      -0.08892822     1.2196561       -0.62759316\n-0.47476718     -0.43337926     -0.10406987     1.4035174\n-1.7120812      1.1328355       0.9219375       1.3813454\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n1.0     0.0     1.0     0.0\n\n(1,2,.,.) =\n0.0     1.0     1.0     1.0\n0.0     0.0     1.0     0.0\n1.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n\n(2,2,.,.) =\n1.0     0.0     1.0     0.0\n0.0     0.0     0.0     1.0\n0.0     1.0     1.0     1.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import BinaryThreshold\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(BinaryThreshold(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767],\n         [0.72650405, 0.53096719, 0.66346109, 0.0589329 ],\n         [0.12994731, 0.92181174, 0.43129874, 0.97306968]],\n\n        [[0.3031087 , 0.20339982, 0.69034712, 0.40191   ],\n         [0.57517034, 0.30159448, 0.4801747 , 0.75175084],\n         [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]],\n\n\n       [[[0.46102959, 0.33029002, 0.69340103, 0.32885719],\n         [0.84405147, 0.03421879, 0.68242578, 0.03560338],\n         [0.12244515, 0.3610654 , 0.01312785, 0.84485178]],\n\n        [[0.73472287, 0.75707757, 0.77070527, 0.40863145],\n         [0.01137898, 0.82896826, 0.1498069 , 0.22309423],\n         [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]])\n\n\n\n\nOutput is\n\n\narray([[[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]],\n\n\n       [[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]]], dtype=float32)\n\n\n\n\n\n\nSqrt\n\n\nApplies an element-wise square root operation to the input.\n\n\nScala:\n\n\nSqrt(inputShape = null)\n\n\n\n\nPython:\n\n\nSqrt(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Sqrt[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6950394       0.5234307       1.7375475\n0.25833175      0.02685826      -0.6046901\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8336902       0.7234851       1.3181607\n0.50826347      0.16388491      NaN\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Sqrt\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Sqrt(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.2484558 , 0.65280218, 0.35286984],\n [0.19616094, 0.30966802, 0.82148169]]\n\n\n\n\nOutput is\n\n\n[[0.4984534 , 0.80796176, 0.5940285 ],\n [0.4429006 , 0.55647826, 0.9063563 ]]\n\n\n\n\n\n\nMul\n\n\nMultiply a single scalar factor to the incoming data\n\n\nScala:\n\n\nMul(inputShape = null)\n\n\n\n\nPython:\n\n\nMul(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Mul\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Mul[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2316265  -2.008802 -1.3908259  -0.61135375\n-0.48992255 0.1786112 0.18872596  0.49621895\n-0.6931602  -0.919745 -0.09019699 -0.41218707\n\n(2,.,.) =\n-0.3135355  -0.4385771  -0.3317269  1.0412029\n-0.8859662  0.17758773  -0.73779273 -0.4445366\n0.3921595 1.6923207 0.014470488 0.4044164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.59036994 -0.9629025  -0.6666808  -0.29304734\n-0.2348403  0.0856158 0.09046422  0.23785843\n-0.33226058 -0.44087213 -0.043235175  -0.19757845\n\n(2,.,.) =\n-0.15029064 -0.21022828 -0.15901053 0.49909195\n-0.42468053 0.0851252 -0.3536548  -0.21308492\n0.18797839  0.81119984  0.006936308 0.19385365\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Mul\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Mul(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.22607292,  0.59806062,  0.19428923,  0.22928606],\n        [ 0.13804536,  0.1615547 ,  0.52824658,  0.52794904],\n        [ 0.4049169 ,  0.94109084,  0.58158453,  0.78368633]],\n\n       [[ 0.86233305,  0.47995805,  0.80430949,  0.9931171 ],\n        [ 0.35179631,  0.33615276,  0.87756877,  0.73560288],\n        [ 0.29775703,  0.11404466,  0.77695536,  0.97580018]]])\n\n\n\n\nOutput is\n\n\narray([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998],\n        [-0.13730718, -0.1606908 , -0.52542186, -0.52512592],\n        [-0.40275168, -0.93605846, -0.57847458, -0.77949566]],\n\n       [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ],\n        [-0.34991512, -0.33435524, -0.87287611, -0.73166931],\n        [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32)\n\n\n\n\n\n\nMulConstant\n\n\nMultiply the input by a (non-learnable) scalar constant.\n\n\nScala:\n\n\nMulConstant(constant, inputShape = null)\n\n\n\n\nPython:\n\n\nMulConstant(constant, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nconstant\n: The scalar constant to be multiplied.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MulConstant[Float](2.2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.16873977     1.0812985       1.0942211       -0.67091423\n1.0086882       0.5915831       0.26184535      -1.361431\n1.5616825       -0.037591368    1.2794676       1.0692137\n\n(2,.,.) =\n0.29868057      -0.23266982     -0.7679556      -2.209848\n-0.13954644     -0.1368473      -0.54510623     1.8397199\n-0.58691734     -0.56410027     -1.5567777      0.050648995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.3712275      2.3788567       2.4072864       -1.4760114\n2.219114        1.3014828       0.57605976      -2.9951482\n3.4357016       -0.08270101     2.8148286       2.3522704\n\n(2,.,.) =\n0.6570973       -0.5118736      -1.6895024      -4.8616657\n-0.3070022      -0.30106407     -1.1992338      4.047384\n-1.2912182      -1.2410206      -3.424911       0.11142779\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MulConstant\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MulConstant(2.2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.39874191, 0.66634984, 0.23907766, 0.31587494],\n  [0.78842014, 0.93057835, 0.80739529, 0.71541279],\n  [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]],\n\n [[0.60142458, 0.41221671, 0.00890549, 0.32069845],\n  [0.51122554, 0.76280426, 0.87579418, 0.17182832],\n  [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]]\n\n\n\n\nOutput is\n\n\n[[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ],\n  [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ],\n  [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]],\n\n [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ],\n  [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234],\n  [1.19093   , 0.43591645, 2.0356452 , 1.2356553 ]]]\n\n\n\n\n\n\nScale\n\n\nScale is the combination of CMul and CAdd.\n\n\nComputes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input.\n\n\nSimilarly, perform an expanded bias and perform an element-wise add.\n\n\nScala:\n\n\nScale(size, inputShape = null)\n\n\n\n\nPython:\n\n\nScale(size, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Size of the weight and bias.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Scale\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nvar array = Array(1, 2)\nmodel.add(Scale[Float](array, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006399727    -0.06412822     -0.2334789\n0.31029955      1.6557469       1.9614618\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.09936619      0.57585865      0.20324506\n0.38537437      -0.8598822      -1.0186496\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Scale\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Scale((2, 1), input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.7242994 , 0.77888884, 0.71470432],\n [0.03058471, 0.00602764, 0.57513629]]\n\n\n\n\nOutput is\n\n\n[[1.0946966 , 1.1255064 , 1.0892813 ],\n [0.58151895, 0.5909191 , 0.37307182]]\n\n\n\n\n\n\nLog\n\n\nApplies a log transformation to the input.\n\n\nScala:\n\n\nLog(inputShape = null)\n\n\n\n\nPython:\n\n\nLog(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Log\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Log[Float](inputShape = Shape(2, 4, 4)))\nval input = Tensor[Float](1, 2, 4, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.38405678      -0.5502389      -0.383079       -0.988537\n-0.6294056      -0.7838047      0.8747865       -1.0659786\n-2.2445498      -0.5488076      -0.42898977     0.6916364\n1.6542299       -0.9966279      -0.38244298     1.6954672\n\n(1,2,.,.) =\n0.43478605      -0.6678534      1.9530942       -0.5209587\n0.12899925      0.20572199      2.0359943       0.55223215\n0.65247816      0.8792108       -0.38860792     0.48663738\n-1.0084358      0.31141177      0.69208467      0.48385203\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.95696485     NaN     NaN     NaN\nNaN     NaN     -0.13377543     NaN\nNaN     NaN     NaN     -0.36869493\n0.5033356       NaN     NaN     0.5279584\n\n(1,2,.,.) =\n-0.83290124     NaN     0.6694149       NaN\n-2.0479486      -1.5812296      0.7109843       -0.5937868\n-0.4269776      -0.12873057     NaN     -0.720236\nNaN     -1.1666392      -0.36804697     -0.72597617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Log\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Log(input_shape=(2, 4, 4)))\ninput = np.random.random([1, 2, 4, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453],\n   [0.46529477, 0.81511804, 0.24435558, 0.45003562],\n   [0.15170845, 0.35157662, 0.0925214 , 0.63852947],\n   [0.27817508, 0.42572846, 0.44363004, 0.03536394]],\n\n  [[0.65027784, 0.00429838, 0.07434429, 0.18653305],\n   [0.19659183, 0.66647529, 0.77821197, 0.65894478],\n   [0.28212032, 0.52307663, 0.09589939, 0.71547588],\n   [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032],\n   [-0.76508415, -0.20442237, -1.4091308 , -0.79842854],\n   [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742],\n   [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]],\n\n  [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ],\n   [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554],\n   [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743],\n   [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]]\n\n\n\n\n\n\nIdentity\n\n\nIdentity just return the input to output.\n\n\nIt's useful in same parallel container to get an origin input.\n\n\nScala:\n\n\nIdentity(inputShape = null)\n\n\n\n\nPython:\n\n\nIdentity(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Identity\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Identity[Float](inputShape = Shape(4, 4)))\nval input = Tensor[Float](3, 4, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Identity\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Identity(input_shape=(4, 4)))\ninput = np.random.random([3, 4, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.36751123, 0.92287101, 0.73894405, 0.33699379],\n  [0.69405782, 0.9653215 , 0.2617223 , 0.68205229],\n  [0.71455325, 0.99419333, 0.90886495, 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921154, 0.26803146]],\n\n  [[0.35898357, 0.72067882, 0.13236563, 0.71935521],\n   [0.30865626, 0.71098844, 0.86718946, 0.12531168],\n   [0.84916882, 0.84221518, 0.52186664, 0.87239729],\n   [0.50637899, 0.10890469, 0.86832705, 0.93581179]],\n\n  [[0.19640105, 0.09341008, 0.12043328, 0.09261859],\n   [0.66019486, 0.07251262, 0.80929761, 0.39094486],\n   [0.63027391, 0.39537796, 0.55578905, 0.53933265],\n   [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]]\n\n\n\n\nOutput is\n\n\n[[[0.36751124, 0.922871  , 0.73894405, 0.33699378],\n  [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ],\n  [0.71455324, 0.9941933 , 0.908865  , 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921156, 0.26803148]],\n\n [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ],\n  [0.30865628, 0.71098846, 0.86718947, 0.12531169],\n  [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ],\n  [0.506379  , 0.10890469, 0.868327  , 0.9358118 ]],\n\n [[0.19640104, 0.09341008, 0.12043328, 0.09261858],\n  [0.6601949 , 0.07251262, 0.8092976 , 0.39094487],\n  [0.63027394, 0.39537796, 0.55578905, 0.5393326 ],\n  [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]]\n\n\n\n\n\n\nSelect\n\n\nSelect an index of the input in the given dim and return the subset part.\n\n\nThe batch dimension needs to be unchanged.\n\n\nFor example, if input is:\n\n\n[[1, 2, 3], \n [4, 5, 6]]\n\n\nSelect(1, 1) will give output [2 5]\n\n\nSelect(1, -1) will give output [3 6]\n\n\nScala:\n\n\nSelect(dim, index, inputShape = null)\n\n\n\n\nPython:\n\n\nSelect(dim, index, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndim\n: The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input.\n\n\nindex\n: The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Select\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3)))\nval input = Tensor[Float](1, 3, 1, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.67646945     -0.5485965      -0.11103154\n(1,2,.,.) =\n-0.13488655     0.43843046      -0.04482145\n(1,3,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Select\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Select(1, 2, input_shape=(3, 1, 3)))\ninput = np.random.random([1, 3, 1, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.53306099, 0.95147881, 0.15222129]],\n        [[0.89604861, 0.90160974, 0.5230576 ]],\n        [[0.70779386, 0.14438568, 0.37601195]]]])\n\n\n\n\nOutput is:\n\n\narray([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32)\n\n\n\n\n\n\nDense\n\n\nA densely-connected NN layer.\n\n\nThe most common input is 2D.\n\n\nScala:\n\n\nDense(outputDim, init = \nglorot_uniform\n, activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nDense(output_dim, init=\nglorot_uniform\n, activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of the output dimension.\n\n\ninit\n: Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method.\n\n\nactivation\n: Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](5, activation = \nrelu\n, inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4289935       -1.7659454      -0.08306135     -1.0153456\n1.0191492       0.37392816      1.3076705       -0.19495767\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5421522       0.49008092      0.0     0.0     0.0\n0.07940009      0.0     0.12953377      0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Dense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(5, activation=\nrelu\n, input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[0.64593485, 0.67393322, 0.72505368, 0.04654095],\n       [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]])\n\n\n\n\nOutput is\n\n\narray([[0.        , 0.        , 1.2698183 , 0.        , 0.10656227],\n       [0.        , 0.        , 0.6236721 , 0.00299606, 0.29664695]],\n      dtype=float32)\n\n\n\n\n\n\nNegative\n\n\nComputes the negative value of each element of the input.\n\n\nScala:\n\n\nNegative(inputShape = null)\n\n\n\n\nPython:\n\n\nNegative(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Negative\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Negative[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.031705        -0.5723963      1.998631\n-0.32908052     2.4069138       -2.4111257\n(2,.,.) =\n0.5355049       -1.4404331      -0.38116863\n-0.45641592     -1.1485358      0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.031705       0.5723963       -1.998631\n0.32908052      -2.4069138      2.4111257\n(2,.,.) =\n-0.5355049      1.4404331       0.38116863\n0.45641592      1.1485358       -0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Negative\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Negative(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.39261261, 0.03164615, 0.32179116],\n        [0.11969367, 0.61610712, 0.42573733]],\n       [[0.36794656, 0.90912174, 0.540356  ],\n        [0.42667627, 0.04154093, 0.84692964]]])\n\n\n\n\nOutput is\n\n\narray([[[-0.3926126 , -0.03164615, -0.32179114],\n        [-0.11969367, -0.6161071 , -0.42573732]],\n       [[-0.36794657, -0.90912175, -0.540356  ],\n        [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32)\n\n\n\n\n\n\nCAdd\n\n\nThis layer has a bias with given size.\n\n\nThe bias will be added element-wise to the input.\n\n\nIf the element number of the bias matches the input, a simple element-wise addition will be done.\n\n\nOr the bias will be expanded to the same size of the input.\n\n\nThe expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised).\n\n\nScala:\n\n\nCAdd(size, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nCAdd(size, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: the size of the bias\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.2183351       0.32434112      0.89350265\n0.3348259       0.78677046      0.24054797\n(2,.,.) =\n0.9945844       0.72363794      0.7737936\n0.05522544      0.3517818       0.7417069\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1358028       0.6956667       1.0837181\n0.6767027       0.7955346       0.5063505\n(2,.,.) =\n0.9120521       1.0949634       0.96400905\n0.3971022       0.36054593      1.0075095\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import CAdd\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(CAdd([2, 1], input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.4122004 , 0.73289359, 0.11500016],\n        [0.26974491, 0.32166632, 0.91408442]],\n       [[0.66824327, 0.80271314, 0.75981145],\n        [0.39271431, 0.07312566, 0.4966805 ]]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.06560206,  0.38629526, -0.23159817],\n        [ 0.44287407,  0.4947955 ,  1.0872136 ]],\n       [[ 0.32164496,  0.45611483,  0.41321313],\n        [ 0.56584346,  0.24625483,  0.6698097 ]]], dtype=float32)\n\n\n\n\n\n\nRepeatVector\n\n\nRepeats the input n times.\n\n\nThe input of this layer should be 2D, i.e. (num_samples, features).\nThe output of thi layer should be 3D, i.e. (num_samples, n, features).\n\n\nScala:\n\n\nRepeatVector(n, inputShape = null)\n\n\n\n\nPython:\n\n\nRepeatVector(n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nn\n: Repetition factor. Integer.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector[Float](4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.31839952 -0.3495366  0.542486\n-0.54981124 -0.8428188  0.8225184\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n\n(2,.,.) =\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import RepeatVector\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[ 0.90715922,  0.54594769,  0.53952404],\n       [ 0.08989831,  0.07265549,  0.45830114]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402]],\n\n       [[ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116]]], dtype=float32)\n\n\n\n\n\n\nGaussianSampler\n\n\nTakes {mean, log_variance} as input and samples from the Gaussian distribution.\n\n\nScala:\n\n\nGaussianSampler(inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianSampler(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler\nimport com.intel.analytics.bigdl.utils.{Shape, MultiShape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval shape1 = Shape(2, 3)\nval shape2 = Shape(2, 3)\nmodel.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2))))\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -\n input1, 2 -\n input2)\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: (1,.,.) =\n           0.9996127    0.8964211       0.7424038\n           0.40628982   0.37035564      0.20108517\n\n           (2,.,.) =\n           0.6974727    0.60202897      0.1535999\n           0.012422224  0.5993025       0.96206\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n        1: (1,.,.) =\n           0.21060324   0.576583        0.21633287\n           0.1484059    0.2730577       0.25317845\n\n           (2,.,.) =\n           0.58513683   0.58095694      0.18811373\n           0.7029449    0.41235915      0.44636542\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5258198       1.9536011       -1.8591263\n-1.0618867      -0.751225       0.35412917\n\n(2,.,.) =\n1.3334517       -0.60312974     0.7324476\n0.09502721      0.8094909       0.44807082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GaussianSampler\n\nmodel = Sequential()\nmodel.add(GaussianSampler(input_shape=[(3,),(3,)]))\ninput1 = np.random.random([2, 3])\ninput2 = np.random.random([2, 3])\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.79941342, 0.87462822, 0.9516901 ],\n  [0.20111287, 0.54634077, 0.83614511]], \n\n [[0.31886989, 0.22829382, 0.84355419],\n  [0.51186641, 0.28043938, 0.29440057]]]\n\n\n\n\nOutput is\n\n\n[[ 0.71405387  2.2944303  -0.41778684]\n [ 0.84234     2.3337283  -0.18952972]]\n\n\n\n\n\n\nExp\n\n\nApplies element-wise exp to the input.\n\n\nWhen you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nExp(inputShape = null)\n\n\n\n\nPython:\n\n\nExp(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Exp\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Exp[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.5841372      -0.13795324     -2.144475       0.09272669\n1.055668        -1.2310301      1.2145554       -0.6073714\n0.9296467       0.2923885       1.3364213       0.1652137\n\n(1,2,.,.) =\n0.2099718       -0.3856573      -0.92586        -0.5317779\n0.6618383       -0.9677452      -1.5014665      -0.35464883\n2.045924        -0.317644       -1.812726       0.95438373\n\n(2,1,.,.) =\n-0.4536791      -0.34785584     1.6424289       -0.07981159\n-0.8022624      -0.4211059      0.3461831       1.9598864\n-0.84695745     -0.6115283      0.7729755       2.3077402\n\n(2,2,.,.) =\n-0.08438411     -0.908458       0.6688936       -0.7292123\n-0.26337254     0.55425745      -0.14925817     -0.010179609\n-0.62562865     -1.0517743      -0.23839666     -1.144982\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.20512469      0.8711394       0.11712951      1.0971619\n2.8738942       0.29199165      3.3687959       0.544781\n2.533614        1.3396233       3.8054006       1.1796452\n\n(1,2,.,.) =\n1.2336433       0.6800035       0.39619055      0.5875594\n1.9383523       0.37993878      0.22280318      0.7014197\n7.7363033       0.7278619       0.16320862      2.5970695\n\n(2,1,.,.) =\n0.63528657      0.70620066      5.167706        0.92329025\n0.44831353      0.6563206       1.4136615       7.0985208\n0.42871734      0.5425211       2.1662023       10.051684\n\n(2,2,.,.) =\n0.9190782       0.4031454       1.9520763       0.48228875\n0.76845556      1.740648        0.8613467       0.98987204\n0.53492504      0.34931743      0.7878901       0.31822965\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Exp\n\nmodel = Sequential()\nmodel.add(Exp(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.93104587 0.94000338 0.84870765 0.98645553]\n   [0.83708846 0.33375541 0.50119834 0.24879265]\n   [0.51966475 0.84514791 0.15496452 0.61538968]]\n\n  [[0.57250337 0.42520832 0.94850757 0.54317573]\n   [0.64228691 0.9904079  0.01008592 0.51365217]\n   [0.78640595 0.7717037  0.51277595 0.24245034]]]\n\n\n [[[0.82184752 0.92537331 0.20632728 0.47539445]\n   [0.44604637 0.1507692  0.5437313  0.2074501 ]\n   [0.93661363 0.93962609 0.29230559 0.74850958]]\n\n  [[0.11659768 0.76177132 0.33194573 0.20695088]\n   [0.49636212 0.85987328 0.49767861 0.96774006]\n   [0.67669121 0.15542122 0.69981032 0.3349874 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[2.5371614 2.5599902 2.3366253 2.6817122]\n   [2.3096325 1.3962016 1.6506982 1.2824761]\n   [1.6814638 2.3283222 1.1676165 1.8503776]]\n\n  [[1.7726992 1.5299091 2.5818534 1.721465 ]\n   [1.9008229 2.6923325 1.010137  1.6713842]\n   [2.1954916 2.163449  1.6699204 1.2743679]]]\n\n\n [[[2.2746985 2.52281   1.2291554 1.6086487]\n   [1.5621239 1.1627283 1.7224218 1.2305363]\n   [2.551327  2.5590243 1.3395122 2.1138473]]\n\n  [[1.1236672 2.1420672 1.3936772 1.2299222]\n   [1.6427343 2.3628614 1.6448984 2.6319895]\n   [1.9673574 1.16815   2.0133708 1.3979228]]]]\n\n\n\n\n\n\nSquare\n\n\nApplies an element-wise square operation to the input.\n\n\nWhen you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nSquare(inputShape = null)\n\n\n\n\nPython:\n\n\nSquare(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nMultiShape\n object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Square\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Square[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.108013034    1.8879265       1.2232096       -1.5076439\n1.4895755       -0.37966672     -0.34892964     0.15224025\n-0.9296686      -1.1523775      0.14153497      -0.26954007\n\n(1,2,.,.) =\n-1.0875931      2.190617        -0.6903083      1.0039362\n-0.1275677      -1.1096588      0.37359753      -0.17367937\n0.23349741      0.14639114      -0.2330162      0.5343827\n\n(2,1,.,.) =\n0.3222191       0.21463287      -1.0157064      -0.22627507\n1.1714277       0.43371263      1.069315        0.5122436\n0.1958086       -1.4601041      2.5394423       -0.470833\n\n(2,2,.,.) =\n-0.38708544     -0.951611       -0.37234613     0.26813275\n1.9477026       0.32779223      -1.2308712      -2.2376378\n0.19652915      0.3304719       -1.7674786      -0.86961496\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.011666816     3.5642662       1.4962418       2.2729902\n2.218835        0.14414681      0.1217519       0.023177093\n0.86428374      1.3279738       0.020032147     0.07265185\n\n(1,2,.,.) =\n1.1828587       4.7988033       0.47652552      1.0078878\n0.016273517     1.2313428       0.13957511      0.030164523\n0.05452104      0.021430366     0.054296546     0.28556487\n\n(2,1,.,.) =\n0.10382515      0.046067268     1.0316595       0.05120041\n1.3722429       0.18810664      1.1434345       0.26239353\n0.038341008     2.131904        6.448767        0.22168371\n\n(2,2,.,.) =\n0.14983514      0.9055635       0.13864164      0.07189517\n3.7935455       0.10744774      1.5150439       5.007023\n0.038623706     0.109211676     3.1239805       0.7562302\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Square\n\nmodel = Sequential()\nmodel.add(Square(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.8708819  0.2698243  0.55854849 0.71699472]\n   [0.66647234 0.72310216 0.8082119  0.66566951]\n   [0.6714764  0.61394108 0.35063125 0.60473593]]\n\n  [[0.37993365 0.64222557 0.96762005 0.18931697]\n   [0.00529722 0.99133455 0.09786619 0.28988077]\n   [0.60052911 0.83712995 0.59847519 0.54361243]]]\n\n\n [[[0.32832672 0.83316023 0.41272485 0.01963383]\n   [0.89593955 0.73433713 0.67529323 0.69711912]\n   [0.81251711 0.56755577 0.31958151 0.09795917]]\n\n  [[0.46465895 0.22818875 0.31505317 0.41912166]\n   [0.87865447 0.3799063  0.091204   0.68144165]\n   [0.88274284 0.70479132 0.32074672 0.71771481]]]]\n\n\n\n\nOutput is\n\n\n[[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01]\n   [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01]\n   [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]]\n\n  [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02]\n   [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02]\n   [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]]\n\n\n [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04]\n   [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01]\n   [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]]\n\n  [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01]\n   [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01]\n   [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]]\n\n\n\n\n\n\nPower\n\n\nApplies an element-wise power operation with scale and shift to the input.\n\n\nf(x) = (shift + scale * x)^power^\n\n\nPower(power, scale = 1, shift = 0, inputShape = null)\n\n\n\n\nPython:\n\n\nPower(power, scale=1, shift=0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npower\n: The exponent\n\n\nscale\n: The scale parameter. Default is 1.\n\n\nshift\n: The shift parameter. Default is 0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Power\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Power[Float](2, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.24691099      0.7588585       0.5785183\n0.10356348      0.2252714       0.3129436\n\n(2,.,.) =\n0.6277785       0.75136995      0.044648796\n0.46396527      0.9793776       0.92727077\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.060965035     0.5758662       0.3346834\n0.010725395     0.050747205     0.0979337\n\n(2,.,.) =\n0.39410582      0.5645568       0.001993515\n0.21526377      0.95918053      0.8598311\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Power\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Power(2, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.5300817 , 0.18128031, 0.19534253],\n        [0.28380639, 0.78365165, 0.6893    ]],\n\n       [[0.05574091, 0.400077  , 0.77051193],\n        [0.033559  , 0.61051396, 0.13970227]]])\n\n\n\n\nOutput is\n\n\narray([[[0.2809866 , 0.03286255, 0.03815871],\n        [0.08054607, 0.61410993, 0.4751345 ]],\n\n       [[0.00310705, 0.16006161, 0.5936886 ],\n        [0.00112621, 0.37272733, 0.01951673]]], dtype=float32)\n\n\n\n\n\n\nAddConstant\n\n\nAdd a (non-learnable) scalar constant to the input.\n\n\nAddConstant(constant, inputShape = null)\n\n\n\n\nPython:\n\n\nAddConstant(constant, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nconstant\n: The scalar constant to be added.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AddConstant[Float](1, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5658301       0.3508225       0.4012322\n0.1941942       0.18934165      0.6909284\n\n(2,.,.) =\n0.5985211       0.5485885       0.778548\n0.16745302      0.10363362      0.92185616\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5658301       1.3508224       1.4012322\n1.1941942       1.1893417       1.6909285\n\n(2,.,.) =\n1.5985211       1.5485885       1.778548\n1.167453        1.1036336       1.9218562\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import AddConstant\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(AddConstant(1, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.71730919, 0.07752598, 0.10448237],\n        [0.52319608, 0.38668494, 0.19588814]],\n\n       [[0.15496092, 0.48405899, 0.41441248],\n        [0.13792111, 0.7523953 , 0.55991187]]])\n\n\n\n\nOutput is\n\n\narray([[[1.7173092, 1.077526 , 1.1044824],\n        [1.5231961, 1.3866849, 1.1958882]],\n\n       [[1.1549609, 1.484059 , 1.4144125],\n        [1.1379211, 1.7523953, 1.5599118]]], dtype=float32)\n\n\n\n\n\n\nNarrow\n\n\nNarrow the input with the number of dimensions not being reduced.\n\n\nThe batch dimension needs to be unchanged.\n\n\nFor example, if input is:\n\n\n[[1 2 3],\n [4 5 6]]\n\n\nNarrow(1, 1, 2) will give output\n\n\n[[2 3],\n [5 6]]\n\n\nNarrow(1, 2, -1) will give output\n\n\n[3,\n 6]\n\n\nNarrow(dim, offset, length = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nNarrow(dim, offset, length=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndim\n: The dimension to narrow. 0-based index. Cannot narrow the batch dimension. \n         -1 means the last dimension of the input.\n\n\noffset\n: Non-negative integer. The start index on the given dimension. 0-based index.\n\n\nlength\n: The length to narrow. Default is 1.\n            Can use a negative length such as -1 in the case where input size is unknown.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.13770224      0.63719153      0.7776689       0.46612367\n0.9026256       0.11982094      0.8282868       0.05095969\n0.889799        0.6386537       0.35438475      0.298043\n\n(1,2,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.63957494      0.1921936       0.7749439       0.19744827\n0.91683346      0.16140814      0.9753973       0.8161283\n0.8481694       0.8802563       0.1233245       0.5732614\n\n(2,2,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Narrow\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Narrow(1, 1, input_shape=(2, 3, 4)))\ninput = np.random.rand(2, 2, 3, 4)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923],\n         [0.28316902, 0.3004414 , 0.40298034, 0.37476436],\n         [0.18825825, 0.38979411, 0.32963262, 0.37783457]],\n\n        [[0.14824117, 0.43532988, 0.57077087, 0.91535978],\n         [0.46375725, 0.90511296, 0.18859044, 0.92820822],\n         [0.13675737, 0.48270908, 0.04260755, 0.97255687]]],\n       [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529],\n         [0.07472717, 0.5715716 , 0.57029986, 0.26475783],\n         [0.56757079, 0.27602746, 0.45799196, 0.74420842]],\n\n        [[0.89048761, 0.08280716, 0.99030481, 0.35956427],\n         [0.70802689, 0.14425212, 0.08320864, 0.82271697],\n         [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ],\n         [0.46375725, 0.905113  , 0.18859044, 0.92820823],\n         [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]],\n\n       [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427],\n         [0.7080269 , 0.14425212, 0.08320864, 0.82271695],\n         [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]],\n      dtype=float32)\n\n\n\n\n\n\nPermute\n\n\nPermutes the dimensions of the input according to a given pattern.\n\n\nUseful for connecting RNNs and convnets together.\n\n\nPermute(dims, inputShape = null)\n\n\n\n\nPython:\n\n\nPermute(dims, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndims\n: Int array. Permutation pattern, does not include the batch dimension.\n          Indexing starts at 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Permute\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.31086245      0.21210302      0.35112163\n\n(1,2,.,.) =\n0.61466074      0.50173014      0.8759959\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.24063066      0.502274        0.9114748\n(2,2,.,.) =\n0.93335986      0.25173688      0.88615775\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.61466074      0.50173014      0.8759959\n\n(1,2,.,.) =\n0.31086245      0.21210302      0.35112163\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.93335986      0.25173688      0.88615775\n(2,2,.,.) =\n0.24063066      0.502274        0.9114748\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Permute\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Permute((2, 1, 3), input_shape=(2, 2, 3)))\ninput = np.random.rand(2, 2, 2, 3)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.14016896, 0.7275626 , 0.79087092],\n         [0.57259566, 0.97387138, 0.70001999]],\n\n        [[0.9232002 , 0.07644555, 0.24705828],\n         [0.17257354, 0.93951155, 0.46183983]]],\n       [[[0.79432476, 0.64299062, 0.33959594],\n         [0.58608318, 0.338014  , 0.92602687]],\n\n        [[0.32638575, 0.69032582, 0.25168083],\n         [0.46813027, 0.95118373, 0.13145026]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.14016896, 0.7275626 , 0.7908709 ],\n         [0.9232002 , 0.07644555, 0.24705827]],\n\n        [[0.57259566, 0.97387135, 0.70002   ],\n         [0.17257354, 0.93951154, 0.46183982]]],\n       [[[0.79432476, 0.64299065, 0.33959594],\n         [0.32638577, 0.6903258 , 0.25168082]],\n        [[0.5860832 , 0.338014  , 0.9260269 ],\n         [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32)\n\n\n\n\n\n\nResizeBilinear\n\n\nResize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout.\n\n\nResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nResizeBilinear(output_height, output_width, align_corner=False, dim_ordering=\nth\n, input_shape=(2, 3, 5, 7), name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputHeight\n: output height\n\n\noutputWidth\n: output width\n\n\nalignCorners\n: align corner or not\n\n\ndimOrdering\n: Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential()\nmodel.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5)))\nval input = Tensor[Float](2, 2, 3, 5).rand()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.6991891       0.007127314     0.73871046      0.95916307      0.9433856\n0.41275907      0.37573513      0.99193203      0.06930728      0.5922364\n0.024281504     0.2592453       0.3898136       0.6635241       0.85888565\n\n(1,2,.,.) =\n0.38028112      0.43709648      0.62538666      0.8468501       0.6445014\n0.45252413      0.48801896      0.59471387      0.013207023     0.3567462\n0.85187584      0.49279585      0.7973665       0.81287366      0.07852263\n\n(2,1,.,.) =\n0.1452374       0.6140467       0.36384684      0.066476084     0.96101314\n0.54862195      0.66091377      0.86857307      0.6844842       0.7368217\n0.25342992      0.71737933      0.12789607      0.21691357      0.7543404\n\n(2,2,.,.) =\n0.79176855      0.1204049       0.58971256      0.115073755     0.10459962\n0.5225398       0.742363        0.7612815       0.9881919       0.13359445\n0.9026869       0.13972941      0.92064524      0.9435532       0.5502235\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of...\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.6991891       0.4948494       0.9539039\n0.21852028      0.5664119       0.48613077\n\n(1,2,.,.) =\n0.38028112      0.56262326      0.7794005\n0.6522  0.6274959       0.34790504\n\n(2,1,.,.) =\n0.1452374       0.4472468       0.36465502\n0.40102595      0.5618719       0.54899293\n\n(2,2,.,.) =\n0.79176855      0.43327665      0.111582376\n0.71261334      0.70765764      0.75788474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import ResizeBilinear\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5)))\ninput = np.random.rand(2, 2, 3, 5, 5)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189],\n         [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155],\n         [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]],\n\n        [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775],\n         [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264],\n         [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]],\n\n\n       [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452],\n         [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ],\n         [0.608378  , 0.10531177, 0.78000335, 0.51679768, 0.65067605]],\n\n        [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255],\n         [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493],\n         [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]])\n\n\n\n\nOutput is\n\n\narray([[[[0.43790358, 0.61913717, 0.2543214 ],\n         [0.6172875 , 0.52657175, 0.3151154 ]],\n\n        [[0.329656  , 0.13861606, 0.20514478],\n         [0.46164483, 0.541788  , 0.5311798 ]]],\n\n\n       [[[0.09462238, 0.57138187, 0.8545758 ],\n         [0.7116966 , 0.5389645 , 0.48184   ]],\n\n        [[0.12074634, 0.6571231 , 0.752728  ],\n         [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)", 
            "title": "Core Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#masking", 
            "text": "Use a mask value to skip timesteps for a sequence.  Scala:  Masking(maskValue = 0.0, inputShape = null)  Python:  Masking(mask_value=0.0, input_shape=None, name=None)  Parameters:   maskValue : Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will be masked (skipped) in all downstream layers.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Masking\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.4539868       1.5623108       -1.4101523\n0.77073747      -0.18994702     2.2574463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.31542103 0.20640659 0.22282763]\n [0.99352167 0.90135718 0.24504717]]  Output is  [[0.31542102 0.2064066  0.22282763]\n [0.9935217  0.9013572  0.24504717]]", 
            "title": "Masking"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#sparsedense", 
            "text": "SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:\nfirstly, SparseDense's input Tensor is a SparseTensor. Secondly, SparseDense doesn't backward\ngradient to next layer in the backpropagation by default, as the gradInput of SparseDense is\nuseless and very big in most cases.  But, considering model like Wide Deep, we provide backwardStart and backwardLength to backward\npart of the gradient to next layer.  The most common input is 2D.  Scala:  SparseDense(outputDim, init =  glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, backwardStart = -1, backwardLength = -1, initWeight = null, initBias = null, initGradWeight = null, initGradBias = null, bias = true, inputShape = null)  Python:  SparseDense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, backward_start=-1, backward_length=-1, init_weight=None, init_bias=None, init_grad_weight=None, init_grad_bias=None, bias=True, input_shape=None, name=None)  Parameters:   outputDim : The size of the output dimension.  init : String representation of the initialization method for the weights of the layer. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. Default is null.  wRegularizer : An instance of [Regularizer], applied to the input weights matrices. Default is null.  bRegularizer : An instance of [Regularizer], applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  backwardStart : Backward start index, counting from 1.  backwardLength : Backward length.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseDense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = SparseDense[Float](outputDim = 5, inputShape = Shape(2, 4))\nlayer.build(Shape(-1, 2, 4))\nval input = Tensor[Float](Array(2, 4)).rand()\ninput.setValue(1, 1, 1f)\ninput.setValue(2, 3, 3f)\nval sparseInput = Tensor.sparse(input)\nval output = layer.forward(sparseInput)  Input is:  input: \n(0, 0) : 1.0\n(0, 1) : 0.2992794\n(0, 2) : 0.11227019\n(0, 3) : 0.722947\n(1, 0) : 0.6147614\n(1, 1) : 0.4288646\n(1, 2) : 3.0\n(1, 3) : 0.7749917\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]  Output is:  output: \n0.053516    0.33429605  0.22587383  -0.8998945  0.24308181  \n0.76745665  -1.614114   0.5381658   -2.2226436  -0.15573677 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseDense\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseDense(output_dim=2, input_shape=(3, 4)))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)  Input is:  JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float  Output is  [[ 1.57136     2.29596   ]\n [ 0.5791738  -1.6598101 ]\n [ 2.331141   -0.84687066]]\n ```\n\n## **SoftShrink**\nApplies the soft shrinkage function element-wise to the input.\n\nWhen you use this layer as the first layer of a model, you need to provide\nthe argument inputShape (a Single Shape, does not include the batch dimension).\n\nRemark: This layer is from Torch and wrapped in Keras style.\n\n\n**Scala:**\n```scala\nSoftShrink(value = 0.5, inputShape = null)  Python:  SoftShrink(value = 0.5, input_shape=None, name=None)  Parameters:   value : value The threshold value. Default is 0.5.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SoftShrink\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SoftShrink[Float](0.6, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.36938807 0.023556225 -1.1655436  -0.34449077\n0.9444338   -0.086538695    -1.0425501  1.364976\n-1.2563878  -0.1842559  0.43428117  1.0756494\n\n(1,2,.,.) =\n-0.19888283 1.251872    0.114836805 -0.6208773\n0.0051822234    -0.8998633  0.06937465  -0.3929931\n-0.1058129  0.6945743   -0.40083578 -0.6252444\n\n(2,1,.,.) =\n-0.9899709  -0.77926594 -0.15497442 -0.15031165\n-0.6028622  0.86623466  -2.1543107  0.41970536\n-0.8215522  0.3014275   -0.32184362 0.14445356\n\n(2,2,.,.) =\n0.74701905  0.10044397  -0.40519297 0.03822808\n0.30726334  0.27862388  1.731753    0.032177072\n-1.3476961  -0.2294767  0.99794704  0.7398458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0 0.0 -0.56554353 0.0\n0.34443378  0.0 -0.44255006 0.764976\n-0.6563878  0.0 0.0 0.47564936\n\n(1,2,.,.) =\n0.0 0.6518719   0.0 -0.020877302\n0.0 -0.29986328 0.0 0.0\n0.0 0.09457427  0.0 -0.025244355\n\n(2,1,.,.) =\n-0.3899709  -0.17926592 0.0 0.0\n-0.0028621554   0.26623464  -1.5543107  0.0\n-0.2215522  0.0 0.0 0.0\n\n(2,2,.,.) =\n0.14701903  0.0 0.0 0.0\n0.0 0.0 1.131753    0.0\n-0.74769604 0.0 0.397947    0.13984579\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SoftShrink\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SoftShrink(0.6, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[ 0.43421006,  0.28394451,  0.15221226,  0.47268966],\n         [ 0.22426224,  0.24855662,  0.790498  ,  0.67767582],\n         [ 0.14879562,  0.56077882,  0.61470262,  0.94875862]],\n\n        [[ 0.72404932,  0.89780875,  0.08456734,  0.01303937],\n         [ 0.25023568,  0.45392504,  0.587254  ,  0.51164461],\n         [ 0.12277567,  0.05571182,  0.17076456,  0.71660884]]],\n\n\n       [[[ 0.06369975,  0.85395557,  0.35752425,  0.606633  ],\n         [ 0.67640252,  0.86861737,  0.18040722,  0.55467108],\n         [ 0.24102058,  0.37580645,  0.81601612,  0.56513788]],\n\n        [[ 0.8461435 ,  0.65668365,  0.17969807,  0.51602926],\n         [ 0.86191073,  0.34245714,  0.62795207,  0.36706125],\n         [ 0.80344028,  0.81056003,  0.80959083,  0.15366483]]]])  Output is  array([[[[ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.19049799,  0.07767582],\n         [ 0.        ,  0.        ,  0.01470262,  0.34875858]],\n\n        [[ 0.12404931,  0.29780871,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.        ,  0.1166088 ]]],\n\n\n       [[[ 0.        ,  0.25395554,  0.        ,  0.00663298],\n         [ 0.07640249,  0.26861733,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.21601611,  0.        ]],\n\n        [[ 0.24614346,  0.05668366,  0.        ,  0.        ],\n         [ 0.26191074,  0.        ,  0.02795208,  0.        ],\n         [ 0.20344025,  0.21056002,  0.20959079,  0.        ]]]], dtype=float32)\n\n ```\n\n---\n## **Reshape**\nReshapes an output to a certain shape.\n\nSupports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).\n\n**Scala:**\n```scala\nReshape(targetShape, inputShape = null)  Python:  Reshape(target_shape, input_shape=None, name=None)  Parameters:   targetShape : The target shape that you desire to have. Batch dimension should be excluded.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Reshape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Reshape\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]  Output is  [[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]", 
            "title": "SparseDense"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#merge", 
            "text": "Used to merge a list of inputs into a single output, following some merge mode.  Merge must have at least two input layers.  Scala:  Merge(layers = null, mode =  sum , concatAxis = -1, inputShape = null)  Python:  Merge(layers=None, mode= sum , concat_axis=-1, input_shape=None, name=None)  Parameters:   layers : A list of layer instances. Must be more than one layer.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.InputLayer\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Merge\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode =  sum )\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -  input1, 2 -  input2)\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Merge, InputLayer\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)  Input is:  [[[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n   [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n   [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n  [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n   [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n   [0.56138318, 0.68165639, 0.10644523, 0.51860127]]],\n\n [[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n   [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n   [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n  [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n   [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n   [0.97294728, 0.68601731, 0.39871792, 0.63172344]]]]  Output is  [[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]", 
            "title": "Merge"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#maxoutdense", 
            "text": "A dense maxout layer that takes the element-wise maximum of linear layers.  This allows the layer to learn a convex, piecewise linear activation function over the inputs.  The input of this layer should be 2D.  Scala:  MaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  MaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of output dimension.  nbFeature : Number of Dense layers to use internally. Integer. Default is 4.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxoutDense\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxoutDense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]  Output is  [[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]", 
            "title": "MaxoutDense"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#squeeze", 
            "text": "Delete the singleton dimension(s). The batch dimension needs to be unchanged.  For example, if input has size (2, 1, 3, 4, 1):  Squeeze(1) will give output size (2, 3, 4, 1),  Squeeze() will give output size (2, 3, 4)  Scala:  Squeeze(dims = null, inputShape = null)  Python:  Squeeze(dim=None, input_shape=None, name=None)  Parameters:   dims : The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Squeeze\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Squeeze[Float](1, inputShape = Shape(1, 1, 32)))\nval input = Tensor[Float](1, 1, 1, 32).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Squeeze\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Squeeze(1, input_shape=(1, 1, 32)))\ninput = np.random.random([1, 1, 1, 32])\noutput = model.forward(input)  Input is:  [[[[0.20585343, 0.47011701, 0.14553177, 0.93915599, 0.57234281,\n    0.91631229, 0.32244256, 0.94243351, 0.86595631, 0.73916763,\n    0.35898731, 0.65208275, 0.07935983, 0.89313423, 0.68601269,\n    0.48919672, 0.28406399, 0.20962799, 0.88071757, 0.45501821,\n    0.60931183, 0.46709718, 0.14218838, 0.42517758, 0.9149958 ,\n    0.0843243 , 0.27302307, 0.75281922, 0.3688931 , 0.86913729,\n    0.89774196, 0.77838838]]]]  Output is  [[[0.20585343, 0.470117  , 0.14553176, 0.939156  , 0.5723428 ,\n   0.9163123 , 0.32244256, 0.94243354, 0.8659563 , 0.73916763,\n   0.3589873 , 0.65208274, 0.07935983, 0.89313424, 0.6860127 ,\n   0.48919672, 0.284064  , 0.20962799, 0.8807176 , 0.45501822,\n   0.6093118 , 0.46709716, 0.14218839, 0.42517757, 0.9149958 ,\n   0.0843243 , 0.27302307, 0.75281924, 0.36889312, 0.8691373 ,\n   0.897742  , 0.7783884 ]]]", 
            "title": "Squeeze"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#binarythreshold", 
            "text": "Threshold the input.  If an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1.  Scala:  BinaryThreshold(value = 1e-6, inputShape = null)  Python:  BinaryThreshold(value=1e-6, input_shape=None, name=None)  Parameters:   value : The threshold value to compare with. Default is 1e-6.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.BinaryThreshold\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BinaryThreshold[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1907398      -0.18995096     -2.0344417      -1.3789974\n-1.8801064      -0.74757665     -0.4339697      0.0058485097\n0.7012256       -0.6363152      2.0156987       -0.5512639\n\n(1,2,.,.) =\n-0.5251603      0.082127444     0.29550993      1.6357868\n-1.3828015      -0.11842779     0.3316966       -0.14360528\n0.21216457      -0.117370956    -0.12934707     -0.35854268\n\n(2,1,.,.) =\n-0.9071151      -2.8566089      -0.4796377      -0.915065\n-0.8439908      -0.25404388     -0.39926198     -0.15191565\n-1.0496653      -0.403675       -1.3591816      0.5311797\n\n(2,2,.,.) =\n0.53509855      -0.08892822     1.2196561       -0.62759316\n-0.47476718     -0.43337926     -0.10406987     1.4035174\n-1.7120812      1.1328355       0.9219375       1.3813454\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n1.0     0.0     1.0     0.0\n\n(1,2,.,.) =\n0.0     1.0     1.0     1.0\n0.0     0.0     1.0     0.0\n1.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     1.0\n\n(2,2,.,.) =\n1.0     0.0     1.0     0.0\n0.0     0.0     0.0     1.0\n0.0     1.0     1.0     1.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import BinaryThreshold\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(BinaryThreshold(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[0.30421481, 0.47800487, 0.54249411, 0.90109767],\n         [0.72650405, 0.53096719, 0.66346109, 0.0589329 ],\n         [0.12994731, 0.92181174, 0.43129874, 0.97306968]],\n\n        [[0.3031087 , 0.20339982, 0.69034712, 0.40191   ],\n         [0.57517034, 0.30159448, 0.4801747 , 0.75175084],\n         [0.8599362 , 0.93523811, 0.34768628, 0.10840162]]],\n\n\n       [[[0.46102959, 0.33029002, 0.69340103, 0.32885719],\n         [0.84405147, 0.03421879, 0.68242578, 0.03560338],\n         [0.12244515, 0.3610654 , 0.01312785, 0.84485178]],\n\n        [[0.73472287, 0.75707757, 0.77070527, 0.40863145],\n         [0.01137898, 0.82896826, 0.1498069 , 0.22309423],\n         [0.92737483, 0.36217222, 0.06679799, 0.33304362]]]])  Output is  array([[[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]],\n\n\n       [[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]]], dtype=float32)", 
            "title": "BinaryThreshold"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#sqrt", 
            "text": "Applies an element-wise square root operation to the input.  Scala:  Sqrt(inputShape = null)  Python:  Sqrt(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Sqrt\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Sqrt[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6950394       0.5234307       1.7375475\n0.25833175      0.02685826      -0.6046901\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8336902       0.7234851       1.3181607\n0.50826347      0.16388491      NaN\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Sqrt\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Sqrt(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.2484558 , 0.65280218, 0.35286984],\n [0.19616094, 0.30966802, 0.82148169]]  Output is  [[0.4984534 , 0.80796176, 0.5940285 ],\n [0.4429006 , 0.55647826, 0.9063563 ]]", 
            "title": "Sqrt"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#mul", 
            "text": "Multiply a single scalar factor to the incoming data  Scala:  Mul(inputShape = null)  Python:  Mul(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Mul\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Mul[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2316265  -2.008802 -1.3908259  -0.61135375\n-0.48992255 0.1786112 0.18872596  0.49621895\n-0.6931602  -0.919745 -0.09019699 -0.41218707\n\n(2,.,.) =\n-0.3135355  -0.4385771  -0.3317269  1.0412029\n-0.8859662  0.17758773  -0.73779273 -0.4445366\n0.3921595 1.6923207 0.014470488 0.4044164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.59036994 -0.9629025  -0.6666808  -0.29304734\n-0.2348403  0.0856158 0.09046422  0.23785843\n-0.33226058 -0.44087213 -0.043235175  -0.19757845\n\n(2,.,.) =\n-0.15029064 -0.21022828 -0.15901053 0.49909195\n-0.42468053 0.0851252 -0.3536548  -0.21308492\n0.18797839  0.81119984  0.006936308 0.19385365\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Mul\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Mul(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.22607292,  0.59806062,  0.19428923,  0.22928606],\n        [ 0.13804536,  0.1615547 ,  0.52824658,  0.52794904],\n        [ 0.4049169 ,  0.94109084,  0.58158453,  0.78368633]],\n\n       [[ 0.86233305,  0.47995805,  0.80430949,  0.9931171 ],\n        [ 0.35179631,  0.33615276,  0.87756877,  0.73560288],\n        [ 0.29775703,  0.11404466,  0.77695536,  0.97580018]]])  Output is  array([[[-0.22486402, -0.59486258, -0.1932503 , -0.22805998],\n        [-0.13730718, -0.1606908 , -0.52542186, -0.52512592],\n        [-0.40275168, -0.93605846, -0.57847458, -0.77949566]],\n\n       [[-0.85772187, -0.47739154, -0.80000854, -0.9878065 ],\n        [-0.34991512, -0.33435524, -0.87287611, -0.73166931],\n        [-0.29616481, -0.11343482, -0.77280068, -0.97058219]]], dtype=float32)", 
            "title": "Mul"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#mulconstant", 
            "text": "Multiply the input by a (non-learnable) scalar constant.  Scala:  MulConstant(constant, inputShape = null)  Python:  MulConstant(constant, input_shape=None, name=None)  Parameters:   constant : The scalar constant to be multiplied.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MulConstant\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MulConstant[Float](2.2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.16873977     1.0812985       1.0942211       -0.67091423\n1.0086882       0.5915831       0.26184535      -1.361431\n1.5616825       -0.037591368    1.2794676       1.0692137\n\n(2,.,.) =\n0.29868057      -0.23266982     -0.7679556      -2.209848\n-0.13954644     -0.1368473      -0.54510623     1.8397199\n-0.58691734     -0.56410027     -1.5567777      0.050648995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.3712275      2.3788567       2.4072864       -1.4760114\n2.219114        1.3014828       0.57605976      -2.9951482\n3.4357016       -0.08270101     2.8148286       2.3522704\n\n(2,.,.) =\n0.6570973       -0.5118736      -1.6895024      -4.8616657\n-0.3070022      -0.30106407     -1.1992338      4.047384\n-1.2912182      -1.2410206      -3.424911       0.11142779\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MulConstant\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MulConstant(2.2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.39874191, 0.66634984, 0.23907766, 0.31587494],\n  [0.78842014, 0.93057835, 0.80739529, 0.71541279],\n  [0.2231424 , 0.3372844 , 0.94678072, 0.52928034]],\n\n [[0.60142458, 0.41221671, 0.00890549, 0.32069845],\n  [0.51122554, 0.76280426, 0.87579418, 0.17182832],\n  [0.54133184, 0.19814384, 0.92529327, 0.5616615 ]]]  Output is  [[[0.8772322 , 1.4659697 , 0.5259709 , 0.6949249 ],\n  [1.7345244 , 2.0472724 , 1.7762697 , 1.5739082 ],\n  [0.4909133 , 0.7420257 , 2.0829177 , 1.1644168 ]],\n\n [[1.3231341 , 0.9068768 , 0.01959208, 0.7055366 ],\n  [1.1246961 , 1.6781695 , 1.9267472 , 0.37802234],\n  [1.19093   , 0.43591645, 2.0356452 , 1.2356553 ]]]", 
            "title": "MulConstant"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#scale", 
            "text": "Scale is the combination of CMul and CAdd.  Computes the element-wise product of the input and weight, with the shape of the weight \"expand\" to match the shape of the input.  Similarly, perform an expanded bias and perform an element-wise add.  Scala:  Scale(size, inputShape = null)  Python:  Scale(size, input_shape=None, name=None)  Parameters:   size : Size of the weight and bias.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Scale\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nvar array = Array(1, 2)\nmodel.add(Scale[Float](array, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006399727    -0.06412822     -0.2334789\n0.31029955      1.6557469       1.9614618\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.09936619      0.57585865      0.20324506\n0.38537437      -0.8598822      -1.0186496\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Scale\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Scale((2, 1), input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.7242994 , 0.77888884, 0.71470432],\n [0.03058471, 0.00602764, 0.57513629]]  Output is  [[1.0946966 , 1.1255064 , 1.0892813 ],\n [0.58151895, 0.5909191 , 0.37307182]]", 
            "title": "Scale"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#log", 
            "text": "Applies a log transformation to the input.  Scala:  Log(inputShape = null)  Python:  Log(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Log\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Log[Float](inputShape = Shape(2, 4, 4)))\nval input = Tensor[Float](1, 2, 4, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.38405678      -0.5502389      -0.383079       -0.988537\n-0.6294056      -0.7838047      0.8747865       -1.0659786\n-2.2445498      -0.5488076      -0.42898977     0.6916364\n1.6542299       -0.9966279      -0.38244298     1.6954672\n\n(1,2,.,.) =\n0.43478605      -0.6678534      1.9530942       -0.5209587\n0.12899925      0.20572199      2.0359943       0.55223215\n0.65247816      0.8792108       -0.38860792     0.48663738\n-1.0084358      0.31141177      0.69208467      0.48385203\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.95696485     NaN     NaN     NaN\nNaN     NaN     -0.13377543     NaN\nNaN     NaN     NaN     -0.36869493\n0.5033356       NaN     NaN     0.5279584\n\n(1,2,.,.) =\n-0.83290124     NaN     0.6694149       NaN\n-2.0479486      -1.5812296      0.7109843       -0.5937868\n-0.4269776      -0.12873057     NaN     -0.720236\nNaN     -1.1666392      -0.36804697     -0.72597617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Log\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Log(input_shape=(2, 4, 4)))\ninput = np.random.random([1, 2, 4, 4])\noutput = model.forward(input)  Input is:  [[[[0.90127539, 0.9861594 , 0.04722941, 0.63719453],\n   [0.46529477, 0.81511804, 0.24435558, 0.45003562],\n   [0.15170845, 0.35157662, 0.0925214 , 0.63852947],\n   [0.27817508, 0.42572846, 0.44363004, 0.03536394]],\n\n  [[0.65027784, 0.00429838, 0.07434429, 0.18653305],\n   [0.19659183, 0.66647529, 0.77821197, 0.65894478],\n   [0.28212032, 0.52307663, 0.09589939, 0.71547588],\n   [0.84344158, 0.25291738, 0.52145649, 0.82982377]]]]  Output is  [[[[-0.10394441, -0.01393729, -3.0527387 , -0.45068032],\n   [-0.76508415, -0.20442237, -1.4091308 , -0.79842854],\n   [-1.8857948 , -1.0453277 , -2.3803153 , -0.44858742],\n   [-1.2795045 , -0.85395354, -0.8127643 , -3.3420627 ]],\n\n  [[-0.43035555, -5.4495163 , -2.5990484 , -1.6791469 ],\n   [-1.6266255 , -0.4057522 , -0.25075635, -0.41711554],\n   [-1.2654216 , -0.64802724, -2.3444557 , -0.33480743],\n   [-0.1702646 , -1.3746924 , -0.6511295 , -0.1865419 ]]]]", 
            "title": "Log"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#identity", 
            "text": "Identity just return the input to output.  It's useful in same parallel container to get an origin input.  Scala:  Identity(inputShape = null)  Python:  Identity(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Identity\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Identity[Float](inputShape = Shape(4, 4)))\nval input = Tensor[Float](3, 4, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.9601166       -0.86010313     0.0023731247    -0.81219757\n1.1469674       -1.5375912      -1.5348053      -0.34829113\n-1.236773       -0.7183283      -0.89256984     0.8605067\n0.7937664       0.52992857      -1.6157389      0.36134166\n\n(2,.,.) =\n-0.44434744     -0.23848957     -0.01632014     -0.58109635\n-0.19856784     -2.3421717      -0.5868049      -0.76775354\n0.80254126      1.78778 -1.1835604      1.4489703\n0.8731402       0.8906672       0.2800079       -0.6715317\n\n(3,.,.) =\n1.4093032       2.358169        -1.4620789      1.1904576\n-0.18263042     -0.31869793     2.01061 1.2159953\n-0.5801479      1.2949371       -0.7510707      -1.0707517\n0.30815956      -1.161963       -0.26964024     -0.4759499\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Identity\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Identity(input_shape=(4, 4)))\ninput = np.random.random([3, 4, 4])\noutput = model.forward(input)  Input is:  [[[0.36751123, 0.92287101, 0.73894405, 0.33699379],\n  [0.69405782, 0.9653215 , 0.2617223 , 0.68205229],\n  [0.71455325, 0.99419333, 0.90886495, 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921154, 0.26803146]],\n\n  [[0.35898357, 0.72067882, 0.13236563, 0.71935521],\n   [0.30865626, 0.71098844, 0.86718946, 0.12531168],\n   [0.84916882, 0.84221518, 0.52186664, 0.87239729],\n   [0.50637899, 0.10890469, 0.86832705, 0.93581179]],\n\n  [[0.19640105, 0.09341008, 0.12043328, 0.09261859],\n   [0.66019486, 0.07251262, 0.80929761, 0.39094486],\n   [0.63027391, 0.39537796, 0.55578905, 0.53933265],\n   [0.13885559, 0.56695373, 0.17036027, 0.4577097 ]]]  Output is  [[[0.36751124, 0.922871  , 0.73894405, 0.33699378],\n  [0.6940578 , 0.9653215 , 0.2617223 , 0.6820523 ],\n  [0.71455324, 0.9941933 , 0.908865  , 0.10232991],\n  [0.1644055 , 0.30013138, 0.98921156, 0.26803148]],\n\n [[0.35898358, 0.7206788 , 0.13236563, 0.7193552 ],\n  [0.30865628, 0.71098846, 0.86718947, 0.12531169],\n  [0.84916884, 0.8422152 , 0.5218666 , 0.8723973 ],\n  [0.506379  , 0.10890469, 0.868327  , 0.9358118 ]],\n\n [[0.19640104, 0.09341008, 0.12043328, 0.09261858],\n  [0.6601949 , 0.07251262, 0.8092976 , 0.39094487],\n  [0.63027394, 0.39537796, 0.55578905, 0.5393326 ],\n  [0.13885559, 0.5669537 , 0.17036027, 0.4577097 ]]]", 
            "title": "Identity"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#select", 
            "text": "Select an index of the input in the given dim and return the subset part.  The batch dimension needs to be unchanged.  For example, if input is:  [[1, 2, 3], \n [4, 5, 6]]  Select(1, 1) will give output [2 5]  Select(1, -1) will give output [3 6]  Scala:  Select(dim, index, inputShape = null)  Python:  Select(dim, index, input_shape=None, name=None)  Parameters:   dim : The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input.  index : The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Select\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Select[Float](1, 2, inputShape = Shape(3, 1, 3)))\nval input = Tensor[Float](1, 3, 1, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.67646945     -0.5485965      -0.11103154\n(1,2,.,.) =\n-0.13488655     0.43843046      -0.04482145\n(1,3,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.18094881     0.19431554      -1.7624844\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3]  Python example:  from zoo.pipeline.api.keras.layers import Select\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Select(1, 2, input_shape=(3, 1, 3)))\ninput = np.random.random([1, 3, 1, 3])\noutput = model.forward(input)  Input is:  array([[[[0.53306099, 0.95147881, 0.15222129]],\n        [[0.89604861, 0.90160974, 0.5230576 ]],\n        [[0.70779386, 0.14438568, 0.37601195]]]])  Output is:  array([[[0.7077939 , 0.14438568, 0.37601194]]], dtype=float32)", 
            "title": "Select"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#dense", 
            "text": "A densely-connected NN layer.  The most common input is 2D.  Scala:  Dense(outputDim, init =  glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Dense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of the output dimension.  init : Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as 'glorot_uniform' or 'normal', etc. for simple init methods in the factory method.  activation : Activation function to use. Default is null.You can also pass in corresponding string representations such as 'relu'or 'sigmoid', etc. for simple activations in the factory method.  wRegularizer : An instance of  Regularizer , applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dense\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense[Float](5, activation =  relu , inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4289935       -1.7659454      -0.08306135     -1.0153456\n1.0191492       0.37392816      1.3076705       -0.19495767\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5421522       0.49008092      0.0     0.0     0.0\n0.07940009      0.0     0.12953377      0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Dense\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(5, activation= relu , input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)  Input is:  array([[0.64593485, 0.67393322, 0.72505368, 0.04654095],\n       [0.19430753, 0.47800889, 0.00743648, 0.6412403 ]])  Output is  array([[0.        , 0.        , 1.2698183 , 0.        , 0.10656227],\n       [0.        , 0.        , 0.6236721 , 0.00299606, 0.29664695]],\n      dtype=float32)", 
            "title": "Dense"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#negative", 
            "text": "Computes the negative value of each element of the input.  Scala:  Negative(inputShape = null)  Python:  Negative(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Negative\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Negative[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.031705        -0.5723963      1.998631\n-0.32908052     2.4069138       -2.4111257\n(2,.,.) =\n0.5355049       -1.4404331      -0.38116863\n-0.45641592     -1.1485358      0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.031705       0.5723963       -1.998631\n0.32908052      -2.4069138      2.4111257\n(2,.,.) =\n-0.5355049      1.4404331       0.38116863\n0.45641592      1.1485358       -0.94766915\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Negative\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Negative(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.39261261, 0.03164615, 0.32179116],\n        [0.11969367, 0.61610712, 0.42573733]],\n       [[0.36794656, 0.90912174, 0.540356  ],\n        [0.42667627, 0.04154093, 0.84692964]]])  Output is  array([[[-0.3926126 , -0.03164615, -0.32179114],\n        [-0.11969367, -0.6161071 , -0.42573732]],\n       [[-0.36794657, -0.90912175, -0.540356  ],\n        [-0.42667627, -0.04154094, -0.84692967]]], dtype=float32)", 
            "title": "Negative"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#cadd", 
            "text": "This layer has a bias with given size.  The bias will be added element-wise to the input.  If the element number of the bias matches the input, a simple element-wise addition will be done.  Or the bias will be expanded to the same size of the input.  The expand means repeat on unmatched singleton dimension (if some unmatched dimension isn't a singleton dimension, an error will be raised).  Scala:  CAdd(size, bRegularizer = null, inputShape = null)  Python:  CAdd(size, b_regularizer=None, input_shape=None, name=None)  Parameters:   size : the size of the bias  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.CAdd\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(CAdd[Float](Array(2, 3), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.2183351       0.32434112      0.89350265\n0.3348259       0.78677046      0.24054797\n(2,.,.) =\n0.9945844       0.72363794      0.7737936\n0.05522544      0.3517818       0.7417069\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1358028       0.6956667       1.0837181\n0.6767027       0.7955346       0.5063505\n(2,.,.) =\n0.9120521       1.0949634       0.96400905\n0.3971022       0.36054593      1.0075095\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import CAdd\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(CAdd([2, 1], input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.4122004 , 0.73289359, 0.11500016],\n        [0.26974491, 0.32166632, 0.91408442]],\n       [[0.66824327, 0.80271314, 0.75981145],\n        [0.39271431, 0.07312566, 0.4966805 ]]])  Output is  array([[[ 0.06560206,  0.38629526, -0.23159817],\n        [ 0.44287407,  0.4947955 ,  1.0872136 ]],\n       [[ 0.32164496,  0.45611483,  0.41321313],\n        [ 0.56584346,  0.24625483,  0.6698097 ]]], dtype=float32)", 
            "title": "CAdd"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#repeatvector", 
            "text": "Repeats the input n times.  The input of this layer should be 2D, i.e. (num_samples, features).\nThe output of thi layer should be 3D, i.e. (num_samples, n, features).  Scala:  RepeatVector(n, inputShape = null)  Python:  RepeatVector(n, input_shape=None, name=None)  Parameters:   n : Repetition factor. Integer.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.RepeatVector\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector[Float](4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.31839952 -0.3495366  0.542486\n-0.54981124 -0.8428188  0.8225184\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n-0.31839952 -0.3495366  0.542486\n\n(2,.,.) =\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n-0.54981124 -0.8428188  0.8225184\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import RepeatVector\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  array([[ 0.90715922,  0.54594769,  0.53952404],\n       [ 0.08989831,  0.07265549,  0.45830114]])  Output is  array([[[ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402],\n        [ 0.90715921,  0.54594767,  0.53952402]],\n\n       [[ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116],\n        [ 0.08989831,  0.07265549,  0.45830116]]], dtype=float32)", 
            "title": "RepeatVector"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#gaussiansampler", 
            "text": "Takes {mean, log_variance} as input and samples from the Gaussian distribution.  Scala:  GaussianSampler(inputShape = null)  Python:  GaussianSampler(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianSampler\nimport com.intel.analytics.bigdl.utils.{Shape, MultiShape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval shape1 = Shape(2, 3)\nval shape2 = Shape(2, 3)\nmodel.add(GaussianSampler[Float](inputShape = MultiShape(List(shape1,shape2))))\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -  input1, 2 -  input2)\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.utils.Table =\n {\n        2: (1,.,.) =\n           0.9996127    0.8964211       0.7424038\n           0.40628982   0.37035564      0.20108517\n\n           (2,.,.) =\n           0.6974727    0.60202897      0.1535999\n           0.012422224  0.5993025       0.96206\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n        1: (1,.,.) =\n           0.21060324   0.576583        0.21633287\n           0.1484059    0.2730577       0.25317845\n\n           (2,.,.) =\n           0.58513683   0.58095694      0.18811373\n           0.7029449    0.41235915      0.44636542\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5258198       1.9536011       -1.8591263\n-1.0618867      -0.751225       0.35412917\n\n(2,.,.) =\n1.3334517       -0.60312974     0.7324476\n0.09502721      0.8094909       0.44807082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GaussianSampler\n\nmodel = Sequential()\nmodel.add(GaussianSampler(input_shape=[(3,),(3,)]))\ninput1 = np.random.random([2, 3])\ninput2 = np.random.random([2, 3])\ninput = [input1, input2]\noutput = model.forward(input)  Input is:  [[[0.79941342, 0.87462822, 0.9516901 ],\n  [0.20111287, 0.54634077, 0.83614511]], \n\n [[0.31886989, 0.22829382, 0.84355419],\n  [0.51186641, 0.28043938, 0.29440057]]]  Output is  [[ 0.71405387  2.2944303  -0.41778684]\n [ 0.84234     2.3337283  -0.18952972]]", 
            "title": "GaussianSampler"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#exp", 
            "text": "Applies element-wise exp to the input.  When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).  Scala:  Exp(inputShape = null)  Python:  Exp(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Exp\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Exp[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.5841372      -0.13795324     -2.144475       0.09272669\n1.055668        -1.2310301      1.2145554       -0.6073714\n0.9296467       0.2923885       1.3364213       0.1652137\n\n(1,2,.,.) =\n0.2099718       -0.3856573      -0.92586        -0.5317779\n0.6618383       -0.9677452      -1.5014665      -0.35464883\n2.045924        -0.317644       -1.812726       0.95438373\n\n(2,1,.,.) =\n-0.4536791      -0.34785584     1.6424289       -0.07981159\n-0.8022624      -0.4211059      0.3461831       1.9598864\n-0.84695745     -0.6115283      0.7729755       2.3077402\n\n(2,2,.,.) =\n-0.08438411     -0.908458       0.6688936       -0.7292123\n-0.26337254     0.55425745      -0.14925817     -0.010179609\n-0.62562865     -1.0517743      -0.23839666     -1.144982\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.20512469      0.8711394       0.11712951      1.0971619\n2.8738942       0.29199165      3.3687959       0.544781\n2.533614        1.3396233       3.8054006       1.1796452\n\n(1,2,.,.) =\n1.2336433       0.6800035       0.39619055      0.5875594\n1.9383523       0.37993878      0.22280318      0.7014197\n7.7363033       0.7278619       0.16320862      2.5970695\n\n(2,1,.,.) =\n0.63528657      0.70620066      5.167706        0.92329025\n0.44831353      0.6563206       1.4136615       7.0985208\n0.42871734      0.5425211       2.1662023       10.051684\n\n(2,2,.,.) =\n0.9190782       0.4031454       1.9520763       0.48228875\n0.76845556      1.740648        0.8613467       0.98987204\n0.53492504      0.34931743      0.7878901       0.31822965\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Exp\n\nmodel = Sequential()\nmodel.add(Exp(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.93104587 0.94000338 0.84870765 0.98645553]\n   [0.83708846 0.33375541 0.50119834 0.24879265]\n   [0.51966475 0.84514791 0.15496452 0.61538968]]\n\n  [[0.57250337 0.42520832 0.94850757 0.54317573]\n   [0.64228691 0.9904079  0.01008592 0.51365217]\n   [0.78640595 0.7717037  0.51277595 0.24245034]]]\n\n\n [[[0.82184752 0.92537331 0.20632728 0.47539445]\n   [0.44604637 0.1507692  0.5437313  0.2074501 ]\n   [0.93661363 0.93962609 0.29230559 0.74850958]]\n\n  [[0.11659768 0.76177132 0.33194573 0.20695088]\n   [0.49636212 0.85987328 0.49767861 0.96774006]\n   [0.67669121 0.15542122 0.69981032 0.3349874 ]]]]  Output is  [[[[2.5371614 2.5599902 2.3366253 2.6817122]\n   [2.3096325 1.3962016 1.6506982 1.2824761]\n   [1.6814638 2.3283222 1.1676165 1.8503776]]\n\n  [[1.7726992 1.5299091 2.5818534 1.721465 ]\n   [1.9008229 2.6923325 1.010137  1.6713842]\n   [2.1954916 2.163449  1.6699204 1.2743679]]]\n\n\n [[[2.2746985 2.52281   1.2291554 1.6086487]\n   [1.5621239 1.1627283 1.7224218 1.2305363]\n   [2.551327  2.5590243 1.3395122 2.1138473]]\n\n  [[1.1236672 2.1420672 1.3936772 1.2299222]\n   [1.6427343 2.3628614 1.6448984 2.6319895]\n   [1.9673574 1.16815   2.0133708 1.3979228]]]]", 
            "title": "Exp"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#square", 
            "text": "Applies an element-wise square operation to the input.  When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).  Scala:  Square(inputShape = null)  Python:  Square(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  MultiShape  object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Square\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Square[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.108013034    1.8879265       1.2232096       -1.5076439\n1.4895755       -0.37966672     -0.34892964     0.15224025\n-0.9296686      -1.1523775      0.14153497      -0.26954007\n\n(1,2,.,.) =\n-1.0875931      2.190617        -0.6903083      1.0039362\n-0.1275677      -1.1096588      0.37359753      -0.17367937\n0.23349741      0.14639114      -0.2330162      0.5343827\n\n(2,1,.,.) =\n0.3222191       0.21463287      -1.0157064      -0.22627507\n1.1714277       0.43371263      1.069315        0.5122436\n0.1958086       -1.4601041      2.5394423       -0.470833\n\n(2,2,.,.) =\n-0.38708544     -0.951611       -0.37234613     0.26813275\n1.9477026       0.32779223      -1.2308712      -2.2376378\n0.19652915      0.3304719       -1.7674786      -0.86961496\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.011666816     3.5642662       1.4962418       2.2729902\n2.218835        0.14414681      0.1217519       0.023177093\n0.86428374      1.3279738       0.020032147     0.07265185\n\n(1,2,.,.) =\n1.1828587       4.7988033       0.47652552      1.0078878\n0.016273517     1.2313428       0.13957511      0.030164523\n0.05452104      0.021430366     0.054296546     0.28556487\n\n(2,1,.,.) =\n0.10382515      0.046067268     1.0316595       0.05120041\n1.3722429       0.18810664      1.1434345       0.26239353\n0.038341008     2.131904        6.448767        0.22168371\n\n(2,2,.,.) =\n0.14983514      0.9055635       0.13864164      0.07189517\n3.7935455       0.10744774      1.5150439       5.007023\n0.038623706     0.109211676     3.1239805       0.7562302\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import Square\n\nmodel = Sequential()\nmodel.add(Square(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.8708819  0.2698243  0.55854849 0.71699472]\n   [0.66647234 0.72310216 0.8082119  0.66566951]\n   [0.6714764  0.61394108 0.35063125 0.60473593]]\n\n  [[0.37993365 0.64222557 0.96762005 0.18931697]\n   [0.00529722 0.99133455 0.09786619 0.28988077]\n   [0.60052911 0.83712995 0.59847519 0.54361243]]]\n\n\n [[[0.32832672 0.83316023 0.41272485 0.01963383]\n   [0.89593955 0.73433713 0.67529323 0.69711912]\n   [0.81251711 0.56755577 0.31958151 0.09795917]]\n\n  [[0.46465895 0.22818875 0.31505317 0.41912166]\n   [0.87865447 0.3799063  0.091204   0.68144165]\n   [0.88274284 0.70479132 0.32074672 0.71771481]]]]  Output is  [[[[7.5843531e-01 7.2805151e-02 3.1197643e-01 5.1408142e-01]\n   [4.4418535e-01 5.2287674e-01 6.5320653e-01 4.4311589e-01]\n   [4.5088059e-01 3.7692365e-01 1.2294226e-01 3.6570552e-01]]\n\n  [[1.4434958e-01 4.1245368e-01 9.3628860e-01 3.5840917e-02]\n   [2.8060573e-05 9.8274422e-01 9.5777912e-03 8.4030852e-02]\n   [3.6063525e-01 7.0078653e-01 3.5817260e-01 2.9551446e-01]]]\n\n\n [[[1.0779844e-01 6.9415593e-01 1.7034180e-01 3.8548734e-04]\n   [8.0270761e-01 5.3925103e-01 4.5602092e-01 4.8597506e-01]\n   [6.6018403e-01 3.2211956e-01 1.0213234e-01 9.5959986e-03]]\n\n  [[2.1590793e-01 5.2070107e-02 9.9258497e-02 1.7566296e-01]\n   [7.7203369e-01 1.4432879e-01 8.3181690e-03 4.6436274e-01]\n   [7.7923489e-01 4.9673077e-01 1.0287846e-01 5.1511449e-01]]]]", 
            "title": "Square"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#power", 
            "text": "Applies an element-wise power operation with scale and shift to the input.  f(x) = (shift + scale * x)^power^  Power(power, scale = 1, shift = 0, inputShape = null)  Python:  Power(power, scale=1, shift=0, input_shape=None, name=None)  Parameters:   power : The exponent  scale : The scale parameter. Default is 1.  shift : The shift parameter. Default is 0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Power\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Power[Float](2, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.24691099      0.7588585       0.5785183\n0.10356348      0.2252714       0.3129436\n\n(2,.,.) =\n0.6277785       0.75136995      0.044648796\n0.46396527      0.9793776       0.92727077\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.060965035     0.5758662       0.3346834\n0.010725395     0.050747205     0.0979337\n\n(2,.,.) =\n0.39410582      0.5645568       0.001993515\n0.21526377      0.95918053      0.8598311\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Power\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Power(2, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.5300817 , 0.18128031, 0.19534253],\n        [0.28380639, 0.78365165, 0.6893    ]],\n\n       [[0.05574091, 0.400077  , 0.77051193],\n        [0.033559  , 0.61051396, 0.13970227]]])  Output is  array([[[0.2809866 , 0.03286255, 0.03815871],\n        [0.08054607, 0.61410993, 0.4751345 ]],\n\n       [[0.00310705, 0.16006161, 0.5936886 ],\n        [0.00112621, 0.37272733, 0.01951673]]], dtype=float32)", 
            "title": "Power"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#addconstant", 
            "text": "Add a (non-learnable) scalar constant to the input.  AddConstant(constant, inputShape = null)  Python:  AddConstant(constant, input_shape=None, name=None)  Parameters:   constant : The scalar constant to be added.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AddConstant\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AddConstant[Float](1, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5658301       0.3508225       0.4012322\n0.1941942       0.18934165      0.6909284\n\n(2,.,.) =\n0.5985211       0.5485885       0.778548\n0.16745302      0.10363362      0.92185616\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.5658301       1.3508224       1.4012322\n1.1941942       1.1893417       1.6909285\n\n(2,.,.) =\n1.5985211       1.5485885       1.778548\n1.167453        1.1036336       1.9218562\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import AddConstant\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(AddConstant(1, input_shape=(2, 3)))\ninput = np.random.rand(2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[0.71730919, 0.07752598, 0.10448237],\n        [0.52319608, 0.38668494, 0.19588814]],\n\n       [[0.15496092, 0.48405899, 0.41441248],\n        [0.13792111, 0.7523953 , 0.55991187]]])  Output is  array([[[1.7173092, 1.077526 , 1.1044824],\n        [1.5231961, 1.3866849, 1.1958882]],\n\n       [[1.1549609, 1.484059 , 1.4144125],\n        [1.1379211, 1.7523953, 1.5599118]]], dtype=float32)", 
            "title": "AddConstant"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#narrow", 
            "text": "Narrow the input with the number of dimensions not being reduced.  The batch dimension needs to be unchanged.  For example, if input is:  [[1 2 3],\n [4 5 6]]  Narrow(1, 1, 2) will give output  [[2 3],\n [5 6]]  Narrow(1, 2, -1) will give output  [3,\n 6]  Narrow(dim, offset, length = 1, inputShape = null)  Python:  Narrow(dim, offset, length=1, input_shape=None, name=None)  Parameters:   dim : The dimension to narrow. 0-based index. Cannot narrow the batch dimension. \n         -1 means the last dimension of the input.  offset : Non-negative integer. The start index on the given dimension. 0-based index.  length : The length to narrow. Default is 1.\n            Can use a negative length such as -1 in the case where input size is unknown.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Narrow\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Narrow[Float](1, 1, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.13770224      0.63719153      0.7776689       0.46612367\n0.9026256       0.11982094      0.8282868       0.05095969\n0.889799        0.6386537       0.35438475      0.298043\n\n(1,2,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.63957494      0.1921936       0.7749439       0.19744827\n0.91683346      0.16140814      0.9753973       0.8161283\n0.8481694       0.8802563       0.1233245       0.5732614\n\n(2,2,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.5029727       0.20103335      0.20150806      0.06437344\n0.2255908       0.5388977       0.59737855      0.5210477\n0.4055072       0.11848069      0.7118382       0.9796308\n\n(2,1,.,.) =\n0.275001        0.35905758      0.15939762      0.09233412\n0.16610192      0.032060683     0.37298614      0.48936844\n0.031097537     0.82767457      0.10246291      0.9951448\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4]  Python example:  from zoo.pipeline.api.keras.layers import Narrow\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Narrow(1, 1, input_shape=(2, 3, 4)))\ninput = np.random.rand(2, 2, 3, 4)\noutput = model.forward(input)  Input is:  array([[[[0.74305305, 0.33925069, 0.31289333, 0.43703923],\n         [0.28316902, 0.3004414 , 0.40298034, 0.37476436],\n         [0.18825825, 0.38979411, 0.32963262, 0.37783457]],\n\n        [[0.14824117, 0.43532988, 0.57077087, 0.91535978],\n         [0.46375725, 0.90511296, 0.18859044, 0.92820822],\n         [0.13675737, 0.48270908, 0.04260755, 0.97255687]]],\n       [[[0.4836805 , 0.45262542, 0.7233705 , 0.63486529],\n         [0.07472717, 0.5715716 , 0.57029986, 0.26475783],\n         [0.56757079, 0.27602746, 0.45799196, 0.74420842]],\n\n        [[0.89048761, 0.08280716, 0.99030481, 0.35956427],\n         [0.70802689, 0.14425212, 0.08320864, 0.82271697],\n         [0.6915224 , 0.70490768, 0.41218963, 0.37024863]]]])  Output is  array([[[[0.14824118, 0.43532988, 0.57077086, 0.9153598 ],\n         [0.46375725, 0.905113  , 0.18859044, 0.92820823],\n         [0.13675737, 0.48270908, 0.04260755, 0.9725569 ]]],\n\n       [[[0.8904876 , 0.08280716, 0.9903048 , 0.35956427],\n         [0.7080269 , 0.14425212, 0.08320864, 0.82271695],\n         [0.6915224 , 0.70490766, 0.41218963, 0.37024862]]]],\n      dtype=float32)", 
            "title": "Narrow"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#permute", 
            "text": "Permutes the dimensions of the input according to a given pattern.  Useful for connecting RNNs and convnets together.  Permute(dims, inputShape = null)  Python:  Permute(dims, input_shape=None, name=None)  Parameters:   dims : Int array. Permutation pattern, does not include the batch dimension.\n          Indexing starts at 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Permute\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute[Float](Array(2, 1, 3), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.31086245      0.21210302      0.35112163\n\n(1,2,.,.) =\n0.61466074      0.50173014      0.8759959\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.24063066      0.502274        0.9114748\n(2,2,.,.) =\n0.93335986      0.25173688      0.88615775\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.8451549       0.06361471      0.7324815\n0.61466074      0.50173014      0.8759959\n\n(1,2,.,.) =\n0.31086245      0.21210302      0.35112163\n0.19090249      0.671227        0.73089105\n(2,1,.,.) =\n0.47867084      0.9341955       0.063592255\n0.93335986      0.25173688      0.88615775\n(2,2,.,.) =\n0.24063066      0.502274        0.9114748\n0.5394321       0.330763        0.89036304\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Permute\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Permute((2, 1, 3), input_shape=(2, 2, 3)))\ninput = np.random.rand(2, 2, 2, 3)\noutput = model.forward(input)  Input is:  array([[[[0.14016896, 0.7275626 , 0.79087092],\n         [0.57259566, 0.97387138, 0.70001999]],\n\n        [[0.9232002 , 0.07644555, 0.24705828],\n         [0.17257354, 0.93951155, 0.46183983]]],\n       [[[0.79432476, 0.64299062, 0.33959594],\n         [0.58608318, 0.338014  , 0.92602687]],\n\n        [[0.32638575, 0.69032582, 0.25168083],\n         [0.46813027, 0.95118373, 0.13145026]]]])  Output is  array([[[[0.14016896, 0.7275626 , 0.7908709 ],\n         [0.9232002 , 0.07644555, 0.24705827]],\n\n        [[0.57259566, 0.97387135, 0.70002   ],\n         [0.17257354, 0.93951154, 0.46183982]]],\n       [[[0.79432476, 0.64299065, 0.33959594],\n         [0.32638577, 0.6903258 , 0.25168082]],\n        [[0.5860832 , 0.338014  , 0.9260269 ],\n         [0.46813026, 0.95118374, 0.13145027]]]], dtype=float32)", 
            "title": "Permute"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#resizebilinear", 
            "text": "Resize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout.  ResizeBilinear(outputHeight, outputWidth, alignCorners = false, dimOrdering =  th , inputShape = null)  Python:  ResizeBilinear(output_height, output_width, align_corner=False, dim_ordering= th , input_shape=(2, 3, 5, 7), name=None)  Parameters:   outputHeight : output height  outputWidth : output width  alignCorners : align corner or not  dimOrdering : Format of input data. Either DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ResizeBilinear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential()\nmodel.add(ResizeBilinear[Float](2, 3, inputShape = Shape(2, 3, 5)))\nval input = Tensor[Float](2, 2, 3, 5).rand()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.6991891       0.007127314     0.73871046      0.95916307      0.9433856\n0.41275907      0.37573513      0.99193203      0.06930728      0.5922364\n0.024281504     0.2592453       0.3898136       0.6635241       0.85888565\n\n(1,2,.,.) =\n0.38028112      0.43709648      0.62538666      0.8468501       0.6445014\n0.45252413      0.48801896      0.59471387      0.013207023     0.3567462\n0.85187584      0.49279585      0.7973665       0.81287366      0.07852263\n\n(2,1,.,.) =\n0.1452374       0.6140467       0.36384684      0.066476084     0.96101314\n0.54862195      0.66091377      0.86857307      0.6844842       0.7368217\n0.25342992      0.71737933      0.12789607      0.21691357      0.7543404\n\n(2,2,.,.) =\n0.79176855      0.1204049       0.58971256      0.115073755     0.10459962\n0.5225398       0.742363        0.7612815       0.9881919       0.13359445\n0.9026869       0.13972941      0.92064524      0.9435532       0.5502235\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of...  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.6991891       0.4948494       0.9539039\n0.21852028      0.5664119       0.48613077\n\n(1,2,.,.) =\n0.38028112      0.56262326      0.7794005\n0.6522  0.6274959       0.34790504\n\n(2,1,.,.) =\n0.1452374       0.4472468       0.36465502\n0.40102595      0.5618719       0.54899293\n\n(2,2,.,.) =\n0.79176855      0.43327665      0.111582376\n0.71261334      0.70765764      0.75788474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import ResizeBilinear\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ResizeBilinear(2, 3, input_shape=(2, 3, 5, 5)))\ninput = np.random.rand(2, 2, 3, 5, 5)\noutput = model.forward(input)  Input is:  array([[[[0.43790358, 0.41882914, 0.71929122, 0.19673119, 0.36950189],\n         [0.38808651, 0.34287751, 0.34076998, 0.02581254, 0.42406155],\n         [0.84648848, 0.18411068, 0.97545126, 0.5468195 , 0.32136674]],\n\n        [[0.32965599, 0.06883324, 0.17350748, 0.01181338, 0.59180775],\n         [0.24667588, 0.36422516, 0.59648387, 0.48699443, 0.32323264],\n         [0.67661373, 0.58779956, 0.55286771, 0.59629101, 0.69727522]]],\n\n\n       [[[0.09462238, 0.35658325, 0.6787812 , 0.78676645, 0.99019452],\n         [0.81501527, 0.13348641, 0.71749101, 0.40543351, 0.3959018 ],\n         [0.608378  , 0.10531177, 0.78000335, 0.51679768, 0.65067605]],\n\n        [[0.12074634, 0.92682843, 0.52227042, 0.98856558, 0.28105255],\n         [0.78411841, 0.19625097, 0.83108171, 0.03777509, 0.15700493],\n         [0.95528158, 0.94003855, 0.61092905, 0.68651048, 0.57563719]]]])  Output is  array([[[[0.43790358, 0.61913717, 0.2543214 ],\n         [0.6172875 , 0.52657175, 0.3151154 ]],\n\n        [[0.329656  , 0.13861606, 0.20514478],\n         [0.46164483, 0.541788  , 0.5311798 ]]],\n\n\n       [[[0.09462238, 0.57138187, 0.8545758 ],\n         [0.7116966 , 0.5389645 , 0.48184   ]],\n\n        [[0.12074634, 0.6571231 , 0.752728  ],\n         [0.86969995, 0.6700518 , 0.36353552]]]], dtype=float32)", 
            "title": "ResizeBilinear"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/", 
            "text": "LocallyConnected2D\n\n\nA Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input.\n\n\nThe input is 2D tensor with shape: (batch_size, channels, rows, cols).\n\n\nScala:\n\n\nLocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = \nvalid\n, subsample = (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode=\nvalid\n, subsample=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.71993834     0.018790463     0.08133635      0.35603827\n-1.1757486      1.8503827       -1.4548069      -0.6309117\n-0.53039306     -0.14174776     0.7653523       -0.1891388\n\n(1,2,.,.) =\n1.0949191       0.13689162      0.35839355      -0.14805469\n-2.5264592      -0.34186792     1.3190275       -0.11725446\n-0.48823252     -1.5305915      -1.0556486      1.792275\n\n(2,1,.,.) =\n0.92393816      0.83243525      0.22506136      0.6694662\n0.7662836       -0.23876576     -0.7719174      0.13114463\n0.042082224     1.2212821       -1.2496184      -0.18717249\n\n(2,2,.,.) =\n0.726698        0.42673108      0.0786712       -1.4069401\n-0.090565465    0.49527475      0.08590904      -0.51858175\n1.4575573       0.9669369       0.21832618      0.34654656\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.022375792     0.669761        -0.25723624\n0.99919814      0.93189466      0.8592935\n\n(1,2,.,.) =\n0.12613812      -1.0531536      0.8148589\n0.66276294      0.12609969      0.6590149\n\n(2,1,.,.) =\n-0.1259023      0.32203823      0.07248953\n-0.125191       -0.1285046      0.021367729\n\n(2,2,.,.) =\n-0.13560611     -0.038621478    -0.08420516\n-0.0021556932   -0.094522506    -0.08551059\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.75179142 0.10678918 0.92663152 0.2041142 ]\n   [0.03534582 0.13742629 0.94115987 0.17303432]\n   [0.91112368 0.19837546 0.45643767 0.16589123]]\n\n  [[0.22996923 0.22878544 0.75623624 0.7058976 ]\n   [0.14107232 0.49484648 0.71194356 0.53604538]\n   [0.46257205 0.46902871 0.48046811 0.83579709]]]\n\n\n [[[0.9397535  0.51814825 0.10492714 0.24623405]\n   [0.69800376 0.12353963 0.69536497 0.05159074]\n   [0.56722731 0.33348394 0.47648031 0.25398067]]\n\n  [[0.51018599 0.3416568  0.14112375 0.76505795]\n   [0.16242231 0.16735028 0.79000471 0.98701885]\n   [0.79852431 0.77458166 0.12551857 0.43866238]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 0.14901309 -0.11168094  0.28349853]\n   [ 0.21792562  0.49922782 -0.06560349]]\n\n  [[ 0.6176302  -0.4638375  -0.13387583]\n   [-0.04903107  0.07764787 -0.33653474]]]\n\n\n [[[ 0.24676235 -0.46874076  0.33973938]\n   [ 0.21408634  0.36619198  0.17972258]]\n\n  [[ 0.35941058 -0.23446569 -0.09271184]\n   [ 0.39490524 -0.00668371 -0.25355732]]]]\n\n\n\n\n\n\nConvolution1D\n\n\nApplies convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nYou can also use \nConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nConvolution1D(nbFilter, filterLength, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution1D(nb_filter, filter_length, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]\n\n\n\n\n\n\nConvolution2D\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n\n\nYou can also use \nConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D, i.e. (samples, channels, rows, cols).\nThe output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols).\n\n\nScala:\n\n\nConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsample = (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D[Float](4, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8852683 -0.81495345 -1.2799169  0.9779215\n1.1456866 -0.10803124 -0.44350016 -1.7670554\n-0.9059258  -0.08115104 -0.888267 1.8203543\n\n(1,2,.,.) =\n-0.69458634 0.31331652  1.4600077 -0.93392456\n1.4808512 0.2082488 -0.008410408  0.013914147\n0.86024827  1.124567  0.28874534  -0.4866409\n\n(2,1,.,.) =\n-0.020653103  0.8077344 -0.9391865  0.2743323\n0.09707443  -0.1877453  2.3798819 1.71017\n0.14860597  0.8954743 2.0009918 1.0548053\n\n(2,2,.,.) =\n-0.06750481 -2.1010966  -0.51831937 -0.40519416\n1.2983296 1.9960507 0.31097296  -1.0400984\n-0.20703147 0.32478333  -0.5247251  1.2356688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.49652004  0.62284863  0.0\n1.2256577 0.11462581  0.761484\n\n(1,2,.,.) =\n0.0 0.0 1.6321466\n0.69082737  0.10713227  0.0\n\n(1,3,.,.) =\n0.0 0.0 1.0226117\n0.0 0.0 0.0\n\n(1,4,.,.) =\n0.017812707 0.044630717 0.0\n0.0 0.0 0.0\n\n(2,1,.,.) =\n0.0 0.79017955  0.0\n1.1551664 0.0 0.0\n\n(2,2,.,.) =\n0.0 0.0 0.0\n0.0 0.9762883 0.0\n\n(2,3,.,.) =\n0.0 0.0 0.0\n0.0 0.0 0.0\n\n(2,4,.,.) =\n0.0 0.0 0.1633394\n0.66279346  0.07180607  1.7188346\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[ 0.70766604,  0.56604946,  0.89172683,  0.35057259],\n         [ 0.89700606,  0.71675588,  0.92357667,  0.73319623],\n         [ 0.38198447,  0.66954234,  0.46397678,  0.81329758]],\n\n        [[ 0.86972625,  0.16386155,  0.73140259,  0.07359015],\n         [ 0.43441431,  0.16852341,  0.15025034,  0.34109183],\n         [ 0.89670592,  0.06335869,  0.72356566,  0.54245763]]],\n\n\n       [[[ 0.37727322,  0.14688331,  0.06249512,  0.29553298],\n         [ 0.50554043,  0.33364744,  0.95334248,  0.40551935],\n         [ 0.81317402,  0.59253283,  0.8249684 ,  0.80419637]],\n\n        [[ 0.71737738,  0.09376579,  0.3793706 ,  0.91432729],\n         [ 0.34433954,  0.74886398,  0.97859311,  0.9538775 ],\n         [ 0.45521369,  0.79446047,  0.35239537,  0.12803574]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.0732559 ,  0.70261478,  0.16962567],\n         [ 0.3641817 ,  0.56304729,  0.71597064]],\n\n        [[-0.5932048 , -0.04155506, -0.49025974],\n         [-0.57992101, -0.00230447, -0.33811107]],\n\n        [[ 0.13634545,  0.27157408, -0.01450583],\n         [ 0.34469086,  0.46334854,  0.55308509]],\n\n        [[-0.01247289,  0.69034004, -0.01554111],\n         [ 0.07790593,  0.09984782,  0.1278697 ]]],\n\n\n       [[[ 0.02547407,  0.64045584,  0.21886043],\n         [ 0.43482357,  0.45493811,  0.26216859]],\n\n        [[-0.39469361, -0.34455007, -0.2396858 ],\n         [-0.15447566, -0.35714447, -0.44134659]],\n\n        [[ 0.30956799,  0.9154281 ,  0.75450832],\n         [ 0.37207305,  0.55432665, -0.29964659]],\n\n        [[-0.48307419, -0.29406634, -0.29416537],\n         [ 0.0138942 ,  0.26592475,  0.38921899]]]], dtype=float32)\n\n\n\n\n\n\nAtrousConvolution2D\n\n\nApplies an atrous convolution operator for filtering windows of 2-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAtrousConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), atrous_rate=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsample\n: Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).\n\n\natrousRate\n: Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D[Float](4, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]\n\n\n\n\n\n\nLocallyConnected1D\n\n\nLocally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nLocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected1D(nb_filter, filter_length, activation=None, border_mode=\nvalid\n, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Dimensionality of the output.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Integer. Factor by which to subsample output.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LocallyConnected1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]\n\n\n\n\n\n\nUpSampling2D\n\n\nUpSampling layer for 2D inputs.\n\n\nRepeats the rows and columns of the data by the specified size.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nUpSampling2D(size = (2, 2), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling2D(size=(2, 2), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 2. UpSampling factors for rows and columns. Default is (2, 2).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) \n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import UpSampling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]\n\n\n\n\n\n\nUpSampling3D\n\n\nUpSampling layer for 3D inputs.\n\n\nRepeats the 1st, 2nd and 3rd dimensions of the data by the specified size.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nUpSampling3D(size = (2, 2, 2), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling3D(size=(2, 2, 2), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.05876646      0.8743367\n-0.15551122     0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n(1,1,2,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.01897243 0.87927954]\n-    [0.13656585 0.3003842 ]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]\n\n   [[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]]]]\n\n\n\n\n\n\nAtrousConvolution1D\n\n\nApplies an atrous convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAtrousConvolution1D(nbFilter, filterLength, init = \nglorot_uniform\n, activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution1D(nb_filter, filter_length, init=\nglorot_uniform\n, activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution kernels to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\natrousRate\n: Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18186663     -0.43034658     0.26391524      -1.4132749\n-0.17445838     1.3798479       0.1737039       1.152537\n0.27590567      0.009284354     -0.80261934     -0.9434588\n\n(2,.,.) =\n-0.20791245     0.21988653      0.8744776       0.2940677\n0.07080339      0.51823103      -0.46097854     -0.037812505\n0.35226902      0.79622966      0.011483789     0.88822025\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.026210725     1.2229221       0.45232815      -1.0826558      0.849349        0.086645454     0.041758537     0.3721839\n\n(2,.,.) =\n-0.14264873     0.060507685     -0.217965       0.42317814      0.17935039      -0.05465065     -0.6533742      -0.009769946\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.44706076 0.5902202  0.3784323  0.4098717 ]\n  [0.74646876 0.98997355 0.64164388 0.61591103]\n  [0.88695659 0.16591123 0.6575717  0.55897158]]\n\n [[0.51990872 0.82065542 0.18409799 0.99078291]\n  [0.03853884 0.0781884  0.82290244 0.99992993]\n  [0.02394716 0.10870804 0.17077537 0.77893951]]]\n\n\n\n\nOutput is\n\n\n[[[-0.09361145  0.48225394 -0.3777458  -0.84651476  0.3678655\n   -0.02871403  1.0220621   0.7548751 ]]\n\n [[-0.0299319   0.37761992 -0.08759689 -0.01757497 -0.01414538\n   -0.2547227   0.70025307  0.49045497]]]\n\n\n\n\n\n\nZeroPadding1D\n\n\nZero-padding layer for 1D input (e.g. temporal sequence).\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nZeroPadding1D(padding = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding1D(padding=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the padding dimension.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]\n\n\n\n\nOutput is\n\n\n[[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]\n\n\n\n\n\n\nZeroPadding3D\n\n\nZero-padding layer for 3D data (spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nZeroPadding3D(padding = (1, 1, 1), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding3D(padding=(1, 1, 1), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2)))\nval input = Tensor[Float](1, 1, 2, 1, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.59840345     -0.06308561\n\n(1,1,2,.,.) =\n0.48804763      0.2723002\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,2,.,.) =\n0.0     0.0     0.0     0.0\n0.0     -0.59840345     -0.06308561     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,3,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.48804763      0.2723002       0.0\n0.0     0.0     0.0     0.0\n\n(1,1,4,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2)))\ninput = np.random.random([1, 1, 2, 1, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.03167021, 0.15764403]],\n\n   [[0.26572586, 0.48872052]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.03167021, 0.15764403, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.26572585, 0.48872054, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]]]]]\n\n\n\n\n\n\nCropping1D\n\n\nCropping layer for 1D input (e.g. temporal sequence).\n\n\nIt crops along the time dimension (axis 1). \n\n\nThe input of this layer should be 3D, i.e. (batch, axis_to_crop, features).\nThe output of this layer should be 3D, i.e. (batch, cropped_axis, features).\n\n\nScala:\n\n\nCropping1D(cropping = (1, 1), inputShape = null)\n\n\n\n\nPython:\n\n\nCropping1D(cropping=(1, 1), input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.06297628  -0.8408224  0.21813048  -0.14371997\n0.9278932   0.069493145 -0.2900171  0.536517\n3.430168    -0.53643423 0.12677099  0.3572487\n\n(2,.,.) =\n1.493348    -1.1703341  -0.37385875 -0.239736\n0.33984247  -0.6005885  1.2722077   -0.5043763\n0.012092848 0.40293974  0.61356264  2.4283617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.9278932   0.069493145 -0.2900171  0.536517\n\n(2,.,.) =\n0.33984247  -0.6005885  1.2722077   -0.5043763\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Cropping1D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.12013423,  0.21359734,  0.92871231,  0.92152503],\n        [ 0.3649771 ,  0.39968689,  0.92007275,  0.16493056],\n        [ 0.11018303,  0.7591447 ,  0.35932136,  0.97727728]],\n\n       [[ 0.06645696,  0.21909036,  0.01219254,  0.46561466],\n        [ 0.64316144,  0.53577975,  0.38302965,  0.56807556],\n        [ 0.25223652,  0.23857826,  0.1884081 ,  0.42532243]]])\n\n\n\n\nOutput is:\n\n\narray([[[ 0.36497709,  0.3996869 ,  0.92007273,  0.16493057]],\n\n       [[ 0.64316142,  0.53577977,  0.38302964,  0.56807554]]], dtype=float32)\n\n\n\n\n\n\nCropping2D\n\n\nCropping layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nCropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nCropping2D(cropping=((0, 0), (0, 0)), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6840084      0.293568        0.045959193     0.91535753\n-0.49666363     -0.05026308     0.22163485      0.08330725\n0.36190453      -0.023894459    0.40037137      0.15155333\n\n(1,2,.,.) =\n1.0107938       0.05100493      -0.88689697     0.111396775\n0.065911256     -0.41727677     0.62742686      -0.5435138\n-1.0133605      0.7352207       -0.77922934     -0.36588958\n\n(2,1,.,.) =\n-0.6847248      0.8627568       -0.5600547      0.48514402\n-0.9261762      -0.34248486     -0.09243064     -0.13134436\n-0.23247129     1.2801572       -1.377833       -1.7608607\n\n(2,2,.,.) =\n1.1907105       0.30009162      -1.2604285      1.0099201\n-1.211673       -0.08809458     0.4386406       -0.6264226\n0.112140626     0.3690179       0.832656        1.3931179\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.293568        0.045959193     0.91535753\n-0.05026308     0.22163485      0.08330725\n\n(1,2,.,.) =\n0.05100493      -0.88689697     0.111396775\n-0.41727677     0.62742686      -0.5435138\n(2,1,.,.) =\n0.8627568       -0.5600547      0.48514402\n-0.34248486     -0.09243064     -0.13134436\n(2,2,.,.) =\n0.30009162      -1.2604285      1.0099201\n-0.08809458     0.4386406       -0.6264226\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.layers import Cropping2D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097],\n         [0.36859968, 0.44601991, 0.94679033, 0.93842937],\n         [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]],\n\n        [[0.32265899, 0.37304445, 0.09097587, 0.52496901],\n         [0.70275446, 0.10796127, 0.74849378, 0.99118752],\n         [0.34310691, 0.60435919, 0.22227177, 0.48464358]]],\n       [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216],\n         [0.48278365, 0.0968289 , 0.9465143 , 0.49814986],\n         [0.36140084, 0.98581155, 0.14834531, 0.71290525]],\n\n        [[0.8909849 , 0.66729728, 0.53332039, 0.83958965],\n         [0.3645429 , 0.40645471, 0.02596942, 0.80835778],\n         [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[0.78710294, 0.4518868 , 0.787381  ],\n         [0.44601992, 0.94679034, 0.93842936]],\n\n        [[0.37304446, 0.09097587, 0.524969  ],\n         [0.10796127, 0.7484938 , 0.9911875 ]]],\n       [[[0.6009071 , 0.09771059, 0.19654216],\n         [0.0968289 , 0.9465143 , 0.49814987]],\n\n        [[0.6672973 , 0.53332037, 0.83958966],\n         [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32)\n\n\n\n\n\n\nCropping3D\n\n\nCropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nCropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nCropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).\n\n\ndimOrdering\n: Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Cropping3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759],\n          [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911],\n          [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353],\n          [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]],\n\n         [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575],\n          [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304],\n          [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954],\n          [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]],\n\n         [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445],\n          [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542],\n          [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911],\n          [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]],\n\n        [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093],\n          [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295],\n          [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334],\n          [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]],\n\n         [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699],\n          [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744],\n          [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854],\n          [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]],\n\n         [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005],\n          [0.9700492 , 0.590918  , 0.88279087, 0.36807701, 0.48872168],\n          [0.847832  , 0.64009568, 0.97971251, 0.06989564, 0.80387185],\n          [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]],\n\n       [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475],\n          [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919],\n          [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606],\n          [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]],\n\n         [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397],\n          [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274],\n          [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272],\n          [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]],\n\n         [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231],\n          [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435],\n          [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504],\n          [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]],\n\n        [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ],\n          [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764],\n          [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024],\n          [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]],\n\n         [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993   ],\n          [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ],\n          [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089],\n          [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]],\n\n         [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002],\n          [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841],\n          [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372],\n          [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[[0.6530752 , 0.4779544 , 0.18358642],\n          [0.57958406, 0.7861404 , 0.12632357]]],\n\n        [[[0.8930068 , 0.8599061 , 0.38889495],\n          [0.4575138 , 0.1316247 , 0.04326183]]]],\n       [[[[0.68833065, 0.76978064, 0.14479478],\n          [0.03855975, 0.12752528, 0.9758718 ]]],\n\n        [[[0.6639144 , 0.49371347, 0.9227675 ],\n          [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32)\n\n\n\n\n\n\nZeroPadding2D\n\n\nZero-padding layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nZeroPadding2D(padding = (1, 1), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding2D(padding=(1, 1), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2227936       0.30803198      -1.3921114\n0.43359384      -0.038079295    -1.241585\n\n(1,2,.,.) =\n-1.1766883      -2.015887       -0.7110933\n-0.5415997      -0.50294536     -1.3715594\n(2,1,.,.) =\n0.10733734      1.3369694       0.037685163\n-1.2942516      0.2693859       0.6846867\n(2,2,.,.) =\n-1.4678168      0.21972063      0.40070927\n0.45242524      -0.03342953     -0.8016073\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     1.2227936       0.30803198      -1.3921114      0.0\n0.0     0.43359384      -0.038079295    -1.241585       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(1,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.1766883      -2.015887       -0.7110933      0.0\n0.0     -0.5415997      -0.50294536     -1.3715594      0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     0.10733734      1.3369694       0.037685163     0.0\n0.0     -1.2942516      0.2693859       0.6846867       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.4678168      0.21972063      0.40070927      0.0\n0.0     0.45242524      -0.03342953     -0.8016073      0.0\n0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.0544422 , 0.21723616, 0.69071413],\n         [0.68166784, 0.78673863, 0.63838101]],\n\n        [[0.43930351, 0.62153019, 0.5539688 ],\n         [0.79930636, 0.07007638, 0.13261168]]],\n       [[[0.21493318, 0.21060602, 0.12101637],\n         [0.90132665, 0.95799647, 0.09733214]],\n\n        [[0.21548934, 0.27369217, 0.06024094],\n         [0.85388521, 0.63911987, 0.34428558]]]])\n\n\n\n\nOutput is:\n\n\narray([[[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.0544422 , 0.21723616, 0.6907141 , 0.        ],\n         [0.        , 0.68166786, 0.78673863, 0.638381  , 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.43930352, 0.6215302 , 0.5539688 , 0.        ],\n         [0.        , 0.79930633, 0.07007638, 0.13261168, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n\n       [[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21493319, 0.21060602, 0.12101637, 0.        ],\n         [0.        , 0.90132666, 0.9579965 , 0.09733213, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21548934, 0.27369216, 0.06024094, 0.        ],\n         [0.        , 0.85388523, 0.63911986, 0.34428558, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]]],\n      dtype=float32)\n\n\n\n\n\n\nShareConvolution2D\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n\n\nYou can also use ShareConv2D as an alias of this layer.\n\n\nData format currently supported for this layer is DataFormat.NCHW (dimOrdering='th').\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nShareConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, subsample = (1, 1), padH = 0, padW = 0, \n                   propagateBack = true, dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nShareConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, subsample=(1, 1), pad_h=0, pad_w=0,\n                   propagate_back=True, dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: Initialization method for the weights of the layer. Default is Xavier.\n          You can also pass in corresponding string representations such as 'glorot_uniform'\n          or 'normal', etc. for simple init methods in the factory method.\n\n\nactivation\n: Activation function to use. Default is null.\n                You can also pass in corresponding string representations such as 'relu'\n                or 'sigmoid', etc. for simple activations in the factory method.\n\n\nsubsample\n: Int array of length 2 corresponding to the step of the convolution in the\n               height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\npadH\n: The additional zeros added to the height dimension. Default is 0.\n\n\npadW\n: The additional zeros added to the width dimension. Default is 0.\n\n\npropagateBack\n: Whether to propagate gradient back. Default is true.\n\n\ndimOrdering\n: Format of input data. Please use DataFormat.NCHW (dimOrdering='th').\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization),\n                  applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear).\n          Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.033261865     -0.5991786      1.7385886\n-0.56382173     0.4827164       -0.62269926\n\n(1,2,.,.) =\n-0.31000894     -0.05032834     -1.1754748\n2.594314        -1.0447274      -1.2348005\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.39924833\n\n(1,2,.,.) =\n-0.05582048\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import ShareConvolution2D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.94476901, 0.20822355, 0.12900894],\n         [0.07171242, 0.40400603, 0.87892258]],\n\n        [[0.40369527, 0.92786425, 0.17116734],\n         [0.73204729, 0.89770083, 0.86390069]]]])\n\n\n\n\nOutput is\n\n\narray([[[[ 0.1860767 ]],\n\n        [[-0.00958405]]]], dtype=float32)\n\n\n\n\n\n\nUpSampling1D\n\n\nUpSampling layer for 1D inputs.\n\n\nRepeats each temporal step 'length' times along the time axis.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nUpSampling1D(length = 2, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling1D(length=2, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlength\n: Integer. UpSampling factor. Default is 2.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]\n\n\n\n\nPython example:\n\n\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling1D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(UpSampling1D(length=3, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.22908319, 0.6684591 , 0.12425427],\n        [0.02378978, 0.12953109, 0.70786959]],\n\n       [[0.40711686, 0.64417535, 0.92019981],\n        [0.28788481, 0.77902591, 0.93019748]]])\n\n\n\n\nOutput is\n\n\narray([[[0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ]],\n\n       [[0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)", 
            "title": "Convolutional Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected2d", 
            "text": "A Locally-connected layer for 2D input works similarly to a SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at different patch of the input.  The input is 2D tensor with shape: (batch_size, channels, rows, cols).  Scala:  LocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode =  valid , subsample = (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D[Float](2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.71993834     0.018790463     0.08133635      0.35603827\n-1.1757486      1.8503827       -1.4548069      -0.6309117\n-0.53039306     -0.14174776     0.7653523       -0.1891388\n\n(1,2,.,.) =\n1.0949191       0.13689162      0.35839355      -0.14805469\n-2.5264592      -0.34186792     1.3190275       -0.11725446\n-0.48823252     -1.5305915      -1.0556486      1.792275\n\n(2,1,.,.) =\n0.92393816      0.83243525      0.22506136      0.6694662\n0.7662836       -0.23876576     -0.7719174      0.13114463\n0.042082224     1.2212821       -1.2496184      -0.18717249\n\n(2,2,.,.) =\n0.726698        0.42673108      0.0786712       -1.4069401\n-0.090565465    0.49527475      0.08590904      -0.51858175\n1.4575573       0.9669369       0.21832618      0.34654656\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.022375792     0.669761        -0.25723624\n0.99919814      0.93189466      0.8592935\n\n(1,2,.,.) =\n0.12613812      -1.0531536      0.8148589\n0.66276294      0.12609969      0.6590149\n\n(2,1,.,.) =\n-0.1259023      0.32203823      0.07248953\n-0.125191       -0.1285046      0.021367729\n\n(2,2,.,.) =\n-0.13560611     -0.038621478    -0.08420516\n-0.0021556932   -0.094522506    -0.08551059\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.75179142 0.10678918 0.92663152 0.2041142 ]\n   [0.03534582 0.13742629 0.94115987 0.17303432]\n   [0.91112368 0.19837546 0.45643767 0.16589123]]\n\n  [[0.22996923 0.22878544 0.75623624 0.7058976 ]\n   [0.14107232 0.49484648 0.71194356 0.53604538]\n   [0.46257205 0.46902871 0.48046811 0.83579709]]]\n\n\n [[[0.9397535  0.51814825 0.10492714 0.24623405]\n   [0.69800376 0.12353963 0.69536497 0.05159074]\n   [0.56722731 0.33348394 0.47648031 0.25398067]]\n\n  [[0.51018599 0.3416568  0.14112375 0.76505795]\n   [0.16242231 0.16735028 0.79000471 0.98701885]\n   [0.79852431 0.77458166 0.12551857 0.43866238]]]]  Output is  [[[[ 0.14901309 -0.11168094  0.28349853]\n   [ 0.21792562  0.49922782 -0.06560349]]\n\n  [[ 0.6176302  -0.4638375  -0.13387583]\n   [-0.04903107  0.07764787 -0.33653474]]]\n\n\n [[[ 0.24676235 -0.46874076  0.33973938]\n   [ 0.21408634  0.36619198  0.17972258]]\n\n  [[ 0.35941058 -0.23446569 -0.09271184]\n   [ 0.39490524 -0.00668371 -0.25355732]]]]", 
            "title": "LocallyConnected2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution1d", 
            "text": "Applies convolution operator for filtering neighborhoods of 1-D inputs.  You can also use  Conv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  Convolution1D(nbFilter, filterLength, init =  glorot_uniform , activation = null, borderMode =  valid , subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]  Output is  [[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]", 
            "title": "Convolution1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution2d", 
            "text": "Applies a 2D convolution over an input image composed of several input planes.  You can also use  Conv2D  as an alias of this layer.  The input of this layer should be 4D, i.e. (samples, channels, rows, cols).\nThe output of this layer should be 4D, i.e. (samples, filters, new_rows, new_cols).  Scala:  Convolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, borderMode =  valid , subsample = (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Convolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D[Float](4, 2, 2, activation =  relu , inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.8852683 -0.81495345 -1.2799169  0.9779215\n1.1456866 -0.10803124 -0.44350016 -1.7670554\n-0.9059258  -0.08115104 -0.888267 1.8203543\n\n(1,2,.,.) =\n-0.69458634 0.31331652  1.4600077 -0.93392456\n1.4808512 0.2082488 -0.008410408  0.013914147\n0.86024827  1.124567  0.28874534  -0.4866409\n\n(2,1,.,.) =\n-0.020653103  0.8077344 -0.9391865  0.2743323\n0.09707443  -0.1877453  2.3798819 1.71017\n0.14860597  0.8954743 2.0009918 1.0548053\n\n(2,2,.,.) =\n-0.06750481 -2.1010966  -0.51831937 -0.40519416\n1.2983296 1.9960507 0.31097296  -1.0400984\n-0.20703147 0.32478333  -0.5247251  1.2356688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.49652004  0.62284863  0.0\n1.2256577 0.11462581  0.761484\n\n(1,2,.,.) =\n0.0 0.0 1.6321466\n0.69082737  0.10713227  0.0\n\n(1,3,.,.) =\n0.0 0.0 1.0226117\n0.0 0.0 0.0\n\n(1,4,.,.) =\n0.017812707 0.044630717 0.0\n0.0 0.0 0.0\n\n(2,1,.,.) =\n0.0 0.79017955  0.0\n1.1551664 0.0 0.0\n\n(2,2,.,.) =\n0.0 0.0 0.0\n0.0 0.9762883 0.0\n\n(2,3,.,.) =\n0.0 0.0 0.0\n0.0 0.0 0.0\n\n(2,4,.,.) =\n0.0 0.0 0.1633394\n0.66279346  0.07180607  1.7188346\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Convolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[ 0.70766604,  0.56604946,  0.89172683,  0.35057259],\n         [ 0.89700606,  0.71675588,  0.92357667,  0.73319623],\n         [ 0.38198447,  0.66954234,  0.46397678,  0.81329758]],\n\n        [[ 0.86972625,  0.16386155,  0.73140259,  0.07359015],\n         [ 0.43441431,  0.16852341,  0.15025034,  0.34109183],\n         [ 0.89670592,  0.06335869,  0.72356566,  0.54245763]]],\n\n\n       [[[ 0.37727322,  0.14688331,  0.06249512,  0.29553298],\n         [ 0.50554043,  0.33364744,  0.95334248,  0.40551935],\n         [ 0.81317402,  0.59253283,  0.8249684 ,  0.80419637]],\n\n        [[ 0.71737738,  0.09376579,  0.3793706 ,  0.91432729],\n         [ 0.34433954,  0.74886398,  0.97859311,  0.9538775 ],\n         [ 0.45521369,  0.79446047,  0.35239537,  0.12803574]]]])  Output is  array([[[[ 0.0732559 ,  0.70261478,  0.16962567],\n         [ 0.3641817 ,  0.56304729,  0.71597064]],\n\n        [[-0.5932048 , -0.04155506, -0.49025974],\n         [-0.57992101, -0.00230447, -0.33811107]],\n\n        [[ 0.13634545,  0.27157408, -0.01450583],\n         [ 0.34469086,  0.46334854,  0.55308509]],\n\n        [[-0.01247289,  0.69034004, -0.01554111],\n         [ 0.07790593,  0.09984782,  0.1278697 ]]],\n\n\n       [[[ 0.02547407,  0.64045584,  0.21886043],\n         [ 0.43482357,  0.45493811,  0.26216859]],\n\n        [[-0.39469361, -0.34455007, -0.2396858 ],\n         [-0.15447566, -0.35714447, -0.44134659]],\n\n        [[ 0.30956799,  0.9154281 ,  0.75450832],\n         [ 0.37207305,  0.55432665, -0.29964659]],\n\n        [[-0.48307419, -0.29406634, -0.29416537],\n         [ 0.0138942 ,  0.26592475,  0.38921899]]]], dtype=float32)", 
            "title": "Convolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution2d", 
            "text": "Applies an atrous convolution operator for filtering windows of 2-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  AtrousConvolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), atrous_rate=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsample : Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).  atrousRate : Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D[Float](4, 2, 2, activation =  relu , inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]  Output is  [[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]", 
            "title": "AtrousConvolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected1d", 
            "text": "Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 3D.  Scala:  LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Dimensionality of the output.  filterLength : The extension (spatial or temporal) of each filter.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Integer. Factor by which to subsample output.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LocallyConnected1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LocallyConnected1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]  Output is  [[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]", 
            "title": "LocallyConnected1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling2d", 
            "text": "UpSampling layer for 2D inputs.  Repeats the rows and columns of the data by the specified size.  The input of this layer should be 4D.  Scala:  UpSampling2D(size = (2, 2), dimOrdering =  th , inputShape = null)  Python:  UpSampling2D(size=(2, 2), dim_ordering= th , input_shape=None, name=None)  Parameters:   size : Length 2. UpSampling factors for rows and columns. Default is (2, 2).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D[Float]((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) \n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import UpSampling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]  Output is:  [[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]", 
            "title": "UpSampling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling3d", 
            "text": "UpSampling layer for 3D inputs.  Repeats the 1st, 2nd and 3rd dimensions of the data by the specified size.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  The input of this layer should be 5D.  Scala:  UpSampling3D(size = (2, 2, 2), dimOrdering =  th , inputShape = null)  Python:  UpSampling3D(size=(2, 2, 2), dim_ordering= th , input_shape=None, name=None)  Parameters:   size : Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D[Float]((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.05876646      0.8743367\n-0.15551122     0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n(1,1,2,.,.) =\n0.05876646      0.05876646      0.8743367       0.8743367\n0.05876646      0.05876646      0.8743367       0.8743367\n-0.15551122     -0.15551122     0.9405281       0.9405281\n-0.15551122     -0.15551122     0.9405281       0.9405281\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.01897243 0.87927954]\n-    [0.13656585 0.3003842 ]]]]]  Output is  [[[[[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]\n\n   [[0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.01897243 0.01897243 0.87927955 0.87927955]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]\n    [0.13656585 0.13656585 0.3003842  0.3003842 ]]]]]", 
            "title": "UpSampling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution1d", 
            "text": "Applies an atrous convolution operator for filtering neighborhoods of 1-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  AtrousConvolution1D(nbFilter, filterLength, init =  glorot_uniform , activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution kernels to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  atrousRate : Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AtrousConvolution1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D[Float](8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18186663     -0.43034658     0.26391524      -1.4132749\n-0.17445838     1.3798479       0.1737039       1.152537\n0.27590567      0.009284354     -0.80261934     -0.9434588\n\n(2,.,.) =\n-0.20791245     0.21988653      0.8744776       0.2940677\n0.07080339      0.51823103      -0.46097854     -0.037812505\n0.35226902      0.79622966      0.011483789     0.88822025\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.026210725     1.2229221       0.45232815      -1.0826558      0.849349        0.086645454     0.041758537     0.3721839\n\n(2,.,.) =\n-0.14264873     0.060507685     -0.217965       0.42317814      0.17935039      -0.05465065     -0.6533742      -0.009769946\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.44706076 0.5902202  0.3784323  0.4098717 ]\n  [0.74646876 0.98997355 0.64164388 0.61591103]\n  [0.88695659 0.16591123 0.6575717  0.55897158]]\n\n [[0.51990872 0.82065542 0.18409799 0.99078291]\n  [0.03853884 0.0781884  0.82290244 0.99992993]\n  [0.02394716 0.10870804 0.17077537 0.77893951]]]  Output is  [[[-0.09361145  0.48225394 -0.3777458  -0.84651476  0.3678655\n   -0.02871403  1.0220621   0.7548751 ]]\n\n [[-0.0299319   0.37761992 -0.08759689 -0.01757497 -0.01414538\n   -0.2547227   0.70025307  0.49045497]]]", 
            "title": "AtrousConvolution1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding1d", 
            "text": "Zero-padding layer for 1D input (e.g. temporal sequence).  The input of this layer should be 3D.  Scala:  ZeroPadding1D(padding = 1, inputShape = null)  Python:  ZeroPadding1D(padding=1, input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the padding dimension.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D[Float](1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]  Output is  [[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]", 
            "title": "ZeroPadding1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding3d", 
            "text": "Zero-padding layer for 3D data (spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  ZeroPadding3D(padding = (1, 1, 1), dimOrdering =  th , inputShape = null)  Python:  ZeroPadding3D(padding=(1, 1, 1), dim_ordering= th , input_shape=None, name=None)  Parameters:   padding : Int array of length 3. How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension. Default is (1, 1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D[Float](padding = (1, 1, 1), inputShape = Shape(1, 2, 1, 2)))\nval input = Tensor[Float](1, 1, 2, 1, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.59840345     -0.06308561\n\n(1,1,2,.,.) =\n0.48804763      0.2723002\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x1x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,2,.,.) =\n0.0     0.0     0.0     0.0\n0.0     -0.59840345     -0.06308561     0.0\n0.0     0.0     0.0     0.0\n\n(1,1,3,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.48804763      0.2723002       0.0\n0.0     0.0     0.0     0.0\n\n(1,1,4,.,.) =\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D(padding=(1, 1, 1), input_shape=(1, 2, 1, 2)))\ninput = np.random.random([1, 1, 2, 1, 2])\noutput = model.forward(input)  Input is:  [[[[[0.03167021, 0.15764403]],\n\n   [[0.26572586, 0.48872052]]]]]  Output is  [[[[[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.03167021, 0.15764403, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.26572585, 0.48872054, 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]],\n\n   [[0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ],\n    [0.        , 0.        , 0.        , 0.        ]]]]]", 
            "title": "ZeroPadding3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping1d", 
            "text": "Cropping layer for 1D input (e.g. temporal sequence).  It crops along the time dimension (axis 1).   The input of this layer should be 3D, i.e. (batch, axis_to_crop, features).\nThe output of this layer should be 3D, i.e. (batch, cropped_axis, features).  Scala:  Cropping1D(cropping = (1, 1), inputShape = null)  Python:  Cropping1D(cropping=(1, 1), input_shape=None, name=None)  Parameters:   cropping : Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D[Float]((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.06297628  -0.8408224  0.21813048  -0.14371997\n0.9278932   0.069493145 -0.2900171  0.536517\n3.430168    -0.53643423 0.12677099  0.3572487\n\n(2,.,.) =\n1.493348    -1.1703341  -0.37385875 -0.239736\n0.33984247  -0.6005885  1.2722077   -0.5043763\n0.012092848 0.40293974  0.61356264  2.4283617\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.9278932   0.069493145 -0.2900171  0.536517\n\n(2,.,.) =\n0.33984247  -0.6005885  1.2722077   -0.5043763\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]  Python example:  from zoo.pipeline.api.keras.layers import Cropping1D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.12013423,  0.21359734,  0.92871231,  0.92152503],\n        [ 0.3649771 ,  0.39968689,  0.92007275,  0.16493056],\n        [ 0.11018303,  0.7591447 ,  0.35932136,  0.97727728]],\n\n       [[ 0.06645696,  0.21909036,  0.01219254,  0.46561466],\n        [ 0.64316144,  0.53577975,  0.38302965,  0.56807556],\n        [ 0.25223652,  0.23857826,  0.1884081 ,  0.42532243]]])  Output is:  array([[[ 0.36497709,  0.3996869 ,  0.92007273,  0.16493057]],\n\n       [[ 0.64316142,  0.53577977,  0.38302964,  0.56807554]]], dtype=float32)", 
            "title": "Cropping1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping2d", 
            "text": "Cropping layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  Cropping2D(cropping = ((0, 0), (0, 0)), dimOrdering =  th , inputShape = null)  Python:  Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering= th , input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D[Float](((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6840084      0.293568        0.045959193     0.91535753\n-0.49666363     -0.05026308     0.22163485      0.08330725\n0.36190453      -0.023894459    0.40037137      0.15155333\n\n(1,2,.,.) =\n1.0107938       0.05100493      -0.88689697     0.111396775\n0.065911256     -0.41727677     0.62742686      -0.5435138\n-1.0133605      0.7352207       -0.77922934     -0.36588958\n\n(2,1,.,.) =\n-0.6847248      0.8627568       -0.5600547      0.48514402\n-0.9261762      -0.34248486     -0.09243064     -0.13134436\n-0.23247129     1.2801572       -1.377833       -1.7608607\n\n(2,2,.,.) =\n1.1907105       0.30009162      -1.2604285      1.0099201\n-1.211673       -0.08809458     0.4386406       -0.6264226\n0.112140626     0.3690179       0.832656        1.3931179\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.293568        0.045959193     0.91535753\n-0.05026308     0.22163485      0.08330725\n\n(1,2,.,.) =\n0.05100493      -0.88689697     0.111396775\n-0.41727677     0.62742686      -0.5435138\n(2,1,.,.) =\n0.8627568       -0.5600547      0.48514402\n-0.34248486     -0.09243064     -0.13134436\n(2,2,.,.) =\n0.30009162      -1.2604285      1.0099201\n-0.08809458     0.4386406       -0.6264226\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  from zoo.pipeline.api.keras.layers import Cropping2D\nfrom zoo.pipeline.api.keras.models import Sequential\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[[0.04386121, 0.78710294, 0.4518868 , 0.78738097],\n         [0.36859968, 0.44601991, 0.94679033, 0.93842937],\n         [0.55705904, 0.30684226, 0.90630488, 0.9323689 ]],\n\n        [[0.32265899, 0.37304445, 0.09097587, 0.52496901],\n         [0.70275446, 0.10796127, 0.74849378, 0.99118752],\n         [0.34310691, 0.60435919, 0.22227177, 0.48464358]]],\n       [[[0.93479186, 0.6009071 , 0.09771059, 0.19654216],\n         [0.48278365, 0.0968289 , 0.9465143 , 0.49814986],\n         [0.36140084, 0.98581155, 0.14834531, 0.71290525]],\n\n        [[0.8909849 , 0.66729728, 0.53332039, 0.83958965],\n         [0.3645429 , 0.40645471, 0.02596942, 0.80835778],\n         [0.62524417, 0.14305505, 0.6706279 , 0.4283277 ]]]])  Output is:  array([[[[0.78710294, 0.4518868 , 0.787381  ],\n         [0.44601992, 0.94679034, 0.93842936]],\n\n        [[0.37304446, 0.09097587, 0.524969  ],\n         [0.10796127, 0.7484938 , 0.9911875 ]]],\n       [[[0.6009071 , 0.09771059, 0.19654216],\n         [0.0968289 , 0.9465143 , 0.49814987]],\n\n        [[0.6672973 , 0.53332037, 0.83958966],\n         [0.4064547 , 0.02596942, 0.8083578 ]]]], dtype=float32)", 
            "title": "Cropping2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping3d", 
            "text": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  Cropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering =  th , inputShape = null)  Python:  Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering= th , input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).  dimOrdering : Format of input data. Either 'CHANNEL_FIRST' (dimOrdering='th') or 'CHANNEL_LAST' (dimOrdering='tf'). Default is 'CHANNEL_FIRST'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Cropping3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D[Float](((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Cropping3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)  Input is:  array([[[[[0.62840716, 0.49718584, 0.12585459, 0.45339446, 0.51496759],\n          [0.09154417, 0.31975017, 0.45159785, 0.69461629, 0.01777911],\n          [0.03056908, 0.58578471, 0.4212357 , 0.81290609, 0.54614353],\n          [0.56553699, 0.42969119, 0.55706099, 0.57701881, 0.41386126]],\n\n         [[0.84399973, 0.79438576, 0.72216539, 0.24147284, 0.02302575],\n          [0.88659717, 0.65307522, 0.47795438, 0.18358642, 0.10409304],\n          [0.02787308, 0.57958405, 0.78614037, 0.12632357, 0.96611954],\n          [0.03602844, 0.29878791, 0.59278562, 0.25408987, 0.60823159]],\n\n         [[0.07057682, 0.8308839 , 0.27391967, 0.90192561, 0.80467445],\n          [0.50686651, 0.6975992 , 0.89386305, 0.33915142, 0.30557542],\n          [0.58812313, 0.41667892, 0.0859111 , 0.21376582, 0.06077911],\n          [0.3321846 , 0.77915362, 0.80878924, 0.44581895, 0.87659508]]],\n\n        [[[0.42478273, 0.41505405, 0.86690148, 0.81330225, 0.85384093],\n          [0.9370089 , 0.18919117, 0.92571803, 0.82038262, 0.75380295],\n          [0.48092604, 0.27035346, 0.30137481, 0.33337198, 0.88508334],\n          [0.44941603, 0.59172234, 0.02723888, 0.3714394 , 0.63989379]],\n\n         [[0.39549828, 0.19292932, 0.91677619, 0.40739894, 0.63731699],\n          [0.91693476, 0.89300681, 0.8599061 , 0.38889494, 0.55620744],\n          [0.8269569 , 0.45751382, 0.1316247 , 0.04326183, 0.71251854],\n          [0.56835414, 0.75783607, 0.6697517 , 0.55425787, 0.1779235 ]],\n\n         [[0.97761621, 0.12224875, 0.0565609 , 0.88227811, 0.15135005],\n          [0.9700492 , 0.590918  , 0.88279087, 0.36807701, 0.48872168],\n          [0.847832  , 0.64009568, 0.97971251, 0.06989564, 0.80387185],\n          [0.33721551, 0.99582496, 0.4309207 , 0.77468415, 0.17438985]]]],\n\n       [[[[0.52570481, 0.15825837, 0.96653256, 0.8395669 , 0.33314475],\n          [0.44051007, 0.66105309, 0.44270763, 0.46340145, 0.09020919],\n          [0.4220039 , 0.75622627, 0.66531762, 0.5474585 , 0.95511606],\n          [0.8150854 , 0.12041384, 0.16459857, 0.90216744, 0.90415106]],\n\n         [[0.23274933, 0.78995579, 0.8205956 , 0.0098613 , 0.39972397],\n          [0.46246117, 0.68833063, 0.76978062, 0.14479477, 0.80658274],\n          [0.29013113, 0.03855975, 0.12752528, 0.97587177, 0.22943272],\n          [0.61845944, 0.39336312, 0.70661959, 0.58377891, 0.41844674]],\n\n         [[0.04968886, 0.83604265, 0.82907304, 0.05302717, 0.15273231],\n          [0.5287088 , 0.54298116, 0.46370681, 0.23882016, 0.93293435],\n          [0.44967435, 0.44840028, 0.46009438, 0.68473051, 0.26375504],\n          [0.04099288, 0.4334504 , 0.08448742, 0.92742616, 0.21594092]]],\n\n        [[[0.99377422, 0.10287153, 0.95161776, 0.41423906, 0.2863645 ],\n          [0.30002606, 0.43550723, 0.87747421, 0.41472721, 0.91166764],\n          [0.41821649, 0.84575542, 0.92085315, 0.85144318, 0.45106024],\n          [0.12081268, 0.86000088, 0.61870455, 0.16207645, 0.96441056]],\n\n         [[0.67447583, 0.07718448, 0.45813553, 0.38294045, 0.47993   ],\n          [0.60947025, 0.66391439, 0.49371347, 0.92276753, 0.5735208 ],\n          [0.19690983, 0.58194273, 0.8964776 , 0.51749435, 0.13312089],\n          [0.88902345, 0.92261557, 0.00146803, 0.76453644, 0.91164938]],\n\n         [[0.15939257, 0.14745922, 0.75721476, 0.44560904, 0.30039002],\n          [0.80775365, 0.96551208, 0.95964112, 0.94420177, 0.42949841],\n          [0.26737604, 0.81199024, 0.05778487, 0.15004785, 0.55616372],\n          [0.51186541, 0.96281586, 0.36559551, 0.79961066, 0.69312035]]]]])  Output is:  array([[[[[0.6530752 , 0.4779544 , 0.18358642],\n          [0.57958406, 0.7861404 , 0.12632357]]],\n\n        [[[0.8930068 , 0.8599061 , 0.38889495],\n          [0.4575138 , 0.1316247 , 0.04326183]]]],\n       [[[[0.68833065, 0.76978064, 0.14479478],\n          [0.03855975, 0.12752528, 0.9758718 ]]],\n\n        [[[0.6639144 , 0.49371347, 0.9227675 ],\n          [0.58194274, 0.8964776 , 0.5174943 ]]]]], dtype=float32)", 
            "title": "Cropping3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding2d", 
            "text": "Zero-padding layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  ZeroPadding2D(padding = (1, 1), dimOrdering =  th , inputShape = null)  Python:  ZeroPadding2D(padding=(1, 1), dim_ordering= th , input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ZeroPadding2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D[Float]((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2227936       0.30803198      -1.3921114\n0.43359384      -0.038079295    -1.241585\n\n(1,2,.,.) =\n-1.1766883      -2.015887       -0.7110933\n-0.5415997      -0.50294536     -1.3715594\n(2,1,.,.) =\n0.10733734      1.3369694       0.037685163\n-1.2942516      0.2693859       0.6846867\n(2,2,.,.) =\n-1.4678168      0.21972063      0.40070927\n0.45242524      -0.03342953     -0.8016073\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     1.2227936       0.30803198      -1.3921114      0.0\n0.0     0.43359384      -0.038079295    -1.241585       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(1,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.1766883      -2.015887       -0.7110933      0.0\n0.0     -0.5415997      -0.50294536     -1.3715594      0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,1,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     0.10733734      1.3369694       0.037685163     0.0\n0.0     -1.2942516      0.2693859       0.6846867       0.0\n0.0     0.0     0.0     0.0     0.0\n\n(2,2,.,.) =\n0.0     0.0     0.0     0.0     0.0\n0.0     -1.4678168      0.21972063      0.40070927      0.0\n0.0     0.45242524      -0.03342953     -0.8016073      0.0\n0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ZeroPadding2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[[0.0544422 , 0.21723616, 0.69071413],\n         [0.68166784, 0.78673863, 0.63838101]],\n\n        [[0.43930351, 0.62153019, 0.5539688 ],\n         [0.79930636, 0.07007638, 0.13261168]]],\n       [[[0.21493318, 0.21060602, 0.12101637],\n         [0.90132665, 0.95799647, 0.09733214]],\n\n        [[0.21548934, 0.27369217, 0.06024094],\n         [0.85388521, 0.63911987, 0.34428558]]]])  Output is:  array([[[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.0544422 , 0.21723616, 0.6907141 , 0.        ],\n         [0.        , 0.68166786, 0.78673863, 0.638381  , 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.43930352, 0.6215302 , 0.5539688 , 0.        ],\n         [0.        , 0.79930633, 0.07007638, 0.13261168, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]],\n\n       [[[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21493319, 0.21060602, 0.12101637, 0.        ],\n         [0.        , 0.90132666, 0.9579965 , 0.09733213, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]],\n\n        [[0.        , 0.        , 0.        , 0.        , 0.        ],\n         [0.        , 0.21548934, 0.27369216, 0.06024094, 0.        ],\n         [0.        , 0.85388523, 0.63911986, 0.34428558, 0.        ],\n         [0.        , 0.        , 0.        , 0.        , 0.        ]]]],\n      dtype=float32)", 
            "title": "ZeroPadding2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#shareconvolution2d", 
            "text": "Applies a 2D convolution over an input image composed of several input planes.  You can also use ShareConv2D as an alias of this layer.  Data format currently supported for this layer is DataFormat.NCHW (dimOrdering='th').  The input of this layer should be 4D.  Scala:  ShareConvolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, subsample = (1, 1), padH = 0, padW = 0, \n                   propagateBack = true, dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  ShareConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, subsample=(1, 1), pad_h=0, pad_w=0,\n                   propagate_back=True, dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : Initialization method for the weights of the layer. Default is Xavier.\n          You can also pass in corresponding string representations such as 'glorot_uniform'\n          or 'normal', etc. for simple init methods in the factory method.  activation : Activation function to use. Default is null.\n                You can also pass in corresponding string representations such as 'relu'\n                or 'sigmoid', etc. for simple activations in the factory method.  subsample : Int array of length 2 corresponding to the step of the convolution in the\n               height and width dimension. Also called strides elsewhere. Default is (1, 1).  padH : The additional zeros added to the height dimension. Default is 0.  padW : The additional zeros added to the width dimension. Default is 0.  propagateBack : Whether to propagate gradient back. Default is true.  dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th').  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization),\n                  applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear).\n          Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ShareConvolution2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ShareConvolution2D[Float](nbFilter = 2, nbRow = 2, nbCol = 3, inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.033261865     -0.5991786      1.7385886\n-0.56382173     0.4827164       -0.62269926\n\n(1,2,.,.) =\n-0.31000894     -0.05032834     -1.1754748\n2.594314        -1.0447274      -1.2348005\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.39924833\n\n(1,2,.,.) =\n-0.05582048\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x1]  Python example:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import ShareConvolution2D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(ShareConvolution2D(2, 2, 3, input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[[0.94476901, 0.20822355, 0.12900894],\n         [0.07171242, 0.40400603, 0.87892258]],\n\n        [[0.40369527, 0.92786425, 0.17116734],\n         [0.73204729, 0.89770083, 0.86390069]]]])  Output is  array([[[[ 0.1860767 ]],\n\n        [[-0.00958405]]]], dtype=float32)", 
            "title": "ShareConvolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling1d", 
            "text": "UpSampling layer for 1D inputs.  Repeats each temporal step 'length' times along the time axis.  The input of this layer should be 3D.  Scala:  UpSampling1D(length = 2, inputShape = null)  Python:  UpSampling1D(length=2, input_shape=None, name=None)  Parameters:   length : Integer. UpSampling factor. Default is 2.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.UpSampling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D[Float](length = 3, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.8499613      0.6955453       -2.8545783\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n-0.26392975     -0.5695636      0.13427743\n\n(2,.,.) =\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n0.52427506      -0.7843101      -0.12673262\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n1.0643414       0.69714475      -0.013671399\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]  Python example:  from zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import UpSampling1D\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(UpSampling1D(length=3, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.22908319, 0.6684591 , 0.12425427],\n        [0.02378978, 0.12953109, 0.70786959]],\n\n       [[0.40711686, 0.64417535, 0.92019981],\n        [0.28788481, 0.77902591, 0.93019748]]])  Output is  array([[[0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.2290832 , 0.6684591 , 0.12425426],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ],\n        [0.02378978, 0.12953109, 0.7078696 ]],\n\n       [[0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.40711686, 0.64417535, 0.9201998 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ],\n        [0.2878848 , 0.7790259 , 0.9301975 ]]], dtype=float32)", 
            "title": "UpSampling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/", 
            "text": "MaxPooling1D\n\n\nMax pooling operation for temporal data.\n\n\nThe input is 3D tensor with shape:(batch_size, steps, feature_dim).\n\n\nScala:\n\n\nMaxPooling1D(poolLength = 2, stride = -1, borderMode = \nvalid\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling1D(pool_length=2, stride=None, border_mode=\nvalid\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which max pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2339195      -1.2134796      0.16991705      -0.10169973     -1.2464932\n0.37946555      0.29533234      -1.2552645      -2.6928735      -0.44519955\n0.98743796      -1.0912303      -0.13897413     1.0241779       -0.5951304\n-0.31459442     -0.088579334    -0.58336115     -0.6427486      -0.1447043\n\n(2,.,.) =\n0.14750746      0.07493488      -0.8554524      -1.6551514      0.16679412\n-0.82279974     0.25704315      0.09921734      -0.8135057      2.7640774\n-1.0111052      0.34388593      -0.7569789      1.0547938       1.6738676\n0.4396624       -1.0570261      0.061429325     1.1752373       -0.14648575\n\n(3,.,.) =\n-0.95818335     0.8790822       -0.99111855     -0.9717616      -0.39238095\n1.2533073       0.23365906      1.7784269       1.0600376       1.6816885\n0.7145845       0.4711851       -0.4465603      -0.77884597     0.484986\n0.42429695      -2.00715        0.6520644       1.3022201       -0.48169184\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.98743796      0.29533234      0.16991705      1.0241779       -0.44519955\n\n(2,.,.) =\n0.14750746      0.34388593      0.09921734      1.0547938       2.7640774\n\n(3,.,.) =\n1.2533073       0.8790822       1.7784269       1.0600376       1.6816885\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192]\n  [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637]\n  [0.24147633 0.2116796  0.54433489 0.22961905 0.88685975]\n  [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]]\n\n [[0.42306184 0.43404804 0.22141668 0.0316458  0.08445576]\n  [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813]\n  [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895]\n  [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]]\n\n [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853]\n  [0.9950283  0.55710408 0.70919634 0.52309929 0.14311439]\n  [0.25394468 0.41519219 0.8074057  0.05341861 0.98447171]\n  [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]]\n\n\n\n\nOutput is:\n\n\n[[[0.27837703 0.8728293  0.9429287  0.48428997 0.8868598 ]]\n\n [[0.9070284  0.43404803 0.52975726 0.43238723 0.50049895]]\n\n [[0.9950283  0.99869156 0.877897   0.6784016  0.98447174]]]\n\n\n\n\n\n\nMaxPooling2D\n\n\nMax pooling operation for spatial data.\n\n\nThe input is 4D tensor with shape:(batch_size, rows, cols, channels).\n\nScala:\n\n\nMaxPooling2D(poolSize = (2, 2), strides = null, borderMode = \nvalid\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling2D(pool_size=(2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.02138003      -0.20666665     -0.93250555     0.41267508\n-0.40883347     0.4919021       0.7189889       1.3442185\n-0.08697278     -0.025719838    2.1126  0.69069535\n\n(1,2,.,.) =\n-0.1685801      -0.07843445     1.3499486       -0.5944459\n0.29377022      0.061167963     -0.60608864     -0.08283464\n0.03402891      -1.0627178      1.9463096       0.0011169242\n\n(2,1,.,.) =\n-1.4524128      1.3868454       2.3057284       1.574949\n-1.165581       0.79445213      -0.63500565     -0.17981622\n-0.98042095     -1.7876958      0.8024988       -0.90554804\n\n(2,2,.,.) =\n-1.6468426      1.1864686       -0.683854       -1.5643677\n2.8272789       -0.5537863      -0.563258       -0.01623243\n-0.31333938     0.03472893      -1.730748       -0.15463233\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput:\n(1,1,.,.) =\n0.4919021       1.3442185\n\n(1,2,.,.) =\n0.29377022      1.3499486\n\n(2,1,.,.) =\n1.3868454       2.3057284\n\n(2,2,.,.) =\n2.8272789       -0.01623243\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.58589442 0.94643201 0.24779969 0.55347075]\n   [0.50604116 0.69884915 0.81253572 0.58586743]\n   [0.94560389 0.11573268 0.12562681 0.63301697]]\n\n  [[0.11736968 0.75641404 0.19342809 0.37670404]\n   [0.55561582 0.54354621 0.9506264  0.65929266]\n   [0.72911388 0.00499644 0.24280364 0.28822998]]]\n\n\n [[[0.53249492 0.43969012 0.20407128 0.49541971]\n   [0.00369797 0.75294821 0.15204289 0.41394393]\n   [0.19416915 0.93034988 0.0358259  0.38001445]]\n\n  [[0.88946341 0.30646232 0.5347175  0.87568066]\n   [0.00439823 0.97792811 0.34842225 0.20433116]\n   [0.42777728 0.93583737 0.54341935 0.31203758]]]]\n\n\n\n\n\nOutput is:\n\n\n[[[[0.946432   0.8125357 ]]\n\n  [[0.75641406 0.95062643]]]\n\n\n [[[0.7529482  0.4954197 ]]\n\n  [[0.9779281  0.8756807 ]]]]\n\n\n\n\n\n\n\nAveragePooling3D\n\n\nApplies average pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\n\n\nScala:\n\n\nAveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.71569425     -0.39595184     -0.47607258\n-0.12621938     -0.66759187     0.86833215\n\n(1,1,2,.,.) =\n1.219894        -0.07514859     0.6606987\n0.073906526     -1.2547257      -0.49249622\n\n(1,2,1,.,.) =\n-1.0730773      0.2780401       -0.8603222\n-0.31499937     0.94786566      -1.6953986\n\n(1,2,2,.,.) =\n0.31038517      1.7660809       -0.9849316\n-1.5245554      0.24002236      0.473947\n\n(2,1,1,.,.) =\n-0.988634       -0.0028023662   -2.1534977\n0.58303267      0.72106487      0.22115333\n\n(2,1,2,.,.) =\n1.3964092       -0.59152335     -0.6552192\n2.0191588       -0.32599944     0.84014076\n\n(2,2,1,.,.) =\n1.4505147       -2.4253457      -0.37597662\n-0.7049585      1.3384854       -1.1081233\n\n(2,2,2,.,.) =\n-0.8498942      1.169977        0.78120154\n0.13814813      -0.7438999      -0.9272572\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n-0.24269137\n\n(1,2,1,.,.) =\n0.07872025\n\n(2,1,1,.,.) =\n0.3513383\n\n(2,2,1,.,.) =\n-0.078371644\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.95796698 0.76067104 0.47285625]\n    [0.90296063 0.64177821 0.23302549]]\n\n   [[0.37135542 0.38455108 0.66999497]\n    [0.06756778 0.16411331 0.39038159]]]\n\n\n  [[[0.9884323  0.97861344 0.69852249]\n    [0.53289779 0.51290587 0.54822396]]\n\n   [[0.77241923 0.06470524 0.00757586]\n    [0.65977832 0.31973607 0.7551191 ]]]]\n\n\n\n [[[[0.56819589 0.20398916 0.26409867]\n    [0.81165023 0.65269175 0.16519667]]\n\n   [[0.7350688  0.52442381 0.29116889]\n    [0.45458689 0.29734681 0.39667421]]]\n\n\n  [[[0.33577239 0.54035235 0.41285576]\n    [0.01023886 0.23677996 0.18901205]]\n\n   [[0.67638612 0.54170351 0.0068781 ]\n    [0.95769069 0.88558419 0.4262852 ]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.5313706 ]]]\n\n\n  [[[0.603686  ]]]]\n\n\n\n [[[[0.5309942 ]]]\n\n\n  [[[0.52306354]]]]]\n\n\n\n\n\n\n\nGlobalMaxPooling1D\n\n\nGlobal max pooling operation for temporal data.\n\n\nThe input is 3D with the shape:(batch_size, steps, features).\n\n\nScala:\n\n\nGlobalMaxPooling1D(inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling1D(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.2998451       2.1855159       -0.05535197\n-0.6448657      0.74119943      -0.8761581\n\n(2,.,.) =\n1.3994918       -1.5119147      -0.6625015\n1.803635        -2.2516544      -0.016894706\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2998451       2.1855159       -0.05535197\n1.803635        -1.5119147      -0.016894706\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.05589183 0.73674405 0.49270549]\n  [0.03348098 0.82000941 0.81752936]]\n\n [[0.97310222 0.8878789  0.72330625]\n  [0.86144601 0.88568162 0.47241316]]]\n\n\n\n\nOutput is:\n\n\n[[0.05589183 0.8200094  0.8175294 ]\n [0.9731022  0.8878789  0.72330624]]\n\n\n\n\n\n\nMaxPooling3D\n\n\nApplies max pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nMaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxPooling3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]\n\n\n\n\n\n\nGlobalMaxPooling2D\n\n\nGlobal max pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalMaxPooling2D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling2D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.12648843      0.15536028      1.3401515       -0.25693455\n0.6002777       0.6886729       -1.0650102      -0.22140503\n-0.7598008      0.8800106       -0.061039474    -1.3625065\n\n(1,2,.,.) =\n-0.37492484     -0.6727478      -0.12211597     1.3243467\n-0.72237        0.6942101       -1.455304       -0.23814173\n-0.38509718     -0.9179013      -0.99926376     0.18432678\n\n(2,1,.,.) =\n0.4457857       -0.36717635     -0.6653158      -1.9075912\n-0.49489713     -0.70543754     0.85306334      0.21031244\n0.08930698      0.046588574     0.9523686       -0.87959886\n\n(2,2,.,.) =\n-0.8523849      0.55808693      -1.5779148      1.312412\n-0.9923541      -0.562809       1.1512411       0.33178216\n1.056546        -2.0607772      -0.8233232      0.024466092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3401515       1.3243467\n0.9523686       1.312412\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.82189558 0.20668687 0.84669433 0.58740261]\n-   [0.33005685 0.93836385 0.51005935 0.11894048]\n-   [0.39757919 0.17126568 0.38237808 0.35911186]]\n-\n-  [[0.98544456 0.10949685 0.47642379 0.21039236]\n-   [0.51058537 0.9625007  0.2519618  0.03186033]\n-   [0.28042435 0.08481816 0.37535567 0.60848855]]]\n-\n-\n- [[[0.34468892 0.48365864 0.01397789 0.16565704]\n-   [0.91387839 0.78507728 0.0912983  0.06167101]\n-   [0.49026863 0.17870698 0.43566122 0.79984653]]\n-\n-  [[0.15157888 0.07546447 0.47063241 0.46052913]\n-   [0.92483801 0.51271677 0.45300461 0.40369727]\n-   [0.94152848 0.61306339 0.43241425 0.88775481]]]]\n\n\n\n\nOutput is:\n\n\n[[0.93836385 0.98544455]\n- [0.9138784  0.9415285 ]]\n\n\n\n\n\n\nGlobalMaxPooling3D\n\n\nApplies global max pooling operation for 3D data.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\nThe output of this layer should be 2D, i.e. (batch_size, channels).\n\n\nScala:\n\n\nGlobalMaxPooling3D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling3D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.50938565  1.6374807   0.8158744\n-0.3293317  -0.17766304 0.9067782\n\n(1,1,2,.,.) =\n1.5450556   -1.0339675  0.056255028\n-0.8867852  -0.05401365 -0.9615863\n\n(1,2,1,.,.) =\n-0.98946816 0.21851462  -0.4431965\n-0.7591889  1.1842074   0.98533714\n\n(1,2,2,.,.) =\n-0.12944926 0.58315176  -1.5754528\n-0.93392104 -0.38259965 0.3566876\n\n(2,1,1,.,.) =\n-0.1219873  -0.06568    0.5519306\n0.32932717  1.4409258   0.68309426\n\n(2,1,2,.,.) =\n-1.4289209  0.47897565  -1.0722001\n-0.64675856 0.7097152   0.31949154\n\n(2,2,1,.,.) =\n-0.89986056 -0.13643691 0.69211197\n0.08849494  0.8695818   1.5527223\n\n(2,2,2,.,.) =\n1.3823601   0.36978078  0.10262361\n0.05734055  -0.41569084 0.009035309\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.6374807   1.1842074\n1.4409258   1.5527223\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n      [[[[[ 0.8402289  0.11503692 0.27831015]\n          [ 0.45756199 0.15043262 0.78778086]]\n\n         [[ 0.37076324 0.65032926 0.74508221]\n          [ 0.32223229 0.81980455 0.14822856]]]\n\n\n        [[[ 0.72858223 0.04609062 0.86802821]\n          [ 0.22619071 0.23091766 0.68856216]]\n\n         [[ 0.54321111 0.94913088 0.59588331]\n          [ 0.90821291 0.42860528 0.39355229]]]]\n\n\n\n       [[[[ 0.06834657 0.41250882 0.55612858]\n          [ 0.72871084 0.59139003 0.83317638]]\n\n         [[ 0.99382906 0.24782635 0.27295274]\n          [ 0.65663701 0.7994264  0.73672449]]]\n\n\n        [[[ 0.11487664 0.74224294 0.39289158]\n          [ 0.34253228 0.47903629 0.66238715]]\n\n         [[ 0.13219379 0.12541975 0.93002441]\n          [ 0.58895306 0.38519765 0.27216034]]]]]\n\n\n\n\nOutput is:\n\n\n[[ 0.84022892  0.94913089]\n [ 0.99382907  0.93002439]]\n\n\n\n\n\n\nAveragePooling2D\n\n\nAverage pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAveragePooling2D(poolSize = (2, 2), strides = null, borderMode = \nvalid\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling2D(pool_size=(2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]\n\n\n\n\n\n\nAveragePooling1D\n\n\nApplies average pooling operation for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAveragePooling1D(poolSize = 2, strides = -1, dimOrdering = \nvalid\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling1D(pool_length=2, stride=None, border_mode=\nvalid\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which average pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. Positive integer, or -1. 2 will halve the input.\n            If -1, it will default to poolLength. Default is -1, and in this case it will\n            be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n2.0454981       -0.9984553      -0.22548687\n-2.9674191      0.61953986      0.9267055\n\n(2,.,.) =\n0.2458116       -0.06563047     0.11032024\n0.29159164      1.0789983       0.6236742\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.4609605      -0.18945771     0.3506093\n\n(2,.,.) =\n0.2687016       0.50668395      0.36699724\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.27910133, 0.62511864, 0.11819567],\n        [0.60144333, 0.17082084, 0.32399398]],\n\n       [[0.44947572, 0.97199261, 0.95654852],\n        [0.72464095, 0.50742734, 0.09491157]]])\n\n\n\n\nOutput is:\n\n\narray([[[0.44027233, 0.39796975, 0.22109482]],\n\n       [[0.5870583 , 0.73971   , 0.52573   ]]], dtype=float32)\n\n\n\n\n\n\nGlobalAveragePooling2D\n\n\nApplies global average pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalAveragePooling2D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalAveragePooling2D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3)))\nval input = Tensor[Float](2, 2, 3, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3950379      0.23557353      -1.8424573\n0.07449951      0.6322816       0.8831866\n0.8229907       1.5395391       -0.84414214\n\n(1,2,.,.) =\n2.1792102       -1.0315448      -1.1207858\n-1.1498563      1.876386        -0.67528623\n0.54306036      0.7579748       0.09953801\n\n(2,1,.,.) =\n-0.5101911      -1.1826278      -0.5852779\n0.53600776      0.6960143       -2.8790317\n-0.4959711      -1.2831435      -0.09703717\n\n(2,2,.,.) =\n0.5213661       -0.4794566      -0.48301712\n0.3673898       -0.048692267    -0.043640807\n-0.60638505     -0.07805356     1.2334769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.011825972     0.16429958\n-0.64458424     0.04255416\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GlobalAveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 3)))\ninput = np.random.random([2, 2, 3, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[[0.54771885, 0.53283909, 0.46927443],\n         [0.47621227, 0.76883995, 0.52303474],\n         [0.60008681, 0.60752329, 0.98198994]],\n\n        [[0.28667601, 0.47522264, 0.4943029 ],\n         [0.00561534, 0.39171735, 0.23420212],\n         [0.50868123, 0.40796681, 0.82682555]]],\n       [[[0.78836132, 0.58607316, 0.93814738],\n         [0.34578363, 0.32976447, 0.49251034],\n         [0.22992651, 0.04771577, 0.56071013]],\n\n        [[0.34291469, 0.13181605, 0.68202722],\n         [0.16404025, 0.54052442, 0.79312374],\n         [0.0254005 , 0.71477398, 0.94485338]]]])\n\n\n\n\nOutput is:\n\n\narray([[0.61194664, 0.40346777],\n       [0.47988808, 0.4821638 ]], dtype=float32)", 
            "title": "Pooling Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling1d", 
            "text": "Max pooling operation for temporal data.  The input is 3D tensor with shape:(batch_size, steps, feature_dim).  Scala:  MaxPooling1D(poolLength = 2, stride = -1, borderMode =  valid , inputShape = null)  Python:  MaxPooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which max pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D[Float](poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.2339195      -1.2134796      0.16991705      -0.10169973     -1.2464932\n0.37946555      0.29533234      -1.2552645      -2.6928735      -0.44519955\n0.98743796      -1.0912303      -0.13897413     1.0241779       -0.5951304\n-0.31459442     -0.088579334    -0.58336115     -0.6427486      -0.1447043\n\n(2,.,.) =\n0.14750746      0.07493488      -0.8554524      -1.6551514      0.16679412\n-0.82279974     0.25704315      0.09921734      -0.8135057      2.7640774\n-1.0111052      0.34388593      -0.7569789      1.0547938       1.6738676\n0.4396624       -1.0570261      0.061429325     1.1752373       -0.14648575\n\n(3,.,.) =\n-0.95818335     0.8790822       -0.99111855     -0.9717616      -0.39238095\n1.2533073       0.23365906      1.7784269       1.0600376       1.6816885\n0.7145845       0.4711851       -0.4465603      -0.77884597     0.484986\n0.42429695      -2.00715        0.6520644       1.3022201       -0.48169184\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.98743796      0.29533234      0.16991705      1.0241779       -0.44519955\n\n(2,.,.) =\n0.14750746      0.34388593      0.09921734      1.0547938       2.7640774\n\n(3,.,.) =\n1.2533073       0.8790822       1.7784269       1.0600376       1.6816885\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.14508341 0.42297648 0.50516337 0.15659868 0.83121192]\n  [0.27837702 0.87282932 0.94292864 0.48428998 0.23604637]\n  [0.24147633 0.2116796  0.54433489 0.22961905 0.88685975]\n  [0.57235359 0.16278372 0.39749189 0.20781401 0.22834635]]\n\n [[0.42306184 0.43404804 0.22141668 0.0316458  0.08445576]\n  [0.88377164 0.00417697 0.52975728 0.43238725 0.40539813]\n  [0.90702837 0.37940347 0.06435512 0.33566794 0.50049895]\n  [0.12146178 0.61599986 0.11874934 0.57207512 0.87713768]]\n\n [[0.56690324 0.99869154 0.87789702 0.67840158 0.64935853]\n  [0.9950283  0.55710408 0.70919634 0.52309929 0.14311439]\n  [0.25394468 0.41519219 0.8074057  0.05341861 0.98447171]\n  [0.71387206 0.74763239 0.27057394 0.09578605 0.68601852]]]  Output is:  [[[0.27837703 0.8728293  0.9429287  0.48428997 0.8868598 ]]\n\n [[0.9070284  0.43404803 0.52975726 0.43238723 0.50049895]]\n\n [[0.9950283  0.99869156 0.877897   0.6784016  0.98447174]]]", 
            "title": "MaxPooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling2d", 
            "text": "Max pooling operation for spatial data.  The input is 4D tensor with shape:(batch_size, rows, cols, channels). Scala:  MaxPooling2D(poolSize = (2, 2), strides = null, borderMode =  valid , dimOrdering =  th , inputShape = null)  Python:  MaxPooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling2D\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.02138003      -0.20666665     -0.93250555     0.41267508\n-0.40883347     0.4919021       0.7189889       1.3442185\n-0.08697278     -0.025719838    2.1126  0.69069535\n\n(1,2,.,.) =\n-0.1685801      -0.07843445     1.3499486       -0.5944459\n0.29377022      0.061167963     -0.60608864     -0.08283464\n0.03402891      -1.0627178      1.9463096       0.0011169242\n\n(2,1,.,.) =\n-1.4524128      1.3868454       2.3057284       1.574949\n-1.165581       0.79445213      -0.63500565     -0.17981622\n-0.98042095     -1.7876958      0.8024988       -0.90554804\n\n(2,2,.,.) =\n-1.6468426      1.1864686       -0.683854       -1.5643677\n2.8272789       -0.5537863      -0.563258       -0.01623243\n-0.31333938     0.03472893      -1.730748       -0.15463233\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output:\n(1,1,.,.) =\n0.4919021       1.3442185\n\n(1,2,.,.) =\n0.29377022      1.3499486\n\n(2,1,.,.) =\n1.3868454       2.3057284\n\n(2,2,.,.) =\n2.8272789       -0.01623243\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.58589442 0.94643201 0.24779969 0.55347075]\n   [0.50604116 0.69884915 0.81253572 0.58586743]\n   [0.94560389 0.11573268 0.12562681 0.63301697]]\n\n  [[0.11736968 0.75641404 0.19342809 0.37670404]\n   [0.55561582 0.54354621 0.9506264  0.65929266]\n   [0.72911388 0.00499644 0.24280364 0.28822998]]]\n\n\n [[[0.53249492 0.43969012 0.20407128 0.49541971]\n   [0.00369797 0.75294821 0.15204289 0.41394393]\n   [0.19416915 0.93034988 0.0358259  0.38001445]]\n\n  [[0.88946341 0.30646232 0.5347175  0.87568066]\n   [0.00439823 0.97792811 0.34842225 0.20433116]\n   [0.42777728 0.93583737 0.54341935 0.31203758]]]]  Output is:  [[[[0.946432   0.8125357 ]]\n\n  [[0.75641406 0.95062643]]]\n\n\n [[[0.7529482  0.4954197 ]]\n\n  [[0.9779281  0.8756807 ]]]]", 
            "title": "MaxPooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling3d", 
            "text": "Applies average pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input is 5D tensor with shape:(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).  Scala:  AveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering =  th , inputShape = null)  Python:  AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.71569425     -0.39595184     -0.47607258\n-0.12621938     -0.66759187     0.86833215\n\n(1,1,2,.,.) =\n1.219894        -0.07514859     0.6606987\n0.073906526     -1.2547257      -0.49249622\n\n(1,2,1,.,.) =\n-1.0730773      0.2780401       -0.8603222\n-0.31499937     0.94786566      -1.6953986\n\n(1,2,2,.,.) =\n0.31038517      1.7660809       -0.9849316\n-1.5245554      0.24002236      0.473947\n\n(2,1,1,.,.) =\n-0.988634       -0.0028023662   -2.1534977\n0.58303267      0.72106487      0.22115333\n\n(2,1,2,.,.) =\n1.3964092       -0.59152335     -0.6552192\n2.0191588       -0.32599944     0.84014076\n\n(2,2,1,.,.) =\n1.4505147       -2.4253457      -0.37597662\n-0.7049585      1.3384854       -1.1081233\n\n(2,2,2,.,.) =\n-0.8498942      1.169977        0.78120154\n0.13814813      -0.7438999      -0.9272572\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n-0.24269137\n\n(1,2,1,.,.) =\n0.07872025\n\n(2,1,1,.,.) =\n0.3513383\n\n(2,2,1,.,.) =\n-0.078371644\n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.95796698 0.76067104 0.47285625]\n    [0.90296063 0.64177821 0.23302549]]\n\n   [[0.37135542 0.38455108 0.66999497]\n    [0.06756778 0.16411331 0.39038159]]]\n\n\n  [[[0.9884323  0.97861344 0.69852249]\n    [0.53289779 0.51290587 0.54822396]]\n\n   [[0.77241923 0.06470524 0.00757586]\n    [0.65977832 0.31973607 0.7551191 ]]]]\n\n\n\n [[[[0.56819589 0.20398916 0.26409867]\n    [0.81165023 0.65269175 0.16519667]]\n\n   [[0.7350688  0.52442381 0.29116889]\n    [0.45458689 0.29734681 0.39667421]]]\n\n\n  [[[0.33577239 0.54035235 0.41285576]\n    [0.01023886 0.23677996 0.18901205]]\n\n   [[0.67638612 0.54170351 0.0068781 ]\n    [0.95769069 0.88558419 0.4262852 ]]]]]  Output is:  [[[[[0.5313706 ]]]\n\n\n  [[[0.603686  ]]]]\n\n\n\n [[[[0.5309942 ]]]\n\n\n  [[[0.52306354]]]]]", 
            "title": "AveragePooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling1d", 
            "text": "Global max pooling operation for temporal data.  The input is 3D with the shape:(batch_size, steps, features).  Scala:  GlobalMaxPooling1D(inputShape = null)  Python:  GlobalMaxPooling1D(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling1D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.2998451       2.1855159       -0.05535197\n-0.6448657      0.74119943      -0.8761581\n\n(2,.,.) =\n1.3994918       -1.5119147      -0.6625015\n1.803635        -2.2516544      -0.016894706\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2998451       2.1855159       -0.05535197\n1.803635        -1.5119147      -0.016894706\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.05589183 0.73674405 0.49270549]\n  [0.03348098 0.82000941 0.81752936]]\n\n [[0.97310222 0.8878789  0.72330625]\n  [0.86144601 0.88568162 0.47241316]]]  Output is:  [[0.05589183 0.8200094  0.8175294 ]\n [0.9731022  0.8878789  0.72330624]]", 
            "title": "GlobalMaxPooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling3d", 
            "text": "Applies max pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  MaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering =  th , inputShape = null)  Python:  MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.MaxPooling3D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import MaxPooling3D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]  Output is:  [[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]", 
            "title": "MaxPooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling2d", 
            "text": "Global max pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalMaxPooling2D(dimOrdering =  th , inputShape = null)  Python:  GlobalMaxPooling2D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.12648843      0.15536028      1.3401515       -0.25693455\n0.6002777       0.6886729       -1.0650102      -0.22140503\n-0.7598008      0.8800106       -0.061039474    -1.3625065\n\n(1,2,.,.) =\n-0.37492484     -0.6727478      -0.12211597     1.3243467\n-0.72237        0.6942101       -1.455304       -0.23814173\n-0.38509718     -0.9179013      -0.99926376     0.18432678\n\n(2,1,.,.) =\n0.4457857       -0.36717635     -0.6653158      -1.9075912\n-0.49489713     -0.70543754     0.85306334      0.21031244\n0.08930698      0.046588574     0.9523686       -0.87959886\n\n(2,2,.,.) =\n-0.8523849      0.55808693      -1.5779148      1.312412\n-0.9923541      -0.562809       1.1512411       0.33178216\n1.056546        -2.0607772      -0.8233232      0.024466092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3401515       1.3243467\n0.9523686       1.312412\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.82189558 0.20668687 0.84669433 0.58740261]\n-   [0.33005685 0.93836385 0.51005935 0.11894048]\n-   [0.39757919 0.17126568 0.38237808 0.35911186]]\n-\n-  [[0.98544456 0.10949685 0.47642379 0.21039236]\n-   [0.51058537 0.9625007  0.2519618  0.03186033]\n-   [0.28042435 0.08481816 0.37535567 0.60848855]]]\n-\n-\n- [[[0.34468892 0.48365864 0.01397789 0.16565704]\n-   [0.91387839 0.78507728 0.0912983  0.06167101]\n-   [0.49026863 0.17870698 0.43566122 0.79984653]]\n-\n-  [[0.15157888 0.07546447 0.47063241 0.46052913]\n-   [0.92483801 0.51271677 0.45300461 0.40369727]\n-   [0.94152848 0.61306339 0.43241425 0.88775481]]]]  Output is:  [[0.93836385 0.98544455]\n- [0.9138784  0.9415285 ]]", 
            "title": "GlobalMaxPooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling3d", 
            "text": "Applies global max pooling operation for 3D data.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D, i.e. (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels).\nThe output of this layer should be 2D, i.e. (batch_size, channels).  Scala:  GlobalMaxPooling3D(dimOrdering =  th , inputShape = null)  Python:  GlobalMaxPooling3D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalMaxPooling3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.50938565  1.6374807   0.8158744\n-0.3293317  -0.17766304 0.9067782\n\n(1,1,2,.,.) =\n1.5450556   -1.0339675  0.056255028\n-0.8867852  -0.05401365 -0.9615863\n\n(1,2,1,.,.) =\n-0.98946816 0.21851462  -0.4431965\n-0.7591889  1.1842074   0.98533714\n\n(1,2,2,.,.) =\n-0.12944926 0.58315176  -1.5754528\n-0.93392104 -0.38259965 0.3566876\n\n(2,1,1,.,.) =\n-0.1219873  -0.06568    0.5519306\n0.32932717  1.4409258   0.68309426\n\n(2,1,2,.,.) =\n-1.4289209  0.47897565  -1.0722001\n-0.64675856 0.7097152   0.31949154\n\n(2,2,1,.,.) =\n-0.89986056 -0.13643691 0.69211197\n0.08849494  0.8695818   1.5527223\n\n(2,2,2,.,.) =\n1.3823601   0.36978078  0.10262361\n0.05734055  -0.41569084 0.009035309\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.6374807   1.1842074\n1.4409258   1.5527223\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:        [[[[[ 0.8402289  0.11503692 0.27831015]\n          [ 0.45756199 0.15043262 0.78778086]]\n\n         [[ 0.37076324 0.65032926 0.74508221]\n          [ 0.32223229 0.81980455 0.14822856]]]\n\n\n        [[[ 0.72858223 0.04609062 0.86802821]\n          [ 0.22619071 0.23091766 0.68856216]]\n\n         [[ 0.54321111 0.94913088 0.59588331]\n          [ 0.90821291 0.42860528 0.39355229]]]]\n\n\n\n       [[[[ 0.06834657 0.41250882 0.55612858]\n          [ 0.72871084 0.59139003 0.83317638]]\n\n         [[ 0.99382906 0.24782635 0.27295274]\n          [ 0.65663701 0.7994264  0.73672449]]]\n\n\n        [[[ 0.11487664 0.74224294 0.39289158]\n          [ 0.34253228 0.47903629 0.66238715]]\n\n         [[ 0.13219379 0.12541975 0.93002441]\n          [ 0.58895306 0.38519765 0.27216034]]]]]  Output is:  [[ 0.84022892  0.94913089]\n [ 0.99382907  0.93002439]]", 
            "title": "GlobalMaxPooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling2d", 
            "text": "Average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  AveragePooling2D(poolSize = (2, 2), strides = null, borderMode =  valid , dimOrdering =  th , inputShape = null)  Python:  AveragePooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]  Output is:  [[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]", 
            "title": "AveragePooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling1d", 
            "text": "Applies average pooling operation for temporal data.  The input of this layer should be 3D.  Scala:  AveragePooling1D(poolSize = 2, strides = -1, dimOrdering =  valid , inputShape = null)  Python:  AveragePooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which average pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. Positive integer, or -1. 2 will halve the input.\n            If -1, it will default to poolLength. Default is -1, and in this case it will\n            be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.AveragePooling1D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n2.0454981       -0.9984553      -0.22548687\n-2.9674191      0.61953986      0.9267055\n\n(2,.,.) =\n0.2458116       -0.06563047     0.11032024\n0.29159164      1.0789983       0.6236742\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.4609605      -0.18945771     0.3506093\n\n(2,.,.) =\n0.2687016       0.50668395      0.36699724\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import AveragePooling1D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[0.27910133, 0.62511864, 0.11819567],\n        [0.60144333, 0.17082084, 0.32399398]],\n\n       [[0.44947572, 0.97199261, 0.95654852],\n        [0.72464095, 0.50742734, 0.09491157]]])  Output is:  array([[[0.44027233, 0.39796975, 0.22109482]],\n\n       [[0.5870583 , 0.73971   , 0.52573   ]]], dtype=float32)", 
            "title": "AveragePooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling2d", 
            "text": "Applies global average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalAveragePooling2D(dimOrdering =  th , inputShape = null)  Python:  GlobalAveragePooling2D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Please use DataFormat.NCHW (dimOrdering='th') or DataFormat.NHWC (dimOrdering='tf'). Default is NCHW.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.GlobalAveragePooling2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D[Float](inputShape = Shape(2, 3, 3)))\nval input = Tensor[Float](2, 2, 3, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3950379      0.23557353      -1.8424573\n0.07449951      0.6322816       0.8831866\n0.8229907       1.5395391       -0.84414214\n\n(1,2,.,.) =\n2.1792102       -1.0315448      -1.1207858\n-1.1498563      1.876386        -0.67528623\n0.54306036      0.7579748       0.09953801\n\n(2,1,.,.) =\n-0.5101911      -1.1826278      -0.5852779\n0.53600776      0.6960143       -2.8790317\n-0.4959711      -1.2831435      -0.09703717\n\n(2,2,.,.) =\n0.5213661       -0.4794566      -0.48301712\n0.3673898       -0.048692267    -0.043640807\n-0.60638505     -0.07805356     1.2334769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.011825972     0.16429958\n-0.64458424     0.04255416\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GlobalAveragePooling2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 3)))\ninput = np.random.random([2, 2, 3, 3])\noutput = model.forward(input)  Input is:  array([[[[0.54771885, 0.53283909, 0.46927443],\n         [0.47621227, 0.76883995, 0.52303474],\n         [0.60008681, 0.60752329, 0.98198994]],\n\n        [[0.28667601, 0.47522264, 0.4943029 ],\n         [0.00561534, 0.39171735, 0.23420212],\n         [0.50868123, 0.40796681, 0.82682555]]],\n       [[[0.78836132, 0.58607316, 0.93814738],\n         [0.34578363, 0.32976447, 0.49251034],\n         [0.22992651, 0.04771577, 0.56071013]],\n\n        [[0.34291469, 0.13181605, 0.68202722],\n         [0.16404025, 0.54052442, 0.79312374],\n         [0.0254005 , 0.71477398, 0.94485338]]]])  Output is:  array([[0.61194664, 0.40346777],\n       [0.47988808, 0.4821638 ]], dtype=float32)", 
            "title": "GlobalAveragePooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/", 
            "text": "SimpleRNN\n\n\nA fully-connected recurrent neural network cell. The output is to be fed back to input.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nSimpleRNN(outputDim, activation = \ntanh\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSimpleRNN(output_dim, activation=\ntanh\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN[Float](8, activation = \nrelu\n, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SimpleRNN\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation=\nrelu\n, input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]\n\n\n\n\nOutput is:\n\n\n[[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]\n\n\n\n\n\n\nLSTM\n\n\nLong Short Term Memory unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nLSTM(outputDim, activation = \ntanh\n, innerActivation = \nhard_sigmoid\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nLSTM(output_dim, activation=\ntanh\n, inner_activation=\nhard_sigmoid\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6857518   0.21570909  -0.019308459\n0.17754157  0.25172755  -1.189466\n\n(2,.,.) =\n0.23807438  1.6879119   -0.36335373\n0.9826865   0.49549296  0.8100107\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.13552098  -0.043483295    -0.10553853 0.19386405  0.18295142  0.037892513 -0.05510225 -0.2420117\n-0.04152686 -0.13908584 0.18151914  0.14170776  0.15598273  0.18968433  -0.042683482    -0.05782121\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LSTM\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.67619723,  0.5168176 ,  0.8093504 ],\n        [ 0.93787417,  0.53016934,  0.51934568]],\n\n       [[ 0.57334472,  0.40007739,  0.65670337],\n        [ 0.74457042,  0.15209156,  0.02015092]]])\n\n\n\n\nOutput is:\n\n\narray([[-0.01563799,  0.16000053, -0.20192699,  0.08859081, -0.14184587,\n         0.11160418,  0.19090165,  0.03475797],\n       [-0.02395577,  0.10148412, -0.13211192,  0.05772379, -0.16488783,\n         0.13513438,  0.15624164,  0.02866406]], dtype=float32)\n\n\n\n\n\n\nGRU\n\n\nGated Recurrent Unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nGRU(outputDim, activation = \ntanh\n, innerActivation = \nhard_sigmoid\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nGRU(output_dim, activation=\ntanh\n, inner_activation=\nhard_sigmoid\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GRU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GRU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]\n\n\n\n\nOutput is:\n\n\n[[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]\n\n\n\n\n\n\nHighway\n\n\nDensely connected highway network.\n\n\nHighway layers are a natural extension of LSTMs to feedforward networks.\n\n\nThe input of this layer should be 2D, i.e. (batch, input dim).\n\n\nScala:\n\n\nHighway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nHighway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Highway\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Highway\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Highway(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]\n\n\n\n\nOutput is:\n\n\n[[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#simplernn", 
            "text": "A fully-connected recurrent neural network cell. The output is to be fed back to input.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  SimpleRNN(outputDim, activation =  tanh , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  SimpleRNN(output_dim, activation= tanh , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SimpleRNN\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN[Float](8, activation =  relu , inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SimpleRNN\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation= relu , input_shape=(4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]  Output is:  [[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]", 
            "title": "SimpleRNN"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#lstm", 
            "text": "Long Short Term Memory unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  LSTM(outputDim, activation =  tanh , innerActivation =  hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  LSTM(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LSTM\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6857518   0.21570909  -0.019308459\n0.17754157  0.25172755  -1.189466\n\n(2,.,.) =\n0.23807438  1.6879119   -0.36335373\n0.9826865   0.49549296  0.8100107\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.13552098  -0.043483295    -0.10553853 0.19386405  0.18295142  0.037892513 -0.05510225 -0.2420117\n-0.04152686 -0.13908584 0.18151914  0.14170776  0.15598273  0.18968433  -0.042683482    -0.05782121\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LSTM\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  array([[[ 0.67619723,  0.5168176 ,  0.8093504 ],\n        [ 0.93787417,  0.53016934,  0.51934568]],\n\n       [[ 0.57334472,  0.40007739,  0.65670337],\n        [ 0.74457042,  0.15209156,  0.02015092]]])  Output is:  array([[-0.01563799,  0.16000053, -0.20192699,  0.08859081, -0.14184587,\n         0.11160418,  0.19090165,  0.03475797],\n       [-0.02395577,  0.10148412, -0.13211192,  0.05772379, -0.16488783,\n         0.13513438,  0.15624164,  0.02866406]], dtype=float32)", 
            "title": "LSTM"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#gru", 
            "text": "Gated Recurrent Unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  GRU(outputDim, activation =  tanh , innerActivation =  hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  GRU(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.GRU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU[Float](8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GRU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]  Output is:  [[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]", 
            "title": "GRU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#highway", 
            "text": "Densely connected highway network.  Highway layers are a natural extension of LSTMs to feedforward networks.  The input of this layer should be 2D, i.e. (batch, input dim).  Scala:  Highway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Highway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.Highway\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Highway\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Highway(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]  Output is:  [[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]", 
            "title": "Highway"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/", 
            "text": "BatchNormalization\n\n\nBatch normalization layer.\n\n\nNormalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n\n\nIt is a feature-wise normalization, each feature map in the input will be normalized separately.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nBatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = \nzero\n, gammaInit = \none\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nBatchNormalization(epsilon=0.001, momentum=0.99, beta_init=\nzero\n, gamma_init=\none\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nepsilon\n: Fuzz parameter. Default is 0.001.\n\n\nmomentum\n: Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.\n\n\nbetaInit\n: Name of initialization function for shift parameter. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\ngammaInit\n: Name of initialization function for scale parameter. See \nhere\n for available initialization strings. Default is 'one'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.35774308      -0.0018262876   -1.0186636      -0.8283433\n0.1458402       -0.8954456      0.65028995      0.74481136\n0.46434486      -0.33841616     -0.2882468      0.27368018\n\n(1,2,.,.) =\n-0.85313565     -1.0957539      -0.7689828      1.7338694\n0.66673565      1.0302666       -1.0154791      0.9704916\n-1.518189       0.34307054      -0.8662138      0.53776205\n\n(2,1,.,.) =\n-1.5997988      0.4131082       -0.83005565     1.3930303\n1.061352        -0.6628746      0.8510218       -0.36472544\n1.4967325       -0.082105584    -1.2064567      0.5379558\n\n(2,2,.,.) =\n0.76886225      0.8283977       -2.815423       -1.1129401\n-0.76033413     -0.09757436     -1.1177903      0.057090428\n-1.1909146      1.3031846       1.8407855       2.2742975\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.42506456      -0.016198127    -1.2640586      -1.0304978\n0.16501783      -1.1128457      0.7840774       0.9000738\n0.55588603      -0.4292604      -0.3676927      0.32190278\n\n(1,2,.,.) =\n-0.66352594     -0.8604744      -0.59521383     1.4365083\n0.57024884      0.86534977      -0.7953103      0.8168265\n-1.2033914      0.30750957      -0.6741423      0.4655529\n\n(2,1,.,.) =\n-1.9772263      0.49300852      -1.0325992      1.6955665\n1.2885318       -0.827435       1.030415        -0.4615471\n1.8228296       -0.11471669     -1.4945178      0.6462212\n\n(2,2,.,.) =\n0.6531514       0.7014801       -2.2564375      -0.8744255\n-0.5881931      -0.050189503    -0.8783628      0.0753616\n-0.9377223      1.0868944       1.5232987       1.8752075\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.90728825 0.06248136 0.38908736 0.41036892]\n   [0.32752508 0.19828444 0.16125344 0.71703399]\n   [0.91384765 0.10565062 0.5159064  0.11213003]]\n\n  [[0.45955865 0.37912534 0.11220941 0.6227701 ]\n   [0.74682518 0.31436052 0.35600359 0.46670668]\n   [0.17039808 0.01137162 0.06768781 0.48850118]]]\n\n\n [[[0.41052004 0.51787735 0.22106962 0.72647921]\n   [0.69059405 0.22422016 0.55071537 0.33162262]\n   [0.92135018 0.81511106 0.76329409 0.30857876]]\n\n  [[0.02103797 0.62061211 0.06155861 0.48460782]\n   [0.95476727 0.66571869 0.53735588 0.09358965]\n   [0.32302843 0.29893286 0.56494356 0.14670565]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 1.5911555  -1.4893758  -0.2984292  -0.22082737]\n   [-0.52291185 -0.9941791  -1.1292102   0.8974061 ]\n   [ 1.6150738  -1.3319621   0.16400792 -1.3083354 ]]\n\n  [[ 0.3420891   0.02168216 -1.0415802   0.99224377]\n   [ 1.4864182  -0.2363091  -0.07042356  0.37056333]\n   [-0.809785   -1.4432687  -1.2189325   0.45738205]]]\n\n\n [[[-0.2202763   0.17119484 -0.91109455  0.9318476 ]\n   [ 0.8009946  -0.8996063   0.29093656 -0.5079704 ]\n   [ 1.6424314   1.2550375   1.0660906  -0.59199834]]\n\n  [[-1.4047626   0.98364717 -1.2433482   0.44187275]\n   [ 2.314758    1.1633297   0.6519953  -1.1157522 ]\n   [-0.20178048 -0.2977654   0.761891   -0.9041641 ]]]]\n\n\n\n\n\n\nLRN2D\n\n\nLocal Response Normalization between different feature maps.\n\n\nScala:\n\n\nLRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nLRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Double. The scaling parameter. Default is 0.0001.\n\n\nk\n: Double. A constant. Default is 1.0.\n\n\nbeta\n: Double. The exponent. Default is 0.75.\n\n\nn\n: The number of channels to sum over. Default is 5.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering = \ntf\n, inputShape = Shape(3, 3, 3)))\nval input = Tensor[Float](2, 3, 3, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6331058      -1.1622255      -0.20002009\n0.031907756     1.4720777       0.36692062\n0.16142464      -0.87992615     1.9201758\n\n(1,2,.,.) =\n-1.0693451      -1.0901353      0.6909652\n0.13340907      1.0220904       -1.0232266\n-1.4288133      0.8749622       -0.07012164\n\n(1,3,.,.) =\n-0.04984741     -1.4627954      1.2438095\n1.5584376       -0.36223406     -0.862751\n-0.68516856     -0.0066024275   -0.55539906\n\n(2,1,.,.) =\n1.8261654       -0.39168724     0.4531422\n-0.09046966     0.61876625      0.4553172\n0.58150214      -2.6587567      0.46114618\n\n(2,2,.,.) =\n0.75011647      -2.220607       -1.4024881\n-0.5560173      0.19422908      -2.5069134\n-0.7417007      1.3029631       -0.660577\n\n(2,3,.,.) =\n-0.17827246     1.8794266       1.2124214\n0.5774041       0.25620413      0.6461205\n0.33391082      -0.532468       1.3129597\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.5884632      -1.0802679      -0.1859234\n0.02965645      1.3681923       0.34102687\n0.15005784      -0.81763095     1.7842402\n\n(1,2,.,.) =\n-0.9938776      -1.0131469      0.6422488\n0.12401139      0.94998133      -0.95103925\n-1.3279068      0.81316966      -0.065184206\n\n(1,3,.,.) =\n-0.046330474    -1.3593558      1.1558554\n1.4484164       -0.33663353     -0.8019933\n-0.63694555     -0.0061375294   -0.5163186\n\n(2,1,.,.) =\n1.6970686       -0.36398944     0.42125463\n-0.08410302     0.5752084       0.4232657\n0.54015917      -2.469669       0.4283661\n\n(2,2,.,.) =\n0.6969334       -2.0627165      -1.3028492\n-0.5168911      0.18043552      -2.32896\n-0.68936265     1.210961        -0.6139712\n\n(2,3,.,.) =\n-0.16566847     1.7462649       1.1265225\n0.53676987      0.23816296      0.60064477\n0.31041232      -0.49490157     1.2203434\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import LRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering=\ntf\n, input_shape=(3, 3, 3)))\ninput = np.random.random([2, 3, 3, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.56356835, 0.57442602, 0.31515783],\n   [0.64858065, 0.45682821, 0.63889742],\n   [0.56114806, 0.32727298, 0.54948325]],\n\n  [[0.25249933, 0.27872938, 0.2341261 ],\n   [0.22254477, 0.0855324 , 0.95981825],\n   [0.55280765, 0.722852  , 0.95902286]],\n\n  [[0.65021279, 0.00722661, 0.64386904],\n   [0.36467587, 0.84466816, 0.05716471],\n   [0.16279813, 0.57831132, 0.52848513]]],\n\n\n [[[0.94372659, 0.32741784, 0.03196349],\n   [0.06181632, 0.8300082 , 0.36091632],\n   [0.4961609 , 0.5816011 , 0.95777095]],\n\n  [[0.12676416, 0.32625023, 0.58114797],\n   [0.05347868, 0.5303113 , 0.20170834],\n   [0.76583324, 0.39418884, 0.84815322]],\n\n  [[0.62523604, 0.56888912, 0.69009855],\n   [0.34074716, 0.05078519, 0.05212047],\n   [0.50672308, 0.30567418, 0.47902636]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.5238933 , 0.53398067, 0.2929779 ],\n   [0.602922  , 0.42464924, 0.59392124],\n   [0.52165645, 0.30423048, 0.5108133 ]],\n\n  [[0.23473667, 0.2591199 , 0.21765617],\n   [0.20689127, 0.07950803, 0.8922195 ],\n   [0.51387984, 0.6718813 , 0.89142925]],\n\n  [[0.604453  , 0.00671771, 0.59855634],\n   [0.3389953 , 0.7851862 , 0.05313992],\n   [0.15134202, 0.53759885, 0.49128178]]],\n\n\n [[[0.87725437, 0.30435583, 0.02971505],\n   [0.05746418, 0.77156085, 0.33550152],\n   [0.46123454, 0.54060525, 0.89028406]],\n\n  [[0.11784688, 0.30328864, 0.5402475 ],\n   [0.04971581, 0.4929952 , 0.1875149 ],\n   [0.7119114 , 0.36640498, 0.7884236 ]],\n\n  [[0.58121526, 0.5288076 , 0.64150494],\n   [0.31677726, 0.04721269, 0.04845466],\n   [0.4710655 , 0.28415698, 0.44531912]]]]\n\n\n\n\n\n\nWithinChannelLRN2D\n\n\nThe local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size).\n\n\nScala:\n\n\nWithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null)\n\n\n\n\nPython:\n\n\nWithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: The side length of the square region to sum over. Default is 5.\n\n\nalpha\n: The scaling parameter. Default is 1.0.\n\n\nbeta\n: The exponent. Default is 0.75.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](1, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.11547339     -0.52518076     0.22743009      0.24847448\n-0.72996384     1.5127875       1.285603        -0.8665928\n2.2911248       0.062601104     -0.07974513     -0.26207858\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.089576244    -0.39988548     0.17317083      0.21585277\n-0.5662553      1.1518734       0.97888964      -0.7528196\n1.7772957       0.047666013     -0.060719892    -0.22767082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import WithinChannelLRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WithinChannelLRN2D(input_shape=(3, 4)))\ninput = np.random.random([1, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.96982874, 0.80581477, 0.35435895, 0.45537825],\n  [0.61421818, 0.54708709, 0.86205409, 0.07374387],\n  [0.67227822, 0.25118575, 0.36258901, 0.28671433]]]\n\n\n\n\nOutput is\n\n\n[[[0.87259495, 0.71950066, 0.3164021 , 0.42620906],\n  [0.55263746, 0.48848635, 0.76971596, 0.06902022],\n  [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#batchnormalization", 
            "text": "Batch normalization layer.  Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.  It is a feature-wise normalization, each feature map in the input will be normalized separately.  The input of this layer should be 4D.  Scala:  BatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit =  zero , gammaInit =  one , dimOrdering =  th , inputShape = null)  Python:  BatchNormalization(epsilon=0.001, momentum=0.99, beta_init= zero , gamma_init= one , dim_ordering= th , input_shape=None, name=None)  Parameters:   epsilon : Fuzz parameter. Default is 0.001.  momentum : Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.  betaInit : Name of initialization function for shift parameter. See  here  for available initialization strings. Default is 'zero'.  gammaInit : Name of initialization function for scale parameter. See  here  for available initialization strings. Default is 'one'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.BatchNormalization\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.35774308      -0.0018262876   -1.0186636      -0.8283433\n0.1458402       -0.8954456      0.65028995      0.74481136\n0.46434486      -0.33841616     -0.2882468      0.27368018\n\n(1,2,.,.) =\n-0.85313565     -1.0957539      -0.7689828      1.7338694\n0.66673565      1.0302666       -1.0154791      0.9704916\n-1.518189       0.34307054      -0.8662138      0.53776205\n\n(2,1,.,.) =\n-1.5997988      0.4131082       -0.83005565     1.3930303\n1.061352        -0.6628746      0.8510218       -0.36472544\n1.4967325       -0.082105584    -1.2064567      0.5379558\n\n(2,2,.,.) =\n0.76886225      0.8283977       -2.815423       -1.1129401\n-0.76033413     -0.09757436     -1.1177903      0.057090428\n-1.1909146      1.3031846       1.8407855       2.2742975\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.42506456      -0.016198127    -1.2640586      -1.0304978\n0.16501783      -1.1128457      0.7840774       0.9000738\n0.55588603      -0.4292604      -0.3676927      0.32190278\n\n(1,2,.,.) =\n-0.66352594     -0.8604744      -0.59521383     1.4365083\n0.57024884      0.86534977      -0.7953103      0.8168265\n-1.2033914      0.30750957      -0.6741423      0.4655529\n\n(2,1,.,.) =\n-1.9772263      0.49300852      -1.0325992      1.6955665\n1.2885318       -0.827435       1.030415        -0.4615471\n1.8228296       -0.11471669     -1.4945178      0.6462212\n\n(2,2,.,.) =\n0.6531514       0.7014801       -2.2564375      -0.8744255\n-0.5881931      -0.050189503    -0.8783628      0.0753616\n-0.9377223      1.0868944       1.5232987       1.8752075\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.90728825 0.06248136 0.38908736 0.41036892]\n   [0.32752508 0.19828444 0.16125344 0.71703399]\n   [0.91384765 0.10565062 0.5159064  0.11213003]]\n\n  [[0.45955865 0.37912534 0.11220941 0.6227701 ]\n   [0.74682518 0.31436052 0.35600359 0.46670668]\n   [0.17039808 0.01137162 0.06768781 0.48850118]]]\n\n\n [[[0.41052004 0.51787735 0.22106962 0.72647921]\n   [0.69059405 0.22422016 0.55071537 0.33162262]\n   [0.92135018 0.81511106 0.76329409 0.30857876]]\n\n  [[0.02103797 0.62061211 0.06155861 0.48460782]\n   [0.95476727 0.66571869 0.53735588 0.09358965]\n   [0.32302843 0.29893286 0.56494356 0.14670565]]]]  Output is  [[[[ 1.5911555  -1.4893758  -0.2984292  -0.22082737]\n   [-0.52291185 -0.9941791  -1.1292102   0.8974061 ]\n   [ 1.6150738  -1.3319621   0.16400792 -1.3083354 ]]\n\n  [[ 0.3420891   0.02168216 -1.0415802   0.99224377]\n   [ 1.4864182  -0.2363091  -0.07042356  0.37056333]\n   [-0.809785   -1.4432687  -1.2189325   0.45738205]]]\n\n\n [[[-0.2202763   0.17119484 -0.91109455  0.9318476 ]\n   [ 0.8009946  -0.8996063   0.29093656 -0.5079704 ]\n   [ 1.6424314   1.2550375   1.0660906  -0.59199834]]\n\n  [[-1.4047626   0.98364717 -1.2433482   0.44187275]\n   [ 2.314758    1.1633297   0.6519953  -1.1157522 ]\n   [-0.20178048 -0.2977654   0.761891   -0.9041641 ]]]]", 
            "title": "BatchNormalization"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#lrn2d", 
            "text": "Local Response Normalization between different feature maps.  Scala:  LRN2D(alpha = 1e-4, k = 1.0, beta = 0.75, n = 5, dimOrdering =  th , inputShape = null)  Python:  LRN2D(alpha=1e-4, k=1.0, beta=0.75, n=5, dim_ordering= th , input_shape=None, name=None)  Parameters:   alpha : Double. The scaling parameter. Default is 0.0001.  k : Double. A constant. Default is 1.0.  beta : Double. The exponent. Default is 0.75.  n : The number of channels to sum over. Default is 5.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.LRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LRN2D[Float](1e-3, 1.2, 0.4, 3, dimOrdering =  tf , inputShape = Shape(3, 3, 3)))\nval input = Tensor[Float](2, 3, 3, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6331058      -1.1622255      -0.20002009\n0.031907756     1.4720777       0.36692062\n0.16142464      -0.87992615     1.9201758\n\n(1,2,.,.) =\n-1.0693451      -1.0901353      0.6909652\n0.13340907      1.0220904       -1.0232266\n-1.4288133      0.8749622       -0.07012164\n\n(1,3,.,.) =\n-0.04984741     -1.4627954      1.2438095\n1.5584376       -0.36223406     -0.862751\n-0.68516856     -0.0066024275   -0.55539906\n\n(2,1,.,.) =\n1.8261654       -0.39168724     0.4531422\n-0.09046966     0.61876625      0.4553172\n0.58150214      -2.6587567      0.46114618\n\n(2,2,.,.) =\n0.75011647      -2.220607       -1.4024881\n-0.5560173      0.19422908      -2.5069134\n-0.7417007      1.3029631       -0.660577\n\n(2,3,.,.) =\n-0.17827246     1.8794266       1.2124214\n0.5774041       0.25620413      0.6461205\n0.33391082      -0.532468       1.3129597\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.5884632      -1.0802679      -0.1859234\n0.02965645      1.3681923       0.34102687\n0.15005784      -0.81763095     1.7842402\n\n(1,2,.,.) =\n-0.9938776      -1.0131469      0.6422488\n0.12401139      0.94998133      -0.95103925\n-1.3279068      0.81316966      -0.065184206\n\n(1,3,.,.) =\n-0.046330474    -1.3593558      1.1558554\n1.4484164       -0.33663353     -0.8019933\n-0.63694555     -0.0061375294   -0.5163186\n\n(2,1,.,.) =\n1.6970686       -0.36398944     0.42125463\n-0.08410302     0.5752084       0.4232657\n0.54015917      -2.469669       0.4283661\n\n(2,2,.,.) =\n0.6969334       -2.0627165      -1.3028492\n-0.5168911      0.18043552      -2.32896\n-0.68936265     1.210961        -0.6139712\n\n(2,3,.,.) =\n-0.16566847     1.7462649       1.1265225\n0.53676987      0.23816296      0.60064477\n0.31041232      -0.49490157     1.2203434\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import LRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(LRN2D(1e-3, 1.2, 0.4, 3, dim_ordering= tf , input_shape=(3, 3, 3)))\ninput = np.random.random([2, 3, 3, 3])\noutput = model.forward(input)  Input is:  [[[[0.56356835, 0.57442602, 0.31515783],\n   [0.64858065, 0.45682821, 0.63889742],\n   [0.56114806, 0.32727298, 0.54948325]],\n\n  [[0.25249933, 0.27872938, 0.2341261 ],\n   [0.22254477, 0.0855324 , 0.95981825],\n   [0.55280765, 0.722852  , 0.95902286]],\n\n  [[0.65021279, 0.00722661, 0.64386904],\n   [0.36467587, 0.84466816, 0.05716471],\n   [0.16279813, 0.57831132, 0.52848513]]],\n\n\n [[[0.94372659, 0.32741784, 0.03196349],\n   [0.06181632, 0.8300082 , 0.36091632],\n   [0.4961609 , 0.5816011 , 0.95777095]],\n\n  [[0.12676416, 0.32625023, 0.58114797],\n   [0.05347868, 0.5303113 , 0.20170834],\n   [0.76583324, 0.39418884, 0.84815322]],\n\n  [[0.62523604, 0.56888912, 0.69009855],\n   [0.34074716, 0.05078519, 0.05212047],\n   [0.50672308, 0.30567418, 0.47902636]]]]  Output is  [[[[0.5238933 , 0.53398067, 0.2929779 ],\n   [0.602922  , 0.42464924, 0.59392124],\n   [0.52165645, 0.30423048, 0.5108133 ]],\n\n  [[0.23473667, 0.2591199 , 0.21765617],\n   [0.20689127, 0.07950803, 0.8922195 ],\n   [0.51387984, 0.6718813 , 0.89142925]],\n\n  [[0.604453  , 0.00671771, 0.59855634],\n   [0.3389953 , 0.7851862 , 0.05313992],\n   [0.15134202, 0.53759885, 0.49128178]]],\n\n\n [[[0.87725437, 0.30435583, 0.02971505],\n   [0.05746418, 0.77156085, 0.33550152],\n   [0.46123454, 0.54060525, 0.89028406]],\n\n  [[0.11784688, 0.30328864, 0.5402475 ],\n   [0.04971581, 0.4929952 , 0.1875149 ],\n   [0.7119114 , 0.36640498, 0.7884236 ]],\n\n  [[0.58121526, 0.5288076 , 0.64150494],\n   [0.31677726, 0.04721269, 0.04845466],\n   [0.4710655 , 0.28415698, 0.44531912]]]]", 
            "title": "LRN2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#withinchannellrn2d", 
            "text": "The local response normalization layer performs a kind of \"lateral inhibition\" by normalizing over local input regions. The local regions extend spatially, in separate channels (i.e., they have shape 1 x size x size).  Scala:  WithinChannelLRN2D(size = 5, alpha = 1.0, beta = 0.75, inputShape = null)  Python:  WithinChannelLRN2D(size=5, alpha=1.0, beta=0.75, input_shape=None, name=None)  Parameters:   size : The side length of the square region to sum over. Default is 5.  alpha : The scaling parameter. Default is 1.0.  beta : The exponent. Default is 0.75.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.WithinChannelLRN2D\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(WithinChannelLRN2D[Float](inputShape = Shape(3, 4)))\nval input = Tensor[Float](1, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.11547339     -0.52518076     0.22743009      0.24847448\n-0.72996384     1.5127875       1.285603        -0.8665928\n2.2911248       0.062601104     -0.07974513     -0.26207858\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.089576244    -0.39988548     0.17317083      0.21585277\n-0.5662553      1.1518734       0.97888964      -0.7528196\n1.7772957       0.047666013     -0.060719892    -0.22767082\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import WithinChannelLRN2D\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WithinChannelLRN2D(input_shape=(3, 4)))\ninput = np.random.random([1, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.96982874, 0.80581477, 0.35435895, 0.45537825],\n  [0.61421818, 0.54708709, 0.86205409, 0.07374387],\n  [0.67227822, 0.25118575, 0.36258901, 0.28671433]]]  Output is  [[[0.87259495, 0.71950066, 0.3164021 , 0.42620906],\n  [0.55263746, 0.48848635, 0.76971596, 0.06902022],\n  [0.60487646, 0.22428022, 0.32375062, 0.26834887]]]", 
            "title": "WithinChannelLRN2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/", 
            "text": "SparseEmbedding\n\n\nSparseEmbedding is the sparse version of layer Embedding.\n\n\nThe input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors.\nIf the input is a SparseTensor, the values are positive integer ids,\nvalues in each row of this SparseTensor will be turned into a dense vector.\nIf the input is two SparseTensors, the first tensor should be the integer ids, just\nlike the SparseTensor input. And the second tensor is the corresponding\nweights of the integer ids.\n\n\nThis layer can only be used as the first layer in a model, you need to provide the argument\ninputShape (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nSparseEmbedding(inputDim, outputDim, combiner = \nsum\n, max_norm = -1.0, init = \nuniform\n, wRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSparseEmbedding(input_dim, output_dim, combiner=\nsum\n, max_norm=-1.0, init=\nuniform\n, W_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputDim\n: Int \n 0. Size of the vocabulary.\n\n\noutputDim\n: Int \n= 0. Dimension of the dense embedding.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. Default is \"uniform\".\n\n\ncombiner\n: A string specifying the reduce type.\n              Currently \"mean\", \"sum\", \"sqrtn\" is supported.\n\n\nmaxNorm\n: If provided, each embedding is normalized to have l2 norm equal to\n               maxNorm before combining.\n\n\nwRegularizer\n: An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer.\n          If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4,\n  combiner = \nsum\n, inputShape = Shape(10))\nlayer.build(Shape(-1, 10))\nval output = layer.forward(input)\n\n\n\n\nInput is:\n\n\ninput: \n(0, 0) : 2.0\n(0, 1) : 4.0\n(1, 0) : 1.0\n(2, 3) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]\n\n\n\n\nOutput is:\n\n\n-0.03674142 -0.01844017 -0.015794257    -0.045957662    \n-0.02645839 -0.024193227    -0.046255145    -0.047514524    \n-0.042759597    0.002117775 -0.041510757    1.9092667E-4    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, )))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\nJTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float\n\n\n\n\nOutput is\n\n\n[[ 0.00771878 -0.05676365  0.03861053  0.04300173]\n [-0.04647886 -0.03346863  0.04642192 -0.0145219 ]\n [ 0.03964841  0.0243053   0.04841208  0.04862341]]\n\n\n\n\n\n\nWordEmbedding\n\n\nEmbedding layer that directly loads pre-trained word vectors as weights.\n\n\nTurn non-negative integers (indices) into dense vectors of fixed size.\n\n\nCurrently only GloVe embedding is supported.\n\n\nThe input of this layer should be 2D.\n\n\nThis layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension).\n\n\nScala:\n\n\nWordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)\n\n\n\n\nPython:\n\n\nWordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nembeddingFile\n: The path to the embedding file.\n                   Currently the following GloVe files are supported:\n                   \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\"\n                   \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\".\n                   You can download them from: https://nlp.stanford.edu/projects/glove/.\n\n\nwordIndex\n: Map of word (String) and its corresponding index (integer).\n               The index is supposed to start from 1 with 0 reserved for unknown words.\n               During the prediction, if you have words that are not in the wordIndex\n               for the training, you can map them to index 0.\n               Default is null. In this case, all the words in the embeddingFile will\n               be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map.\n\n\ntrainable\n: To configure whether the weights of this layer will be updated or not.\n               Only false is supported for now.\n\n\ninputLength\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = Sequential[Double]()\nmodel.add(WordEmbedding[Double](\n/path/to/glove.6B.50d.txt\n, wordIndex = WordEmbedding.getWordIndex(\n/path/to/glove.6B.50d.txt\n), inputLength = 1))\nval input = Tensor(data = Array(0.418), shape = Array(1, 1))\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n0.418\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import WordEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WordEmbedding(\n/path/to/glove.6B.50d.txt\n, word_index=WordEmbedding.get_word_index(\n/path/to/glove.6B.50d.txt\n), input_length=1))\ninput = np.random.random([1, 1])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[0.18575166]])\n\n\n\n\nOutput is\n\n\narray([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]]], dtype=float32)", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/#sparseembedding", 
            "text": "SparseEmbedding is the sparse version of layer Embedding.  The input of SparseEmbedding should be a 2D SparseTensor or two 2D sparseTensors.\nIf the input is a SparseTensor, the values are positive integer ids,\nvalues in each row of this SparseTensor will be turned into a dense vector.\nIf the input is two SparseTensors, the first tensor should be the integer ids, just\nlike the SparseTensor input. And the second tensor is the corresponding\nweights of the integer ids.  This layer can only be used as the first layer in a model, you need to provide the argument\ninputShape (a Single Shape, does not include the batch dimension).  Scala:  SparseEmbedding(inputDim, outputDim, combiner =  sum , max_norm = -1.0, init =  uniform , wRegularizer = null, inputShape = null)  Python:  SparseEmbedding(input_dim, output_dim, combiner= sum , max_norm=-1.0, init= uniform , W_regularizer=None, input_shape=None, name=None)  Parameters:   inputDim : Int   0. Size of the vocabulary.  outputDim : Int  = 0. Dimension of the dense embedding.  init : String representation of the initialization method for the weights of the layer. Default is \"uniform\".  combiner : A string specifying the reduce type.\n              Currently \"mean\", \"sum\", \"sqrtn\" is supported.  maxNorm : If provided, each embedding is normalized to have l2 norm equal to\n               maxNorm before combining.  wRegularizer : An instance of [Regularizer], (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer.\n          If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SparseEmbedding\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval layer = SparseEmbedding[Float](inputDim = 10, outputDim = 4,\n  combiner =  sum , inputShape = Shape(10))\nlayer.build(Shape(-1, 10))\nval output = layer.forward(input)  Input is:  input: \n(0, 0) : 2.0\n(0, 1) : 4.0\n(1, 0) : 1.0\n(2, 3) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]  Output is:  -0.03674142 -0.01844017 -0.015794257    -0.045957662    \n-0.02645839 -0.024193227    -0.046255145    -0.047514524    \n-0.042759597    0.002117775 -0.041510757    1.9092667E-4    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SparseEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.util.common import JTensor\n\nmodel = Sequential()\nmodel.add(SparseEmbedding(input_dim=10, output_dim=4, input_shape=(4, )))\ninput = JTensor.sparse(\n    a_ndarray=np.array([1, 3, 2, 4]),\n    i_ndarray = np.array([[0, 0, 1, 2],\n             [0, 3, 2, 1]]),\n    shape = np.array([3, 4])\n)\noutput = model.forward(input)  Input is:  JTensor: storage: [1. 3. 2. 4.], shape: [3 4] ,indices [[0 0 1 2]\n [0 3 2 1]], float  Output is  [[ 0.00771878 -0.05676365  0.03861053  0.04300173]\n [-0.04647886 -0.03346863  0.04642192 -0.0145219 ]\n [ 0.03964841  0.0243053   0.04841208  0.04862341]]", 
            "title": "SparseEmbedding"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/#wordembedding", 
            "text": "Embedding layer that directly loads pre-trained word vectors as weights.  Turn non-negative integers (indices) into dense vectors of fixed size.  Currently only GloVe embedding is supported.  The input of this layer should be 2D.  This layer can only be used as the first layer in a model, you need to provide the argument inputLength (a Single Shape, does not include the batch dimension).  Scala:  WordEmbedding(embeddingFile, wordIndex = null, trainable = false, inputLength = -1)  Python:  WordEmbedding(embedding_file, word_index=None, trainable=False, input_length=None, name=None)  Parameters:   embeddingFile : The path to the embedding file.\n                   Currently the following GloVe files are supported:\n                   \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\"\n                   \"glove.6B.300d.txt\", \"glove.42B.300d.txt\", \"glove.840B.300d.txt\".\n                   You can download them from: https://nlp.stanford.edu/projects/glove/.  wordIndex : Map of word (String) and its corresponding index (integer).\n               The index is supposed to start from 1 with 0 reserved for unknown words.\n               During the prediction, if you have words that are not in the wordIndex\n               for the training, you can map them to index 0.\n               Default is null. In this case, all the words in the embeddingFile will\n               be taken into account and you can call WordEmbedding.getWordIndex(embeddingFile) to retrieve the map.  trainable : To configure whether the weights of this layer will be updated or not.\n               Only false is supported for now.  inputLength : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a positive integer. For Python API, it should be a positive int. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.WordEmbedding\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = Sequential[Double]()\nmodel.add(WordEmbedding[Double]( /path/to/glove.6B.50d.txt , wordIndex = WordEmbedding.getWordIndex( /path/to/glove.6B.50d.txt ), inputLength = 1))\nval input = Tensor(data = Array(0.418), shape = Array(1, 1))\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n0.418\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 1x1]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.00.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x50]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import WordEmbedding\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(WordEmbedding( /path/to/glove.6B.50d.txt , word_index=WordEmbedding.get_word_index( /path/to/glove.6B.50d.txt ), input_length=1))\ninput = np.random.random([1, 1])\noutput = model.forward(input)  Input is:  array([[0.18575166]])  Output is  array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]]], dtype=float32)", 
            "title": "WordEmbedding"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/", 
            "text": "SpatialDropout3D\n\n\nSpatial 3D version of Dropout.\n\n\nThis version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.\n\n\nThe input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3)\n\n\nScala:\n\n\nSpatialDropout3D(p = 0.5, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout3D(p=0.5, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.5842006       -1.486708       -1.0261744\n-0.8227147      0.1386223       -0.46191332\n\n(1,1,2,.,.) =\n-0.7794714      0.52259976      1.5326598\n0.32597166      0.84018683      -0.24034925\n\n(1,2,1,.,.) =\n0.5037644       -0.42065156     1.1590574\n1.4855213       -1.4098096      0.5154563\n\n(1,2,2,.,.) =\n2.1119535       0.4159602       -0.33109334\n-1.9544226      0.014503485     -0.7715549\n\n(2,1,1,.,.) =\n1.1496683       0.20273614      -2.6363356\n-1.6820912      -1.1656585      -0.8387814\n\n(2,1,2,.,.) =\n-1.1125584      -1.9073812      0.78532314\n-1.0033096      -0.24038585     1.0534006\n\n(2,2,1,.,.) =\n0.46944886      -1.8767697      0.7275591\n0.36211884      0.34403932      -1.3721423\n\n(2,2,2,.,.) =\n0.37117565      -0.45195773     0.66517854\n0.3873176       -1.8218406      1.9105781\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     -0.0    -0.0\n-0.0    0.0     -0.0\n\n(1,1,2,.,.) =\n-0.0    0.0     0.0\n0.0     0.0     -0.0\n\n(1,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n(1,2,2,.,.) =\n0.0     0.0     -0.0\n-0.0    0.0     -0.0\n\n(2,1,1,.,.) =\n0.0     0.0     -0.0\n-0.0    -0.0    -0.0\n\n(2,1,2,.,.) =\n-0.0    -0.0    0.0\n-0.0    -0.0    0.0\n\n(2,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     0.0     -0.0\n\n(2,2,2,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.19861794 0.32822715]\n    [0.78735804 0.0586697 ]]\n\n   [[0.22181565 0.09894792]\n    [0.43668179 0.22321872]]]\n\n\n  [[[0.81122679 0.44084158]\n    [0.70199098 0.10383273]]\n\n   [[0.78102397 0.62514588]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.22229716 0.90939922]\n    [0.2453606  0.49500498]]\n\n   [[0.95518136 0.78983711]\n    [0.724247   0.62801332]]]\n\n\n  [[[0.89800761 0.5523274 ]\n    [0.83153558 0.58200981]]\n\n   [[0.84787731 0.16651971]\n    [0.22528241 0.68706778]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.19861795 0.32822713]\n    [0.78735805 0.0586697 ]]\n\n   [[0.22181565 0.09894791]\n    [0.43668178 0.22321871]]]\n\n\n  [[[0.8112268  0.4408416 ]\n    [0.70199096 0.10383273]]\n\n   [[0.781024   0.62514585]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.         0.        ]\n    [0.         0.        ]]\n\n   [[0.         0.        ]\n    [0.         0.        ]]]\n\n\n  [[[0.89800763 0.5523274 ]\n    [0.8315356  0.5820098 ]]\n\n   [[0.8478773  0.16651972]\n    [0.22528242 0.6870678 ]]]]]\n\n\n\n\n\n\nDropout\n\n\nApplies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.\n\n\nScala:\n\n\nDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout[Float](0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.5496527       0.34846303      1.8184849       -0.8750735\n-0.2907603      0.124056354     -0.5447822      -0.34512782\n1.003834        -0.27847317     -0.16524693     -0.12172801\n\n(2,.,.) =\n-0.50297844     -0.78188837     -1.5617784      -1.2353797\n-1.5052266      -1.6246556      0.5203618       1.144502\n-0.18044183     -0.032648038    -1.9599762      -0.6970337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n2.2137897       0.49780434      2.5978355       -1.250105\n0.0     0.17722337      0.0     0.0\n1.4340487       0.0     0.0     -0.17389716\n\n(2,.,.) =\n-0.71854067     -1.1169834      -2.231112       -1.7648282\n-2.1503239      -2.3209367      0.743374        1.635003\n-0.25777406     0.0     -2.799966       -0.99576247\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import Dropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815],\n        [0.70987046, 0.11246564, 0.68062359, 0.48074257],\n        [0.61979472, 0.36682032, 0.08320745, 0.41117697]],\n\n       [[0.19616717, 0.18093539, 0.52080897, 0.73326568],\n        [0.72752776, 0.81963229, 0.05652756, 0.37253947],\n        [0.70200807, 0.27836313, 0.24421078, 0.58191582]]])\n\n\n\n\nOutput is\n\n\narray([[[1.1523907 , 0.7672588 , 0.        , 0.6953831 ],\n        [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ],\n        [0.        , 0.5240291 , 0.11886779, 0.58739567]],\n\n       [[0.2802388 , 0.        , 0.74401283, 1.0475224 ],\n        [1.0393254 , 1.1709033 , 0.08075366, 0.53219926],\n        [1.0028687 , 0.39766163, 0.        , 0.8313083 ]]], dtype=float32)\n\n\n\n\n\n\nGaussianDropout\n\n\nApply multiplicative 1-centered Gaussian noise.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the layer. If not specified, its name will by default to be a generated string.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8969221   2.454179    -0.26737544 0.86235714\n-0.61781764 -0.48739514 0.2337097   1.0086832\n1.7666794   -1.120229   -0.28245732 0.845279\n\n(2,.,.) =\n1.2763704   -0.3854067  0.0061038486    0.931373\n0.67848265  -3.098805   -0.1240183  0.36834922\n0.9772534   -0.639048   -0.078967154    1.4179249\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.8251847   4.3458977   -0.6353459  -0.10734326\n-0.4009521  -0.5479114  0.1226105   2.0534828\n-0.03313    -2.271632   0.122886114 -0.44396263\n\n(2,.,.) =\n0.45101312  -0.48233575 0.008046541 2.2945886\n1.3415622   -1.9070724  -0.1681036  0.60575134\n0.88338673  -1.4186113  -0.012104415    0.3102114\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianDropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[ 0.55167758,  0.07427833,  0.59777983,  0.86986969],\n        [ 0.53097779,  0.4174687 ,  0.58065922,  0.73479602],\n        [ 0.43731939,  0.64465237,  0.32946076,  0.59878638]],\n\n       [[ 0.26428987,  0.29575131,  0.36229906,  0.66938424],\n        [ 0.74325536,  0.08672916,  0.35460851,  0.00122828],\n        [ 0.27095285,  0.09442922,  0.02280022,  0.68735133]]])\n\n\n\n\nOutput is\n\n\narray([[[  1.29282939e+00,   7.24226162e-02,   5.17048061e-01,\n           8.93751144e-01],\n        [  5.48077464e-01,  -1.90222517e-01,   4.40389782e-01,\n           1.86340976e+00],\n        [  4.28632259e-01,   1.25118005e+00,   4.43376899e-01,\n           1.07255065e+00]],\n\n       [[ -4.06714790e-02,   9.10973027e-02,   1.28347218e+00,\n           1.03069496e+00],\n        [  2.37148595e+00,   3.56667452e-02,   1.25722930e-01,\n           1.17819163e-05],\n        [  3.79356921e-01,   8.55060294e-02,   3.33660096e-02,\n           3.40193957e-02]]], dtype=float32)\n\n\n\n\n\n\nSpatialDropout2D\n\n\nSpatial 2D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.\n\n\nThe input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last).\n\n\nScala:\n\n\nSpatialDropout2D(p = 0.5, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout2D(p=0.5, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.266674        -0.19261484     0.8210725       -0.22291088\n-0.38138267     1.7019615       1.1729054       0.59097356\n-0.50952524     -1.9868233      -0.17180282     -1.2743127\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     -0.0    0.0     -0.0\n-0.0    0.0     0.0     0.0\n-0.0    -0.0    -0.0    -0.0\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.45638721 0.87479404 0.28319946 0.85046252]\n   [0.90687581 0.29446766 0.23341603 0.92425726]\n   [0.51232495 0.83895807 0.90536451 0.41231943]]\n\n  [[0.00397271 0.28512243 0.32912336 0.27304027]\n   [0.97274043 0.92907157 0.25843125 0.201849  ]\n   [0.42783297 0.91400856 0.19290376 0.83749261]]]\n\n\n [[[0.03282751 0.60866148 0.47616452 0.4300911 ]\n   [0.75731354 0.34609462 0.66514783 0.18193801]\n   [0.6748754  0.94068849 0.38504096 0.66447561]]\n\n  [[0.61274329 0.56573389 0.21795374 0.45314279]\n   [0.2883045  0.22641016 0.83014439 0.21362862]\n   [0.33618578 0.47346473 0.96971251 0.2937416 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.45638722 0.87479407 0.28319946 0.8504625 ]\n   [0.9068758  0.29446766 0.23341602 0.9242573 ]\n   [0.5123249  0.8389581  0.9053645  0.41231942]]\n\n  [[0.00397271 0.28512242 0.32912338 0.27304026]\n   [0.9727404  0.92907155 0.25843126 0.201849  ]\n   [0.42783296 0.91400856 0.19290376 0.8374926 ]]]\n\n\n [[[0.03282751 0.6086615  0.47616452 0.4300911 ]\n   [0.75731355 0.3460946  0.66514784 0.18193801]\n   [0.6748754  0.9406885  0.38504097 0.6644756 ]]\n\n  [[0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]]]]\n\n\n\n\n\n\nGaussianNoise\n\n\nApply additive zero-centered Gaussian noise.\n\n\nThis is useful to mitigate overfitting (you could see it as a form of random data augmentation).\n\n\nGaussian Noise is a natural choice as corruption process for real valued inputs.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianNoise(sigma, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianNoise(sigma, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsigma\n: Standard deviation of the noise distribution.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.57896155     -0.19616802     1.7000706       -2.2136402\n0.2245884       -0.167104       0.08521592      -0.31111532\n-1.2676435      1.9858241       -0.27946314     -0.72280097\n\n(2,.,.) =\n1.263968        -0.1366611      0.7511876       -0.42096275\n-0.2524562      -2.082302       -1.3312799      0.035666652\n-1.6895409      -0.8562052      0.69322604      -0.080461726\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.25664312     0.1474515       2.066732        -1.5476861\n0.34144306      1.1049318       0.4146787       -0.15529981\n-1.3980585      2.0075183       0.09995845      -0.9865419\n\n(2,.,.) =\n0.8450401       0.0076646805    0.5062498       -0.5671178\n0.89790833      -2.1620805      -1.5945435      -0.74607164\n-1.7677919      -0.6946467      0.35671985      0.9388765\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianNoise\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\narray([[[0.87836839, 0.29835789, 0.99199298, 0.61462649],\n        [0.24045628, 0.9334569 , 0.69817451, 0.80795268],\n        [0.82978091, 0.32160601, 0.97033687, 0.34726345]],\n\n       [[0.11581215, 0.2012782 , 0.89101947, 0.24642749],\n        [0.51231345, 0.47586449, 0.53419205, 0.71586367],\n        [0.88794988, 0.20960408, 0.46741968, 0.31609195]]])\n\n\n\n\nOutput is\n\n\narray([[[ 0.9021132 ,  0.05798048,  0.9235187 ,  0.8105377 ],\n        [ 0.82122934,  0.87509984,  1.3449373 ,  0.115228  ],\n        [ 0.2612275 ,  0.02238336,  0.8971698 ,  0.3349191 ]],\n\n       [[-0.7950512 , -0.4547084 ,  1.6517348 ,  1.5761411 ],\n        [ 0.9232183 ,  0.33405185,  0.6043875 ,  0.54677534],\n        [ 1.4350419 , -1.4409285 , -0.31246042,  0.5502143 ]]],\n      dtype=float32)", 
            "title": "Dropout Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout3d", 
            "text": "Spatial 3D version of Dropout.  This version performs the same functionalities as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.  The input is 5D tensor with shape: (batch_size, channels, dim1, dim2, dim3)  Scala:  SpatialDropout3D(p = 0.5, dimOrdering =  th , inputShape = null)  Python:  SpatialDropout3D(p=0.5, dim_ordering= th , input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout3D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D[Float](inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.5842006       -1.486708       -1.0261744\n-0.8227147      0.1386223       -0.46191332\n\n(1,1,2,.,.) =\n-0.7794714      0.52259976      1.5326598\n0.32597166      0.84018683      -0.24034925\n\n(1,2,1,.,.) =\n0.5037644       -0.42065156     1.1590574\n1.4855213       -1.4098096      0.5154563\n\n(1,2,2,.,.) =\n2.1119535       0.4159602       -0.33109334\n-1.9544226      0.014503485     -0.7715549\n\n(2,1,1,.,.) =\n1.1496683       0.20273614      -2.6363356\n-1.6820912      -1.1656585      -0.8387814\n\n(2,1,2,.,.) =\n-1.1125584      -1.9073812      0.78532314\n-1.0033096      -0.24038585     1.0534006\n\n(2,2,1,.,.) =\n0.46944886      -1.8767697      0.7275591\n0.36211884      0.34403932      -1.3721423\n\n(2,2,2,.,.) =\n0.37117565      -0.45195773     0.66517854\n0.3873176       -1.8218406      1.9105781\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     -0.0    -0.0\n-0.0    0.0     -0.0\n\n(1,1,2,.,.) =\n-0.0    0.0     0.0\n0.0     0.0     -0.0\n\n(1,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n(1,2,2,.,.) =\n0.0     0.0     -0.0\n-0.0    0.0     -0.0\n\n(2,1,1,.,.) =\n0.0     0.0     -0.0\n-0.0    -0.0    -0.0\n\n(2,1,2,.,.) =\n-0.0    -0.0    0.0\n-0.0    -0.0    0.0\n\n(2,2,1,.,.) =\n0.0     -0.0    0.0\n0.0     0.0     -0.0\n\n(2,2,2,.,.) =\n0.0     -0.0    0.0\n0.0     -0.0    0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.19861794 0.32822715]\n    [0.78735804 0.0586697 ]]\n\n   [[0.22181565 0.09894792]\n    [0.43668179 0.22321872]]]\n\n\n  [[[0.81122679 0.44084158]\n    [0.70199098 0.10383273]]\n\n   [[0.78102397 0.62514588]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.22229716 0.90939922]\n    [0.2453606  0.49500498]]\n\n   [[0.95518136 0.78983711]\n    [0.724247   0.62801332]]]\n\n\n  [[[0.89800761 0.5523274 ]\n    [0.83153558 0.58200981]]\n\n   [[0.84787731 0.16651971]\n    [0.22528241 0.68706778]]]]]  Output is  [[[[[0.19861795 0.32822713]\n    [0.78735805 0.0586697 ]]\n\n   [[0.22181565 0.09894791]\n    [0.43668178 0.22321871]]]\n\n\n  [[[0.8112268  0.4408416 ]\n    [0.70199096 0.10383273]]\n\n   [[0.781024   0.62514585]\n    [0.6933126  0.7830806 ]]]]\n\n\n\n [[[[0.         0.        ]\n    [0.         0.        ]]\n\n   [[0.         0.        ]\n    [0.         0.        ]]]\n\n\n  [[[0.89800763 0.5523274 ]\n    [0.8315356  0.5820098 ]]\n\n   [[0.8478773  0.16651972]\n    [0.22528242 0.6870678 ]]]]]", 
            "title": "SpatialDropout3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#dropout", 
            "text": "Applies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.  Scala:  Dropout(p, inputShape = null)  Python:  Dropout(p, input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.Dropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout[Float](0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.5496527       0.34846303      1.8184849       -0.8750735\n-0.2907603      0.124056354     -0.5447822      -0.34512782\n1.003834        -0.27847317     -0.16524693     -0.12172801\n\n(2,.,.) =\n-0.50297844     -0.78188837     -1.5617784      -1.2353797\n-1.5052266      -1.6246556      0.5203618       1.144502\n-0.18044183     -0.032648038    -1.9599762      -0.6970337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n2.2137897       0.49780434      2.5978355       -1.250105\n0.0     0.17722337      0.0     0.0\n1.4340487       0.0     0.0     -0.17389716\n\n(2,.,.) =\n-0.71854067     -1.1169834      -2.231112       -1.7648282\n-2.1503239      -2.3209367      0.743374        1.635003\n-0.25777406     0.0     -2.799966       -0.99576247\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import Dropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[0.80667346, 0.5370812 , 0.59039134, 0.48676815],\n        [0.70987046, 0.11246564, 0.68062359, 0.48074257],\n        [0.61979472, 0.36682032, 0.08320745, 0.41117697]],\n\n       [[0.19616717, 0.18093539, 0.52080897, 0.73326568],\n        [0.72752776, 0.81963229, 0.05652756, 0.37253947],\n        [0.70200807, 0.27836313, 0.24421078, 0.58191582]]])  Output is  array([[[1.1523907 , 0.7672588 , 0.        , 0.6953831 ],\n        [1.0141007 , 0.1606652 , 0.9723194 , 0.6867751 ],\n        [0.        , 0.5240291 , 0.11886779, 0.58739567]],\n\n       [[0.2802388 , 0.        , 0.74401283, 1.0475224 ],\n        [1.0393254 , 1.1709033 , 0.08075366, 0.53219926],\n        [1.0028687 , 0.39766163, 0.        , 0.8313083 ]]], dtype=float32)", 
            "title": "Dropout"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiandropout", 
            "text": "Apply multiplicative 1-centered Gaussian noise.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianDropout(p, inputShape = null)  Python:  GaussianDropout(p, input_shape=None, name=None)  Parameters:   p : Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the layer. If not specified, its name will by default to be a generated string.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianDropout\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout[Float](0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.8969221   2.454179    -0.26737544 0.86235714\n-0.61781764 -0.48739514 0.2337097   1.0086832\n1.7666794   -1.120229   -0.28245732 0.845279\n\n(2,.,.) =\n1.2763704   -0.3854067  0.0061038486    0.931373\n0.67848265  -3.098805   -0.1240183  0.36834922\n0.9772534   -0.639048   -0.078967154    1.4179249\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.8251847   4.3458977   -0.6353459  -0.10734326\n-0.4009521  -0.5479114  0.1226105   2.0534828\n-0.03313    -2.271632   0.122886114 -0.44396263\n\n(2,.,.) =\n0.45101312  -0.48233575 0.008046541 2.2945886\n1.3415622   -1.9070724  -0.1681036  0.60575134\n0.88338673  -1.4186113  -0.012104415    0.3102114\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianDropout\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[ 0.55167758,  0.07427833,  0.59777983,  0.86986969],\n        [ 0.53097779,  0.4174687 ,  0.58065922,  0.73479602],\n        [ 0.43731939,  0.64465237,  0.32946076,  0.59878638]],\n\n       [[ 0.26428987,  0.29575131,  0.36229906,  0.66938424],\n        [ 0.74325536,  0.08672916,  0.35460851,  0.00122828],\n        [ 0.27095285,  0.09442922,  0.02280022,  0.68735133]]])  Output is  array([[[  1.29282939e+00,   7.24226162e-02,   5.17048061e-01,\n           8.93751144e-01],\n        [  5.48077464e-01,  -1.90222517e-01,   4.40389782e-01,\n           1.86340976e+00],\n        [  4.28632259e-01,   1.25118005e+00,   4.43376899e-01,\n           1.07255065e+00]],\n\n       [[ -4.06714790e-02,   9.10973027e-02,   1.28347218e+00,\n           1.03069496e+00],\n        [  2.37148595e+00,   3.56667452e-02,   1.25722930e-01,\n           1.17819163e-05],\n        [  3.79356921e-01,   8.55060294e-02,   3.33660096e-02,\n           3.40193957e-02]]], dtype=float32)", 
            "title": "GaussianDropout"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout2d", 
            "text": "Spatial 2D version of Dropout.  This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.  The input of this layer should be 4D tensor with shape: (samples, channels, rows, cols) if data_format='th' (Channel First) or 4D tensor with shape: (samples, rows, cols, channels) if data_format='tf' (Channel Last).  Scala:  SpatialDropout2D(p = 0.5, dimOrdering =  th , inputShape = null)  Python:  SpatialDropout2D(p=0.5, dim_ordering= th , input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SpatialDropout2D\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D[Float](inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.266674        -0.19261484     0.8210725       -0.22291088\n-0.38138267     1.7019615       1.1729054       0.59097356\n-0.50952524     -1.9868233      -0.17180282     -1.2743127\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     -0.0    0.0     -0.0\n-0.0    0.0     0.0     0.0\n-0.0    -0.0    -0.0    -0.0\n\n(1,2,.,.) =\n-0.13727586     -0.7740464      1.2427979       -0.46285817\n-1.747042       1.3353567       1.1310997       -0.26019064\n0.9580778       -0.69689065     -0.77704996     0.704949\n\n(2,1,.,.) =\n0.040080033     0.08806901      0.44471294      0.4693497\n-1.2577269      -2.5343444      -0.5290871      0.73988694\n-0.4042877      -0.20460072     -0.68553877     0.59006995\n\n(2,2,.,.) =\n-0.06227895     -0.9075216      1.226318        1.0563084\n-0.6985987      -0.20155957     0.1005844       -0.49736363\n1.3935218       -2.8411357      -1.6742039      0.26154035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.45638721 0.87479404 0.28319946 0.85046252]\n   [0.90687581 0.29446766 0.23341603 0.92425726]\n   [0.51232495 0.83895807 0.90536451 0.41231943]]\n\n  [[0.00397271 0.28512243 0.32912336 0.27304027]\n   [0.97274043 0.92907157 0.25843125 0.201849  ]\n   [0.42783297 0.91400856 0.19290376 0.83749261]]]\n\n\n [[[0.03282751 0.60866148 0.47616452 0.4300911 ]\n   [0.75731354 0.34609462 0.66514783 0.18193801]\n   [0.6748754  0.94068849 0.38504096 0.66447561]]\n\n  [[0.61274329 0.56573389 0.21795374 0.45314279]\n   [0.2883045  0.22641016 0.83014439 0.21362862]\n   [0.33618578 0.47346473 0.96971251 0.2937416 ]]]]  Output is  [[[[0.45638722 0.87479407 0.28319946 0.8504625 ]\n   [0.9068758  0.29446766 0.23341602 0.9242573 ]\n   [0.5123249  0.8389581  0.9053645  0.41231942]]\n\n  [[0.00397271 0.28512242 0.32912338 0.27304026]\n   [0.9727404  0.92907155 0.25843126 0.201849  ]\n   [0.42783296 0.91400856 0.19290376 0.8374926 ]]]\n\n\n [[[0.03282751 0.6086615  0.47616452 0.4300911 ]\n   [0.75731355 0.3460946  0.66514784 0.18193801]\n   [0.6748754  0.9406885  0.38504097 0.6644756 ]]\n\n  [[0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]\n   [0.         0.         0.         0.        ]]]]", 
            "title": "SpatialDropout2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiannoise", 
            "text": "Apply additive zero-centered Gaussian noise.  This is useful to mitigate overfitting (you could see it as a form of random data augmentation).  Gaussian Noise is a natural choice as corruption process for real valued inputs.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianNoise(sigma, inputShape = null)  Python:  GaussianNoise(sigma, input_shape=None, name=None)  Parameters:   sigma : Standard deviation of the noise distribution.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.GaussianNoise\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise[Float](0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.57896155     -0.19616802     1.7000706       -2.2136402\n0.2245884       -0.167104       0.08521592      -0.31111532\n-1.2676435      1.9858241       -0.27946314     -0.72280097\n\n(2,.,.) =\n1.263968        -0.1366611      0.7511876       -0.42096275\n-0.2524562      -2.082302       -1.3312799      0.035666652\n-1.6895409      -0.8562052      0.69322604      -0.080461726\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.25664312     0.1474515       2.066732        -1.5476861\n0.34144306      1.1049318       0.4146787       -0.15529981\n-1.3980585      2.0075183       0.09995845      -0.9865419\n\n(2,.,.) =\n0.8450401       0.0076646805    0.5062498       -0.5671178\n0.89790833      -2.1620805      -1.5945435      -0.74607164\n-1.7677919      -0.6946467      0.35671985      0.9388765\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import GaussianNoise\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  array([[[0.87836839, 0.29835789, 0.99199298, 0.61462649],\n        [0.24045628, 0.9334569 , 0.69817451, 0.80795268],\n        [0.82978091, 0.32160601, 0.97033687, 0.34726345]],\n\n       [[0.11581215, 0.2012782 , 0.89101947, 0.24642749],\n        [0.51231345, 0.47586449, 0.53419205, 0.71586367],\n        [0.88794988, 0.20960408, 0.46741968, 0.31609195]]])  Output is  array([[[ 0.9021132 ,  0.05798048,  0.9235187 ,  0.8105377 ],\n        [ 0.82122934,  0.87509984,  1.3449373 ,  0.115228  ],\n        [ 0.2612275 ,  0.02238336,  0.8971698 ,  0.3349191 ]],\n\n       [[-0.7950512 , -0.4547084 ,  1.6517348 ,  1.5761411 ],\n        [ 0.9232183 ,  0.33405185,  0.6043875 ,  0.54677534],\n        [ 1.4350419 , -1.4409285 , -0.31246042,  0.5502143 ]]],\n      dtype=float32)", 
            "title": "GaussianNoise"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/", 
            "text": "PReLU\n\n\nApplies parametric ReLU, where parameter varies the slope of the negative part.\n\n\nIt follows: f(x) = max(0, x) + a * min(0, x)\n\n\nScala:\n\n\nPReLU(nOutputPlane = 0, inputShape = null)\n\n\n\n\nPython:\n\n\nPReLU(nOutputPlane=0, input_shape=None)\n\n\n\n\nParameters:\n\n\n\n\nnOutputPlane\n: Input map number. Default is 0,\n                  which means using PReLU in shared version and has only one parameter.\n\n\ninputShape\n:  A Single Shape, does not include the batch dimension.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(PReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.9026888      -1.0402212      1.3878769\n-0.17167428     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.2256722      -0.2600553      1.3878769\n-0.04291857     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import PReLU\n\nmodel = Sequential()\nmodel.add(PReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.61639702 0.08877075 0.93652509]\n [0.38800821 0.76286851 0.95777973]]\n\n\n\n\nOutput is\n\n\n[[0.616397   0.08877075 0.9365251 ]\n [0.3880082  0.7628685  0.9577797 ]]\n\n\n\n\n\n\nELU\n\n\nExponential Linear Unit.\n\n\nIt follows: f(x) =  alpha * (exp(x) - 1.) for x \n 0, f(x) = x for x \n= 0.\n\n\nScala:\n\n\nELU(alpha = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nELU(alpha=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Scale for the negative factor. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]\n\n\n\n\nOutput is\n\n\n[[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]\n\n\n\n\n\n\nSReLU\n\n\nS-shaped Rectified Linear Unit.\n\n\nIt follows: f(x) = t^r + a^r(x - t^r) for x \n= t^r, f(x) = x for t^r \n x \n t^l, f(x) = t^l + a^l(x - t^l) for x \n= t^l.\n\n\nScala:\n\n\nSReLU(tLeftInit = \nzero\n, aLeftInit = \nglorot_uniform\n, tRightInit = \nglorot_uniform\n, aRightInit = \none\n, sharedAxes = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSReLU(t_left_init=\nzero\n, a_left_init=\nglorot_uniform\n, t_right_init=\nglorot_uniform\n, a_right_init=\none\n, shared_axes=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntLeftInit\n: String representation of the initialization method for the left part intercept. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\naLeftInit\n: String representation of the initialization method for the left part slope. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\ntRightInit\n: String representation of ithe nitialization method for the right part intercept. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\naRightInit\n: String representation of the initialization method for the right part slope. See \nhere\n for available initialization strings. Default is 'one'.\n\n\nsharedAxes\n: The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import SReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]\n\n\n\n\nOutput is\n\n\n[[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]\n\n\n\n\n\n\nThresholdedReLU\n\n\nThresholded Rectified Linear Unit.\n\n\nIt follows: f(x) = x for x \n theta, f(x) = 0 otherwise.\n\n\nScala:\n\n\nThresholdedReLU(theta = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nThresholdedReLU(theta=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntheta\n: Threshold location of activation. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import ThresholdedReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]\n\n\n\n\nOutput is\n\n\n[[0.0   0.0   0.0]\n [0.0   0.0   0.0]]", 
            "title": "Advanced Activations"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#prelu", 
            "text": "Applies parametric ReLU, where parameter varies the slope of the negative part.  It follows: f(x) = max(0, x) + a * min(0, x)  Scala:  PReLU(nOutputPlane = 0, inputShape = null)  Python:  PReLU(nOutputPlane=0, input_shape=None)  Parameters:   nOutputPlane : Input map number. Default is 0,\n                  which means using PReLU in shared version and has only one parameter.  inputShape :  A Single Shape, does not include the batch dimension.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.PReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(PReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.9026888      -1.0402212      1.3878769\n-0.17167428     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.2256722      -0.2600553      1.3878769\n-0.04291857     0.08202032      1.2682742\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom zoo.pipeline.api.keras.layers import PReLU\n\nmodel = Sequential()\nmodel.add(PReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.61639702 0.08877075 0.93652509]\n [0.38800821 0.76286851 0.95777973]]  Output is  [[0.616397   0.08877075 0.9365251 ]\n [0.3880082  0.7628685  0.9577797 ]]", 
            "title": "PReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#elu", 
            "text": "Exponential Linear Unit.  It follows: f(x) =  alpha * (exp(x) - 1.) for x   0, f(x) = x for x  = 0.  Scala:  ELU(alpha = 1.0, inputShape = null)  Python:  ELU(alpha=1.0, input_shape=None, name=None)  Parameters:   alpha : Scale for the negative factor. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ELU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ELU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]  Output is  [[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]", 
            "title": "ELU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#srelu", 
            "text": "S-shaped Rectified Linear Unit.  It follows: f(x) = t^r + a^r(x - t^r) for x  = t^r, f(x) = x for t^r   x   t^l, f(x) = t^l + a^l(x - t^l) for x  = t^l.  Scala:  SReLU(tLeftInit =  zero , aLeftInit =  glorot_uniform , tRightInit =  glorot_uniform , aRightInit =  one , sharedAxes = null, inputShape = null)  Python:  SReLU(t_left_init= zero , a_left_init= glorot_uniform , t_right_init= glorot_uniform , a_right_init= one , shared_axes=None, input_shape=None, name=None)  Parameters:   tLeftInit : String representation of the initialization method for the left part intercept. See  here  for available initialization strings. Default is 'zero'.  aLeftInit : String representation of the initialization method for the left part slope. See  here  for available initialization strings. Default is 'glorot_uniform'.  tRightInit : String representation of ithe nitialization method for the right part intercept. See  here  for available initialization strings. Default is 'glorot_uniform'.  aRightInit : String representation of the initialization method for the right part slope. See  here  for available initialization strings. Default is 'one'.  sharedAxes : The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.SReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU[Float](inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import SReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]  Output is  [[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]", 
            "title": "SReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#thresholdedrelu", 
            "text": "Thresholded Rectified Linear Unit.  It follows: f(x) = x for x   theta, f(x) = 0 otherwise.  Scala:  ThresholdedReLU(theta = 1.0, inputShape = null)  Python:  ThresholdedReLU(theta=1.0, input_shape=None, name=None)  Parameters:   theta : Threshold location of activation. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.ThresholdedReLU\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU[Float](inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import ThresholdedReLU\nfrom zoo.pipeline.api.keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]  Output is  [[0.0   0.0   0.0]\n [0.0   0.0   0.0]]", 
            "title": "ThresholdedReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/", 
            "text": "KerasLayerWrapper\n\n\nWrap a torch style layer to keras style layer.\n\n\nThis layer can be built multiple times.\n\n\nScala:\n\n\nKerasLayerWrapper(torchLayer, inputShape = null)\n\n\n\n\nPython:\n\n\nKerasLayerWrapper(torch_layer, input_shape=None)\n\n\n\n\nParameters:\n\n\n\n\ntorchLayer\n: a torch style layer.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.nn.Linear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20))\nmodel.add(dense)\nval input = Tensor[Float](2, 20).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.55278283      -0.5434559      -0.13098523     0.3069534       -0.12007129     0.031956512     -0.019634819    -0.09178751     -1.2957728      1.3516346      1.3507701       -0.93318635     -1.1111038      1.0057137       0.093072094     0.16315712      -0.18079235     0.80998576      0.6703253     0.21223836\n-1.007659       1.5507021       -0.14909777     0.49734116      1.4081444       0.1438721       1.7318599       -1.3321369      -0.6123855      0.43861434     0.9198252       1.1758715       -0.5824179      -0.90594006     -0.33974242     -0.58157283     1.3687168       -2.160458       -0.18854974   0.4541929\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5819317       0.7231704       0.21700777      -0.1763548      0.02167879      0.19229038      0.7264892       -0.7566038      -0.8883222      0.47539598\n-0.92322034     -0.33127156     0.48748493      -0.7715719      1.0859711       0.5226875       -0.6108173      -0.29417562     0.75702786      0.009688854\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom zoo.pipeline.api.keras.layers import KerasLayerWrapper\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.nn.layer import Linear\n\nmodel = Sequential()\nmodel.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, )))\ninput = np.random.random([2, 20])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444,\n  0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214,\n  0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721,\n  0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057],\n [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703,\n  0.74951992, 0.71846465, 0.72513163, 0.141432  , 0.54936796,\n  0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522,\n  0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]]\n\n\n\n\nOutput is\n\n\n[[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539,\n   0.03494176, -0.66940045,  0.6229225 ,  0.38492152, -0.527405  ],\n [-0.36529738, -0.57997525,  0.08127502, -0.7578952 , -0.1762895 ,\n  -0.10188193, -0.18423618,  0.37726521,  0.21360731, -0.5451691 ]]", 
            "title": "Layer Wrappers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/#keraslayerwrapper", 
            "text": "Wrap a torch style layer to keras style layer.  This layer can be built multiple times.  Scala:  KerasLayerWrapper(torchLayer, inputShape = null)  Python:  KerasLayerWrapper(torch_layer, input_shape=None)  Parameters:   torchLayer : a torch style layer.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.zoo.pipeline.api.keras.layers.KerasLayerWrapper\nimport com.intel.analytics.zoo.pipeline.api.keras.models.Sequential\nimport com.intel.analytics.bigdl.nn.Linear\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval dense = new KerasLayerWrapper[Float](Linear[Float](20, 10), inputShape = Shape(20))\nmodel.add(dense)\nval input = Tensor[Float](2, 20).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.55278283      -0.5434559      -0.13098523     0.3069534       -0.12007129     0.031956512     -0.019634819    -0.09178751     -1.2957728      1.3516346      1.3507701       -0.93318635     -1.1111038      1.0057137       0.093072094     0.16315712      -0.18079235     0.80998576      0.6703253     0.21223836\n-1.007659       1.5507021       -0.14909777     0.49734116      1.4081444       0.1438721       1.7318599       -1.3321369      -0.6123855      0.43861434     0.9198252       1.1758715       -0.5824179      -0.90594006     -0.33974242     -0.58157283     1.3687168       -2.160458       -0.18854974   0.4541929\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x20]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.5819317       0.7231704       0.21700777      -0.1763548      0.02167879      0.19229038      0.7264892       -0.7566038      -0.8883222      0.47539598\n-0.92322034     -0.33127156     0.48748493      -0.7715719      1.0859711       0.5226875       -0.6108173      -0.29417562     0.75702786      0.009688854\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]  Python example:  import numpy as np\nfrom zoo.pipeline.api.keras.layers import KerasLayerWrapper\nfrom zoo.pipeline.api.keras.models import Sequential\nfrom bigdl.nn.layer import Linear\n\nmodel = Sequential()\nmodel.add(KerasLayerWrapper(Linear(20, 10, with_bias=True) , input_shape=(20, )))\ninput = np.random.random([2, 20])\noutput = model.forward(input)  Input is:  [[0.64178322, 0.83031778, 0.67272342, 0.3648695 , 0.37011444,\n  0.87917395, 0.89792049, 0.93706952, 0.14721198, 0.76431214,\n  0.11406789, 0.63280433, 0.72859274, 0.16546726, 0.94027721,\n  0.7184913 , 0.04049882, 0.13775462, 0.88335614, 0.01030057],\n [0.69802784, 0.41952477, 0.79192261, 0.62655966, 0.00229703,\n  0.74951992, 0.71846465, 0.72513163, 0.141432  , 0.54936796,\n  0.18440429, 0.83081221, 0.42115396, 0.35078732, 0.35471522,\n  0.2179049 , 0.95257499, 0.64030687, 0.95059945, 0.31188082]]  Output is  [[-0.0319711 , -0.5341565 , -0.11790018, -0.7164225 , -0.10448539,\n   0.03494176, -0.66940045,  0.6229225 ,  0.38492152, -0.527405  ],\n [-0.36529738, -0.57997525,  0.08127502, -0.7578952 , -0.1762895 ,\n  -0.10188193, -0.18423618,  0.37726521,  0.21360731, -0.5451691 ]]", 
            "title": "KerasLayerWrapper"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/", 
            "text": "This page shows how to train, evaluate or predict a model using the Keras-Style API.\n\n\nYou may refer to the \nUser Guide\n page to see how to define a model in \nPython\n or \nScala\n correspondingly.\n\n\nYou may refer to \nLayers\n section to find all the available layers.\n\n\nAfter defining a model with the Keras-Style API, you can call the following \nmethods\n on the model:\n\n\n\n\nCompile\n\n\nConfigure the learning process. Must be called before \nfit\n or \nevaluate\n.\n\n\nScala:\n\n\ncompile(optimizer, loss, metrics = null)\n\n\n\n\nParameters:\n\n\n\n\noptimizer\n: Optimization method to be used.\n\n\nloss\n: Criterion to be used.\n\n\nmetrics\n: Validation method(s) to be used. Default is null if no validation is needed. \n\n\n\n\nAlternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\")\n\n\nPython\n\n\ncompile(optimizer, loss, metrics=None)\n\n\n\n\nParameters:\n\n\n\n\noptimizer\n: Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'.\n\n\nloss\n: Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see \nhere\n).\n\n\nmetrics\n: List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy'].\n\n\n\n\n\n\nFit\n\n\nTrain a model for a fixed number of epochs on a DataSet.\n\n\nScala:\n\n\nfit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Training dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchSize\n: Number of samples per gradient update. Default is 32.\n\n\nnbEpoch\n: Number of epochs to train. Default is 10.\n\n\nvalidationData\n: RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null.\n\n\n\n\nPython\n\n\nfit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Training data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\ny\n: Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet.\n\n\nbatch_size\n: Number of samples per gradient update. Default is 32.\n\n\nnb_epoch\n: Number of epochs to train. Default is 10.\n\n\nvalidation_data\n: Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays.\n                    Can also be RDD of Sample or ImageSet or TextSet.\n                    Default is None if no validation is involved.\n\n\ndistributed\n: Boolean. Whether to train the model in distributed mode or local mode.\n                 Default is True. In local mode, x and y must both be Numpy arrays.\n\n\n\n\n\n\nEvaluate\n\n\nEvaluate a model on a given dataset in distributed mode.\n\n\nScala:\n\n\nevaluate(x, batchSize = 32)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Evaluation dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchSize\n: Number of samples per batch. Default is 32.\n\n\n\n\nPython\n\n\nevaluate(x, y=None, batch_size=32)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Evaluation data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\ny\n: Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet.\n\n\nbatch_size\n: Number of samples per batch. Default is 32.\n\n\n\n\n\n\nPredict\n\n\nUse a model to do prediction.\n\n\nScala:\n\n\npredict(x, batchPerThread = 4)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchPerThread\n: The total batchSize is batchPerThread * numOfCores.\n\n\n\n\nPython\n\n\npredict(x, batch_per_thread=4, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatch_per_thread\n:\n        The default value is 4.\n        When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False, the total batch size is batch_per_thread * numOfCores.\n\n\ndistributed\n: Boolean. Whether to do prediction in distributed mode or local mode.\n                 Default is True. In local mode, x must be a Numpy array.\n\n\n\n\nUse a model to predict class labels.\n\n\nScala:\n\n\npredictClasses(x, batchPerThread = 4, zeroBasedLabel = true)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction dataset. RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatchPerThread\n: The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions.\n\n\nzeroBasedLabel\n: Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1.\n\n\n\n\nPython\n\n\npredict_classes(x, batch_per_thread=4, zero_based_label=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction data. A Numpy array or RDD of Sample or \nImageSet\n or \nTextSet\n.\n\n\nbatch_per_thread\n:\n        The default value is 4.\n        When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False the total batch size is batch_per_thread * numOfCores.\n\n\nzero_based_label\n: Boolean. Whether result labels start from 0.\n                      Default is True. If False, result labels start from 1.", 
            "title": "Train, evaluate or predict a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#compile", 
            "text": "Configure the learning process. Must be called before  fit  or  evaluate .  Scala:  compile(optimizer, loss, metrics = null)  Parameters:   optimizer : Optimization method to be used.  loss : Criterion to be used.  metrics : Validation method(s) to be used. Default is null if no validation is needed.    Alternatively, one can pass in the corresponding Keras-Style string representations when calling compile. For example: optimizer = \"sgd\", loss = \"mse\", metrics = List(\"accuracy\")  Python  compile(optimizer, loss, metrics=None)  Parameters:   optimizer : Optimization method to be used. One can alternatively pass in the corresponding string representation, such as 'sgd'.  loss : Criterion to be used. One can alternatively pass in the corresponding string representation, such as 'mse'. (see  here ).  metrics : List of validation methods to be used. Default is None if no validation is needed. For convenience, string representations are supported: 'accuracy' (or 'acc'), 'top5accuracy' (or 'top5acc'), 'mae', 'auc', 'treennaccuracy' and 'loss'. For example, you can either use [Accuracy()] or ['accuracy'].", 
            "title": "Compile"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#fit", 
            "text": "Train a model for a fixed number of epochs on a DataSet.  Scala:  fit(x, batchSize = 32\uff0cnbEpoch = 10, validationData = null)  Parameters:   x : Training dataset. RDD of Sample or  ImageSet  or  TextSet .  batchSize : Number of samples per gradient update. Default is 32.  nbEpoch : Number of epochs to train. Default is 10.  validationData : RDD of Sample or ImageSet or TextSet, or null if validation is not configured. Default is null.   Python  fit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)  Parameters:   x : Training data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  y : Labels. A Numpy array. Default is None if x is already Sample RDD or ImageSet or TextSet.  batch_size : Number of samples per gradient update. Default is 32.  nb_epoch : Number of epochs to train. Default is 10.  validation_data : Tuple (x_val, y_val) where x_val and y_val are both Numpy arrays.\n                    Can also be RDD of Sample or ImageSet or TextSet.\n                    Default is None if no validation is involved.  distributed : Boolean. Whether to train the model in distributed mode or local mode.\n                 Default is True. In local mode, x and y must both be Numpy arrays.", 
            "title": "Fit"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#evaluate", 
            "text": "Evaluate a model on a given dataset in distributed mode.  Scala:  evaluate(x, batchSize = 32)  Parameters:   x : Evaluation dataset. RDD of Sample or  ImageSet  or  TextSet .  batchSize : Number of samples per batch. Default is 32.   Python  evaluate(x, y=None, batch_size=32)  Parameters:   x : Evaluation data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  y : Labels. Default is None if x is set already. A Numpy array or RDD of Sample or ImageSet or TextSet.  batch_size : Number of samples per batch. Default is 32.", 
            "title": "Evaluate"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#predict", 
            "text": "Use a model to do prediction.  Scala:  predict(x, batchPerThread = 4)  Parameters:   x : Prediction dataset. RDD of Sample or  ImageSet  or  TextSet .  batchPerThread : The total batchSize is batchPerThread * numOfCores.   Python  predict(x, batch_per_thread=4, distributed=True)  Parameters:   x : Prediction data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  batch_per_thread :\n        The default value is 4.\n        When distributed is True, the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False, the total batch size is batch_per_thread * numOfCores.  distributed : Boolean. Whether to do prediction in distributed mode or local mode.\n                 Default is True. In local mode, x must be a Numpy array.   Use a model to predict class labels.  Scala:  predictClasses(x, batchPerThread = 4, zeroBasedLabel = true)  Parameters:   x : Prediction dataset. RDD of Sample or  ImageSet  or  TextSet .  batchPerThread : The default value is 4, and the total batchSize is batchPerThread * rdd.getNumPartitions.  zeroBasedLabel : Boolean. Whether result labels start from 0. Default is true. If false, result labels start from 1.   Python  predict_classes(x, batch_per_thread=4, zero_based_label=True)  Parameters:   x : Prediction data. A Numpy array or RDD of Sample or  ImageSet  or  TextSet .  batch_per_thread :\n        The default value is 4.\n        When distributed is True,the total batch size is batch_per_thread * rdd.getNumPartitions.\n        When distributed is False the total batch size is batch_per_thread * numOfCores.  zero_based_label : Boolean. Whether result labels start from 0.\n                      Default is True. If False, result labels start from 1.", 
            "title": "Predict"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/", 
            "text": "Usage of optimizers\n\n\nAn optimizer is one of the two arguments required for compiling a model.\n\n\nScala:\n\n\nmodel.compile(loss = \nmean_squared_error\n, optimizer = \nsgd\n)\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\nScala:\n\n\nmodel.compile(loss = \nmean_squared_error\n, optimizer = Adam())\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer=Adam())\n\n\n\n\n\n\nAvailable optimizers\n\n\nSGD\n\n\nA plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.\n\n\nScala:\n\n\nval optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, \n                      weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, \n                      nesterov = false, learningRateSchedule = Default(), \n                      learningRates = null, weightDecays = null)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\nweightDecay\n : weight decay\n\n\nmomentum\n : momentum\n\n\ndampening\n : dampening for momentum\n\n\nnesterov\n : enables Nesterov momentum\n\n\nlearningRateSchedule\n : learning rate scheduler\n\n\nlearningRates\n : 1D tensor of individual learning rates\n\n\nweightDecays\n : 1D tensor of individual weight decays\n\n\n\n\nPython:\n\n\noptim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, \n                   momentum=0.0, dampening=DOUBLEMAX, nesterov=False, \n                   leaningrate_schedule=None, learningrates=None, \n                   weightdecays=None)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\nweightdecay\n : weight decay\n\n\nmomentum\n : momentum\n\n\ndampening\n : dampening for momentum\n\n\nnesterov\n : enables Nesterov momentum\n\n\nleaningrate_schedule\n : learning rate scheduler\n\n\nlearningrates\n : 1D tensor of individual learning rates\n\n\nweightdecays\n : 1D tensor of individual weight decays\n\n\n\n\nAdam\n\n\nAn implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. \nhttp://arxiv.org/pdf/1412.6980.pdf\n\n\nScala:\n\n\nval optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n learning rate. Default value is 1e-3. \n\n\nlearningRateDecay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nEpsilon\n for numerical stability. Default value is 1e-8.\n\n\n\n\nPython:\n\n\noptim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n learning rate. Default value is 1e-3. \n\n\nlearningrate_decay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nepsilon\n for numerical stability. Default value is 1e-8.\n\n\n\n\nAdamax\n\n\nAn implementation of Adamax: \nhttp://arxiv.org/pdf/1412.6980.pdf\n\n\nScala:\n\n\nval optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nbeta1\n : first moment coefficient\n\n\nbeta2\n : second moment coefficient\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nbeta1\n : first moment coefficient\n\n\nbeta2\n : second moment coefficient\n\n\nepsilon\n : for numerical stability\n\n\n\n\nAdadelta\n\n\nAdaDelta\n implementation for \nSGD\n \nIt has been proposed in \nADADELTA: An Adaptive Learning Rate Method\n.\n\nhttp://arxiv.org/abs/1212.5701.\n\n\nScala:\n\n\nval optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)\n\n\n\n\nParameters:\n\n\n\n\ndecayRate\n : decayRate, also called interpolation parameter rho\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = AdaDelta(decayrate=0.9, epsilon=1e-10)\n\n\n\n\nParameters:\n\n\n\n\ndecayrate\n : decayRate, also called interpolation parameter rho\n\n\nepsilon\n : for numerical stability\n\n\n\n\nAdagrad\n\n\nAn implementation of Adagrad. See the original paper:\n \nhttp://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf\n\n\nScala:\n\n\nval optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0)\n\n\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\nweightDecay\n : weight decay\n\n\n\n\nPython:\n\n\noptim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\nweightdecay\n : weight decay\n\n\n\n\nRmsprop\n\n\nAn implementation of RMSprop (Reference: \nhttp://arxiv.org/pdf/1308.0850v5.pdf\n, Sec 4.2)\n\n\nScala:\n\n\nval optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningRate\n : learning rate\n\n\nlearningRateDecay\n : learning rate decay\n\n\ndecayRate\n : decayRate, also called rho\n\n\nEpsilon\n : for numerical stability\n\n\n\n\nPython:\n\n\noptim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8)\n\n\n\n\nParameters:\n\n\n\n\nlearningrate\n : learning rate\n\n\nlearningrate_decay\n : learning rate decay\n\n\ndecayrate\n : decayRate, also called rho\n\n\nepsilon\n : for numerical stability", 
            "title": "Optimizers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#usage-of-optimizers", 
            "text": "An optimizer is one of the two arguments required for compiling a model.  Scala:  model.compile(loss =  mean_squared_error , optimizer =  sgd )  Python:  model.compile(loss='mean_squared_error', optimizer='sgd')  Scala:  model.compile(loss =  mean_squared_error , optimizer = Adam())  Python:  model.compile(loss='mean_squared_error', optimizer=Adam())", 
            "title": "Usage of optimizers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#available-optimizers", 
            "text": "", 
            "title": "Available optimizers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#sgd", 
            "text": "A plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.  Scala:  val optimMethod = SGD(learningRate = 1e-3, learningRateDecay = 0.0, \n                      weightDecay = 0.0, momentum = 0.0, dampening = Double.MaxValue, \n                      nesterov = false, learningRateSchedule = Default(), \n                      learningRates = null, weightDecays = null)  Parameters:   learningRate  : learning rate  learningRateDecay  : learning rate decay  weightDecay  : weight decay  momentum  : momentum  dampening  : dampening for momentum  nesterov  : enables Nesterov momentum  learningRateSchedule  : learning rate scheduler  learningRates  : 1D tensor of individual learning rates  weightDecays  : 1D tensor of individual weight decays   Python:  optim_method = SGD(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0, \n                   momentum=0.0, dampening=DOUBLEMAX, nesterov=False, \n                   leaningrate_schedule=None, learningrates=None, \n                   weightdecays=None)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  weightdecay  : weight decay  momentum  : momentum  dampening  : dampening for momentum  nesterov  : enables Nesterov momentum  leaningrate_schedule  : learning rate scheduler  learningrates  : 1D tensor of individual learning rates  weightdecays  : 1D tensor of individual weight decays", 
            "title": "SGD"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adam", 
            "text": "An implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions.  http://arxiv.org/pdf/1412.6980.pdf  Scala:  val optimMethod = new Adam(learningRate = 1e-3, learningRateDecay = 0.0, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)  Parameters:   learningRate  learning rate. Default value is 1e-3.   learningRateDecay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  Epsilon  for numerical stability. Default value is 1e-8.   Python:  optim_method = Adam(learningrate=1e-3, learningrate_decay=0.0, beta1=0.9, beta2=0.999, epsilon=1e-8)  Parameters:   learningrate  learning rate. Default value is 1e-3.   learningrate_decay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  epsilon  for numerical stability. Default value is 1e-8.", 
            "title": "Adam"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adamax", 
            "text": "An implementation of Adamax:  http://arxiv.org/pdf/1412.6980.pdf  Scala:  val optimMethod = new Adamax(learningRate = 0.002, beta1 = 0.9, beta2 = 0.999, Epsilon = 1e-8)  Parameters:   learningRate  : learning rate  beta1  : first moment coefficient  beta2  : second moment coefficient  Epsilon  : for numerical stability   Python:  optim_method = Adam(learningrate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8)  Parameters:   learningrate  : learning rate  beta1  : first moment coefficient  beta2  : second moment coefficient  epsilon  : for numerical stability", 
            "title": "Adamax"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adadelta", 
            "text": "AdaDelta  implementation for  SGD  \nIt has been proposed in  ADADELTA: An Adaptive Learning Rate Method . http://arxiv.org/abs/1212.5701.  Scala:  val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)  Parameters:   decayRate  : decayRate, also called interpolation parameter rho  Epsilon  : for numerical stability   Python:  optim_method = AdaDelta(decayrate=0.9, epsilon=1e-10)  Parameters:   decayrate  : decayRate, also called interpolation parameter rho  epsilon  : for numerical stability", 
            "title": "Adadelta"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#adagrad", 
            "text": "An implementation of Adagrad. See the original paper:\n  http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf  Scala:  val optimMethod = new Adagrad(learningRate = 1e-3, learningRateDecay = 0.0, weightDecay = 0.0)   learningRate  : learning rate  learningRateDecay  : learning rate decay  weightDecay  : weight decay   Python:  optim_method = Adagrad(learningrate=1e-3, learningrate_decay=0.0, weightdecay=0.0)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  weightdecay  : weight decay", 
            "title": "Adagrad"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizers/#rmsprop", 
            "text": "An implementation of RMSprop (Reference:  http://arxiv.org/pdf/1308.0850v5.pdf , Sec 4.2)  Scala:  val optimMethod = new RMSprop(learningRate = 0.002, learningRateDecay = 0.0, decayRate = 0.99, Epsilon = 1e-8)  Parameters:   learningRate  : learning rate  learningRateDecay  : learning rate decay  decayRate  : decayRate, also called rho  Epsilon  : for numerical stability   Python:  optim_method = RMSprop(learningrate=0.002, learningrate_decay=0.0, decayrate=0.99, epsilon=1e-8)  Parameters:   learningrate  : learning rate  learningrate_decay  : learning rate decay  decayrate  : decayRate, also called rho  epsilon  : for numerical stability", 
            "title": "Rmsprop"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/", 
            "text": "Usage of objectives\n\n\nAn objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:\n\n\nScala:\n\n\nmodel.compile(loss = \nmean_squared_error\n, optimizer = \nsgd\n)\n\n\n\n\nPython:\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\nScala:\n\n\nmodel.compile(loss = MeanSquaredError(sizeAverage = true), optimizer = \nsgd\n)\n\n\n\n\nPython:\n\n\nmodel.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd')\n\n\n\n\n\n\nAvailable objectives\n\n\nMeanSquaredError\n\n\nThe mean squared error criterion e.g. input: a, target: b, total elements: n\n\n\nloss(a, b) = 1/n * sum(|a_i - b_i|^2)\n\n\n\n\nScala:\n\n\nloss = MeanSquaredError(sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanSquaredError(size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nMeanAbsoluteError\n\n\nMeasures the mean absolute value of the element-wise difference between input and target\n\n\nScala:\n\n\nloss = MeanAbsoluteError(sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanAbsoluteError(size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nBinaryCrossEntropy\n\n\nAlso known as logloss. \n\n\nScala:\n\n\nloss = BinaryCrossEntropy(weights = null, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsizeAverage\n whether to divide the sequence length. Default is true.\n\n\n\n\nPython:\n\n\nloss = BinaryCrossEntropy(weights=None, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsize_average\n whether to divide the sequence length. Default is True.\n\n\n\n\nSparseCategoricalCrossEntropy\n\n\nA loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0.\n\n\nScala:\n\n\nloss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1)\n\n\n\n\nParameters:\n\n\n\n\nlogProbAsInput\n Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.\n\n\nzeroBasedLabel\n Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.\n\n\nweights\n Tensor. Weights of each class if you have an unbalanced training set. Default is null.\n\n\nsizeAverage\n Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch.\n\n\npaddingValue\n Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.\n\n\n\n\nPython:\n\n\nloss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1)\n\n\n\n\nParameters:\n\n\n\n\nlog_prob_as_input\n Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.\n\n\nzero_based_label\n Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.\n\n\nweights\n A Numpy array. Weights of each class if you have an unbalanced training set. Default is None.\n\n\nsize_average\n Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch.\n\n\npadding_value\n Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.\n\n\n\n\nMeanAbsolutePercentageError\n\n\nCompute mean absolute percentage error for intput and target\n\n\nScala:\n\n\nloss = MeanAbsolutePercentageError()\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nPython:\n\n\nloss = MeanAbsolutePercentageError()\n\n\n\n\nParameters:\n\n\n\n\nsize_average\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True\n\n\n\n\nMeanSquaredLogarithmicError\n\n\nCompute mean squared logarithmic error for input and target\n\n\nScala:\n\n\nloss = MeanSquaredLogarithmicError()\n\n\n\n\nPython:\n\n\nloss = MeanSquaredLogarithmicError()\n\n\n\n\nCategoricalCrossEntropy\n\n\nThis is same with cross entropy criterion, except the target tensor is a\none-hot tensor.\n\n\nScala:\n\n\nloss = CategoricalCrossEntropy()\n\n\n\n\nPython:\n\n\nloss = CategoricalCrossEntropy()\n\n\n\n\nHinge\n\n\nCreates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n\n\nScala:\n\n\nloss = Hinge(margin = 1.0, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsizeAverage\n whether to average the loss, is by default true\n\n\n\n\nPython:\n\n\nloss = Hinge(margin=1.0, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsize_average\n whether to average the loss, is by default True\n\n\n\n\nRankHinge\n\n\nHinge loss for pairwise ranking problems.\n\n\nScala:\n\n\nloss = RankHinge(margin = 1.0)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\n\n\nPython:\n\n\nloss = RankHinge(margin=1.0)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\n\n\nSquaredHinge\n\n\nCreates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n\n\nScala:\n\n\nloss = SquaredHinge(margin = 1.0, sizeAverage = true)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsizeAverage\n whether to average the loss, is by default true\n\n\n\n\nPython:\n\n\nloss = SquaredHinge(margin=1.0, size_average=True)\n\n\n\n\nParameters:\n\n\n\n\nmargin\n if unspecified, is by default 1.\n\n\nsize_average\n whether to average the loss, is by default True\n\n\n\n\nPoisson\n\n\nCompute Poisson error for intput and target\n\n\nScala:\n\n\nloss = Poisson()\n\n\n\n\nPython:\n\n\nloss = Poisson()\n\n\n\n\nCosineProximity\n\n\nComputes the negative of the mean cosine proximity between predictions and targets.\n\n\nScala:\n\n\nloss = CosineProximity()\n\n\n\n\nPython:\n\n\nloss = CosineProximity()\n\n\n\n\nKullbackLeiblerDivergence\n\n\nLoss calculated as:\n\n\ny_true = K.clip(y_true, K.epsilon(), 1)\ny_pred = K.clip(y_pred, K.epsilon(), 1)\n\n\n\n\nand output K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n\n\nScala:\n\n\nloss = KullbackLeiblerDivergence()\n\n\n\n\nPython:\n\n\nloss = KullbackLeiblerDivergence()", 
            "title": "Objectives"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#usage-of-objectives", 
            "text": "An objective function (or loss function, or optimization score function) is one of the two parameters required to compile a model:  Scala:  model.compile(loss =  mean_squared_error , optimizer =  sgd )  Python:  model.compile(loss='mean_squared_error', optimizer='sgd')  Scala:  model.compile(loss = MeanSquaredError(sizeAverage = true), optimizer =  sgd )  Python:  model.compile(loss=MeanSquaredError(size_average=True), optimizer='sgd')", 
            "title": "Usage of objectives"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#available-objectives", 
            "text": "", 
            "title": "Available objectives"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meansquarederror", 
            "text": "The mean squared error criterion e.g. input: a, target: b, total elements: n  loss(a, b) = 1/n * sum(|a_i - b_i|^2)  Scala:  loss = MeanSquaredError(sizeAverage = true)  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanSquaredError(size_average=True)  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True", 
            "title": "MeanSquaredError"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meanabsoluteerror", 
            "text": "Measures the mean absolute value of the element-wise difference between input and target  Scala:  loss = MeanAbsoluteError(sizeAverage = true)  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanAbsoluteError(size_average=True)  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True", 
            "title": "MeanAbsoluteError"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#binarycrossentropy", 
            "text": "Also known as logloss.   Scala:  loss = BinaryCrossEntropy(weights = null, sizeAverage = true)  Parameters:   weights  A tensor assigning weight to each of the classes  sizeAverage  whether to divide the sequence length. Default is true.   Python:  loss = BinaryCrossEntropy(weights=None, size_average=True)  Parameters:   weights  A tensor assigning weight to each of the classes  size_average  whether to divide the sequence length. Default is True.", 
            "title": "BinaryCrossEntropy"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#sparsecategoricalcrossentropy", 
            "text": "A loss often used in multi-class classification problems with SoftMax as the last layer of the neural network. By default, input(y_pred) is supposed to be probabilities of each class, and target(y_true) is supposed to be the class label starting from 0.  Scala:  loss = SparseCategoricalCrossEntropy(logProbAsInput = false, zeroBasedLabel = true, weights = null, sizeAverage = true, paddingValue = -1)  Parameters:   logProbAsInput  Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.  zeroBasedLabel  Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.  weights  Tensor. Weights of each class if you have an unbalanced training set. Default is null.  sizeAverage  Boolean. Whether losses are averaged over observations for each mini-batch. Default is true. If false, the losses are instead summed for each mini-batch.  paddingValue  Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.   Python:  loss = SparseCategoricalCrossEntropy(log_prob_as_input=False, zero_based_label=True, weights=None, size_average=True, padding_value=-1)  Parameters:   log_prob_as_input  Boolean. Whether to accept log-probabilities or probabilities as input. Default is false and inputs should be probabilities.  zero_based_label  Boolean. Whether target labels start from 0. Default is true. If false, labels start from 1.  weights  A Numpy array. Weights of each class if you have an unbalanced training set. Default is None.  size_average  Boolean. Whether losses are averaged over observations for each mini-batch. Default is True. If False, the losses are instead summed for each mini-batch.  padding_value  Integer. If the target is set to this value, the training process will skip this sample. In other words, the forward process will return zero output and the backward process will also return zero gradInput. Default is -1.", 
            "title": "SparseCategoricalCrossEntropy"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meanabsolutepercentageerror", 
            "text": "Compute mean absolute percentage error for intput and target  Scala:  loss = MeanAbsolutePercentageError()  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Python:  loss = MeanAbsolutePercentageError()  Parameters:   size_average  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: True", 
            "title": "MeanAbsolutePercentageError"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#meansquaredlogarithmicerror", 
            "text": "Compute mean squared logarithmic error for input and target  Scala:  loss = MeanSquaredLogarithmicError()  Python:  loss = MeanSquaredLogarithmicError()", 
            "title": "MeanSquaredLogarithmicError"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#categoricalcrossentropy", 
            "text": "This is same with cross entropy criterion, except the target tensor is a\none-hot tensor.  Scala:  loss = CategoricalCrossEntropy()  Python:  loss = CategoricalCrossEntropy()", 
            "title": "CategoricalCrossEntropy"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#hinge", 
            "text": "Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.  Scala:  loss = Hinge(margin = 1.0, sizeAverage = true)  Parameters:   margin  if unspecified, is by default 1.  sizeAverage  whether to average the loss, is by default true   Python:  loss = Hinge(margin=1.0, size_average=True)  Parameters:   margin  if unspecified, is by default 1.  size_average  whether to average the loss, is by default True", 
            "title": "Hinge"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#rankhinge", 
            "text": "Hinge loss for pairwise ranking problems.  Scala:  loss = RankHinge(margin = 1.0)  Parameters:   margin  if unspecified, is by default 1.   Python:  loss = RankHinge(margin=1.0)  Parameters:   margin  if unspecified, is by default 1.", 
            "title": "RankHinge"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#squaredhinge", 
            "text": "Creates a criterion that optimizes a two-class classification squared hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.  Scala:  loss = SquaredHinge(margin = 1.0, sizeAverage = true)  Parameters:   margin  if unspecified, is by default 1.  sizeAverage  whether to average the loss, is by default true   Python:  loss = SquaredHinge(margin=1.0, size_average=True)  Parameters:   margin  if unspecified, is by default 1.  size_average  whether to average the loss, is by default True", 
            "title": "SquaredHinge"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#poisson", 
            "text": "Compute Poisson error for intput and target  Scala:  loss = Poisson()  Python:  loss = Poisson()", 
            "title": "Poisson"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#cosineproximity", 
            "text": "Computes the negative of the mean cosine proximity between predictions and targets.  Scala:  loss = CosineProximity()  Python:  loss = CosineProximity()", 
            "title": "CosineProximity"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/objectives/#kullbackleiblerdivergence", 
            "text": "Loss calculated as:  y_true = K.clip(y_true, K.epsilon(), 1)\ny_pred = K.clip(y_pred, K.epsilon(), 1)  and output K.sum(y_true * K.log(y_true / y_pred), axis=-1)  Scala:  loss = KullbackLeiblerDivergence()  Python:  loss = KullbackLeiblerDivergence()", 
            "title": "KullbackLeiblerDivergence"
        }, 
        {
            "location": "/powered-by/", 
            "text": "Powered By\n\n\n\n\n\n\nDell EMC\n: \nAI-assisted Radiology Using Distributed Deep\nLearning on Apache Spark and Analytics Zoo\n \n\n\nMasterCard\n: \nLearning with Analytic Zoo Optimizes Mastercard* Recommender AI Service\n\n\nTalroo\n: \nTalroo\n Uses Analytics Zoo and AWS\n to Leverage Deep Learning for Job Recommendations\n\n\nTencent\n: \nEnhance Tencent's TUSI Identity Practice with Intel Analytics Zoo\n \n\n\nYunda\n: \nIntelligent transformation brings \"quality change\" to the express delivery industry\n \n\n\nMicrosoft Azure\n: \nUse Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 1\n \n\n\nAlibaba\n: \nDeploy Analytics Zoo in Aliyun EMR\n \n\n\nBaosight\n: \nLSTM-Based Time Series Anomaly Detection Using Analytics Zoo for Apache Spark* and BigDL at Baosight\n\n\nMidea\n: \nIndustrial Inspection Platform in Midea\n and KUKA\n: Using Distributed TensorFlow* on Analytics Zoo", 
            "title": "Powered by"
        }, 
        {
            "location": "/powered-by/#powered-by", 
            "text": "Dell EMC :  AI-assisted Radiology Using Distributed Deep\nLearning on Apache Spark and Analytics Zoo    MasterCard :  Learning with Analytic Zoo Optimizes Mastercard* Recommender AI Service  Talroo :  Talroo  Uses Analytics Zoo and AWS  to Leverage Deep Learning for Job Recommendations  Tencent :  Enhance Tencent's TUSI Identity Practice with Intel Analytics Zoo    Yunda :  Intelligent transformation brings \"quality change\" to the express delivery industry    Microsoft Azure :  Use Analytics Zoo to Inject AI Into Customer Service Platforms on Microsoft Azure: Part 1    Alibaba :  Deploy Analytics Zoo in Aliyun EMR    Baosight :  LSTM-Based Time Series Anomaly Detection Using Analytics Zoo for Apache Spark* and BigDL at Baosight  Midea :  Industrial Inspection Platform in Midea  and KUKA : Using Distributed TensorFlow* on Analytics Zoo", 
            "title": "Powered By"
        }, 
        {
            "location": "/presentations/", 
            "text": "Talks:\n\n\n\n\n\n\nLSTM-based time series anomaly detection using Analytics Zoo for Spark and BigDL, \nStrata Data conference\n, May 2019, London (\nslides\n)\n\n\n\n\n\n\nGame Playing Using AI on Apache Spark, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing Deep Learning on Apache Spark to Diagnose Thoracic Pathology from Chest X-rays in DELL EMC, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nLeveraging NLP and Deep Learning for Document Recommendation in the Cloud, \nSpark+AI Summit\n, April 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nAnalytics Zoo: Distributed Tensorflow, Keras and BigDL in production on Apache Spark, \nStrata Data conference\n, March 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nUser-based real-time product recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Office Depot, \nStrata Data conference\n, March 2019, San Francisco (\nslides\n)\n\n\n\n\n\n\nAnalytics Zoo: Unifying Big Data Analytics and AI for Apache Spark, \nShanghai Apache Spark + AI meetup\n, Nov 2018, Shanghai (\nslides\n)\n\n\n\n\n\n\nUse Intel Analytics Zoo to build an intelligent QA Bot for Microsoft Azure, \nShanghai Apache Spark + AI meetup\n, Nov 2018, Shanghai (\nslides\n)\n\n\n\n\n\n\nA deep learning approach for precipitation nowcasting with RNN using Analytics Zoo in Cray, \nStrata Data conference\n, Sep 2018, New York (\nslides\n)\n\n\n\n\n\n\nJob recommendations leveraging deep learning using Analytics Zoo on Apache Spark in Talroo, \nStrata Data conference\n, Sep 2018, New York (\nslides\n)\n\n\n\n\n\n\nAccelerating Deep Learning Training with BigDL and Drizzle on Apache Spark, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing Crowdsourced Images to Create Image Recognition Models with Analytics Zoo in World Bank, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nBuilding Deep Reinforcement Learning Applications on Apache Spark with Analytics Zoo using BigDL, \nSpark + AI Summit\n, June 2018, San Francisco (\nslides\n)\n\n\n\n\n\n\nUsing BigDL on Apache Spark to Improve the MLS Real Estate Search Experience at Scale, \nSpark + AI Summit\n, June 2018, San Francisco\n\n\n\n\n\n\nAnalytics Zoo: Building Analytics and AI Pipeline for Apache Spark and BigDL, \nSpark + AI Summit\n, June 2018, San Francisco\n\n\n\n\n\n\nUsing Siamese CNNs for removing duplicate entries from real estate listing databases, \nStrata Data conference\n, May 2018, London (\nslides\n)\n\n\n\n\n\n\nClassifying images on Spark in World Bank, \nAI conference\n, May 2018, New York (\nslides\n)\n\n\n\n\n\n\nImproving user-merchant propensity modeling using neural collaborative filtering and wide and deep models on Spark BigDL in Mastercard, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)\n\n\n\n\n\n\nAccelerating deep learning on Apache Spark using BigDL with coarse-grained scheduling, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)\n\n\n\n\n\n\nAutomatic 3D MRI knee damage classification with 3D CNN using BigDL on Spark in UCSF, \nStrata Data conference\n, March 2018, San Jose (\nslides\n)", 
            "title": "Presentations"
        }, 
        {
            "location": "/known-issues/", 
            "text": "If you encounter the following exception when calling the Python API of Analytics Zoo when you are using Python 3.5 or 3.6:\n\n\n\n\nPy4JJavaError: An error occurred while calling z:org.apache.spark.bigdl.api.python.BigDLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\n\n\n\nyou may need to check whether your input argument involves Numpy types (such as \nnumpy.int64\n). See \nhere\n for the related issue.\n\n\nFor example, invoking \nnp.min\n, \nnp.max\n, \nnp.unique\n, etc. will return type \nnumpy.int64\n. One way to solve this is to use \nint()\n to convert a number of type \nnumpy.int64\n to a Python int.", 
            "title": "FAQ and Known Issues"
        }
    ]
}