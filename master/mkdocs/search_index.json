{
    "docs": [
        {
            "location": "/", 
            "text": "Analytics Zoo\n\n\nAnalytics + AI Platform for Apache Spark and \nBigDL\n.\n\n\n\n\nWhat is Analytics Zoo?\n\n\nAnalytics Zoo makes it easy to build deep learning application on Spark and BigDL, by providing an end-to-end \nAnalytics + AI Platform\n (including high level pipeline APIs, built-in deep learning models, reference use cases, etc.).\n\n\n\n\n\n\nHigh level pipeline APIs\n\n\n\n\nnnframes\n: native deep learning support in \nSpark DataFrames and ML Pipelines\n\n\nautograd\n: build custom layer/loss using \nauto differentiation operations\n \n\n\nTransfer learning\n: customize pretained model for \nfeature extraction or fine-tuning\n\n\n\n\n\n\n\n\nBuilt-in deep learning models\n\n\n\n\nObject detection API\n: high-level API and pretrained models (e.g., SSD and Faster-RCNN) for \nobject detection\n\n\nImage classification API\n: high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for \nimage classification\n\n\nText classification API\n: high-level API and pre-defined models (using CNN, LSTM, etc.) for \ntext classification\n\n\nRecommedation API\n: high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for \nrecommendation\n\n\n\n\n\n\n\n\nReference use cases\n: a collection of end-to-end \nreference use cases\n (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)\n\n\n\n\n\n\nHow to use Analytics Zoo?\n\n\n\n\n\n\nTo get started, please refer to the \nPython install guide\n or \nScala install guide\n.\n\n\n\n\n\n\nFor more information, You may refer to the \nAnalytis Zoo document website\n\n\n\n\n\n\nFor additional questions and discussions, you can join the \nGoogle User Group\n (or subscribe to the \nMail List\n) \n\n\n\n\n\n\n\n\nHigh level pipeline APIs\n\n\nAnalytics Zoo provides a set of easy-to-use, high level pipeline APIs that natively support Spark DataFrames and ML Pipelines, autograd and custom layer/loss, trasnfer learning, etc.\n\n\nnnframes\n\n\nnnframes\n provides \nnative deep learning support in Spark DataFrames and ML Pipelines\n, so that you can easily build complex deep learning pipelines in just a few lines, as illustracted below. (See more details \nhere\n)\n\n\n1.Initialize \nNNContext\n and load images into \nDataFrames\n using \nNNImageReader\n\n\n   from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   sc = init_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)\n\n\n\n\n2.Process loaded data using \nDataFrames transformations\n\n\n   getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn(\nname\n, getName(col(\nimage\n))).withColumn(\nlabel\n, getLabel(col('name')))\n\n\n\n\n3.Processing image using built-in \nfeature engineering operations\n\n\n   from zoo.feature.image import *\n   transformer = RowToImageFeature() -\n ImageResize(64, 64) -\n ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -\n ImageMatToTensor() -\n ImageFeatureToTensor())\n\n\n\n\n4.Define model using \nKeras-style APIs\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))\n\n\n\n\n5.Train model using \nSpark ML Pipelines\n\n\n   classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol(\nimage\n).setCachingSample(False)\n   nnModel = classifier.fit(df)\n\n\n\n\nautograd\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustracted below. (See more details \nhere\n)\n\n\n1.Define custom functions using \nautograd\n\n\n   from zoo.pipeline.api.autograd import *\n\n   def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)\n\n   def add_one_func(x):\n       return x + 1.0\n\n\n\n\n2.Define model using Keras-style API and \ncustom \nLambda\n layer\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Dense(1, input_shape=(2,))) \\\n                       .add(Lambda(function=add_one_func))\n\n\n\n\n3.Train model with \ncustom loss function\n\n\n   model.compile(optimizer = SGD(), loss = mean_absolute_error)\n   model.fit(x = ..., y = ...)\n\n\n\n\nTransfer learning\n\n\nUsing the high level transfer learning APIs, you can easily customize pretrained models for \nfeature extraction or fine-tuning\n. (See more details \nhere\n)\n\n\n1.Load an existing model (pretrained in Caffe)\n\n\n   from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)\n\n\n\n\n2.Remove last few layers\n\n\n   # create a new model by remove layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\n3.Freeze first few layers\n\n\n   # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\n4.Add a few new layers\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name=\ninput\n, shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)\n\n\n\n\n\n\nBuilt-in deep learning models\n\n\nAnalytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as \nobject detection\n, \nimage classification\n, \ntext classification\n, \nrecommendation\n, etc.\n\n\nObject detection API\n\n\nUsing \nAnalytics Zoo Object Detection API\n (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details \nhere\n)\n\n\n1.Download object detection models in Analytics Zoo\n\n\nYou can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from \ndetection model zoo\n.\n\n\n2.Use \nObject Detection API\n for off-the-shell inference\n\n\n   from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nImage classification API\n\n\nUsing \nAnalytics Zoo Image Classification API\n (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details \nhere\n)\n\n\n1.Download image classification models in Analytics Zoo\n\n\nYou can download a collection of image classification models (pretrained on the ImageNet dataset) from \nimage classification model zoo\n\n\n2.Use \nImage classification API\n for off-the-shell inference\n\n\n   from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nText classification API\n\n\nAnalytics Zoo Text Classification API\n provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details \nhere\n)\n\n\nRecommendation API\n\n\nAnalytics Zoo Recommendation API\n provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details \nhere\n)\n\n\n\n\nReference use cases\n\n\nAnalytics Zoo provides a collection of end-to-end reference use cases, including \nanomaly detection (for time series data)\n, \nsentiment analysis\n, \nfraud detection\n, \nimage augmentation\n, \nobject detection\n, \nvariational autoencoder\n, etc. (See more details \nhere\n)", 
            "title": "Overview"
        }, 
        {
            "location": "/#analytics-zoo", 
            "text": "Analytics + AI Platform for Apache Spark and  BigDL .", 
            "title": "Analytics Zoo"
        }, 
        {
            "location": "/#what-is-analytics-zoo", 
            "text": "Analytics Zoo makes it easy to build deep learning application on Spark and BigDL, by providing an end-to-end  Analytics + AI Platform  (including high level pipeline APIs, built-in deep learning models, reference use cases, etc.).    High level pipeline APIs   nnframes : native deep learning support in  Spark DataFrames and ML Pipelines  autograd : build custom layer/loss using  auto differentiation operations    Transfer learning : customize pretained model for  feature extraction or fine-tuning     Built-in deep learning models   Object detection API : high-level API and pretrained models (e.g., SSD and Faster-RCNN) for  object detection  Image classification API : high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for  image classification  Text classification API : high-level API and pre-defined models (using CNN, LSTM, etc.) for  text classification  Recommedation API : high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for  recommendation     Reference use cases : a collection of end-to-end  reference use cases  (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)", 
            "title": "What is Analytics Zoo?"
        }, 
        {
            "location": "/#how-to-use-analytics-zoo", 
            "text": "To get started, please refer to the  Python install guide  or  Scala install guide .    For more information, You may refer to the  Analytis Zoo document website    For additional questions and discussions, you can join the  Google User Group  (or subscribe to the  Mail List )", 
            "title": "How to use Analytics Zoo?"
        }, 
        {
            "location": "/#high-level-pipeline-apis", 
            "text": "Analytics Zoo provides a set of easy-to-use, high level pipeline APIs that natively support Spark DataFrames and ML Pipelines, autograd and custom layer/loss, trasnfer learning, etc.", 
            "title": "High level pipeline APIs"
        }, 
        {
            "location": "/#nnframes", 
            "text": "nnframes  provides  native deep learning support in Spark DataFrames and ML Pipelines , so that you can easily build complex deep learning pipelines in just a few lines, as illustracted below. (See more details  here )  1.Initialize  NNContext  and load images into  DataFrames  using  NNImageReader     from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   sc = init_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)  2.Process loaded data using  DataFrames transformations     getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn( name , getName(col( image ))).withColumn( label , getLabel(col('name')))  3.Processing image using built-in  feature engineering operations     from zoo.feature.image import *\n   transformer = RowToImageFeature() -  ImageResize(64, 64) -  ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -  ImageMatToTensor() -  ImageFeatureToTensor())  4.Define model using  Keras-style APIs     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))  5.Train model using  Spark ML Pipelines     classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol( image ).setCachingSample(False)\n   nnModel = classifier.fit(df)", 
            "title": "nnframes"
        }, 
        {
            "location": "/#autograd", 
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustracted below. (See more details  here )  1.Define custom functions using  autograd     from zoo.pipeline.api.autograd import *\n\n   def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)\n\n   def add_one_func(x):\n       return x + 1.0  2.Define model using Keras-style API and  custom  Lambda  layer     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Dense(1, input_shape=(2,))) \\\n                       .add(Lambda(function=add_one_func))  3.Train model with  custom loss function     model.compile(optimizer = SGD(), loss = mean_absolute_error)\n   model.fit(x = ..., y = ...)", 
            "title": "autograd"
        }, 
        {
            "location": "/#transfer-learning", 
            "text": "Using the high level transfer learning APIs, you can easily customize pretrained models for  feature extraction or fine-tuning . (See more details  here )  1.Load an existing model (pretrained in Caffe)     from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)  2.Remove last few layers     # create a new model by remove layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([ pool5/drop_7x7_s1 ])  3.Freeze first few layers     # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([ pool4/3x3_s2 ])  4.Add a few new layers     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name= input , shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)", 
            "title": "Transfer learning"
        }, 
        {
            "location": "/#built-in-deep-learning-models", 
            "text": "Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as  object detection ,  image classification ,  text classification ,  recommendation , etc.", 
            "title": "Built-in deep learning models"
        }, 
        {
            "location": "/#object-detection-api", 
            "text": "Using  Analytics Zoo Object Detection API  (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details  here )  1.Download object detection models in Analytics Zoo  You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from  detection model zoo .  2.Use  Object Detection API  for off-the-shell inference     from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Object detection API"
        }, 
        {
            "location": "/#image-classification-api", 
            "text": "Using  Analytics Zoo Image Classification API  (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details  here )  1.Download image classification models in Analytics Zoo  You can download a collection of image classification models (pretrained on the ImageNet dataset) from  image classification model zoo  2.Use  Image classification API  for off-the-shell inference     from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Image classification API"
        }, 
        {
            "location": "/#text-classification-api", 
            "text": "Analytics Zoo Text Classification API  provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details  here )", 
            "title": "Text classification API"
        }, 
        {
            "location": "/#recommendation-api", 
            "text": "Analytics Zoo Recommendation API  provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details  here )", 
            "title": "Recommendation API"
        }, 
        {
            "location": "/#reference-use-cases", 
            "text": "Analytics Zoo provides a collection of end-to-end reference use cases, including  anomaly detection (for time series data) ,  sentiment analysis ,  fraud detection ,  image augmentation ,  object detection ,  variational autoencoder , etc. (See more details  here )", 
            "title": "Reference use cases"
        }, 
        {
            "location": "/release-download/", 
            "text": "Release 0.1.0 nightly build\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload", 
            "title": "Download"
        }, 
        {
            "location": "/release-download/#release-010-nightly-build", 
            "text": "Linux x64      Spark 1.6.0  download    Spark 2.1.0  download    Spark 2.2.0  download", 
            "title": "Release 0.1.0 nightly build"
        }, 
        {
            "location": "/release-docs/", 
            "text": "Release 0.1.1\n\n\nAnalytics-Zoo 0.1 Docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/release-docs/#release-011", 
            "text": "Analytics-Zoo 0.1 Docs", 
            "title": "Release 0.1.1"
        }, 
        {
            "location": "/PythonUserGuide/install/", 
            "text": "For Python users, Analytics Zoo can be installed either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: Only \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\n\n\nInstall from pip\n\n\nAnalytics Zoo can be installed via pip easily using the following command.\n\n\nInstall analytics-zoo-0.1.0.dev2\n\n\n\n\nNote that you might need to add \nsudo\n if you don't have the permission for installation.\n\n\n\n\npip install --upgrade pip\npip install analytics-zoo==0.1.0.dev2     # for Python 2.7\npip3 install analytics-zoo==0.1.0.dev2    # for Python 3.5 and Python 3.6\n\n\n\n\nImportant:\n Please always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nRemarks:\n\n\n\n\nPip install supports \nMac\n and \nLinux\n platforms.\n\n\nPip install only supports \nlocal\n mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to \ninstall without pip\n.\n\n\nIf you use pip install, it is \nnot\n necessary to set \nSPARK_HOME\n.\n\n\nYou need to install Java \n= JDK8\n before running Analytics Zoo, which is required by \npyspark\n.\n\n\nWe've tested this package with pip 9.0.1.\n\n\nbigdl==0.5.0\n and its dependencies will be automatically installed first before installing analytics-zoo if they haven't been detected in the current Python environment.\n\n\n\n\n\n\nInstall without pip\n\n\nIf you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.\n\n\nSteps:\n\n\n\n\n\n\nDownload Spark\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and \n=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\n\n\n\n\nYou can download the Analytics Zoo release and nightly build from the \nRelease Page\n\n  or build the Analytics Zoo package from \nsource\n.\n\n\n\n\n\n\nInstall Python dependencies. Analytics Zoo only depends on \nnumpy\n and \nsix\n for now.\n\n\n\n\n\n\nFor Spark standalone cluster\n\n\n\n\nRemark\n: If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.\n\n\nInstall numpy: \n\nsudo apt-get install python-numpy\n (Ubuntu)\n\n\nInstall six: \n\nsudo apt-get install python-six\n (Ubuntu)\n\n\n\n\nFor Yarn cluster\n\n\nYou can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).\n\n\nYou can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment.\n\n\nFollow the steps below to create the virtual environment: \n\n\n\n\nMake sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first.\nOn Ubuntu, you can run these commands to install:\n\n\n\n\napt-get update\napt-get install -y python-setuptools python-dev\napt-get install -y gcc make\napt-get install -y zip\neasy_install pip\n\n\n\n\n\n\n\n\nCreate the virtualenv package for dependencies.\n\n\n\n\n\n\nUnder $ANALYTICS_ZOO_HOME (the dist directory under the Analytics Zoo project), you can find \nbin/python_package.sh\n. Run this script to create the dependency virtual environment according to the dependencies listed in \nrequirements.txt\n. You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.\n\n\n\n\n\n\nAfter running this script, there will be \nvenv.zip\n and \nvenv\n directory generated in current directory. You can use them to submit your Python jobs. Please refer to \nhere\n for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster.\n\n\n\n\n\n\n\n\n\n\nFAQ\n\n\nIn case you encounter the following errors when you create the environment package using the above command:\n\n\n\n\nvirtualenv ImportError: No module named urllib3\n\n\nUsing python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.\n\n\n\n\n\n\nAttributeError: 'module' object has no attribute 'sslwrap'\n\n\nTry upgrading \ngevent\n with \npip install --upgrade gevent\n.", 
            "title": "Install"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-from-pip", 
            "text": "Analytics Zoo can be installed via pip easily using the following command.  Install analytics-zoo-0.1.0.dev2   Note that you might need to add  sudo  if you don't have the permission for installation.   pip install --upgrade pip\npip install analytics-zoo==0.1.0.dev2     # for Python 2.7\npip3 install analytics-zoo==0.1.0.dev2    # for Python 3.5 and Python 3.6  Important:  Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.  from zoo.common.nncontext import *\nsc = init_nncontext()  Remarks:   Pip install supports  Mac  and  Linux  platforms.  Pip install only supports  local  mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to  install without pip .  If you use pip install, it is  not  necessary to set  SPARK_HOME .  You need to install Java  = JDK8  before running Analytics Zoo, which is required by  pyspark .  We've tested this package with pip 9.0.1.  bigdl==0.5.0  and its dependencies will be automatically installed first before installing analytics-zoo if they haven't been detected in the current Python environment.", 
            "title": "Install from pip"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-without-pip", 
            "text": "If you choose to install Analytics Zoo without pip, you need to prepare Spark and install necessary Python dependencies.  Steps:    Download Spark   Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and  =2.2.0. See  this issue  for more discussion.     You can download the Analytics Zoo release and nightly build from the  Release Page \n  or build the Analytics Zoo package from  source .    Install Python dependencies. Analytics Zoo only depends on  numpy  and  six  for now.", 
            "title": "Install without pip"
        }, 
        {
            "location": "/PythonUserGuide/install/#for-spark-standalone-cluster", 
            "text": "Remark : If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.  Install numpy:  sudo apt-get install python-numpy  (Ubuntu)  Install six:  sudo apt-get install python-six  (Ubuntu)", 
            "title": "For Spark standalone cluster"
        }, 
        {
            "location": "/PythonUserGuide/install/#for-yarn-cluster", 
            "text": "You can run Analytics Zoo Python programs on Yarn clusters without changes to the cluster (i.e., no need to pre-install any Python dependency).  You can first package all the required dependencies into a virtual environment on the local node (where you will run the spark-submit command),\nand then directly use spark-submit to run the Analytics Zoo Python program on the Yarn cluster using that virtual environment.  Follow the steps below to create the virtual environment:    Make sure you already installed such libraries (python-setuptools, python-dev, gcc, make, zip, pip) for creating the virtual environment. If not, please install them first.\nOn Ubuntu, you can run these commands to install:   apt-get update\napt-get install -y python-setuptools python-dev\napt-get install -y gcc make\napt-get install -y zip\neasy_install pip    Create the virtualenv package for dependencies.    Under $ANALYTICS_ZOO_HOME (the dist directory under the Analytics Zoo project), you can find  bin/python_package.sh . Run this script to create the dependency virtual environment according to the dependencies listed in  requirements.txt . You can add your own dependencies into this file if you wish. The current requirements only contain those needed for running Analytics Zoo Python examples and models.    After running this script, there will be  venv.zip  and  venv  directory generated in current directory. You can use them to submit your Python jobs. Please refer to  here  for the commands to submit an Analytics Zoo Python job with the created virtual environment in Yarn cluster.      FAQ  In case you encounter the following errors when you create the environment package using the above command:   virtualenv ImportError: No module named urllib3  Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.    AttributeError: 'module' object has no attribute 'sslwrap'  Try upgrading  gevent  with  pip install --upgrade gevent .", 
            "title": "For Yarn cluster"
        }, 
        {
            "location": "/PythonUserGuide/run/", 
            "text": "You need to first \ninstall\n analytics-zoo, either \nfrom pip\n or \nwithout pip\n.\n\n\nNOTE\n: Only \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\n\n\nRun after pip install\n\n\nImportant:\n Please always first call \ninit_nncontext()\n at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.\n\n\nfrom zoo.common.nncontext import *\nsc = init_nncontext()\n\n\n\n\nUse an Interactive Shell\n\n\n\n\nType \npython\n in the command line to start a REPL.\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nUse Jupyter Notebook\n\n\n\n\nStart jupyter notebook as you normally do, e.g.\n\n\n\n\njupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\nConfigurations\n\n\n\n\nIncrease memory\n\n\n\n\nexport SPARK_DRIVER_MEMORY=20g\n\n\n\n\n\n\nAdd extra jars or python packages\n\n\n\n\n Set the environment variables \nBIGDL_JARS\n and \nBIGDL_PACKAGES\n \nBEFORE\n creating \nSparkContext\n:\n\n\nexport BIGDL_JARS=...\nexport BIGDL_PACKAGES=...\n\n\n\n\n\n\nRun without pip install\n\n\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and \n=2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nSet SPARK_HOME and ANALYTICS_ZOO_HOME\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself:\n\n\n\n\nexport SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo\n\n\n\n\nUpdate spark-analytics-zoo.conf (Optional)\n\n\nIf you have some customized properties in some files, which will be used with the \n--properties-file\n option\nin \nspark-submit/pyspark\n, you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.\n\n\n\n\nRun with pyspark\n\n\n${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with spark-submit\n\n\nAn Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo \nObject Detection Python example\n\nas follows:\n\n\n${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path\n\n\n\n\n\n\nRun with Jupyter Notebook\n\n\nWith the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.\n\n\nPrerequisites\n: Install all the necessary libraries on the local node where you will run Jupyter, e.g., \n\n\nsudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud\n\n\n\n\nLaunch the Jupyter Notebook as follows:\n\n\n${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nAfter successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/\n\n\nTry to run the \nexample code\n for verification.\n\n\n\n\nRun with virtual environment on Yarn\n\n\nIf you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide \nhere\n,\nyou can run Python programs using Analytics Zoo using the following command.\n\n\nHere we use Analytics Zoo \nObject Detection Python example\n for illustration.\n\n\n\n\nYarn cluster mode\n\n\n\n\n    SPARK_HOME=the root directory of Spark\n    ANALYTICS_ZOO_ROOT=the root directory of the Analytics Zoo project\n    ANALYTICS_ZOO_HOME=$ANALYTICS_ZOO_ROOT/dist\n    ANALYTICS_ZOO_PY_ZIP=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-python-api.zip\n    ANALYTICS_ZOO_JAR=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n    ANALYTICS_ZOO_CONF=${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf\n    PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n    VENV_HOME=the parent directory of venv.zip and venv folder\n\n    PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --properties-file ${ANALYTICS_ZOO_CONF} \\\n    --jars ${ANALYTICS_ZOO_JAR} \\\n    --py-files ${ANALYTICS_ZOO_PY_ZIP} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    ${ANALYTICS_ZOO_ROOT}/pyzoo/zoo/examples/objectdetection/predict.py model_path image_path output_path\n\n\n\n\n\n\nYarn client mode\n\n\n\n\n    SPARK_HOME=the root directory of Spark\n    ANALYTICS_ZOO_ROOT=the root directory of the Analytics Zoo project\n    ANALYTICS_ZOO_HOME=$ANALYTICS_ZOO_ROOT/dist\n    ANALYTICS_ZOO_PY_ZIP=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-python-api.zip\n    ANALYTICS_ZOO_JAR=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n    ANALYTICS_ZOO_CONF=${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf\n    PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n    VENV_HOME=the parent directory of venv.zip and venv folder\n\n    PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --properties-file ${ANALYTICS_ZOO_CONF} \\\n    --jars ${ANALYTICS_ZOO_JAR} \\\n    --py-files ${ANALYTICS_ZOO_PY_ZIP} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    ${ANALYTICS_ZOO_ROOT}/pyzoo/zoo/examples/objectdetection/predict.py model_path image_path output_path\n\n\n\n\n\n\nExample code\n\n\nTo verify if Analytics Zoo can run successfully, run the following simple code:\n\n\nimport zoo.version\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.version.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))", 
            "title": "Run"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-after-pip-install", 
            "text": "Important:  Please always first call  init_nncontext()  at the very beginning of your code after pip install. This will create a SparkContext with optimized performance configuration and initialize the BigDL engine.  from zoo.common.nncontext import *\nsc = init_nncontext()  Use an Interactive Shell   Type  python  in the command line to start a REPL.  Try to run the  example code  to verify the installation.   Use Jupyter Notebook   Start jupyter notebook as you normally do, e.g.   jupyter notebook --notebook-dir=./ --ip=* --no-browser   Try to run the  example code  to verify the installation.   Configurations   Increase memory   export SPARK_DRIVER_MEMORY=20g   Add extra jars or python packages    Set the environment variables  BIGDL_JARS  and  BIGDL_PACKAGES   BEFORE  creating  SparkContext :  export BIGDL_JARS=...\nexport BIGDL_PACKAGES=...", 
            "title": "Run after pip install"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-without-pip-install", 
            "text": "Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and  =2.2.0. See  this issue  for more discussion.   Set SPARK_HOME and ANALYTICS_ZOO_HOME   If you download Analytics Zoo from the  Release Page :   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the path where you extract the analytics-zoo package   If you build Analytics Zoo by yourself:   export SPARK_HOME=the root directory of Spark\nexport ANALYTICS_ZOO_HOME=the dist directory of Analytics Zoo  Update spark-analytics-zoo.conf (Optional)  If you have some customized properties in some files, which will be used with the  --properties-file  option\nin  spark-submit/pyspark , you can add these customized properties into ${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf.", 
            "title": "Run without pip install"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-pyspark", 
            "text": "${ANALYTICS_ZOO_HOME}/bin/pyspark-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  Try to run the  example code  for verification.", 
            "title": "Run with pyspark"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-spark-submit", 
            "text": "An Analytics Zoo Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., numpy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the Analytics Zoo  Object Detection Python example \nas follows:  ${ANALTICS_ZOO_HOME}/bin/spark-submit-with-zoo.sh --master local[*] predict.py model_path image_path output_path", 
            "title": "Run with spark-submit"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-jupyter-notebook", 
            "text": "With the full Python API support in Analytics Zoo, users can use our package together with powerful notebooks\n(such as Jupyter Notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL/DataFrames and MLlib, deep learning models in Analytics Zoo, as well as interactive\nvisualization tools.  Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g.,   sudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud  Launch the Jupyter Notebook as follows:  ${ANALYTICS_ZOO_HOME}/bin/jupyter-with-zoo.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/  Try to run the  example code  for verification.", 
            "title": "Run with Jupyter Notebook"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-with-virtual-environment-on-yarn", 
            "text": "If you have already created Analytics Zoo dependency virtual environment according to Yarn cluster guide  here ,\nyou can run Python programs using Analytics Zoo using the following command.  Here we use Analytics Zoo  Object Detection Python example  for illustration.   Yarn cluster mode       SPARK_HOME=the root directory of Spark\n    ANALYTICS_ZOO_ROOT=the root directory of the Analytics Zoo project\n    ANALYTICS_ZOO_HOME=$ANALYTICS_ZOO_ROOT/dist\n    ANALYTICS_ZOO_PY_ZIP=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-python-api.zip\n    ANALYTICS_ZOO_JAR=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n    ANALYTICS_ZOO_CONF=${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf\n    PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n    VENV_HOME=the parent directory of venv.zip and venv folder\n\n    PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --properties-file ${ANALYTICS_ZOO_CONF} \\\n    --jars ${ANALYTICS_ZOO_JAR} \\\n    --py-files ${ANALYTICS_ZOO_PY_ZIP} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    ${ANALYTICS_ZOO_ROOT}/pyzoo/zoo/examples/objectdetection/predict.py model_path image_path output_path   Yarn client mode       SPARK_HOME=the root directory of Spark\n    ANALYTICS_ZOO_ROOT=the root directory of the Analytics Zoo project\n    ANALYTICS_ZOO_HOME=$ANALYTICS_ZOO_ROOT/dist\n    ANALYTICS_ZOO_PY_ZIP=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-python-api.zip\n    ANALYTICS_ZOO_JAR=${ANALYTICS_ZOO_HOME}/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n    ANALYTICS_ZOO_CONF=${ANALYTICS_ZOO_HOME}/conf/spark-analytics-zoo.conf\n    PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n    VENV_HOME=the parent directory of venv.zip and venv folder\n\n    PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=${VENV_HOME}/venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --master yarn \\\n    --deploy-mode client \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 16 \\\n    --num-executors 2 \\\n    --properties-file ${ANALYTICS_ZOO_CONF} \\\n    --jars ${ANALYTICS_ZOO_JAR} \\\n    --py-files ${ANALYTICS_ZOO_PY_ZIP} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    --conf spark.executor.extraClassPath=${ANALYTICS_ZOO_JAR} \\\n    ${ANALYTICS_ZOO_ROOT}/pyzoo/zoo/examples/objectdetection/predict.py model_path image_path output_path", 
            "title": "Run with virtual environment on Yarn"
        }, 
        {
            "location": "/PythonUserGuide/run/#example-code", 
            "text": "To verify if Analytics Zoo can run successfully, run the following simple code:  import zoo.version\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.version.__version__\n# Create a SparkContext and initialize the BigDL engine.\nsc = init_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))", 
            "title": "Example code"
        }, 
        {
            "location": "/PythonUserGuide/examples/", 
            "text": "Analytics Zoo provides plenty of examples and notebooks ready for re-use as listed below.\n\n\n\n\nImage Classification\n: This example illustrates how to classify images with a pre-trained model.\n\n\nObject Detection\n: This example illustrates how to detect objects in images with a pre-trained model.\n\n\nRecommendation\n: There are two Python notebooks for recommendation models, including wide and deep(WND) model and Neural network-based Collaborative Filtering(NCF) model.\n\n\nText Classification\n: This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU TextClassifier model on 20 Newsgroup dataset.\n\n\nDataFrame\n: There are three examples to show how to perform transfer learning and model inference using pre-trained Inception v1 model with DataFrame-based API.\n\n\nTFNet\n: This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences.\n\n\nSee \nhere\n for more notebooks on user applications and demos.", 
            "title": "Examples"
        }, 
        {
            "location": "/PythonUserGuide/python-faq/", 
            "text": "This page lists solutions to some common questions.\n\n\n\n\n\n\nImportError\n: from zoo.pipeline.api.keras.layers import *\n\n\n\n\nCheck if the path is pointing to python-api.zip: \n--py-files ${ANALYTICS_ZOO_PY_ZIP}\n\n\nCheck if the path is pointing to python-api.zip:\n\n\n\n\nexport PYTHONPATH=${ANALYTICS_ZOO_PY_ZIP}:$PYTHONPATH\n\n\n\n\n\n\nPython in worker has a different version 2.7 than that in driver 3.5\n\n\n\n\nexport PYSPARK_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every worker node.\n\n\nexport PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every driver node.\n\n\n\n\n\n\n\n\nTypeError\n: 'JavaPackage' object is not callable\n\n\n\n\nCheck if every path within the launch script is valid especially the path that ends with jar.\n\n\nIf there are extra jars involved, check if the Spark version Analytics Zoo is built and the Spark version the extra jar is built are compatible.\n\n\n\n\n\n\n\n\njava.lang.\nNoSuchMethodError\n:XXX or \nPy4JError\n: ofFloat does not exist in the JVM\n\n\n\n\nCheck if the Spark version matches, i.e check if you are using Spark 2.x but the underneath Analytics Zoo is compiled with Spark 1.6.\n\n\nIf there are extra jars involved, also check if the Spark version matches.", 
            "title": "FAQ"
        }, 
        {
            "location": "/ScalaUserGuide/install/", 
            "text": "Download a pre-built library\n\n\nYou can download the Analytics Zoo release and nightly build from the \nRelease Page\n\n\n\n\nLink with a release version\n\n\nCurrently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.zoo\n/groupId\n\n    \nartifactId\nanalytics-zoo-[SPARK_1.6|SPARK_2.1|SPARK_2.2]\n/artifactId\n\n    \nversion\n${ANALYTICS_ZOO_VERSION}\n/version\n\n\n/dependency\n\n\n\n\n\nPlease choose the suffix according to your Spark platform.\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.zoo\n % \nanalytics-zoo-[SPARK_1.6|SPARK_2.1|SPARK_2.2]\n % \n${ANALYTICS_ZOO_VERSION}\n\n\n\n\n\nYou can find the optional \n${ANALYTICS_ZOO_VERSION}\n from the \nRelease Page\n.\n\n\n\n\nLink with a development version\n\n\nCurrently, Analytics Zoo development version is hosted on \nSonaType\n.\n\n\nTo link your application with the latest Analytics Zoo development version, you should add some dependencies like \nLinking with Analytics Zoo releases\n, but set \n${ANALYTICS_ZOO_VERSION}\n to \n0.2.0\n, and add below repository to your pom.xml.\n\n\nrepository\n\n    \nid\nsonatype\n/id\n\n    \nname\nsonatype repository\n/name\n\n    \nurl\nhttps://oss.sonatype.org/content/groups/public/\n/url\n\n    \nreleases\n\n        \nenabled\ntrue\n/enabled\n\n    \n/releases\n\n    \nsnapshots\n\n        \nenabled\ntrue\n/enabled\n\n    \n/snapshots\n\n\n/repository\n\n\n\n\n\nSBT developers can use\n\n\nresolvers += \nossrh repository\n at \nhttps://oss.sonatype.org/content/repositories/snapshots/\n\n\n\n\n\nDownload Analytics Zoo Source\n\n\nAnalytics Zoo source code is available at \nGitHub\n\n\n$ git clone https://github.com/intel-analytics/analytics-zoo.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of Analytics Zoo, if you want a release version, you can use command \ngit checkout\n to change the version.\n\n\nSetup Build Environment\n\n\nThe following instructions are aligned with master code.\n\n\nMaven 3 is needed to build Analytics Zoo, you can download it from the \nmaven website\n.\n\n\nAfter installing Maven 3, please set the environment variable MAVEN_OPTS as follows:\n\n\n$ export MAVEN_OPTS=\n-Xmx2g -XX:ReservedCodeCacheSize=512m\n\n\n\n\n\nWhen compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.\n\n\nBuild with script (Recommended)\n\n\nIt is highly recommended that you build Analytics Zoo using the \nmake-dist.sh script\n. And it will handle the MAVEN_OPTS variable.\n\n\nOnce downloaded, you can build Analytics Zoo with the following commands:\n\n\n$ bash make-dist.sh\n\n\n\n\nAfter that, you can find a \ndist\n folder, which contains all the needed files to run a Analytics Zoo program. The files in \ndist\n include:\n\n\n\n\ndist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar\n: This jar package contains all dependencies except Spark classes.\n\n\ndist/lib/analytics-zoo-VERSION-python-api.zip\n: This zip package contains all Python files of Analytics Zoo.\n\n\n\n\nThe instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use \nJava 8\n when running with Spark 2.x; otherwise you may observe very poor performance.\n\n\nBuild for Spark 1.6\n\n\nTo build for Spark 1.6(which uses Scala 2.10 by default), pass \n-P spark_1.6\n to the \nmake-dist.sh\n script:\n\n\n$ bash make-dist.sh -P spark_1.6\n\n\n\n\nBuild for Scala 2.10 or 2.11\n\n\nBy default, \nmake-dist.sh\n uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass \n-P scala_2.10\n or \n-P scala_2.11\n to \nmake-dist.sh\n as appropriate.\n\n\n\n\nBuild with Maven\n\n\nTo build Analytics Zoo directly using Maven, run the command below:\n\n\n$ mvn clean package -DskipTests\n\n\n\n\nAfter that, you can find that jar packages in \nPATH_TO_ANALYTICS_ZOO\n/target/, where \nPATH_TO_ANALYTICS_ZOO\n is the path to the directory of the Analytics Zoo.\n\n\nNote that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven:\n\n\n\n\n-P spark_1.6\n: build for Spark 1.6 (using Scala 2.10).\n\n\n-P scala_2.10\n (or \n-P scala_2.11\n): build using Scala 2.10 (or Scala 2.11)\n\n\n\n\n\n\nSetup IDE\n\n\nWe set the scope of spark related library to \nprovided\n in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.\n\n\nThis will cause a problem in IDE. When you run applications, it will throw \nNoClassDefFoundError\n because the library scope is \nprovided\n.\n\n\nYou can easily change the scopes by the \nall-in-one\n profile.\n\n\n\n\nIn Intellij, go to View -\n Tools Windows -\n Maven Projects. Then in the Maven Projects panel, Profiles -\n click \"all-in-one\".", 
            "title": "Install"
        }, 
        {
            "location": "/ScalaUserGuide/install/#download-a-pre-built-library", 
            "text": "You can download the Analytics Zoo release and nightly build from the  Release Page", 
            "title": "Download a pre-built library"
        }, 
        {
            "location": "/ScalaUserGuide/install/#link-with-a-release-version", 
            "text": "Currently, Analytics Zoo releases are hosted on maven central; here's an example to add the Analytics Zoo dependency to your own project:  dependency \n     groupId com.intel.analytics.zoo /groupId \n     artifactId analytics-zoo-[SPARK_1.6|SPARK_2.1|SPARK_2.2] /artifactId \n     version ${ANALYTICS_ZOO_VERSION} /version  /dependency   Please choose the suffix according to your Spark platform.  SBT developers can use  libraryDependencies +=  com.intel.analytics.zoo  %  analytics-zoo-[SPARK_1.6|SPARK_2.1|SPARK_2.2]  %  ${ANALYTICS_ZOO_VERSION}   You can find the optional  ${ANALYTICS_ZOO_VERSION}  from the  Release Page .", 
            "title": "Link with a release version"
        }, 
        {
            "location": "/ScalaUserGuide/install/#link-with-a-development-version", 
            "text": "Currently, Analytics Zoo development version is hosted on  SonaType .  To link your application with the latest Analytics Zoo development version, you should add some dependencies like  Linking with Analytics Zoo releases , but set  ${ANALYTICS_ZOO_VERSION}  to  0.2.0 , and add below repository to your pom.xml.  repository \n     id sonatype /id \n     name sonatype repository /name \n     url https://oss.sonatype.org/content/groups/public/ /url \n     releases \n         enabled true /enabled \n     /releases \n     snapshots \n         enabled true /enabled \n     /snapshots  /repository   SBT developers can use  resolvers +=  ossrh repository  at  https://oss.sonatype.org/content/repositories/snapshots/", 
            "title": "Link with a development version"
        }, 
        {
            "location": "/ScalaUserGuide/install/#download-analytics-zoo-source", 
            "text": "Analytics Zoo source code is available at  GitHub  $ git clone https://github.com/intel-analytics/analytics-zoo.git  By default,  git clone  will download the development version of Analytics Zoo, if you want a release version, you can use command  git checkout  to change the version.", 
            "title": "Download Analytics Zoo Source"
        }, 
        {
            "location": "/ScalaUserGuide/install/#setup-build-environment", 
            "text": "The following instructions are aligned with master code.  Maven 3 is needed to build Analytics Zoo, you can download it from the  maven website .  After installing Maven 3, please set the environment variable MAVEN_OPTS as follows:  $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m   When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.", 
            "title": "Setup Build Environment"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-with-script-recommended", 
            "text": "It is highly recommended that you build Analytics Zoo using the  make-dist.sh script . And it will handle the MAVEN_OPTS variable.  Once downloaded, you can build Analytics Zoo with the following commands:  $ bash make-dist.sh  After that, you can find a  dist  folder, which contains all the needed files to run a Analytics Zoo program. The files in  dist  include:   dist/lib/analytics-zoo-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes.  dist/lib/analytics-zoo-VERSION-python-api.zip : This zip package contains all Python files of Analytics Zoo.   The instructions above will build Analytics Zoo with Spark 2.0(using Scala 2.11). It is highly recommended to use  Java 8  when running with Spark 2.x; otherwise you may observe very poor performance.", 
            "title": "Build with script (Recommended)"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-for-spark-16", 
            "text": "To build for Spark 1.6(which uses Scala 2.10 by default), pass  -P spark_1.6  to the  make-dist.sh  script:  $ bash make-dist.sh -P spark_1.6", 
            "title": "Build for Spark 1.6"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-for-scala-210-or-211", 
            "text": "By default,  make-dist.sh  uses Scala 2.11 for Spark 2.1, and Scala 2.10 for Spark 1.6. To override the default behaviors, you can pass  -P scala_2.10  or  -P scala_2.11  to  make-dist.sh  as appropriate.", 
            "title": "Build for Scala 2.10 or 2.11"
        }, 
        {
            "location": "/ScalaUserGuide/install/#build-with-maven", 
            "text": "To build Analytics Zoo directly using Maven, run the command below:  $ mvn clean package -DskipTests  After that, you can find that jar packages in  PATH_TO_ANALYTICS_ZOO /target/, where  PATH_TO_ANALYTICS_ZOO  is the path to the directory of the Analytics Zoo.  Note that the instructions above will build Analytics Zoo with Spark 2.0 (using Scala 2.11) for Linux. Similarly, you may customize the default behaviors by passing the following parameters to maven:   -P spark_1.6 : build for Spark 1.6 (using Scala 2.10).  -P scala_2.10  (or  -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11)", 
            "title": "Build with Maven"
        }, 
        {
            "location": "/ScalaUserGuide/install/#setup-ide", 
            "text": "We set the scope of spark related library to  provided  in pom.xml. The reason is that we don't want package spark related jars which will make analytics zoo a huge jar, and generally as analytics zoo is invoked by spark-submit, these dependencies will be provided by spark at run-time.  This will cause a problem in IDE. When you run applications, it will throw  NoClassDefFoundError  because the library scope is  provided .  You can easily change the scopes by the  all-in-one  profile.   In Intellij, go to View -  Tools Windows -  Maven Projects. Then in the Maven Projects panel, Profiles -  click \"all-in-one\".", 
            "title": "Setup IDE"
        }, 
        {
            "location": "/ScalaUserGuide/run/", 
            "text": "Set Environment Variables\n\n\nSet \nANALYTICS_ZOO_HOME\n and \nSPARK_HOME\n:\n\n\n\n\nIf you download Analytics Zoo from the \nRelease Page\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package\n\n\n\n\n\n\nIf you build Analytics Zoo by yourself\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder\n\n\n\n\n\n\nUse Interactive Spark Shell\n\n\nYou can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:\n\n\n${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]\n\n\n\n\nYou will see a welcome message looking like below:\n\n\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala\n\n\n\n\n\nNow you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:\n\n\nscala\n import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala\n ObjectDetector.loadModel[Float](params.modelPath)\n\n\n\n\n\n\nRun as a Spark Program\n\n\nYou can run a analytics zoo program, e.g., the \nObject Detection\n, as a standard Spark program (running in either local mode or cluster mode) as follows:\n\n\n\n\nDownload the pre-trained model from \nhere\n.\n\n\nPrepare predict images\n\n\nRun the following command:\n\n\n\n\n  # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n\n\n\nIf you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.\n\n\nimport com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)", 
            "title": "Run"
        }, 
        {
            "location": "/ScalaUserGuide/run/#set-environment-variables", 
            "text": "Set  ANALYTICS_ZOO_HOME  and  SPARK_HOME :   If you download Analytics Zoo from the  Release Page   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=folder path where you extract the analytics zoo package   If you build Analytics Zoo by yourself   export SPARK_HOME=folder path where you extract the spark package\nexport ANALYTICS_ZOO_HOME=the dist folder generated by the build process, which is under the top level of the source folder", 
            "title": "Set Environment Variables"
        }, 
        {
            "location": "/ScalaUserGuide/run/#use-interactive-spark-shell", 
            "text": "You can try Analytics Zoo easily using the Spark interactive shell. Run below command to start spark shell with Analytics Zoo support:  ${ANALYTICS_ZOO_HOME}/bin/spark-shell-with-zoo.sh --master local[*]  You will see a welcome message looking like below:  Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala   Now you'll be able to play with Analytics Zoo API's.\nFor instance, to load a pre-trained object detection model, you may try below code:  scala  import com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\nimport com.intel.analytics.zoo.models.image.objectdetection.ObjectDetector\n\nscala  ObjectDetector.loadModel[Float](params.modelPath)", 
            "title": "Use Interactive Spark Shell"
        }, 
        {
            "location": "/ScalaUserGuide/run/#run-as-a-spark-program", 
            "text": "You can run a analytics zoo program, e.g., the  Object Detection , as a standard Spark program (running in either local mode or cluster mode) as follows:   Download the pre-trained model from  here .  Prepare predict images  Run the following command:     # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.zoo.examples.objectdetection.Predict \\\n  dist/lib/analytics-zoo-VERSION-SNAPSHOT-jar-with-dependencies.jar \\\n  --image path_to_your_images --output path_to_output --model path_to_model  If you are to run your own program, do remember to create SparkContext and initialize before calling other Analytics Zoo API's, as shown below.  import com.intel.analytics.zoo.common.NNContext\nval sc = NNContext.initNNContext(conf)", 
            "title": "Run as a Spark Program"
        }, 
        {
            "location": "/ScalaUserGuide/examples/", 
            "text": "Analytics Zoo provides plenty of examples ready for re-use as listed below.\n\n\n\n\nImage Classification\n: This example illustrates how to do the image classification with pre-trained model.\n\n\nObject Detection\n: This example illustrates how to detect objects in image with pre-trained model.\n\n\nRecommendation\n: There are two Scala examples for recommender models, including wide and deep(WND) model and Neural network-based Collaborative Filtering(NCF) model.\n\n\nText Classification\n: This example uses pre-trained GloVe embeddings to convert words to vectors and trains a CNN, LSTM or GRU \nTextClassifier\n model on 20 Newsgroup dataset\n\n\nDataFrame\n: There are three examples to show how to perform transfer learning/model inference using pre-trained Inception v1 model with DataFrame-based API.\n\n\nTFNet\n: TFNet can encapsulate a frozen TensorFlow graph as an Analytics Zoo layer for inference. This example illustrates how to use a pre-trained TensorFlow object detection model to make inferences using Analytics Zoo on Spark.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/", 
            "text": "Overview\n\n\nNNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.\n\n\nHighlights\n\n\n\n\n\n\nEasy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.\n\n\n\n\n\n\nEffortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.\n\n\n\n\n\n\nIn a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.\n\n\n\n\n\n\nTraining of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).\n\n\n\n\n\n\nRich toolset for feature extraction and processing, including image, audio and texts.\n\n\n\n\n\n\nExamples:\n\n\nThe examples are included in the Analytics Zoo source code.\n\n\n\n\nimage classification: model inference using pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\nimage classification: transfer learning from pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\n\n\nPrimary APIs\n\n\nNNEstimator and NNModel\n\n\nAnalytics Zoo provides \nNNEstimator\n for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark\n\nEstimator\n/\n\nTransfomer\n\npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of\n\nNNEstimator\n is a NNModel, which is a Spark ML Transformer.\n\n\nplease check our\n\nNNEstimator API\n for detailed usage.\n\n\nNNClassifier and NNClassifierModel\n\n\nNNClassifier\n and \nNNClassifierModel\nextends \nNNEstimator\n and \nNNModel\n and focus on \nclassification tasks, where both label column and prediction column are of Double type.\n\n\nNNImageReader\n\nNNImageReader loads image into Spark DataFrame.\n\n\nplease check our\n\nImageProcessing\n for detailed usage.", 
            "title": "DataFrame and ML Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#overview", 
            "text": "NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.  Highlights    Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.    Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.    In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.    Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).    Rich toolset for feature extraction and processing, including image, audio and texts.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#examples", 
            "text": "The examples are included in the Analytics Zoo source code.   image classification: model inference using pre-trained Inception v1 model.\n     Scala version \n     Python version  image classification: transfer learning from pre-trained Inception v1 model.\n     Scala version \n     Python version", 
            "title": "Examples:"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#primary-apis", 
            "text": "NNEstimator and NNModel  Analytics Zoo provides  NNEstimator  for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer \npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator  is a NNModel, which is a Spark ML Transformer.  please check our NNEstimator API  for detailed usage.  NNClassifier and NNClassifierModel  NNClassifier  and  NNClassifierModel extends  NNEstimator  and  NNModel  and focus on \nclassification tasks, where both label column and prediction column are of Double type.  NNImageReader \nNNImageReader loads image into Spark DataFrame.  please check our ImageProcessing  for detailed usage.", 
            "title": "Primary APIs"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/", 
            "text": "Overview\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustracted below. (See more examples \nhere\n). Conceptually we use reverse mode together with the chain rule for automatic differentiation. \nVariable\n is used to record the linkage of the operation history, which would generated a directed acyclic graph for the backward execution. Within the execution graph, leaves are the input \nvariables\n and roots are the output \nvariables\n.\n\n\n1.Define custom functions using \nautograd\n\n\nfrom zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)\n\ndef add_one_func(x):\n   return x + 1.0\n\n\n\n\n2.Define model using Keras-style API and \ncustom \nLambda\n layer\n\n\nfrom zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size\n\n\n\n\n\n3.Train model with \ncustom loss function\n\n\nmodel.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)\n\n# Evaluation for debug purpose\nCustomLoss(mean_absolute_error, [2]).forward(np.random.uniform(0, 1, shape[3, 2])) # [2] is the shape without batch, 3 is the batch size.", 
            "title": "Autograd"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/#overview", 
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustracted below. (See more examples  here ). Conceptually we use reverse mode together with the chain rule for automatic differentiation.  Variable  is used to record the linkage of the operation history, which would generated a directed acyclic graph for the backward execution. Within the execution graph, leaves are the input  variables  and roots are the output  variables .  1.Define custom functions using  autograd  from zoo.pipeline.api.autograd import *\n\ndef mean_absolute_error(y_true, y_pred):\n   return mean(abs(y_true - y_pred), axis=1)\n\ndef add_one_func(x):\n   return x + 1.0  2.Define model using Keras-style API and  custom  Lambda  layer  from zoo.pipeline.api.keras.layers import *\nfrom zoo.pipeline.api.keras.models import *\nmodel = Sequential().add(Dense(1, input_shape=(2,))) \\\n                   .add(Lambda(function=add_one_func))\n# Evaluation for debug purpose.\nmodel.forward(np.random.uniform(0, 1, shape[3, 2])) # 3 is the batch size  3.Train model with  custom loss function  model.compile(optimizer = SGD(), loss = mean_absolute_error)\nmodel.fit(x = ..., y = ...)\n\n# Evaluation for debug purpose\nCustomLoss(mean_absolute_error, [2]).forward(np.random.uniform(0, 1, shape[3, 2])) # [2] is the shape without batch, 3 is the batch size.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/", 
            "text": "Overview\n\n\nAnalytics Zoo provides some useful utilities for transfer learning.\n\n\nLoading a pre-trained model\n\n\nWe can use the \nNet\n api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to \nNet API Guide\n\n\nRemove the last a few layers\n\n\nWhen a model is loaded using \nNet\n, we can use the \nnewGraph(output)\n api to define a Model with\nthe output specified by the parameter.\n\n\nFor example, \n\n\nIn scala:\n\n\nval inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output = \npool5/drop_7x7_s1\n)\n\n\n\n\n\nIn python:\n\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\nThe returning model's output layer is \"pool5/drop_7x7_s1\".\n\n\nFreeze some layers\n\n\nIn transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the \nfreezeUpTo(endPoint)\n api to do that.\n\n\nFor example,\n\n\nIn scala:\n\n\ninception.freezeUpTo(\npool4/3x3_s2\n) // freeze layer pool4/3x3_s2 and the layers before it\n\n\n\n\nIn python:\n\n\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\nThis will freeze all the layers from the input layer to \"pool4/3x3_s2\"\n\n\nExample\n\n\nFor a complete example, refer to the \nscala transfer learning example\n\nand \npython transfer learning example", 
            "title": "Transfer Learning"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#overview", 
            "text": "Analytics Zoo provides some useful utilities for transfer learning.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#loading-a-pre-trained-model", 
            "text": "We can use the  Net  api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to  Net API Guide", 
            "title": "Loading a pre-trained model"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#remove-the-last-a-few-layers", 
            "text": "When a model is loaded using  Net , we can use the  newGraph(output)  api to define a Model with\nthe output specified by the parameter.  For example,   In scala:  val inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output =  pool5/drop_7x7_s1 )  In python:  full_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])  The returning model's output layer is \"pool5/drop_7x7_s1\".", 
            "title": "Remove the last a few layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#freeze-some-layers", 
            "text": "In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the  freezeUpTo(endPoint)  api to do that.  For example,  In scala:  inception.freezeUpTo( pool4/3x3_s2 ) // freeze layer pool4/3x3_s2 and the layers before it  In python:  # freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])  This will freeze all the layers from the input layer to \"pool4/3x3_s2\"", 
            "title": "Freeze some layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#example", 
            "text": "For a complete example, refer to the  scala transfer learning example \nand  python transfer learning example", 
            "title": "Example"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/", 
            "text": "Working with images\n\n\nAnalytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nAnalytics Zoo can process image data as Spark Data Frame.\n\nNNImageReader\n is the primary DataFrame-based image loading interface to read images into DataFrame.\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext(\napp\n)\nval imageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nval imageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nval imageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\n\nPython:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext(create_spark_conf().setAppName(\napp\n))\nimageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nimageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nimageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.\n\n\nLoad to ImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\n// create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython example:\n\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo has many pre-defined image processing transformers built on top of OpenCV:\n\n\n\n\nBrightness\n: Adjust the image brightness.\n\n\nHue\n: Adjust the image hue.\n\n\nSaturation\n: Adjust the image Saturation.\n\n\nContrast\n: Adjust the image Contrast.\n\n\nChannelOrder\n: Random change the channel order of an image\n\n\nColorJitter\n: Random adjust brightness, contrast, hue, saturation\n\n\nResize\n: Resize image\n\n\nAspectScale\n: Resize the image, keep the aspect ratio. scale according to the short edge\n\n\nRandomAspectScale\n: Resize the image by randomly choosing a scale\n\n\nChannelNormalize\n: Image channel normalize\n\n\nPixelNormalizer\n: Pixel level normalizer\n\n\nCenterCrop\n: Crop a \ncropWidth\n x \ncropHeight\n patch from center of image.\n\n\nRandomCrop\n: Random crop a \ncropWidth\n x \ncropHeight\n patch from an image.\n\n\nFixedCrop\n: Crop a fixed area of image\n\n\nDetectionCrop\n: Crop from object detections, each image should has a tensor detection,\n\n\nExpand\n: Expand image, fill the blank part with the meanR, meanG, meanB\n\n\nFiller\n: Fill part of image with certain pixel value\n\n\nHFlip\n: Flip the image horizontally\n\n\nRandomTransformer\n: It is a wrapper for transformers to control the transform probability\n\n\nBytesToMat\n: Transform byte array(original image file in byte) to OpenCVMat\n\n\nMatToFloats\n: Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n\n\nMatToTensor\n: Transform opencv mat to tensor, note that in this transformer, the mat is released.\n\n\nImageFrameToSample\n: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.\n\n\n\n\nMore examples can be found \nhere\n\n\nYou can also define your own Transformer by extending \nImageProcessing\n,\nand override the function \ntransformMat\n to do the actual transformation to \nImageFeature\n.\n\n\nBuild Image Transformation Pipeline\n\n\nYou can easily build the image transformation pipeline by chaining transformers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -\n ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n             ImageChannelNormalize(123, 117, 104) -\n\n             ImageMatToTensor[Float]() -\n\n             ImageSetToSample[Float]()\n\n\n\n\nIn the above example, the transformations will perform sequentially.\n\n\nAssume you have an ImageFrame containing original bytes array,\n\nImageBytesToMat\n will transform the bytes array to \nOpenCVMat\n.\n\n\nImageColorJitter\n, \nImageExpand\n, \nImageResize\n, \nImageHFlip\n and \nImageChannelNormalize\n will transform over \nOpenCVMat\n,\nnote that \nOpenCVMat\n is overwrite by default.\n\n\nImageMatToTensor\n transform \nOpenCVMat\n to \nTensor\n, and \nOpenCVMat\n is released in this step.\n\n\nImageSetToSample\n transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.\n\n\nPython example:\n\n\nfrom zoo.feature.image.imagePreprocessing import *\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])\n\n\n\n\nImage Train\n\n\nTrain with Image DataFrame\n\n\nYou can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call \nfit\n method to let Analytics Zoo train the model\n\n\nFor detail APIs, please refer to: \nNNFrames\n\n\nScala example:\n\n\nval batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                   ImageCenterCrop(224, 224) -\n\n                                   ImageChannelNormalize(123, 117, 104) -\n\n                                   ImageMatToTensor() -\n\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\nimage\n)\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n\n\n\n\nPython example:\n\n\nbatchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\nimage\n)\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\n\n\nTrain with ImageSet\n\n\nYou can train Zoo Keras model with ImageSet. Just call \nfit\n method to let Analytics Zoo train the model.\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(create_spark_conf().setAppName(\ntrain keras\n))\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\n\n\n\n\nImage Predict\n\n\nPredict with Image DataFrame\n\n\nAfter training with NNEstimator/NNCLassifier, you'll get a trained NNModel/NNClassifierModel. You can call \ntransform\n to predict Image DataFrame with this NNModel/NNClassifierModel.\n Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to \ntransform\n to predict Image DataFrame.\n After prediction, there is a new column \nprediction\n in the prediction image dataframe.\n\n\nScala example:\n\n ```scala\n val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                    ImageCenterCrop(224, 224) -\n\n                                    ImageChannelNormalize(123, 117, 104) -\n\n                                    ImageMatToTensor() -\n\n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion\nFloat\n, featureTransformer)\n         .setFeaturesCol(\"image\")\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)\n\n\n// predict with loaded pre-trained model\n val model = Module.loadModule\nFloat\n\n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol(\"image\")\n         .setPredictionCol(\"prediction\") \n val resultDF = dlmodel.transform(testDf)\n \n**Python example:**\npython\n batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol(\"image\")\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\npredict with trained model\n\n\npredictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)\n\n\npredict with loaded pre-trained model\n\n\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)\n ```\n\n\nPredict with ImageSet\n\n\nAfter training Zoo Keras model, you can call \npredict\n to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nPredict with trained Zoo Keras Model\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(create_spark_conf().setAppName(\ntrain keras\n))\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()\n\n\n\n\nPredict with loaded Model\n\n\nYou can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nFor details, you can check guide of \nimage classificaion\n or \nobject detection", 
            "title": "Working with Images"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#working-with-images", 
            "text": "Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.", 
            "title": "Working with images"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-data-frame", 
            "text": "Analytics Zoo can process image data as Spark Data Frame. NNImageReader  is the primary DataFrame-based image loading interface to read images into DataFrame.  Scala example:  import com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.initNNContext( app )\nval imageDF1 = NNImageReader.readImages( /tmp , sc)\nval imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nval imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  Python:  from zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = init_nncontext(create_spark_conf().setAppName( app ))\nimageDF1 = NNImageReader.readImages( /tmp , sc)\nimageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nimageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  // create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read( /tmp/image/ , sc, 2)  Python example:  # create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "Load to ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-transformer", 
            "text": "Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV:   Brightness : Adjust the image brightness.  Hue : Adjust the image hue.  Saturation : Adjust the image Saturation.  Contrast : Adjust the image Contrast.  ChannelOrder : Random change the channel order of an image  ColorJitter : Random adjust brightness, contrast, hue, saturation  Resize : Resize image  AspectScale : Resize the image, keep the aspect ratio. scale according to the short edge  RandomAspectScale : Resize the image by randomly choosing a scale  ChannelNormalize : Image channel normalize  PixelNormalizer : Pixel level normalizer  CenterCrop : Crop a  cropWidth  x  cropHeight  patch from center of image.  RandomCrop : Random crop a  cropWidth  x  cropHeight  patch from an image.  FixedCrop : Crop a fixed area of image  DetectionCrop : Crop from object detections, each image should has a tensor detection,  Expand : Expand image, fill the blank part with the meanR, meanG, meanB  Filler : Fill part of image with certain pixel value  HFlip : Flip the image horizontally  RandomTransformer : It is a wrapper for transformers to control the transform probability  BytesToMat : Transform byte array(original image file in byte) to OpenCVMat  MatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released.  MatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released.  ImageFrameToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.   More examples can be found  here  You can also define your own Transformer by extending  ImageProcessing ,\nand override the function  transformMat  to do the actual transformation to  ImageFeature .", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#build-image-transformation-pipeline", 
            "text": "You can easily build the image transformation pipeline by chaining transformers.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -  ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n             ImageChannelNormalize(123, 117, 104) - \n             ImageMatToTensor[Float]() - \n             ImageSetToSample[Float]()  In the above example, the transformations will perform sequentially.  Assume you have an ImageFrame containing original bytes array, ImageBytesToMat  will transform the bytes array to  OpenCVMat .  ImageColorJitter ,  ImageExpand ,  ImageResize ,  ImageHFlip  and  ImageChannelNormalize  will transform over  OpenCVMat ,\nnote that  OpenCVMat  is overwrite by default.  ImageMatToTensor  transform  OpenCVMat  to  Tensor , and  OpenCVMat  is released in this step.  ImageSetToSample  transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.  Python example:  from zoo.feature.image.imagePreprocessing import *\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])", 
            "title": "Build Image Transformation Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-train", 
            "text": "", 
            "title": "Image Train"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-image-dataframe", 
            "text": "You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call  fit  method to let Analytics Zoo train the model  For detail APIs, please refer to:  NNFrames  Scala example:  val batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                   ImageCenterCrop(224, 224) - \n                                   ImageChannelNormalize(123, 117, 104) - \n                                   ImageMatToTensor() - \n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol( image )\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)  Python example:  batchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol( image )\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)", 
            "title": "Train with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-imageset", 
            "text": "You can train Zoo Keras model with ImageSet. Just call  fit  method to let Analytics Zoo train the model.  Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(create_spark_conf().setAppName( train keras ))\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)", 
            "title": "Train with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-predict", 
            "text": "", 
            "title": "Image Predict"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-image-dataframe", 
            "text": "After training with NNEstimator/NNCLassifier, you'll get a trained NNModel/NNClassifierModel. You can call  transform  to predict Image DataFrame with this NNModel/NNClassifierModel.\n Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to  transform  to predict Image DataFrame.\n After prediction, there is a new column  prediction  in the prediction image dataframe.  Scala example: \n ```scala\n val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                    ImageCenterCrop(224, 224) - \n                                    ImageChannelNormalize(123, 117, 104) - \n                                    ImageMatToTensor() - \n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion Float , featureTransformer)\n         .setFeaturesCol(\"image\")\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)  // predict with loaded pre-trained model\n val model = Module.loadModule Float \n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol(\"image\")\n         .setPredictionCol(\"prediction\") \n val resultDF = dlmodel.transform(testDf)\n  **Python example:** python\n batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol(\"image\")\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)", 
            "title": "Predict with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-model", 
            "text": "predictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)", 
            "title": "predict with trained model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-pre-trained-model", 
            "text": "model = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)\n ```", 
            "title": "predict with loaded pre-trained model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-imageset", 
            "text": "After training Zoo Keras model, you can call  predict  to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.", 
            "title": "Predict with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-zoo-keras-model", 
            "text": "Python example:  from zoo.common.nncontext import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = init_nncontext(create_spark_conf().setAppName( train keras ))\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()", 
            "title": "Predict with trained Zoo Keras Model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-model", 
            "text": "You can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.  For details, you can check guide of  image classificaion  or  object detection", 
            "title": "Predict with loaded Model"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Apache Spark, Apache Storm or Apache Flink.\n\n\nObject Detection examples\n\n\nAnalytics Zoo provides two typical kind of pre-trained Object Detection models : \nSSD\n and \nFaster-RCNN\n on dataset \nPASCAL\n and \nCOCO\n. For the usage of these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nUsers can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) -\n\n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) -\n\n                         MatToTensor() -\n ImageFrameToSample()\nval output = model.predictImageset(data)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nDownload link\n\n\nPASCAL VOC models\n\n\n\n\nSSD 300x300 MobileNet\n\n\nSSD 300x300 VGG\n\n\nSSD 512x512 VGG\n\n\nFaster-RCNN VGG\n\n\nFaster-RCNN VGG Compress\n\n\nFaster-RCNN PvaNet\n\n\nFaster-RCNN PvaNet Compress\n\n\n\n\nCOCO models\n\n\n\n\nSSD 300x300 VGG\n\n\nSSD 512x512 VGG", 
            "title": "Object Detection API"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#object-detection-examples", 
            "text": "Analytics Zoo provides two typical kind of pre-trained Object Detection models :  SSD  and  Faster-RCNN  on dataset  PASCAL  and  COCO . For the usage of these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)  For preprocessors for Object Detection models, please check  Object Detection Config  Users can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) - \n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) - \n                         MatToTensor() -  ImageFrameToSample()\nval output = model.predictImageset(data)  Python  Python example  It's very easy to apply the model for inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  model = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing)\noutput = model.predict_image_set(image_set)  For preprocessors for Object Detection models, please check  Object Detection Config", 
            "title": "Object Detection examples"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#download-link", 
            "text": "PASCAL VOC models   SSD 300x300 MobileNet  SSD 300x300 VGG  SSD 512x512 VGG  Faster-RCNN VGG  Faster-RCNN VGG Compress  Faster-RCNN PvaNet  Faster-RCNN PvaNet Compress   COCO models   SSD 300x300 VGG  SSD 512x512 VGG", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nImage Classification examples\n\n\nAnalytics Zoo provides several typical kind of pre-trained Image Classfication models : \nAlexnet\n, \nInception-V1\n, \nVGG\n, \nResnet\n, \nDensenet\n, \nMobilenet\n, \nSqueezenet\n models. To use these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n        ImageChannelNormalize(123, 117, 104) -\n\n        ImageMatToTensor[Float]() -\n\n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Image Classification models, please check \nImage Classification Config\n\n\nDownload link\n\n\n\n\nAlexnet\n\n\nInception-V1\n\n\nVGG-16\n\n\nVGG-19\n\n\nResnet-50\n\n\nDensenet-161\n\n\nMobilenet\n\n\nSqueezenet", 
            "title": "Image Classification API"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#image-classification-examples", 
            "text": "Analytics Zoo provides several typical kind of pre-trained Image Classfication models :  Alexnet ,  Inception-V1 ,  VGG ,  Resnet ,  Densenet ,  Mobilenet ,  Squeezenet  models. To use these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)  User can also define his own configuration to do the inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n        ImageChannelNormalize(123, 117, 104) - \n        ImageMatToTensor[Float]() - \n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)  Python  Python example  It's very easy to apply the model for inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)  For preprocessors for Image Classification models, please check  Image Classification Config", 
            "title": "Image Classification examples"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#download-link", 
            "text": "Alexnet  Inception-V1  VGG-16  VGG-19  Resnet-50  Densenet-161  Mobilenet  Squeezenet", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/", 
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\n\n\nHighlights\n\n\n\n\nEasy-to-use models, could be fed into NNFrames or BigDL Optimizer for training.\n\n\nThe encoders we support include CNN, LSTM and GRU.\n\n\n\n\n\n\nBuild a TextClassifier model\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, tokenLength, sequenceLength = 500, encoder = \ncnn\n, encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\ntokenLength\n: The size of each word vector. Positive integer.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, token_length, sequence_length=500, encoder=\ncnn\n, encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\ntoken_length\n: The size of each word vector. Positive int.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\n\n\nTrain a TextClassifier model\n\n\nAfter building the model, we can use BigDL Optimizer to train it (with validation) using RDD of \nSample\n.\n\n\nNote that raw text data may need to go through tokenization and vectorization before being fed into the Optimizer. You can refer to the \nexamples\n we provide for data pre-processing.\n\n\nScala\n\n\nval optimizer = Optimizer(\n  model = textClassifier,\n  sampleRDD = trainRDD,\n  criterion = ClassNLLCriterion[Float](logProbAsInput = false),\n  batchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), 128)\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()\n\n\n\n\nPython\n\n\noptimizer = Optimizer(\n    model=text_classifier,\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(logProbAsInput=False),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    val_rdd=val_rdd,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()])\n\n\n\n\n\n\nDo prediction\n\n\nAfter training the model, it can be used to predict probabilities or class labels.\n\n\nScala\n\n\n// Predict for probability distributions\nval results = textClassifier.predict(rdd)\n// Predict for class labels\nval resultClasses = textClassifier.predictClass(rdd)\n\n\n\n\nPython\n\n\n# Predict for probability distributions\nresults = text_classifier.predict(rdd)\n# Predict for class labels\nresult_classes = text_classifier.predict_class(rdd)\n\n\n\n\n\n\nExamples\n\n\nWe provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nSee \nhere\n for the Scala example.\n\n\nSee \nhere\n for the Python example.", 
            "title": "Text Classification API"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#build-a-textclassifier-model", 
            "text": "Scala  val textClassifier = TextClassifier(classNum, tokenLength, sequenceLength = 500, encoder =  cnn , encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  tokenLength : The size of each word vector. Positive integer.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   Python  text_classifier = TextClassifier(class_num, token_length, sequence_length=500, encoder= cnn , encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  token_length : The size of each word vector. Positive int.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.", 
            "title": "Build a TextClassifier model"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#train-a-textclassifier-model", 
            "text": "After building the model, we can use BigDL Optimizer to train it (with validation) using RDD of  Sample .  Note that raw text data may need to go through tokenization and vectorization before being fed into the Optimizer. You can refer to the  examples  we provide for data pre-processing.  Scala  val optimizer = Optimizer(\n  model = textClassifier,\n  sampleRDD = trainRDD,\n  criterion = ClassNLLCriterion[Float](logProbAsInput = false),\n  batchSize = 128)\n\noptimizer\n  .setOptimMethod(new Adagrad(learningRate = 0.01, learningRateDecay = 0.001))\n  .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), 128)\n  .setEndWhen(Trigger.maxEpoch(20))\n  .optimize()  Python  optimizer = Optimizer(\n    model=text_classifier,\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(logProbAsInput=False),\n    end_trigger=MaxEpoch(20),\n    batch_size=128,\n    optim_method=Adagrad(learningrate=0.01, learningrate_decay=0.001))\n\noptimizer.set_validation(\n    batch_size=128,\n    val_rdd=val_rdd,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()])", 
            "title": "Train a TextClassifier model"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#do-prediction", 
            "text": "After training the model, it can be used to predict probabilities or class labels.  Scala  // Predict for probability distributions\nval results = textClassifier.predict(rdd)\n// Predict for class labels\nval resultClasses = textClassifier.predictClass(rdd)  Python  # Predict for probability distributions\nresults = text_classifier.predict(rdd)\n# Predict for class labels\nresult_classes = text_classifier.predict_class(rdd)", 
            "title": "Do prediction"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/#examples", 
            "text": "We provide an example to train the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  See  here  for the Scala example.  See  here  for the Python example.", 
            "title": "Examples"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/", 
            "text": "Analytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model. \n\n\nHighlights\n\n\n\n\nEasy-to-use models, could be fed into NNFrames or BigDL Optimizer for training.\n\n\nRecommenders can handle either explict or implicit feedback, given corresponding features.\n\n\nIt provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items).\n\n\n\n\nThe examples/notebooks are included in the Analytics Zoo source code.\n\n\n\n\nWide and Deep Learning Model.\n    \nScala example\n\n    \nPython notebook\n\n\nNCF.\n    \nScala example\n\n    \nPython notebook\n\n\n\n\n\n\nWide and Deep\n\n\nScala\n\n\nBuild a WND model for recommendation. \n\n\nval wideAndDeep = WideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer.\n\n\nval optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n.\n\n\nPython\n\n\nBuild a WND model for recommendation. \n\n\nwide_n_deep = WideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nScala\n\n\nBuild a NCF model for recommendation. \n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\nval optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a NCF model for recommendation. \n\n\nncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our \nRecommender API\n and \nPython notebook\n.", 
            "title": "Recommendation API"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#wide-and-deep", 
            "text": "Scala  Build a WND model for recommendation.   val wideAndDeep = WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))  Train a WND model using BigDL Optimizer.  val optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example .  Python  Build a WND model for recommendation.   wide_n_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))  Train a WND model using BigDL Optimizer   optimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .", 
            "title": "Wide and Deep"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "Scala  Build a NCF model for recommendation.   val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)  Train a NCF model using BigDL Optimizer   val optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example  Python  Build a NCF model for recommendation.   ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)  Train a NCF model using BigDL Optimizer   optimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)  See more details in our  Recommender API  and  Python notebook .", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/ProgrammingGuide/usercases-overview/", 
            "text": "Overview\n\n\nAnalytics Zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in \nanalytics-zoo/apps\n.\n\n\n\n\n\n\nAnomaly Detection\n demostrates using LSTM network to detect anomalies in time series data.\n\n\n\n\n\n\nFraud Detection\n demostrates using feed-forward neural network to detect frauds in credit card transactions data. \n\n\n\n\n\n\nImage Augmentation\n demostrates how to do image augmentation for vision projects. \n\n\n\n\n\n\nObject Detection\n demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos. \n\n\n\n\n\n\nRecommendation\n demonstrates how to use Analytics Zoo Recommendation APIs (i.e.Neural Collaborative Filtering, Wide and Deep Learning) to do recommendation on data with explicit feedback. \n\n\n\n\n\n\nSentiment Analysis\n demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU, Bi-LSTM).  \n\n\n\n\n\n\nVariational AutoEncoder\n demostrates how to use variational autoencoder to generate faces and digital numbers.", 
            "title": "Use Cases"
        }, 
        {
            "location": "/ProgrammingGuide/usercases-overview/#overview", 
            "text": "Analytics Zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in  analytics-zoo/apps .    Anomaly Detection  demostrates using LSTM network to detect anomalies in time series data.    Fraud Detection  demostrates using feed-forward neural network to detect frauds in credit card transactions data.     Image Augmentation  demostrates how to do image augmentation for vision projects.     Object Detection  demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos.     Recommendation  demonstrates how to use Analytics Zoo Recommendation APIs (i.e.Neural Collaborative Filtering, Wide and Deep Learning) to do recommendation on data with explicit feedback.     Sentiment Analysis  demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU, Bi-LSTM).      Variational AutoEncoder  demostrates how to use variational autoencoder to generate faces and digital numbers.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/", 
            "text": "Analytics Zoo shows how to detect anomalies in time series data based on RNN network. Currently, a \nPython notebook\n is provided. \nIn the example, a RNN network using Analytics Zoo Keras-Style API is built, and \nNYC taxi passengers dataset\n is used to train and test the model.\n\n\nWe split the entire curve into 2 sections - training data and testing data. The training data section is treated all as normal and an RNN model is trained to fit the training data, the model has three LSTM layers followed by one Dense layer at the end.\n\n\nmodel = Sequential()\nmodel.add(LSTM(input_shape=(input_dim1, input_dim2, output_dim=8, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(15,return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=1))\n\n\n\n\nTrain the model using using MSE loss (as a regression problem).\n\n\nmodel.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(x_train,y_train,batch_size=3028,nb_epoch=30)\n\n\n\n\nUse this RNN model to predict the testing curve.\n\n\npredictions = model.predict(x_test)\n\n\n\n\nAnomalies could be defined by comparing the predictions and actual values. The current example defines data points as anomalies if the difference of predictions and actual values are larger than a certain value(threshold).\nSee more details in the exmaple \nPython notebook", 
            "title": "Anomaly Detection"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/", 
            "text": "NNEstimator\n\n\nScala:\n\n\nval estimator = NNEstimator(model, criterion)\n\n\n\n\nPython:\n\n\nestimator = NNEstimator(model, criterion)\n\n\n\n\nNNEstimator\n extends \norg.apache.spark.ml.Estimator\n and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.\n\n\nNNEstimator\n supports different feature and label data types through \nPreprocessing\n.\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe \nPreprocessing\n to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL \nSample\n. Each\n\nPreprocessing\n conducts a data conversion step in the preprocessing phase, multiple\n\nPreprocessing\n can be combined into a \nChainedPreprocessing\n. Some pre-defined \n\nPreprocessing\n for popular data types like Image, Array or Vector are provided in package\n\ncom.intel.analytics.zoo.feature\n, while user can also develop customized \nPreprocessing\n.\nBy default, \nSeqToTensor\n is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the \nPreprocessing\n allows \nNNEstimator\n to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\nMore concrete examples are available in package \ncom.intel.analytics.zoo.examples.nnframes\n\n\nNNEstimator\n can be created with various parameters for different scenarios.\n\n\n\n\nNNEstimator(model, criterion)\n\n\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   \nPreprocessing\n. \nNNEstimator\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL \nSample\n and send to model for\n   training.\n2. \nNNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). \nNNEstimator\n\n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n3. \nNNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion, featurePreprocessing and labelPreprocessing.  \nNNEstimator\n\n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNEstimator\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample according to user-specified Preprocessing.\n\n\nScala Example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)\n\n\n\n\n\n\nNNModel\n\n\nScala:\n\n\nval nnModel = NNModel(bigDLModel)\n\n\n\n\nPython:\n\n\nnn_model = NNModel(bigDLModel)\n\n\n\n\nNNModel\n extends Spark's ML\n\nTransformer\n. User can invoke\n\nfit\n in \nNNEstimator\n to get a \nNNModel\n, or directly compose a \nNNModel\n from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for \nDataFrame\n(DataSet)\n. \n\n\nNNModel\n can be created with various parameters for different scenarios.\n\n\n\n\nNNModel(model)\n\n\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNModel\n will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2. \nNNModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3. \nNNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNModel\n will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNModel\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nNNClassifier\n\n\nScala:\n\n\nval classifer =  NNClassifer(model, criterion)\n\n\n\n\nPython:\n\n\nclassifier = NNClassifer(model, criterion)\n\n\n\n\nNNClassifier\n is a specialized \nNNEstimator\n that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted \nNNClassifierModel\n will have the prediction column of \nDoubleType.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\n\n\nNNClassifier\n can be created with various parameters for different scenarios.\n\n\n\n\nNNClassifier(model, criterion)\n\n\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   Preprocessing. \nNNClassifier\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n2. \nNNClassifier(model, criterion, featureSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int). \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size. \nScalarToTensor\n is used to convert the label column.\n3. \nNNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion and featurePreprocessing.  \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifier\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample with user-specified Preprocessing.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\n\n\n\n\nNNClassifierModel\n\n\nScala:\n\n\nval nnClassifierModel = NNClassifierModel(model, featureSize)\n\n\n\n\nPython:\n\n\nnn_classifier_model = NNClassifierModel(model)\n\n\n\n\nNNClassifierModel is a specialized \nNNModel\n for classification tasks.\nBoth label and prediction column will have the datatype of Double.\n\n\nNNClassifierModel\n can be created with various parameters for different scenarios.\n\n\n\n\nNNClassifierModel(model)\n\n\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNClassifierModel\n will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2. \nNNClassifierModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNClassifierModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3. \nNNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNClassifierModel\n will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifierModel\n\nsupports: \nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nHyperparameter setting\n\n\nPrior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or\n\nNNEstimator\n/\nNNClassifier\n will use the default value.\n\n\nContinue the codes above, NNEstimator and NNClassifier can be set in the same way.\n\n\nScala:\n\n\n//for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n\n\n\n\nPython:\n\n\n# for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n\n\n\n\n\nPrepare the data and start the training process\n\n\nNNEstimator/NNCLassifer supports training with Spark's\n\nDataFrame/DataSet\n\n\nSuppose \ndf\n is the training data, simple call \nfit\n method and let Analytics Zoo train the model\nfor you.\n\n\nScala:\n\n\n//get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)\n\n\n\n\nPython:\n\n\n# get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)\n\n\n\n\nUser may also set validation DataFrame and validation frequency through \nsetValidation\n method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.\n\n\nMake prediction on chosen data\n\n\nSince \nNNModel\n/\nNNClassifierModel\n inherits from Spark's \nTransformer\n abstract class, simply call \n\ntransform\n method on \nNNModel\n/\nNNClassifierModel\n to make prediction.\n\n\nScala:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nPython:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nFor the complete examples of NNFrames, please refer to:\n\nScala examples\n\n\nPython examples\n\n\nNNImageReader\n\n\nNNImageReader\n is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.\n\n\nScala:\n\n\n    val imageDF = NNImageReader.readImages(imageDirectory, sc)\n\n\n\n\nPython:\n\n\n    image_frame = NNImageReader.readImages(image_path, self.sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.", 
            "title": "NNFrames"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnestimator", 
            "text": "Scala:  val estimator = NNEstimator(model, criterion)  Python:  estimator = NNEstimator(model, criterion)  NNEstimator  extends  org.apache.spark.ml.Estimator  and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.  NNEstimator  supports different feature and label data types through  Preprocessing .\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe  Preprocessing  to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL  Sample . Each Preprocessing  conducts a data conversion step in the preprocessing phase, multiple Preprocessing  can be combined into a  ChainedPreprocessing . Some pre-defined  Preprocessing  for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized  Preprocessing .\nBy default,  SeqToTensor  is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the  Preprocessing  allows  NNEstimator  to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\nMore concrete examples are available in package  com.intel.analytics.zoo.examples.nnframes  NNEstimator  can be created with various parameters for different scenarios.   NNEstimator(model, criterion)   Takes only model and criterion and use  SeqToTensor  as feature and label\n    Preprocessing .  NNEstimator  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL  Sample  and send to model for\n   training.\n2.  NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])  Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int).  NNEstimator \n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n3.  NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion, featurePreprocessing and labelPreprocessing.   NNEstimator \n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNEstimator  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample according to user-specified Preprocessing.  Scala Example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)", 
            "title": "NNEstimator"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnmodel", 
            "text": "Scala:  val nnModel = NNModel(bigDLModel)  Python:  nn_model = NNModel(bigDLModel)  NNModel  extends Spark's ML Transformer . User can invoke fit  in  NNEstimator  to get a  NNModel , or directly compose a  NNModel  from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for  DataFrame\n(DataSet) .   NNModel  can be created with various parameters for different scenarios.   NNModel(model)   Takes only model and use  SeqToTensor  as feature Preprocessing.  NNModel  will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2.  NNModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3.  NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNModel  will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNModel  supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifier", 
            "text": "Scala:  val classifer =  NNClassifer(model, criterion)  Python:  classifier = NNClassifer(model, criterion)  NNClassifier  is a specialized  NNEstimator  that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted  NNClassifierModel  will have the prediction column of \nDoubleType.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient   NNClassifier  can be created with various parameters for different scenarios.   NNClassifier(model, criterion)   Takes only model and criterion and use  SeqToTensor  as feature and label\n   Preprocessing.  NNClassifier  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n2.  NNClassifier(model, criterion, featureSize: Array[Int])  Takes model, criterion, featureSize(Array of Int).  NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size.  ScalarToTensor  is used to convert the label column.\n3.  NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion and featurePreprocessing.   NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifier  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample with user-specified Preprocessing.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)", 
            "title": "NNClassifier"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifiermodel", 
            "text": "Scala:  val nnClassifierModel = NNClassifierModel(model, featureSize)  Python:  nn_classifier_model = NNClassifierModel(model)  NNClassifierModel is a specialized  NNModel  for classification tasks.\nBoth label and prediction column will have the datatype of Double.  NNClassifierModel  can be created with various parameters for different scenarios.   NNClassifierModel(model)   Takes only model and use  SeqToTensor  as feature Preprocessing.  NNClassifierModel  will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2.  NNClassifierModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNClassifierModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3.  NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNClassifierModel  will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifierModel \nsupports:  setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNClassifierModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#hyperparameter-setting", 
            "text": "Prior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier  will use the default value.  Continue the codes above, NNEstimator and NNClassifier can be set in the same way.  Scala:  //for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())  Python:  # for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())", 
            "title": "Hyperparameter setting"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#prepare-the-data-and-start-the-training-process", 
            "text": "NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet  Suppose  df  is the training data, simple call  fit  method and let Analytics Zoo train the model\nfor you.  Scala:  //get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)  Python:  # get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)  User may also set validation DataFrame and validation frequency through  setValidation  method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.", 
            "title": "Prepare the data and start the training process"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#make-prediction-on-chosen-data", 
            "text": "Since  NNModel / NNClassifierModel  inherits from Spark's  Transformer  abstract class, simply call  transform  method on  NNModel / NNClassifierModel  to make prediction.  Scala:  nnModel.transform(df).show(false)  Python:  nnModel.transform(df).show(false)  For the complete examples of NNFrames, please refer to: Scala examples  Python examples", 
            "title": "Make prediction on chosen data"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnimagereader", 
            "text": "NNImageReader  is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.  Scala:      val imageDF = NNImageReader.readImages(imageDirectory, sc)  Python:      image_frame = NNImageReader.readImages(image_path, self.sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "NNImageReader"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/", 
            "text": "Basic operators: \n+ - * /\n\n\nThose are supported as element-wise operation.\n\n\nScala example\n\n\nx + 1.0\nx + y\n\n\n\n\nPython example\n\n\nx + 1.0\nx + y\n\n\n\n\nmean\n\n\nMean of a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepDims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeepDims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nmean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nmean(x, axis=0, keepDims=False):\n\n\n\n\nabs\n\n\nElement-wise absolute value.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nabs(x: Variable[T])\n\n\n\n\nPython example\n\n\nabs(x):\n\n\n\n\nsum\n\n\nSum of the values in a \nVariable\n, alongside the specified axis.\n- \naxis\n axis to compute the mean. 0-based indexed.\n- \nkeepDims\n A boolean, whether to keep the dimensions or not.\n   If \nkeepdims\n is \nFalse\n, the rank of the \nVariable\n is reduced\n   by 1. If \nkeep_dims\n is \nTrue\n,\n   the reduced dimensions are retained with length 1.\n\n\nScala example\n\n\nsum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)\n\n\n\n\nPython example\n\n\nsum(x, axis=0, keepDims=False):\n\n\n\n\nclip\n\n\nElement-wise value clipping.\n- \nx\n A \nVariable\n.\n- \nmin\n Double\n- \nmax\n Double\n\n\nScala example\n\n\nclip(x: Variable[T], min: Double, max: Double)\n\n\n\n\nPython example\n\n\nclip(x, min, max)\n\n\n\n\nsquare\n\n\nElement-wise square.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsquare(x: Variable[T])\n\n\n\n\nPython example\n\n\nsquare(x):\n\n\n\n\nsqrt\n\n\nElement-wise square root.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nsqrt(x: Variable[T])\n\n\n\n\nPython example\n\n\nsqrt(x):\n\n\n\n\nmaximum\n\n\nElement-wise maximum of two \nVariables\n.\n- \nx\n A \nVariable\n.\n- \ny\n A \nVariable\n or Double.\n\n\nScala example\n\n\nmaximum(x: Variable[T], y: Variable[T])\n\n\n\n\nPython example\n\n\nmaximum(x, y):\n\n\n\n\nlog\n\n\nElement-wise log.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nlog(x: Variable[T])\n\n\n\n\nPython example\n\n\nlog(x):\n\n\n\n\nexp\n\n\nElement-wise exponential.\n- \nx\n A \nVariable\n.\n\n\nScala example\n\n\nexp(x: Variable[T])\n\n\n\n\nPython example\n\n\nexp(x):\n\n\n\n\npow\n\n\nElement-wise exponentiation.\n- \nx\n A \nVariable\n.\n- \na\n Double.   \n\n\nScala example\n\n\npow(x: Variable[T])\n\n\n\n\nPython example\n\n\npow(x):\n\n\n\n\nsoftsign\n\n\nSoftsign of a \nVariable\n.\n\n\nScala example\n\n\nsoftsign(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftsign(x):\n\n\n\n\nsoftplus\n\n\nSoftplus of a \nVariable\n.\n\n\nScala example\n\n\nsoftplus(x: Variable[T])\n\n\n\n\nPython example\n\n\nsoftplus(x):", 
            "title": "Autograd"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#basic-operators-", 
            "text": "Those are supported as element-wise operation.  Scala example  x + 1.0\nx + y  Python example  x + 1.0\nx + y", 
            "title": "Basic operators: + - * /"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#mean", 
            "text": "Mean of a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepDims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keepDims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  mean(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  mean(x, axis=0, keepDims=False):", 
            "title": "mean"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#abs", 
            "text": "Element-wise absolute value.\n-  x  A  Variable .  Scala example  abs(x: Variable[T])  Python example  abs(x):", 
            "title": "abs"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#sum", 
            "text": "Sum of the values in a  Variable , alongside the specified axis.\n-  axis  axis to compute the mean. 0-based indexed.\n-  keepDims  A boolean, whether to keep the dimensions or not.\n   If  keepdims  is  False , the rank of the  Variable  is reduced\n   by 1. If  keep_dims  is  True ,\n   the reduced dimensions are retained with length 1.  Scala example  sum(x: Variable[T], axis: Int = 0, keepDims: Boolean = false)  Python example  sum(x, axis=0, keepDims=False):", 
            "title": "sum"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#clip", 
            "text": "Element-wise value clipping.\n-  x  A  Variable .\n-  min  Double\n-  max  Double  Scala example  clip(x: Variable[T], min: Double, max: Double)  Python example  clip(x, min, max)", 
            "title": "clip"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#square", 
            "text": "Element-wise square.\n-  x  A  Variable .  Scala example  square(x: Variable[T])  Python example  square(x):", 
            "title": "square"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#sqrt", 
            "text": "Element-wise square root.\n-  x  A  Variable .  Scala example  sqrt(x: Variable[T])  Python example  sqrt(x):", 
            "title": "sqrt"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#maximum", 
            "text": "Element-wise maximum of two  Variables .\n-  x  A  Variable .\n-  y  A  Variable  or Double.  Scala example  maximum(x: Variable[T], y: Variable[T])  Python example  maximum(x, y):", 
            "title": "maximum"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#log", 
            "text": "Element-wise log.\n-  x  A  Variable .  Scala example  log(x: Variable[T])  Python example  log(x):", 
            "title": "log"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#exp", 
            "text": "Element-wise exponential.\n-  x  A  Variable .  Scala example  exp(x: Variable[T])  Python example  exp(x):", 
            "title": "exp"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#pow", 
            "text": "Element-wise exponentiation.\n-  x  A  Variable .\n-  a  Double.     Scala example  pow(x: Variable[T])  Python example  pow(x):", 
            "title": "pow"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#softsign", 
            "text": "Softsign of a  Variable .  Scala example  softsign(x: Variable[T])  Python example  softsign(x):", 
            "title": "softsign"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/#softplus", 
            "text": "Softplus of a  Variable .  Scala example  softplus(x: Variable[T])  Python example  softplus(x):", 
            "title": "softplus"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/", 
            "text": "Net\n\n\nLoad Analytics Zoo Model\n\n\nUse \nNet.load\n(in Scala) or \nNet.load\n (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.  \nNet\n (Scala) or \nNet\n(Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.\n\n\nScala example\n\n\nval model = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.load(\nhdfs://...\n) //load from hdfs\nval model = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.load(\nhdfs://...\n) //load from hdfs\nmodel = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nLoad BigDL Model\n\n\nScala example\n\n\nval model = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nval model = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nLoad Torch Model\n\n\nScala example\n\n\nval model = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nval model = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nval model = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nmodel = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nLoad Caffe Model\n\n\nScala example\n\n\nval model = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nval model = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nval model = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nmodel = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nmodel = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nLoad Tensorflow model\n\n\nWe also provides utilities to load tensorflow model.\nfor more information.\n\n\nIf we already have a frozen graph protobuf file, we can use the \nloadTF\n api directly to\nload the tensorflow model. \n\n\nOtherwise, we should first use the \nexport_tf_checkpoint.py\n script provided by BigDL's distribution\npackage, or the \ndump_model\n function defined in \nhere\n to\ngenerate the model definition file (\nmodel.pb\n) and variable binary file (\nmodel.bin\n). \n\n\nUse Script\n\n\nGRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH\n\n\n\n\nUse python function\n\n\nimport tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path = \n/tmp/model\n\n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)\n\n\n\n\nThen we can use the \nloadTF\n api to load the tensorflow model into BigDL.\n\n\nScala example\n\n\nval modelPath = \n/tmp/model/model.pb\n\nval binPath = \n/tmp/model/model.bin\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\n\n// For tensorflow frozen graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))\n\n\n\n\nPython example\n\n\nmodel_def = \n/tmp/model/model.pb\n\nmodel_variable = \n/tmp/model/model.bin\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\n# For tensorflow frozen graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n)\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n, bin_file=model_variable)\n\n\n\n\nTFNet\n\n\nScala:\n\n\nval m = TFNet(frozenModelPath, inputs, outputs)\n\n\n\n\nPython:\n\n\nm = TFNet(frozen_model_path, inputs, outputs)\n\n\n\n\nThis is a layer that wraps a tensorflow frozen sub graph as a layer and run tensorflow in parallel.", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#net", 
            "text": "", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-analytics-zoo-model", 
            "text": "Use  Net.load (in Scala) or  Net.load  (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.   Net  (Scala) or  Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.  Scala example  val model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.load( hdfs://... ) //load from hdfs\nval model = Net.load( s3://... ) //load from s3  Python example  model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.load( hdfs://... ) //load from hdfs\nmodel = Net.load( s3://... ) //load from s3", 
            "title": "Load Analytics Zoo Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-bigdl-model", 
            "text": "Scala example  val model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.loadBigDL( hdfs://... ) //load from hdfs\nval model = Net.loadBigDL( s3://... ) //load from s3  Python example  model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.loadBigDL( hdfs://... ) //load from hdfs\nmodel = Net.loadBigDL( s3://... ) //load from s3", 
            "title": "Load BigDL Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-torch-model", 
            "text": "Scala example  val model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nval model = Net.loadTorch( hdfs://... ) //load from hdfs\nval model = Net.loadTorch( s3://... ) //load from s3  Python example  model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nmodel = Net.loadTorch( hdfs://... ) //load from hdfs\nmodel = Net.loadTorch( s3://... ) //load from s3", 
            "title": "Load Torch Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-caffe-model", 
            "text": "Scala example  val model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nval model = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nval model = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3  Python example  model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nmodel = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nmodel = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3", 
            "title": "Load Caffe Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-tensorflow-model", 
            "text": "We also provides utilities to load tensorflow model.\nfor more information.  If we already have a frozen graph protobuf file, we can use the  loadTF  api directly to\nload the tensorflow model.   Otherwise, we should first use the  export_tf_checkpoint.py  script provided by BigDL's distribution\npackage, or the  dump_model  function defined in  here  to\ngenerate the model definition file ( model.pb ) and variable binary file ( model.bin ).   Use Script  GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH  Use python function  import tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path =  /tmp/model \n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)  Then we can use the  loadTF  api to load the tensorflow model into BigDL.  Scala example  val modelPath =  /tmp/model/model.pb \nval binPath =  /tmp/model/model.bin \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\n\n// For tensorflow frozen graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))  Python example  model_def =  /tmp/model/model.pb \nmodel_variable =  /tmp/model/model.bin \ninputs = [ Placeholder ]\noutputs = [ output ]\n# For tensorflow frozen graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float )\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float , bin_file=model_variable)", 
            "title": "Load Tensorflow model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfnet", 
            "text": "Scala:  val m = TFNet(frozenModelPath, inputs, outputs)  Python:  m = TFNet(frozen_model_path, inputs, outputs)  This is a layer that wraps a tensorflow frozen sub graph as a layer and run tensorflow in parallel.", 
            "title": "TFNet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/", 
            "text": "Analytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nScala:\n\n\npackage com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1): DataFrame\n}\n\n\n\n\nRead the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.\n\n\n\n\npath: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).\n\n\nsc: SparkContext to be used.\n\n\nminPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead\n\n\n\n\nPython:\n\n\nclass zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, bigdl_type=\nfloat\n)\n\n\n\n\nImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala APIs:\n\n\nobject com.intel.analytics.zoo.feature.image.ImageSet\n\n\n\n\ndef array(data: Array[ImageFeature]): LocalImageSet\n\n\n\n\nCreate LocalImageSet from array of ImeageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\ndef rdd(data: RDD[ImageFeature]): DistributedImageSet\n\n\n\n\nCreate DistributedImageSet from rdd of ImageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\n  def read(path: String, sc: SparkContext = null, minPartitions: Int = 1): ImageSet\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\n\n\nExample:\n\n\n// create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.ImageSet\n\n\n\n\nread(path, sc=None, min_partitions=1, bigdl_type=\nfloat\n)\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\n\n\nPython example:\n\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. \n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndeltaLow: low bound of brightness parameter\n\n\ndeltaHigh: high bound of brightness parameter\n\n\n\n\nExample:\n\n\nval transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type=\nfloat\n)\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndelta_low: low bound of brightness parameter\n\n\ndelta_high: high bound of brightness parameter\n\n\n\n\nExample:\n\n\ntransformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)", 
            "title": "Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-to-data-frame", 
            "text": "Scala:  package com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1): DataFrame\n}  Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.   path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).  sc: SparkContext to be used.  minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead   Python:  class zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, bigdl_type= float )", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala APIs:  object com.intel.analytics.zoo.feature.image.ImageSet  def array(data: Array[ImageFeature]): LocalImageSet  Create LocalImageSet from array of ImeageFeature   data: array of ImageFeature   def rdd(data: RDD[ImageFeature]): DistributedImageSet  Create DistributedImageSet from rdd of ImageFeature   data: array of ImageFeature     def read(path: String, sc: SparkContext = null, minPartitions: Int = 1): ImageSet  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.   Example:  // create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read( /tmp/image/ , sc, 2)  Python APIs:  class zoo.feature.image.ImageSet  read(path, sc=None, min_partitions=1, bigdl_type= float )  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.   Python example:  # create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "ImageSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#image-transformer", 
            "text": "Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call  transform  with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training.   Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness  Adjust the image brightness.   deltaLow: low bound of brightness parameter  deltaHigh: high bound of brightness parameter   Example:  val transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)  Python APIs:  class zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type= float )  Adjust the image brightness.   delta_low: low bound of brightness parameter  delta_high: high bound of brightness parameter   Example:  transformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/preprocessing/", 
            "text": "", 
            "title": "Preprocessing"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink.\n\n\nModel Load\n\n\nUse \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float](\n/tmp/zoo.model\n) //load from local fs\nval model = ObjectDetector.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ObjectDetector.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model(\n/tmp/zoo.model\n) //load from local fs\nmodel = ObjectDetector.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ObjectDetector.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.\n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageSet before model inference\n\n\npostProcessor: postprocessor of ImageSet after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)\n\n\n\n\nPredict with loaded object detection model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this prediction\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel(\n/tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model\n)\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  prediction\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Object Detection"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#model-load", 
            "text": "Use  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float]( /tmp/zoo.model ) //load from local fs\nval model = ObjectDetector.loadModel( hdfs://... ) //load from hdfs\nval model = ObjectDetector.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model( /tmp/zoo.model ) //load from local fs\nmodel = ObjectDetector.load_model( hdfs://... ) //load from hdfs\nmodel = ObjectDetector.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.  Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageSet before model inference  postProcessor: postprocessor of ImageSet after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#predict-with-loaded-object-detection-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this prediction   Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.initNNContext()\nval model = ObjectDetector.loadModel( /tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model )\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  prediction   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.objectdetection import *\n\nsc = init_nncontext()\nmodel = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Predict with loaded object detection model"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nModel Load\n\n\nUse \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.  \nModule\n (Scala) or \nModel\n(Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float](\n/tmp/model.zoo\n, \n/tmp/model.bin\n) //load from local fs\nval model = ImageClassifier.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ImageClassifier.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model(\n/tmp/...model\n, \n/tmp/model.bin\n) //load from local fs\nmodel = ImageClassifier.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ImageClassifier.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. \n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageFrame before model inference\n\n\npostProcessor: postprocessor of ImageFrame after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing) \n\n\n\n\nPredict with loaded image classification model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  predcition\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel(\n/tmp/analytics-zoo_inception-v1_imagenet_0.1.0\n) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this predcition\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Image Classification"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#model-load", 
            "text": "Use  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.   Module  (Scala) or  Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float]( /tmp/model.zoo ,  /tmp/model.bin ) //load from local fs\nval model = ImageClassifier.loadModel( hdfs://... ) //load from hdfs\nval model = ImageClassifier.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model( /tmp/...model ,  /tmp/model.bin ) //load from local fs\nmodel = ImageClassifier.load_model( hdfs://... ) //load from hdfs\nmodel = ImageClassifier.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.   Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageFrame before model inference  postProcessor: postprocessor of ImageFrame after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#predict-with-loaded-image-classification-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  predcition   Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.initNNContext()\nval model = ImageClassifier.loadModel( /tmp/analytics-zoo_inception-v1_imagenet_0.1.0 ) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this predcition   Python example  from zoo.common.nncontext import *\nfrom zoo.models.image.imageclassification import *\n\nsc = init_nncontext()\nmodel = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = model.predict_image_set(image_set)", 
            "title": "Predict with loaded image classification model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/", 
            "text": "Analytics Zoo provides pre-defined models having different encoders that can be used for classifying texts.\nThe model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\n\n\nBuild a TextClassifier Model\n\n\nScala\n\n\nval textClassifier = TextClassifier(classNum, tokenLength, sequenceLength = 500, encoder = \ncnn\n, encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\ntokenLength\n: The size of each word vector. Positive integer.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nSee \nhere\n for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nPython\n\n\ntext_classifier = TextClassifier(class_num, token_length, sequence_length=500, encoder=\ncnn\n, encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\ntoken_length\n: The size of each word vector. Positive int.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\nSee \nhere\n for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\n\n\nModel Save\n\n\nAfter building and training a TextClassifier model, you can save it for future use.\n\n\nScala\n\n\ntextClassifier.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\ntext_classifier.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nModel Load\n\n\nTo load a TextClassifier model (with weights) saved \nabove\n:\n\n\nScala\n\n\nTextClassifier.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nTextClassifier.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.", 
            "title": "Text Classification"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#build-a-textclassifier-model", 
            "text": "Scala  val textClassifier = TextClassifier(classNum, tokenLength, sequenceLength = 500, encoder =  cnn , encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  tokenLength : The size of each word vector. Positive integer.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   See  here  for the Scala example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.  Python  text_classifier = TextClassifier(class_num, token_length, sequence_length=500, encoder= cnn , encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  token_length : The size of each word vector. Positive int.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.   See  here  for the Python example that trains the TextClassifier model on 20 Newsgroup dataset and uses the model to do prediction.", 
            "title": "Build a TextClassifier Model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#model-save", 
            "text": "After building and training a TextClassifier model, you can save it for future use.  Scala  textClassifier.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  text_classifier.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Model Save"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#model-load", 
            "text": "To load a TextClassifier model (with weights) saved  above :  Scala  TextClassifier.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  TextClassifier.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/", 
            "text": "Analytics Zoo provides two Recommenders, including Wide and Deep (WND) model and Neural network-based Collaborative Filtering (NCF) model. Each model could be fed into NNFrames or BigDL Optimizer directly for training.\n\n\nRecommenders can handle models with either explict or implicit feedback, given corresponding features.\n\n\nWe also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See \nhere\n for more details.\n\n\n\n\nWide and Deep\n\n\nWide and Deep Learning Model, proposed by \nGoogle, 2016\n, is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.\n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval wideAndDeep = WideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\n\n\nmodelType\n: String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\ncolumnInfo\n An instance of \nColumnFeatureInfo\n.\n\n\nhiddenLayers\n: Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).\n\n\n\n\nSee \nhere\n for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nwide_and_deep = WideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\n\n\nclass_num\n: The number of classes. Positive int.\n\n\ncolumn_info\n: An instance of \nColumnFeatureInfo\n.\n\n\nmodel_type\n: String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.\n\n\nhidden_layers\n: Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).\n\n\n\n\nSee \nhere\n for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nNCF (\nHe, 2015\n) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. \nincludeMF\n(Boolean) is provided for users to build a \nNeuralCF\n model with or without matrix factorization. \n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\n\n\nuserCount\n: The number of users. Positive integer.\n\n\nitemCount\n: The number of items. Positive integer.\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\nuserEmbed\n: Units of user embedding. Positive integer. Default is 20.\n\n\nitemEmbed\n: Units of item embedding. Positive integer. Default is 20.\n\n\nhiddenLayers\n: Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).\n\n\nincludeMF\n: Whether to include Matrix Factorization. Boolean. Default is true.\n\n\nmfEmbed\n: Units of matrix factorization embedding. Positive integer. Default is 20.\n\n\n\n\nSee \nhere\n for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\n\n\nuser_count\n: The number of users. Positive int.\n\n\nitem_count\n: The number of classes. Positive int.\n\n\nclass_num:\n The number of classes. Positive int.\n\n\nuser_embed\n: Units of user embedding. Positive int. Default is 20.\n\n\nitem_embed\n: itemEmbed Units of item embedding. Positive int. Default is 20.\n\n\nhidden_layers\n: Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).\n\n\ninclude_mf\n: Whether to include Matrix Factorization. Boolean. Default is True.\n\n\nmf_embed\n: Units of matrix factorization embedding. Positive int. Default is 20.\n\n\n\n\nSee \nhere\n for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nPrediction and Recommendation\n\n\nPredict for user-item pairs\n\n\nGive prediction for each pair of user and item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\npredictUserItemPair(featureRdd)\n\n\n\n\nPython\n\n\npredict_user_item_pair(feature_rdd)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\n\n\nRecommend for users\n\n\nRecommend a number of items for each user. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForUser(featureRdd, maxItems)\n\n\n\n\nPython\n\n\nrecommend_for_user(feature_rdd, max_items)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxItems\n: The number of items to be recommended to each user. Positive integer.\n\n\n\n\nRecommend for items\n\n\nRecommend a number of users for each item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForItem(featureRdd, maxUsers)\n\n\n\n\nPython\n\n\nrecommend_for_item(feature_rdd, max_users)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxUsers\n: The number of users to be recommended to each item. Positive integer.\n\n\n\n\n\n\nModel Save\n\n\nAfter building and training a WideAndDeep or NeuralCF model, you can save it for future use.\n\n\nScala\n\n\nwideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path to save weights. Default is null.\n\n\noverWrite\n: Whether to overwrite the file if it already exists. Default is false.\n\n\n\n\nPython\n\n\nwide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)\n\n\n\n\n\n\npath\n: The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path to save weights. Default is None.\n\n\nover_write\n: Whether to overwrite the file if it already exists. Default is False.\n\n\n\n\n\n\nModel Load\n\n\nTo load a WideAndDeep or NeuralCF model (with weights) saved \nabove\n:\n\n\nScala\n\n\nWideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".\n\n\nweightPath\n: The path for pre-trained weights if any. Default is null.\n\n\n\n\nPython\n\n\nWideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)\n\n\n\n\n\n\npath\n: The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.\n\n\nweight_path\n: The path for pre-trained weights if any. Default is None.\n\n\n\n\n\n\nUserItemFeature\n\n\nRepresent records of user-item with features.\n\n\nEach record should contain the following fields:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitem_id\n: Positive integer.\n\n\nsample\n: \nSample\n which consists of feature(s) and label(s).\n\n\n\n\nScala\n\n\nUserItemFeature(userId, itemId, sample)\n\n\n\n\nPython\n\n\nUserItemFeature(user_id, item_id, sample)\n\n\n\n\n\n\nUserItemPrediction\n\n\nRepresent the prediction results of user-item pairs.\n\n\nEach prediction record will contain the following information:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitemId\n: Positive integer.\n\n\nprediction\n: The prediction (rating) for the user on the item.\n\n\nprobability\n: The probability for the prediction.\n\n\n\n\nScala\n\n\nUserItemPrediction(userId, itemId, prediction, probability)\n\n\n\n\nPython\n\n\nUserItemPrediction(user_id, item_id, prediction, probability)\n\n\n\n\n\n\nColumnFeatureInfo\n\n\nAn instance of \nColumnFeatureInfo\n contains the same data information shared by the \nWideAndDeep\n model and its feature generation part.\n\n\nYou can choose to include the following information for feature engineering and the \nWideAndDeep\n model:\n\n\n\n\nwideBaseCols\n: Data of \nwideBaseCols\n together with \nwideCrossCols\n will be fed into the wide model.\n\n\nwideBaseDims\n: Dimensions of \nwideBaseCols\n. The dimensions of the data in \nwideBaseCols\n should be within the range of \nwideBaseDims\n.\n\n\nwideCrossCols\n: Data of \nwideCrossCols\n will be fed into the wide model.\n\n\nwideCrossDims\n: Dimensions of \nwideCrossCols\n. The dimensions of the data in \nwideCrossCols\n should be within the range of \nwideCrossDims\n.\n\n\nindicatorCols\n: Data of \nindicatorCols\n will be fed into the deep model as multi-hot vectors. \n\n\nindicatorDims\n: Dimensions of \nindicatorCols\n. The dimensions of the data in \nindicatorCols\n should be within the range of \nindicatorDims\n.\n\n\nembedCols\n: Data of \nembedCols\n will be fed into the deep model as embeddings.\n\n\nembedInDims\n: Input dimension of the data in \nembedCols\n. The dimensions of the data in \nembedCols\n should be within the range of \nembedInDims\n.\n\n\nembedOutDims\n: The dimensions of embeddings for \nembedCols\n.\n\n\ncontinuousCols\n: Data of \ncontinuousCols\n will be treated as continuous values for the deep model.\n\n\nlabel\n: The name of the 'label' column. String. Default is \"label\".\n\n\n\n\nRemark:\n\n\nFields that involve \nCols\n should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.\n\n\nFields that involve \nDims\n should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.\n\n\nIf any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).\n\n\nScala\n\n\nColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label = \nlabel\n)\n\n\n\n\nPython\n\n\nColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label=\nlabel\n)", 
            "title": "Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#wide-and-deep", 
            "text": "Wide and Deep Learning Model, proposed by  Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.  After training the model, users can use the model to  do prediction and recommendation .  Scala  val wideAndDeep = WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))   modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".  numClasses : The number of classes. Positive integer.  columnInfo  An instance of  ColumnFeatureInfo .  hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).   See  here  for the Scala example that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  wide_and_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))   class_num : The number of classes. Positive int.  column_info : An instance of  ColumnFeatureInfo .  model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.  hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).   See  here  for the Python notebook that trains the WideAndDeep model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Wide and Deep"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework.  includeMF (Boolean) is provided for users to build a  NeuralCF  model with or without matrix factorization.   After training the model, users can use the model to  do prediction and recommendation .  Scala  val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)   userCount : The number of users. Positive integer.  itemCount : The number of items. Positive integer.  numClasses : The number of classes. Positive integer.  userEmbed : Units of user embedding. Positive integer. Default is 20.  itemEmbed : Units of item embedding. Positive integer. Default is 20.  hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).  includeMF : Whether to include Matrix Factorization. Boolean. Default is true.  mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20.   See  here  for the Scala example that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  ncf = NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)   user_count : The number of users. Positive int.  item_count : The number of classes. Positive int.  class_num:  The number of classes. Positive int.  user_embed : Units of user embedding. Positive int. Default is 20.  item_embed : itemEmbed Units of item embedding. Positive int. Default is 20.  hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).  include_mf : Whether to include Matrix Factorization. Boolean. Default is True.  mf_embed : Units of matrix factorization embedding. Positive int. Default is 20.   See  here  for the Python notebook that trains the NeuralCF model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#prediction-and-recommendation", 
            "text": "Predict for user-item pairs  Give prediction for each pair of user and item. Return RDD of  UserItemPrediction .  Scala  predictUserItemPair(featureRdd)  Python  predict_user_item_pair(feature_rdd)  Parameters:   featureRdd : RDD of  UserItemFeature .   Recommend for users  Recommend a number of items for each user. Return RDD of  UserItemPrediction .  Scala  recommendForUser(featureRdd, maxItems)  Python  recommend_for_user(feature_rdd, max_items)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxItems : The number of items to be recommended to each user. Positive integer.   Recommend for items  Recommend a number of users for each item. Return RDD of  UserItemPrediction .  Scala  recommendForItem(featureRdd, maxUsers)  Python  recommend_for_item(feature_rdd, max_users)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxUsers : The number of users to be recommended to each item. Positive integer.", 
            "title": "Prediction and Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#model-save", 
            "text": "After building and training a WideAndDeep or NeuralCF model, you can save it for future use.  Scala  wideAndDeep.saveModel(path, weightPath = null, overWrite = false)\n\nncf.saveModel(path, weightPath = null, overWrite = false)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path to save weights. Default is null.  overWrite : Whether to overwrite the file if it already exists. Default is false.   Python  wide_and_deep.save_model(path, weight_path=None, over_write=False)\n\nncf.save_model(path, weight_path=None, over_write=False)   path : The path to save the model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path to save weights. Default is None.  over_write : Whether to overwrite the file if it already exists. Default is False.", 
            "title": "Model Save"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#model-load", 
            "text": "To load a WideAndDeep or NeuralCF model (with weights) saved  above :  Scala  WideAndDeep.loadModel[Float](path, weightPath = null)\n\nNeuralCF.loadModel[Float](path, weightPath = null)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like \"hdfs://[host]:[port]/xxx\". Amazon S3 path should be like \"s3a://bucket/xxx\".  weightPath : The path for pre-trained weights if any. Default is null.   Python  WideAndDeep.load_model(path, weight_path=None)\n\nNeuralCF.load_model(path, weight_path=None)   path : The path for the pre-defined model. Local file system, HDFS and Amazon S3 are supported. HDFS path should be like 'hdfs://[host]:[port]/xxx'. Amazon S3 path should be like 's3a://bucket/xxx'.  weight_path : The path for pre-trained weights if any. Default is None.", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemfeature", 
            "text": "Represent records of user-item with features.  Each record should contain the following fields:   userId : Positive integer.  item_id : Positive integer.  sample :  Sample  which consists of feature(s) and label(s).   Scala  UserItemFeature(userId, itemId, sample)  Python  UserItemFeature(user_id, item_id, sample)", 
            "title": "UserItemFeature"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemprediction", 
            "text": "Represent the prediction results of user-item pairs.  Each prediction record will contain the following information:   userId : Positive integer.  itemId : Positive integer.  prediction : The prediction (rating) for the user on the item.  probability : The probability for the prediction.   Scala  UserItemPrediction(userId, itemId, prediction, probability)  Python  UserItemPrediction(user_id, item_id, prediction, probability)", 
            "title": "UserItemPrediction"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#columnfeatureinfo", 
            "text": "An instance of  ColumnFeatureInfo  contains the same data information shared by the  WideAndDeep  model and its feature generation part.  You can choose to include the following information for feature engineering and the  WideAndDeep  model:   wideBaseCols : Data of  wideBaseCols  together with  wideCrossCols  will be fed into the wide model.  wideBaseDims : Dimensions of  wideBaseCols . The dimensions of the data in  wideBaseCols  should be within the range of  wideBaseDims .  wideCrossCols : Data of  wideCrossCols  will be fed into the wide model.  wideCrossDims : Dimensions of  wideCrossCols . The dimensions of the data in  wideCrossCols  should be within the range of  wideCrossDims .  indicatorCols : Data of  indicatorCols  will be fed into the deep model as multi-hot vectors.   indicatorDims : Dimensions of  indicatorCols . The dimensions of the data in  indicatorCols  should be within the range of  indicatorDims .  embedCols : Data of  embedCols  will be fed into the deep model as embeddings.  embedInDims : Input dimension of the data in  embedCols . The dimensions of the data in  embedCols  should be within the range of  embedInDims .  embedOutDims : The dimensions of embeddings for  embedCols .  continuousCols : Data of  continuousCols  will be treated as continuous values for the deep model.  label : The name of the 'label' column. String. Default is \"label\".   Remark:  Fields that involve  Cols  should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.  Fields that involve  Dims  should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.  If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).  Scala  ColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label =  label )  Python  ColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label= label )", 
            "title": "ColumnFeatureInfo"
        }, 
        {
            "location": "/powered-by/", 
            "text": "Powered By", 
            "title": "Powered by"
        }, 
        {
            "location": "/powered-by/#powered-by", 
            "text": "", 
            "title": "Powered By"
        }, 
        {
            "location": "/known-issues/", 
            "text": "If you encounter the following exception when calling the Python API of Analytics Zoo when you are using Python 3.5 or 3.6:\n\n\n\n\nPy4JJavaError: An error occurred while calling z:org.apache.spark.bigdl.api.python.BigDLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\n\n\n\nyou may need to check whether your input argument involves Numpy types (such as \nnumpy.int64\n). See \nhere\n for the related issue.\n\n\nFor example, invoking \nnp.min\n, \nnp.max\n, \nnp.unique\n, etc. will return type \nnumpy.int64\n. One way to solve this is to use \nint()\n to convert a number of type \nnumpy.int64\n to a Python int.", 
            "title": "FAQ and Known Issues"
        }
    ]
}