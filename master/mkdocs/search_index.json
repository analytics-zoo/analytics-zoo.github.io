{
    "docs": [
        {
            "location": "/", 
            "text": "Analytics Zoo\n\n\nAnalytics + AI Platform for Apache Spark and \nBigDL\n\n\n\n\nAnalytics Zoo makes it easy to build deep learning application on Spark and BigDL, by providing an end-to-end analytics + AI Platform (including \nhigh level pipeline APIs\n, \nbuilt-in deep learning models\n, \nreference use cases\n, etc.).\n\n\n\n\n\n\nHigh level pipeline APIs\n\n\n\n\nnnframes\n: native deep learning support in \nSpark DataFrames and ML Pipelines\n\n\nautograd\n: build custom layer/loss using \nauto differentiation operations\n \n\n\nTransfer learning\n: customize pretained model for \nfeature extraction or fine-tuning\n\n\n\n\n\n\n\n\nBuilt-in deep learning models\n\n\n\n\nObject detection API\n: high-level API and pretrained models (e.g., SSD and Faster-RCNN) for \nobject detection\n\n\nImage classification API\n: high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for \nimage classification\n\n\nText classification API\n: high-level API and pre-defined models (using CNN, LSTM, etc.) for \ntext classification\n\n\nRecommedation API\n: high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for \nrecommendation\n\n\n\n\n\n\n\n\nReference use cases\n: a collection of end-to-end \nreference use cases\n (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)\n\n\n\n\n\n\n\n\nHigh level pipeline APIs\n\n\nAnalytics Zoo provides a set of easy-to-use, high level pipeline APIs that natively support Spark DataFrames and ML Pipelines, autograd and custom layer/loss, trasnfer learning, etc.\n\n\nnnframes\n\n\nnnframes\n provides \nnative deep learning support in Spark DataFrames and ML Pipelines\n, so that you can easily build complex deep learning pipelines in just a few lines, as illustracted below. (See more details \nhere\n)\n\n\n1.Load images into DataFrames using \nNNImageReader\n\n\n   from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   sc = get_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)\n\n\n\n\n2.Process loaded data using \nDataFrames transformations\n\n\n   getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn(\nname\n, getName(col(\nimage\n))).withColumn(\nlabel\n, getLabel(col('name')))\n\n\n\n\n3.Processing image using built-in \nfeature engineering operations\n\n\n   from zoo.feature.image import *\n   transformer = RowToImageFeature() -\n ImageResize(64, 64) -\n ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -\n ImageMatToTensor() -\n ImageFeatureToTensor())\n\n\n\n\n4.Define model using \nKeras-style APIs\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))\n\n\n\n\n5.Train model using \nSpark ML Pipelines\n\n\n   classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol(\nimage\n).setCachingSample(False)\n   nnModel = classifier.fit(df)\n\n\n\n\nautograd\n\n\nautograd\n provides automatic differentiation for math operations, so that you can easily build your own \ncustom loss and layer\n (in both Python and Scala), as illustracted below. (See more details \nhere\n)\n\n\n1.Define custom functions using \nautograd\n\n\n   from zoo.pipeline.api.autograd import *\n\n   def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)\n\n   def add_one_func(x):\n       return x + 1.0\n\n\n\n\n2.Define model using Keras-style API and \ncustom \nLambda\n layer\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Dense(1, input_shape=(2,))) \\\n                       .add(Lambda(function=add_one_func))\n\n\n\n\n3.Train model with \ncustom loss function\n\n\n   model.compile(optimizer = SGD(), loss = mean_absolute_error)\n   model.fit(x = ..., y = ...)\n\n\n\n\nTransfer learning\n\n\nUsing the high level transfer learning APIs, you can easily customize pretrained models for \nfeature extraction or fine-tuning\n. (See more details \nhere\n)\n\n\n1.Load an existing model (pretrained in Caffe)\n\n\n   from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)\n\n\n\n\n2.Remove last few layers\n\n\n   # create a new model by remove layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\n3.Freeze first few layers\n\n\n   # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\n4.Add a few new layers\n\n\n   from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name=\ninput\n, shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)\n\n\n\n\n\n\nBuilt-in deep learning models\n\n\nAnalytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as \nobject detection\n, \nimage classification\n, \ntext classification\n, \nrecommendation\n, etc.\n\n\nObject detection API\n\n\nUsing \nAnalytics Zoo Object Detection API\n (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details \nhere\n)\n\n\n1.Download object detection models in Analytics Zoo\n\n\nYou can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from \ndetection model zoo\n.\n\n\n2.Use \nObject Detection API\n for off-the-shell inference\n\n\n   from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nImage classification API\n\n\nUsing \nAnalytics Zoo Image Classification API\n (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details \nhere\n)\n\n\n1.Download image classification models in Analytics Zoo\n\n\nYou can download a collection of image classification models (pretrained on the ImageNet dataset) from \nimage classification model zoo\n\n\n2.Use \nImage classification API\n for off-the-shell inference\n\n\n   from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)\n\n\n\n\nText classification API\n\n\nAnalytics Zoo Text Classification API\n provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details \nhere\n)\n\n\nRecommendation API\n\n\nAnalytics Zoo Recommendation API\n provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for receommendations. (See more details \nhere\n)\n\n\n\n\nReference use cases\n\n\nAnalytics Zoo provides a collection of end-to-end reference use cases, including \nanomaly detection (for time series data)\n, \nsentiment analysis\n, \nfraud detection\n, \nimage augmentation\n, \nobject detection\n, \nvariational autoencoder\n, etc. (See more details \nhere\n)", 
            "title": "Overview"
        }, 
        {
            "location": "/#analytics-zoo", 
            "text": "Analytics + AI Platform for Apache Spark and  BigDL   Analytics Zoo makes it easy to build deep learning application on Spark and BigDL, by providing an end-to-end analytics + AI Platform (including  high level pipeline APIs ,  built-in deep learning models ,  reference use cases , etc.).    High level pipeline APIs   nnframes : native deep learning support in  Spark DataFrames and ML Pipelines  autograd : build custom layer/loss using  auto differentiation operations    Transfer learning : customize pretained model for  feature extraction or fine-tuning     Built-in deep learning models   Object detection API : high-level API and pretrained models (e.g., SSD and Faster-RCNN) for  object detection  Image classification API : high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for  image classification  Text classification API : high-level API and pre-defined models (using CNN, LSTM, etc.) for  text classification  Recommedation API : high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for  recommendation     Reference use cases : a collection of end-to-end  reference use cases  (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)", 
            "title": "Analytics Zoo"
        }, 
        {
            "location": "/#high-level-pipeline-apis", 
            "text": "Analytics Zoo provides a set of easy-to-use, high level pipeline APIs that natively support Spark DataFrames and ML Pipelines, autograd and custom layer/loss, trasnfer learning, etc.", 
            "title": "High level pipeline APIs"
        }, 
        {
            "location": "/#nnframes", 
            "text": "nnframes  provides  native deep learning support in Spark DataFrames and ML Pipelines , so that you can easily build complex deep learning pipelines in just a few lines, as illustracted below. (See more details  here )  1.Load images into DataFrames using  NNImageReader     from zoo.common.nncontext import *\n   from zoo.pipeline.nnframes import *\n   sc = get_nncontext()\n   imageDF = NNImageReader.readImages(image_path, sc)  2.Process loaded data using  DataFrames transformations     getName = udf(lambda row: ...)\n   getLabel = udf(lambda name: ...)\n   df = imageDF.withColumn( name , getName(col( image ))).withColumn( label , getLabel(col('name')))  3.Processing image using built-in  feature engineering operations     from zoo.feature.image import *\n   transformer = RowToImageFeature() -  ImageResize(64, 64) -  ImageChannelNormalize(123.0, 117.0, 104.0) \\\n                 -  ImageMatToTensor() -  ImageFeatureToTensor())  4.Define model using  Keras-style APIs     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \\\n                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))  5.Train model using  Spark ML Pipelines     classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \\\n                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol( image ).setCachingSample(False)\n   nnModel = classifier.fit(df)", 
            "title": "nnframes"
        }, 
        {
            "location": "/#autograd", 
            "text": "autograd  provides automatic differentiation for math operations, so that you can easily build your own  custom loss and layer  (in both Python and Scala), as illustracted below. (See more details  here )  1.Define custom functions using  autograd     from zoo.pipeline.api.autograd import *\n\n   def mean_absolute_error(y_true, y_pred):\n       return mean(abs(y_true - y_pred), axis=1)\n\n   def add_one_func(x):\n       return x + 1.0  2.Define model using Keras-style API and  custom  Lambda  layer     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   model = Sequential().add(Dense(1, input_shape=(2,))) \\\n                       .add(Lambda(function=add_one_func))  3.Train model with  custom loss function     model.compile(optimizer = SGD(), loss = mean_absolute_error)\n   model.fit(x = ..., y = ...)", 
            "title": "autograd"
        }, 
        {
            "location": "/#transfer-learning", 
            "text": "Using the high level transfer learning APIs, you can easily customize pretrained models for  feature extraction or fine-tuning . (See more details  here )  1.Load an existing model (pretrained in Caffe)     from zoo.pipeline.api.net import *\n   full_model = Net.load_caffe(def_path, model_path)  2.Remove last few layers     # create a new model by remove layers after pool5/drop_7x7_s1\n   model = full_model.new_graph([ pool5/drop_7x7_s1 ])  3.Freeze first few layers     # freeze layers from input to pool4/3x3_s2 inclusive\n   model.freeze_up_to([ pool4/3x3_s2 ])  4.Add a few new layers     from zoo.pipeline.api.keras.layers import *\n   from zoo.pipeline.api.keras.models import *\n   inputs = Input(name= input , shape=(3, 224, 224))\n   inception = model.to_keras()(inputs)\n   flatten = Flatten()(inception)\n   logits = Dense(2)(flatten)\n   newModel = Model(inputs, logits)", 
            "title": "Transfer learning"
        }, 
        {
            "location": "/#built-in-deep-learning-models", 
            "text": "Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as  object detection ,  image classification ,  text classification ,  recommendation , etc.", 
            "title": "Built-in deep learning models"
        }, 
        {
            "location": "/#object-detection-api", 
            "text": "Using  Analytics Zoo Object Detection API  (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details  here )  1.Download object detection models in Analytics Zoo  You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from  detection model zoo .  2.Use  Object Detection API  for off-the-shell inference     from zoo.models.image.objectdetection import *\n   model = ObjectDetector.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Object detection API"
        }, 
        {
            "location": "/#image-classification-api", 
            "text": "Using  Analytics Zoo Image Classification API  (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details  here )  1.Download image classification models in Analytics Zoo  You can download a collection of image classification models (pretrained on the ImageNet dataset) from  image classification model zoo  2.Use  Image classification API  for off-the-shell inference     from zoo.models.image.imageclassification import *\n   model = ImageClassifier.load_model(model_path)\n   image_set = ImageSet.read(img_path, sc)\n   output = model.predict_image_set(image_set)", 
            "title": "Image classification API"
        }, 
        {
            "location": "/#text-classification-api", 
            "text": "Analytics Zoo Text Classification API  provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details  here )", 
            "title": "Text classification API"
        }, 
        {
            "location": "/#recommendation-api", 
            "text": "Analytics Zoo Recommendation API  provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for receommendations. (See more details  here )", 
            "title": "Recommendation API"
        }, 
        {
            "location": "/#reference-use-cases", 
            "text": "Analytics Zoo provides a collection of end-to-end reference use cases, including  anomaly detection (for time series data) ,  sentiment analysis ,  fraud detection ,  image augmentation ,  object detection ,  variational autoencoder , etc. (See more details  here )", 
            "title": "Reference use cases"
        }, 
        {
            "location": "/release-download/", 
            "text": "Release 0.1.0\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload", 
            "title": "Download"
        }, 
        {
            "location": "/release-download/#release-010", 
            "text": "Linux x64  Mac      Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Release 0.1.0"
        }, 
        {
            "location": "/release-docs/", 
            "text": "Release 0.1.1\n\n\nAnalytics-Zoo 0.1 Docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/release-docs/#release-011", 
            "text": "Analytics-Zoo 0.1 Docs", 
            "title": "Release 0.1.1"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/", 
            "text": "Overview\n\n\nNNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.\n\n\nHighlights\n\n1. Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.\n2. Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.\n3. In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.\n4. Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).\n5. Rich toolset for feature extraction and processing, including image, audio and texts.\n\n\nExamples:\n\n\nThe examples are included in the Analytics Zoo source code.\n\n\n\n\nimage classification: model inference using pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\nimage classification: transfer learning from pre-trained Inception v1 model.\n    \nScala version\n\n    \nPython version\n\n\n\n\nPrimary APIs\n\n\nNNEstimator and NNModel\n\n\nAnalytics Zoo provides \nNNEstimator\n for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark\n\nEstimator\n/\n\nTransfomer\n\npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of\n\nNNEstimator\n is a NNModel, which is a Spark ML Transformer.\n\n\nplease check our\n\nNNEstimator API\n for detailed usage.\n\n\nNNClassifier and NNClassifierModel\n\n\nNNClassifier\n and \nNNClassifierModel\nextends \nNNEstimator\n and \nNNModel\n and focus on \nclassification tasks, where both label column and prediction column are of Double type.\n\n\nNNImageReader\n\nNNImageReader loads image into Spark DataFrame.\n\n\nplease check our\n\nImageProcessing\n for detailed usage.", 
            "title": "DataFrame and ML Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#overview", 
            "text": "NNFrames is a package in Analytics Zoo aiming to provide DataFrame-based high level API to\nfacilitate Spark users and speed-up development. It supports native integration with Spark ML\nPipeline, which allows user to combine the power of Analytics Zoo, BigDL and Apache Spark MLlib.\nNNFrames provides both Python and Scala interfaces, and is compatible with both Spark 1.6 and\nSpark 2.x.  Highlights \n1. Easy-to-use DataFrame(DataSet)-based API for training, prediction and evaluation with deep learning models.\n2. Effortless integration with Spark ML pipeline and compatibility with other feature transformers and algorithms in Spark ML.\n3. In a few lines, run large scale inference or transfer learning from pre-trained models of Caffe, Keras, Tensorflow or BigDL.\n4. Training of customized model or BigDL built-in neural models (e.g. Inception, ResNet, Wide And Deep).\n5. Rich toolset for feature extraction and processing, including image, audio and texts.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#examples", 
            "text": "The examples are included in the Analytics Zoo source code.   image classification: model inference using pre-trained Inception v1 model.\n     Scala version \n     Python version  image classification: transfer learning from pre-trained Inception v1 model.\n     Scala version \n     Python version", 
            "title": "Examples:"
        }, 
        {
            "location": "/ProgrammingGuide/nnframes/#primary-apis", 
            "text": "NNEstimator and NNModel  Analytics Zoo provides  NNEstimator  for model training with Spark DataFrame, which\nprovides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer \npattern, thus users can conveniently fit Analytics Zoo into a ML pipeline. The fit result of NNEstimator  is a NNModel, which is a Spark ML Transformer.  please check our NNEstimator API  for detailed usage.  NNClassifier and NNClassifierModel  NNClassifier  and  NNClassifierModel extends  NNEstimator  and  NNModel  and focus on \nclassification tasks, where both label column and prediction column are of Double type.  NNImageReader \nNNImageReader loads image into Spark DataFrame.  please check our ImageProcessing  for detailed usage.", 
            "title": "Primary APIs"
        }, 
        {
            "location": "/ProgrammingGuide/autograd/", 
            "text": "", 
            "title": "Autograd"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/", 
            "text": "Overview\n\n\nAnalytics Zoo provides some useful utilities for transfer learning.\n\n\nLoading a pre-trained model\n\n\nWe can use the \nNet\n api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to \nNet API Guide\n\n\nRemove the last a few layers\n\n\nWhen a model is loaded using \nNet\n, we can use the \nnewGraph(output)\n api to define a Model with\nthe output specified by the parameter.\n\n\nFor example, \n\n\nIn scala:\n\n\nval inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output = \npool5/drop_7x7_s1\n)\n\n\n\n\n\nIn python:\n\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n\n\n\n\nThe returning model's output layer is \"pool5/drop_7x7_s1\".\n\n\nFreeze some layers\n\n\nIn transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the \nfreezeUpTo(endPoint)\n api to do that.\n\n\nFor example,\n\n\nIn scala:\n\n\ninception.freezeUpTo(\npool4/3x3_s2\n) // freeze layer pool4/3x3_s2 and the layers before it\n\n\n\n\nIn python:\n\n\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\n\n\n\nThis will freeze all the layers from the input layer to \"pool4/3x3_s2\"\n\n\nExample\n\n\nFor a complete example, refer to the \nscala transfer learning example\n\nand \npython transfer learning example", 
            "title": "Transfer Learning"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#overview", 
            "text": "Analytics Zoo provides some useful utilities for transfer learning.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#loading-a-pre-trained-model", 
            "text": "We can use the  Net  api to load a pre-trained model, including models saved by Analytics Zoo,\nBigDL, Torch, Caffe and Tensorflow. Please refer to  Net API Guide", 
            "title": "Loading a pre-trained model"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#remove-the-last-a-few-layers", 
            "text": "When a model is loaded using  Net , we can use the  newGraph(output)  api to define a Model with\nthe output specified by the parameter.  For example,   In scala:  val inception = Net.loadBigDL[Float](inception_path)\n      .newGraph(output =  pool5/drop_7x7_s1 )  In python:  full_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])  The returning model's output layer is \"pool5/drop_7x7_s1\".", 
            "title": "Remove the last a few layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#freeze-some-layers", 
            "text": "In transfer learning, we often want to freeze some layers to prevent overfitting. In Analytics Zoo,\nwe can use the  freezeUpTo(endPoint)  api to do that.  For example,  In scala:  inception.freezeUpTo( pool4/3x3_s2 ) // freeze layer pool4/3x3_s2 and the layers before it  In python:  # freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])  This will freeze all the layers from the input layer to \"pool4/3x3_s2\"", 
            "title": "Freeze some layers"
        }, 
        {
            "location": "/ProgrammingGuide/transferlearning/#example", 
            "text": "For a complete example, refer to the  scala transfer learning example \nand  python transfer learning example", 
            "title": "Example"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/", 
            "text": "Working with images\n\n\nAnalytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nAnalytics Zoo can process image data as Spark Data Frame.\n\nNNImageReader\n is the primary DataFrame-based image loading interface to read images into DataFrame.\n\n\nScala example:\n\n\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.getNNContext(\napp\n)\nval imageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nval imageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nval imageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\n\nPython:\n\n\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = get_nncontext(create_spark_conf().setAppName(\napp\n))\nimageDF1 = NNImageReader.readImages(\n/tmp\n, sc)\nimageDF2 = NNImageReader.readImages(\n/tmp/*.jpg\n, sc)\nimageDF3 = NNImageReader.readImages(\n/tmp/a.jpg, /tmp/b.jpg\n, sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.\n\n\nLoad to ImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\n// create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython example:\n\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo has many pre-defined image processing transformers built on top of OpenCV:\n\n\n\n\nBrightness\n: Adjust the image brightness.\n\n\nHue\n: Adjust the image hue.\n\n\nSaturation\n: Adjust the image Saturation.\n\n\nContrast\n: Adjust the image Contrast.\n\n\nChannelOrder\n: Random change the channel order of an image\n\n\nColorJitter\n: Random adjust brightness, contrast, hue, saturation\n\n\nResize\n: Resize image\n\n\nAspectScale\n: Resize the image, keep the aspect ratio. scale according to the short edge\n\n\nRandomAspectScale\n: Resize the image by randomly choosing a scale\n\n\nChannelNormalize\n: Image channel normalize\n\n\nPixelNormalizer\n: Pixel level normalizer\n\n\nCenterCrop\n: Crop a \ncropWidth\n x \ncropHeight\n patch from center of image.\n\n\nRandomCrop\n: Random crop a \ncropWidth\n x \ncropHeight\n patch from an image.\n\n\nFixedCrop\n: Crop a fixed area of image\n\n\nDetectionCrop\n: Crop from object detections, each image should has a tensor detection,\n\n\nExpand\n: Expand image, fill the blank part with the meanR, meanG, meanB\n\n\nFiller\n: Fill part of image with certain pixel value\n\n\nHFlip\n: Flip the image horizontally\n\n\nRandomTransformer\n: It is a wrapper for transformers to control the transform probability\n\n\nBytesToMat\n: Transform byte array(original image file in byte) to OpenCVMat\n\n\nMatToFloats\n: Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n\n\nMatToTensor\n: Transform opencv mat to tensor, note that in this transformer, the mat is released.\n\n\nImageFrameToSample\n: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.\n\n\n\n\nMore examples can be found \nhere\n\n\nYou can also define your own Transformer by extending \nImageProcessing\n,\nand override the function \ntransformMat\n to do the actual transformation to \nImageFeature\n.\n\n\nBuild Image Transformation Pipeline\n\n\nYou can easily build the image transformation pipeline by chaining transformers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -\n ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n             ImageChannelNormalize(123, 117, 104) -\n\n             ImageMatToTensor[Float]() -\n\n             ImageSetToSample[Float]()\n\n\n\n\nIn the above example, the transformations will perform sequentially.\n\n\nAssume you have an ImageFrame containing original bytes array,\n\nImageBytesToMat\n will transform the bytes array to \nOpenCVMat\n.\n\n\nImageColorJitter\n, \nImageExpand\n, \nImageResize\n, \nImageHFlip\n and \nImageChannelNormalize\n will transform over \nOpenCVMat\n,\nnote that \nOpenCVMat\n is overwrite by default.\n\n\nImageMatToTensor\n transform \nOpenCVMat\n to \nTensor\n, and \nOpenCVMat\n is released in this step.\n\n\nImageSetToSample\n transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.\n\n\nPython example:\n\n\nfrom zoo.feature.image.imagePreprocessing import *\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])\n\n\n\n\nImage Train\n\n\nTrain with Image DataFrame\n\n\nYou can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call \nfit\n method to let Analytics Zoo train the model\n\n\nFor detail APIs, please refer to: \nNNFrames\n\n\nScala example:\n\n\nval batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                   ImageCenterCrop(224, 224) -\n\n                                   ImageChannelNormalize(123, 117, 104) -\n\n                                   ImageMatToTensor() -\n\n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol(\nimage\n)\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)\n\n\n\n\nPython example:\n\n\nbatchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol(\nimage\n)\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\n\n\nTrain with ImageSet\n\n\nYou can train Zoo Keras model with ImageSet. Just call \nfit\n method to let Analytics Zoo train the model.\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import get_nncontext\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_nncontext(create_spark_conf().setAppName(\ntrain keras\n))\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\n\n\n\n\nImage Predict\n\n\nPredict with Image DataFrame\n\n\nAfter training with NNEstimator/NNCLassifier, you'll get a trained NNModel/NNClassifierModel. You can call \ntransform\n to predict Image DataFrame with this NNModel/NNClassifierModel.\n Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to \ntransform\n to predict Image DataFrame.\n After prediction, there is a new column \nprediction\n in the prediction image dataframe.\n\n\nScala example:\n\n ```scala\n val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -\n ImageResize(256, 256) -\n\n                                    ImageCenterCrop(224, 224) -\n\n                                    ImageChannelNormalize(123, 117, 104) -\n\n                                    ImageMatToTensor() -\n\n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion\nFloat\n, featureTransformer)\n         .setFeaturesCol(\"image\")\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)\n\n\n// predict with loaded pre-trained model\n val model = Module.loadModule\nFloat\n\n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol(\"image\")\n         .setPredictionCol(\"prediction\") \n val resultDF = dlmodel.transform(testDf)\n \n**Python example:**\npython\n batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol(\"image\")\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)\n\n\npredict with trained model\n\n\npredictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)\n\n\npredict with loaded pre-trained model\n\n\nmodel = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)\n ```\n\n\nPredict with ImageSet\n\n\nAfter training Zoo Keras model, you can call \npredict\n to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nPredict with trained Zoo Keras Model\n\n\nPython example:\n\n\nfrom zoo.common.nncontext import get_nncontext\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_nncontext(create_spark_conf().setAppName(\ntrain keras\n))\nimg_path=\n/tmp/image\n\nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path=\n/tmp/bigdl_inception-v1_imagenet_0.4.0.model\n\nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\npool5/drop_7x7_s1\n])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([\npool4/3x3_s2\n])\n\ninputNode = Input(name=\ninput\n, shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()\n\n\n\n\nPredict with loaded Model\n\n\nYou can load pre-trained Analytics-Zoo/BigDL model. Then call to \npredictImageSet\n to predict ImageSet.\n\n\nFor details, you can check guide of \nimage classificaion\n or \nobject detection", 
            "title": "Working with Images"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#working-with-images", 
            "text": "Analytics Zoo provides supports for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.", 
            "title": "Working with images"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-data-frame", 
            "text": "Analytics Zoo can process image data as Spark Data Frame. NNImageReader  is the primary DataFrame-based image loading interface to read images into DataFrame.  Scala example:  import com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.pipeline.nnframes.NNImageReader\n\nval sc = NNContext.getNNContext( app )\nval imageDF1 = NNImageReader.readImages( /tmp , sc)\nval imageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nval imageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  Python:  from zoo.common.nncontext import *\nfrom zoo.pipeline.nnframes import *\n\nsc = get_nncontext(create_spark_conf().setAppName( app ))\nimageDF1 = NNImageReader.readImages( /tmp , sc)\nimageDF2 = NNImageReader.readImages( /tmp/*.jpg , sc)\nimageDF3 = NNImageReader.readImages( /tmp/a.jpg, /tmp/b.jpg , sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#load-to-imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  // create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read( /tmp/image/ , sc, 2)  Python example:  # create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "Load to ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-transformer", 
            "text": "Analytics Zoo has many pre-defined image processing transformers built on top of OpenCV:   Brightness : Adjust the image brightness.  Hue : Adjust the image hue.  Saturation : Adjust the image Saturation.  Contrast : Adjust the image Contrast.  ChannelOrder : Random change the channel order of an image  ColorJitter : Random adjust brightness, contrast, hue, saturation  Resize : Resize image  AspectScale : Resize the image, keep the aspect ratio. scale according to the short edge  RandomAspectScale : Resize the image by randomly choosing a scale  ChannelNormalize : Image channel normalize  PixelNormalizer : Pixel level normalizer  CenterCrop : Crop a  cropWidth  x  cropHeight  patch from center of image.  RandomCrop : Random crop a  cropWidth  x  cropHeight  patch from an image.  FixedCrop : Crop a fixed area of image  DetectionCrop : Crop from object detections, each image should has a tensor detection,  Expand : Expand image, fill the blank part with the meanR, meanG, meanB  Filler : Fill part of image with certain pixel value  HFlip : Flip the image horizontally  RandomTransformer : It is a wrapper for transformers to control the transform probability  BytesToMat : Transform byte array(original image file in byte) to OpenCVMat  MatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released.  MatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released.  ImageFrameToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.   More examples can be found  here  You can also define your own Transformer by extending  ImageProcessing ,\nand override the function  transformMat  to do the actual transformation to  ImageFeature .", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#build-image-transformation-pipeline", 
            "text": "You can easily build the image transformation pipeline by chaining transformers.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.zoo.feature.image._\n\n\nval imgAug = ImageBytesToMat() -  ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n             ImageChannelNormalize(123, 117, 104) - \n             ImageMatToTensor[Float]() - \n             ImageSetToSample[Float]()  In the above example, the transformations will perform sequentially.  Assume you have an ImageFrame containing original bytes array, ImageBytesToMat  will transform the bytes array to  OpenCVMat .  ImageColorJitter ,  ImageExpand ,  ImageResize ,  ImageHFlip  and  ImageChannelNormalize  will transform over  OpenCVMat ,\nnote that  OpenCVMat  is overwrite by default.  ImageMatToTensor  transform  OpenCVMat  to  Tensor , and  OpenCVMat  is released in this step.  ImageSetToSample  transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.  Python example:  from zoo.feature.image.imagePreprocessing import *\n\nimg_aug = ChainedPreprocessing([ImageBytesToMat(),\n      ImageColorJitter(),\n      ImageExpand(),\n      ImageResize(300, 300, -1),\n      ImageHFlip(),\n      ImageChannelNormalize(123.0, 117.0, 104.0),\n      ImageMatToTensor(),\n      ImageSetToSample()])", 
            "title": "Build Image Transformation Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-train", 
            "text": "", 
            "title": "Image Train"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-image-dataframe", 
            "text": "You can use NNEstimator/NNCLassifier to train Zoo Keras/BigDL model with Image DataFrame. You can pass in image preprocessing to NNEstimator/NNClassifier to do image preprocessing before training. Then call  fit  method to let Analytics Zoo train the model  For detail APIs, please refer to:  NNFrames  Scala example:  val batchsize = 128\nval nEpochs = 10\nval featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                   ImageCenterCrop(224, 224) - \n                                   ImageChannelNormalize(123, 117, 104) - \n                                   ImageMatToTensor() - \n                                   ImageFeatureToTensor()\nval classifier = NNClassifier(model, CrossEntropyCriterion[Float](), featureTransformer)\n        .setFeaturesCol( image )\n        .setLearningRate(0.003)\n        .setBatchSize(batchsize)\n        .setMaxEpoch(nEpochs)\n        .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\nval trainedModel = classifier.fit(trainDf)  Python example:  batchsize = 128\nnEpochs = 10\nfeatureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                   ImageCenterCrop(224, 224),\n                                   ImageChannelNormalize(123, 117, 104),\n                                   ImageMatToTensor(),\n                                   ImageFeatureToTensor()])\nclassifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n        .setFeaturesCol( image )\\\n        .setLearningRate(0.003)\\\n        .setBatchSize(batchsize)\\\n        .setMaxEpoch(nEpochs)\\\n        .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)", 
            "title": "Train with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#train-with-imageset", 
            "text": "You can train Zoo Keras model with ImageSet. Just call  fit  method to let Analytics Zoo train the model.  Python example:  from zoo.common.nncontext import get_nncontext\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_nncontext(create_spark_conf().setAppName( train keras ))\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)", 
            "title": "Train with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#image-predict", 
            "text": "", 
            "title": "Image Predict"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-image-dataframe", 
            "text": "After training with NNEstimator/NNCLassifier, you'll get a trained NNModel/NNClassifierModel. You can call  transform  to predict Image DataFrame with this NNModel/NNClassifierModel.\n Or you can load pre-trained Analytics-Zoo/BigDL/Caffe/Torch/Tensorflow model and create NNModel/NNClassifierModel with this model. Then call to  transform  to predict Image DataFrame.\n After prediction, there is a new column  prediction  in the prediction image dataframe.  Scala example: \n ```scala\n val batchsize = 128\n val nEpochs = 10\n val featureTransformer = RowToImageFeature() -  ImageResize(256, 256) - \n                                    ImageCenterCrop(224, 224) - \n                                    ImageChannelNormalize(123, 117, 104) - \n                                    ImageMatToTensor() - \n                                    ImageFeatureToTensor()\n val classifier = NNClassifier(model, CrossEntropyCriterion Float , featureTransformer)\n         .setFeaturesCol(\"image\")\n         .setLearningRate(0.003)\n         .setBatchSize(batchsize)\n         .setMaxEpoch(nEpochs)\n         .setValidation(Trigger.everyEpoch, valDf, Array(new Top1Accuracy()), batchsize)\n val trainedModel = classifier.fit(trainDf)\n // predict with trained model\n val predictions = trainedModel.transform(testDf)\n predictions.select(col(\"image\"), col(\"label\"), col(\"prediction\")).show(false)  // predict with loaded pre-trained model\n val model = Module.loadModule Float \n val dlmodel = NNClassifierModel(model, featureTransformer)\n         .setBatchSize(batchsize)\n         .setFeaturesCol(\"image\")\n         .setPredictionCol(\"prediction\") \n val resultDF = dlmodel.transform(testDf)\n  **Python example:** python\n batchsize = 128\n nEpochs = 10\n featureTransformer = ChainedPreprocessing([RowToImageFeature(), ImageResize(256, 256),\n                                    ImageCenterCrop(224, 224),\n                                    ImageChannelNormalize(123, 117, 104),\n                                    ImageMatToTensor(),\n                                    ImageFeatureToTensor()])\n classifier = NNClassifier(model, CrossEntropyCriterion(), featureTransformer)\\\n         .setFeaturesCol(\"image\")\\\n         .setLearningRate(0.003)\\\n         .setBatchSize(batchsize)\\\n         .setMaxEpoch(nEpochs)\\\n         .setValidation(EveryEpoch(), valDf, [Top1Accuracy()], batch_size)\ntrainedModel = classifier.fit(trainDf)", 
            "title": "Predict with Image DataFrame"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-model", 
            "text": "predictions = trainedModel.transform(testDf)\npredictions.select(\"image\", \"label\",\"prediction\").show(False)", 
            "title": "predict with trained model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-pre-trained-model", 
            "text": "model = Model.loadModel(model_path)\ndlmodel = NNClassifierModel(model, featureTransformer)\\\n         .setBatchSize(batchsize)\\\n         .setFeaturesCol(\"image\")\\\n         .setPredictionCol(\"prediction\") \nresultDF = dlmodel.transform(testDf)\n ```", 
            "title": "predict with loaded pre-trained model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-imageset", 
            "text": "After training Zoo Keras model, you can call  predict  to predict ImageSet.\nOr you can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.", 
            "title": "Predict with ImageSet"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-trained-zoo-keras-model", 
            "text": "Python example:  from zoo.common.nncontext import get_nncontext\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_nncontext(create_spark_conf().setAppName( train keras ))\nimg_path= /tmp/image \nimage_set = ImageSet.read(img_path,sc, min_partitions=1)\ntransformer = ChainedPreprocessing(\n        [ImageResize(256, 256), ImageCenterCrop(224, 224),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n         ImageSetToSample()])\nimage_data = transformer(image_set)\nlabels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\nlabel_rdd = sc.parallelize(labels, 1)\nsamples = image_data.get_image().zip(label_rdd).map(\n        lambda tuple: Sample.from_ndarray(tuple[0], tuple[1]))\n# create model\nmodel_path= /tmp/bigdl_inception-v1_imagenet_0.4.0.model \nfull_model = Net.load_bigdl(model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([ pool5/drop_7x7_s1 ])\n# freeze layers from input to pool4/3x3_s2 inclusive\nmodel.freeze_up_to([ pool4/3x3_s2 ])\n\ninputNode = Input(name= input , shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(2)(flatten)\nlrModel = Model(inputNode, logits)\n\nbatchsize = 4\nnEpochs = 10\nlrModel.compile(optimizer=Adam(learningrate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\nlrModel.fit(x = samples, batch_size=batchsize, nb_epoch=nEpochs)\nprediction = lrModel.predict(samples)\nresult = prediction.collect()", 
            "title": "Predict with trained Zoo Keras Model"
        }, 
        {
            "location": "/ProgrammingGuide/workingwithimages/#predict-with-loaded-model", 
            "text": "You can load pre-trained Analytics-Zoo/BigDL model. Then call to  predictImageSet  to predict ImageSet.  For details, you can check guide of  image classificaion  or  object detection", 
            "title": "Predict with loaded Model"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/", 
            "text": "Analytics Zoo Object Detection API\n\n\nAnalytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nObject Detection models\n\n\nAnalytics Zoo provides two typical kind of pre-trained Object Detection models : \nSSD\n and \nFaster-RCNN\n on dataset \nPASCAL\n and \nCOCO\n. For the usage of these models, please check below examples.\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)\n\n\n\n\nFor preprocessors for Object Detection models, please check \nObject Detection Config\n\n\nUsers can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:\n\n\nval model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) -\n\n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) -\n\n                         MatToTensor() -\n ImageFrameToSample()\nval output = model.predictImageset(data)\n\n\n\n\nDownload link\n\n\nObject Detection\n\n\n\n\nPASCAL VOC models\n\n\nSSD 300x300 MobileNet\n\n\nSSD 300x300 VGG\n\n\nSSD 512x512 VGG\n\n\nFaster-RCNN VGG\n\n\nFaster-RCNN VGG Compress\n\n\nFaster-RCNN PvaNet\n\n\n\n\nFaster-RCNN PvaNet Compress\n\n\n\n\n\n\nCOCO models\n\n\n\n\n\n\nSSD 300x300 VGG\n\n\n\n\nSSD 512x512 VGG", 
            "title": "Object Detection"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#analytics-zoo-object-detection-api", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.  Object Detection models  Analytics Zoo provides two typical kind of pre-trained Object Detection models :  SSD  and  Faster-RCNN  on dataset  PASCAL  and  COCO . For the usage of these models, please check below examples.  Scala example  It's very easy to apply the model for inference with below code piece.  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = model.predictImageSet(data)  For preprocessors for Object Detection models, please check  Object Detection Config  Users can also do the inference directly using Analytics zoo.\nSample code for SSD VGG on PASCAL as below:  val model = ObjectDetector.load[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessor = Resize(300, 300) - \n                         ChannelNormalize(123f, 117f, 104f, 1f, 1f, 1f) - \n                         MatToTensor() -  ImageFrameToSample()\nval output = model.predictImageset(data)", 
            "title": "Analytics Zoo Object Detection API"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#download-link", 
            "text": "", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/object-detection/#object-detection", 
            "text": "PASCAL VOC models  SSD 300x300 MobileNet  SSD 300x300 VGG  SSD 512x512 VGG  Faster-RCNN VGG  Faster-RCNN VGG Compress  Faster-RCNN PvaNet   Faster-RCNN PvaNet Compress    COCO models    SSD 300x300 VGG   SSD 512x512 VGG", 
            "title": "Object Detection"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/", 
            "text": "Analytics Zoo Image Classification\n\n\nAnalytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nImage Classification models\n\n\nAnalytics Zoo provides several typical kind of pre-trained Image Classfication models : \nAlexnet\n, \nInception-V1\n, \nVGG\n, \nResnet\n, \nDensenet\n, \nMobilenet\n, \nSqueezenet\n models. To use these models, please check below examples.\n\n\nScala\n\n\nScala example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nval imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n        ImageChannelNormalize(123, 117, 104) -\n\n        ImageMatToTensor[Float]() -\n\n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)\n\n\n\n\nPython\n\n\nPython example\n\n\nIt's very easy to apply the model for inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)\n\n\n\n\nUser can also define his own configuration to do the inference with below code piece.\n\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)\n\n\n\n\nFor preprocessors for Image Classification models, please check \nImage Classification Config\n\n\nDownload link\n\n\n\n\nAlexnet\n\n\nInception-V1\n\n\nVGG-16\n\n\nVGG-19\n\n\nResnet-50\n\n\nDensenet-161\n\n\nMobilenet\n\n\nSqueezenet", 
            "title": "Image Classification"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#analytics-zoo-image-classification", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.  Image Classification models  Analytics Zoo provides several typical kind of pre-trained Image Classfication models :  Alexnet ,  Inception-V1 ,  VGG ,  Resnet ,  Densenet ,  Mobilenet ,  Squeezenet  models. To use these models, please check below examples.  Scala  Scala example  It's very easy to apply the model for inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval output = imc.predictImageSet(data)  User can also define his own configuration to do the inference with below code piece.  val imc = ImageClassifier.loadModel[Float](params.model)\nval data = ImageSet.read(params.image, sc, params.nPartition)\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n        ImageChannelNormalize(123, 117, 104) - \n        ImageMatToTensor[Float]() - \n        ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preprocessing)        \nval output = imc.predictImageSet(data, config)  Python  Python example  It's very easy to apply the model for inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)  User can also define his own configuration to do the inference with below code piece.  imc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(preprocessing) \noutput = imc.predict_image_set(image_set)  For preprocessors for Image Classification models, please check  Image Classification Config", 
            "title": "Analytics Zoo Image Classification"
        }, 
        {
            "location": "/ProgrammingGuide/image-classification/#download-link", 
            "text": "Alexnet  Inception-V1  VGG-16  VGG-19  Resnet-50  Densenet-161  Mobilenet  Squeezenet", 
            "title": "Download link"
        }, 
        {
            "location": "/ProgrammingGuide/text-classification/", 
            "text": "", 
            "title": "Text Classification"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/", 
            "text": "Analytics Zoo Recommender\n\n\nAnalytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model. \n\n\nHighlights\n\n1. Easy-to-use models, could be fed into NNFrames and BigDL Optimizer for training..\n2. Recommenders can handle either explict or implicit feedback, given corresponding features.\n3. It provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). \n\n\nThe examples/notebooks are included in the Analytics Zoo source code.\n\n\n\n\nWide and Deep Learning Model.\n    \nScala example\n\n    \nPython notebook\n\n\nNCF.\n    \nScala example\n\n    \nPython notebook\n\n\n\n\nWide and Deep Recommender model\n\n\nScala\n\n\nBuild a WND model for recommendation. \n\n\nval wideAndDeep = WideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer.\n\n\nval optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a WND model for recommendation. \n\n\nwide_n_deep = WideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\nTrain a WND model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nPython notebook\n\n\nNeural network-based Collaborative Filtering\n\n\nScala\n\n\nBuild a NCF model for recommendation. \n\n\nval ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\nval optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()\n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nval userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nScala example\n\n\nPython\n\n\nBuild a NCF model for recommendation. \n\n\nncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\nTrain a NCF model using BigDL Optimizer \n\n\noptimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize() \n\n\n\n\nPredict and recommend items(users) for users(items) with given features.\n\n\nuserItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)\n\n\n\n\nSee more details in our\nRecommender API\n and \nPython notebook", 
            "title": "Recommendation"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#analytics-zoo-recommender", 
            "text": "Analytics Zoo provides two Recommender models, including Wide and Deep(WND) learning model and Neural network-based Collaborative Filtering (NCF) model.   Highlights \n1. Easy-to-use models, could be fed into NNFrames and BigDL Optimizer for training..\n2. Recommenders can handle either explict or implicit feedback, given corresponding features.\n3. It provides three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items).   The examples/notebooks are included in the Analytics Zoo source code.   Wide and Deep Learning Model.\n     Scala example \n     Python notebook  NCF.\n     Scala example \n     Python notebook", 
            "title": "Analytics Zoo Recommender"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#wide-and-deep-recommender-model", 
            "text": "Scala  Build a WND model for recommendation.   val wideAndDeep = WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))  Train a WND model using BigDL Optimizer.  val optimizer = Optimizer(\n      model = wideAndDeep,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = wideAndDeep.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = wideAndDeep.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = wideAndDeep.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example  Python  Build a WND model for recommendation.   wide_n_deep = WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))  Train a WND model using BigDL Optimizer   optimizer = Optimizer(\n    model=wide_n_deep,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = wide_n_deep.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = wide_n_deep.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = wide_n_deep.recommend_for_item(valPairFeatureRdds, 3)  See more details in our Recommender API  and  Python notebook", 
            "title": "Wide and Deep Recommender model"
        }, 
        {
            "location": "/ProgrammingGuide/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "Scala  Build a NCF model for recommendation.   val ncf = NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)  Train a NCF model using BigDL Optimizer   val optimizer = Optimizer(\n      model = ncf,\n      sampleRDD = trainRdds,\n      criterion = ClassNLLCriterion[Float](),\n      batchSize = 8000)\n\noptimizer\n      .setOptimMethod(new Adam[Float](learningRate = 1e-2,learningRateDecay = 1e-5))\n      .setEndWhen(Trigger.maxEpoch(10))\n      .optimize()  Predict and recommend items(users) for users(items) with given features.  val userItemPairPrediction = ncf.predictUserItemPair(validationpairFeatureRdds)\nval userRecs = ncf.recommendForUser(validationpairFeatureRdds, 3)\nval itemRecs = ncf.recommendForItem(validationpairFeatureRdds, 3)  See more details in our Recommender API  and  Scala example  Python  Build a NCF model for recommendation.   ncf=NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)  Train a NCF model using BigDL Optimizer   optimizer = Optimizer(\n    model=ncf,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adam(learningrate = 0.001, learningrate_decay=0.00005),\n    end_trigger=MaxEpoch(10),\n    batch_size=batch_size)\noptimizer.optimize()   Predict and recommend items(users) for users(items) with given features.  userItemPairPrediction = ncf.predict_user_item_pair(valPairFeatureRdds)\nuserRecs = ncf.recommend_for_user(valPairFeatureRdds, 3)\nitemRecs = ncf.recommend_for_item(valPairFeatureRdds, 3)  See more details in our Recommender API  and  Python notebook", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/ProgrammingGuide/usercases-overview/", 
            "text": "User Cases\n\n\nanalytics-zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in \nanalytics-zoo/apps\n.\n\n\n\n\n\n\nAnomaly Detection\n demostrates using LSTM network to detect anomalies in time series data.\n\n\n\n\n\n\nFraud Detection\n demostrates using feed-forward neural network to detect frauds in credit card transactions data. \n\n\n\n\n\n\nImage Augmentation\n demostrates how to do image augmentation for vision projects. \n\n\n\n\n\n\nObject Detection\n demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos. \n\n\n\n\n\n\nRecommendation\n: demonstrates how to use Analytics Zoo Recommendation APIs (i.e.Neural Collaborative Filtering, Wide and Deep Learning) to do recommendation on data with explicitfeedback. \n\n\n\n\n\n\nSentiment Analysis\n demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU,Bi-LSTM).  \n\n\n\n\n\n\nVariational AutoEncoder\n demostrates how to use variational autoencoder to generate faces and digital numbers.", 
            "title": "overview"
        }, 
        {
            "location": "/ProgrammingGuide/usercases-overview/#user-cases", 
            "text": "analytics-zoo provides a collection of reference user applications and demos, which can be modified or even used off-the-shelf in real world applications. Some are listed below. See all in  analytics-zoo/apps .    Anomaly Detection  demostrates using LSTM network to detect anomalies in time series data.    Fraud Detection  demostrates using feed-forward neural network to detect frauds in credit card transactions data.     Image Augmentation  demostrates how to do image augmentation for vision projects.     Object Detection  demonstrates how to use Analytics Zoo Object Detection API (and pretrained SSD model) on videos.     Recommendation : demonstrates how to use Analytics Zoo Recommendation APIs (i.e.Neural Collaborative Filtering, Wide and Deep Learning) to do recommendation on data with explicitfeedback.     Sentiment Analysis  demostrates how to do sentiment analysis using neural network models (e.g. CNN, LSTM, GRU,Bi-LSTM).      Variational AutoEncoder  demostrates how to use variational autoencoder to generate faces and digital numbers.", 
            "title": "User Cases"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/", 
            "text": "Analytics Zoo Anomaly detection\n\n\nAnalytics Zoo shows how to detect anomalies in time series data based on RNN network. Currently, a \npython notebook\n is provided. \nIn the example, a RNN network using Analytics Zoo Keras-Style API is built, and \nNYC taxi passengers dataset\n is used to train and test the model.\n\n\nBuild a RNN model for anomaly detection. There are three LSTM layers followed by one Dense layer at the end.\n\n\nmodel = Sequential()\nmodel.add(LSTM(input_shape=(input_dim1, input_dim2, output_dim=8, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(15,return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=1))\n\n\n\n\nTrain the model using Analytics Zoo APIs.\n\n\nmodel.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(x_train,y_train,batch_size=3028,nb_epoch=30)\n\n\n\n\nPredict with given features.\n\n\npredictions = model.predict(x_test)\n\n\n\n\nAnomalies could be defined by comparing the predictions and actual values. The current example defines data points as anomalies if the difference of predictions and actual values are larger than a certain value.\nSee more details in the exmaple \nPython notebook", 
            "title": "Anomaly Detection"
        }, 
        {
            "location": "/ProgrammingGuide/anomaly-detection/#analytics-zoo-anomaly-detection", 
            "text": "Analytics Zoo shows how to detect anomalies in time series data based on RNN network. Currently, a  python notebook  is provided. \nIn the example, a RNN network using Analytics Zoo Keras-Style API is built, and  NYC taxi passengers dataset  is used to train and test the model.  Build a RNN model for anomaly detection. There are three LSTM layers followed by one Dense layer at the end.  model = Sequential()\nmodel.add(LSTM(input_shape=(input_dim1, input_dim2, output_dim=8, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(15,return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=1))  Train the model using Analytics Zoo APIs.  model.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(x_train,y_train,batch_size=3028,nb_epoch=30)  Predict with given features.  predictions = model.predict(x_test)  Anomalies could be defined by comparing the predictions and actual values. The current example defines data points as anomalies if the difference of predictions and actual values are larger than a certain value.\nSee more details in the exmaple  Python notebook", 
            "title": "Analytics Zoo Anomaly detection"
        }, 
        {
            "location": "/PythonUserGuide/install/", 
            "text": "Install From Pip\n\n\n\n\nNOTES\n\n\n\n\nPip install supports \nMac\n and \nLinux\n platforms.\n\n\nPip install only supports \nlocal\n mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to \ninstall without pip\n.\n\n\nIf you use pip install, it is \nnot\n necessary to set \nSPARK_HOME\n.\n\n\nYou need to install Java \n= JDK8\n before running Analytics Zoo, which is required by \npyspark\n.\n\n\nWe've tested this package with \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n. Only these three Python versions are supported for now.\n\n\n\n\n\n\nInstall analytics-zoo-0.1.0.dev0\n\n\npip install --upgrade pip\npip install analytics-zoo==0.1.0.dev0     # for Python 2.7\npip3 install analytics-zoo==0.1.0.dev0    # for Python 3.5 and Python 3.6\n\n\n\n\nRemark:\n\n\n\n\n\n\nWe tested this on pip 9.0.1.\n\n\n\n\n\n\nYou might need to add \nsudo\n if you don't have the permission for installation.\n\n\n\n\n\n\nbigdl==0.5.0\n and its dependencies (including \npyspark\n, \nnumpy\n and \nsix\n) will be automatically installed first before installing analytics-zoo if they haven't been detected in the current Python environment.", 
            "title": "Install"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-from-pip", 
            "text": "", 
            "title": "Install From Pip"
        }, 
        {
            "location": "/PythonUserGuide/install/#notes", 
            "text": "Pip install supports  Mac  and  Linux  platforms.  Pip install only supports  local  mode. Cluster mode might be supported in the future. For those who want to use Analytics Zoo in cluster mode, please try to  install without pip .  If you use pip install, it is  not  necessary to set  SPARK_HOME .  You need to install Java  = JDK8  before running Analytics Zoo, which is required by  pyspark .  We've tested this package with  Python 2.7 ,  Python 3.5  and  Python 3.6 . Only these three Python versions are supported for now.", 
            "title": "NOTES"
        }, 
        {
            "location": "/PythonUserGuide/install/#install-analytics-zoo-010dev0", 
            "text": "pip install --upgrade pip\npip install analytics-zoo==0.1.0.dev0     # for Python 2.7\npip3 install analytics-zoo==0.1.0.dev0    # for Python 3.5 and Python 3.6  Remark:    We tested this on pip 9.0.1.    You might need to add  sudo  if you don't have the permission for installation.    bigdl==0.5.0  and its dependencies (including  pyspark ,  numpy  and  six ) will be automatically installed first before installing analytics-zoo if they haven't been detected in the current Python environment.", 
            "title": "Install analytics-zoo-0.1.0.dev0"
        }, 
        {
            "location": "/PythonUserGuide/run/", 
            "text": "Run after pip install\n\n\nPrecondition\n\n\n\n\nInstall analytics-zoo from pip\n\n\nOnly \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\n\n\n\n\nUse an Interactive Shell\n\n\n\n\nType \npython\n in the command line to start a REPL.\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\n\n\nUse Jupyter Notebook\n\n\n\n\nJust start jupyter notebook as you normally do, e.g.\n\n\n\n\njupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nTry to run the \nexample code\n to verify the installation.\n\n\n\n\n\n\nExample code\n\n\nTo verify if Analytics Zoo can run successfully, run the following simple code:\n\n\nimport zoo.version\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.version.__version__\n# Create or get a SparkContext. This will also init the BigDL engine.\nsc = get_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))\n\n\n\n\nConfigurations\n\n\n\n\nIncrease memory\n\n\n\n\nexport SPARK_DRIVER_MEMORY=20g\n\n\n\n\n\n\nAdd extra jars or python packages\n\n\n\n\n Set the environment variables \nBIGDL_JARS\n and \nBIGDL_PACKAGES\n \nBEFORE\n creating \nSparkContext\n:\n\n\nexport BIGDL_JARS=...\nexport BIGDL_PACKAGES=...", 
            "title": "Run"
        }, 
        {
            "location": "/PythonUserGuide/run/#run-after-pip-install", 
            "text": "", 
            "title": "Run after pip install"
        }, 
        {
            "location": "/PythonUserGuide/run/#precondition", 
            "text": "Install analytics-zoo from pip  Only  Python 2.7 ,  Python 3.5  and  Python 3.6  are supported for now.", 
            "title": "Precondition"
        }, 
        {
            "location": "/PythonUserGuide/run/#use-an-interactive-shell", 
            "text": "Type  python  in the command line to start a REPL.  Try to run the  example code  to verify the installation.", 
            "title": "Use an Interactive Shell"
        }, 
        {
            "location": "/PythonUserGuide/run/#use-jupyter-notebook", 
            "text": "Just start jupyter notebook as you normally do, e.g.   jupyter notebook --notebook-dir=./ --ip=* --no-browser   Try to run the  example code  to verify the installation.", 
            "title": "Use Jupyter Notebook"
        }, 
        {
            "location": "/PythonUserGuide/run/#example-code", 
            "text": "To verify if Analytics Zoo can run successfully, run the following simple code:  import zoo.version\nfrom zoo.common.nncontext import *\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.keras.layers import *\n\n# Get the current Analytics Zoo version\nzoo.version.__version__\n# Create or get a SparkContext. This will also init the BigDL engine.\nsc = get_nncontext()\n# Create a Sequential model containing a Dense layer.\nmodel = Sequential()\nmodel.add(Dense(8, input_shape=(10, )))", 
            "title": "Example code"
        }, 
        {
            "location": "/PythonUserGuide/run/#configurations", 
            "text": "Increase memory   export SPARK_DRIVER_MEMORY=20g   Add extra jars or python packages    Set the environment variables  BIGDL_JARS  and  BIGDL_PACKAGES   BEFORE  creating  SparkContext :  export BIGDL_JARS=...\nexport BIGDL_PACKAGES=...", 
            "title": "Configurations"
        }, 
        {
            "location": "/PythonUserGuide/examples/", 
            "text": "TBD", 
            "title": "Examples"
        }, 
        {
            "location": "/PythonUserGuide/examples/#tbd", 
            "text": "", 
            "title": "TBD"
        }, 
        {
            "location": "/ScalaUserGuide/install/", 
            "text": "TBD", 
            "title": "Install"
        }, 
        {
            "location": "/ScalaUserGuide/install/#tbd", 
            "text": "", 
            "title": "TBD"
        }, 
        {
            "location": "/ScalaUserGuide/run/", 
            "text": "", 
            "title": "Run"
        }, 
        {
            "location": "/ScalaUserGuide/examples/", 
            "text": "TBD", 
            "title": "Examples"
        }, 
        {
            "location": "/ScalaUserGuide/examples/#tbd", 
            "text": "", 
            "title": "TBD"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/", 
            "text": "NNEstimator\n\n\nScala:\n\n\nval estimator = NNEstimator(model, criterion)\n\n\n\n\nPython:\n\n\nestimator = NNEstimator(model, criterion)\n\n\n\n\nNNEstimator\n extends \norg.apache.spark.ml.Estimator\n and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.\n\n\nNNEstimator\n supports different feature and label data types through \nPreprocessing\n.\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe \nPreprocessing\n to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL \nSample\n. Each\n\nPreprocessing\n conducts a data conversion step in the preprocessing phase, multiple\n\nPreprocessing\n can be combined into a \nChainedPreprocessing\n. Some pre-defined \n\nPreprocessing\n for popular data types like Image, Array or Vector are provided in package\n\ncom.intel.analytics.zoo.feature\n, while user can also develop customized \nPreprocessing\n.\nBy default, \nSeqToTensor\n is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the \nPreprocessing\n allows \nNNEstimator\n to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\nMore concrete examples are available in package \ncom.intel.analytics.zoo.examples.nnframes\n\n\nNNEstimator\n can be created with various parameters for different scenarios.\n\n\n\n\nNNEstimator(model, criterion)\n\n\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   \nPreprocessing\n. \nNNEstimator\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL \nSample\n and send to model for\n   training.\n2. \nNNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int) and labelSize(Array of Int). \nNNEstimator\n\n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n3. \nNNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion, featurePreprocessing and labelPreprocessing.  \nNNEstimator\n\n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNEstimator\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample according to user-specified Preprocessing.\n\n\nScala Example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)\n\n\n\n\n\n\nNNModel\n\n\nScala:\n\n\nval nnModel = NNModel(bigDLModel)\n\n\n\n\nPython:\n\n\nnn_model = NNModel(bigDLModel)\n\n\n\n\nNNModel\n extends Spark's ML\n\nTransformer\n. User can invoke\n\nfit\n in \nNNEstimator\n to get a \nNNModel\n, or directly compose a \nNNModel\n from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for \nDataFrame\n(DataSet)\n. \n\n\nNNModel\n can be created with various parameters for different scenarios.\n\n\n\n\nNNModel(model)\n\n\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNModel\n will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2. \nNNModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3. \nNNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNModel\n will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNModel\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nNNClassifier\n\n\nScala:\n\n\nval classifer =  NNClassifer(model, criterion)\n\n\n\n\nPython:\n\n\nclassifier = NNClassifer(model, criterion)\n\n\n\n\nNNClassifier\n is a specialized \nNNEstimator\n that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted \nNNClassifierModel\n will have the prediction column of \nDoubleType.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\n\n\nNNClassifier\n can be created with various parameters for different scenarios.\n\n\n\n\nNNClassifier(model, criterion)\n\n\n\n\nTakes only model and criterion and use \nSeqToTensor\n as feature and label\n   Preprocessing. \nNNClassifier\n will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n2. \nNNClassifier(model, criterion, featureSize: Array[Int])\n\n\nTakes model, criterion, featureSize(Array of Int). \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size. \nScalarToTensor\n is used to convert the label column.\n3. \nNNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model, criterion and featurePreprocessing.  \nNNClassifier\n\n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifier\n supports:\n\nsetSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])\n to directly compose\nSample with user-specified Preprocessing.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\n\n\n\n\nNNClassifierModel\n\n\nScala:\n\n\nval nnClassifierModel = NNClassifierModel(model, featureSize)\n\n\n\n\nPython:\n\n\nnn_classifier_model = NNClassifierModel(model)\n\n\n\n\nNNClassifierModel is a specialized \nNNModel\n for classification tasks.\nBoth label and prediction column will have the datatype of Double.\n\n\nNNClassifierModel\n can be created with various parameters for different scenarios.\n\n\n\n\nNNClassifierModel(model)\n\n\n\n\nTakes only model and use \nSeqToTensor\n as feature Preprocessing. \nNNClassifierModel\n will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2. \nNNClassifierModel(model, featureSize: Array[Int])\n\n\nTakes model and featureSize(Array of Int). \nNNClassifierModel\n will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3. \nNNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])\n\n\nTakes model and featurePreprocessing. \nNNClassifierModel\n will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.\n\n\nMeanwhile, for advanced use cases (e.g. model with multiple input tensor), \nNNClassifierModel\n\nsupports: \nsetSamplePreprocessing(value: Preprocessing[Any, Sample[T]])\nto directly compose\nSample according to user-specified Preprocessing.\n\n\n\n\nHyperparameter setting\n\n\nPrior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or\n\nNNEstimator\n/\nNNClassifier\n will use the default value.\n\n\nContinue the codes above, NNEstimator and NNClassifier can be set in the same way.\n\n\nScala:\n\n\n//for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n\n\n\n\nPython:\n\n\n# for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n\n\n\n\n\nPrepare the data and start the training process\n\n\nNNEstimator/NNCLassifer supports training with Spark's\n\nDataFrame/DataSet\n\n\nSuppose \ndf\n is the training data, simple call \nfit\n method and let Analytics Zoo train the model\nfor you.\n\n\nScala:\n\n\n//get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)\n\n\n\n\nPython:\n\n\n# get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)\n\n\n\n\nUser may also set validation DataFrame and validation frequency through \nsetValidation\n method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.\n\n\nMake prediction on chosen data\n\n\nSince \nNNModel\n/\nNNClassifierModel\n inherits from Spark's \nTransformer\n abstract class, simply call \n\ntransform\n method on \nNNModel\n/\nNNClassifierModel\n to make prediction.\n\n\nScala:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nPython:\n\n\nnnModel.transform(df).show(false)\n\n\n\n\nFor the complete examples of NNFrames, please refer to:\n\nScala examples\n\n\nPython examples\n\n\nNNImageReader\n\n\nNNImageReader\n is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.\n\n\nScala:\n\n\n    val imageDF = NNImageReader.readImages(imageDirectory, sc)\n\n\n\n\nPython:\n\n\n    image_frame = NNImageReader.readImages(image_path, self.sc)\n\n\n\n\nThe output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from \ncom.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema\n.\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand \ndata\n holds the original file bytes for the image file. \nmode\n represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.\n\n\n  val byteSchema = StructType(\n    StructField(\norigin\n, StringType, true) ::\n      StructField(\nheight\n, IntegerType, false) ::\n      StructField(\nwidth\n, IntegerType, false) ::\n      StructField(\nnChannels\n, IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField(\nmode\n, IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField(\ndata\n, BinaryType, false) :: Nil)\n\n\n\n\nAfter loading the image, user can compose the preprocess steps with the \nPreprocessing\n defined\nin \ncom.intel.analytics.zoo.feature.image\n.", 
            "title": "NNFrames"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnestimator", 
            "text": "Scala:  val estimator = NNEstimator(model, criterion)  Python:  estimator = NNEstimator(model, criterion)  NNEstimator  extends  org.apache.spark.ml.Estimator  and supports training a BigDL\nmodel with Spark DataFrame data. It can be integrated into a standard Spark ML Pipeline\nto allow users to combine the components of BigDL and Spark MLlib.  NNEstimator  supports different feature and label data types through  Preprocessing .\nDuring fit (training), NNEstimator will extract feature and label data from input DataFrame and use\nthe  Preprocessing  to convert data for the model, typically converts the feature and label\nto Tensors or converts the (feature, option[Label]) tuple to a BigDL  Sample . Each Preprocessing  conducts a data conversion step in the preprocessing phase, multiple Preprocessing  can be combined into a  ChainedPreprocessing . Some pre-defined  Preprocessing  for popular data types like Image, Array or Vector are provided in package com.intel.analytics.zoo.feature , while user can also develop customized  Preprocessing .\nBy default,  SeqToTensor  is used to convert an array or Vector to a 1-dimension Tensor.\nUsing the  Preprocessing  allows  NNEstimator  to cache only the raw data and decrease the \nmemory consumption during feature conversion and training, it also enables the model to digest\nextra data types that DataFrame does not support currently.\nMore concrete examples are available in package  com.intel.analytics.zoo.examples.nnframes  NNEstimator  can be created with various parameters for different scenarios.   NNEstimator(model, criterion)   Takes only model and criterion and use  SeqToTensor  as feature and label\n    Preprocessing .  NNEstimator  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL  Sample  and send to model for\n   training.\n2.  NNEstimator(model, criterion, featureSize: Array[Int], labelSize: Array[Int])  Takes model, criterion, featureSize(Array of Int) and labelSize(Array of Int).  NNEstimator \n   will extract the data from feature and label columns (only Scalar, Array[_] or Vector data\n   type are supported) and convert each feature/label to Tensor according to the specified Tensor\n   size.\n3.  NNEstimator(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]],\nlabelPreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion, featurePreprocessing and labelPreprocessing.   NNEstimator \n   will extract the data from feature and label columns and convert each feature/label to Tensor\n   with the featurePreprocessing and labelPreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNEstimator  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample according to user-specified Preprocessing.  Scala Example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNEstimator\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNEstimator(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval nnModel = estimator.fit(df)\nnnModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.feature.common import *\n\ndata = self.sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = self.sqlContext.createDataFrame(data, schema)\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = NNEstimator(model, criterion, SeqToTensor([2]), ArrayToTensor([2]))\\\n    .setBatchSize(4).setLearningRate(0.2).setMaxEpoch(40)\nnnModel = estimator.fit(df)\nres = nnModel.transform(df)", 
            "title": "NNEstimator"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnmodel", 
            "text": "Scala:  val nnModel = NNModel(bigDLModel)  Python:  nn_model = NNModel(bigDLModel)  NNModel  extends Spark's ML Transformer . User can invoke fit  in  NNEstimator  to get a  NNModel , or directly compose a  NNModel  from BigDLModel.\nIt enables users to wrap a pre-trained BigDL Model into a NNModel,\nand use it as a transformer in your Spark ML pipeline to predict the results for  DataFrame\n(DataSet) .   NNModel  can be created with various parameters for different scenarios.   NNModel(model)   Takes only model and use  SeqToTensor  as feature Preprocessing.  NNModel  will extract the\n   data from feature column (only Scalar, Array[_] or Vector data type are supported) and\n   convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2.  NNModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3.  NNModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNModel  will extract the data from feature column\n   and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNModel  supports: setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifier", 
            "text": "Scala:  val classifer =  NNClassifer(model, criterion)  Python:  classifier = NNClassifer(model, criterion)  NNClassifier  is a specialized  NNEstimator  that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of\nDoubleType, and the fitted  NNClassifierModel  will have the prediction column of \nDoubleType.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient   NNClassifier  can be created with various parameters for different scenarios.   NNClassifier(model, criterion)   Takes only model and criterion and use  SeqToTensor  as feature and label\n   Preprocessing.  NNClassifier  will extract the data from feature and label columns (\n   only Scalar, Array[_] or Vector data type are supported) and convert each feature/label to\n   1-dimension Tensor. The tensors will be combined into BigDL samples and send to model for\n   training.\n2.  NNClassifier(model, criterion, featureSize: Array[Int])  Takes model, criterion, featureSize(Array of Int).  NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   according to the specified Tensor size.  ScalarToTensor  is used to convert the label column.\n3.  NNClassifier(model, criterion, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model, criterion and featurePreprocessing.   NNClassifier \n   will extract the data from feature and label columns and convert each feature to Tensor\n   with the featurePreprocessing. This constructor provides more flexibility\n   in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifier  supports: setSamplePreprocessing(value: Preprocessing[(Any, Option[Any]), Sample[T]])  to directly compose\nSample with user-specified Preprocessing.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.zoo.pipeline.nnframes.NNClassifier\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = NNClassifier(model, criterion)\n  .setLearningRate(0.2)\n  .setMaxEpoch(40)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df = sqlContext.createDataFrame(data).toDF( features ,  label )\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\n\n#Logistic Regression with BigDL layers and Analytics zoo NNClassifier\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = NNClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)", 
            "title": "NNClassifier"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnclassifiermodel", 
            "text": "Scala:  val nnClassifierModel = NNClassifierModel(model, featureSize)  Python:  nn_classifier_model = NNClassifierModel(model)  NNClassifierModel is a specialized  NNModel  for classification tasks.\nBoth label and prediction column will have the datatype of Double.  NNClassifierModel  can be created with various parameters for different scenarios.   NNClassifierModel(model)   Takes only model and use  SeqToTensor  as feature Preprocessing.  NNClassifierModel  will\n   extract the data from feature column (only Scalar, Array[_] or Vector data type are supported)\n   and convert each feature to 1-dimension Tensor. The tensors will be sent to model for inference.\n2.  NNClassifierModel(model, featureSize: Array[Int])  Takes model and featureSize(Array of Int).  NNClassifierModel  will extract the data from feature\n   column (only Scalar, Array[_] or Vector data type are supported) and convert each feature\n   to Tensor according to the specified Tensor size.\n3.  NNClassifierModel(model, featurePreprocessing: Preprocessing[F, Tensor[T]])  Takes model and featurePreprocessing.  NNClassifierModel  will extract the data from feature\n   column and convert each feature to Tensor with the featurePreprocessing. This constructor provides\n   more flexibility in supporting extra data types.  Meanwhile, for advanced use cases (e.g. model with multiple input tensor),  NNClassifierModel \nsupports:  setSamplePreprocessing(value: Preprocessing[Any, Sample[T]]) to directly compose\nSample according to user-specified Preprocessing.", 
            "title": "NNClassifierModel"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#hyperparameter-setting", 
            "text": "Prior to the commencement of the training process, you can modify the optimization algorithm, batch \nsize, the epoch number of your training, and learning rate to meet your goal or NNEstimator / NNClassifier  will use the default value.  Continue the codes above, NNEstimator and NNClassifier can be set in the same way.  Scala:  //for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(new Adam())  Python:  # for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01).setOptimMethod(Adam())", 
            "title": "Hyperparameter setting"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#prepare-the-data-and-start-the-training-process", 
            "text": "NNEstimator/NNCLassifer supports training with Spark's DataFrame/DataSet  Suppose  df  is the training data, simple call  fit  method and let Analytics Zoo train the model\nfor you.  Scala:  //get a NNClassifierModel\nval nnClassifierModel = classifier.fit(df)  Python:  # get a NNClassifierModel\nnnClassifierModel = classifier.fit(df)  User may also set validation DataFrame and validation frequency through  setValidation  method.\nTrain summay and validation summary can also be configured to log the training process for\nvisualization in Tensorboard.", 
            "title": "Prepare the data and start the training process"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#make-prediction-on-chosen-data", 
            "text": "Since  NNModel / NNClassifierModel  inherits from Spark's  Transformer  abstract class, simply call  transform  method on  NNModel / NNClassifierModel  to make prediction.  Scala:  nnModel.transform(df).show(false)  Python:  nnModel.transform(df).show(false)  For the complete examples of NNFrames, please refer to: Scala examples  Python examples", 
            "title": "Make prediction on chosen data"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/nnframes/#nnimagereader", 
            "text": "NNImageReader  is the primary DataFrame-based image loading interface, defining API to read images\ninto DataFrame.  Scala:      val imageDF = NNImageReader.readImages(imageDirectory, sc)  Python:      image_frame = NNImageReader.readImages(image_path, self.sc)  The output DataFrame contains a sinlge column named \"image\". The schema of \"image\" column can be\naccessed from  com.intel.analytics.zoo.pipeline.nnframes.DLImageSchema.byteSchema .\nEach record in \"image\" column represents one image record, in the format of\nRow(origin, height, width, num of channels, mode, data), where origin contains the URI for the image file,\nand  data  holds the original file bytes for the image file.  mode  represents the OpenCV-compatible\ntype: CV_8UC3, CV_8UC1 in most cases.    val byteSchema = StructType(\n    StructField( origin , StringType, true) ::\n      StructField( height , IntegerType, false) ::\n      StructField( width , IntegerType, false) ::\n      StructField( nChannels , IntegerType, false) ::\n      // OpenCV-compatible type: CV_8UC3, CV_32FC3 in most cases\n      StructField( mode , IntegerType, false) ::\n      // Bytes in OpenCV-compatible order: row-wise BGR in most cases\n      StructField( data , BinaryType, false) :: Nil)  After loading the image, user can compose the preprocess steps with the  Preprocessing  defined\nin  com.intel.analytics.zoo.feature.image .", 
            "title": "NNImageReader"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/autograd/", 
            "text": "", 
            "title": "Autograd"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/", 
            "text": "Net\n\n\nLoad Analytics Zoo Model\n\n\nUse \nNet.load\n(in Scala) or \nNet.load\n (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.  \nNet\n (Scala) or \nNet\n(Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.\n\n\nScala example\n\n\nval model = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.load(\nhdfs://...\n) //load from hdfs\nval model = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.load(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.load(\nhdfs://...\n) //load from hdfs\nmodel = Net.load(\ns3://...\n) //load from s3\n\n\n\n\nLoad BigDL Model\n\n\nScala example\n\n\nval model = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nval model = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nval model = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadBigDL(\n/tmp/model.def\n, \n/tmp/model.weights\n) //load from local fs\nmodel = Net.loadBigDL(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadBigDL(\ns3://...\n) //load from s3\n\n\n\n\nLoad Torch Model\n\n\nScala example\n\n\nval model = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nval model = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nval model = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadTorch(\n/tmp/torch_model\n) //load from local fs\nmodel = Net.loadTorch(\nhdfs://...\n) //load from hdfs\nmodel = Net.loadTorch(\ns3://...\n) //load from s3\n\n\n\n\nLoad Caffe Model\n\n\nScala example\n\n\nval model = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nval model = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nval model = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Net.loadCaffe(\n/tmp/def/path\n, \n/tmp/model/path\n) //load from local fs\nmodel = Net.loadCaffe(\nhdfs://def/path\n, \nhdfs://model/path\n) //load from hdfs\nmodel = Net.loadCaffe(\ns3://def/path\n, \ns3://model/path\n) //load from s3\n\n\n\n\nLoad Tensorflow model\n\n\nWe also provides utilities to load tensorflow model.\nfor more information.\n\n\nIf we already have a freezed graph protobuf file, we can use the \nloadTF\n api directly to\nload the tensorflow model. \n\n\nOtherwise, we should first use the \nexport_tf_checkpoint.py\n script provided by BigDL's distribution\npackage, or the \ndump_model\n function defined in \nhere\n to\ngenerate the model definition file (\nmodel.pb\n) and variable binary file (\nmodel.bin\n). \n\n\nUse Script\n\n\nGRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH\n\n\n\n\nUse python function\n\n\nimport tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path = \n/tmp/model\n\n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)\n\n\n\n\nThen we can use the \nloadTF\n api to load the tensorflow model into BigDL.\n\n\nScala example\n\n\nval modelPath = \n/tmp/model/model.pb\n\nval binPath = \n/tmp/model/model.bin\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\n\n// For tensorflow freezed graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))\n\n\n\n\nPython example\n\n\nmodel_def = \n/tmp/model/model.pb\n\nmodel_variable = \n/tmp/model/model.bin\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\n# For tensorflow freezed graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n)\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n, bin_file=model_variable)\n\n\n\n\nTFNet\n\n\nScala:\n\n\nval m = TFNet(freezedModelPath, inputs, outputs)\n\n\n\n\nPython:\n\n\nm = TFNet(freezed_model_path, inputs, outputs)\n\n\n\n\nThis is a layer that wraps a tensorflow freezed sub graph as a layer and run tensorflow in parallel.", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#net", 
            "text": "", 
            "title": "Net"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-analytics-zoo-model", 
            "text": "Use  Net.load (in Scala) or  Net.load  (in Python) to load an existing model defined using the Analytics Zoo Keras-style API.   Net  (Scala) or  Net (Python) is a utility class provided in Analytics Zoo. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.  Scala example  val model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.load( hdfs://... ) //load from hdfs\nval model = Net.load( s3://... ) //load from s3  Python example  model = Net.load( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.load( hdfs://... ) //load from hdfs\nmodel = Net.load( s3://... ) //load from s3", 
            "title": "Load Analytics Zoo Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-bigdl-model", 
            "text": "Scala example  val model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nval model = Net.loadBigDL( hdfs://... ) //load from hdfs\nval model = Net.loadBigDL( s3://... ) //load from s3  Python example  model = Net.loadBigDL( /tmp/model.def ,  /tmp/model.weights ) //load from local fs\nmodel = Net.loadBigDL( hdfs://... ) //load from hdfs\nmodel = Net.loadBigDL( s3://... ) //load from s3", 
            "title": "Load BigDL Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-torch-model", 
            "text": "Scala example  val model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nval model = Net.loadTorch( hdfs://... ) //load from hdfs\nval model = Net.loadTorch( s3://... ) //load from s3  Python example  model = Net.loadTorch( /tmp/torch_model ) //load from local fs\nmodel = Net.loadTorch( hdfs://... ) //load from hdfs\nmodel = Net.loadTorch( s3://... ) //load from s3", 
            "title": "Load Torch Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-caffe-model", 
            "text": "Scala example  val model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nval model = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nval model = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3  Python example  model = Net.loadCaffe( /tmp/def/path ,  /tmp/model/path ) //load from local fs\nmodel = Net.loadCaffe( hdfs://def/path ,  hdfs://model/path ) //load from hdfs\nmodel = Net.loadCaffe( s3://def/path ,  s3://model/path ) //load from s3", 
            "title": "Load Caffe Model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#load-tensorflow-model", 
            "text": "We also provides utilities to load tensorflow model.\nfor more information.  If we already have a freezed graph protobuf file, we can use the  loadTF  api directly to\nload the tensorflow model.   Otherwise, we should first use the  export_tf_checkpoint.py  script provided by BigDL's distribution\npackage, or the  dump_model  function defined in  here  to\ngenerate the model definition file ( model.pb ) and variable binary file ( model.bin ).   Use Script  GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH  Use python function  import tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path =  /tmp/model \n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)  Then we can use the  loadTF  api to load the tensorflow model into BigDL.  Scala example  val modelPath =  /tmp/model/model.pb \nval binPath =  /tmp/model/model.bin \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\n\n// For tensorflow freezed graph or graph without Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Net.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))  Python example  model_def =  /tmp/model/model.pb \nmodel_variable =  /tmp/model/model.bin \ninputs = [ Placeholder ]\noutputs = [ output ]\n# For tensorflow freezed graph or graph without Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float )\n\n# For tensorflow graph with Variables\nmodel = Net.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float , bin_file=model_variable)", 
            "title": "Load Tensorflow model"
        }, 
        {
            "location": "/APIGuide/PipelineAPI/net/#tfnet", 
            "text": "Scala:  val m = TFNet(freezedModelPath, inputs, outputs)  Python:  m = TFNet(freezed_model_path, inputs, outputs)  This is a layer that wraps a tensorflow freezed sub graph as a layer and run tensorflow in parallel.", 
            "title": "TFNet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/", 
            "text": "Analytics Zoo Image API\n\n\nAnalytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.\n\n\nLoad Image\n\n\nAnalytics Zoo provides APIs to read image to different formats:\n\n\nLoad to Data Frame\n\n\nScala:\n\n\npackage com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1): DataFrame\n}\n\n\n\n\nRead the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.\n\n\n\n\npath: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).\n\n\nsc: SparkContext to be used.\n\n\nminPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead\n\n\n\n\nPython:\n\n\nclass zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, bigdl_type=\nfloat\n)\n\n\n\n\nImageSet\n\n\nImageSet\n is a collection of \nImageFeature\n. It can be a \nDistributedImageSet\n for distributed image RDD or\n \nLocalImageSet\n for local image array.\nYou can read image data as \nImageSet\n from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala APIs:\n\n\nobject com.intel.analytics.zoo.feature.image.ImageSet\n\n\n\n\ndef array(data: Array[ImageFeature]): LocalImageSet\n\n\n\n\nCreate LocalImageSet from array of ImeageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\ndef rdd(data: RDD[ImageFeature]): DistributedImageSet\n\n\n\n\nCreate DistributedImageSet from rdd of ImageFeature\n\n\n\n\ndata: array of ImageFeature\n\n\n\n\n  def read(path: String, sc: SparkContext = null, minPartitions: Int = 1): ImageSet\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\n\n\nExample:\n\n\n// create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read(\n/tmp/image/\n)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.ImageSet\n\n\n\n\nread(path, sc=None, min_partitions=1, bigdl_type=\nfloat\n)\n\n\n\n\nRead images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system\n\n\n\n\npath: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character\n\n\nsc: SparkContext\n\n\nminPartitions: A suggestion value of the minimal splitting number for input data.\n\n\n\n\nPython example:\n\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read(\n/tmp/image/\n)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nImage Transformer\n\n\nAnalytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call \ntransform\n with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training. \n\n\nScala APIs:\n\n\npackage com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndeltaLow: low bound of brightness parameter\n\n\ndeltaHigh: high bound of brightness parameter\n\n\n\n\nExample:\n\n\nval transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)\n\n\n\n\nPython APIs:\n\n\nclass zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type=\nfloat\n)\n\n\n\n\nAdjust the image brightness.\n\n\n\n\ndelta_low: low bound of brightness parameter\n\n\ndelta_high: high bound of brightness parameter\n\n\n\n\nExample:\n\n\ntransformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)", 
            "title": "Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#analytics-zoo-image-api", 
            "text": "Analytics Zoo provides a series of Image APIs for end-to-end image processing pipeline, including image loading, pre-processing, inference/training and some utilities on different formats.", 
            "title": "Analytics Zoo Image API"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-image", 
            "text": "Analytics Zoo provides APIs to read image to different formats:", 
            "title": "Load Image"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#load-to-data-frame", 
            "text": "Scala:  package com.intel.analytics.zoo.pipeline.nnframes\n\nobject NNImageReader {\n  def readImages(path: String, sc: SparkContext, minPartitions: Int = 1): DataFrame\n}  Read the directory of images from the local or remote source, return DataFrame with a single column \"image\" of images.   path: Directory to the input data files, the path can be comma separated paths as the list of inputs. Wildcards path are supported similarly to sc.binaryFiles(path).  sc: SparkContext to be used.  minPartitions: Number of the DataFrame partitions, if omitted uses defaultParallelism instead   Python:  class zoo.pipeline.nnframes.NNImageReader\n    static readImages(path, sc=None, minPartitions=1, bigdl_type= float )", 
            "title": "Load to Data Frame"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#imageset", 
            "text": "ImageSet  is a collection of  ImageFeature . It can be a  DistributedImageSet  for distributed image RDD or\n  LocalImageSet  for local image array.\nYou can read image data as  ImageSet  from local/distributed image path, or you can directly construct a ImageSet from RDD[ImageFeature] or Array[ImageFeature].  Scala APIs:  object com.intel.analytics.zoo.feature.image.ImageSet  def array(data: Array[ImageFeature]): LocalImageSet  Create LocalImageSet from array of ImeageFeature   data: array of ImageFeature   def rdd(data: RDD[ImageFeature]): DistributedImageSet  Create DistributedImageSet from rdd of ImageFeature   data: array of ImageFeature     def read(path: String, sc: SparkContext = null, minPartitions: Int = 1): ImageSet  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.   Example:  // create LocalImageSet from an image folder\nval localImageFrame = ImageSet.read( /tmp/image/ )\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageSet.read( /tmp/image/ , sc, 2)  Python APIs:  class zoo.feature.image.ImageSet  read(path, sc=None, min_partitions=1, bigdl_type= float )  Read images as Image Set.\nIf sc is defined, read image as DistributedImageSet from local file system or HDFS.\nIf sc is null, Read image as LocalImageSet from local file system   path: path to read images. If sc is defined, path can be local or HDFS. Wildcard character are supported. If sc is null, path is local directory/image file/image file with wildcard character  sc: SparkContext  minPartitions: A suggestion value of the minimal splitting number for input data.   Python example:  # create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageSet.read( /tmp/image/ )\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageSet.read( /tmp/image/ , sc, 2)", 
            "title": "ImageSet"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/image/#image-transformer", 
            "text": "Analytics Zoo provides many pre-defined image processing transformers built on top of OpenCV. After create these transformers, call  transform  with ImageSet to get transformed ImageSet. Or pass the transformer to NNEstimator/NNClassifier to preprocess before training.   Scala APIs:  package com.intel.analytics.zoo.feature.image\n\nobject ImageBrightness\n\ndef apply(deltaLow: Double, deltaHigh: Double): ImageBrightness  Adjust the image brightness.   deltaLow: low bound of brightness parameter  deltaHigh: high bound of brightness parameter   Example:  val transformer = ImageBrightness(0.0, 32.0)\nval transformed = imageSet.transform(transformer)  Python APIs:  class zoo.feature.image.imagePreprocessing.ImageBrightness\n\ndef __init__(delta_low, delta_high, bigdl_type= float )  Adjust the image brightness.   delta_low: low bound of brightness parameter  delta_high: high bound of brightness parameter   Example:  transformer = ImageBrightness(0.0, 32.0)\ntransformed = imageSet.transform(transformer)", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/APIGuide/FeatureEngineering/preprocessing/", 
            "text": "", 
            "title": "Preprocessing"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/", 
            "text": "Analytics Zoo Object Detection API\n\n\nAnalytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink.\n\n\nModel Load\n\n\nUse \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float](\n/tmp/zoo.model\n) //load from local fs\nval model = ObjectDetector.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ObjectDetector.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model(\n/tmp/zoo.model\n) //load from local fs\nmodel = ObjectDetector.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ObjectDetector.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nObjectDetector.loadModel\n(in Scala) or \nObjectDetector.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.\n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageSet before model inference\n\n\npostProcessor: postprocessor of ImageSet after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)\n\n\n\n\nPredict with loaded object detection model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this prediction\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.getNNContext()\nval model = ObjectDetector.loadModel(\n/tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model\n)\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  prediction\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import get_nncontext\nfrom zoo.models.image.objectdetection import *\n\nimc = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)", 
            "title": "Object Detection"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#analytics-zoo-object-detection-api", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Object Detection. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios. User can run the inference as local program without Spark Context, or in a distributed environment such like Apache Spark, Apache Storm or Apache Flink.", 
            "title": "Analytics Zoo Object Detection API"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#model-load", 
            "text": "Use  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python) to load an pre-trained Analytics Zoo model or third-party(BigDL) model. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\n\nval model = ObjectDetector.loadModel[Float]( /tmp/zoo.model ) //load from local fs\nval model = ObjectDetector.loadModel( hdfs://... ) //load from hdfs\nval model = ObjectDetector.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.objectdetection import *\n\nmodel = ObjectDetector.load_model( /tmp/zoo.model ) //load from local fs\nmodel = ObjectDetector.load_model( hdfs://... ) //load from hdfs\nmodel = ObjectDetector.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ObjectDetector.loadModel (in Scala) or  ObjectDetector.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.  Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageSet before model inference  postProcessor: postprocessor of ImageSet after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/object-detection/#predict-with-loaded-object-detection-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this prediction   Scala example  import com.intel.analytics.zoo.models.image.objectdetection._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.getNNContext()\nval model = ObjectDetector.loadModel( /tmp/analytics-zoo_ssd-mobilenet-300x300_PASCAL_0.1.0.model )\nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  prediction   Python example  from zoo.common.nncontext import get_nncontext\nfrom zoo.models.image.objectdetection import *\n\nimc = ObjectDetector.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)", 
            "title": "Predict with loaded object detection model"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/", 
            "text": "Analytics Zoo Image Classification API\n\n\nAnalytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.\n\n\nModel Load\n\n\nUse \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.  \nModule\n (Scala) or \nModel\n(Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float](\n/tmp/model.zoo\n, \n/tmp/model.bin\n) //load from local fs\nval model = ImageClassifier.loadModel(\nhdfs://...\n) //load from hdfs\nval model = ImageClassifier.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model(\n/tmp/...model\n, \n/tmp/model.bin\n) //load from local fs\nmodel = ImageClassifier.load_model(\nhdfs://...\n) //load from hdfs\nmodel = ImageClassifier.load_model(\ns3://...\n) //load from s3\n\n\n\n\nCreat image configuration\n\n\nIf the loaded model is a published Analytics Zoo model, when you call \nImageClassifier.loadModel\n(in Scala) or \nImageClassifier.load_model\n (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration. \n\n\nScala API\n\n\nImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)\n\n\n\n\n\n\npreProcessor: preprocessor of ImageFrame before model inference\n\n\npostProcessor: postprocessor of ImageFrame after model inference\n\n\nbatchPerPartition: batch size per partition\n\n\nlabelMap: label mapping\n\n\nfeaturePaddingParam: featurePaddingParam if the inputs have variant size\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-\n ImageCenterCrop(224, 224) -\n\n                     ImageChannelNormalize(123, 117, 104) -\n\n                     ImageMatToTensor[Float]() -\n\n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)\n\n\n\n\nPython API\n\n\nclass ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type=\nfloat\n)\n\n\n\n\n\n\npre_processor:  preprocessor of ImageSet before model inference\n\n\npost_processor:  postprocessor of ImageSet after model inference\n\n\nbatch_per_partition:  batch size per partition\n\n\nlabel_map mapping:  from prediction result indexes to real dataset labels\n\n\nfeature_padding_param:  featurePaddingParam if the inputs have variant size\n\n\n\n\nPython example\n\n\nfrom zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing) \n\n\n\n\nPredict with loaded image classification model\n\n\nScala API\n\n\npredictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  predcition\n\n\n\n\nScala example\n\n\nimport com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath=\n/tmp/image\n\nval sc = NNContext.getNNContext()\nval model = ImageClassifier.loadModel(\n/tmp/analytics-zoo_inception-v1_imagenet_0.1.0\n) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)\n\n\n\n\nPython API\n\n\npredict_image_set(image, configure=None)\n\n\n\n\n\n\nimage:  Analytics Zoo ImageSet to be predicted\n\n\nconfigure: Image Configure for this  predcition\n\n\n\n\nPython example\n\n\nfrom zoo.common.nncontext import get_nncontext\nfrom zoo.models.image.imageclassification import *\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)", 
            "title": "Image Classification"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#analytics-zoo-image-classification-api", 
            "text": "Analytics Zoo provides a collection of pre-trained models for Image Classification. These models can be used for out-of-the-box inference if you are interested in categories already in the corresponding datasets. According to the business scenarios, users can embed the models locally, distributedly in Spark such as Apache Storm and Apache Flink.", 
            "title": "Analytics Zoo Image Classification API"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#model-load", 
            "text": "Use  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python) to load an pre-trained analytics zoo model or third-party(BigDL) model.   Module  (Scala) or  Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model.  Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\n\nval model = ImageClassifier.loadModel[Float]( /tmp/model.zoo ,  /tmp/model.bin ) //load from local fs\nval model = ImageClassifier.loadModel( hdfs://... ) //load from hdfs\nval model = ImageClassifier.loadModel( s3://... ) //load from s3  Python example  from zoo.models.image.imageclassification import *\n\nmodel = ImageClassifier.load_model( /tmp/...model ,  /tmp/model.bin ) //load from local fs\nmodel = ImageClassifier.load_model( hdfs://... ) //load from hdfs\nmodel = ImageClassifier.load_model( s3://... ) //load from s3", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#creat-image-configuration", 
            "text": "If the loaded model is a published Analytics Zoo model, when you call  ImageClassifier.loadModel (in Scala) or  ImageClassifier.load_model  (in Python), it would create the default Image Configuration for model inference. If the loaded model is not a published Analytics Zoo model or you want to customize the configuration for model inference, you need to create your own Image Configuration.   Scala API  ImageConfigure[T: ClassTag](\n  preProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  postProcessor: Preprocessing[ImageFeature, ImageFeature] = null,\n  batchPerPartition: Int = 4,\n  labelMap: Map[Int, String] = null,\n  featurePaddingParam: Option[PaddingParam[T]] = None)   preProcessor: preprocessor of ImageFrame before model inference  postProcessor: postprocessor of ImageFrame after model inference  batchPerPartition: batch size per partition  labelMap: label mapping  featurePaddingParam: featurePaddingParam if the inputs have variant size   Scala example  import com.intel.analytics.zoo.models.image.common._\nimport com.intel.analytics.zoo.feature.image._\n\nval preprocessing = ImageResize(256, 256)-  ImageCenterCrop(224, 224) - \n                     ImageChannelNormalize(123, 117, 104) - \n                     ImageMatToTensor[Float]() - \n                     ImageSetToSample[Float]()\nval config = ImageConfigure[Float](preProcessor=preprocessing)  Python API  class ImageConfigure()\n    def __init__(self, pre_processor=None,\n                 post_processor=None,\n                 batch_per_partition=4,\n                 label_map=None, feature_padding_param=None, jvalue=None, bigdl_type= float )   pre_processor:  preprocessor of ImageSet before model inference  post_processor:  postprocessor of ImageSet after model inference  batch_per_partition:  batch size per partition  label_map mapping:  from prediction result indexes to real dataset labels  feature_padding_param:  featurePaddingParam if the inputs have variant size   Python example  from zoo.models.image.common.image_config import *\nfrom zoo.feature.image.imagePreprocessing import *\n\npreprocessing = ChainedPreprocessing(\n                [ImageResize(256, 256), ImageCenterCrop(224, 224),\n                ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(),\n                ImageSetToSample()])\nconfig = ImageConfigure(pre_processor=preprocessing)", 
            "title": "Creat image configuration"
        }, 
        {
            "location": "/APIGuide/Models/image-classification/#predict-with-loaded-image-classification-model", 
            "text": "Scala API  predictImageSet(image: ImageSet, configure: ImageConfigure[T] = null)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  predcition   Scala example  import com.intel.analytics.zoo.models.image.imageclassification._\nimport com.intel.analytics.zoo.common.NNContext\nimport com.intel.analytics.zoo.feature.image._\n\nval imagePath= /tmp/image \nval sc = NNContext.getNNContext()\nval model = ImageClassifier.loadModel( /tmp/analytics-zoo_inception-v1_imagenet_0.1.0 ) \nval data = ImageSet.read(image_path, sc)\nval output = model.predictImageSet(data)  Python API  predict_image_set(image, configure=None)   image:  Analytics Zoo ImageSet to be predicted  configure: Image Configure for this  predcition   Python example  from zoo.common.nncontext import get_nncontext\nfrom zoo.models.image.imageclassification import *\n\nimc = ImageClassifier.load_model(model_path)\nimage_set = ImageSet.read(img_path, sc)\noutput = imc.predict_image_set(image_set)", 
            "title": "Predict with loaded image classification model"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/", 
            "text": "Analytics Zoo Text Classification API\n\n\nAnalytics Zoo provides a set of pre-defined models that can be used for classifying texts with different encoders. This model could be fed into NNFrames and BigDL Optimizer directly for training.\n\n\nScala\n\n\nTextClassifier(classNum, tokenLength, sequenceLength = 500, encoder = \ncnn\n, encoderOutputDim = 256)\n\n\n\n\n\n\nclassNum\n: The number of text categories to be classified. Positive integer.\n\n\ntokenLength\n: The size of each word vector. Positive integer.\n\n\nsequenceLength\n: The length of a sequence. Positive integer. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".\n\n\nencoderOutputDim\n: The output dimension for the encoder. Positive integer. Default is 256.\n\n\n\n\nSee \nhere\n for the Scala example that trains the \nTextClassifier\n model on 20 Newsgroup dataset and uses the model to do prediction.\n\n\nPython\n\n\nTextClassifier(class_num, token_length, sequence_length=500, encoder=\ncnn\n, encoder_output_dim=256)\n\n\n\n\n\n\nclass_num\n: The number of text categories to be classified. Positive int.\n\n\ntoken_length\n: The size of each word vector. Positive int.\n\n\nsequence_length\n: The length of a sequence. Positive int. Default is 500.\n\n\nencoder\n: The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.\n\n\nencoder_output_dim\n: The output dimension for the encoder. Positive int. Default is 256.\n\n\n\n\nSee \nhere\n for the Python example that trains the \nTextClassifier\n model on 20 Newsgroup dataset and uses the model to do prediction.", 
            "title": "Text Classification"
        }, 
        {
            "location": "/APIGuide/Models/text-classification/#analytics-zoo-text-classification-api", 
            "text": "Analytics Zoo provides a set of pre-defined models that can be used for classifying texts with different encoders. This model could be fed into NNFrames and BigDL Optimizer directly for training.  Scala  TextClassifier(classNum, tokenLength, sequenceLength = 500, encoder =  cnn , encoderOutputDim = 256)   classNum : The number of text categories to be classified. Positive integer.  tokenLength : The size of each word vector. Positive integer.  sequenceLength : The length of a sequence. Positive integer. Default is 500.  encoder : The encoder for input sequences. String. \"cnn\" or \"lstm\" or \"gru\" are supported. Default is \"cnn\".  encoderOutputDim : The output dimension for the encoder. Positive integer. Default is 256.   See  here  for the Scala example that trains the  TextClassifier  model on 20 Newsgroup dataset and uses the model to do prediction.  Python  TextClassifier(class_num, token_length, sequence_length=500, encoder= cnn , encoder_output_dim=256)   class_num : The number of text categories to be classified. Positive int.  token_length : The size of each word vector. Positive int.  sequence_length : The length of a sequence. Positive int. Default is 500.  encoder : The encoder for input sequences. String. 'cnn' or 'lstm' or 'gru' are supported. Default is 'cnn'.  encoder_output_dim : The output dimension for the encoder. Positive int. Default is 256.   See  here  for the Python example that trains the  TextClassifier  model on 20 Newsgroup dataset and uses the model to do prediction.", 
            "title": "Analytics Zoo Text Classification API"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/", 
            "text": "Analytics Zoo Recommender API\n\n\nAnalytics Zoo provides two Recommenders, including Wide and Deep (WND) model and Neural network-based Collaborative Filtering (NCF) model. Each model could be fed into NNFrames and BigDL Optimizer directly for training.\n\n\nRecommenders can handle models with either explict or implicit feedback, given corresponding features.\n\n\nWe also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See \nhere\n for more details.\n\n\n\n\nWide and Deep\n\n\nWide and Deep Learning Model, proposed by \nGoogle, 2016\n, is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.\n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nWideAndDeep(modelType = \nwide_n_deep\n, numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))\n\n\n\n\n\n\nmodelType\n: String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\ncolumnInfo\n An instance of \nColumnFeatureInfo\n.\n\n\nhiddenLayers\n: Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).\n\n\n\n\nSee \nhere\n for the Scala example that trains the \nWideAndDeep\n model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nWideAndDeep(class_num, column_info, model_type=\nwide_n_deep\n, hidden_layers=(40, 20, 10))\n\n\n\n\n\n\nclass_num\n: The number of classes. Positive int.\n\n\ncolumn_info\n: An instance of \nColumnFeatureInfo\n.\n\n\nmodel_type\n: String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.\n\n\nhidden_layers\n: Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).\n\n\n\n\nSee \nhere\n for the Python notebook that trains the \nWideAndDeep\n model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nColumnFeatureInfo\n\n\nAn instance of \nColumnFeatureInfo\n contains the same data information shared by the \nWideAndDeep\n model and its feature generation part.\n\n\nYou can choose to include the following information for feature engineering and the \nWideAndDeep\n model:\n\n\n\n\nwideBaseCols\n: Data of \nwideBaseCols\n together with \nwideCrossCols\n will be fed into the wide model.\n\n\nwideBaseDims\n: Dimensions of \nwideBaseCols\n. The dimensions of the data in \nwideBaseCols\n should be within the range of \nwideBaseDims\n.\n\n\nwideCrossCols\n: Data of \nwideCrossCols\n will be fed into the wide model.\n\n\nwideCrossDims\n: Dimensions of \nwideCrossCols\n. The dimensions of the data in \nwideCrossCols\n should be within the range of \nwideCrossDims\n.\n\n\nindicatorCols\n: Data of \nindicatorCols\n will be fed into the deep model as multi-hot vectors. \n\n\nindicatorDims\n: Dimensions of \nindicatorCols\n. The dimensions of the data in \nindicatorCols\n should be within the range of \nindicatorDims\n.\n\n\nembedCols\n: Data of \nembedCols\n will be fed into the deep model as embeddings.\n\n\nembedInDims\n: Input dimension of the data in \nembedCols\n. The dimensions of the data in \nembedCols\n should be within the range of \nembedInDims\n.\n\n\nembedOutDims\n: The dimensions of embeddings for \nembedCols\n.\n\n\ncontinuousCols\n: Data of \ncontinuousCols\n will be treated as continuous values for the deep model.\n\n\nlabel\n: The name of the 'label' column. String. Default is \"label\".\n\n\n\n\nRemark:\n\n\nFields that involve \nCols\n should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.\n\n\nFields that involve \nDims\n should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.\n\n\nIf any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).\n\n\nScala\n\n\nColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label = \nlabel\n)\n\n\n\n\nPython\n\n\nColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label=\nlabel\n)\n\n\n\n\n\n\nNeural network-based Collaborative Filtering\n\n\nNCF (\nHe, 2015\n) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework. \nincludeMF\n(Boolean) is provided for users to build a \nNeuralCF\n model with or without matrix factorization. \n\n\nAfter training the model, users can use the model to \ndo prediction and recommendation\n.\n\n\nScala\n\n\nNeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)\n\n\n\n\n\n\nuserCount\n: The number of users. Positive integer.\n\n\nitemCount\n: The number of items. Positive integer.\n\n\nnumClasses\n: The number of classes. Positive integer.\n\n\nuserEmbed\n: Units of user embedding. Positive integer. Default is 20.\n\n\nitemEmbed\n: Units of item embedding. Positive integer. Default is 20.\n\n\nhiddenLayers\n: Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).\n\n\nincludeMF\n: Whether to include Matrix Factorization. Boolean. Default is true.\n\n\nmfEmbed\n: Units of matrix factorization embedding. Positive integer. Default is 20.\n\n\n\n\nSee \nhere\n for the Scala example that trains the \nNeuralCF\n model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\nPython\n\n\nNeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)\n\n\n\n\n\n\nuser_count\n: The number of users. Positive int.\n\n\nitem_count\n: The number of classes. Positive int.\n\n\nclass_num:\n The number of classes. Positive int.\n\n\nuser_embed\n: Units of user embedding. Positive int. Default is 20.\n\n\nitem_embed\n: itemEmbed Units of item embedding. Positive int. Default is 20.\n\n\nhidden_layers\n: Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).\n\n\ninclude_mf\n: Whether to include Matrix Factorization. Boolean. Default is True.\n\n\nmf_embed\n: Units of matrix factorization embedding. Positive int. Default is 20.\n\n\n\n\nSee \nhere\n for the Python notebook that trains the \nNeuralCF\n model on MovieLens 1M dataset and uses the model to do prediction and recommendation.\n\n\n\n\nPrediction and Recommendation\n\n\nPredict for user-item pairs\n\n\nGive prediction for each pair of user and item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\npredictUserItemPair(featureRdd)\n\n\n\n\nPython\n\n\npredict_user_item_pair(feature_rdd)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\n\n\nRecommend for users\n\n\nRecommend a number of items for each user. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForUser(featureRdd, maxItems)\n\n\n\n\nPython\n\n\nrecommend_for_user(feature_rdd, max_items)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxItems\n: The number of items to be recommended to each user. Positive integer.\n\n\n\n\nRecommend for items\n\n\nRecommend a number of users for each item. Return RDD of \nUserItemPrediction\n.\n\n\nScala\n\n\nrecommendForItem(featureRdd, maxUsers)\n\n\n\n\nPython\n\n\nrecommend_for_item(feature_rdd, max_users)\n\n\n\n\nParameters:\n\n\n\n\nfeatureRdd\n: RDD of \nUserItemFeature\n.\n\n\nmaxUsers\n: The number of users to be recommended to each item. Positive integer.\n\n\n\n\nUserItemFeature\n\n\nRepresent records of user-item with features.\n\n\nEach record should contain the following fields:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitem_id\n: Positive integer.\n\n\nsample\n: \nSample\n which consists of feature(s) and label(s).\n\n\n\n\nScala\n\n\nUserItemFeature(userId, itemId, sample)\n\n\n\n\nPython\n\n\nUserItemFeature(user_id, item_id, sample)\n\n\n\n\nUserItemPrediction\n\n\nRepresent the prediction results of user-item pairs.\n\n\nEach prediction record will contain the following information:\n\n\n\n\nuserId\n: Positive integer.\n\n\nitemId\n: Positive integer.\n\n\nprediction\n: The prediction (rating) for the user on the item.\n\n\nprobability\n: The probability for the prediction.\n\n\n\n\nScala\n\n\nUserItemPrediction(userId, itemId, prediction, probability)\n\n\n\n\nPython\n\n\nUserItemPrediction(user_id, item_id, prediction, probability)", 
            "title": "Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#analytics-zoo-recommender-api", 
            "text": "Analytics Zoo provides two Recommenders, including Wide and Deep (WND) model and Neural network-based Collaborative Filtering (NCF) model. Each model could be fed into NNFrames and BigDL Optimizer directly for training.  Recommenders can handle models with either explict or implicit feedback, given corresponding features.  We also provide three user-friendly APIs to predict user item pairs, and recommend items (users) for users (items). See  here  for more details.", 
            "title": "Analytics Zoo Recommender API"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#wide-and-deep", 
            "text": "Wide and Deep Learning Model, proposed by  Google, 2016 , is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.  After training the model, users can use the model to  do prediction and recommendation .  Scala  WideAndDeep(modelType =  wide_n_deep , numClasses, columnInfo, hiddenLayers = Array(40, 20, 10))   modelType : String. \"wide\", \"deep\", \"wide_n_deep\" are supported. Default is \"wide_n_deep\".  numClasses : The number of classes. Positive integer.  columnInfo  An instance of  ColumnFeatureInfo .  hiddenLayers : Units of hidden layers for the deep model. Array of positive integers. Default is Array(40, 20, 10).   See  here  for the Scala example that trains the  WideAndDeep  model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  WideAndDeep(class_num, column_info, model_type= wide_n_deep , hidden_layers=(40, 20, 10))   class_num : The number of classes. Positive int.  column_info : An instance of  ColumnFeatureInfo .  model_type : String. 'wide', 'deep' and 'wide_n_deep' are supported. Default is 'wide_n_deep'.  hidden_layers : Units of hidden layers for the deep model. Tuple of positive int. Default is (40, 20, 10).   See  here  for the Python notebook that trains the  WideAndDeep  model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Wide and Deep"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#columnfeatureinfo", 
            "text": "An instance of  ColumnFeatureInfo  contains the same data information shared by the  WideAndDeep  model and its feature generation part.  You can choose to include the following information for feature engineering and the  WideAndDeep  model:   wideBaseCols : Data of  wideBaseCols  together with  wideCrossCols  will be fed into the wide model.  wideBaseDims : Dimensions of  wideBaseCols . The dimensions of the data in  wideBaseCols  should be within the range of  wideBaseDims .  wideCrossCols : Data of  wideCrossCols  will be fed into the wide model.  wideCrossDims : Dimensions of  wideCrossCols . The dimensions of the data in  wideCrossCols  should be within the range of  wideCrossDims .  indicatorCols : Data of  indicatorCols  will be fed into the deep model as multi-hot vectors.   indicatorDims : Dimensions of  indicatorCols . The dimensions of the data in  indicatorCols  should be within the range of  indicatorDims .  embedCols : Data of  embedCols  will be fed into the deep model as embeddings.  embedInDims : Input dimension of the data in  embedCols . The dimensions of the data in  embedCols  should be within the range of  embedInDims .  embedOutDims : The dimensions of embeddings for  embedCols .  continuousCols : Data of  continuousCols  will be treated as continuous values for the deep model.  label : The name of the 'label' column. String. Default is \"label\".   Remark:  Fields that involve  Cols  should be an array of String (Scala) or a list of String (Python) indicating the name of the columns in the data.  Fields that involve  Dims  should be an array of integers (Scala) or a list of integers (Python) indicating the dimensions of the corresponding columns.  If any field is not specified, it will by default to be an empty array (Scala) or an empty list (Python).  Scala  ColumnFeatureInfo(\n    wideBaseCols = Array[String](),\n    wideBaseDims = Array[Int](),\n    wideCrossCols = Array[String](),\n    wideCrossDims = Array[Int](),\n    indicatorCols = Array[String](),\n    indicatorDims = Array[Int](),\n    embedCols = Array[String](),\n    embedInDims = Array[Int](),\n    embedOutDims = Array[Int](),\n    continuousCols = Array[String](),\n    label =  label )  Python  ColumnFeatureInfo(\n    wide_base_cols=None,\n    wide_base_dims=None,\n    wide_cross_cols=None,\n    wide_cross_dims=None,\n    indicator_cols=None,\n    indicator_dims=None,\n    embed_cols=None,\n    embed_in_dims=None,\n    embed_out_dims=None,\n    continuous_cols=None,\n    label= label )", 
            "title": "ColumnFeatureInfo"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#neural-network-based-collaborative-filtering", 
            "text": "NCF ( He, 2015 ) leverages a multi-layer perceptrons to learn the user\u2013item interaction function. At the mean time, NCF can express and generalize matrix factorization under its framework.  includeMF (Boolean) is provided for users to build a  NeuralCF  model with or without matrix factorization.   After training the model, users can use the model to  do prediction and recommendation .  Scala  NeuralCF(userCount, itemCount, numClasses, userEmbed = 20, itemEmbed = 20, hiddenLayers = Array(40, 20, 10), includeMF = true, mfEmbed = 20)   userCount : The number of users. Positive integer.  itemCount : The number of items. Positive integer.  numClasses : The number of classes. Positive integer.  userEmbed : Units of user embedding. Positive integer. Default is 20.  itemEmbed : Units of item embedding. Positive integer. Default is 20.  hiddenLayers : Units hiddenLayers for MLP. Array of positive integers. Default is Array(40, 20, 10).  includeMF : Whether to include Matrix Factorization. Boolean. Default is true.  mfEmbed : Units of matrix factorization embedding. Positive integer. Default is 20.   See  here  for the Scala example that trains the  NeuralCF  model on MovieLens 1M dataset and uses the model to do prediction and recommendation.  Python  NeuralCF(user_count, item_count, class_num, user_embed=20, item_embed=20, hidden_layers=(40, 20, 10), include_mf=True, mf_embed=20)   user_count : The number of users. Positive int.  item_count : The number of classes. Positive int.  class_num:  The number of classes. Positive int.  user_embed : Units of user embedding. Positive int. Default is 20.  item_embed : itemEmbed Units of item embedding. Positive int. Default is 20.  hidden_layers : Units of hidden layers for MLP. Tuple of positive int. Default is (40, 20, 10).  include_mf : Whether to include Matrix Factorization. Boolean. Default is True.  mf_embed : Units of matrix factorization embedding. Positive int. Default is 20.   See  here  for the Python notebook that trains the  NeuralCF  model on MovieLens 1M dataset and uses the model to do prediction and recommendation.", 
            "title": "Neural network-based Collaborative Filtering"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#prediction-and-recommendation", 
            "text": "", 
            "title": "Prediction and Recommendation"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#predict-for-user-item-pairs", 
            "text": "Give prediction for each pair of user and item. Return RDD of  UserItemPrediction .  Scala  predictUserItemPair(featureRdd)  Python  predict_user_item_pair(feature_rdd)  Parameters:   featureRdd : RDD of  UserItemFeature .", 
            "title": "Predict for user-item pairs"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#recommend-for-users", 
            "text": "Recommend a number of items for each user. Return RDD of  UserItemPrediction .  Scala  recommendForUser(featureRdd, maxItems)  Python  recommend_for_user(feature_rdd, max_items)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxItems : The number of items to be recommended to each user. Positive integer.", 
            "title": "Recommend for users"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#recommend-for-items", 
            "text": "Recommend a number of users for each item. Return RDD of  UserItemPrediction .  Scala  recommendForItem(featureRdd, maxUsers)  Python  recommend_for_item(feature_rdd, max_users)  Parameters:   featureRdd : RDD of  UserItemFeature .  maxUsers : The number of users to be recommended to each item. Positive integer.", 
            "title": "Recommend for items"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemfeature", 
            "text": "Represent records of user-item with features.  Each record should contain the following fields:   userId : Positive integer.  item_id : Positive integer.  sample :  Sample  which consists of feature(s) and label(s).   Scala  UserItemFeature(userId, itemId, sample)  Python  UserItemFeature(user_id, item_id, sample)", 
            "title": "UserItemFeature"
        }, 
        {
            "location": "/APIGuide/Models/recommendation/#useritemprediction", 
            "text": "Represent the prediction results of user-item pairs.  Each prediction record will contain the following information:   userId : Positive integer.  itemId : Positive integer.  prediction : The prediction (rating) for the user on the item.  probability : The probability for the prediction.   Scala  UserItemPrediction(userId, itemId, prediction, probability)  Python  UserItemPrediction(user_id, item_id, prediction, probability)", 
            "title": "UserItemPrediction"
        }, 
        {
            "location": "/powered-by/", 
            "text": "Powered By", 
            "title": "Powered by"
        }, 
        {
            "location": "/powered-by/#powered-by", 
            "text": "", 
            "title": "Powered By"
        }, 
        {
            "location": "/known-issues/", 
            "text": "If you encounter the following exception when calling the Python API of Analytics Zoo:\n\n\n\n\nPy4JJavaError: An error occurred while calling z:org.apache.spark.bigdl.api.python.BigDLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\n\n\n\nyou may need to check whether your input argument involves Numpy types (such as \nnumpy.int64\n). See \nhere\n for the related issue.\n\n\nFor example, invoking \nnp.min\n, \nnp.max\n, \nnp.unique\n, etc. will return type \nnumpy.int64\n. One way to solve this is to use \nint()\n to convert a number of type \nnumpy.int64\n to a Python int.", 
            "title": "FAQ and Known Issues"
        }
    ]
}