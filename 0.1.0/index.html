<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="None">
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Analytics Zoo</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="./extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
      <script src="/js/elasticlunr.min.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '.';
      var is_top_frame = (window === window.parent);
        
        var pageToc = [
          {title: "Analytics Zoo", url: "#analytics-zoo", children: [
              {title: "What is Analytics Zoo?", url: "#what-is-analytics-zoo" },
              {title: "How to use Analytics Zoo?", url: "#how-to-use-analytics-zoo" },
              {title: "High level pipeline APIs", url: "#high-level-pipeline-apis" },
              {title: "Built-in deep learning models", url: "#built-in-deep-learning-models" },
              {title: "Reference use cases", url: "#reference-use-cases" },
          ]},
        ];

    </script>
    <script src="/js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>

<nav class="navbar wm-page-top-frame">
  <div class="container-fluid wm-top-container">
    
    <div class="wm-top-tool pull-right wm-vcenter">
      <form class="dropdown wm-vcentered" id="wm-search-form" action="./search.html">
        
        <button id="wm-search-show" class="btn btn-sm btn-default" type="submit"><i class="fa fa-search" aria-hidden="true"></i></button>                                                                           

        <div class="input-group input-group-sm wm-top-search">
          <input type="text" name="q" class="form-control" id="mkdocs-search-query" placeholder="Search">
          <span class="input-group-btn" role="search">
            
            <button class="btn btn-default dropdown-toggle collapse" data-toggle="dropdown" type="button"><span class="caret"></span></button>
            <ul id="mkdocs-search-results" class="dropdown-menu dropdown-menu-right"></ul>
            <button id="wm-search-go" class="btn btn-default" type="submit"><i class="fa fa-search" aria-hidden="true"></i></button>
          </span>
        </div>
      </form>
    </div>

    
    <div class="wm-top-tool wm-vcenter pull-right wm-small-left">
      <button id="wm-toc-button" type="button" class="btn btn-sm btn-default wm-vcentered"><i class="fa fa-th-list" aria-hidden="true"></i></button>
    </div>

    
    
    

    
    <div>
      <div class="wm-top-title">
        <a href="" class="wm-top-brand wm-top-link wm-vcenter ">
            <!--img class="wm-top-logo" src="/img/bigdl_logo.png"/-->
	    <span tilte="name">Analytics-Zoo</span>
        </a>
      </div>
      
      <div class="wm-top-title">
          <select id="versions" class="wm-top-link wm-top-more wm-top-version-select" onchange="javascript:switchVersion(this)">
          </select>
      </div>
      
    </div>
  </div>
</nav>

  <div id="main-content" class="wm-page-top-frame">
    
<nav class="wm-toc-pane">
  
    <ul class="wm-toctree wm-toc-repo">
      <li class="wm-toc-li wm-toc-lev1">
      <a class="wm-article-link wm-toc-text wm-toc-repolink" href="https://github.com/intel-analytics/analytics-zoo">
        <img class="wm-top-logo" src="/img/github.ico"/>
        Fork on GitHub 
      </a>
      </li>
    </ul>
  <ul class="wm-toctree">
        <li class="wm-toc-li wm-toc-lev1 "><a href="." class="wm-article-link wm-toc-text">Overview</a>
</li>
        <li class="wm-toc-li wm-toc-lev1 wm-toc-opener"><span class="wm-toc-text">Releases</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev2 "><a href="release-download/" class="wm-article-link wm-toc-text">Download</a>
</li>
      <li class="wm-toc-li wm-toc-lev2 "><a href="release-docs/" class="wm-article-link wm-toc-text">Documentation</a>
</li>
  </ul>
</li>

        <li class="wm-toc-li wm-toc-lev1 wm-toc-opener"><span class="wm-toc-text">User Guide</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Python</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="PythonUserGuide/install/" class="wm-article-link wm-toc-text">Install</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="PythonUserGuide/run/" class="wm-article-link wm-toc-text">Run</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="PythonUserGuide/examples/" class="wm-article-link wm-toc-text">Examples</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="PythonUserGuide/python-faq/" class="wm-article-link wm-toc-text">FAQ</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Scala</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="ScalaUserGuide/install/" class="wm-article-link wm-toc-text">Install</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ScalaUserGuide/run/" class="wm-article-link wm-toc-text">Run</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ScalaUserGuide/examples/" class="wm-article-link wm-toc-text">Examples</a>
</li>
  </ul>
</li>

  </ul>
</li>

        <li class="wm-toc-li wm-toc-lev1 wm-toc-opener"><span class="wm-toc-text">Programming Guide</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Pipeline APIs</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/nnframes/" class="wm-article-link wm-toc-text">DataFrame and ML Pipeline</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/autograd/" class="wm-article-link wm-toc-text">Autograd</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/transferlearning/" class="wm-article-link wm-toc-text">Transfer Learning</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Feature Engineering</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/workingwithimages/" class="wm-article-link wm-toc-text">Working with Images</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Built-in Models</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/object-detection/" class="wm-article-link wm-toc-text">Object Detection API</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/image-classification/" class="wm-article-link wm-toc-text">Image Classification API</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/text-classification/" class="wm-article-link wm-toc-text">Text Classification API</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/recommendation/" class="wm-article-link wm-toc-text">Recommendation API</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Reference Use Cases</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/usercases-overview/" class="wm-article-link wm-toc-text">Use Cases</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="ProgrammingGuide/anomaly-detection/" class="wm-article-link wm-toc-text">Anomaly Detection</a>
</li>
  </ul>
</li>

  </ul>
</li>

        <li class="wm-toc-li wm-toc-lev1 wm-toc-opener"><span class="wm-toc-text">API Guide</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Pipeline APIs</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/PipelineAPI/nnframes/" class="wm-article-link wm-toc-text">NNFrames</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/PipelineAPI/autograd/" class="wm-article-link wm-toc-text">Autograd</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/PipelineAPI/net/" class="wm-article-link wm-toc-text">Net</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Feature Engineering</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/FeatureEngineering/image/" class="wm-article-link wm-toc-text">Image</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/FeatureEngineering/preprocessing/" class="wm-article-link wm-toc-text">Preprocessing</a>
</li>
  </ul>
</li>

      <li class="wm-toc-li wm-toc-lev2 wm-toc-opener"><span class="wm-toc-text">Models</span>
</li>
<li class="wm-toc-li-nested collapse">
  <ul class="wm-toctree">
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/Models/object-detection/" class="wm-article-link wm-toc-text">Object Detection</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/Models/image-classification/" class="wm-article-link wm-toc-text">Image Classification</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/Models/text-classification/" class="wm-article-link wm-toc-text">Text Classification</a>
</li>
      <li class="wm-toc-li wm-toc-lev3 "><a href="APIGuide/Models/recommendation/" class="wm-article-link wm-toc-text">Recommendation</a>
</li>
  </ul>
</li>

  </ul>
</li>

        <li class="wm-toc-li wm-toc-lev1 "><a href="powered-by/" class="wm-article-link wm-toc-text">Powered by</a>
</li>
        <li class="wm-toc-li wm-toc-lev1 "><a href="known-issues/" class="wm-article-link wm-toc-text">FAQ and Known Issues</a>
</li>
  </ul>
</nav>

    <div class="wm-content-pane">
      <iframe class="wm-article" name="article"></iframe>
    </div>
  </div>

<div class="container-fluid wm-page-content">
    
    <h1><strong>Overview</strong></h1>
    <hr>
    <h1 id="analytics-zoo"><font size="6">Analytics Zoo</font></h1>
<p><em>Analytics + AI Platform for Apache Spark and <a href="https://bigdl-project.github.io/master/#whitepaper/">BigDL</a>.</em></p>
<hr />
<h2 id="what-is-analytics-zoo">What is Analytics Zoo?</h2>
<p>Analytics Zoo makes it easy to build deep learning application on Spark and BigDL, by providing an end-to-end <em>Analytics + AI Platform</em> (including high level pipeline APIs, built-in deep learning models, reference use cases, etc.).</p>
<ul>
<li>
<p><a href="#high-level-pipeline-apis">High level pipeline APIs</a></p>
<ul>
<li><a href="#nnframes">nnframes</a>: native deep learning support in <em>Spark DataFrames and ML Pipelines</em></li>
<li><a href="#autograd">autograd</a>: build custom layer/loss using <em>auto differentiation operations</em> </li>
<li><a href="#transfer-learning">Transfer learning</a>: customize pretained model for <em>feature extraction or fine-tuning</em></li>
</ul>
</li>
<li>
<p><a href="#built-in-deep-learning-models">Built-in deep learning models</a></p>
<ul>
<li><a href="#object-detection-api">Object detection API</a>: high-level API and pretrained models (e.g., SSD and Faster-RCNN) for <em>object detection</em></li>
<li><a href="#image-classification-api">Image classification API</a>: high-level API and pretrained models (e.g., VGG, Inception, ResNet, MobileNet, etc.) for <em>image classification</em></li>
<li><a href="#text-classification-api">Text classification API</a>: high-level API and pre-defined models (using CNN, LSTM, etc.) for <em>text classification</em></li>
<li><a href="#recommendation-api">Recommedation API</a>: high-level API and pre-defined models (e.g., Neural Collaborative Filtering, Wide and Deep Learning, etc.) for <em>recommendation</em></li>
</ul>
</li>
<li>
<p><a href="#reference-use-cases">Reference use cases</a>: a collection of end-to-end <em>reference use cases</em> (e.g., anomaly detection, sentiment analysis, fraud detection, image augmentation, object detection, variational autoencoder, etc.)</p>
</li>
</ul>
<h2 id="how-to-use-analytics-zoo">How to use Analytics Zoo?</h2>
<ul>
<li>
<p>To get started, please refer to the <a href="https://analytics-zoo.github.io/master/#PythonUserGuide/install/">Python install guide</a> or <a href="https://analytics-zoo.github.io/master/#ScalaUserGuide/install/">Scala install guide</a>.</p>
</li>
<li>
<p>For more information, You may refer to the <a href="https://analytics-zoo.github.io/">Analytis Zoo document website</a></p>
</li>
<li>
<p>For additional questions and discussions, you can join the <a href="https://groups.google.com/forum/#!forum/bigdl-user-group">Google User Group</a> (or subscribe to the <a href="mailto:bigdl-user-group+subscribe@googlegroups.com">Mail List</a>) </p>
</li>
</ul>
<hr />
<h2 id="high-level-pipeline-apis">High level pipeline APIs</h2>
<p>Analytics Zoo provides a set of easy-to-use, high level pipeline APIs that natively support Spark DataFrames and ML Pipelines, autograd and custom layer/loss, trasnfer learning, etc.</p>
<h3 id="nnframes">nnframes</h3>
<p><code>nnframes</code> provides <em>native deep learning support in Spark DataFrames and ML Pipelines</em>, so that you can easily build complex deep learning pipelines in just a few lines, as illustracted below. (See more details <a href="ProgrammingGuide/nnframes/">here</a>)</p>
<p>1.Initialize <em>NNContext</em> and load images into <em>DataFrames</em> using <code>NNImageReader</code></p>
<pre><code>   from zoo.common.nncontext import *
   from zoo.pipeline.nnframes import *
   sc = init_nncontext()
   imageDF = NNImageReader.readImages(image_path, sc)
</code></pre>

<p>2.Process loaded data using <em>DataFrames transformations</em></p>
<pre><code>   getName = udf(lambda row: ...)
   getLabel = udf(lambda name: ...)
   df = imageDF.withColumn(&quot;name&quot;, getName(col(&quot;image&quot;))).withColumn(&quot;label&quot;, getLabel(col('name')))
</code></pre>

<p>3.Processing image using built-in <em>feature engineering operations</em></p>
<pre><code>   from zoo.feature.image import *
   transformer = RowToImageFeature() -&gt; ImageResize(64, 64) -&gt; ImageChannelNormalize(123.0, 117.0, 104.0) \
                 -&gt; ImageMatToTensor() -&gt; ImageFeatureToTensor())
</code></pre>

<p>4.Define model using <em>Keras-style APIs</em></p>
<pre><code>   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *
   model = Sequential().add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1, 28, 28))) \
                   .add(MaxPooling2D(pool_size=(2, 2))).add(Flatten()).add(Dense(10, activation='softmax')))
</code></pre>

<p>5.Train model using <em>Spark ML Pipelines</em></p>
<pre><code>   classifier = NNClassifier(model, CrossEntropyCriterion(),transformer).setLearningRate(0.003) \
                   .setBatchSize(40).setMaxEpoch(1).setFeaturesCol(&quot;image&quot;).setCachingSample(False)
   nnModel = classifier.fit(df)
</code></pre>

<h3 id="autograd">autograd</h3>
<p><code>autograd</code> provides automatic differentiation for math operations, so that you can easily build your own <em>custom loss and layer</em> (in both Python and Scala), as illustracted below. (See more details <a href="ProgrammingGuide/autograd/">here</a>)</p>
<p>1.Define custom functions using <code>autograd</code></p>
<pre><code>   from zoo.pipeline.api.autograd import *

   def mean_absolute_error(y_true, y_pred):
       return mean(abs(y_true - y_pred), axis=1)

   def add_one_func(x):
       return x + 1.0
</code></pre>

<p>2.Define model using Keras-style API and <em>custom <code>Lambda</code> layer</em></p>
<pre><code>   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *
   model = Sequential().add(Dense(1, input_shape=(2,))) \
                       .add(Lambda(function=add_one_func))
</code></pre>

<p>3.Train model with <em>custom loss function</em></p>
<pre><code>   model.compile(optimizer = SGD(), loss = mean_absolute_error)
   model.fit(x = ..., y = ...)
</code></pre>

<h3 id="transfer-learning">Transfer learning</h3>
<p>Using the high level transfer learning APIs, you can easily customize pretrained models for <em>feature extraction or fine-tuning</em>. (See more details <a href="ProgrammingGuide/transferlearning/">here</a>)</p>
<p>1.Load an existing model (pretrained in Caffe)</p>
<pre><code>   from zoo.pipeline.api.net import *
   full_model = Net.load_caffe(def_path, model_path)
</code></pre>

<p>2.Remove last few layers</p>
<pre><code>   # create a new model by remove layers after pool5/drop_7x7_s1
   model = full_model.new_graph([&quot;pool5/drop_7x7_s1&quot;])
</code></pre>

<p>3.Freeze first few layers</p>
<pre><code>   # freeze layers from input to pool4/3x3_s2 inclusive
   model.freeze_up_to([&quot;pool4/3x3_s2&quot;])
</code></pre>

<p>4.Add a few new layers</p>
<pre><code>   from zoo.pipeline.api.keras.layers import *
   from zoo.pipeline.api.keras.models import *
   inputs = Input(name=&quot;input&quot;, shape=(3, 224, 224))
   inception = model.to_keras()(inputs)
   flatten = Flatten()(inception)
   logits = Dense(2)(flatten)
   newModel = Model(inputs, logits)
</code></pre>

<hr />
<h2 id="built-in-deep-learning-models">Built-in deep learning models</h2>
<p>Analytics Zoo provides several built-in deep learning models that you can use for a variety of problem types, such as <em>object detection</em>, <em>image classification</em>, <em>text classification</em>, <em>recommendation</em>, etc.</p>
<h3 id="object-detection-api">Object detection API</h3>
<p>Using <em>Analytics Zoo Object Detection API</em> (including a set of pretrained detection models such as SSD and Faster-RCNN), you can easily build your object detection applications (e.g., localizing and identifying multiple objects in images and videos), as illustrated below. (See more details <a href="ProgrammingGuide/object-detection/">here</a>)</p>
<p>1.Download object detection models in Analytics Zoo</p>
<p>You can download a collection of detection models (pretrained on the PSCAL VOC dataset and COCO dataset) from <a href="ProgrammingGuide/object-detection/#download-link">detection model zoo</a>.</p>
<p>2.Use <em>Object Detection API</em> for off-the-shell inference</p>
<pre><code>   from zoo.models.image.objectdetection import *
   model = ObjectDetector.load_model(model_path)
   image_set = ImageSet.read(img_path, sc)
   output = model.predict_image_set(image_set)
</code></pre>

<h3 id="image-classification-api">Image classification API</h3>
<p>Using <em>Analytics Zoo Image Classification API</em> (including a set of pretrained detection models such as VGG, Inception, ResNet, MobileNet,  etc.), you can easily build your image classification applications, as illustrated below. (See more details <a href="ProgrammingGuide/image-classification/">here</a>)</p>
<p>1.Download image classification models in Analytics Zoo</p>
<p>You can download a collection of image classification models (pretrained on the ImageNet dataset) from <a href="ProgrammingGuide/image-classification/#download-link">image classification model zoo</a></p>
<p>2.Use <em>Image classification API</em> for off-the-shell inference</p>
<pre><code>   from zoo.models.image.imageclassification import *
   model = ImageClassifier.load_model(model_path)
   image_set = ImageSet.read(img_path, sc)
   output = model.predict_image_set(image_set)
</code></pre>

<h3 id="text-classification-api">Text classification API</h3>
<p><em>Analytics Zoo Text Classification API</em> provides a set of pre-defined models (using CNN, LSTM, etc.) for text classifications. (See more details <a href="ProgrammingGuide/text-classification/">here</a>)</p>
<h3 id="recommendation-api">Recommendation API</h3>
<p><em>Analytics Zoo Recommendation API</em> provides a set of pre-defined models (such as Neural Collaborative Filtering, Wide and Deep Learning, etc.) for recommendations. (See more details <a href="ProgrammingGuide/recommendation/">here</a>)</p>
<hr />
<h2 id="reference-use-cases">Reference use cases</h2>
<p>Analytics Zoo provides a collection of end-to-end reference use cases, including <em>anomaly detection (for time series data)</em>, <em>sentiment analysis</em>, <em>fraud detection</em>, <em>image augmentation</em>, <em>object detection</em>, <em>variational autoencoder</em>, etc. (See more details <a href="ProgrammingGuide/usercases-overview/">here</a>)</p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>
<!--
MkDocs version : 0.16.3
Build Date UTC : 2019-02-01 15:29:50
-->